{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706e4687-b9d8-41da-9f4c-1e19f84a14ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T10:23:14.646426Z",
     "start_time": "2025-08-04T10:23:09.734362Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import os\n",
    "import sys\n",
    "os.chdir('L:\\\\SPEC\\\\ICU\\\\RESEARCH\\\\Data-onderzoek\\\\studenten\\\\Econometrie\\\\Bao Phung\\\\Jip')\n",
    "sys.path.insert(0, 'L:\\\\SPEC\\\\ICU\\\\RESEARCH\\\\Data-onderzoek\\\\studenten\\\\Econometrie\\\\Bao Phung\\\\Jip')\n",
    "\n",
    "import importlib\n",
    "import scripts.vrae\n",
    "importlib.reload(scripts.vrae)\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Load local scripts\n",
    "# Add scripts folder to sys.path so scripts can be imported\n",
    "sys.path.insert(1, 'scripts')\n",
    "from scripts.data_functions import load_ecg_data,addDamicAdmissionData, load_selected_ecg\n",
    "from scripts.visualisation import plot_ecgs_per_location, plot_ecgs_at_ICU, plot_ecgs_per_year\n",
    "\n",
    "from scripts.vrae import VRAE\n",
    "\n",
    "from scripts.utils import *\n",
    "# ============= #\n",
    "# Load ECG data #\n",
    "# ============= #\n",
    "\n",
    "# Set quickload to True if you only want to quickly read the ECG metadata.\n",
    "# Set quickload to False if you want to load all ECG data including the\n",
    "# waveform data (this can take multiple hours).\n",
    "quickload = True\n",
    "makePlots = False # Set to True for overview plots\n",
    "save = True\n",
    "\n",
    "# Specify folder directories\n",
    "data_path = r\"L:/SPEC/ICU/RESEARCH/Data-onderzoek/ECG dataset/data\"\n",
    "local_ecg_path = r\"L:/SPEC/ICU/RESEARCH/Data-onderzoek/ECG dataset/XML subset\"\n",
    "figure_path = \"figures\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5904af4c79aebf0d",
   "metadata": {},
   "source": [
    "Run quickloads and make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4279a1d14458331c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T10:25:05.388422Z",
     "start_time": "2025-08-04T10:23:16.758997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[2KAdmission 23700/23777"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:\\SPEC\\ICU\\RESEARCH\\Data-onderzoek\\studenten\\Econometrie\\Bao Phung\\Jip\\scripts\\data_functions.py:409: FutureWarning:\n",
      "\n",
      "Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-58 days +12:09:09' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "\n",
      "L:\\SPEC\\ICU\\RESEARCH\\Data-onderzoek\\studenten\\Econometrie\\Bao Phung\\Jip\\scripts\\data_functions.py:396: FutureWarning:\n",
      "\n",
      "Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0 days 00:00:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[2KECG 295800/295813"
     ]
    }
   ],
   "source": [
    "if quickload:\n",
    "    df_ecg = load_ecg_data(data_path = data_path,\n",
    "                           quickload = quickload)\n",
    "else:\n",
    "    load_ecg_data(local_ecg_path = local_ecg_path, quickload = quickload)\n",
    "\n",
    "# =============== #\n",
    "# Add DAM-IC data #\n",
    "# =============== #\n",
    "# Load DAM-IC data\n",
    "mostRecentDamicFile = r\"L:\\SPEC\\ICU\\RESEARCH\\Data-onderzoek\\Basisdataset\\DAM-IC\\Definitief cohort versies\\ADAMICPatientCohort_HrCorrected2013-2023_hashed_2024-10-15.csv\"\n",
    "df_ecg=addDamicAdmissionData(df_ecg, mostRecentDamicFile)\n",
    "\n",
    "\n",
    "\n",
    "# ============== #\n",
    "# Visualise data #\n",
    "# ============== #\n",
    "if makePlots:\n",
    "    plot_ecgs_per_location(df_ecg, save = save, save_path = figure_path)\n",
    "\n",
    "    plot_ecgs_at_ICU(df_ecg, save = save, save_path = figure_path)\n",
    "\n",
    "    plot_ecgs_per_year(df_ecg, save = save, save_path = figure_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0d3ac8ecc0b3",
   "metadata": {},
   "source": [
    "Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99157fe6033447e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:20:29.885303Z",
     "start_time": "2025-08-03T14:20:29.182046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>PatientAge.1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Site</th>\n",
       "      <th>SiteName</th>\n",
       "      <th>RoomID</th>\n",
       "      <th>AcquisitionDevice</th>\n",
       "      <th>...</th>\n",
       "      <th>AcquisitionDateTime</th>\n",
       "      <th>isBeforeIcu</th>\n",
       "      <th>isAfterIcu</th>\n",
       "      <th>isDuringIcu</th>\n",
       "      <th>timeToNextIcu</th>\n",
       "      <th>timeSincePrevIcu</th>\n",
       "      <th>uniqueEncId</th>\n",
       "      <th>isDuring24HrICU</th>\n",
       "      <th>timeToNextIcu_hours</th>\n",
       "      <th>timeSincePrevIcu_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSE_20240429_164621_29000.XML</td>\n",
       "      <td>61124542.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>RESTING</td>\n",
       "      <td>1</td>\n",
       "      <td>MUMC+</td>\n",
       "      <td>SEH 20</td>\n",
       "      <td>DatamedFT</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-12-30 21:50:51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-58 days +12:09:09</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1379.847500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSE_20240429_164622_89000.XML</td>\n",
       "      <td>61124542.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>RESTING</td>\n",
       "      <td>1</td>\n",
       "      <td>MUMC+</td>\n",
       "      <td>SEH 20</td>\n",
       "      <td>DatamedFT</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-12-30 21:51:46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-58 days +12:08:14</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1379.862778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MUSE_20240429_164624_33000.XML</td>\n",
       "      <td>41240760.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESTING</td>\n",
       "      <td>1</td>\n",
       "      <td>MUMC+</td>\n",
       "      <td>SEH 10</td>\n",
       "      <td>DatamedFT</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-12-30 23:58:43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1895 days +10:01:17</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-45469.978611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSE_20240429_164625_15000.XML</td>\n",
       "      <td>72524034.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESTING</td>\n",
       "      <td>1</td>\n",
       "      <td>MUMC+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAC55</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-12-30 21:14:25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-2 days +14:45:35</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.240278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MUSE_20240429_164626_90000.XML</td>\n",
       "      <td>72524034.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESTING</td>\n",
       "      <td>1</td>\n",
       "      <td>MUMC+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAC55</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-12-30 21:14:06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-2 days +14:45:54</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MUSE_20240429_164628_49000.XML</td>\n",
       "      <td>72524034.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESTING</td>\n",
       "      <td>1</td>\n",
       "      <td>MUMC+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAC55</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-12-30 21:12:47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-2 days +14:47:13</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.213056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MUSE_20240429_164629_34000.XML</td>\n",
       "      <td>61782061.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESTING</td>\n",
       "      <td>1</td>\n",
       "      <td>MUMC+</td>\n",
       "      <td>SEH 14</td>\n",
       "      <td>DatamedFT</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-12-30 19:53:17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-2366 days +20:06:43</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-56763.888056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MUSE_20240429_164631_93000.XML</td>\n",
       "      <td>21048206.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESTING</td>\n",
       "      <td>1</td>\n",
       "      <td>MUMC+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAC55</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-12-30 18:35:33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MUSE_20240429_164632_84000.XML</td>\n",
       "      <td>21048206.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESTING</td>\n",
       "      <td>1</td>\n",
       "      <td>MUMC+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAC55</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-12-30 16:31:21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MUSE_20240429_164633_32000.XML</td>\n",
       "      <td>21048206.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESTING</td>\n",
       "      <td>1</td>\n",
       "      <td>MUMC+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAC55</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-12-30 16:25:33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename   PatientID  PatientAge  PatientAge.1  \\\n",
       "0  MUSE_20240429_164621_29000.XML  61124542.0        78.0          78.0   \n",
       "1  MUSE_20240429_164622_89000.XML  61124542.0        78.0          78.0   \n",
       "2  MUSE_20240429_164624_33000.XML  41240760.0        88.0          88.0   \n",
       "3  MUSE_20240429_164625_15000.XML  72524034.0        68.0          68.0   \n",
       "4  MUSE_20240429_164626_90000.XML  72524034.0        68.0          68.0   \n",
       "5  MUSE_20240429_164628_49000.XML  72524034.0        68.0          68.0   \n",
       "6  MUSE_20240429_164629_34000.XML  61782061.0        73.0          73.0   \n",
       "7  MUSE_20240429_164631_93000.XML  21048206.0        76.0          76.0   \n",
       "8  MUSE_20240429_164632_84000.XML  21048206.0        76.0          76.0   \n",
       "9  MUSE_20240429_164633_32000.XML  21048206.0        76.0          76.0   \n",
       "\n",
       "   Gender DataType  Site SiteName  RoomID AcquisitionDevice  ...  \\\n",
       "0    MALE  RESTING     1    MUMC+  SEH 20         DatamedFT  ...   \n",
       "1    MALE  RESTING     1    MUMC+  SEH 20         DatamedFT  ...   \n",
       "2  FEMALE  RESTING     1    MUMC+  SEH 10         DatamedFT  ...   \n",
       "3  FEMALE  RESTING     1    MUMC+     NaN             MAC55  ...   \n",
       "4  FEMALE  RESTING     1    MUMC+     NaN             MAC55  ...   \n",
       "5  FEMALE  RESTING     1    MUMC+     NaN             MAC55  ...   \n",
       "6  FEMALE  RESTING     1    MUMC+  SEH 14         DatamedFT  ...   \n",
       "7  FEMALE  RESTING     1    MUMC+     NaN             MAC55  ...   \n",
       "8  FEMALE  RESTING     1    MUMC+     NaN             MAC55  ...   \n",
       "9  FEMALE  RESTING     1    MUMC+     NaN             MAC55  ...   \n",
       "\n",
       "  AcquisitionDateTime isBeforeIcu isAfterIcu  isDuringIcu  timeToNextIcu  \\\n",
       "0 2023-12-30 21:50:51           0          1            0            NaT   \n",
       "1 2023-12-30 21:51:46           0          1            0            NaT   \n",
       "2 2023-12-30 23:58:43           0          1            0            NaT   \n",
       "3 2023-12-30 21:14:25           0          1            0            NaT   \n",
       "4 2023-12-30 21:14:06           0          1            0            NaT   \n",
       "5 2023-12-30 21:12:47           0          1            0            NaT   \n",
       "6 2023-12-30 19:53:17           0          1            0            NaT   \n",
       "7 2023-12-30 18:35:33           0          0            0            NaT   \n",
       "8 2023-12-30 16:31:21           0          0            0            NaT   \n",
       "9 2023-12-30 16:25:33           0          0            0            NaT   \n",
       "\n",
       "       timeSincePrevIcu  uniqueEncId  isDuring24HrICU  timeToNextIcu_hours  \\\n",
       "0    -58 days +12:09:09         <NA>                0                  NaN   \n",
       "1    -58 days +12:08:14         <NA>                0                  NaN   \n",
       "2  -1895 days +10:01:17         <NA>                0                  NaN   \n",
       "3     -2 days +14:45:35         <NA>                0                  NaN   \n",
       "4     -2 days +14:45:54         <NA>                0                  NaN   \n",
       "5     -2 days +14:47:13         <NA>                0                  NaN   \n",
       "6  -2366 days +20:06:43         <NA>                0                  NaN   \n",
       "7                   NaT         <NA>                0                  NaN   \n",
       "8                   NaT         <NA>                0                  NaN   \n",
       "9                   NaT         <NA>                0                  NaN   \n",
       "\n",
       "   timeSincePrevIcu_hours  \n",
       "0            -1379.847500  \n",
       "1            -1379.862778  \n",
       "2           -45469.978611  \n",
       "3              -33.240278  \n",
       "4              -33.235000  \n",
       "5              -33.213056  \n",
       "6           -56763.888056  \n",
       "7                     NaN  \n",
       "8                     NaN  \n",
       "9                     NaN  \n",
       "\n",
       "[10 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations: 295813\n",
      "Observations with an encounter ID (ICU): 36569\n",
      "Percentage of observations with a unique encounter ID: 12.36%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at head of df\n",
    "display(df_ecg.head(10))\n",
    "\n",
    "# Proportion of patients with unique encounter ID\n",
    "total_observations =  df_ecg.shape[0]\n",
    "icu_observations = df_ecg['uniqueEncId'].notna().sum()\n",
    "percentage_with_encounter_id = icu_observations / df_ecg.shape[0] * 100\n",
    "\n",
    "print(f\"Total observations: {total_observations}\")\n",
    "print(f\"Observations with an encounter ID (ICU): {icu_observations}\")\n",
    "print(f\"Percentage of observations with a unique encounter ID: {percentage_with_encounter_id:.2f}%\")\n",
    "\n",
    "\n",
    "def encounter_counts_plot(df):\n",
    "    \"\"\"\n",
    "    Plots a histogram where the x-axis represents the number of rows for each unique EncounterID\n",
    "    and the y-axis represents how many unique EncounterIDs have that number of rows.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The dataframe containing the 'EncounterID' column.\n",
    "    \"\"\"\n",
    "    # Count the occurrences of each EncounterID using value_counts()\n",
    "    encounter_counts = df['uniqueEncId'].value_counts()\n",
    "\n",
    "    # Count how many EncounterIDs have the same number of rows\n",
    "    encounter_frequency = encounter_counts.value_counts()\n",
    "\n",
    "    #\n",
    "\n",
    "    # Plot the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    encounter_frequency.sort_index().plot(kind='bar', edgecolor='black')\n",
    "    plt.title('Distribution of Encounter Counts')\n",
    "    plt.xlabel('Number of ECGs for Each Encounter ID')\n",
    "    plt.ylabel('Number of Unique EncounterIDs')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your dataframe\n",
    "encounter_counts_plot(df_ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80562bd2fc98a35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:20:36.405409Z",
     "start_time": "2025-08-03T14:20:36.291840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique patients with ECG in first 24h: 9074\n",
      "Percentage of those patients out of total patients: 83.63%\n",
      "                              filename uniqueEncId\n",
      "172859  MUSE_20240502_162122_67000.XML       23872\n",
      "76062   MUSE_20240430_231805_60000.XML     1719688\n",
      "107339  MUSE_20240501_121655_57000.XML     1757036\n",
      "226202  MUSE_20240503_153423_42000.XML     2895998\n",
      "6339    MUSE_20240429_190151_87000.XML     4605079\n"
     ]
    }
   ],
   "source": [
    "# Count how many patients that has an ECG recording during the first 24 hours of ICU admission.\n",
    "def count_ecg_within_24h(df_ecg):\n",
    "    \"\"\"\n",
    "    Counts unique patients with at least one ECG recorded in the first 24 hours of ICU admission.\n",
    "    Also calculates the percentage of these patients out of all unique patients.\n",
    "\n",
    "    Parameters:\n",
    "        df_ecg (pd.DataFrame): DataFrame containing ECG data with columns 'uniqueEncId' and 'isDuring24HrICU'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (count of patients with ECG in first 24h, percentage of total patients)\n",
    "    \"\"\"\n",
    "\n",
    "    # Count unique patients who had an ECG within the first 24 hours\n",
    "    unique_patients_24h = df_ecg[df_ecg[\"isDuring24HrICU\"] == 1][\"uniqueEncId\"].nunique()\n",
    "\n",
    "    # Count total unique patients\n",
    "    total_unique_patients = df_ecg[\"uniqueEncId\"].nunique()\n",
    "\n",
    "    # Compute percentage\n",
    "    percentage_24h = (unique_patients_24h / total_unique_patients) * 100 if total_unique_patients > 0 else 0\n",
    "\n",
    "    return unique_patients_24h, percentage_24h\n",
    "\n",
    "\n",
    "# Apply to df_ecg\n",
    "num_patients, percent_patients = count_ecg_within_24h(df_ecg)\n",
    "print(f\"Unique patients with ECG in first 24h: {num_patients}\")\n",
    "print(f\"Percentage of those patients out of total patients: {percent_patients:.2f}%\")\n",
    "\n",
    "\n",
    "# Find the earliest ECG (by AcquisitionDateTime) for each unique patient who had at least one ECG recorded in the first 24 hours of ICU admission.\n",
    "def get_first_ecg_within_24h(df_ecg):\n",
    "    \"\"\"\n",
    "    Finds the earliest ECG (by AcquisitionDateTime) for each unique patient (uniqueEncId)\n",
    "    who had at least one ECG recorded in the first 24 hours of ICU admission (isDuring24HrICU == 1).\n",
    "\n",
    "    Parameters:\n",
    "        df_ecg (pd.DataFrame): DataFrame containing ECG data with columns 'uniqueEncId', 'isDuring24HrICU',\n",
    "                               'AcquisitionDateTime', and 'filename'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with 'filename' and 'uniqueEncId' for the first ECG recorded within 24h.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter only records where isDuring24HrICU is 1\n",
    "    df_24h = df_ecg[df_ecg[\"isDuring24HrICU\"] == 1]\n",
    "\n",
    "    # Find the first (earliest) ECG per uniqueEncId\n",
    "    df_first_ecg = df_24h.loc[\n",
    "        df_24h.groupby(\"uniqueEncId\")[\"AcquisitionDateTime\"].idxmin(), [\"filename\", \"uniqueEncId\"]]\n",
    "\n",
    "    return df_first_ecg\n",
    "\n",
    "\n",
    "# Apply to df_ecg\n",
    "df_first_ecg = get_first_ecg_within_24h(df_ecg)\n",
    "print(df_first_ecg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbafd65222f84afa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:20:41.412590Z",
     "start_time": "2025-08-03T14:20:41.376448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              filename uniqueEncId\n",
      "172859  MUSE_20240502_162122_67000.XML       23872\n",
      "76062   MUSE_20240430_231805_60000.XML     1719688\n",
      "107339  MUSE_20240501_121655_57000.XML     1757036\n",
      "226202  MUSE_20240503_153423_42000.XML     2895998\n",
      "6339    MUSE_20240429_190151_87000.XML     4605079\n"
     ]
    }
   ],
   "source": [
    "# Find the earliest ECG (by AcquisitionDateTime) for each unique patient who had at least one ECG recorded in the first 24 hours of ICU admission.\n",
    "def get_first_ecg_within_24h(df_ecg):\n",
    "    \"\"\"\n",
    "    Finds the earliest ECG (by AcquisitionDateTime) for each unique patient (uniqueEncId)\n",
    "    who had at least one ECG recorded in the first 24 hours of ICU admission (isDuring24HrICU == 1).\n",
    "\n",
    "    Parameters:\n",
    "        df_ecg (pd.DataFrame): DataFrame containing ECG data with columns 'uniqueEncId', 'isDuring24HrICU',\n",
    "                               'AcquisitionDateTime', and 'filename'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with 'filename' and 'uniqueEncId' for the first ECG recorded within 24h.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter only records where isDuring24HrICU is 1\n",
    "    df_24h = df_ecg[df_ecg[\"isDuring24HrICU\"] == 1]\n",
    "\n",
    "    # Find the first (earliest) ECG per uniqueEncId\n",
    "    df_first_ecg = df_24h.loc[df_24h.groupby(\"uniqueEncId\")[\"AcquisitionDateTime\"].idxmin(), [\"filename\", \"uniqueEncId\"]]\n",
    "\n",
    "    return df_first_ecg\n",
    "\n",
    "# Apply to df_ecg\n",
    "df_first_ecg = get_first_ecg_within_24h(df_ecg)\n",
    "print(df_first_ecg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac3508b53472e59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T15:07:53.948935Z",
     "start_time": "2025-08-03T15:07:23.080488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/9074 ECG files...\n",
      "Processed 907/9074 ECG files...\n",
      "Processed 1814/9074 ECG files...\n",
      "Processed 2721/9074 ECG files...\n",
      "Processed 3628/9074 ECG files...\n",
      "Processed 4535/9074 ECG files...\n",
      "Skipping MUSE_20240502_122237_46000.XML - 14 leads detected.\n",
      "Processed 5442/9074 ECG files...\n",
      "Processed 6349/9074 ECG files...\n",
      "Processed 8163/9074 ECG files...\n",
      "Processed 9070/9074 ECG files...\n",
      "Loading ECGs took 28.06 minutes.\n",
      "Excluded 1 files due to excess leads.\n",
      "Excluded 1785 files due to missing numeric ECG values.\n",
      "\n",
      "Final Time-Matched Merged DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7288 entries, Unnamed 0 to Unnamed 7286\n",
      "Data columns (total 31 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   filename             7288 non-null   object        \n",
      " 1   PatientID            7288 non-null   int64         \n",
      " 2   PatientAge           7288 non-null   object        \n",
      " 3   Gender               7288 non-null   object        \n",
      " 4   VentricularRate      7288 non-null   object        \n",
      " 5   AtrialRate           7288 non-null   object        \n",
      " 6   PRInterval           7288 non-null   object        \n",
      " 7   QRSDuration          7288 non-null   object        \n",
      " 8   QTInterval           7288 non-null   object        \n",
      " 9   QTCorrected          7288 non-null   object        \n",
      " 10  PAxis                7288 non-null   object        \n",
      " 11  RAxis                7288 non-null   object        \n",
      " 12  TAxis                7288 non-null   object        \n",
      " 13  QRSCount             7288 non-null   object        \n",
      " 14  ECGSampleBase        7288 non-null   object        \n",
      " 15  ECGSampleExponent    7288 non-null   object        \n",
      " 16  QTcFrederica         7288 non-null   object        \n",
      " 17  AcquisitionDateTime  7288 non-null   datetime64[ns]\n",
      " 18  gender               6693 non-null   object        \n",
      " 19  nice_age             6693 non-null   object        \n",
      " 20  length               6519 non-null   object        \n",
      " 21  weight               6539 non-null   object        \n",
      " 22  nice_died            6693 non-null   object        \n",
      " 23  los_hosp             6634 non-null   object        \n",
      " 24  nice_ap4_prob        6690 non-null   object        \n",
      " 25  nice_ap4_model       6693 non-null   object        \n",
      " 26  cardiogroep          6693 non-null   object        \n",
      " 27  cardio_vasc_insuf    6693 non-null   object        \n",
      " 28  adm_type             6689 non-null   object        \n",
      " 29  nice_adm_icu         6693 non-null   object        \n",
      " 30  nice_dis_icu         6693 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(29)\n",
      "memory usage: 1.8+ MB\n",
      "None\n",
      "                                 filename  PatientID PatientAge  Gender  \\\n",
      "Unnamed 0  MUSE_20240502_162122_67000.XML   22087758         56    MALE   \n",
      "Unnamed 1  MUSE_20240430_231805_60000.XML   11467543         53    MALE   \n",
      "Unnamed 2  MUSE_20240501_121655_57000.XML   71140451         80    MALE   \n",
      "Unnamed 3  MUSE_20240503_153423_42000.XML   11968221         48    MALE   \n",
      "Unnamed 4  MUSE_20240429_190151_87000.XML   31426522         70  FEMALE   \n",
      "\n",
      "          VentricularRate AtrialRate PRInterval QRSDuration QTInterval  \\\n",
      "Unnamed 0             111        111        162         102        350   \n",
      "Unnamed 1              95         95        128         104        352   \n",
      "Unnamed 2              75         75        160         176        486   \n",
      "Unnamed 3              77         77        124          74        364   \n",
      "Unnamed 4             101        101        117          61        308   \n",
      "\n",
      "          QTCorrected  ... weight nice_died los_hosp nice_ap4_prob  \\\n",
      "Unnamed 0         476  ...   80.0         0      5.0      0.004013   \n",
      "Unnamed 1         442  ...   84.0         0     28.0      0.074479   \n",
      "Unnamed 2         542  ...   75.0         1      1.0      0.972723   \n",
      "Unnamed 3         411  ...   80.0         0      4.0       0.00453   \n",
      "Unnamed 4         400  ...   80.0         0     17.0       0.26745   \n",
      "\n",
      "          nice_ap4_model cardiogroep cardio_vasc_insuf adm_type  \\\n",
      "Unnamed 0           CABG           1                 0      2.0   \n",
      "Unnamed 1       NON CABG           0                 0      1.0   \n",
      "Unnamed 2       NON CABG           0                 0      1.0   \n",
      "Unnamed 3           CABG           1                 0      4.0   \n",
      "Unnamed 4       NON CABG           3                 0      2.0   \n",
      "\n",
      "                  nice_adm_icu         nice_dis_icu  \n",
      "Unnamed 0  2016-09-24 02:00:00  2016-09-26 11:18:00  \n",
      "Unnamed 1  2021-02-19 13:26:00  2021-03-19 12:07:00  \n",
      "Unnamed 2  2019-09-22 14:00:00  2019-09-23 10:16:00  \n",
      "Unnamed 3  2014-01-17 13:11:00  2014-01-18 14:00:00  \n",
      "Unnamed 4  2023-08-08 15:30:00  2023-08-14 11:31:00  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load ECG selection\n",
    "select_df = df_first_ecg\n",
    "\n",
    "# Load ECG waveform data\n",
    "df_selected_wave, x_ecg, ecg_data = load_selected_ecg(\n",
    "    selected=select_df,\n",
    "    local_ecg_path=r\"L:/SPEC/ICU/RESEARCH/Data-onderzoek/ECG dataset/XML Rosmalen\",\n",
    "    data_path=data_path,\n",
    "    scale=False,\n",
    "    save=False\n",
    ")\n",
    "\n",
    "# Load and prepare MDS metadata\n",
    "mds_path = r\"L:\\SPEC\\ICU\\RESEARCH\\Data-onderzoek\\studenten\\Econometrie\\Bao Phung\\ECG loading scripts\\data\\MDS dataset 2013-2024_withPatientNumbers.xlsx\"\n",
    "mds_df = pd.read_excel(mds_path)\n",
    "\n",
    "# Required columns including ICU admission/discharge\n",
    "columns_needed = [\n",
    "    'lifetimeNumber', 'gender', 'nice_age', 'length', 'weight', 'nice_died',\n",
    "    'los_hosp', 'nice_ap4_prob', 'nice_ap4_model', 'cardiogroep',\n",
    "    'cardio_vasc_insuf', 'adm_type', 'nice_adm_icu', 'nice_dis_icu'\n",
    "]\n",
    "mds_df = mds_df[columns_needed]\n",
    "\n",
    "# Type conversions\n",
    "df_selected_wave['PatientID'] = pd.to_numeric(df_selected_wave['PatientID'], errors='coerce')\n",
    "mds_df['lifetimeNumber'] = pd.to_numeric(mds_df['lifetimeNumber'], errors='coerce')\n",
    "\n",
    "df_selected_wave['AcquisitionDateTime'] = pd.to_datetime(df_selected_wave['AcquisitionDateTime'], errors='coerce')\n",
    "mds_df['nice_adm_icu'] = pd.to_datetime(mds_df['nice_adm_icu'], errors='coerce')\n",
    "mds_df['nice_dis_icu'] = pd.to_datetime(mds_df['nice_dis_icu'], errors='coerce')\n",
    "\n",
    "# Drop rows with critical missing values\n",
    "df_selected_wave.dropna(subset=['PatientID', 'AcquisitionDateTime'], inplace=True)\n",
    "mds_df.dropna(subset=['lifetimeNumber', 'nice_adm_icu', 'nice_dis_icu'], inplace=True)\n",
    "\n",
    "# Initialize list for merged rows\n",
    "merged_rows = []\n",
    "\n",
    "# Iterate through selected ECGs\n",
    "for _, ecg_row in df_selected_wave.iterrows():\n",
    "    pid = ecg_row['PatientID']\n",
    "    acq_time = ecg_row['AcquisitionDateTime']\n",
    "\n",
    "    # Filter MDS rows matching PID and ICU window\n",
    "    valid_mds = mds_df[\n",
    "        (mds_df['lifetimeNumber'] == pid) &\n",
    "        (mds_df['nice_adm_icu'] <= acq_time) &\n",
    "        (mds_df['nice_dis_icu'] >= acq_time)\n",
    "    ]\n",
    "\n",
    "    if not valid_mds.empty:\n",
    "        # Take the first valid ICU stay metadata (if multiple)\n",
    "        matched_metadata = valid_mds.iloc[0].drop(labels='lifetimeNumber')\n",
    "    else:\n",
    "        # No valid metadata -> fill with NaNs\n",
    "        matched_metadata = pd.Series({col: pd.NA for col in mds_df.columns if col != 'lifetimeNumber'})\n",
    "\n",
    "    # Combine ECG row with matched metadata\n",
    "    merged_row = pd.concat([ecg_row, matched_metadata])\n",
    "    merged_rows.append(merged_row)\n",
    "\n",
    "# Final merged DataFrame\n",
    "df_merged = pd.DataFrame(merged_rows)\n",
    "\n",
    "# Display output info\n",
    "print(\"\\nFinal Time-Matched Merged DataFrame:\")\n",
    "print(df_merged.info())\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a5a1663-97ea-40cc-a5a1-bdc592409620",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ecg_backup = x_ecg.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94224923-9f5c-40e2-b5b7-a2ff8119b705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQR-based Outlier Thresholds:\n",
      " - Q1: -8.140511956619411\n",
      " - Q3: 6.09953663843787\n",
      " - Lower bound: -1432.1453714623474\n",
      " - Upper bound: 1430.104396144166\n",
      "\n",
      "Original number of samples: 7288\n",
      "Number of samples removed due to IQR outliers: 47\n",
      "Number of samples after filtering: 7241\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Flatten and concatenate all values\n",
    "all_ecg_values = np.concatenate(x_ecg)\n",
    "flattened_values = np.ravel(all_ecg_values)\n",
    "\n",
    "# --- Histogram BEFORE filtering ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(flattened_values, bins=300, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of All ECG Signal Values (Before Filtering)')\n",
    "plt.xlabel('ECG Amplitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- IQR Outlier Filtering ---\n",
    "Q1 = np.nanpercentile(flattened_values, 25)\n",
    "Q3 = np.nanpercentile(flattened_values, 75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 100 * IQR\n",
    "upper_bound = Q3 + 100* IQR\n",
    "\n",
    "print(f\"IQR-based Outlier Thresholds:\")\n",
    "print(f\" - Q1: {Q1}\")\n",
    "print(f\" - Q3: {Q3}\")\n",
    "print(f\" - Lower bound: {lower_bound}\")\n",
    "print(f\" - Upper bound: {upper_bound}\")\n",
    "\n",
    "# Remove samples with any value outside the IQR bounds\n",
    "original_count = x_ecg.shape[0]\n",
    "mask = np.array([\n",
    "    np.all((sample >= lower_bound) & (sample <= upper_bound))\n",
    "    for sample in x_ecg\n",
    "])\n",
    "x_ecg_filtered = x_ecg[mask]\n",
    "\n",
    "removed_count = original_count - x_ecg_filtered.shape[0]\n",
    "print(f\"\\nOriginal number of samples: {original_count}\")\n",
    "print(f\"Number of samples removed due to IQR outliers: {removed_count}\")\n",
    "print(f\"Number of samples after filtering: {x_ecg_filtered.shape[0]}\")\n",
    "\n",
    "# Override x_ecg with x_ecg_filtered\n",
    "x_ecg = x_ecg_filtered.copy()\n",
    "\n",
    "# --- Histogram AFTER filtering ---\n",
    "flattened_filtered = np.ravel(np.concatenate(x_ecg_filtered))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(flattened_filtered, bins=300, color='lightgreen', edgecolor='black')\n",
    "plt.title('Histogram of ECG Signal Values (After IQR Outlier Removal)')\n",
    "plt.xlabel('ECG Amplitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.ylim(top=50)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Scale (standardise) data\n",
    "scaler = StandardScaler()\n",
    "            \n",
    "x_ecg_shape = x_ecg.shape # Determine shape\n",
    "\n",
    "x_ecg = np.reshape(\n",
    "    scaler.fit_transform(np.reshape(\n",
    "        x_ecg,(x_ecg_shape[0] * 2500, 12))\n",
    "        ), x_ecg_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea9855633af43deb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T15:08:17.382948Z",
     "start_time": "2025-08-03T15:08:17.284096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VentricularRate</th>\n",
       "      <th>AtrialRate</th>\n",
       "      <th>PRInterval</th>\n",
       "      <th>QRSDuration</th>\n",
       "      <th>QTInterval</th>\n",
       "      <th>QTCorrected</th>\n",
       "      <th>PAxis</th>\n",
       "      <th>RAxis</th>\n",
       "      <th>TAxis</th>\n",
       "      <th>QRSCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7288</td>\n",
       "      <td>7288</td>\n",
       "      <td>7288</td>\n",
       "      <td>7288</td>\n",
       "      <td>7288</td>\n",
       "      <td>7288</td>\n",
       "      <td>7288</td>\n",
       "      <td>7288</td>\n",
       "      <td>7288</td>\n",
       "      <td>7288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>135</td>\n",
       "      <td>148</td>\n",
       "      <td>282</td>\n",
       "      <td>155</td>\n",
       "      <td>349</td>\n",
       "      <td>285</td>\n",
       "      <td>256</td>\n",
       "      <td>298</td>\n",
       "      <td>360</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>144</td>\n",
       "      <td>86</td>\n",
       "      <td>412</td>\n",
       "      <td>457</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>517</td>\n",
       "      <td>488</td>\n",
       "      <td>179</td>\n",
       "      <td>354</td>\n",
       "      <td>129</td>\n",
       "      <td>118</td>\n",
       "      <td>126</td>\n",
       "      <td>79</td>\n",
       "      <td>74</td>\n",
       "      <td>1293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       VentricularRate AtrialRate PRInterval QRSDuration QTInterval  \\\n",
       "count             7288       7288       7288        7288       7288   \n",
       "unique             135        148        282         155        349   \n",
       "top                 80         80        144          86        412   \n",
       "freq               517        488        179         354        129   \n",
       "\n",
       "       QTCorrected PAxis RAxis TAxis QRSCount  \n",
       "count         7288  7288  7288  7288     7288  \n",
       "unique         285   256   298   360       28  \n",
       "top            457    54     3    58       13  \n",
       "freq           118   126    79    74     1293  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select numeric ECG features\n",
    "ecg_intervals = [\"VentricularRate\", \"AtrialRate\", \"PRInterval\", \"QRSDuration\", \"QTInterval\", \"QTCorrected\", \"PAxis\", \"RAxis\", \"TAxis\", \"QRSCount\"]\n",
    "df_merged[ecg_intervals].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e83ab349c3c8c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T15:08:21.544256Z",
     "start_time": "2025-08-03T15:08:20.127015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1600 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_ecg_example(ecg_data, sample_idx=0, leads=list(range(12)), time_range=None):\n",
    "    \"\"\"\n",
    "    Plots 12 ECG leads of a sample as separate subplots in one figure (3x4 layout).\n",
    "\n",
    "    Parameters:\n",
    "    - ecg_data: numpy array of shape (n_samples, n_timepoints, n_leads)\n",
    "    - sample_idx: index of the ECG sample to plot\n",
    "    - leads: list of lead indices to plot (default: all 12 leads)\n",
    "    - time_range: tuple (start, end) to zoom in (default: full length)\n",
    "    \"\"\"\n",
    "    timepoints = ecg_data.shape[1]\n",
    "    if time_range is None:\n",
    "        time_range = (0, timepoints)\n",
    "\n",
    "    fig, axes = plt.subplots(6, 2, figsize=(12, 16))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, lead in enumerate(leads):\n",
    "        ax = axes[i]\n",
    "        signal = ecg_data[sample_idx, time_range[0]:time_range[1], lead]\n",
    "        ax.plot(range(time_range[0], time_range[1]), signal, color='blue')\n",
    "        ax.set_title(f\"Lead {lead + 1}\")\n",
    "        ax.set_xlabel(\"Timepoints\")\n",
    "        ax.set_ylabel(\"Voltage (mV)\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Hide any unused subplots if fewer than 12 leads\n",
    "    for j in range(len(leads), len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    fig.suptitle(f\"ECG Sample {sample_idx} - 12 Lead View\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_ecg_example(x_ecg, sample_idx=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb759eb9-e5cf-45ee-8de5-5e47cd668dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Minimum value of 52.00793468598585 found in:\n",
      "- Sample index: 863\n",
      "- Timepoint index: 1415\n",
      "- Lead index: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1600 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_max = np.nanmax(x_ecg)\n",
    "\n",
    "# Step 2: Find the sample, timepoint, and lead where the min value occurs\n",
    "max_indices = np.where(x_ecg == global_max)\n",
    "\n",
    "# If there are multiple occurrences, take the first one\n",
    "sample_idx, time_idx, lead_idx = max_indices[0][0], max_indices[1][0], max_indices[2][0]\n",
    "\n",
    "print(f\"\\nMinimum value of {global_max} found in:\")\n",
    "print(f\"- Sample index: {sample_idx}\")\n",
    "print(f\"- Timepoint index: {time_idx}\")\n",
    "print(f\"- Lead index: {lead_idx}\")\n",
    "\n",
    "# Step 3: Plot the ECG of the sample with the min value\n",
    "plot_ecg_example(x_ecg, sample_idx=sample_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3107f36de25ec4b2",
   "metadata": {},
   "source": [
    "Verify the shape and type of the ECG data\n",
    "Standardize the data for VRAE application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7331bc1773569490",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T15:08:35.110177Z",
     "start_time": "2025-08-03T15:08:35.090435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of x_ecg: <class 'numpy.ndarray'>\n",
      "Shape of x_ecg: (7241, 2500, 12)\n",
      "Number of samples: 7241\n",
      "Number of timepoints per sample: 2500\n",
      "Number of leads per sample: 12\n"
     ]
    }
   ],
   "source": [
    "# Check type and shape of the data\n",
    "print(\"Type of x_ecg:\", type(x_ecg))\n",
    "if isinstance(x_ecg, np.ndarray):\n",
    "    print(\"Shape of x_ecg:\", x_ecg.shape)  # (n_samples, n_timepoints, n_leads)\n",
    "    print(\"Number of samples:\", x_ecg.shape[0])\n",
    "    print(\"Number of timepoints per sample:\", x_ecg.shape[1])\n",
    "    print(\"Number of leads per sample:\", x_ecg.shape[2])\n",
    "else:\n",
    "    raise ValueError(\"x_ecg is not a numpy array\")\n",
    "\n",
    "# Standardize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9192260950662",
   "metadata": {},
   "source": [
    "Apply VRAE:\n",
    "- Split data\n",
    "- Set up model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25b6fe22ed112599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T15:08:37.204163Z",
     "start_time": "2025-08-03T15:08:37.192687Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add plot function for train vs validation losses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(model, title=None):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(model.train_losses, label='Train Loss')\n",
    "    if hasattr(model, 'val_losses') and model.val_losses:\n",
    "        plt.plot(model.val_losses, label='Validation Loss')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(title or \"Training vs Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41b0588ccf9e0b9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T15:09:07.040070Z",
     "start_time": "2025-08-03T15:08:40.236967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-lead mean after standardization:\n",
      "[-0.  0. -0.  0.  0. -0. -0.  0. -0. -0.  0.  0.]\n",
      "\n",
      "Per-lead std after standardization:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Check correct standardization\n",
    "import numpy as np\n",
    "\n",
    "lead_means = np.mean(x_ecg, axis=(0, 1))\n",
    "lead_stds = np.std(x_ecg, axis=(0, 1))\n",
    "\n",
    "print(\"Per-lead mean after standardization:\")\n",
    "print(np.round(lead_means, 4))\n",
    "\n",
    "print(\"\\nPer-lead std after standardization:\")\n",
    "print(np.round(lead_stds, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa4dabda8ae792",
   "metadata": {},
   "source": [
    "VRAE application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4505f045c9fd09c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-08-03T15:11:07.503465Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: ./ecg_model_logs\n",
      "Log file: ./ecg_model_logs\\training_log.txt\n",
      "Data split: 5792 training samples, 1449 validation samples.\n",
      "\n",
      "CUDA available: True\n",
      "\n",
      "==================================================\n",
      "=========== VRAE HYPERPARAMETER TUNING ===========\n",
      "==================================================\n",
      "\n",
      "[VRAE Run 1/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7889, recon=0.7889, kl=0.2023, beta=0.0000\n",
      "Batch 40, loss=0.4443, recon=0.4443, kl=0.4274, beta=0.0000\n",
      "Batch 60, loss=0.4097, recon=0.4097, kl=2.9852, beta=0.0000\n",
      "Batch 80, loss=0.3252, recon=0.3252, kl=8.9087, beta=0.0000\n",
      "Batch 100, loss=0.2664, recon=0.2664, kl=14.7123, beta=0.0000\n",
      "Batch 120, loss=0.3726, recon=0.3726, kl=17.7182, beta=0.0000\n",
      "Batch 140, loss=0.2651, recon=0.2651, kl=20.0650, beta=0.0000\n",
      "Batch 160, loss=0.3261, recon=0.3261, kl=21.3996, beta=0.0000\n",
      "Batch 180, loss=0.3256, recon=0.3256, kl=22.4300, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4273 (Recon: 0.4273, KL: 10.9579, Current Beta: 0.0000) | Avg Valid Loss: 0.2276 | Avg Valid recon Loss: 0.2276\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1955, recon=0.1955, kl=23.8359, beta=0.0000\n",
      "Batch 40, loss=0.2045, recon=0.2045, kl=24.3776, beta=0.0000\n",
      "Batch 60, loss=0.2637, recon=0.2637, kl=25.1560, beta=0.0000\n",
      "Batch 80, loss=0.3863, recon=0.3863, kl=25.9526, beta=0.0000\n",
      "Batch 100, loss=0.1343, recon=0.1343, kl=26.8830, beta=0.0000\n",
      "Batch 120, loss=0.1205, recon=0.1205, kl=27.9072, beta=0.0000\n",
      "Batch 140, loss=0.1295, recon=0.1295, kl=28.2372, beta=0.0000\n",
      "Batch 160, loss=0.1952, recon=0.1952, kl=29.2230, beta=0.0000\n",
      "Batch 180, loss=0.1710, recon=0.1710, kl=29.4925, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2101 (Recon: 0.2101, KL: 26.4205, Current Beta: 0.0000) | Avg Valid Loss: 0.1466 | Avg Valid recon Loss: 0.1466\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1410, recon=0.1410, kl=30.9184, beta=0.0000\n",
      "Batch 40, loss=0.1463, recon=0.1463, kl=31.2167, beta=0.0000\n",
      "Batch 60, loss=0.0905, recon=0.0905, kl=31.5378, beta=0.0000\n",
      "Batch 80, loss=0.2551, recon=0.2551, kl=32.4060, beta=0.0000\n",
      "Batch 100, loss=0.1025, recon=0.1025, kl=32.8950, beta=0.0000\n",
      "Batch 120, loss=0.1465, recon=0.1465, kl=33.1693, beta=0.0000\n",
      "Batch 140, loss=0.1308, recon=0.1308, kl=34.3668, beta=0.0000\n",
      "Batch 160, loss=0.3948, recon=0.3948, kl=35.1293, beta=0.0000\n",
      "Batch 180, loss=0.1050, recon=0.1050, kl=35.6245, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1563 (Recon: 0.1563, KL: 32.7070, Current Beta: 0.0000) | Avg Valid Loss: 0.1135 | Avg Valid recon Loss: 0.1135\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1275, recon=0.1275, kl=36.0321, beta=0.0000\n",
      "Batch 40, loss=0.1450, recon=0.1450, kl=36.5926, beta=0.0000\n",
      "Batch 60, loss=0.0750, recon=0.0750, kl=36.8852, beta=0.0000\n",
      "Batch 80, loss=0.0876, recon=0.0876, kl=37.0769, beta=0.0000\n",
      "Batch 100, loss=0.0878, recon=0.0878, kl=36.8054, beta=0.0000\n",
      "Batch 120, loss=0.1231, recon=0.1231, kl=37.5895, beta=0.0000\n",
      "Batch 140, loss=0.0809, recon=0.0809, kl=38.0209, beta=0.0000\n",
      "Batch 160, loss=0.0875, recon=0.0875, kl=38.2302, beta=0.0000\n",
      "Batch 180, loss=0.1000, recon=0.1000, kl=39.3171, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1271 (Recon: 0.1271, KL: 37.1373, Current Beta: 0.0000) | Avg Valid Loss: 0.0982 | Avg Valid recon Loss: 0.0982\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0740, recon=0.0740, kl=40.0096, beta=0.0000\n",
      "Batch 40, loss=0.0687, recon=0.0687, kl=40.1725, beta=0.0000\n",
      "Batch 60, loss=0.1901, recon=0.1901, kl=40.3358, beta=0.0000\n",
      "Batch 80, loss=0.0810, recon=0.0810, kl=41.2474, beta=0.0000\n",
      "Batch 100, loss=0.1309, recon=0.1309, kl=41.3297, beta=0.0000\n",
      "Batch 120, loss=0.0672, recon=0.0672, kl=40.7553, beta=0.0000\n",
      "Batch 140, loss=0.0782, recon=0.0782, kl=40.9492, beta=0.0000\n",
      "Batch 160, loss=0.0850, recon=0.0850, kl=41.0565, beta=0.0000\n",
      "Batch 180, loss=0.0969, recon=0.0969, kl=41.2936, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1091 (Recon: 0.1091, KL: 40.7515, Current Beta: 0.0000) | Avg Valid Loss: 0.0868 | Avg Valid recon Loss: 0.0868\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0703, recon=0.0703, kl=42.0695, beta=0.0000\n",
      "Batch 40, loss=0.1392, recon=0.1392, kl=41.8344, beta=0.0000\n",
      "Batch 60, loss=0.0931, recon=0.0931, kl=42.5709, beta=0.0000\n",
      "Batch 80, loss=0.0731, recon=0.0731, kl=43.3231, beta=0.0000\n",
      "Batch 100, loss=0.0593, recon=0.0593, kl=43.7722, beta=0.0000\n",
      "Batch 120, loss=0.0557, recon=0.0557, kl=43.8061, beta=0.0000\n",
      "Batch 140, loss=0.0421, recon=0.0421, kl=44.2972, beta=0.0000\n",
      "Batch 160, loss=0.1304, recon=0.1304, kl=44.6809, beta=0.0000\n",
      "Batch 180, loss=0.0729, recon=0.0729, kl=44.8669, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0971 (Recon: 0.0971, KL: 43.3290, Current Beta: 0.0000) | Avg Valid Loss: 0.0790 | Avg Valid recon Loss: 0.0790\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0779, recon=0.0779, kl=45.0678, beta=0.0000\n",
      "Batch 40, loss=0.0633, recon=0.0633, kl=44.9388, beta=0.0000\n",
      "Batch 60, loss=0.1150, recon=0.1150, kl=45.3145, beta=0.0000\n",
      "Batch 80, loss=0.0600, recon=0.0600, kl=45.4030, beta=0.0000\n",
      "Batch 100, loss=0.2654, recon=0.2654, kl=45.5786, beta=0.0000\n",
      "Batch 120, loss=0.0586, recon=0.0586, kl=45.6937, beta=0.0000\n",
      "Batch 140, loss=0.0522, recon=0.0522, kl=45.7600, beta=0.0000\n",
      "Batch 160, loss=0.0595, recon=0.0595, kl=46.2565, beta=0.0000\n",
      "Batch 180, loss=0.0900, recon=0.0900, kl=46.6479, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0877 (Recon: 0.0877, KL: 45.5163, Current Beta: 0.0000) | Avg Valid Loss: 0.0737 | Avg Valid recon Loss: 0.0737\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0484, recon=0.0484, kl=46.2635, beta=0.0000\n",
      "Batch 40, loss=0.0730, recon=0.0730, kl=45.8296, beta=0.0000\n",
      "Batch 60, loss=0.0675, recon=0.0675, kl=45.3268, beta=0.0000\n",
      "Batch 80, loss=0.0812, recon=0.0812, kl=45.1403, beta=0.0000\n",
      "Batch 100, loss=0.0398, recon=0.0398, kl=44.4627, beta=0.0000\n",
      "Batch 120, loss=0.0541, recon=0.0541, kl=44.0707, beta=0.0000\n",
      "Batch 140, loss=0.0456, recon=0.0456, kl=42.8480, beta=0.0000\n",
      "Batch 160, loss=0.0970, recon=0.0970, kl=41.9744, beta=0.0000\n",
      "Batch 180, loss=0.0565, recon=0.0565, kl=42.2431, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0810 (Recon: 0.0810, KL: 44.4306, Current Beta: 0.0000) | Avg Valid Loss: 0.0687 | Avg Valid recon Loss: 0.0687\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0699, recon=0.0699, kl=41.4518, beta=0.0000\n",
      "Batch 40, loss=0.0461, recon=0.0461, kl=40.3119, beta=0.0000\n",
      "Batch 60, loss=0.0567, recon=0.0566, kl=38.5773, beta=0.0000\n",
      "Batch 80, loss=0.0900, recon=0.0900, kl=36.6401, beta=0.0000\n",
      "Batch 100, loss=0.0580, recon=0.0580, kl=35.1507, beta=0.0000\n",
      "Batch 120, loss=0.0744, recon=0.0744, kl=33.7588, beta=0.0000\n",
      "Batch 140, loss=0.0691, recon=0.0691, kl=33.5753, beta=0.0000\n",
      "Batch 160, loss=0.0592, recon=0.0592, kl=32.8842, beta=0.0000\n",
      "Batch 180, loss=0.0465, recon=0.0465, kl=32.1748, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0761 (Recon: 0.0760, KL: 36.5410, Current Beta: 0.0000) | Avg Valid Loss: 0.0659 | Avg Valid recon Loss: 0.0659\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0606, recon=0.0606, kl=29.0377, beta=0.0000\n",
      "Batch 40, loss=0.0450, recon=0.0450, kl=26.3663, beta=0.0000\n",
      "Batch 60, loss=0.0489, recon=0.0489, kl=23.7079, beta=0.0000\n",
      "Batch 80, loss=0.0582, recon=0.0582, kl=22.2940, beta=0.0000\n",
      "Batch 100, loss=0.0620, recon=0.0620, kl=21.9232, beta=0.0000\n",
      "Batch 120, loss=0.0524, recon=0.0524, kl=20.8964, beta=0.0000\n",
      "Batch 140, loss=0.0416, recon=0.0416, kl=20.4156, beta=0.0000\n",
      "Batch 160, loss=0.0361, recon=0.0360, kl=19.6474, beta=0.0000\n",
      "Batch 180, loss=0.0700, recon=0.0700, kl=19.7008, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0725 (Recon: 0.0725, KL: 23.2595, Current Beta: 0.0000) | Avg Valid Loss: 0.0638 | Avg Valid recon Loss: 0.0637\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0429, recon=0.0429, kl=16.6317, beta=0.0000\n",
      "Batch 40, loss=0.0606, recon=0.0605, kl=12.6638, beta=0.0000\n",
      "Batch 60, loss=0.0338, recon=0.0338, kl=12.1844, beta=0.0000\n",
      "Batch 80, loss=0.0586, recon=0.0586, kl=11.5518, beta=0.0000\n",
      "Batch 100, loss=0.0993, recon=0.0992, kl=11.6158, beta=0.0000\n",
      "Batch 120, loss=0.0448, recon=0.0448, kl=10.6535, beta=0.0000\n",
      "Batch 140, loss=0.0501, recon=0.0501, kl=10.9740, beta=0.0000\n",
      "Batch 160, loss=0.0476, recon=0.0476, kl=10.3364, beta=0.0000\n",
      "Batch 180, loss=0.0781, recon=0.0781, kl=9.9437, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0694 (Recon: 0.0693, KL: 12.4119, Current Beta: 0.0000) | Avg Valid Loss: 0.0607 | Avg Valid recon Loss: 0.0607\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0629, recon=0.0629, kl=6.0815, beta=0.0000\n",
      "Batch 40, loss=0.0349, recon=0.0349, kl=4.6534, beta=0.0000\n",
      "Batch 60, loss=0.0498, recon=0.0498, kl=4.6102, beta=0.0000\n",
      "Batch 80, loss=0.0540, recon=0.0540, kl=4.4003, beta=0.0000\n",
      "Batch 100, loss=0.0609, recon=0.0609, kl=4.0011, beta=0.0000\n",
      "Batch 120, loss=0.0624, recon=0.0624, kl=4.1174, beta=0.0000\n",
      "Batch 140, loss=0.1065, recon=0.1065, kl=3.6695, beta=0.0000\n",
      "Batch 160, loss=0.0715, recon=0.0715, kl=3.5418, beta=0.0000\n",
      "Batch 180, loss=0.0588, recon=0.0587, kl=3.6528, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0669 (Recon: 0.0668, KL: 4.6218, Current Beta: 0.0000) | Avg Valid Loss: 0.0589 | Avg Valid recon Loss: 0.0589\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0414, recon=0.0414, kl=1.8300, beta=0.0000\n",
      "Batch 40, loss=0.0510, recon=0.0509, kl=1.6088, beta=0.0000\n",
      "Batch 60, loss=0.0352, recon=0.0352, kl=1.4800, beta=0.0000\n",
      "Batch 80, loss=0.0626, recon=0.0626, kl=1.2308, beta=0.0000\n",
      "Batch 100, loss=0.0504, recon=0.0504, kl=1.2845, beta=0.0000\n",
      "Batch 120, loss=0.0455, recon=0.0454, kl=1.3130, beta=0.0000\n",
      "Batch 140, loss=0.0596, recon=0.0596, kl=1.3579, beta=0.0000\n",
      "Batch 160, loss=0.0322, recon=0.0322, kl=1.0621, beta=0.0000\n",
      "Batch 180, loss=0.0310, recon=0.0310, kl=1.0184, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0646 (Recon: 0.0646, KL: 1.4720, Current Beta: 0.0000) | Avg Valid Loss: 0.0568 | Avg Valid recon Loss: 0.0568\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0384, recon=0.0384, kl=0.6204, beta=0.0000\n",
      "Batch 40, loss=0.0391, recon=0.0390, kl=0.3567, beta=0.0000\n",
      "Batch 60, loss=0.0554, recon=0.0554, kl=0.2950, beta=0.0000\n",
      "Batch 80, loss=0.0347, recon=0.0347, kl=0.2960, beta=0.0000\n",
      "Batch 100, loss=0.0644, recon=0.0644, kl=0.3228, beta=0.0000\n",
      "Batch 120, loss=0.2839, recon=0.2839, kl=0.2357, beta=0.0000\n",
      "Batch 140, loss=0.0476, recon=0.0475, kl=0.4255, beta=0.0000\n",
      "Batch 160, loss=0.0438, recon=0.0438, kl=0.2204, beta=0.0000\n",
      "Batch 180, loss=0.0254, recon=0.0254, kl=0.1917, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0625 (Recon: 0.0624, KL: 0.3566, Current Beta: 0.0000) | Avg Valid Loss: 0.0550 | Avg Valid recon Loss: 0.0550\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0379, recon=0.0379, kl=0.1336, beta=0.0001\n",
      "Batch 40, loss=0.0452, recon=0.0452, kl=0.0693, beta=0.0001\n",
      "Batch 60, loss=0.0399, recon=0.0399, kl=0.1035, beta=0.0001\n",
      "Batch 80, loss=0.0514, recon=0.0514, kl=0.0678, beta=0.0001\n",
      "Batch 100, loss=0.3243, recon=0.3243, kl=0.1022, beta=0.0001\n",
      "Batch 120, loss=0.0857, recon=0.0857, kl=0.0994, beta=0.0001\n",
      "Batch 140, loss=0.0283, recon=0.0283, kl=0.0360, beta=0.0001\n",
      "Batch 160, loss=0.0275, recon=0.0275, kl=0.0798, beta=0.0001\n",
      "Batch 180, loss=0.1391, recon=0.1391, kl=0.0392, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0605 (Recon: 0.0605, KL: 0.0949, Current Beta: 0.0001) | Avg Valid Loss: 0.0538 | Avg Valid recon Loss: 0.0538\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0510, recon=0.0510, kl=0.0205, beta=0.0001\n",
      "Batch 40, loss=0.0601, recon=0.0601, kl=0.0193, beta=0.0001\n",
      "Batch 60, loss=0.0370, recon=0.0370, kl=0.0280, beta=0.0001\n",
      "Batch 80, loss=0.0738, recon=0.0738, kl=0.0247, beta=0.0001\n",
      "Batch 100, loss=0.0873, recon=0.0873, kl=0.0126, beta=0.0001\n",
      "Batch 120, loss=0.1139, recon=0.1139, kl=0.0347, beta=0.0001\n",
      "Batch 140, loss=0.0375, recon=0.0375, kl=0.0162, beta=0.0001\n",
      "Batch 160, loss=0.0580, recon=0.0580, kl=0.0110, beta=0.0001\n",
      "Batch 180, loss=0.0552, recon=0.0552, kl=0.0173, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0591 (Recon: 0.0591, KL: 0.0190, Current Beta: 0.0001) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0330, recon=0.0330, kl=0.0149, beta=0.0001\n",
      "Batch 40, loss=0.0311, recon=0.0311, kl=0.0057, beta=0.0001\n",
      "Batch 60, loss=0.0544, recon=0.0544, kl=0.0133, beta=0.0001\n",
      "Batch 80, loss=0.0577, recon=0.0577, kl=0.0090, beta=0.0001\n",
      "Batch 100, loss=0.0469, recon=0.0469, kl=0.0131, beta=0.0001\n",
      "Batch 120, loss=0.0723, recon=0.0723, kl=0.0066, beta=0.0001\n",
      "Batch 140, loss=0.0382, recon=0.0382, kl=0.0066, beta=0.0001\n",
      "Batch 160, loss=0.0313, recon=0.0313, kl=0.0088, beta=0.0001\n",
      "Batch 180, loss=0.0457, recon=0.0457, kl=0.0101, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0576 (Recon: 0.0576, KL: 0.0111, Current Beta: 0.0001) | Avg Valid Loss: 0.0509 | Avg Valid recon Loss: 0.0509\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0481, recon=0.0481, kl=0.0058, beta=0.0001\n",
      "Batch 40, loss=1.0777, recon=1.0777, kl=0.0065, beta=0.0001\n",
      "Batch 60, loss=0.0491, recon=0.0491, kl=0.0161, beta=0.0001\n",
      "Batch 80, loss=0.0329, recon=0.0329, kl=0.0088, beta=0.0001\n",
      "Batch 100, loss=0.0256, recon=0.0256, kl=0.0049, beta=0.0001\n",
      "Batch 120, loss=0.0716, recon=0.0716, kl=0.0048, beta=0.0001\n",
      "Batch 140, loss=0.0502, recon=0.0502, kl=0.0070, beta=0.0001\n",
      "Batch 160, loss=0.0492, recon=0.0492, kl=0.0086, beta=0.0001\n",
      "Batch 180, loss=0.0400, recon=0.0400, kl=0.0042, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0564 (Recon: 0.0564, KL: 0.0082, Current Beta: 0.0001) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0499\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0356, recon=0.0356, kl=0.0048, beta=0.0001\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=0.0042, beta=0.0001\n",
      "Batch 60, loss=0.0334, recon=0.0334, kl=0.0036, beta=0.0001\n",
      "Batch 80, loss=0.0352, recon=0.0352, kl=0.0045, beta=0.0001\n",
      "Batch 100, loss=0.0474, recon=0.0474, kl=0.0085, beta=0.0001\n",
      "Batch 120, loss=0.0961, recon=0.0961, kl=0.0042, beta=0.0001\n",
      "Batch 140, loss=0.0371, recon=0.0371, kl=0.0047, beta=0.0001\n",
      "Batch 160, loss=0.0373, recon=0.0373, kl=0.0050, beta=0.0001\n",
      "Batch 180, loss=0.0269, recon=0.0269, kl=0.0082, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 0.0054, Current Beta: 0.0001) | Avg Valid Loss: 0.0491 | Avg Valid recon Loss: 0.0491\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0627, recon=0.0627, kl=0.0044, beta=0.0001\n",
      "Batch 40, loss=0.0280, recon=0.0280, kl=0.0059, beta=0.0001\n",
      "Batch 60, loss=0.1100, recon=0.1100, kl=0.0033, beta=0.0001\n",
      "Batch 80, loss=0.1973, recon=0.1973, kl=0.0018, beta=0.0001\n",
      "Batch 100, loss=0.0400, recon=0.0400, kl=0.0060, beta=0.0001\n",
      "Batch 120, loss=0.0343, recon=0.0343, kl=0.0043, beta=0.0001\n",
      "Batch 140, loss=0.0312, recon=0.0312, kl=0.0033, beta=0.0001\n",
      "Batch 160, loss=0.2864, recon=0.2864, kl=0.0099, beta=0.0001\n",
      "Batch 180, loss=0.0759, recon=0.0759, kl=0.0020, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0540, KL: 0.0049, Current Beta: 0.0001) | Avg Valid Loss: 0.0481 | Avg Valid recon Loss: 0.0481\n",
      " New best VRAE model found with validation loss: 0.0481\n",
      "   Model saved to ./ecg_model_logs\\best_vrae_model.pth\n",
      "\n",
      "[VRAE Run 2/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3128, recon=0.3128, kl=14.0619, beta=0.0000\n",
      "Batch 40, loss=0.1914, recon=0.1914, kl=25.1604, beta=0.0000\n",
      "Batch 60, loss=0.1344, recon=0.1344, kl=23.2474, beta=0.0000\n",
      "Batch 80, loss=0.1061, recon=0.1061, kl=26.0433, beta=0.0000\n",
      "Batch 100, loss=0.0848, recon=0.0848, kl=25.7394, beta=0.0000\n",
      "Batch 120, loss=0.0825, recon=0.0825, kl=26.8883, beta=0.0000\n",
      "Batch 140, loss=0.2157, recon=0.2157, kl=30.2948, beta=0.0000\n",
      "Batch 160, loss=0.0738, recon=0.0738, kl=25.2059, beta=0.0000\n",
      "Batch 180, loss=0.0540, recon=0.0540, kl=29.0311, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1818 (Recon: 0.1818, KL: 23.6070, Current Beta: 0.0000) | Avg Valid Loss: 0.0750 | Avg Valid recon Loss: 0.0750\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0648, recon=0.0648, kl=31.6286, beta=0.0000\n",
      "Batch 40, loss=0.0768, recon=0.0768, kl=31.4888, beta=0.0000\n",
      "Batch 60, loss=0.0459, recon=0.0459, kl=32.2313, beta=0.0000\n",
      "Batch 80, loss=0.0879, recon=0.0879, kl=33.7977, beta=0.0000\n",
      "Batch 100, loss=0.0584, recon=0.0584, kl=35.0536, beta=0.0000\n",
      "Batch 120, loss=0.0498, recon=0.0498, kl=28.9112, beta=0.0000\n",
      "Batch 140, loss=0.0525, recon=0.0525, kl=31.5091, beta=0.0000\n",
      "Batch 160, loss=0.0336, recon=0.0336, kl=28.7332, beta=0.0000\n",
      "Batch 180, loss=0.0545, recon=0.0545, kl=27.7291, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0785 (Recon: 0.0785, KL: 31.2295, Current Beta: 0.0000) | Avg Valid Loss: 0.0608 | Avg Valid recon Loss: 0.0608\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1245, recon=0.1245, kl=31.2414, beta=0.0000\n",
      "Batch 40, loss=0.0613, recon=0.0613, kl=33.1967, beta=0.0000\n",
      "Batch 60, loss=0.0430, recon=0.0430, kl=31.8825, beta=0.0000\n",
      "Batch 80, loss=0.0635, recon=0.0635, kl=34.2870, beta=0.0000\n",
      "Batch 100, loss=0.0610, recon=0.0610, kl=36.5003, beta=0.0000\n",
      "Batch 120, loss=0.0389, recon=0.0389, kl=34.8594, beta=0.0000\n",
      "Batch 140, loss=0.1035, recon=0.1035, kl=36.6127, beta=0.0000\n",
      "Batch 160, loss=0.0682, recon=0.0682, kl=38.5467, beta=0.0000\n",
      "Batch 180, loss=0.0560, recon=0.0560, kl=36.4910, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0687 (Recon: 0.0687, KL: 34.6045, Current Beta: 0.0000) | Avg Valid Loss: 0.0586 | Avg Valid recon Loss: 0.0586\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0470, recon=0.0470, kl=31.5207, beta=0.0000\n",
      "Batch 40, loss=0.0419, recon=0.0419, kl=31.7472, beta=0.0000\n",
      "Batch 60, loss=0.0564, recon=0.0564, kl=32.6177, beta=0.0000\n",
      "Batch 80, loss=0.1184, recon=0.1184, kl=34.1844, beta=0.0000\n",
      "Batch 100, loss=0.0361, recon=0.0361, kl=34.4069, beta=0.0000\n",
      "Batch 120, loss=0.0366, recon=0.0366, kl=34.8663, beta=0.0000\n",
      "Batch 140, loss=0.0328, recon=0.0328, kl=34.3806, beta=0.0000\n",
      "Batch 160, loss=0.0339, recon=0.0339, kl=33.7621, beta=0.0000\n",
      "Batch 180, loss=0.0495, recon=0.0495, kl=33.5238, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0615 (Recon: 0.0615, KL: 33.5143, Current Beta: 0.0000) | Avg Valid Loss: 0.0518 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0246, recon=0.0246, kl=33.0679, beta=0.0000\n",
      "Batch 40, loss=0.9504, recon=0.9504, kl=34.6689, beta=0.0000\n",
      "Batch 60, loss=0.0528, recon=0.0528, kl=34.3404, beta=0.0000\n",
      "Batch 80, loss=0.0472, recon=0.0472, kl=34.2486, beta=0.0000\n",
      "Batch 100, loss=0.0528, recon=0.0528, kl=35.0343, beta=0.0000\n",
      "Batch 120, loss=0.0515, recon=0.0515, kl=35.2453, beta=0.0000\n",
      "Batch 140, loss=0.0500, recon=0.0500, kl=37.4305, beta=0.0000\n",
      "Batch 160, loss=0.0418, recon=0.0418, kl=38.1062, beta=0.0000\n",
      "Batch 180, loss=0.0448, recon=0.0448, kl=37.4606, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0578 (Recon: 0.0578, KL: 35.4233, Current Beta: 0.0000) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0478\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0331, recon=0.0331, kl=36.6097, beta=0.0000\n",
      "Batch 40, loss=0.2075, recon=0.2075, kl=39.2969, beta=0.0000\n",
      "Batch 60, loss=0.0752, recon=0.0752, kl=38.9717, beta=0.0000\n",
      "Batch 80, loss=0.0434, recon=0.0434, kl=38.8924, beta=0.0000\n",
      "Batch 100, loss=0.2153, recon=0.2153, kl=38.3006, beta=0.0000\n",
      "Batch 120, loss=0.0305, recon=0.0305, kl=38.2904, beta=0.0000\n",
      "Batch 140, loss=0.0297, recon=0.0297, kl=39.1551, beta=0.0000\n",
      "Batch 160, loss=0.0443, recon=0.0443, kl=40.1692, beta=0.0000\n",
      "Batch 180, loss=0.0426, recon=0.0426, kl=39.8436, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 38.6388, Current Beta: 0.0000) | Avg Valid Loss: 0.0453 | Avg Valid recon Loss: 0.0453\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0278, recon=0.0278, kl=39.7343, beta=0.0000\n",
      "Batch 40, loss=0.2115, recon=0.2114, kl=40.0547, beta=0.0000\n",
      "Batch 60, loss=0.0462, recon=0.0462, kl=39.8363, beta=0.0000\n",
      "Batch 80, loss=0.0436, recon=0.0436, kl=40.5326, beta=0.0000\n",
      "Batch 100, loss=0.0383, recon=0.0383, kl=38.4842, beta=0.0000\n",
      "Batch 120, loss=0.0408, recon=0.0408, kl=37.8016, beta=0.0000\n",
      "Batch 140, loss=0.0432, recon=0.0432, kl=37.6279, beta=0.0000\n",
      "Batch 160, loss=0.0840, recon=0.0840, kl=37.7063, beta=0.0000\n",
      "Batch 180, loss=0.0399, recon=0.0399, kl=37.4400, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0534, KL: 39.0090, Current Beta: 0.0000) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0458\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0608, recon=0.0608, kl=35.6307, beta=0.0000\n",
      "Batch 40, loss=0.0441, recon=0.0441, kl=34.0767, beta=0.0000\n",
      "Batch 60, loss=0.0432, recon=0.0432, kl=33.0511, beta=0.0000\n",
      "Batch 80, loss=0.0576, recon=0.0576, kl=31.6753, beta=0.0000\n",
      "Batch 100, loss=0.0418, recon=0.0418, kl=32.2104, beta=0.0000\n",
      "Batch 120, loss=0.0768, recon=0.0768, kl=33.6456, beta=0.0000\n",
      "Batch 140, loss=0.2098, recon=0.2098, kl=33.9054, beta=0.0000\n",
      "Batch 160, loss=0.0348, recon=0.0348, kl=31.6953, beta=0.0000\n",
      "Batch 180, loss=0.0252, recon=0.0252, kl=31.0669, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0523, KL: 33.4113, Current Beta: 0.0000) | Avg Valid Loss: 0.0427 | Avg Valid recon Loss: 0.0427\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0556, recon=0.0555, kl=29.2803, beta=0.0000\n",
      "Batch 40, loss=0.0329, recon=0.0329, kl=25.9613, beta=0.0000\n",
      "Batch 60, loss=0.0303, recon=0.0303, kl=26.2812, beta=0.0000\n",
      "Batch 80, loss=0.0729, recon=0.0728, kl=24.8204, beta=0.0000\n",
      "Batch 100, loss=0.1723, recon=0.1723, kl=24.8351, beta=0.0000\n",
      "Batch 120, loss=0.0378, recon=0.0378, kl=24.8480, beta=0.0000\n",
      "Batch 140, loss=0.0310, recon=0.0310, kl=25.4488, beta=0.0000\n",
      "Batch 160, loss=0.0567, recon=0.0567, kl=25.7038, beta=0.0000\n",
      "Batch 180, loss=0.0412, recon=0.0412, kl=24.8165, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0488 (Recon: 0.0487, KL: 26.1412, Current Beta: 0.0000) | Avg Valid Loss: 0.0477 | Avg Valid recon Loss: 0.0477\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0320, recon=0.0320, kl=22.3265, beta=0.0000\n",
      "Batch 40, loss=0.0636, recon=0.0636, kl=21.9763, beta=0.0000\n",
      "Batch 60, loss=0.0365, recon=0.0364, kl=22.6764, beta=0.0000\n",
      "Batch 80, loss=0.0327, recon=0.0326, kl=21.1220, beta=0.0000\n",
      "Batch 100, loss=0.0435, recon=0.0435, kl=24.1091, beta=0.0000\n",
      "Batch 120, loss=0.0358, recon=0.0357, kl=23.0955, beta=0.0000\n",
      "Batch 140, loss=0.0700, recon=0.0700, kl=21.8604, beta=0.0000\n",
      "Batch 160, loss=0.0575, recon=0.0575, kl=23.2093, beta=0.0000\n",
      "Batch 180, loss=0.7049, recon=0.7049, kl=21.2802, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0519 (Recon: 0.0519, KL: 22.7871, Current Beta: 0.0000) | Avg Valid Loss: 0.0580 | Avg Valid recon Loss: 0.0580\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0414, recon=0.0414, kl=15.9078, beta=0.0000\n",
      "Batch 40, loss=0.0476, recon=0.0475, kl=13.1592, beta=0.0000\n",
      "Batch 60, loss=0.0347, recon=0.0346, kl=22.1317, beta=0.0000\n",
      "Batch 80, loss=0.0341, recon=0.0341, kl=22.8942, beta=0.0000\n",
      "Batch 100, loss=0.0511, recon=0.0511, kl=19.8988, beta=0.0000\n",
      "Batch 120, loss=0.0279, recon=0.0279, kl=18.2313, beta=0.0000\n",
      "Batch 140, loss=0.0265, recon=0.0265, kl=17.1889, beta=0.0000\n",
      "Batch 160, loss=0.1418, recon=0.1418, kl=15.5418, beta=0.0000\n",
      "Batch 180, loss=0.0408, recon=0.0408, kl=14.2224, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0533, KL: 17.9335, Current Beta: 0.0000) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0465\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0391, recon=0.0390, kl=10.9634, beta=0.0000\n",
      "Batch 40, loss=0.0388, recon=0.0388, kl=8.7004, beta=0.0000\n",
      "Batch 60, loss=0.0556, recon=0.0555, kl=6.8928, beta=0.0000\n",
      "Batch 80, loss=0.0294, recon=0.0294, kl=7.3595, beta=0.0000\n",
      "Batch 100, loss=0.0364, recon=0.0364, kl=7.6757, beta=0.0000\n",
      "Batch 120, loss=0.0354, recon=0.0354, kl=6.2238, beta=0.0000\n",
      "Batch 140, loss=0.0295, recon=0.0294, kl=5.4864, beta=0.0000\n",
      "Batch 160, loss=0.0331, recon=0.0330, kl=4.6507, beta=0.0000\n",
      "Batch 180, loss=0.0348, recon=0.0347, kl=4.6317, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0491 (Recon: 0.0490, KL: 7.3810, Current Beta: 0.0000) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0470, recon=0.0469, kl=2.5834, beta=0.0000\n",
      "Batch 40, loss=0.0270, recon=0.0270, kl=2.4027, beta=0.0000\n",
      "Batch 60, loss=0.0750, recon=0.0749, kl=2.7167, beta=0.0000\n",
      "Batch 80, loss=0.0474, recon=0.0474, kl=3.2410, beta=0.0000\n",
      "Batch 100, loss=0.0514, recon=0.0513, kl=3.7720, beta=0.0000\n",
      "Batch 120, loss=0.0276, recon=0.0275, kl=1.9981, beta=0.0000\n",
      "Batch 140, loss=0.0248, recon=0.0247, kl=1.6324, beta=0.0000\n",
      "Batch 160, loss=0.0373, recon=0.0372, kl=1.5824, beta=0.0000\n",
      "Batch 180, loss=0.0312, recon=0.0312, kl=1.1181, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0484, KL: 2.5356, Current Beta: 0.0000) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0393\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0301, recon=0.0300, kl=0.1805, beta=0.0000\n",
      "Batch 40, loss=0.0347, recon=0.0347, kl=0.4537, beta=0.0000\n",
      "Batch 60, loss=0.0375, recon=0.0375, kl=0.4213, beta=0.0000\n",
      "Batch 80, loss=0.0292, recon=0.0291, kl=0.4700, beta=0.0000\n",
      "Batch 100, loss=0.0663, recon=0.0663, kl=0.3526, beta=0.0000\n",
      "Batch 120, loss=0.0346, recon=0.0346, kl=0.2750, beta=0.0000\n",
      "Batch 140, loss=0.0366, recon=0.0366, kl=0.0969, beta=0.0000\n",
      "Batch 160, loss=0.0559, recon=0.0559, kl=0.2404, beta=0.0000\n",
      "Batch 180, loss=0.0577, recon=0.0577, kl=0.3303, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0478 (Recon: 0.0478, KL: 0.3533, Current Beta: 0.0000) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0480\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0605, recon=0.0605, kl=0.1482, beta=0.0001\n",
      "Batch 40, loss=0.0454, recon=0.0453, kl=0.5125, beta=0.0001\n",
      "Batch 60, loss=0.0428, recon=0.0428, kl=0.2535, beta=0.0001\n",
      "Batch 80, loss=0.0406, recon=0.0406, kl=0.2021, beta=0.0001\n",
      "Batch 100, loss=0.0336, recon=0.0336, kl=0.1444, beta=0.0001\n",
      "Batch 120, loss=0.0418, recon=0.0418, kl=0.1088, beta=0.0001\n",
      "Batch 140, loss=0.0315, recon=0.0315, kl=0.0864, beta=0.0001\n",
      "Batch 160, loss=0.0439, recon=0.0439, kl=0.3732, beta=0.0001\n",
      "Batch 180, loss=0.0274, recon=0.0274, kl=0.2696, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0494, KL: 0.2371, Current Beta: 0.0001) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0344, recon=0.0344, kl=0.0325, beta=0.0001\n",
      "Batch 40, loss=0.0470, recon=0.0470, kl=0.0300, beta=0.0001\n",
      "Batch 60, loss=0.0314, recon=0.0314, kl=0.0170, beta=0.0001\n",
      "Batch 80, loss=0.0278, recon=0.0278, kl=0.0111, beta=0.0001\n",
      "Batch 100, loss=0.0282, recon=0.0282, kl=0.0100, beta=0.0001\n",
      "Batch 120, loss=0.0313, recon=0.0313, kl=0.0375, beta=0.0001\n",
      "Batch 140, loss=0.0428, recon=0.0428, kl=0.0175, beta=0.0001\n",
      "Batch 160, loss=0.1125, recon=0.1125, kl=0.0333, beta=0.0001\n",
      "Batch 180, loss=0.0431, recon=0.0431, kl=0.0771, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0501 (Recon: 0.0501, KL: 0.0366, Current Beta: 0.0001) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0460\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1198, recon=0.1197, kl=0.0719, beta=0.0001\n",
      "Batch 40, loss=0.0658, recon=0.0658, kl=0.0212, beta=0.0001\n",
      "Batch 60, loss=0.0414, recon=0.0413, kl=0.0546, beta=0.0001\n",
      "Batch 80, loss=0.0364, recon=0.0364, kl=0.0147, beta=0.0001\n",
      "Batch 100, loss=0.0911, recon=0.0911, kl=0.0898, beta=0.0001\n",
      "Batch 120, loss=0.0437, recon=0.0437, kl=0.0771, beta=0.0001\n",
      "Batch 140, loss=0.0574, recon=0.0574, kl=0.0424, beta=0.0001\n",
      "Batch 160, loss=0.0388, recon=0.0388, kl=0.0352, beta=0.0001\n",
      "Batch 180, loss=0.0467, recon=0.0467, kl=0.0241, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0493 (Recon: 0.0493, KL: 0.0714, Current Beta: 0.0001) | Avg Valid Loss: 0.0519 | Avg Valid recon Loss: 0.0519\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0363, recon=0.0363, kl=0.0111, beta=0.0001\n",
      "Batch 40, loss=0.0447, recon=0.0447, kl=0.0298, beta=0.0001\n",
      "Batch 60, loss=0.0478, recon=0.0478, kl=0.0284, beta=0.0001\n",
      "Batch 80, loss=0.0455, recon=0.0455, kl=0.0242, beta=0.0001\n",
      "Batch 100, loss=0.0626, recon=0.0626, kl=0.0874, beta=0.0001\n",
      "Batch 120, loss=0.0374, recon=0.0374, kl=0.0498, beta=0.0001\n",
      "Batch 140, loss=0.0914, recon=0.0914, kl=0.0783, beta=0.0001\n",
      "Batch 160, loss=0.0239, recon=0.0239, kl=0.2135, beta=0.0001\n",
      "Batch 180, loss=0.0429, recon=0.0429, kl=0.0400, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0500 (Recon: 0.0500, KL: 0.0614, Current Beta: 0.0001) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0292, recon=0.0292, kl=0.0111, beta=0.0001\n",
      "Batch 40, loss=0.0365, recon=0.0365, kl=0.0261, beta=0.0001\n",
      "Batch 60, loss=0.0298, recon=0.0298, kl=0.0120, beta=0.0001\n",
      "Batch 80, loss=0.0280, recon=0.0280, kl=0.1405, beta=0.0001\n",
      "Batch 100, loss=0.0548, recon=0.0548, kl=0.0314, beta=0.0001\n",
      "Batch 120, loss=0.1648, recon=0.1648, kl=0.1788, beta=0.0001\n",
      "Batch 140, loss=0.0331, recon=0.0331, kl=0.2804, beta=0.0001\n",
      "Batch 160, loss=0.0307, recon=0.0307, kl=0.1107, beta=0.0001\n",
      "Batch 180, loss=0.0604, recon=0.0604, kl=0.0328, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0448 (Recon: 0.0448, KL: 0.0776, Current Beta: 0.0001) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0392\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0780, recon=0.0780, kl=0.0276, beta=0.0001\n",
      "Batch 40, loss=0.0319, recon=0.0319, kl=0.0137, beta=0.0001\n",
      "Batch 60, loss=0.0775, recon=0.0775, kl=0.0678, beta=0.0001\n",
      "Batch 80, loss=0.0360, recon=0.0360, kl=0.0484, beta=0.0001\n",
      "Batch 100, loss=0.0240, recon=0.0240, kl=0.0666, beta=0.0001\n",
      "Batch 120, loss=0.0302, recon=0.0302, kl=0.0466, beta=0.0001\n",
      "Batch 140, loss=0.0321, recon=0.0321, kl=0.0124, beta=0.0001\n",
      "Batch 160, loss=0.0361, recon=0.0361, kl=0.0062, beta=0.0001\n",
      "Batch 180, loss=0.0261, recon=0.0261, kl=0.0149, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0446, KL: 0.0348, Current Beta: 0.0001) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0395\n",
      " New best VRAE model found with validation loss: 0.0395\n",
      "   Model saved to ./ecg_model_logs\\best_vrae_model.pth\n",
      "\n",
      "[VRAE Run 3/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6130, recon=0.6130, kl=0.6228, beta=0.0000\n",
      "Batch 40, loss=0.5813, recon=0.5813, kl=0.9757, beta=0.0000\n",
      "Batch 60, loss=0.4021, recon=0.4021, kl=2.5927, beta=0.0000\n",
      "Batch 80, loss=0.2881, recon=0.2881, kl=7.0189, beta=0.0000\n",
      "Batch 100, loss=0.3242, recon=0.3242, kl=17.0646, beta=0.0000\n",
      "Batch 120, loss=0.2134, recon=0.2134, kl=25.6910, beta=0.0000\n",
      "Batch 140, loss=0.3056, recon=0.3056, kl=29.5763, beta=0.0000\n",
      "Batch 160, loss=0.2136, recon=0.2136, kl=32.5838, beta=0.0000\n",
      "Batch 180, loss=0.1230, recon=0.1230, kl=36.2179, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4697 (Recon: 0.4697, KL: 15.2301, Current Beta: 0.0000) | Avg Valid Loss: 0.2502 | Avg Valid recon Loss: 0.2502\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1628, recon=0.1628, kl=38.9384, beta=0.0000\n",
      "Batch 40, loss=0.4639, recon=0.4639, kl=41.0415, beta=0.0000\n",
      "Batch 60, loss=0.2447, recon=0.2447, kl=43.4832, beta=0.0000\n",
      "Batch 80, loss=0.1925, recon=0.1925, kl=44.8125, beta=0.0000\n",
      "Batch 100, loss=0.1487, recon=0.1487, kl=47.3988, beta=0.0000\n",
      "Batch 120, loss=0.2566, recon=0.2566, kl=49.0226, beta=0.0000\n",
      "Batch 140, loss=0.2044, recon=0.2044, kl=52.2613, beta=0.0000\n",
      "Batch 160, loss=0.1790, recon=0.1790, kl=54.4218, beta=0.0000\n",
      "Batch 180, loss=0.1159, recon=0.1159, kl=56.1546, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2222 (Recon: 0.2222, KL: 46.5999, Current Beta: 0.0000) | Avg Valid Loss: 0.1567 | Avg Valid recon Loss: 0.1567\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1177, recon=0.1177, kl=57.6659, beta=0.0000\n",
      "Batch 40, loss=0.1303, recon=0.1303, kl=59.0522, beta=0.0000\n",
      "Batch 60, loss=0.2039, recon=0.2039, kl=60.6012, beta=0.0000\n",
      "Batch 80, loss=0.1613, recon=0.1613, kl=61.3522, beta=0.0000\n",
      "Batch 100, loss=0.1819, recon=0.1819, kl=62.9349, beta=0.0000\n",
      "Batch 120, loss=0.1538, recon=0.1538, kl=63.4618, beta=0.0000\n",
      "Batch 140, loss=0.0968, recon=0.0968, kl=64.3785, beta=0.0000\n",
      "Batch 160, loss=0.2821, recon=0.2821, kl=65.2019, beta=0.0000\n",
      "Batch 180, loss=0.1274, recon=0.1274, kl=67.5389, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1621 (Recon: 0.1621, KL: 62.0058, Current Beta: 0.0000) | Avg Valid Loss: 0.1207 | Avg Valid recon Loss: 0.1207\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0736, recon=0.0736, kl=69.1225, beta=0.0000\n",
      "Batch 40, loss=0.1400, recon=0.1400, kl=69.6724, beta=0.0000\n",
      "Batch 60, loss=0.0934, recon=0.0934, kl=70.8137, beta=0.0000\n",
      "Batch 80, loss=0.0907, recon=0.0907, kl=71.4191, beta=0.0000\n",
      "Batch 100, loss=0.0836, recon=0.0836, kl=71.8745, beta=0.0000\n",
      "Batch 120, loss=0.0791, recon=0.0791, kl=71.6748, beta=0.0000\n",
      "Batch 140, loss=0.0870, recon=0.0870, kl=72.4731, beta=0.0000\n",
      "Batch 160, loss=0.0752, recon=0.0752, kl=73.5358, beta=0.0000\n",
      "Batch 180, loss=0.1716, recon=0.1716, kl=75.2859, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1305 (Recon: 0.1305, KL: 71.3581, Current Beta: 0.0000) | Avg Valid Loss: 0.1017 | Avg Valid recon Loss: 0.1017\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0813, recon=0.0813, kl=76.0521, beta=0.0000\n",
      "Batch 40, loss=0.0858, recon=0.0858, kl=76.5872, beta=0.0000\n",
      "Batch 60, loss=0.1307, recon=0.1307, kl=77.4074, beta=0.0000\n",
      "Batch 80, loss=0.0815, recon=0.0815, kl=77.7969, beta=0.0000\n",
      "Batch 100, loss=0.1104, recon=0.1104, kl=79.1885, beta=0.0000\n",
      "Batch 120, loss=0.0903, recon=0.0903, kl=79.4788, beta=0.0000\n",
      "Batch 140, loss=0.1239, recon=0.1239, kl=80.7197, beta=0.0000\n",
      "Batch 160, loss=0.0668, recon=0.0668, kl=81.0259, beta=0.0000\n",
      "Batch 180, loss=0.1081, recon=0.1081, kl=81.9603, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1117 (Recon: 0.1117, KL: 78.5344, Current Beta: 0.0000) | Avg Valid Loss: 0.0900 | Avg Valid recon Loss: 0.0900\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0636, recon=0.0636, kl=82.5022, beta=0.0000\n",
      "Batch 40, loss=0.0793, recon=0.0793, kl=83.0915, beta=0.0000\n",
      "Batch 60, loss=0.0761, recon=0.0761, kl=83.7843, beta=0.0000\n",
      "Batch 80, loss=0.0783, recon=0.0783, kl=84.4537, beta=0.0000\n",
      "Batch 100, loss=0.1143, recon=0.1143, kl=84.1440, beta=0.0000\n",
      "Batch 120, loss=0.1127, recon=0.1127, kl=84.2098, beta=0.0000\n",
      "Batch 140, loss=0.0905, recon=0.0905, kl=85.2462, beta=0.0000\n",
      "Batch 160, loss=0.0802, recon=0.0802, kl=85.5701, beta=0.0000\n",
      "Batch 180, loss=0.0524, recon=0.0524, kl=85.9303, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0992 (Recon: 0.0992, KL: 84.0552, Current Beta: 0.0000) | Avg Valid Loss: 0.0814 | Avg Valid recon Loss: 0.0814\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0466, recon=0.0466, kl=85.4374, beta=0.0000\n",
      "Batch 40, loss=0.0811, recon=0.0811, kl=85.8890, beta=0.0000\n",
      "Batch 60, loss=0.0831, recon=0.0831, kl=85.4433, beta=0.0000\n",
      "Batch 80, loss=0.0744, recon=0.0744, kl=85.8096, beta=0.0000\n",
      "Batch 100, loss=0.0564, recon=0.0564, kl=86.2006, beta=0.0000\n",
      "Batch 120, loss=0.0708, recon=0.0707, kl=85.4792, beta=0.0000\n",
      "Batch 140, loss=0.0629, recon=0.0629, kl=85.3843, beta=0.0000\n",
      "Batch 160, loss=0.0787, recon=0.0787, kl=85.9522, beta=0.0000\n",
      "Batch 180, loss=0.1161, recon=0.1161, kl=85.6168, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0907 (Recon: 0.0907, KL: 85.8267, Current Beta: 0.0000) | Avg Valid Loss: 0.0757 | Avg Valid recon Loss: 0.0757\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0625, recon=0.0625, kl=84.9214, beta=0.0000\n",
      "Batch 40, loss=0.0727, recon=0.0727, kl=83.5163, beta=0.0000\n",
      "Batch 60, loss=0.0563, recon=0.0563, kl=82.1772, beta=0.0000\n",
      "Batch 80, loss=0.0987, recon=0.0987, kl=81.2512, beta=0.0000\n",
      "Batch 100, loss=0.0558, recon=0.0557, kl=80.2552, beta=0.0000\n",
      "Batch 120, loss=0.0681, recon=0.0681, kl=79.7753, beta=0.0000\n",
      "Batch 140, loss=0.0466, recon=0.0466, kl=78.2605, beta=0.0000\n",
      "Batch 160, loss=0.0688, recon=0.0687, kl=76.9296, beta=0.0000\n",
      "Batch 180, loss=0.0507, recon=0.0507, kl=76.0177, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0840 (Recon: 0.0840, KL: 80.7121, Current Beta: 0.0000) | Avg Valid Loss: 0.0716 | Avg Valid recon Loss: 0.0716\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0641, recon=0.0641, kl=72.9682, beta=0.0000\n",
      "Batch 40, loss=0.0698, recon=0.0698, kl=69.5638, beta=0.0000\n",
      "Batch 60, loss=0.0661, recon=0.0661, kl=66.0733, beta=0.0000\n",
      "Batch 80, loss=0.0532, recon=0.0531, kl=62.5828, beta=0.0000\n",
      "Batch 100, loss=0.0763, recon=0.0763, kl=60.8938, beta=0.0000\n",
      "Batch 120, loss=0.0776, recon=0.0776, kl=58.3852, beta=0.0000\n",
      "Batch 140, loss=0.0714, recon=0.0714, kl=56.8784, beta=0.0000\n",
      "Batch 160, loss=0.0433, recon=0.0433, kl=55.6673, beta=0.0000\n",
      "Batch 180, loss=0.0580, recon=0.0580, kl=53.4056, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0791 (Recon: 0.0791, KL: 62.9860, Current Beta: 0.0000) | Avg Valid Loss: 0.0673 | Avg Valid recon Loss: 0.0673\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=47.4334, beta=0.0000\n",
      "Batch 40, loss=0.0465, recon=0.0465, kl=40.8392, beta=0.0000\n",
      "Batch 60, loss=0.0614, recon=0.0613, kl=35.9860, beta=0.0000\n",
      "Batch 80, loss=0.0556, recon=0.0555, kl=33.4513, beta=0.0000\n",
      "Batch 100, loss=0.2394, recon=0.2394, kl=32.4953, beta=0.0000\n",
      "Batch 120, loss=0.0622, recon=0.0622, kl=32.0170, beta=0.0000\n",
      "Batch 140, loss=0.0477, recon=0.0477, kl=29.9409, beta=0.0000\n",
      "Batch 160, loss=0.0557, recon=0.0557, kl=28.6251, beta=0.0000\n",
      "Batch 180, loss=0.0423, recon=0.0423, kl=27.5853, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0748 (Recon: 0.0747, KL: 35.6095, Current Beta: 0.0000) | Avg Valid Loss: 0.0646 | Avg Valid recon Loss: 0.0645\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0362, recon=0.0361, kl=21.2242, beta=0.0000\n",
      "Batch 40, loss=0.0394, recon=0.0394, kl=15.6599, beta=0.0000\n",
      "Batch 60, loss=0.0408, recon=0.0408, kl=15.1333, beta=0.0000\n",
      "Batch 80, loss=0.0827, recon=0.0826, kl=14.2448, beta=0.0000\n",
      "Batch 100, loss=0.0576, recon=0.0575, kl=13.0518, beta=0.0000\n",
      "Batch 120, loss=0.0422, recon=0.0422, kl=12.9771, beta=0.0000\n",
      "Batch 140, loss=0.0685, recon=0.0684, kl=13.0356, beta=0.0000\n",
      "Batch 160, loss=0.0567, recon=0.0567, kl=12.3444, beta=0.0000\n",
      "Batch 180, loss=0.0483, recon=0.0483, kl=12.6184, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0713 (Recon: 0.0712, KL: 15.2171, Current Beta: 0.0000) | Avg Valid Loss: 0.0618 | Avg Valid recon Loss: 0.0618\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0379, recon=0.0379, kl=7.1601, beta=0.0000\n",
      "Batch 40, loss=0.0386, recon=0.0385, kl=6.4672, beta=0.0000\n",
      "Batch 60, loss=0.0420, recon=0.0419, kl=5.7056, beta=0.0000\n",
      "Batch 80, loss=0.0537, recon=0.0536, kl=7.2740, beta=0.0000\n",
      "Batch 100, loss=0.0478, recon=0.0478, kl=5.5817, beta=0.0000\n",
      "Batch 120, loss=0.0361, recon=0.0361, kl=5.0071, beta=0.0000\n",
      "Batch 140, loss=0.0644, recon=0.0643, kl=4.9362, beta=0.0000\n",
      "Batch 160, loss=0.0640, recon=0.0640, kl=4.9161, beta=0.0000\n",
      "Batch 180, loss=0.0553, recon=0.0552, kl=4.7467, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0683 (Recon: 0.0682, KL: 6.0853, Current Beta: 0.0000) | Avg Valid Loss: 0.0592 | Avg Valid recon Loss: 0.0592\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0314, recon=0.0314, kl=2.5430, beta=0.0000\n",
      "Batch 40, loss=0.0709, recon=0.0709, kl=2.4342, beta=0.0000\n",
      "Batch 60, loss=0.0588, recon=0.0588, kl=2.2452, beta=0.0000\n",
      "Batch 80, loss=0.0364, recon=0.0364, kl=2.0212, beta=0.0000\n",
      "Batch 100, loss=0.0406, recon=0.0406, kl=2.0512, beta=0.0000\n",
      "Batch 120, loss=0.0451, recon=0.0450, kl=1.9073, beta=0.0000\n",
      "Batch 140, loss=0.0757, recon=0.0757, kl=1.7060, beta=0.0000\n",
      "Batch 160, loss=0.2101, recon=0.2100, kl=1.6530, beta=0.0000\n",
      "Batch 180, loss=0.0421, recon=0.0421, kl=1.4135, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0661 (Recon: 0.0661, KL: 2.1746, Current Beta: 0.0000) | Avg Valid Loss: 0.0572 | Avg Valid recon Loss: 0.0572\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0432, recon=0.0432, kl=0.9026, beta=0.0000\n",
      "Batch 40, loss=0.0625, recon=0.0624, kl=0.8880, beta=0.0000\n",
      "Batch 60, loss=0.0415, recon=0.0415, kl=0.7301, beta=0.0000\n",
      "Batch 80, loss=0.0888, recon=0.0887, kl=0.5926, beta=0.0000\n",
      "Batch 100, loss=0.0434, recon=0.0434, kl=0.6967, beta=0.0000\n",
      "Batch 120, loss=0.0465, recon=0.0465, kl=0.4404, beta=0.0000\n",
      "Batch 140, loss=0.0498, recon=0.0497, kl=0.6492, beta=0.0000\n",
      "Batch 160, loss=0.0361, recon=0.0361, kl=0.4551, beta=0.0000\n",
      "Batch 180, loss=0.0487, recon=0.0486, kl=0.4722, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0638 (Recon: 0.0638, KL: 0.6958, Current Beta: 0.0000) | Avg Valid Loss: 0.0557 | Avg Valid recon Loss: 0.0557\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0772, recon=0.0772, kl=0.2091, beta=0.0001\n",
      "Batch 40, loss=0.0442, recon=0.0442, kl=0.1789, beta=0.0001\n",
      "Batch 60, loss=0.0783, recon=0.0783, kl=0.1275, beta=0.0001\n",
      "Batch 80, loss=0.0824, recon=0.0824, kl=0.1535, beta=0.0001\n",
      "Batch 100, loss=0.0417, recon=0.0417, kl=0.1029, beta=0.0001\n",
      "Batch 120, loss=0.0292, recon=0.0292, kl=0.2441, beta=0.0001\n",
      "Batch 140, loss=0.0245, recon=0.0245, kl=0.0826, beta=0.0001\n",
      "Batch 160, loss=0.0439, recon=0.0439, kl=0.0893, beta=0.0001\n",
      "Batch 180, loss=0.0865, recon=0.0865, kl=0.0671, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0618 (Recon: 0.0618, KL: 0.1610, Current Beta: 0.0001) | Avg Valid Loss: 0.0539 | Avg Valid recon Loss: 0.0539\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0517, recon=0.0517, kl=0.0384, beta=0.0001\n",
      "Batch 40, loss=0.0441, recon=0.0441, kl=0.0314, beta=0.0001\n",
      "Batch 60, loss=0.0417, recon=0.0417, kl=0.0228, beta=0.0001\n",
      "Batch 80, loss=0.0397, recon=0.0397, kl=0.0454, beta=0.0001\n",
      "Batch 100, loss=0.0422, recon=0.0422, kl=0.0212, beta=0.0001\n",
      "Batch 120, loss=0.0381, recon=0.0381, kl=0.0132, beta=0.0001\n",
      "Batch 140, loss=0.0581, recon=0.0581, kl=0.0280, beta=0.0001\n",
      "Batch 160, loss=0.0469, recon=0.0469, kl=0.0175, beta=0.0001\n",
      "Batch 180, loss=0.1117, recon=0.1117, kl=0.0585, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0603 (Recon: 0.0603, KL: 0.0294, Current Beta: 0.0001) | Avg Valid Loss: 0.0530 | Avg Valid recon Loss: 0.0530\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0336, recon=0.0336, kl=0.0174, beta=0.0001\n",
      "Batch 40, loss=0.0496, recon=0.0496, kl=0.0178, beta=0.0001\n",
      "Batch 60, loss=0.0616, recon=0.0616, kl=0.0155, beta=0.0001\n",
      "Batch 80, loss=0.0435, recon=0.0435, kl=0.0096, beta=0.0001\n",
      "Batch 100, loss=0.0426, recon=0.0426, kl=0.0158, beta=0.0001\n",
      "Batch 120, loss=0.1694, recon=0.1694, kl=0.0256, beta=0.0001\n",
      "Batch 140, loss=0.0830, recon=0.0830, kl=0.0103, beta=0.0001\n",
      "Batch 160, loss=0.0293, recon=0.0293, kl=0.0089, beta=0.0001\n",
      "Batch 180, loss=0.0593, recon=0.0593, kl=0.0074, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0587 (Recon: 0.0587, KL: 0.0155, Current Beta: 0.0001) | Avg Valid Loss: 0.0514 | Avg Valid recon Loss: 0.0514\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0428, recon=0.0428, kl=0.0086, beta=0.0001\n",
      "Batch 40, loss=0.0618, recon=0.0618, kl=0.0107, beta=0.0001\n",
      "Batch 60, loss=0.0442, recon=0.0442, kl=0.0076, beta=0.0001\n",
      "Batch 80, loss=0.0368, recon=0.0368, kl=0.0108, beta=0.0001\n",
      "Batch 100, loss=0.0536, recon=0.0536, kl=0.0109, beta=0.0001\n",
      "Batch 120, loss=0.0792, recon=0.0792, kl=0.0128, beta=0.0001\n",
      "Batch 140, loss=0.0463, recon=0.0463, kl=0.0067, beta=0.0001\n",
      "Batch 160, loss=0.0461, recon=0.0461, kl=0.0113, beta=0.0001\n",
      "Batch 180, loss=0.0318, recon=0.0318, kl=0.0094, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0576 (Recon: 0.0576, KL: 0.0103, Current Beta: 0.0001) | Avg Valid Loss: 0.0504 | Avg Valid recon Loss: 0.0504\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0403, recon=0.0403, kl=0.0088, beta=0.0001\n",
      "Batch 40, loss=0.0321, recon=0.0321, kl=0.0075, beta=0.0001\n",
      "Batch 60, loss=0.0349, recon=0.0349, kl=0.0023, beta=0.0001\n",
      "Batch 80, loss=0.0385, recon=0.0385, kl=0.0070, beta=0.0001\n",
      "Batch 100, loss=0.0494, recon=0.0494, kl=0.0079, beta=0.0001\n",
      "Batch 120, loss=0.0357, recon=0.0357, kl=0.0106, beta=0.0001\n",
      "Batch 140, loss=0.0352, recon=0.0352, kl=0.0051, beta=0.0001\n",
      "Batch 160, loss=0.0494, recon=0.0494, kl=0.0066, beta=0.0001\n",
      "Batch 180, loss=0.0350, recon=0.0350, kl=0.0090, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0566 (Recon: 0.0566, KL: 0.0081, Current Beta: 0.0001) | Avg Valid Loss: 0.0492 | Avg Valid recon Loss: 0.0492\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0407, recon=0.0407, kl=0.0089, beta=0.0001\n",
      "Batch 40, loss=0.0358, recon=0.0358, kl=0.0026, beta=0.0001\n",
      "Batch 60, loss=0.0382, recon=0.0382, kl=0.0032, beta=0.0001\n",
      "Batch 80, loss=0.0543, recon=0.0543, kl=0.0087, beta=0.0001\n",
      "Batch 100, loss=0.0476, recon=0.0476, kl=0.0052, beta=0.0001\n",
      "Batch 120, loss=0.0312, recon=0.0312, kl=0.0037, beta=0.0001\n",
      "Batch 140, loss=0.0384, recon=0.0384, kl=0.0028, beta=0.0001\n",
      "Batch 160, loss=0.0415, recon=0.0415, kl=0.0058, beta=0.0001\n",
      "Batch 180, loss=0.0908, recon=0.0908, kl=0.0035, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0553 (Recon: 0.0553, KL: 0.0059, Current Beta: 0.0001) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0480\n",
      "\n",
      "[VRAE Run 4/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2499, recon=0.2499, kl=17.6119, beta=0.0000\n",
      "Batch 40, loss=0.1587, recon=0.1587, kl=31.9462, beta=0.0000\n",
      "Batch 60, loss=0.0698, recon=0.0698, kl=44.3018, beta=0.0000\n",
      "Batch 80, loss=0.1216, recon=0.1216, kl=53.0815, beta=0.0000\n",
      "Batch 100, loss=0.2814, recon=0.2814, kl=54.4774, beta=0.0000\n",
      "Batch 120, loss=0.1032, recon=0.1032, kl=44.4890, beta=0.0000\n",
      "Batch 140, loss=0.0506, recon=0.0506, kl=53.7943, beta=0.0000\n",
      "Batch 160, loss=0.0685, recon=0.0685, kl=58.3165, beta=0.0000\n",
      "Batch 180, loss=0.0915, recon=0.0915, kl=62.3332, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1798 (Recon: 0.1798, KL: 43.6058, Current Beta: 0.0000) | Avg Valid Loss: 0.0762 | Avg Valid recon Loss: 0.0762\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0466, recon=0.0466, kl=62.4874, beta=0.0000\n",
      "Batch 40, loss=0.1661, recon=0.1661, kl=62.8027, beta=0.0000\n",
      "Batch 60, loss=0.0585, recon=0.0585, kl=64.7213, beta=0.0000\n",
      "Batch 80, loss=0.0450, recon=0.0450, kl=66.1110, beta=0.0000\n",
      "Batch 100, loss=0.0618, recon=0.0618, kl=64.1505, beta=0.0000\n",
      "Batch 120, loss=0.0607, recon=0.0607, kl=62.1846, beta=0.0000\n",
      "Batch 140, loss=0.0839, recon=0.0839, kl=63.8383, beta=0.0000\n",
      "Batch 160, loss=0.0877, recon=0.0877, kl=67.8204, beta=0.0000\n",
      "Batch 180, loss=0.0485, recon=0.0485, kl=63.3461, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0788 (Recon: 0.0788, KL: 64.8464, Current Beta: 0.0000) | Avg Valid Loss: 0.0670 | Avg Valid recon Loss: 0.0670\n",
      "Epoch 3/20\n",
      "Batch 20, loss=1.3257, recon=1.3257, kl=68.1247, beta=0.0000\n",
      "Batch 40, loss=0.0457, recon=0.0457, kl=68.4670, beta=0.0000\n",
      "Batch 60, loss=0.0572, recon=0.0572, kl=62.2909, beta=0.0000\n",
      "Batch 80, loss=0.0536, recon=0.0536, kl=64.9649, beta=0.0000\n",
      "Batch 100, loss=0.0434, recon=0.0434, kl=62.4572, beta=0.0000\n",
      "Batch 120, loss=0.0454, recon=0.0454, kl=66.6197, beta=0.0000\n",
      "Batch 140, loss=0.0459, recon=0.0459, kl=69.7891, beta=0.0000\n",
      "Batch 160, loss=0.0532, recon=0.0532, kl=72.6564, beta=0.0000\n",
      "Batch 180, loss=0.1151, recon=0.1151, kl=66.4495, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0665 (Recon: 0.0665, KL: 67.2824, Current Beta: 0.0000) | Avg Valid Loss: 0.0545 | Avg Valid recon Loss: 0.0545\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0853, recon=0.0853, kl=66.6416, beta=0.0000\n",
      "Batch 40, loss=0.0330, recon=0.0330, kl=66.8982, beta=0.0000\n",
      "Batch 60, loss=0.0487, recon=0.0487, kl=66.7768, beta=0.0000\n",
      "Batch 80, loss=0.0658, recon=0.0658, kl=66.6118, beta=0.0000\n",
      "Batch 100, loss=0.0440, recon=0.0440, kl=63.2743, beta=0.0000\n",
      "Batch 120, loss=0.0487, recon=0.0487, kl=64.0825, beta=0.0000\n",
      "Batch 140, loss=0.0413, recon=0.0413, kl=65.3826, beta=0.0000\n",
      "Batch 160, loss=0.0487, recon=0.0487, kl=66.4511, beta=0.0000\n",
      "Batch 180, loss=0.0524, recon=0.0524, kl=65.5026, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0623 (Recon: 0.0623, KL: 65.6257, Current Beta: 0.0000) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0598, recon=0.0598, kl=69.0890, beta=0.0000\n",
      "Batch 40, loss=0.0357, recon=0.0357, kl=68.9406, beta=0.0000\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=68.9740, beta=0.0000\n",
      "Batch 80, loss=0.0860, recon=0.0860, kl=67.3227, beta=0.0000\n",
      "Batch 100, loss=0.0366, recon=0.0366, kl=68.6305, beta=0.0000\n",
      "Batch 120, loss=0.0400, recon=0.0400, kl=74.6573, beta=0.0000\n",
      "Batch 140, loss=0.0331, recon=0.0331, kl=80.5446, beta=0.0000\n",
      "Batch 160, loss=0.0279, recon=0.0279, kl=79.5294, beta=0.0000\n",
      "Batch 180, loss=0.0238, recon=0.0238, kl=72.9959, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 72.0674, Current Beta: 0.0000) | Avg Valid Loss: 0.0481 | Avg Valid recon Loss: 0.0481\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0579, recon=0.0579, kl=73.2009, beta=0.0000\n",
      "Batch 40, loss=0.0492, recon=0.0492, kl=73.0522, beta=0.0000\n",
      "Batch 60, loss=0.0373, recon=0.0373, kl=74.4801, beta=0.0000\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=74.8631, beta=0.0000\n",
      "Batch 100, loss=0.0662, recon=0.0662, kl=75.8826, beta=0.0000\n",
      "Batch 120, loss=0.0415, recon=0.0415, kl=74.8293, beta=0.0000\n",
      "Batch 140, loss=0.0735, recon=0.0735, kl=74.3536, beta=0.0000\n",
      "Batch 160, loss=0.0348, recon=0.0348, kl=72.9299, beta=0.0000\n",
      "Batch 180, loss=0.0561, recon=0.0561, kl=68.8674, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0564 (Recon: 0.0564, KL: 73.9422, Current Beta: 0.0000) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0359, recon=0.0359, kl=65.9210, beta=0.0000\n",
      "Batch 40, loss=0.0373, recon=0.0373, kl=64.3832, beta=0.0000\n",
      "Batch 60, loss=0.0479, recon=0.0479, kl=68.5803, beta=0.0000\n",
      "Batch 80, loss=0.0817, recon=0.0816, kl=65.6830, beta=0.0000\n",
      "Batch 100, loss=0.0362, recon=0.0361, kl=62.8355, beta=0.0000\n",
      "Batch 120, loss=0.0396, recon=0.0396, kl=69.0733, beta=0.0000\n",
      "Batch 140, loss=0.0328, recon=0.0328, kl=72.2069, beta=0.0000\n",
      "Batch 160, loss=0.0380, recon=0.0380, kl=69.4698, beta=0.0000\n",
      "Batch 180, loss=0.0275, recon=0.0275, kl=68.8838, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0528 (Recon: 0.0528, KL: 67.0674, Current Beta: 0.0000) | Avg Valid Loss: 0.0432 | Avg Valid recon Loss: 0.0432\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0525, recon=0.0525, kl=65.3111, beta=0.0000\n",
      "Batch 40, loss=0.0525, recon=0.0525, kl=64.2633, beta=0.0000\n",
      "Batch 60, loss=0.0590, recon=0.0590, kl=63.0616, beta=0.0000\n",
      "Batch 80, loss=0.0487, recon=0.0487, kl=60.7366, beta=0.0000\n",
      "Batch 100, loss=0.2236, recon=0.2236, kl=58.5850, beta=0.0000\n",
      "Batch 120, loss=0.0419, recon=0.0419, kl=56.3499, beta=0.0000\n",
      "Batch 140, loss=0.0287, recon=0.0287, kl=56.6864, beta=0.0000\n",
      "Batch 160, loss=0.0496, recon=0.0496, kl=62.3546, beta=0.0000\n",
      "Batch 180, loss=0.0348, recon=0.0348, kl=61.2009, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0514 (Recon: 0.0514, KL: 61.2809, Current Beta: 0.0000) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0443\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=57.0085, beta=0.0000\n",
      "Batch 40, loss=0.0415, recon=0.0415, kl=55.1296, beta=0.0000\n",
      "Batch 60, loss=0.0317, recon=0.0317, kl=50.8735, beta=0.0000\n",
      "Batch 80, loss=0.0415, recon=0.0415, kl=48.4994, beta=0.0000\n",
      "Batch 100, loss=0.0666, recon=0.0666, kl=49.3142, beta=0.0000\n",
      "Batch 120, loss=0.0385, recon=0.0385, kl=49.3195, beta=0.0000\n",
      "Batch 140, loss=0.0376, recon=0.0376, kl=50.7864, beta=0.0000\n",
      "Batch 160, loss=0.0311, recon=0.0311, kl=52.0634, beta=0.0000\n",
      "Batch 180, loss=0.0490, recon=0.0490, kl=50.6174, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0562 (Recon: 0.0562, KL: 52.0618, Current Beta: 0.0000) | Avg Valid Loss: 0.0646 | Avg Valid recon Loss: 0.0646\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0413, recon=0.0413, kl=43.1755, beta=0.0000\n",
      "Batch 40, loss=0.0628, recon=0.0627, kl=39.9128, beta=0.0000\n",
      "Batch 60, loss=0.0400, recon=0.0400, kl=38.8564, beta=0.0000\n",
      "Batch 80, loss=0.0420, recon=0.0419, kl=40.2033, beta=0.0000\n",
      "Batch 100, loss=0.0379, recon=0.0378, kl=43.1758, beta=0.0000\n",
      "Batch 120, loss=0.0450, recon=0.0450, kl=43.9541, beta=0.0000\n",
      "Batch 140, loss=0.0483, recon=0.0482, kl=44.9701, beta=0.0000\n",
      "Batch 160, loss=0.0447, recon=0.0447, kl=38.0960, beta=0.0000\n",
      "Batch 180, loss=0.0354, recon=0.0354, kl=36.4513, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0580 (Recon: 0.0579, KL: 41.7442, Current Beta: 0.0000) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0302, recon=0.0301, kl=26.2722, beta=0.0000\n",
      "Batch 40, loss=0.0356, recon=0.0355, kl=23.6350, beta=0.0000\n",
      "Batch 60, loss=0.0304, recon=0.0303, kl=21.3034, beta=0.0000\n",
      "Batch 80, loss=0.0407, recon=0.0406, kl=21.5335, beta=0.0000\n",
      "Batch 100, loss=0.0679, recon=0.0679, kl=17.9597, beta=0.0000\n",
      "Batch 120, loss=0.0496, recon=0.0495, kl=21.9857, beta=0.0000\n",
      "Batch 140, loss=0.0334, recon=0.0334, kl=20.3671, beta=0.0000\n",
      "Batch 160, loss=0.0663, recon=0.0663, kl=20.9026, beta=0.0000\n",
      "Batch 180, loss=0.0376, recon=0.0376, kl=25.5515, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0526, KL: 22.5741, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0486, recon=0.0485, kl=16.5469, beta=0.0000\n",
      "Batch 40, loss=0.0330, recon=0.0329, kl=9.7563, beta=0.0000\n",
      "Batch 60, loss=0.0260, recon=0.0260, kl=9.1295, beta=0.0000\n",
      "Batch 80, loss=0.0244, recon=0.0243, kl=14.0550, beta=0.0000\n",
      "Batch 100, loss=0.0372, recon=0.0369, kl=34.0112, beta=0.0000\n",
      "Batch 120, loss=0.0272, recon=0.0270, kl=33.4644, beta=0.0000\n",
      "Batch 140, loss=0.0372, recon=0.0370, kl=30.4895, beta=0.0000\n",
      "Batch 160, loss=0.1040, recon=0.1038, kl=29.2168, beta=0.0000\n",
      "Batch 180, loss=0.0305, recon=0.0303, kl=24.7248, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0493, KL: 22.6424, Current Beta: 0.0000) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0446, recon=0.0443, kl=16.2356, beta=0.0000\n",
      "Batch 40, loss=0.0583, recon=0.0580, kl=13.3494, beta=0.0000\n",
      "Batch 60, loss=0.0228, recon=0.0224, kl=21.2286, beta=0.0000\n",
      "Batch 80, loss=0.0325, recon=0.0321, kl=22.2672, beta=0.0000\n",
      "Batch 100, loss=0.0560, recon=0.0556, kl=25.8494, beta=0.0000\n",
      "Batch 120, loss=0.0405, recon=0.0402, kl=20.3332, beta=0.0000\n",
      "Batch 140, loss=0.0415, recon=0.0411, kl=17.4692, beta=0.0000\n",
      "Batch 160, loss=0.0362, recon=0.0359, kl=13.9968, beta=0.0000\n",
      "Batch 180, loss=0.0339, recon=0.0336, kl=11.7345, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0513, KL: 18.6505, Current Beta: 0.0000) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0470\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0441, recon=0.0439, kl=7.7440, beta=0.0000\n",
      "Batch 40, loss=0.0475, recon=0.0472, kl=9.4653, beta=0.0000\n",
      "Batch 60, loss=0.0382, recon=0.0379, kl=7.9690, beta=0.0000\n",
      "Batch 80, loss=0.0268, recon=0.0267, kl=4.8174, beta=0.0000\n",
      "Batch 100, loss=0.0413, recon=0.0410, kl=7.3767, beta=0.0000\n",
      "Batch 120, loss=0.0406, recon=0.0404, kl=5.3957, beta=0.0000\n",
      "Batch 140, loss=0.0330, recon=0.0328, kl=5.5525, beta=0.0000\n",
      "Batch 160, loss=0.0433, recon=0.0430, kl=8.8719, beta=0.0000\n",
      "Batch 180, loss=0.0371, recon=0.0368, kl=7.6991, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0493, KL: 7.5955, Current Beta: 0.0000) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0473, recon=0.0469, kl=5.3617, beta=0.0001\n",
      "Batch 40, loss=0.0278, recon=0.0276, kl=3.8773, beta=0.0001\n",
      "Batch 60, loss=0.0402, recon=0.0400, kl=2.8738, beta=0.0001\n",
      "Batch 80, loss=0.0328, recon=0.0326, kl=3.3147, beta=0.0001\n",
      "Batch 100, loss=0.0458, recon=0.0456, kl=2.5519, beta=0.0001\n",
      "Batch 120, loss=0.0525, recon=0.0524, kl=2.5089, beta=0.0001\n",
      "Batch 140, loss=0.0216, recon=0.0214, kl=2.2027, beta=0.0001\n",
      "Batch 160, loss=0.0426, recon=0.0424, kl=3.0563, beta=0.0001\n",
      "Batch 180, loss=0.0642, recon=0.0640, kl=2.2690, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0454, KL: 3.4147, Current Beta: 0.0001) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0264, recon=0.0262, kl=1.5851, beta=0.0001\n",
      "Batch 40, loss=0.0350, recon=0.0347, kl=2.3559, beta=0.0001\n",
      "Batch 60, loss=0.0896, recon=0.0894, kl=1.8429, beta=0.0001\n",
      "Batch 80, loss=0.0570, recon=0.0569, kl=1.4929, beta=0.0001\n",
      "Batch 100, loss=0.0664, recon=0.0663, kl=1.3134, beta=0.0001\n",
      "Batch 120, loss=0.0330, recon=0.0328, kl=2.1446, beta=0.0001\n",
      "Batch 140, loss=0.0296, recon=0.0294, kl=2.0250, beta=0.0001\n",
      "Batch 160, loss=0.0352, recon=0.0351, kl=1.3517, beta=0.0001\n",
      "Batch 180, loss=0.0418, recon=0.0417, kl=1.0249, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0459, KL: 1.7696, Current Beta: 0.0001) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0314, recon=0.0313, kl=0.9895, beta=0.0001\n",
      "Batch 40, loss=0.0582, recon=0.0581, kl=1.1856, beta=0.0001\n",
      "Batch 60, loss=0.0546, recon=0.0542, kl=3.9023, beta=0.0001\n",
      "Batch 80, loss=0.0602, recon=0.0590, kl=11.9339, beta=0.0001\n",
      "Batch 100, loss=0.0370, recon=0.0356, kl=14.0414, beta=0.0001\n",
      "Batch 120, loss=0.0406, recon=0.0392, kl=13.6718, beta=0.0001\n",
      "Batch 140, loss=0.0486, recon=0.0474, kl=12.9635, beta=0.0001\n",
      "Batch 160, loss=0.0630, recon=0.0617, kl=12.1155, beta=0.0001\n",
      "Batch 180, loss=0.0281, recon=0.0270, kl=11.6286, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0525, KL: 8.6700, Current Beta: 0.0001) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0333, recon=0.0322, kl=11.3846, beta=0.0001\n",
      "Batch 40, loss=0.0394, recon=0.0384, kl=10.6204, beta=0.0001\n",
      "Batch 60, loss=0.0370, recon=0.0360, kl=10.0329, beta=0.0001\n",
      "Batch 80, loss=0.0256, recon=0.0247, kl=9.4166, beta=0.0001\n",
      "Batch 100, loss=0.0295, recon=0.0288, kl=7.8122, beta=0.0001\n",
      "Batch 120, loss=0.0427, recon=0.0419, kl=7.7450, beta=0.0001\n",
      "Batch 140, loss=0.0406, recon=0.0399, kl=7.2119, beta=0.0001\n",
      "Batch 160, loss=0.0679, recon=0.0672, kl=7.1555, beta=0.0001\n",
      "Batch 180, loss=0.0325, recon=0.0319, kl=5.1049, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0500 (Recon: 0.0491, KL: 8.7710, Current Beta: 0.0001) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0285, recon=0.0279, kl=6.2973, beta=0.0001\n",
      "Batch 40, loss=0.0381, recon=0.0375, kl=6.3105, beta=0.0001\n",
      "Batch 60, loss=0.0515, recon=0.0509, kl=5.6926, beta=0.0001\n",
      "Batch 80, loss=0.0396, recon=0.0391, kl=5.3157, beta=0.0001\n",
      "Batch 100, loss=0.0414, recon=0.0410, kl=4.6518, beta=0.0001\n",
      "Batch 120, loss=0.0514, recon=0.0508, kl=5.3393, beta=0.0001\n",
      "Batch 140, loss=0.0726, recon=0.0720, kl=5.3538, beta=0.0001\n",
      "Batch 160, loss=0.0361, recon=0.0356, kl=5.0600, beta=0.0001\n",
      "Batch 180, loss=0.0690, recon=0.0684, kl=5.7542, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0483 (Recon: 0.0477, KL: 5.5658, Current Beta: 0.0001) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0510, recon=0.0505, kl=5.3127, beta=0.0001\n",
      "Batch 40, loss=0.4703, recon=0.4698, kl=5.4761, beta=0.0001\n",
      "Batch 60, loss=0.0416, recon=0.0411, kl=4.9921, beta=0.0001\n",
      "Batch 80, loss=0.0306, recon=0.0301, kl=4.5499, beta=0.0001\n",
      "Batch 100, loss=0.0253, recon=0.0248, kl=4.9120, beta=0.0001\n",
      "Batch 120, loss=0.0771, recon=0.0767, kl=4.7007, beta=0.0001\n",
      "Batch 140, loss=0.0334, recon=0.0330, kl=4.5715, beta=0.0001\n",
      "Batch 160, loss=0.0552, recon=0.0548, kl=4.2641, beta=0.0001\n",
      "Batch 180, loss=0.0414, recon=0.0409, kl=4.5601, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0483 (Recon: 0.0478, KL: 4.8727, Current Beta: 0.0001) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0389\n",
      " New best VRAE model found with validation loss: 0.0394\n",
      "   Model saved to ./ecg_model_logs\\best_vrae_model.pth\n",
      "\n",
      "[VRAE Run 5/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7940, recon=0.7940, kl=0.8004, beta=0.0000\n",
      "Batch 40, loss=0.7476, recon=0.7476, kl=1.6985, beta=0.0000\n",
      "Batch 60, loss=0.4444, recon=0.4444, kl=13.7161, beta=0.0000\n",
      "Batch 80, loss=0.3773, recon=0.3773, kl=35.9260, beta=0.0000\n",
      "Batch 100, loss=0.3703, recon=0.3703, kl=53.3820, beta=0.0000\n",
      "Batch 120, loss=0.3521, recon=0.3521, kl=65.0617, beta=0.0000\n",
      "Batch 140, loss=0.3318, recon=0.3318, kl=72.5845, beta=0.0000\n",
      "Batch 160, loss=0.3243, recon=0.3243, kl=79.0743, beta=0.0000\n",
      "Batch 180, loss=0.1414, recon=0.1414, kl=83.9061, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4602 (Recon: 0.4602, KL: 40.8373, Current Beta: 0.0000) | Avg Valid Loss: 0.2528 | Avg Valid recon Loss: 0.2528\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2511, recon=0.2511, kl=88.0009, beta=0.0000\n",
      "Batch 40, loss=0.2354, recon=0.2354, kl=91.5589, beta=0.0000\n",
      "Batch 60, loss=0.2728, recon=0.2728, kl=94.8911, beta=0.0000\n",
      "Batch 80, loss=0.2059, recon=0.2059, kl=98.5764, beta=0.0000\n",
      "Batch 100, loss=0.2389, recon=0.2389, kl=102.2819, beta=0.0000\n",
      "Batch 120, loss=0.1467, recon=0.1467, kl=106.0218, beta=0.0000\n",
      "Batch 140, loss=0.2153, recon=0.2153, kl=109.1194, beta=0.0000\n",
      "Batch 160, loss=0.2097, recon=0.2097, kl=111.1929, beta=0.0000\n",
      "Batch 180, loss=0.1832, recon=0.1832, kl=113.4758, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2255 (Recon: 0.2255, KL: 100.2707, Current Beta: 0.0000) | Avg Valid Loss: 0.1601 | Avg Valid recon Loss: 0.1601\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1069, recon=0.1069, kl=116.0220, beta=0.0000\n",
      "Batch 40, loss=0.1010, recon=0.1010, kl=117.9467, beta=0.0000\n",
      "Batch 60, loss=0.2022, recon=0.2022, kl=119.5070, beta=0.0000\n",
      "Batch 80, loss=0.4511, recon=0.4511, kl=122.6492, beta=0.0000\n",
      "Batch 100, loss=0.1455, recon=0.1455, kl=124.7440, beta=0.0000\n",
      "Batch 120, loss=0.1491, recon=0.1491, kl=127.2886, beta=0.0000\n",
      "Batch 140, loss=0.1605, recon=0.1605, kl=128.4510, beta=0.0000\n",
      "Batch 160, loss=0.1751, recon=0.1751, kl=127.3851, beta=0.0000\n",
      "Batch 180, loss=0.1251, recon=0.1251, kl=131.0302, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1640 (Recon: 0.1640, KL: 123.2843, Current Beta: 0.0000) | Avg Valid Loss: 0.1218 | Avg Valid recon Loss: 0.1218\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1013, recon=0.1013, kl=131.5378, beta=0.0000\n",
      "Batch 40, loss=0.0786, recon=0.0786, kl=131.9785, beta=0.0000\n",
      "Batch 60, loss=0.1333, recon=0.1333, kl=132.9887, beta=0.0000\n",
      "Batch 80, loss=0.0950, recon=0.0950, kl=133.4684, beta=0.0000\n",
      "Batch 100, loss=0.1029, recon=0.1029, kl=134.0566, beta=0.0000\n",
      "Batch 120, loss=0.0648, recon=0.0648, kl=135.1430, beta=0.0000\n",
      "Batch 140, loss=0.0855, recon=0.0855, kl=135.7343, beta=0.0000\n",
      "Batch 160, loss=0.0639, recon=0.0639, kl=136.8042, beta=0.0000\n",
      "Batch 180, loss=0.2439, recon=0.2439, kl=137.8068, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1315 (Recon: 0.1315, KL: 134.0011, Current Beta: 0.0000) | Avg Valid Loss: 0.1021 | Avg Valid recon Loss: 0.1021\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0932, recon=0.0932, kl=138.5222, beta=0.0000\n",
      "Batch 40, loss=0.0856, recon=0.0856, kl=139.1346, beta=0.0000\n",
      "Batch 60, loss=0.0704, recon=0.0704, kl=140.0872, beta=0.0000\n",
      "Batch 80, loss=0.6483, recon=0.6483, kl=141.4634, beta=0.0000\n",
      "Batch 100, loss=0.0706, recon=0.0706, kl=142.7558, beta=0.0000\n",
      "Batch 120, loss=0.0706, recon=0.0706, kl=143.8227, beta=0.0000\n",
      "Batch 140, loss=0.0882, recon=0.0882, kl=144.9473, beta=0.0000\n",
      "Batch 160, loss=0.0689, recon=0.0689, kl=146.2863, beta=0.0000\n",
      "Batch 180, loss=0.0744, recon=0.0744, kl=147.1598, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1118 (Recon: 0.1118, KL: 142.1831, Current Beta: 0.0000) | Avg Valid Loss: 0.0908 | Avg Valid recon Loss: 0.0908\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0884, recon=0.0884, kl=148.4036, beta=0.0000\n",
      "Batch 40, loss=0.1138, recon=0.1138, kl=148.1776, beta=0.0000\n",
      "Batch 60, loss=0.0824, recon=0.0824, kl=148.9010, beta=0.0000\n",
      "Batch 80, loss=0.0999, recon=0.0999, kl=149.8411, beta=0.0000\n",
      "Batch 100, loss=0.0717, recon=0.0717, kl=150.4483, beta=0.0000\n",
      "Batch 120, loss=0.0894, recon=0.0894, kl=150.1097, beta=0.0000\n",
      "Batch 140, loss=0.0577, recon=0.0577, kl=151.1033, beta=0.0000\n",
      "Batch 160, loss=0.1365, recon=0.1365, kl=151.2379, beta=0.0000\n",
      "Batch 180, loss=0.1563, recon=0.1563, kl=151.1989, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0987 (Recon: 0.0987, KL: 149.6614, Current Beta: 0.0000) | Avg Valid Loss: 0.0817 | Avg Valid recon Loss: 0.0816\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1382, recon=0.1382, kl=150.9226, beta=0.0000\n",
      "Batch 40, loss=0.0792, recon=0.0792, kl=150.2768, beta=0.0000\n",
      "Batch 60, loss=0.0676, recon=0.0676, kl=149.9465, beta=0.0000\n",
      "Batch 80, loss=0.0809, recon=0.0809, kl=148.1274, beta=0.0000\n",
      "Batch 100, loss=0.0991, recon=0.0991, kl=149.0800, beta=0.0000\n",
      "Batch 120, loss=0.1690, recon=0.1690, kl=144.5493, beta=0.0000\n",
      "Batch 140, loss=0.0882, recon=0.0882, kl=146.3612, beta=0.0000\n",
      "Batch 160, loss=0.0504, recon=0.0504, kl=145.9017, beta=0.0000\n",
      "Batch 180, loss=0.0729, recon=0.0729, kl=145.6334, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0888 (Recon: 0.0888, KL: 148.4754, Current Beta: 0.0000) | Avg Valid Loss: 0.0746 | Avg Valid recon Loss: 0.0746\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0507, recon=0.0507, kl=142.4977, beta=0.0000\n",
      "Batch 40, loss=0.0920, recon=0.0920, kl=139.0972, beta=0.0000\n",
      "Batch 60, loss=0.0689, recon=0.0689, kl=135.3022, beta=0.0000\n",
      "Batch 80, loss=0.0454, recon=0.0454, kl=130.5313, beta=0.0000\n",
      "Batch 100, loss=0.0638, recon=0.0638, kl=125.0500, beta=0.0000\n",
      "Batch 120, loss=0.0990, recon=0.0990, kl=119.3195, beta=0.0000\n",
      "Batch 140, loss=0.0605, recon=0.0605, kl=118.5599, beta=0.0000\n",
      "Batch 160, loss=0.0584, recon=0.0584, kl=116.8348, beta=0.0000\n",
      "Batch 180, loss=0.0408, recon=0.0408, kl=114.8581, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0822 (Recon: 0.0822, KL: 128.2685, Current Beta: 0.0000) | Avg Valid Loss: 0.0705 | Avg Valid recon Loss: 0.0704\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0730, recon=0.0730, kl=104.7297, beta=0.0000\n",
      "Batch 40, loss=0.0675, recon=0.0675, kl=92.2485, beta=0.0000\n",
      "Batch 60, loss=0.0834, recon=0.0833, kl=80.9131, beta=0.0000\n",
      "Batch 80, loss=0.0748, recon=0.0748, kl=77.2833, beta=0.0000\n",
      "Batch 100, loss=0.1042, recon=0.1042, kl=73.0802, beta=0.0000\n",
      "Batch 120, loss=0.0493, recon=0.0493, kl=72.8918, beta=0.0000\n",
      "Batch 140, loss=0.0672, recon=0.0671, kl=73.9576, beta=0.0000\n",
      "Batch 160, loss=0.0448, recon=0.0448, kl=73.3254, beta=0.0000\n",
      "Batch 180, loss=0.0428, recon=0.0428, kl=70.4338, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0776 (Recon: 0.0776, KL: 82.0750, Current Beta: 0.0000) | Avg Valid Loss: 0.0671 | Avg Valid recon Loss: 0.0671\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0544, recon=0.0544, kl=51.2818, beta=0.0000\n",
      "Batch 40, loss=0.0593, recon=0.0592, kl=46.2144, beta=0.0000\n",
      "Batch 60, loss=0.0477, recon=0.0477, kl=40.6391, beta=0.0000\n",
      "Batch 80, loss=0.0508, recon=0.0507, kl=41.3638, beta=0.0000\n",
      "Batch 100, loss=0.0665, recon=0.0665, kl=41.8609, beta=0.0000\n",
      "Batch 120, loss=0.0592, recon=0.0592, kl=38.0259, beta=0.0000\n",
      "Batch 140, loss=0.0437, recon=0.0437, kl=37.0036, beta=0.0000\n",
      "Batch 160, loss=0.0447, recon=0.0446, kl=35.6123, beta=0.0000\n",
      "Batch 180, loss=0.0495, recon=0.0494, kl=34.8753, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0733 (Recon: 0.0733, KL: 42.6892, Current Beta: 0.0000) | Avg Valid Loss: 0.0642 | Avg Valid recon Loss: 0.0642\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0464, recon=0.0463, kl=21.0953, beta=0.0000\n",
      "Batch 40, loss=0.0650, recon=0.0649, kl=20.2257, beta=0.0000\n",
      "Batch 60, loss=0.0550, recon=0.0550, kl=17.9135, beta=0.0000\n",
      "Batch 80, loss=0.0508, recon=0.0508, kl=17.7225, beta=0.0000\n",
      "Batch 100, loss=0.0596, recon=0.0595, kl=16.6295, beta=0.0000\n",
      "Batch 120, loss=0.0495, recon=0.0495, kl=14.7330, beta=0.0000\n",
      "Batch 140, loss=0.0440, recon=0.0439, kl=14.2134, beta=0.0000\n",
      "Batch 160, loss=0.0389, recon=0.0389, kl=14.0582, beta=0.0000\n",
      "Batch 180, loss=0.0845, recon=0.0844, kl=13.0664, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0701 (Recon: 0.0700, KL: 17.7341, Current Beta: 0.0000) | Avg Valid Loss: 0.0616 | Avg Valid recon Loss: 0.0616\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0379, recon=0.0379, kl=7.1936, beta=0.0000\n",
      "Batch 40, loss=0.0593, recon=0.0593, kl=6.7727, beta=0.0000\n",
      "Batch 60, loss=0.0566, recon=0.0566, kl=8.7127, beta=0.0000\n",
      "Batch 80, loss=0.0496, recon=0.0495, kl=6.4285, beta=0.0000\n",
      "Batch 100, loss=0.0417, recon=0.0417, kl=5.7952, beta=0.0000\n",
      "Batch 120, loss=0.0372, recon=0.0372, kl=5.2456, beta=0.0000\n",
      "Batch 140, loss=0.3554, recon=0.3554, kl=4.9349, beta=0.0000\n",
      "Batch 160, loss=0.0479, recon=0.0479, kl=5.0662, beta=0.0000\n",
      "Batch 180, loss=0.0470, recon=0.0470, kl=4.4575, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0671 (Recon: 0.0671, KL: 6.3863, Current Beta: 0.0000) | Avg Valid Loss: 0.0591 | Avg Valid recon Loss: 0.0591\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0868, recon=0.0868, kl=1.9369, beta=0.0000\n",
      "Batch 40, loss=0.0340, recon=0.0340, kl=2.2225, beta=0.0000\n",
      "Batch 60, loss=0.0549, recon=0.0549, kl=2.4755, beta=0.0000\n",
      "Batch 80, loss=0.0400, recon=0.0400, kl=1.8406, beta=0.0000\n",
      "Batch 100, loss=0.0327, recon=0.0326, kl=2.1755, beta=0.0000\n",
      "Batch 120, loss=0.0449, recon=0.0449, kl=1.8950, beta=0.0000\n",
      "Batch 140, loss=0.0477, recon=0.0476, kl=1.5683, beta=0.0000\n",
      "Batch 160, loss=0.0475, recon=0.0475, kl=1.4909, beta=0.0000\n",
      "Batch 180, loss=0.0641, recon=0.0641, kl=1.4507, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0650 (Recon: 0.0650, KL: 2.0216, Current Beta: 0.0000) | Avg Valid Loss: 0.0572 | Avg Valid recon Loss: 0.0572\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0757, recon=0.0757, kl=0.8669, beta=0.0000\n",
      "Batch 40, loss=0.0370, recon=0.0370, kl=0.7672, beta=0.0000\n",
      "Batch 60, loss=0.0442, recon=0.0442, kl=0.6941, beta=0.0000\n",
      "Batch 80, loss=0.0440, recon=0.0440, kl=0.6598, beta=0.0000\n",
      "Batch 100, loss=0.1591, recon=0.1591, kl=0.6664, beta=0.0000\n",
      "Batch 120, loss=0.0649, recon=0.0649, kl=0.6868, beta=0.0000\n",
      "Batch 140, loss=0.0424, recon=0.0424, kl=0.4837, beta=0.0000\n",
      "Batch 160, loss=0.0278, recon=0.0278, kl=0.5323, beta=0.0000\n",
      "Batch 180, loss=0.0565, recon=0.0565, kl=0.4538, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0628 (Recon: 0.0627, KL: 0.6788, Current Beta: 0.0000) | Avg Valid Loss: 0.0557 | Avg Valid recon Loss: 0.0557\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=0.3301, beta=0.0001\n",
      "Batch 40, loss=0.0648, recon=0.0648, kl=0.3254, beta=0.0001\n",
      "Batch 60, loss=0.0372, recon=0.0372, kl=0.2785, beta=0.0001\n",
      "Batch 80, loss=0.0496, recon=0.0496, kl=0.2617, beta=0.0001\n",
      "Batch 100, loss=0.0613, recon=0.0613, kl=0.2262, beta=0.0001\n",
      "Batch 120, loss=0.0378, recon=0.0378, kl=0.1954, beta=0.0001\n",
      "Batch 140, loss=0.0327, recon=0.0327, kl=0.1516, beta=0.0001\n",
      "Batch 160, loss=0.0357, recon=0.0357, kl=0.1554, beta=0.0001\n",
      "Batch 180, loss=0.0396, recon=0.0396, kl=0.1438, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0608 (Recon: 0.0608, KL: 0.2465, Current Beta: 0.0001) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0537\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0386, recon=0.0386, kl=0.0761, beta=0.0001\n",
      "Batch 40, loss=0.0440, recon=0.0440, kl=0.0725, beta=0.0001\n",
      "Batch 60, loss=0.0486, recon=0.0486, kl=0.0489, beta=0.0001\n",
      "Batch 80, loss=0.0332, recon=0.0332, kl=0.0611, beta=0.0001\n",
      "Batch 100, loss=0.0561, recon=0.0561, kl=0.0424, beta=0.0001\n",
      "Batch 120, loss=0.0413, recon=0.0413, kl=0.0384, beta=0.0001\n",
      "Batch 140, loss=0.0399, recon=0.0399, kl=0.0267, beta=0.0001\n",
      "Batch 160, loss=0.0421, recon=0.0421, kl=0.0229, beta=0.0001\n",
      "Batch 180, loss=0.0368, recon=0.0368, kl=0.0245, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0593 (Recon: 0.0593, KL: 0.0550, Current Beta: 0.0001) | Avg Valid Loss: 0.0523 | Avg Valid recon Loss: 0.0523\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0424, recon=0.0424, kl=0.0210, beta=0.0001\n",
      "Batch 40, loss=0.0482, recon=0.0482, kl=0.0182, beta=0.0001\n",
      "Batch 60, loss=0.0483, recon=0.0483, kl=0.0139, beta=0.0001\n",
      "Batch 80, loss=0.0285, recon=0.0285, kl=0.0164, beta=0.0001\n",
      "Batch 100, loss=0.0449, recon=0.0449, kl=0.0147, beta=0.0001\n",
      "Batch 120, loss=0.0573, recon=0.0573, kl=0.0110, beta=0.0001\n",
      "Batch 140, loss=0.0410, recon=0.0410, kl=0.0100, beta=0.0001\n",
      "Batch 160, loss=0.0615, recon=0.0615, kl=0.0086, beta=0.0001\n",
      "Batch 180, loss=0.0311, recon=0.0311, kl=0.0100, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 0.0155, Current Beta: 0.0001) | Avg Valid Loss: 0.0509 | Avg Valid recon Loss: 0.0509\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0419, recon=0.0419, kl=0.0117, beta=0.0001\n",
      "Batch 40, loss=0.0379, recon=0.0379, kl=0.0084, beta=0.0001\n",
      "Batch 60, loss=0.0381, recon=0.0381, kl=0.0068, beta=0.0001\n",
      "Batch 80, loss=0.0549, recon=0.0549, kl=0.0071, beta=0.0001\n",
      "Batch 100, loss=0.0448, recon=0.0448, kl=0.0067, beta=0.0001\n",
      "Batch 120, loss=0.0352, recon=0.0352, kl=0.0052, beta=0.0001\n",
      "Batch 140, loss=0.0589, recon=0.0589, kl=0.0045, beta=0.0001\n",
      "Batch 160, loss=0.2275, recon=0.2275, kl=0.0093, beta=0.0001\n",
      "Batch 180, loss=0.0436, recon=0.0436, kl=0.0070, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0564 (Recon: 0.0564, KL: 0.0083, Current Beta: 0.0001) | Avg Valid Loss: 0.0498 | Avg Valid recon Loss: 0.0498\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0580, recon=0.0580, kl=0.0079, beta=0.0001\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=0.0052, beta=0.0001\n",
      "Batch 60, loss=0.0490, recon=0.0490, kl=0.0075, beta=0.0001\n",
      "Batch 80, loss=0.0356, recon=0.0356, kl=0.0078, beta=0.0001\n",
      "Batch 100, loss=0.0574, recon=0.0574, kl=0.0063, beta=0.0001\n",
      "Batch 120, loss=0.0548, recon=0.0548, kl=0.0038, beta=0.0001\n",
      "Batch 140, loss=0.0263, recon=0.0263, kl=0.0035, beta=0.0001\n",
      "Batch 160, loss=0.0301, recon=0.0301, kl=0.0032, beta=0.0001\n",
      "Batch 180, loss=0.0556, recon=0.0556, kl=0.0091, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0550 (Recon: 0.0549, KL: 0.0062, Current Beta: 0.0001) | Avg Valid Loss: 0.0486 | Avg Valid recon Loss: 0.0486\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0500, recon=0.0500, kl=0.0042, beta=0.0001\n",
      "Batch 40, loss=0.0397, recon=0.0397, kl=0.0046, beta=0.0001\n",
      "Batch 60, loss=0.0378, recon=0.0378, kl=0.0026, beta=0.0001\n",
      "Batch 80, loss=0.0276, recon=0.0276, kl=0.0030, beta=0.0001\n",
      "Batch 100, loss=0.0293, recon=0.0293, kl=0.0043, beta=0.0001\n",
      "Batch 120, loss=0.0501, recon=0.0501, kl=0.0027, beta=0.0001\n",
      "Batch 140, loss=0.0443, recon=0.0443, kl=0.0039, beta=0.0001\n",
      "Batch 160, loss=0.0354, recon=0.0354, kl=0.0058, beta=0.0001\n",
      "Batch 180, loss=0.0441, recon=0.0441, kl=0.0056, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0539 (Recon: 0.0539, KL: 0.0046, Current Beta: 0.0001) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0474\n",
      "\n",
      "[VRAE Run 6/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4408, recon=0.4408, kl=45.8734, beta=0.0000\n",
      "Batch 40, loss=0.4833, recon=0.4833, kl=87.6052, beta=0.0000\n",
      "Batch 60, loss=0.0993, recon=0.0993, kl=83.9223, beta=0.0000\n",
      "Batch 80, loss=0.1340, recon=0.1340, kl=107.2895, beta=0.0000\n",
      "Batch 100, loss=0.1164, recon=0.1164, kl=106.4463, beta=0.0000\n",
      "Batch 120, loss=0.1116, recon=0.1116, kl=108.0305, beta=0.0000\n",
      "Batch 140, loss=0.0487, recon=0.0487, kl=101.8574, beta=0.0000\n",
      "Batch 160, loss=0.0973, recon=0.0973, kl=119.7469, beta=0.0000\n",
      "Batch 180, loss=0.0525, recon=0.0525, kl=130.5729, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1811 (Recon: 0.1811, KL: 91.6897, Current Beta: 0.0000) | Avg Valid Loss: 0.0741 | Avg Valid recon Loss: 0.0741\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1127, recon=0.1127, kl=116.7065, beta=0.0000\n",
      "Batch 40, loss=0.0659, recon=0.0659, kl=117.4227, beta=0.0000\n",
      "Batch 60, loss=0.0685, recon=0.0685, kl=118.5845, beta=0.0000\n",
      "Batch 80, loss=0.0568, recon=0.0568, kl=104.7566, beta=0.0000\n",
      "Batch 100, loss=0.0445, recon=0.0445, kl=103.6501, beta=0.0000\n",
      "Batch 120, loss=0.0527, recon=0.0527, kl=116.6304, beta=0.0000\n",
      "Batch 140, loss=0.0665, recon=0.0665, kl=116.3051, beta=0.0000\n",
      "Batch 160, loss=0.1436, recon=0.1436, kl=129.5472, beta=0.0000\n",
      "Batch 180, loss=0.0671, recon=0.0671, kl=130.5886, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0766 (Recon: 0.0766, KL: 117.1226, Current Beta: 0.0000) | Avg Valid Loss: 0.0728 | Avg Valid recon Loss: 0.0728\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0918, recon=0.0918, kl=124.6169, beta=0.0000\n",
      "Batch 40, loss=0.0566, recon=0.0566, kl=132.5780, beta=0.0000\n",
      "Batch 60, loss=0.0525, recon=0.0525, kl=136.0103, beta=0.0000\n",
      "Batch 80, loss=0.0635, recon=0.0635, kl=137.6750, beta=0.0000\n",
      "Batch 100, loss=0.0514, recon=0.0514, kl=128.5240, beta=0.0000\n",
      "Batch 120, loss=0.0404, recon=0.0404, kl=131.3077, beta=0.0000\n",
      "Batch 140, loss=0.0620, recon=0.0620, kl=136.3998, beta=0.0000\n",
      "Batch 160, loss=0.0912, recon=0.0912, kl=125.4089, beta=0.0000\n",
      "Batch 180, loss=0.0525, recon=0.0525, kl=132.4087, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0702 (Recon: 0.0702, KL: 131.2592, Current Beta: 0.0000) | Avg Valid Loss: 0.0554 | Avg Valid recon Loss: 0.0554\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0560, recon=0.0560, kl=140.2930, beta=0.0000\n",
      "Batch 40, loss=0.2639, recon=0.2639, kl=138.0176, beta=0.0000\n",
      "Batch 60, loss=0.0422, recon=0.0422, kl=137.4175, beta=0.0000\n",
      "Batch 80, loss=0.0453, recon=0.0453, kl=138.9667, beta=0.0000\n",
      "Batch 100, loss=0.0485, recon=0.0485, kl=140.9292, beta=0.0000\n",
      "Batch 120, loss=0.1007, recon=0.1007, kl=134.5863, beta=0.0000\n",
      "Batch 140, loss=0.0380, recon=0.0380, kl=128.0471, beta=0.0000\n",
      "Batch 160, loss=0.2235, recon=0.2235, kl=129.6593, beta=0.0000\n",
      "Batch 180, loss=0.0666, recon=0.0666, kl=126.5257, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0632 (Recon: 0.0632, KL: 135.8893, Current Beta: 0.0000) | Avg Valid Loss: 0.0520 | Avg Valid recon Loss: 0.0520\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0522, recon=0.0522, kl=127.8883, beta=0.0000\n",
      "Batch 40, loss=0.0474, recon=0.0474, kl=133.5010, beta=0.0000\n",
      "Batch 60, loss=0.0352, recon=0.0352, kl=132.4210, beta=0.0000\n",
      "Batch 80, loss=0.0401, recon=0.0401, kl=130.5680, beta=0.0000\n",
      "Batch 100, loss=0.0613, recon=0.0613, kl=135.1866, beta=0.0000\n",
      "Batch 120, loss=0.0669, recon=0.0669, kl=130.6350, beta=0.0000\n",
      "Batch 140, loss=0.0582, recon=0.0582, kl=120.5309, beta=0.0000\n",
      "Batch 160, loss=0.0892, recon=0.0892, kl=134.2110, beta=0.0000\n",
      "Batch 180, loss=0.0505, recon=0.0505, kl=141.9916, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0618 (Recon: 0.0618, KL: 131.8157, Current Beta: 0.0000) | Avg Valid Loss: 0.0534 | Avg Valid recon Loss: 0.0534\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0379, recon=0.0379, kl=148.1229, beta=0.0000\n",
      "Batch 40, loss=0.0387, recon=0.0387, kl=139.3479, beta=0.0000\n",
      "Batch 60, loss=0.0511, recon=0.0511, kl=137.5666, beta=0.0000\n",
      "Batch 80, loss=0.0614, recon=0.0614, kl=129.1677, beta=0.0000\n",
      "Batch 100, loss=0.0409, recon=0.0409, kl=138.2775, beta=0.0000\n",
      "Batch 120, loss=0.0261, recon=0.0261, kl=151.9294, beta=0.0000\n",
      "Batch 140, loss=0.0494, recon=0.0494, kl=154.3754, beta=0.0000\n",
      "Batch 160, loss=0.0925, recon=0.0925, kl=144.9764, beta=0.0000\n",
      "Batch 180, loss=0.0432, recon=0.0432, kl=130.3437, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0615 (Recon: 0.0615, KL: 142.5219, Current Beta: 0.0000) | Avg Valid Loss: 0.0556 | Avg Valid recon Loss: 0.0555\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=141.5613, beta=0.0000\n",
      "Batch 40, loss=0.0382, recon=0.0382, kl=143.8193, beta=0.0000\n",
      "Batch 60, loss=0.0334, recon=0.0334, kl=138.5639, beta=0.0000\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=135.3922, beta=0.0000\n",
      "Batch 100, loss=0.0829, recon=0.0828, kl=136.9932, beta=0.0000\n",
      "Batch 120, loss=0.0406, recon=0.0406, kl=137.5480, beta=0.0000\n",
      "Batch 140, loss=0.0612, recon=0.0612, kl=136.6013, beta=0.0000\n",
      "Batch 160, loss=0.0638, recon=0.0638, kl=133.5010, beta=0.0000\n",
      "Batch 180, loss=0.0351, recon=0.0351, kl=136.3779, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0570 (Recon: 0.0570, KL: 137.6670, Current Beta: 0.0000) | Avg Valid Loss: 0.0495 | Avg Valid recon Loss: 0.0495\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0388, recon=0.0388, kl=134.0568, beta=0.0000\n",
      "Batch 40, loss=0.0517, recon=0.0517, kl=120.4737, beta=0.0000\n",
      "Batch 60, loss=0.0569, recon=0.0569, kl=114.2693, beta=0.0000\n",
      "Batch 80, loss=0.0419, recon=0.0419, kl=118.6058, beta=0.0000\n",
      "Batch 100, loss=0.0429, recon=0.0429, kl=121.0651, beta=0.0000\n",
      "Batch 120, loss=0.0390, recon=0.0390, kl=116.7939, beta=0.0000\n",
      "Batch 140, loss=0.0550, recon=0.0550, kl=110.6298, beta=0.0000\n",
      "Batch 160, loss=0.0394, recon=0.0394, kl=111.0632, beta=0.0000\n",
      "Batch 180, loss=0.0387, recon=0.0387, kl=117.3535, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0551 (Recon: 0.0550, KL: 119.3838, Current Beta: 0.0000) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=110.6282, beta=0.0000\n",
      "Batch 40, loss=0.0406, recon=0.0406, kl=100.3304, beta=0.0000\n",
      "Batch 60, loss=0.0346, recon=0.0345, kl=96.7280, beta=0.0000\n",
      "Batch 80, loss=0.0373, recon=0.0373, kl=99.7323, beta=0.0000\n",
      "Batch 100, loss=0.0353, recon=0.0353, kl=98.8750, beta=0.0000\n",
      "Batch 120, loss=0.1548, recon=0.1547, kl=98.1115, beta=0.0000\n",
      "Batch 140, loss=0.0438, recon=0.0438, kl=96.9030, beta=0.0000\n",
      "Batch 160, loss=0.0687, recon=0.0687, kl=99.1949, beta=0.0000\n",
      "Batch 180, loss=0.0367, recon=0.0366, kl=101.1627, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0529, KL: 101.0548, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0394, recon=0.0393, kl=86.7286, beta=0.0000\n",
      "Batch 40, loss=0.0336, recon=0.0335, kl=73.8442, beta=0.0000\n",
      "Batch 60, loss=0.0331, recon=0.0330, kl=68.7502, beta=0.0000\n",
      "Batch 80, loss=0.0344, recon=0.0343, kl=78.5649, beta=0.0000\n",
      "Batch 100, loss=0.0296, recon=0.0295, kl=89.6008, beta=0.0000\n",
      "Batch 120, loss=0.0463, recon=0.0462, kl=87.6964, beta=0.0000\n",
      "Batch 140, loss=0.0394, recon=0.0393, kl=77.2199, beta=0.0000\n",
      "Batch 160, loss=0.0752, recon=0.0751, kl=81.4382, beta=0.0000\n",
      "Batch 180, loss=0.0334, recon=0.0333, kl=77.7944, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0513 (Recon: 0.0512, KL: 81.0962, Current Beta: 0.0000) | Avg Valid Loss: 0.0476 | Avg Valid recon Loss: 0.0475\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0291, recon=0.0289, kl=60.9037, beta=0.0000\n",
      "Batch 40, loss=0.0403, recon=0.0401, kl=60.5809, beta=0.0000\n",
      "Batch 60, loss=0.0250, recon=0.0248, kl=57.1692, beta=0.0000\n",
      "Batch 80, loss=0.0383, recon=0.0382, kl=46.7680, beta=0.0000\n",
      "Batch 100, loss=0.0629, recon=0.0628, kl=42.0540, beta=0.0000\n",
      "Batch 120, loss=0.1006, recon=0.1005, kl=50.2166, beta=0.0000\n",
      "Batch 140, loss=0.0374, recon=0.0373, kl=54.3316, beta=0.0000\n",
      "Batch 160, loss=0.0288, recon=0.0286, kl=54.1731, beta=0.0000\n",
      "Batch 180, loss=0.0428, recon=0.0426, kl=48.9395, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0515, KL: 54.3205, Current Beta: 0.0000) | Avg Valid Loss: 0.0419 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0388, recon=0.0386, kl=35.4308, beta=0.0000\n",
      "Batch 40, loss=0.0550, recon=0.0546, kl=48.0936, beta=0.0000\n",
      "Batch 60, loss=0.0356, recon=0.0353, kl=39.7174, beta=0.0000\n",
      "Batch 80, loss=0.0353, recon=0.0351, kl=33.2779, beta=0.0000\n",
      "Batch 100, loss=0.0263, recon=0.0261, kl=28.1103, beta=0.0000\n",
      "Batch 120, loss=0.0510, recon=0.0508, kl=33.1864, beta=0.0000\n",
      "Batch 140, loss=0.0253, recon=0.0251, kl=35.8003, beta=0.0000\n",
      "Batch 160, loss=0.0381, recon=0.0379, kl=30.5960, beta=0.0000\n",
      "Batch 180, loss=0.0609, recon=0.0607, kl=24.1084, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0505, KL: 35.8653, Current Beta: 0.0000) | Avg Valid Loss: 0.0475 | Avg Valid recon Loss: 0.0474\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0287, recon=0.0281, kl=33.7291, beta=0.0000\n",
      "Batch 40, loss=0.0367, recon=0.0356, kl=58.7188, beta=0.0000\n",
      "Batch 60, loss=0.0365, recon=0.0358, kl=37.6346, beta=0.0000\n",
      "Batch 80, loss=0.0309, recon=0.0304, kl=27.5145, beta=0.0000\n",
      "Batch 100, loss=0.0554, recon=0.0550, kl=22.9880, beta=0.0000\n",
      "Batch 120, loss=0.0405, recon=0.0399, kl=30.5852, beta=0.0000\n",
      "Batch 140, loss=0.0723, recon=0.0715, kl=45.0960, beta=0.0000\n",
      "Batch 160, loss=0.0255, recon=0.0248, kl=38.9152, beta=0.0000\n",
      "Batch 180, loss=0.0304, recon=0.0298, kl=32.3312, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0496, KL: 35.6609, Current Beta: 0.0000) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0357, recon=0.0347, kl=26.4524, beta=0.0000\n",
      "Batch 40, loss=0.0370, recon=0.0362, kl=19.6068, beta=0.0000\n",
      "Batch 60, loss=0.0494, recon=0.0488, kl=15.1131, beta=0.0000\n",
      "Batch 80, loss=0.0799, recon=0.0794, kl=12.2794, beta=0.0000\n",
      "Batch 100, loss=0.0303, recon=0.0298, kl=13.0843, beta=0.0000\n",
      "Batch 120, loss=0.0377, recon=0.0372, kl=11.4214, beta=0.0000\n",
      "Batch 140, loss=0.0259, recon=0.0256, kl=8.8547, beta=0.0000\n",
      "Batch 160, loss=0.0376, recon=0.0374, kl=6.2256, beta=0.0000\n",
      "Batch 180, loss=0.0650, recon=0.0645, kl=14.4070, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0493 (Recon: 0.0487, KL: 14.6100, Current Beta: 0.0000) | Avg Valid Loss: 0.0439 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0339, recon=0.0323, kl=25.8978, beta=0.0001\n",
      "Batch 40, loss=0.0916, recon=0.0902, kl=21.6930, beta=0.0001\n",
      "Batch 60, loss=0.5328, recon=0.5317, kl=18.9146, beta=0.0001\n",
      "Batch 80, loss=0.0437, recon=0.0426, kl=16.7061, beta=0.0001\n",
      "Batch 100, loss=0.0429, recon=0.0421, kl=12.2940, beta=0.0001\n",
      "Batch 120, loss=0.0414, recon=0.0406, kl=13.0642, beta=0.0001\n",
      "Batch 140, loss=0.0400, recon=0.0393, kl=10.8853, beta=0.0001\n",
      "Batch 160, loss=0.0449, recon=0.0444, kl=7.5997, beta=0.0001\n",
      "Batch 180, loss=0.0333, recon=0.0328, kl=8.8956, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0498 (Recon: 0.0488, KL: 15.9299, Current Beta: 0.0001) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0262, recon=0.0256, kl=6.1778, beta=0.0001\n",
      "Batch 40, loss=0.0320, recon=0.0315, kl=5.5597, beta=0.0001\n",
      "Batch 60, loss=0.0604, recon=0.0595, kl=8.4900, beta=0.0001\n",
      "Batch 80, loss=0.1532, recon=0.1525, kl=7.1036, beta=0.0001\n",
      "Batch 100, loss=0.0406, recon=0.0401, kl=5.2975, beta=0.0001\n",
      "Batch 120, loss=0.0571, recon=0.0567, kl=4.9142, beta=0.0001\n",
      "Batch 140, loss=0.0372, recon=0.0368, kl=4.3901, beta=0.0001\n",
      "Batch 160, loss=0.0317, recon=0.0313, kl=4.2891, beta=0.0001\n",
      "Batch 180, loss=0.0312, recon=0.0309, kl=3.9058, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0460, KL: 5.8152, Current Beta: 0.0001) | Avg Valid Loss: 0.0360 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0432, recon=0.0428, kl=3.7305, beta=0.0001\n",
      "Batch 40, loss=0.0302, recon=0.0298, kl=3.9560, beta=0.0001\n",
      "Batch 60, loss=0.0343, recon=0.0339, kl=3.6364, beta=0.0001\n",
      "Batch 80, loss=0.0468, recon=0.0464, kl=4.6017, beta=0.0001\n",
      "Batch 100, loss=0.0250, recon=0.0247, kl=3.3989, beta=0.0001\n",
      "Batch 120, loss=0.0325, recon=0.0322, kl=3.0895, beta=0.0001\n",
      "Batch 140, loss=0.0305, recon=0.0296, kl=8.9740, beta=0.0001\n",
      "Batch 160, loss=0.0413, recon=0.0405, kl=7.8414, beta=0.0001\n",
      "Batch 180, loss=0.0276, recon=0.0270, kl=6.2643, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0453 (Recon: 0.0448, KL: 5.0325, Current Beta: 0.0001) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0686, recon=0.0679, kl=6.5447, beta=0.0001\n",
      "Batch 40, loss=0.0391, recon=0.0380, kl=11.4131, beta=0.0001\n",
      "Batch 60, loss=0.0273, recon=0.0262, kl=10.9185, beta=0.0001\n",
      "Batch 80, loss=0.0271, recon=0.0261, kl=9.4684, beta=0.0001\n",
      "Batch 100, loss=0.0322, recon=0.0313, kl=8.3625, beta=0.0001\n",
      "Batch 120, loss=0.0311, recon=0.0304, kl=7.2418, beta=0.0001\n",
      "Batch 140, loss=0.0310, recon=0.0303, kl=7.6000, beta=0.0001\n",
      "Batch 160, loss=0.0597, recon=0.0586, kl=10.6157, beta=0.0001\n",
      "Batch 180, loss=0.0647, recon=0.0637, kl=10.4213, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0473, KL: 9.0312, Current Beta: 0.0001) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0434\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0303, recon=0.0293, kl=9.6363, beta=0.0001\n",
      "Batch 40, loss=0.0538, recon=0.0529, kl=9.1760, beta=0.0001\n",
      "Batch 60, loss=0.0310, recon=0.0301, kl=8.4137, beta=0.0001\n",
      "Batch 80, loss=0.0353, recon=0.0345, kl=8.0323, beta=0.0001\n",
      "Batch 100, loss=0.0737, recon=0.0729, kl=7.4458, beta=0.0001\n",
      "Batch 120, loss=0.0427, recon=0.0420, kl=7.1746, beta=0.0001\n",
      "Batch 140, loss=0.0806, recon=0.0799, kl=6.6781, beta=0.0001\n",
      "Batch 160, loss=0.0347, recon=0.0340, kl=6.9153, beta=0.0001\n",
      "Batch 180, loss=0.0513, recon=0.0506, kl=7.5618, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0537, KL: 8.0806, Current Beta: 0.0001) | Avg Valid Loss: 0.0454 | Avg Valid recon Loss: 0.0446\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0395, recon=0.0388, kl=7.1427, beta=0.0001\n",
      "Batch 40, loss=0.0385, recon=0.0379, kl=6.7510, beta=0.0001\n",
      "Batch 60, loss=0.0464, recon=0.0457, kl=6.5084, beta=0.0001\n",
      "Batch 80, loss=0.0384, recon=0.0378, kl=6.0551, beta=0.0001\n",
      "Batch 100, loss=0.1456, recon=0.1451, kl=5.4739, beta=0.0001\n",
      "Batch 120, loss=1.5603, recon=1.5598, kl=5.4281, beta=0.0001\n",
      "Batch 140, loss=0.0926, recon=0.0908, kl=17.5519, beta=0.0001\n",
      "Batch 160, loss=0.0667, recon=0.0647, kl=20.1563, beta=0.0001\n",
      "Batch 180, loss=0.0623, recon=0.0603, kl=20.2691, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0689 (Recon: 0.0678, KL: 10.1901, Current Beta: 0.0001) | Avg Valid Loss: 0.0582 | Avg Valid recon Loss: 0.0562\n",
      "\n",
      "[VRAE Run 7/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4068, recon=0.4068, kl=0.2375, beta=0.0000\n",
      "Batch 40, loss=0.3694, recon=0.3694, kl=3.1015, beta=0.0000\n",
      "Batch 60, loss=0.3947, recon=0.3947, kl=12.4345, beta=0.0000\n",
      "Batch 80, loss=0.3186, recon=0.3186, kl=18.2374, beta=0.0000\n",
      "Batch 100, loss=0.2724, recon=0.2724, kl=21.4168, beta=0.0000\n",
      "Batch 120, loss=0.1509, recon=0.1509, kl=23.1798, beta=0.0000\n",
      "Batch 140, loss=0.2087, recon=0.2087, kl=24.9095, beta=0.0000\n",
      "Batch 160, loss=0.1806, recon=0.1806, kl=26.9841, beta=0.0000\n",
      "Batch 180, loss=0.1319, recon=0.1319, kl=28.2768, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3024 (Recon: 0.3024, KL: 16.2674, Current Beta: 0.0000) | Avg Valid Loss: 0.1410 | Avg Valid recon Loss: 0.1410\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1645, recon=0.1645, kl=28.3706, beta=0.0000\n",
      "Batch 40, loss=0.1315, recon=0.1315, kl=28.9861, beta=0.0000\n",
      "Batch 60, loss=0.1088, recon=0.1088, kl=29.4645, beta=0.0000\n",
      "Batch 80, loss=0.1302, recon=0.1302, kl=30.3969, beta=0.0000\n",
      "Batch 100, loss=0.1224, recon=0.1224, kl=31.0964, beta=0.0000\n",
      "Batch 120, loss=0.1323, recon=0.1323, kl=31.9591, beta=0.0000\n",
      "Batch 140, loss=0.1071, recon=0.1071, kl=33.8119, beta=0.0000\n",
      "Batch 160, loss=0.2150, recon=0.2150, kl=34.6039, beta=0.0000\n",
      "Batch 180, loss=0.1350, recon=0.1350, kl=35.3799, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1477 (Recon: 0.1477, KL: 31.2820, Current Beta: 0.0000) | Avg Valid Loss: 0.0980 | Avg Valid recon Loss: 0.0980\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0845, recon=0.0845, kl=38.2987, beta=0.0000\n",
      "Batch 40, loss=0.1101, recon=0.1101, kl=40.9491, beta=0.0000\n",
      "Batch 60, loss=0.0883, recon=0.0883, kl=41.5620, beta=0.0000\n",
      "Batch 80, loss=0.0891, recon=0.0891, kl=42.0329, beta=0.0000\n",
      "Batch 100, loss=0.6017, recon=0.6017, kl=43.3424, beta=0.0000\n",
      "Batch 120, loss=0.0568, recon=0.0568, kl=41.9002, beta=0.0000\n",
      "Batch 140, loss=0.0757, recon=0.0757, kl=43.2805, beta=0.0000\n",
      "Batch 160, loss=0.1133, recon=0.1133, kl=43.3824, beta=0.0000\n",
      "Batch 180, loss=0.1194, recon=0.1194, kl=44.7406, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1107 (Recon: 0.1107, KL: 41.6878, Current Beta: 0.0000) | Avg Valid Loss: 0.0803 | Avg Valid recon Loss: 0.0803\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0557, recon=0.0557, kl=46.1236, beta=0.0000\n",
      "Batch 40, loss=0.1099, recon=0.1099, kl=49.2716, beta=0.0000\n",
      "Batch 60, loss=0.0595, recon=0.0595, kl=51.4903, beta=0.0000\n",
      "Batch 80, loss=0.0692, recon=0.0692, kl=51.5890, beta=0.0000\n",
      "Batch 100, loss=0.0745, recon=0.0745, kl=51.4033, beta=0.0000\n",
      "Batch 120, loss=0.0700, recon=0.0700, kl=53.1740, beta=0.0000\n",
      "Batch 140, loss=0.0908, recon=0.0908, kl=57.0736, beta=0.0000\n",
      "Batch 160, loss=0.0573, recon=0.0573, kl=59.6667, beta=0.0000\n",
      "Batch 180, loss=0.0611, recon=0.0611, kl=58.5999, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0906 (Recon: 0.0906, KL: 52.4062, Current Beta: 0.0000) | Avg Valid Loss: 0.0709 | Avg Valid recon Loss: 0.0709\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0631, recon=0.0631, kl=56.7302, beta=0.0000\n",
      "Batch 40, loss=0.0457, recon=0.0457, kl=56.0050, beta=0.0000\n",
      "Batch 60, loss=0.0688, recon=0.0688, kl=55.1105, beta=0.0000\n",
      "Batch 80, loss=0.0493, recon=0.0493, kl=55.3316, beta=0.0000\n",
      "Batch 100, loss=0.0520, recon=0.0520, kl=57.4633, beta=0.0000\n",
      "Batch 120, loss=0.0485, recon=0.0485, kl=57.7992, beta=0.0000\n",
      "Batch 140, loss=0.0402, recon=0.0402, kl=59.2490, beta=0.0000\n",
      "Batch 160, loss=0.0445, recon=0.0445, kl=58.2352, beta=0.0000\n",
      "Batch 180, loss=0.0677, recon=0.0677, kl=55.8946, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0785 (Recon: 0.0785, KL: 57.0456, Current Beta: 0.0000) | Avg Valid Loss: 0.0631 | Avg Valid recon Loss: 0.0631\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0475, recon=0.0475, kl=54.4716, beta=0.0000\n",
      "Batch 40, loss=0.0568, recon=0.0568, kl=54.2825, beta=0.0000\n",
      "Batch 60, loss=0.0564, recon=0.0564, kl=54.8029, beta=0.0000\n",
      "Batch 80, loss=0.0449, recon=0.0449, kl=52.3149, beta=0.0000\n",
      "Batch 100, loss=0.1278, recon=0.1278, kl=50.9286, beta=0.0000\n",
      "Batch 120, loss=0.0530, recon=0.0530, kl=51.2366, beta=0.0000\n",
      "Batch 140, loss=0.0671, recon=0.0671, kl=52.7755, beta=0.0000\n",
      "Batch 160, loss=0.0483, recon=0.0483, kl=56.3294, beta=0.0000\n",
      "Batch 180, loss=0.0471, recon=0.0471, kl=53.7812, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0702 (Recon: 0.0702, KL: 53.6221, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0544, recon=0.0544, kl=51.3700, beta=0.0000\n",
      "Batch 40, loss=0.0770, recon=0.0770, kl=50.0773, beta=0.0000\n",
      "Batch 60, loss=0.0629, recon=0.0629, kl=47.6858, beta=0.0000\n",
      "Batch 80, loss=0.0424, recon=0.0424, kl=48.1144, beta=0.0000\n",
      "Batch 100, loss=0.0299, recon=0.0299, kl=47.5724, beta=0.0000\n",
      "Batch 120, loss=0.0349, recon=0.0349, kl=50.0602, beta=0.0000\n",
      "Batch 140, loss=0.0443, recon=0.0443, kl=49.4673, beta=0.0000\n",
      "Batch 160, loss=0.0492, recon=0.0492, kl=48.4511, beta=0.0000\n",
      "Batch 180, loss=0.0418, recon=0.0418, kl=46.4832, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0650 (Recon: 0.0650, KL: 49.1747, Current Beta: 0.0000) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0559\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0454, recon=0.0454, kl=44.5601, beta=0.0000\n",
      "Batch 40, loss=0.0397, recon=0.0397, kl=44.6555, beta=0.0000\n",
      "Batch 60, loss=0.0744, recon=0.0744, kl=43.4653, beta=0.0000\n",
      "Batch 80, loss=0.0798, recon=0.0797, kl=41.9965, beta=0.0000\n",
      "Batch 100, loss=0.0399, recon=0.0399, kl=40.0147, beta=0.0000\n",
      "Batch 120, loss=0.0285, recon=0.0285, kl=39.9846, beta=0.0000\n",
      "Batch 140, loss=0.0279, recon=0.0278, kl=37.4516, beta=0.0000\n",
      "Batch 160, loss=0.0416, recon=0.0415, kl=35.4618, beta=0.0000\n",
      "Batch 180, loss=0.0284, recon=0.0283, kl=34.7686, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0613 (Recon: 0.0613, KL: 40.9347, Current Beta: 0.0000) | Avg Valid Loss: 0.0530 | Avg Valid recon Loss: 0.0530\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0448, recon=0.0448, kl=33.0686, beta=0.0000\n",
      "Batch 40, loss=0.0552, recon=0.0552, kl=30.0278, beta=0.0000\n",
      "Batch 60, loss=0.0606, recon=0.0606, kl=27.7382, beta=0.0000\n",
      "Batch 80, loss=0.2061, recon=0.2061, kl=26.3451, beta=0.0000\n",
      "Batch 100, loss=0.0569, recon=0.0569, kl=25.9113, beta=0.0000\n",
      "Batch 120, loss=0.0511, recon=0.0511, kl=24.2201, beta=0.0000\n",
      "Batch 140, loss=0.0638, recon=0.0638, kl=26.3938, beta=0.0000\n",
      "Batch 160, loss=0.0313, recon=0.0313, kl=24.4365, beta=0.0000\n",
      "Batch 180, loss=0.0398, recon=0.0398, kl=24.5067, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0580 (Recon: 0.0580, KL: 27.4759, Current Beta: 0.0000) | Avg Valid Loss: 0.0500 | Avg Valid recon Loss: 0.0500\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0413, recon=0.0413, kl=19.9138, beta=0.0000\n",
      "Batch 40, loss=0.0455, recon=0.0455, kl=17.6134, beta=0.0000\n",
      "Batch 60, loss=0.0457, recon=0.0457, kl=16.1030, beta=0.0000\n",
      "Batch 80, loss=0.0489, recon=0.0489, kl=17.5918, beta=0.0000\n",
      "Batch 100, loss=0.0600, recon=0.0600, kl=17.9824, beta=0.0000\n",
      "Batch 120, loss=0.0289, recon=0.0289, kl=15.7242, beta=0.0000\n",
      "Batch 140, loss=0.0439, recon=0.0439, kl=15.8419, beta=0.0000\n",
      "Batch 160, loss=0.0597, recon=0.0596, kl=16.5518, beta=0.0000\n",
      "Batch 180, loss=0.0355, recon=0.0354, kl=16.0474, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0555, KL: 17.4537, Current Beta: 0.0000) | Avg Valid Loss: 0.0482 | Avg Valid recon Loss: 0.0481\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0245, recon=0.0244, kl=10.5883, beta=0.0000\n",
      "Batch 40, loss=0.0328, recon=0.0327, kl=8.2684, beta=0.0000\n",
      "Batch 60, loss=0.0441, recon=0.0441, kl=8.5136, beta=0.0000\n",
      "Batch 80, loss=0.0349, recon=0.0348, kl=8.0374, beta=0.0000\n",
      "Batch 100, loss=0.0425, recon=0.0424, kl=9.0467, beta=0.0000\n",
      "Batch 120, loss=0.0600, recon=0.0600, kl=7.2857, beta=0.0000\n",
      "Batch 140, loss=0.0375, recon=0.0375, kl=7.3665, beta=0.0000\n",
      "Batch 160, loss=0.0343, recon=0.0343, kl=7.2540, beta=0.0000\n",
      "Batch 180, loss=0.0268, recon=0.0268, kl=7.0661, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0532 (Recon: 0.0532, KL: 8.6183, Current Beta: 0.0000) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0471\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0275, recon=0.0275, kl=3.7382, beta=0.0000\n",
      "Batch 40, loss=0.0364, recon=0.0363, kl=3.6055, beta=0.0000\n",
      "Batch 60, loss=0.1097, recon=0.1097, kl=3.7463, beta=0.0000\n",
      "Batch 80, loss=0.0464, recon=0.0464, kl=3.5251, beta=0.0000\n",
      "Batch 100, loss=0.0401, recon=0.0400, kl=3.6878, beta=0.0000\n",
      "Batch 120, loss=0.0358, recon=0.0357, kl=3.4040, beta=0.0000\n",
      "Batch 140, loss=0.0428, recon=0.0428, kl=3.4325, beta=0.0000\n",
      "Batch 160, loss=0.0688, recon=0.0688, kl=2.8269, beta=0.0000\n",
      "Batch 180, loss=0.0685, recon=0.0685, kl=2.3855, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0513 (Recon: 0.0513, KL: 3.5949, Current Beta: 0.0000) | Avg Valid Loss: 0.0451 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0507, recon=0.0507, kl=1.5017, beta=0.0000\n",
      "Batch 40, loss=0.0316, recon=0.0316, kl=1.6602, beta=0.0000\n",
      "Batch 60, loss=0.1745, recon=0.1744, kl=1.4265, beta=0.0000\n",
      "Batch 80, loss=0.0328, recon=0.0328, kl=1.0174, beta=0.0000\n",
      "Batch 100, loss=0.0635, recon=0.0634, kl=1.3185, beta=0.0000\n",
      "Batch 120, loss=0.0291, recon=0.0290, kl=1.0558, beta=0.0000\n",
      "Batch 140, loss=0.0264, recon=0.0264, kl=1.4304, beta=0.0000\n",
      "Batch 160, loss=0.0470, recon=0.0470, kl=1.3820, beta=0.0000\n",
      "Batch 180, loss=0.0250, recon=0.0250, kl=0.6018, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0496, KL: 1.4249, Current Beta: 0.0000) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0274, recon=0.0274, kl=0.6550, beta=0.0000\n",
      "Batch 40, loss=0.0291, recon=0.0291, kl=0.6204, beta=0.0000\n",
      "Batch 60, loss=0.0301, recon=0.0301, kl=0.9532, beta=0.0000\n",
      "Batch 80, loss=0.0386, recon=0.0386, kl=0.4550, beta=0.0000\n",
      "Batch 100, loss=0.0313, recon=0.0312, kl=0.5159, beta=0.0000\n",
      "Batch 120, loss=0.0517, recon=0.0517, kl=0.4748, beta=0.0000\n",
      "Batch 140, loss=0.0365, recon=0.0365, kl=0.4933, beta=0.0000\n",
      "Batch 160, loss=0.0362, recon=0.0362, kl=0.4273, beta=0.0000\n",
      "Batch 180, loss=0.0451, recon=0.0451, kl=0.4043, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0484 (Recon: 0.0484, KL: 0.5682, Current Beta: 0.0000) | Avg Valid Loss: 0.0424 | Avg Valid recon Loss: 0.0424\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0626, recon=0.0626, kl=0.1554, beta=0.0001\n",
      "Batch 40, loss=0.0342, recon=0.0342, kl=0.2368, beta=0.0001\n",
      "Batch 60, loss=0.0279, recon=0.0279, kl=0.1830, beta=0.0001\n",
      "Batch 80, loss=0.0256, recon=0.0256, kl=0.2015, beta=0.0001\n",
      "Batch 100, loss=0.0591, recon=0.0590, kl=0.1142, beta=0.0001\n",
      "Batch 120, loss=0.0342, recon=0.0342, kl=0.1063, beta=0.0001\n",
      "Batch 140, loss=0.0220, recon=0.0220, kl=0.0484, beta=0.0001\n",
      "Batch 160, loss=0.0291, recon=0.0291, kl=0.0823, beta=0.0001\n",
      "Batch 180, loss=0.0372, recon=0.0372, kl=0.0556, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 0.1554, Current Beta: 0.0001) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0396, recon=0.0396, kl=0.0329, beta=0.0001\n",
      "Batch 40, loss=0.0435, recon=0.0435, kl=0.0267, beta=0.0001\n",
      "Batch 60, loss=0.0345, recon=0.0345, kl=0.0252, beta=0.0001\n",
      "Batch 80, loss=0.0240, recon=0.0240, kl=0.0202, beta=0.0001\n",
      "Batch 100, loss=0.0363, recon=0.0363, kl=0.0306, beta=0.0001\n",
      "Batch 120, loss=0.0617, recon=0.0617, kl=0.0157, beta=0.0001\n",
      "Batch 140, loss=0.0350, recon=0.0350, kl=0.0193, beta=0.0001\n",
      "Batch 160, loss=0.0478, recon=0.0478, kl=0.0126, beta=0.0001\n",
      "Batch 180, loss=0.0275, recon=0.0275, kl=0.0121, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0461, KL: 0.0258, Current Beta: 0.0001) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0237, recon=0.0237, kl=0.0231, beta=0.0001\n",
      "Batch 40, loss=0.0252, recon=0.0252, kl=0.0122, beta=0.0001\n",
      "Batch 60, loss=0.0300, recon=0.0300, kl=0.0125, beta=0.0001\n",
      "Batch 80, loss=0.0413, recon=0.0413, kl=0.0080, beta=0.0001\n",
      "Batch 100, loss=0.0327, recon=0.0327, kl=0.0185, beta=0.0001\n",
      "Batch 120, loss=0.0277, recon=0.0277, kl=0.0231, beta=0.0001\n",
      "Batch 140, loss=0.0230, recon=0.0230, kl=0.0213, beta=0.0001\n",
      "Batch 160, loss=0.0249, recon=0.0249, kl=0.0083, beta=0.0001\n",
      "Batch 180, loss=0.0349, recon=0.0349, kl=0.0080, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0451 (Recon: 0.0451, KL: 0.0171, Current Beta: 0.0001) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=0.0196, beta=0.0001\n",
      "Batch 40, loss=0.0335, recon=0.0335, kl=0.0106, beta=0.0001\n",
      "Batch 60, loss=0.0267, recon=0.0267, kl=0.0065, beta=0.0001\n",
      "Batch 80, loss=0.0301, recon=0.0301, kl=0.0077, beta=0.0001\n",
      "Batch 100, loss=0.0486, recon=0.0486, kl=0.0478, beta=0.0001\n",
      "Batch 120, loss=0.1048, recon=0.1048, kl=0.0150, beta=0.0001\n",
      "Batch 140, loss=0.0384, recon=0.0384, kl=0.0077, beta=0.0001\n",
      "Batch 160, loss=0.0392, recon=0.0392, kl=0.0058, beta=0.0001\n",
      "Batch 180, loss=0.0250, recon=0.0250, kl=0.0034, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 0.0130, Current Beta: 0.0001) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=0.0269, beta=0.0001\n",
      "Batch 40, loss=0.0276, recon=0.0276, kl=0.0070, beta=0.0001\n",
      "Batch 60, loss=0.0298, recon=0.0298, kl=0.0073, beta=0.0001\n",
      "Batch 80, loss=0.0209, recon=0.0209, kl=0.0233, beta=0.0001\n",
      "Batch 100, loss=0.0286, recon=0.0286, kl=0.0067, beta=0.0001\n",
      "Batch 120, loss=0.0404, recon=0.0404, kl=0.0068, beta=0.0001\n",
      "Batch 140, loss=0.0564, recon=0.0564, kl=0.0554, beta=0.0001\n",
      "Batch 160, loss=0.0367, recon=0.0367, kl=0.0033, beta=0.0001\n",
      "Batch 180, loss=0.0817, recon=0.0817, kl=0.0069, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0434, KL: 0.0102, Current Beta: 0.0001) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0239, recon=0.0239, kl=0.0056, beta=0.0001\n",
      "Batch 40, loss=0.0291, recon=0.0291, kl=0.0096, beta=0.0001\n",
      "Batch 60, loss=0.0229, recon=0.0229, kl=0.0096, beta=0.0001\n",
      "Batch 80, loss=0.0270, recon=0.0270, kl=0.0115, beta=0.0001\n",
      "Batch 100, loss=0.0258, recon=0.0258, kl=0.0150, beta=0.0001\n",
      "Batch 120, loss=0.0255, recon=0.0255, kl=0.0075, beta=0.0001\n",
      "Batch 140, loss=0.0462, recon=0.0462, kl=0.0065, beta=0.0001\n",
      "Batch 160, loss=0.0312, recon=0.0312, kl=0.0055, beta=0.0001\n",
      "Batch 180, loss=0.0617, recon=0.0617, kl=0.0063, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0427 (Recon: 0.0427, KL: 0.0088, Current Beta: 0.0001) | Avg Valid Loss: 0.0365 | Avg Valid recon Loss: 0.0365\n",
      " New best VRAE model found with validation loss: 0.0365\n",
      "   Model saved to ./ecg_model_logs\\best_vrae_model.pth\n",
      "\n",
      "[VRAE Run 8/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2103, recon=0.2103, kl=27.6230, beta=0.0000\n",
      "Batch 40, loss=0.1183, recon=0.1183, kl=26.2220, beta=0.0000\n",
      "Batch 60, loss=0.0812, recon=0.0812, kl=26.6361, beta=0.0000\n",
      "Batch 80, loss=0.0556, recon=0.0556, kl=25.4569, beta=0.0000\n",
      "Batch 100, loss=0.1256, recon=0.1256, kl=27.8681, beta=0.0000\n",
      "Batch 120, loss=0.0551, recon=0.0551, kl=22.6950, beta=0.0000\n",
      "Batch 140, loss=0.1342, recon=0.1342, kl=30.3263, beta=0.0000\n",
      "Batch 160, loss=0.0586, recon=0.0586, kl=30.5679, beta=0.0000\n",
      "Batch 180, loss=0.0584, recon=0.0584, kl=32.3669, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1321 (Recon: 0.1321, KL: 26.5076, Current Beta: 0.0000) | Avg Valid Loss: 0.0617 | Avg Valid recon Loss: 0.0617\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0518, recon=0.0518, kl=33.1779, beta=0.0000\n",
      "Batch 40, loss=0.0440, recon=0.0440, kl=33.0786, beta=0.0000\n",
      "Batch 60, loss=0.0522, recon=0.0522, kl=34.2661, beta=0.0000\n",
      "Batch 80, loss=0.0415, recon=0.0415, kl=30.7139, beta=0.0000\n",
      "Batch 100, loss=0.0523, recon=0.0523, kl=33.4531, beta=0.0000\n",
      "Batch 120, loss=0.0535, recon=0.0535, kl=24.6076, beta=0.0000\n",
      "Batch 140, loss=0.0331, recon=0.0331, kl=26.9765, beta=0.0000\n",
      "Batch 160, loss=0.0464, recon=0.0464, kl=29.8460, beta=0.0000\n",
      "Batch 180, loss=0.0418, recon=0.0418, kl=32.0726, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0650 (Recon: 0.0650, KL: 30.9878, Current Beta: 0.0000) | Avg Valid Loss: 0.0605 | Avg Valid recon Loss: 0.0605\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0469, recon=0.0469, kl=34.7556, beta=0.0000\n",
      "Batch 40, loss=0.2623, recon=0.2623, kl=34.1460, beta=0.0000\n",
      "Batch 60, loss=0.0578, recon=0.0578, kl=35.6359, beta=0.0000\n",
      "Batch 80, loss=0.0250, recon=0.0250, kl=35.0786, beta=0.0000\n",
      "Batch 100, loss=0.1049, recon=0.1049, kl=35.4585, beta=0.0000\n",
      "Batch 120, loss=0.0334, recon=0.0334, kl=37.2100, beta=0.0000\n",
      "Batch 140, loss=0.0466, recon=0.0466, kl=35.9667, beta=0.0000\n",
      "Batch 160, loss=0.0273, recon=0.0273, kl=32.0420, beta=0.0000\n",
      "Batch 180, loss=0.0508, recon=0.0508, kl=32.0301, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0556 (Recon: 0.0556, KL: 34.6914, Current Beta: 0.0000) | Avg Valid Loss: 0.0526 | Avg Valid recon Loss: 0.0526\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0418, recon=0.0418, kl=31.3711, beta=0.0000\n",
      "Batch 40, loss=0.0541, recon=0.0541, kl=32.4960, beta=0.0000\n",
      "Batch 60, loss=0.0294, recon=0.0294, kl=35.2100, beta=0.0000\n",
      "Batch 80, loss=0.0449, recon=0.0449, kl=36.1501, beta=0.0000\n",
      "Batch 100, loss=0.0305, recon=0.0305, kl=35.5149, beta=0.0000\n",
      "Batch 120, loss=0.0623, recon=0.0623, kl=31.8542, beta=0.0000\n",
      "Batch 140, loss=0.0304, recon=0.0304, kl=33.2022, beta=0.0000\n",
      "Batch 160, loss=0.0263, recon=0.0263, kl=33.7097, beta=0.0000\n",
      "Batch 180, loss=0.0384, recon=0.0384, kl=36.4516, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 33.9451, Current Beta: 0.0000) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0242, recon=0.0242, kl=36.9609, beta=0.0000\n",
      "Batch 40, loss=0.0523, recon=0.0523, kl=37.1894, beta=0.0000\n",
      "Batch 60, loss=0.0276, recon=0.0276, kl=36.3601, beta=0.0000\n",
      "Batch 80, loss=0.0296, recon=0.0296, kl=36.9318, beta=0.0000\n",
      "Batch 100, loss=0.0394, recon=0.0394, kl=36.3451, beta=0.0000\n",
      "Batch 120, loss=0.0399, recon=0.0399, kl=35.1067, beta=0.0000\n",
      "Batch 140, loss=0.0382, recon=0.0382, kl=35.6200, beta=0.0000\n",
      "Batch 160, loss=0.0434, recon=0.0434, kl=32.6889, beta=0.0000\n",
      "Batch 180, loss=0.0325, recon=0.0325, kl=34.0684, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0495, KL: 35.8593, Current Beta: 0.0000) | Avg Valid Loss: 0.0445 | Avg Valid recon Loss: 0.0445\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0229, recon=0.0229, kl=33.3421, beta=0.0000\n",
      "Batch 40, loss=0.0574, recon=0.0574, kl=33.5138, beta=0.0000\n",
      "Batch 60, loss=0.0458, recon=0.0458, kl=35.0419, beta=0.0000\n",
      "Batch 80, loss=0.0339, recon=0.0339, kl=33.7188, beta=0.0000\n",
      "Batch 100, loss=0.0306, recon=0.0306, kl=33.5379, beta=0.0000\n",
      "Batch 120, loss=0.0469, recon=0.0469, kl=34.2362, beta=0.0000\n",
      "Batch 140, loss=0.0446, recon=0.0446, kl=33.8384, beta=0.0000\n",
      "Batch 160, loss=0.0242, recon=0.0242, kl=33.9585, beta=0.0000\n",
      "Batch 180, loss=0.0351, recon=0.0351, kl=35.6719, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0463, KL: 34.0438, Current Beta: 0.0000) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0872, recon=0.0872, kl=37.1723, beta=0.0000\n",
      "Batch 40, loss=0.0250, recon=0.0250, kl=36.6082, beta=0.0000\n",
      "Batch 60, loss=0.0305, recon=0.0305, kl=36.9836, beta=0.0000\n",
      "Batch 80, loss=0.0285, recon=0.0285, kl=35.6942, beta=0.0000\n",
      "Batch 100, loss=0.0277, recon=0.0277, kl=35.8616, beta=0.0000\n",
      "Batch 120, loss=0.0240, recon=0.0240, kl=34.6093, beta=0.0000\n",
      "Batch 140, loss=0.0330, recon=0.0330, kl=33.9843, beta=0.0000\n",
      "Batch 160, loss=0.0357, recon=0.0357, kl=31.5705, beta=0.0000\n",
      "Batch 180, loss=0.1135, recon=0.1135, kl=33.3369, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0429, KL: 35.1216, Current Beta: 0.0000) | Avg Valid Loss: 0.0516 | Avg Valid recon Loss: 0.0516\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0643, recon=0.0643, kl=33.5207, beta=0.0000\n",
      "Batch 40, loss=0.0727, recon=0.0727, kl=32.8637, beta=0.0000\n",
      "Batch 60, loss=0.0556, recon=0.0555, kl=31.0709, beta=0.0000\n",
      "Batch 80, loss=0.0545, recon=0.0545, kl=30.0024, beta=0.0000\n",
      "Batch 100, loss=0.0589, recon=0.0589, kl=29.7168, beta=0.0000\n",
      "Batch 120, loss=0.0354, recon=0.0354, kl=30.1264, beta=0.0000\n",
      "Batch 140, loss=0.0307, recon=0.0307, kl=30.7620, beta=0.0000\n",
      "Batch 160, loss=0.0453, recon=0.0453, kl=31.6641, beta=0.0000\n",
      "Batch 180, loss=0.1582, recon=0.1582, kl=33.1684, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0471 (Recon: 0.0471, KL: 31.4547, Current Beta: 0.0000) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0314, recon=0.0314, kl=32.0496, beta=0.0000\n",
      "Batch 40, loss=0.0319, recon=0.0319, kl=29.7912, beta=0.0000\n",
      "Batch 60, loss=0.0491, recon=0.0491, kl=29.4277, beta=0.0000\n",
      "Batch 80, loss=0.0223, recon=0.0223, kl=28.3868, beta=0.0000\n",
      "Batch 100, loss=0.0278, recon=0.0278, kl=27.4842, beta=0.0000\n",
      "Batch 120, loss=0.0281, recon=0.0281, kl=27.2918, beta=0.0000\n",
      "Batch 140, loss=0.0262, recon=0.0262, kl=28.5224, beta=0.0000\n",
      "Batch 160, loss=0.0436, recon=0.0436, kl=26.9424, beta=0.0000\n",
      "Batch 180, loss=0.0379, recon=0.0379, kl=26.3825, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0461, KL: 28.7708, Current Beta: 0.0000) | Avg Valid Loss: 0.0378 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0312, recon=0.0311, kl=25.5179, beta=0.0000\n",
      "Batch 40, loss=0.1172, recon=0.1171, kl=25.4207, beta=0.0000\n",
      "Batch 60, loss=0.0496, recon=0.0495, kl=24.3793, beta=0.0000\n",
      "Batch 80, loss=0.0418, recon=0.0418, kl=23.8081, beta=0.0000\n",
      "Batch 100, loss=0.0363, recon=0.0362, kl=23.2773, beta=0.0000\n",
      "Batch 120, loss=0.0423, recon=0.0423, kl=21.0764, beta=0.0000\n",
      "Batch 140, loss=0.0257, recon=0.0257, kl=23.8230, beta=0.0000\n",
      "Batch 160, loss=0.0362, recon=0.0362, kl=24.1026, beta=0.0000\n",
      "Batch 180, loss=0.0359, recon=0.0359, kl=22.9371, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0430, KL: 24.0692, Current Beta: 0.0000) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0267, recon=0.0266, kl=20.8930, beta=0.0000\n",
      "Batch 40, loss=0.0352, recon=0.0351, kl=18.3175, beta=0.0000\n",
      "Batch 60, loss=0.0368, recon=0.0368, kl=15.8078, beta=0.0000\n",
      "Batch 80, loss=0.0443, recon=0.0443, kl=18.7195, beta=0.0000\n",
      "Batch 100, loss=0.0423, recon=0.0423, kl=18.2158, beta=0.0000\n",
      "Batch 120, loss=0.0678, recon=0.0677, kl=15.5486, beta=0.0000\n",
      "Batch 140, loss=0.0307, recon=0.0306, kl=16.5589, beta=0.0000\n",
      "Batch 160, loss=0.0310, recon=0.0310, kl=15.2649, beta=0.0000\n",
      "Batch 180, loss=0.0218, recon=0.0218, kl=16.4022, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0419, KL: 17.6294, Current Beta: 0.0000) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0355\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0672, recon=0.0670, kl=14.5176, beta=0.0000\n",
      "Batch 40, loss=0.0554, recon=0.0553, kl=12.3518, beta=0.0000\n",
      "Batch 60, loss=0.0343, recon=0.0342, kl=12.5103, beta=0.0000\n",
      "Batch 80, loss=0.0288, recon=0.0287, kl=10.3909, beta=0.0000\n",
      "Batch 100, loss=0.0285, recon=0.0284, kl=10.4732, beta=0.0000\n",
      "Batch 120, loss=0.0394, recon=0.0393, kl=8.7616, beta=0.0000\n",
      "Batch 140, loss=0.0429, recon=0.0428, kl=10.5450, beta=0.0000\n",
      "Batch 160, loss=0.0302, recon=0.0300, kl=16.1790, beta=0.0000\n",
      "Batch 180, loss=0.0493, recon=0.0492, kl=12.7636, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0432, KL: 12.3525, Current Beta: 0.0000) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0360\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0661, recon=0.0660, kl=7.9177, beta=0.0000\n",
      "Batch 40, loss=0.1392, recon=0.1391, kl=6.6279, beta=0.0000\n",
      "Batch 60, loss=0.0414, recon=0.0413, kl=5.9312, beta=0.0000\n",
      "Batch 80, loss=0.0350, recon=0.0349, kl=6.3683, beta=0.0000\n",
      "Batch 100, loss=0.0368, recon=0.0366, kl=14.7702, beta=0.0000\n",
      "Batch 120, loss=0.0285, recon=0.0282, kl=12.4596, beta=0.0000\n",
      "Batch 140, loss=0.0409, recon=0.0408, kl=9.1475, beta=0.0000\n",
      "Batch 160, loss=0.0345, recon=0.0344, kl=7.6173, beta=0.0000\n",
      "Batch 180, loss=0.0340, recon=0.0338, kl=7.1186, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0441 (Recon: 0.0440, KL: 8.9276, Current Beta: 0.0000) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0366\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0330, recon=0.0328, kl=5.5276, beta=0.0000\n",
      "Batch 40, loss=0.0217, recon=0.0215, kl=3.8758, beta=0.0000\n",
      "Batch 60, loss=0.0458, recon=0.0457, kl=2.8295, beta=0.0000\n",
      "Batch 80, loss=0.1342, recon=0.1341, kl=2.2820, beta=0.0000\n",
      "Batch 100, loss=0.0265, recon=0.0264, kl=2.6663, beta=0.0000\n",
      "Batch 120, loss=0.0481, recon=0.0479, kl=2.8546, beta=0.0000\n",
      "Batch 140, loss=0.0930, recon=0.0929, kl=2.6916, beta=0.0000\n",
      "Batch 160, loss=0.0452, recon=0.0451, kl=2.7988, beta=0.0000\n",
      "Batch 180, loss=0.0295, recon=0.0294, kl=2.5324, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0414, KL: 3.3302, Current Beta: 0.0000) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0809, recon=0.0808, kl=1.4089, beta=0.0001\n",
      "Batch 40, loss=0.0574, recon=0.0573, kl=0.8821, beta=0.0001\n",
      "Batch 60, loss=0.0254, recon=0.0253, kl=1.5537, beta=0.0001\n",
      "Batch 80, loss=0.0393, recon=0.0392, kl=1.6557, beta=0.0001\n",
      "Batch 100, loss=0.0379, recon=0.0378, kl=1.2527, beta=0.0001\n",
      "Batch 120, loss=0.0358, recon=0.0357, kl=0.8631, beta=0.0001\n",
      "Batch 140, loss=0.0355, recon=0.0354, kl=1.1929, beta=0.0001\n",
      "Batch 160, loss=0.0551, recon=0.0550, kl=1.2211, beta=0.0001\n",
      "Batch 180, loss=0.0225, recon=0.0224, kl=0.9985, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0441 (Recon: 0.0440, KL: 1.3187, Current Beta: 0.0001) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0239, recon=0.0238, kl=0.4055, beta=0.0001\n",
      "Batch 40, loss=0.0326, recon=0.0326, kl=0.2077, beta=0.0001\n",
      "Batch 60, loss=0.0377, recon=0.0377, kl=0.2400, beta=0.0001\n",
      "Batch 80, loss=0.0363, recon=0.0363, kl=0.2735, beta=0.0001\n",
      "Batch 100, loss=0.1527, recon=0.1526, kl=0.2876, beta=0.0001\n",
      "Batch 120, loss=0.0382, recon=0.0382, kl=0.2181, beta=0.0001\n",
      "Batch 140, loss=0.0563, recon=0.0563, kl=0.1576, beta=0.0001\n",
      "Batch 160, loss=0.0351, recon=0.0350, kl=0.3178, beta=0.0001\n",
      "Batch 180, loss=0.0308, recon=0.0307, kl=0.4940, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0398 (Recon: 0.0398, KL: 0.3201, Current Beta: 0.0001) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0200, recon=0.0200, kl=0.2312, beta=0.0001\n",
      "Batch 40, loss=0.0251, recon=0.0251, kl=0.1309, beta=0.0001\n",
      "Batch 60, loss=0.0261, recon=0.0261, kl=0.1981, beta=0.0001\n",
      "Batch 80, loss=0.0304, recon=0.0304, kl=0.1953, beta=0.0001\n",
      "Batch 100, loss=0.0377, recon=0.0377, kl=0.1590, beta=0.0001\n",
      "Batch 120, loss=0.0216, recon=0.0215, kl=0.4576, beta=0.0001\n",
      "Batch 140, loss=0.0316, recon=0.0315, kl=0.5932, beta=0.0001\n",
      "Batch 160, loss=0.0227, recon=0.0227, kl=0.5234, beta=0.0001\n",
      "Batch 180, loss=0.0354, recon=0.0354, kl=0.2766, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0388, KL: 0.3215, Current Beta: 0.0001) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0334\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0199, recon=0.0199, kl=0.1222, beta=0.0001\n",
      "Batch 40, loss=0.0356, recon=0.0355, kl=0.1215, beta=0.0001\n",
      "Batch 60, loss=0.0399, recon=0.0399, kl=0.5114, beta=0.0001\n",
      "Batch 80, loss=0.0299, recon=0.0298, kl=0.5565, beta=0.0001\n",
      "Batch 100, loss=0.0340, recon=0.0340, kl=0.4190, beta=0.0001\n",
      "Batch 120, loss=0.0289, recon=0.0289, kl=0.2911, beta=0.0001\n",
      "Batch 140, loss=0.0347, recon=0.0347, kl=0.2030, beta=0.0001\n",
      "Batch 160, loss=0.1574, recon=0.1573, kl=0.2212, beta=0.0001\n",
      "Batch 180, loss=0.0268, recon=0.0268, kl=0.2741, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0383 (Recon: 0.0382, KL: 0.3034, Current Beta: 0.0001) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1426, recon=0.1426, kl=0.2755, beta=0.0001\n",
      "Batch 40, loss=0.0381, recon=0.0381, kl=0.2019, beta=0.0001\n",
      "Batch 60, loss=0.0332, recon=0.0331, kl=0.1990, beta=0.0001\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=0.1979, beta=0.0001\n",
      "Batch 100, loss=0.0409, recon=0.0409, kl=0.2430, beta=0.0001\n",
      "Batch 120, loss=0.0284, recon=0.0284, kl=0.2273, beta=0.0001\n",
      "Batch 140, loss=0.0513, recon=0.0513, kl=0.1683, beta=0.0001\n",
      "Batch 160, loss=0.0327, recon=0.0327, kl=0.1506, beta=0.0001\n",
      "Batch 180, loss=0.0206, recon=0.0206, kl=0.1379, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0393 (Recon: 0.0393, KL: 0.2095, Current Beta: 0.0001) | Avg Valid Loss: 0.0323 | Avg Valid recon Loss: 0.0323\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0271, recon=0.0271, kl=0.1071, beta=0.0001\n",
      "Batch 40, loss=0.0319, recon=0.0318, kl=0.1486, beta=0.0001\n",
      "Batch 60, loss=0.0537, recon=0.0537, kl=0.2371, beta=0.0001\n",
      "Batch 80, loss=0.0400, recon=0.0399, kl=0.2104, beta=0.0001\n",
      "Batch 100, loss=0.0314, recon=0.0314, kl=0.2774, beta=0.0001\n",
      "Batch 120, loss=0.0294, recon=0.0294, kl=0.2259, beta=0.0001\n",
      "Batch 140, loss=0.0260, recon=0.0260, kl=0.1824, beta=0.0001\n",
      "Batch 160, loss=0.0364, recon=0.0364, kl=0.1805, beta=0.0001\n",
      "Batch 180, loss=0.0235, recon=0.0235, kl=0.1857, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0393 (Recon: 0.0392, KL: 0.1917, Current Beta: 0.0001) | Avg Valid Loss: 0.0344 | Avg Valid recon Loss: 0.0344\n",
      " New best VRAE model found with validation loss: 0.0344\n",
      "   Model saved to ./ecg_model_logs\\best_vrae_model.pth\n",
      "\n",
      "[VRAE Run 9/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3630, recon=0.3630, kl=0.3494, beta=0.0000\n",
      "Batch 40, loss=0.3978, recon=0.3978, kl=1.9083, beta=0.0000\n",
      "Batch 60, loss=0.1958, recon=0.1958, kl=22.8413, beta=0.0000\n",
      "Batch 80, loss=0.1491, recon=0.1491, kl=35.1029, beta=0.0000\n",
      "Batch 100, loss=0.1291, recon=0.1291, kl=42.1390, beta=0.0000\n",
      "Batch 120, loss=0.1880, recon=0.1880, kl=47.3407, beta=0.0000\n",
      "Batch 140, loss=0.2219, recon=0.2219, kl=53.4046, beta=0.0000\n",
      "Batch 160, loss=0.1533, recon=0.1533, kl=56.0057, beta=0.0000\n",
      "Batch 180, loss=0.1323, recon=0.1323, kl=59.3304, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2938 (Recon: 0.2938, KL: 32.5377, Current Beta: 0.0000) | Avg Valid Loss: 0.1342 | Avg Valid recon Loss: 0.1342\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1119, recon=0.1119, kl=61.8064, beta=0.0000\n",
      "Batch 40, loss=0.1535, recon=0.1535, kl=63.1560, beta=0.0000\n",
      "Batch 60, loss=0.0987, recon=0.0987, kl=65.7072, beta=0.0000\n",
      "Batch 80, loss=0.1310, recon=0.1310, kl=68.0305, beta=0.0000\n",
      "Batch 100, loss=0.1098, recon=0.1098, kl=69.5689, beta=0.0000\n",
      "Batch 120, loss=0.1165, recon=0.1165, kl=73.9426, beta=0.0000\n",
      "Batch 140, loss=0.1269, recon=0.1269, kl=75.6052, beta=0.0000\n",
      "Batch 160, loss=0.1250, recon=0.1250, kl=77.5614, beta=0.0000\n",
      "Batch 180, loss=0.0619, recon=0.0619, kl=79.1912, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1424 (Recon: 0.1424, KL: 69.5115, Current Beta: 0.0000) | Avg Valid Loss: 0.0954 | Avg Valid recon Loss: 0.0954\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0889, recon=0.0889, kl=79.9600, beta=0.0000\n",
      "Batch 40, loss=0.2026, recon=0.2026, kl=79.0074, beta=0.0000\n",
      "Batch 60, loss=0.1013, recon=0.1013, kl=80.8710, beta=0.0000\n",
      "Batch 80, loss=0.0996, recon=0.0996, kl=84.0607, beta=0.0000\n",
      "Batch 100, loss=0.0911, recon=0.0911, kl=86.4473, beta=0.0000\n",
      "Batch 120, loss=0.0590, recon=0.0590, kl=87.4070, beta=0.0000\n",
      "Batch 140, loss=0.0882, recon=0.0882, kl=89.4133, beta=0.0000\n",
      "Batch 160, loss=0.0907, recon=0.0907, kl=88.3956, beta=0.0000\n",
      "Batch 180, loss=0.1373, recon=0.1373, kl=88.1182, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1086 (Recon: 0.1086, KL: 84.4442, Current Beta: 0.0000) | Avg Valid Loss: 0.0786 | Avg Valid recon Loss: 0.0786\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0668, recon=0.0668, kl=90.1639, beta=0.0000\n",
      "Batch 40, loss=0.0808, recon=0.0808, kl=91.9652, beta=0.0000\n",
      "Batch 60, loss=0.0605, recon=0.0605, kl=94.3493, beta=0.0000\n",
      "Batch 80, loss=0.0697, recon=0.0697, kl=93.8266, beta=0.0000\n",
      "Batch 100, loss=0.0640, recon=0.0640, kl=94.1721, beta=0.0000\n",
      "Batch 120, loss=0.0525, recon=0.0525, kl=94.8352, beta=0.0000\n",
      "Batch 140, loss=0.0858, recon=0.0858, kl=96.3107, beta=0.0000\n",
      "Batch 160, loss=1.5052, recon=1.5052, kl=95.9845, beta=0.0000\n",
      "Batch 180, loss=0.0439, recon=0.0439, kl=97.7021, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0899 (Recon: 0.0899, KL: 93.9180, Current Beta: 0.0000) | Avg Valid Loss: 0.0700 | Avg Valid recon Loss: 0.0700\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0508, recon=0.0508, kl=98.2473, beta=0.0000\n",
      "Batch 40, loss=0.1086, recon=0.1086, kl=98.1279, beta=0.0000\n",
      "Batch 60, loss=0.0643, recon=0.0643, kl=100.5176, beta=0.0000\n",
      "Batch 80, loss=0.0513, recon=0.0513, kl=99.6727, beta=0.0000\n",
      "Batch 100, loss=0.0637, recon=0.0637, kl=99.4176, beta=0.0000\n",
      "Batch 120, loss=1.3997, recon=1.3997, kl=98.9614, beta=0.0000\n",
      "Batch 140, loss=0.0864, recon=0.0864, kl=99.9337, beta=0.0000\n",
      "Batch 160, loss=0.0855, recon=0.0855, kl=102.2622, beta=0.0000\n",
      "Batch 180, loss=0.0448, recon=0.0448, kl=104.6140, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0785 (Recon: 0.0785, KL: 99.8421, Current Beta: 0.0000) | Avg Valid Loss: 0.0633 | Avg Valid recon Loss: 0.0633\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.4077, recon=0.4077, kl=102.9168, beta=0.0000\n",
      "Batch 40, loss=0.1549, recon=0.1549, kl=102.9847, beta=0.0000\n",
      "Batch 60, loss=0.0724, recon=0.0724, kl=103.5847, beta=0.0000\n",
      "Batch 80, loss=0.0476, recon=0.0476, kl=103.5050, beta=0.0000\n",
      "Batch 100, loss=0.0859, recon=0.0859, kl=103.6194, beta=0.0000\n",
      "Batch 120, loss=0.0414, recon=0.0414, kl=102.1805, beta=0.0000\n",
      "Batch 140, loss=0.0538, recon=0.0538, kl=101.8104, beta=0.0000\n",
      "Batch 160, loss=0.0532, recon=0.0532, kl=102.8153, beta=0.0000\n",
      "Batch 180, loss=0.0756, recon=0.0756, kl=100.7907, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0702 (Recon: 0.0702, KL: 102.9026, Current Beta: 0.0000) | Avg Valid Loss: 0.0580 | Avg Valid recon Loss: 0.0580\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0400, recon=0.0400, kl=100.1243, beta=0.0000\n",
      "Batch 40, loss=0.0998, recon=0.0998, kl=96.0073, beta=0.0000\n",
      "Batch 60, loss=0.0594, recon=0.0594, kl=95.3972, beta=0.0000\n",
      "Batch 80, loss=0.0568, recon=0.0568, kl=95.1177, beta=0.0000\n",
      "Batch 100, loss=0.0705, recon=0.0705, kl=92.4458, beta=0.0000\n",
      "Batch 120, loss=0.0340, recon=0.0340, kl=92.4473, beta=0.0000\n",
      "Batch 140, loss=0.0705, recon=0.0705, kl=90.3996, beta=0.0000\n",
      "Batch 160, loss=0.0382, recon=0.0382, kl=89.5381, beta=0.0000\n",
      "Batch 180, loss=0.0340, recon=0.0340, kl=88.7318, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0649 (Recon: 0.0649, KL: 94.0509, Current Beta: 0.0000) | Avg Valid Loss: 0.0547 | Avg Valid recon Loss: 0.0547\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1073, recon=0.1073, kl=85.4172, beta=0.0000\n",
      "Batch 40, loss=0.0522, recon=0.0522, kl=78.9295, beta=0.0000\n",
      "Batch 60, loss=0.0514, recon=0.0514, kl=77.5338, beta=0.0000\n",
      "Batch 80, loss=0.0375, recon=0.0375, kl=73.8915, beta=0.0000\n",
      "Batch 100, loss=0.0521, recon=0.0521, kl=70.8789, beta=0.0000\n",
      "Batch 120, loss=0.0439, recon=0.0439, kl=69.1692, beta=0.0000\n",
      "Batch 140, loss=0.0507, recon=0.0507, kl=67.7928, beta=0.0000\n",
      "Batch 160, loss=0.0493, recon=0.0493, kl=68.0499, beta=0.0000\n",
      "Batch 180, loss=0.0439, recon=0.0439, kl=68.1127, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0603 (Recon: 0.0603, KL: 74.3483, Current Beta: 0.0000) | Avg Valid Loss: 0.0517 | Avg Valid recon Loss: 0.0517\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0352, recon=0.0351, kl=64.2261, beta=0.0000\n",
      "Batch 40, loss=0.0599, recon=0.0599, kl=59.2352, beta=0.0000\n",
      "Batch 60, loss=0.0470, recon=0.0469, kl=54.7738, beta=0.0000\n",
      "Batch 80, loss=0.0564, recon=0.0563, kl=50.6540, beta=0.0000\n",
      "Batch 100, loss=0.0779, recon=0.0779, kl=48.4994, beta=0.0000\n",
      "Batch 120, loss=0.0339, recon=0.0339, kl=50.0674, beta=0.0000\n",
      "Batch 140, loss=0.0443, recon=0.0443, kl=47.7010, beta=0.0000\n",
      "Batch 160, loss=0.0515, recon=0.0515, kl=46.7110, beta=0.0000\n",
      "Batch 180, loss=0.0550, recon=0.0550, kl=45.0749, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0571 (Recon: 0.0571, KL: 53.0343, Current Beta: 0.0000) | Avg Valid Loss: 0.0497 | Avg Valid recon Loss: 0.0497\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0883, recon=0.0883, kl=39.7159, beta=0.0000\n",
      "Batch 40, loss=0.0329, recon=0.0329, kl=32.4914, beta=0.0000\n",
      "Batch 60, loss=0.0397, recon=0.0397, kl=31.2929, beta=0.0000\n",
      "Batch 80, loss=0.0235, recon=0.0234, kl=29.3968, beta=0.0000\n",
      "Batch 100, loss=0.0366, recon=0.0365, kl=29.7155, beta=0.0000\n",
      "Batch 120, loss=0.0381, recon=0.0381, kl=28.9050, beta=0.0000\n",
      "Batch 140, loss=0.1453, recon=0.1453, kl=27.8522, beta=0.0000\n",
      "Batch 160, loss=0.2478, recon=0.2478, kl=27.6757, beta=0.0000\n",
      "Batch 180, loss=0.0335, recon=0.0335, kl=28.2860, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0546 (Recon: 0.0546, KL: 31.6064, Current Beta: 0.0000) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0480\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0286, recon=0.0285, kl=20.5380, beta=0.0000\n",
      "Batch 40, loss=0.0344, recon=0.0344, kl=16.7524, beta=0.0000\n",
      "Batch 60, loss=0.0372, recon=0.0372, kl=16.7594, beta=0.0000\n",
      "Batch 80, loss=0.0445, recon=0.0445, kl=16.0869, beta=0.0000\n",
      "Batch 100, loss=0.9267, recon=0.9267, kl=15.7797, beta=0.0000\n",
      "Batch 120, loss=0.0700, recon=0.0700, kl=15.7708, beta=0.0000\n",
      "Batch 140, loss=0.0362, recon=0.0362, kl=14.0607, beta=0.0000\n",
      "Batch 160, loss=0.0330, recon=0.0330, kl=14.8770, beta=0.0000\n",
      "Batch 180, loss=0.0562, recon=0.0561, kl=14.7304, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0523, KL: 16.9189, Current Beta: 0.0000) | Avg Valid Loss: 0.0457 | Avg Valid recon Loss: 0.0456\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0394, recon=0.0393, kl=9.2292, beta=0.0000\n",
      "Batch 40, loss=0.0363, recon=0.0363, kl=7.8295, beta=0.0000\n",
      "Batch 60, loss=0.0350, recon=0.0350, kl=6.5646, beta=0.0000\n",
      "Batch 80, loss=0.0510, recon=0.0510, kl=6.6380, beta=0.0000\n",
      "Batch 100, loss=0.0503, recon=0.0503, kl=6.9300, beta=0.0000\n",
      "Batch 120, loss=0.0559, recon=0.0559, kl=6.1846, beta=0.0000\n",
      "Batch 140, loss=0.0275, recon=0.0275, kl=5.8673, beta=0.0000\n",
      "Batch 160, loss=0.0399, recon=0.0398, kl=5.5468, beta=0.0000\n",
      "Batch 180, loss=0.0308, recon=0.0307, kl=5.1274, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0506 (Recon: 0.0505, KL: 7.0842, Current Beta: 0.0000) | Avg Valid Loss: 0.0442 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0283, recon=0.0283, kl=2.6530, beta=0.0000\n",
      "Batch 40, loss=0.0224, recon=0.0223, kl=2.8022, beta=0.0000\n",
      "Batch 60, loss=0.0346, recon=0.0346, kl=2.5392, beta=0.0000\n",
      "Batch 80, loss=0.0350, recon=0.0350, kl=2.3619, beta=0.0000\n",
      "Batch 100, loss=0.0287, recon=0.0287, kl=2.7620, beta=0.0000\n",
      "Batch 120, loss=0.0358, recon=0.0357, kl=2.4857, beta=0.0000\n",
      "Batch 140, loss=0.0423, recon=0.0422, kl=1.9204, beta=0.0000\n",
      "Batch 160, loss=0.0531, recon=0.0530, kl=2.1683, beta=0.0000\n",
      "Batch 180, loss=0.0288, recon=0.0288, kl=1.8544, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0491 (Recon: 0.0491, KL: 2.5583, Current Beta: 0.0000) | Avg Valid Loss: 0.0428 | Avg Valid recon Loss: 0.0428\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=0.8871, beta=0.0000\n",
      "Batch 40, loss=0.0255, recon=0.0255, kl=1.2179, beta=0.0000\n",
      "Batch 60, loss=0.0295, recon=0.0294, kl=0.8369, beta=0.0000\n",
      "Batch 80, loss=0.0263, recon=0.0263, kl=0.9368, beta=0.0000\n",
      "Batch 100, loss=0.0388, recon=0.0387, kl=0.9583, beta=0.0000\n",
      "Batch 120, loss=0.0414, recon=0.0414, kl=0.7581, beta=0.0000\n",
      "Batch 140, loss=0.0775, recon=0.0775, kl=0.9080, beta=0.0000\n",
      "Batch 160, loss=0.0580, recon=0.0580, kl=0.7171, beta=0.0000\n",
      "Batch 180, loss=0.0328, recon=0.0328, kl=1.0655, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0479, KL: 0.9647, Current Beta: 0.0000) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1392, recon=0.1392, kl=0.3001, beta=0.0001\n",
      "Batch 40, loss=0.1146, recon=0.1146, kl=0.4362, beta=0.0001\n",
      "Batch 60, loss=0.0324, recon=0.0323, kl=0.4848, beta=0.0001\n",
      "Batch 80, loss=0.0437, recon=0.0437, kl=0.3236, beta=0.0001\n",
      "Batch 100, loss=0.0270, recon=0.0270, kl=0.2593, beta=0.0001\n",
      "Batch 120, loss=0.0238, recon=0.0238, kl=0.3394, beta=0.0001\n",
      "Batch 140, loss=0.0860, recon=0.0860, kl=0.2436, beta=0.0001\n",
      "Batch 160, loss=0.0269, recon=0.0269, kl=0.2052, beta=0.0001\n",
      "Batch 180, loss=0.0276, recon=0.0275, kl=0.1839, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0468 (Recon: 0.0467, KL: 0.3484, Current Beta: 0.0001) | Avg Valid Loss: 0.0409 | Avg Valid recon Loss: 0.0409\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0531, recon=0.0531, kl=0.1094, beta=0.0001\n",
      "Batch 40, loss=0.0268, recon=0.0268, kl=0.0480, beta=0.0001\n",
      "Batch 60, loss=0.0258, recon=0.0258, kl=0.1247, beta=0.0001\n",
      "Batch 80, loss=0.0292, recon=0.0292, kl=0.0577, beta=0.0001\n",
      "Batch 100, loss=0.0362, recon=0.0362, kl=0.0810, beta=0.0001\n",
      "Batch 120, loss=0.0417, recon=0.0417, kl=0.0517, beta=0.0001\n",
      "Batch 140, loss=0.0304, recon=0.0304, kl=0.0661, beta=0.0001\n",
      "Batch 160, loss=0.0287, recon=0.0287, kl=0.0389, beta=0.0001\n",
      "Batch 180, loss=0.0345, recon=0.0345, kl=0.0525, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 0.0757, Current Beta: 0.0001) | Avg Valid Loss: 0.0404 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0275, recon=0.0275, kl=0.0308, beta=0.0001\n",
      "Batch 40, loss=0.0214, recon=0.0214, kl=0.0305, beta=0.0001\n",
      "Batch 60, loss=0.0256, recon=0.0256, kl=0.0284, beta=0.0001\n",
      "Batch 80, loss=0.1603, recon=0.1603, kl=0.0445, beta=0.0001\n",
      "Batch 100, loss=0.0319, recon=0.0319, kl=0.0230, beta=0.0001\n",
      "Batch 120, loss=0.0262, recon=0.0262, kl=0.0271, beta=0.0001\n",
      "Batch 140, loss=0.0584, recon=0.0584, kl=0.0190, beta=0.0001\n",
      "Batch 160, loss=0.0271, recon=0.0271, kl=0.0232, beta=0.0001\n",
      "Batch 180, loss=0.0437, recon=0.0437, kl=0.1751, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0445 (Recon: 0.0445, KL: 0.0299, Current Beta: 0.0001) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0277, recon=0.0277, kl=0.0194, beta=0.0001\n",
      "Batch 40, loss=0.0294, recon=0.0294, kl=0.0199, beta=0.0001\n",
      "Batch 60, loss=0.0466, recon=0.0466, kl=0.0529, beta=0.0001\n",
      "Batch 80, loss=0.0451, recon=0.0451, kl=0.0383, beta=0.0001\n",
      "Batch 100, loss=0.0292, recon=0.0292, kl=0.1014, beta=0.0001\n",
      "Batch 120, loss=0.0412, recon=0.0412, kl=0.0186, beta=0.0001\n",
      "Batch 140, loss=0.0369, recon=0.0369, kl=0.0185, beta=0.0001\n",
      "Batch 160, loss=0.0426, recon=0.0426, kl=0.0134, beta=0.0001\n",
      "Batch 180, loss=0.0293, recon=0.0293, kl=0.0128, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 0.0230, Current Beta: 0.0001) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0317, recon=0.0317, kl=0.0137, beta=0.0001\n",
      "Batch 40, loss=0.0234, recon=0.0234, kl=0.0097, beta=0.0001\n",
      "Batch 60, loss=0.0259, recon=0.0259, kl=0.0144, beta=0.0001\n",
      "Batch 80, loss=0.0266, recon=0.0266, kl=0.0135, beta=0.0001\n",
      "Batch 100, loss=0.0569, recon=0.0569, kl=0.0125, beta=0.0001\n",
      "Batch 120, loss=0.0294, recon=0.0294, kl=0.0235, beta=0.0001\n",
      "Batch 140, loss=0.0280, recon=0.0280, kl=0.0122, beta=0.0001\n",
      "Batch 160, loss=0.0231, recon=0.0231, kl=0.0105, beta=0.0001\n",
      "Batch 180, loss=0.0265, recon=0.0265, kl=0.0155, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0430, KL: 0.0127, Current Beta: 0.0001) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0651, recon=0.0651, kl=0.0104, beta=0.0001\n",
      "Batch 40, loss=0.0344, recon=0.0344, kl=0.0364, beta=0.0001\n",
      "Batch 60, loss=0.0287, recon=0.0287, kl=0.0129, beta=0.0001\n",
      "Batch 80, loss=0.0553, recon=0.0553, kl=0.0145, beta=0.0001\n",
      "Batch 100, loss=0.0295, recon=0.0295, kl=0.0066, beta=0.0001\n",
      "Batch 120, loss=0.0245, recon=0.0245, kl=0.0094, beta=0.0001\n",
      "Batch 140, loss=0.0197, recon=0.0197, kl=0.0220, beta=0.0001\n",
      "Batch 160, loss=0.0305, recon=0.0305, kl=0.0105, beta=0.0001\n",
      "Batch 180, loss=0.0218, recon=0.0218, kl=0.0087, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 0.0148, Current Beta: 0.0001) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "\n",
      "[VRAE Run 10/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2570, recon=0.2570, kl=45.2064, beta=0.0000\n",
      "Batch 40, loss=0.1217, recon=0.1217, kl=47.8361, beta=0.0000\n",
      "Batch 60, loss=0.0786, recon=0.0786, kl=57.0932, beta=0.0000\n",
      "Batch 80, loss=0.0962, recon=0.0962, kl=53.2326, beta=0.0000\n",
      "Batch 100, loss=0.0971, recon=0.0971, kl=58.7509, beta=0.0000\n",
      "Batch 120, loss=0.0696, recon=0.0696, kl=60.8337, beta=0.0000\n",
      "Batch 140, loss=0.0558, recon=0.0558, kl=53.2883, beta=0.0000\n",
      "Batch 160, loss=0.0488, recon=0.0488, kl=56.2144, beta=0.0000\n",
      "Batch 180, loss=0.0452, recon=0.0452, kl=60.4281, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1327 (Recon: 0.1327, KL: 51.1964, Current Beta: 0.0000) | Avg Valid Loss: 0.0605 | Avg Valid recon Loss: 0.0605\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0392, recon=0.0392, kl=47.9397, beta=0.0000\n",
      "Batch 40, loss=0.3280, recon=0.3280, kl=48.4566, beta=0.0000\n",
      "Batch 60, loss=0.0513, recon=0.0513, kl=53.6025, beta=0.0000\n",
      "Batch 80, loss=0.0409, recon=0.0409, kl=57.2979, beta=0.0000\n",
      "Batch 100, loss=0.0479, recon=0.0479, kl=56.1389, beta=0.0000\n",
      "Batch 120, loss=0.0431, recon=0.0431, kl=61.7656, beta=0.0000\n",
      "Batch 140, loss=0.0311, recon=0.0311, kl=58.2440, beta=0.0000\n",
      "Batch 160, loss=0.0626, recon=0.0626, kl=82.4497, beta=0.0000\n",
      "Batch 180, loss=0.0657, recon=0.0657, kl=73.8368, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0645 (Recon: 0.0645, KL: 60.2173, Current Beta: 0.0000) | Avg Valid Loss: 0.0586 | Avg Valid recon Loss: 0.0586\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0393, recon=0.0393, kl=66.1607, beta=0.0000\n",
      "Batch 40, loss=0.0406, recon=0.0406, kl=66.8873, beta=0.0000\n",
      "Batch 60, loss=0.0596, recon=0.0596, kl=72.3162, beta=0.0000\n",
      "Batch 80, loss=0.0379, recon=0.0379, kl=76.2096, beta=0.0000\n",
      "Batch 100, loss=0.0614, recon=0.0614, kl=81.7840, beta=0.0000\n",
      "Batch 120, loss=0.0387, recon=0.0387, kl=81.4426, beta=0.0000\n",
      "Batch 140, loss=0.0494, recon=0.0494, kl=84.0957, beta=0.0000\n",
      "Batch 160, loss=0.0316, recon=0.0316, kl=88.8841, beta=0.0000\n",
      "Batch 180, loss=0.0445, recon=0.0445, kl=89.3758, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0582 (Recon: 0.0582, KL: 77.4236, Current Beta: 0.0000) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0499\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0336, recon=0.0336, kl=91.7674, beta=0.0000\n",
      "Batch 40, loss=0.2183, recon=0.2183, kl=88.5456, beta=0.0000\n",
      "Batch 60, loss=0.0333, recon=0.0333, kl=86.5791, beta=0.0000\n",
      "Batch 80, loss=0.0369, recon=0.0369, kl=85.7410, beta=0.0000\n",
      "Batch 100, loss=0.0573, recon=0.0573, kl=85.6158, beta=0.0000\n",
      "Batch 120, loss=0.0336, recon=0.0336, kl=87.8477, beta=0.0000\n",
      "Batch 140, loss=0.0362, recon=0.0362, kl=87.2842, beta=0.0000\n",
      "Batch 160, loss=0.0329, recon=0.0329, kl=92.7516, beta=0.0000\n",
      "Batch 180, loss=0.0269, recon=0.0269, kl=86.7905, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0529, KL: 88.0332, Current Beta: 0.0000) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0239, recon=0.0239, kl=82.5952, beta=0.0000\n",
      "Batch 40, loss=0.0371, recon=0.0371, kl=80.2127, beta=0.0000\n",
      "Batch 60, loss=0.0523, recon=0.0523, kl=83.2921, beta=0.0000\n",
      "Batch 80, loss=0.0274, recon=0.0274, kl=84.5834, beta=0.0000\n",
      "Batch 100, loss=0.0577, recon=0.0577, kl=84.4209, beta=0.0000\n",
      "Batch 120, loss=0.0451, recon=0.0451, kl=85.0342, beta=0.0000\n",
      "Batch 140, loss=0.0513, recon=0.0513, kl=84.7942, beta=0.0000\n",
      "Batch 160, loss=0.0517, recon=0.0517, kl=85.3276, beta=0.0000\n",
      "Batch 180, loss=0.1706, recon=0.1706, kl=78.5606, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0497, KL: 83.8060, Current Beta: 0.0000) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0613, recon=0.0613, kl=79.0288, beta=0.0000\n",
      "Batch 40, loss=0.0292, recon=0.0292, kl=77.7178, beta=0.0000\n",
      "Batch 60, loss=0.0803, recon=0.0803, kl=78.4745, beta=0.0000\n",
      "Batch 80, loss=0.0281, recon=0.0281, kl=79.3721, beta=0.0000\n",
      "Batch 100, loss=0.0237, recon=0.0237, kl=79.4129, beta=0.0000\n",
      "Batch 120, loss=0.0341, recon=0.0341, kl=79.0625, beta=0.0000\n",
      "Batch 140, loss=0.0286, recon=0.0286, kl=77.4232, beta=0.0000\n",
      "Batch 160, loss=0.0604, recon=0.0604, kl=77.2035, beta=0.0000\n",
      "Batch 180, loss=0.0727, recon=0.0727, kl=78.2907, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0467 (Recon: 0.0467, KL: 78.6356, Current Beta: 0.0000) | Avg Valid Loss: 0.0514 | Avg Valid recon Loss: 0.0514\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0404, recon=0.0404, kl=73.3755, beta=0.0000\n",
      "Batch 40, loss=0.0498, recon=0.0498, kl=72.1221, beta=0.0000\n",
      "Batch 60, loss=0.0583, recon=0.0583, kl=76.7045, beta=0.0000\n",
      "Batch 80, loss=0.0457, recon=0.0457, kl=76.4735, beta=0.0000\n",
      "Batch 100, loss=0.0225, recon=0.0225, kl=73.0713, beta=0.0000\n",
      "Batch 120, loss=0.0327, recon=0.0327, kl=72.7712, beta=0.0000\n",
      "Batch 140, loss=0.0261, recon=0.0261, kl=73.8750, beta=0.0000\n",
      "Batch 160, loss=0.7056, recon=0.7056, kl=74.0683, beta=0.0000\n",
      "Batch 180, loss=0.0329, recon=0.0329, kl=77.5950, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0474 (Recon: 0.0473, KL: 73.9568, Current Beta: 0.0000) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0684, recon=0.0684, kl=76.2169, beta=0.0000\n",
      "Batch 40, loss=0.0704, recon=0.0704, kl=73.3044, beta=0.0000\n",
      "Batch 60, loss=0.0366, recon=0.0366, kl=75.3344, beta=0.0000\n",
      "Batch 80, loss=0.0337, recon=0.0337, kl=72.2368, beta=0.0000\n",
      "Batch 100, loss=0.0252, recon=0.0251, kl=71.5164, beta=0.0000\n",
      "Batch 120, loss=0.0258, recon=0.0258, kl=73.4335, beta=0.0000\n",
      "Batch 140, loss=0.0388, recon=0.0388, kl=73.4757, beta=0.0000\n",
      "Batch 160, loss=0.0670, recon=0.0670, kl=74.1697, beta=0.0000\n",
      "Batch 180, loss=0.0282, recon=0.0282, kl=75.1519, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0463, KL: 73.9970, Current Beta: 0.0000) | Avg Valid Loss: 0.0429 | Avg Valid recon Loss: 0.0429\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=69.8488, beta=0.0000\n",
      "Batch 40, loss=0.0371, recon=0.0371, kl=67.1002, beta=0.0000\n",
      "Batch 60, loss=0.0456, recon=0.0456, kl=64.2251, beta=0.0000\n",
      "Batch 80, loss=0.0525, recon=0.0525, kl=63.1911, beta=0.0000\n",
      "Batch 100, loss=0.1178, recon=0.1177, kl=62.6252, beta=0.0000\n",
      "Batch 120, loss=0.0362, recon=0.0362, kl=62.6458, beta=0.0000\n",
      "Batch 140, loss=0.0372, recon=0.0372, kl=58.6434, beta=0.0000\n",
      "Batch 160, loss=0.0324, recon=0.0323, kl=56.1075, beta=0.0000\n",
      "Batch 180, loss=0.0413, recon=0.0412, kl=57.7476, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0454 (Recon: 0.0453, KL: 63.3620, Current Beta: 0.0000) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0367\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0234, recon=0.0233, kl=53.1192, beta=0.0000\n",
      "Batch 40, loss=0.0239, recon=0.0238, kl=50.0398, beta=0.0000\n",
      "Batch 60, loss=0.0316, recon=0.0316, kl=44.3199, beta=0.0000\n",
      "Batch 80, loss=0.0273, recon=0.0272, kl=42.8311, beta=0.0000\n",
      "Batch 100, loss=0.0626, recon=0.0626, kl=43.8426, beta=0.0000\n",
      "Batch 120, loss=0.0328, recon=0.0327, kl=42.5271, beta=0.0000\n",
      "Batch 140, loss=0.0414, recon=0.0414, kl=46.2339, beta=0.0000\n",
      "Batch 160, loss=0.0329, recon=0.0328, kl=48.5695, beta=0.0000\n",
      "Batch 180, loss=0.1267, recon=0.1266, kl=50.2590, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0420, KL: 47.3364, Current Beta: 0.0000) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1307, recon=0.1306, kl=40.3392, beta=0.0000\n",
      "Batch 40, loss=0.0218, recon=0.0217, kl=33.8644, beta=0.0000\n",
      "Batch 60, loss=0.0243, recon=0.0242, kl=33.8456, beta=0.0000\n",
      "Batch 80, loss=0.0349, recon=0.0348, kl=31.9615, beta=0.0000\n",
      "Batch 100, loss=0.0470, recon=0.0469, kl=33.5816, beta=0.0000\n",
      "Batch 120, loss=0.0381, recon=0.0380, kl=34.1534, beta=0.0000\n",
      "Batch 140, loss=0.0262, recon=0.0261, kl=32.1024, beta=0.0000\n",
      "Batch 160, loss=0.0325, recon=0.0324, kl=32.8469, beta=0.0000\n",
      "Batch 180, loss=0.0348, recon=0.0347, kl=33.7908, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0433, KL: 35.0726, Current Beta: 0.0000) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0293, recon=0.0291, kl=27.5487, beta=0.0000\n",
      "Batch 40, loss=0.1329, recon=0.1327, kl=29.7558, beta=0.0000\n",
      "Batch 60, loss=0.0652, recon=0.0650, kl=27.3813, beta=0.0000\n",
      "Batch 80, loss=0.0571, recon=0.0568, kl=38.9541, beta=0.0000\n",
      "Batch 100, loss=0.1567, recon=0.1564, kl=34.3971, beta=0.0000\n",
      "Batch 120, loss=0.0281, recon=0.0279, kl=29.4167, beta=0.0000\n",
      "Batch 140, loss=0.0363, recon=0.0361, kl=25.6736, beta=0.0000\n",
      "Batch 160, loss=0.0446, recon=0.0444, kl=26.8279, beta=0.0000\n",
      "Batch 180, loss=0.0351, recon=0.0349, kl=26.4743, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0456 (Recon: 0.0454, KL: 30.3116, Current Beta: 0.0000) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0392\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0263, recon=0.0260, kl=18.0845, beta=0.0000\n",
      "Batch 40, loss=0.0407, recon=0.0403, kl=18.6835, beta=0.0000\n",
      "Batch 60, loss=0.0321, recon=0.0317, kl=23.9687, beta=0.0000\n",
      "Batch 80, loss=0.0305, recon=0.0302, kl=18.7149, beta=0.0000\n",
      "Batch 100, loss=0.1644, recon=0.1641, kl=15.5735, beta=0.0000\n",
      "Batch 120, loss=0.0386, recon=0.0383, kl=13.1961, beta=0.0000\n",
      "Batch 140, loss=0.0390, recon=0.0388, kl=12.1515, beta=0.0000\n",
      "Batch 160, loss=0.0407, recon=0.0404, kl=13.2553, beta=0.0000\n",
      "Batch 180, loss=0.0206, recon=0.0204, kl=11.9978, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0430, KL: 17.0060, Current Beta: 0.0000) | Avg Valid Loss: 0.0349 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0262, recon=0.0260, kl=7.1339, beta=0.0000\n",
      "Batch 40, loss=0.0429, recon=0.0428, kl=5.1338, beta=0.0000\n",
      "Batch 60, loss=0.0310, recon=0.0308, kl=6.6514, beta=0.0000\n",
      "Batch 80, loss=0.0294, recon=0.0292, kl=5.0177, beta=0.0000\n",
      "Batch 100, loss=0.0329, recon=0.0327, kl=3.8474, beta=0.0000\n",
      "Batch 120, loss=0.0332, recon=0.0330, kl=3.4483, beta=0.0000\n",
      "Batch 140, loss=0.0244, recon=0.0242, kl=3.1197, beta=0.0000\n",
      "Batch 160, loss=0.0484, recon=0.0483, kl=2.6630, beta=0.0000\n",
      "Batch 180, loss=0.0292, recon=0.0291, kl=2.0893, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0416, KL: 4.8675, Current Beta: 0.0000) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0274, recon=0.0274, kl=0.7936, beta=0.0001\n",
      "Batch 40, loss=0.0260, recon=0.0258, kl=2.0105, beta=0.0001\n",
      "Batch 60, loss=0.0255, recon=0.0253, kl=2.8456, beta=0.0001\n",
      "Batch 80, loss=0.0286, recon=0.0285, kl=2.0950, beta=0.0001\n",
      "Batch 100, loss=0.0266, recon=0.0265, kl=1.8648, beta=0.0001\n",
      "Batch 120, loss=0.0382, recon=0.0381, kl=1.6095, beta=0.0001\n",
      "Batch 140, loss=0.0404, recon=0.0404, kl=1.0463, beta=0.0001\n",
      "Batch 160, loss=0.0536, recon=0.0535, kl=1.4423, beta=0.0001\n",
      "Batch 180, loss=0.0374, recon=0.0371, kl=5.9527, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0386, KL: 1.9789, Current Beta: 0.0001) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0361, recon=0.0357, kl=3.8031, beta=0.0001\n",
      "Batch 40, loss=0.0225, recon=0.0223, kl=1.9448, beta=0.0001\n",
      "Batch 60, loss=0.0622, recon=0.0621, kl=1.0837, beta=0.0001\n",
      "Batch 80, loss=0.0326, recon=0.0326, kl=0.9029, beta=0.0001\n",
      "Batch 100, loss=0.0363, recon=0.0362, kl=1.0560, beta=0.0001\n",
      "Batch 120, loss=0.0315, recon=0.0314, kl=1.0526, beta=0.0001\n",
      "Batch 140, loss=0.0258, recon=0.0258, kl=0.7452, beta=0.0001\n",
      "Batch 160, loss=0.0310, recon=0.0309, kl=0.5980, beta=0.0001\n",
      "Batch 180, loss=0.0368, recon=0.0367, kl=0.5830, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0399 (Recon: 0.0397, KL: 1.6013, Current Beta: 0.0001) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0332\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0621, recon=0.0620, kl=0.4446, beta=0.0001\n",
      "Batch 40, loss=0.0226, recon=0.0225, kl=0.3919, beta=0.0001\n",
      "Batch 60, loss=0.0261, recon=0.0261, kl=0.3851, beta=0.0001\n",
      "Batch 80, loss=0.0477, recon=0.0476, kl=0.5024, beta=0.0001\n",
      "Batch 100, loss=0.0407, recon=0.0406, kl=0.5483, beta=0.0001\n",
      "Batch 120, loss=0.0509, recon=0.0509, kl=0.5238, beta=0.0001\n",
      "Batch 140, loss=0.0488, recon=0.0487, kl=0.3981, beta=0.0001\n",
      "Batch 160, loss=0.0650, recon=0.0649, kl=0.3402, beta=0.0001\n",
      "Batch 180, loss=0.0396, recon=0.0396, kl=0.2417, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0394 (Recon: 0.0394, KL: 0.4329, Current Beta: 0.0001) | Avg Valid Loss: 0.0343 | Avg Valid recon Loss: 0.0343\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0311, recon=0.0311, kl=0.2546, beta=0.0001\n",
      "Batch 40, loss=0.0233, recon=0.0233, kl=0.2609, beta=0.0001\n",
      "Batch 60, loss=0.0401, recon=0.0400, kl=0.2936, beta=0.0001\n",
      "Batch 80, loss=0.0251, recon=0.0250, kl=0.2861, beta=0.0001\n",
      "Batch 100, loss=0.0329, recon=0.0329, kl=0.2163, beta=0.0001\n",
      "Batch 120, loss=0.0336, recon=0.0336, kl=0.1818, beta=0.0001\n",
      "Batch 140, loss=0.0290, recon=0.0290, kl=0.1589, beta=0.0001\n",
      "Batch 160, loss=0.0260, recon=0.0259, kl=0.3653, beta=0.0001\n",
      "Batch 180, loss=0.0424, recon=0.0423, kl=0.4530, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0365 (Recon: 0.0365, KL: 0.2646, Current Beta: 0.0001) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0443\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0392, recon=0.0391, kl=0.3289, beta=0.0001\n",
      "Batch 40, loss=0.0502, recon=0.0502, kl=0.2889, beta=0.0001\n",
      "Batch 60, loss=0.0303, recon=0.0302, kl=0.2397, beta=0.0001\n",
      "Batch 80, loss=0.0438, recon=0.0438, kl=0.1781, beta=0.0001\n",
      "Batch 100, loss=0.0869, recon=0.0869, kl=0.1508, beta=0.0001\n",
      "Batch 120, loss=0.0583, recon=0.0583, kl=0.1449, beta=0.0001\n",
      "Batch 140, loss=0.0194, recon=0.0192, kl=1.4057, beta=0.0001\n",
      "Batch 160, loss=0.1161, recon=0.1158, kl=3.5687, beta=0.0001\n",
      "Batch 180, loss=0.0180, recon=0.0178, kl=2.3468, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0418, KL: 0.8797, Current Beta: 0.0001) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0192, recon=0.0191, kl=1.1627, beta=0.0001\n",
      "Batch 40, loss=0.0412, recon=0.0411, kl=0.6652, beta=0.0001\n",
      "Batch 60, loss=0.0418, recon=0.0417, kl=0.6314, beta=0.0001\n",
      "Batch 80, loss=0.0264, recon=0.0264, kl=0.3940, beta=0.0001\n",
      "Batch 100, loss=0.0247, recon=0.0247, kl=0.3310, beta=0.0001\n",
      "Batch 120, loss=0.0455, recon=0.0454, kl=0.3223, beta=0.0001\n",
      "Batch 140, loss=0.0385, recon=0.0385, kl=0.3033, beta=0.0001\n",
      "Batch 160, loss=0.0565, recon=0.0565, kl=0.2524, beta=0.0001\n",
      "Batch 180, loss=0.1195, recon=0.1194, kl=0.2727, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0396 (Recon: 0.0395, KL: 0.5732, Current Beta: 0.0001) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0370\n",
      "\n",
      "[VRAE Run 11/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6954, recon=0.6954, kl=0.7115, beta=0.0000\n",
      "Batch 40, loss=0.2504, recon=0.2504, kl=7.9758, beta=0.0000\n",
      "Batch 60, loss=0.3913, recon=0.3913, kl=45.6793, beta=0.0000\n",
      "Batch 80, loss=0.2412, recon=0.2412, kl=66.3021, beta=0.0000\n",
      "Batch 100, loss=1.0368, recon=1.0368, kl=77.1984, beta=0.0000\n",
      "Batch 120, loss=0.1658, recon=0.1658, kl=86.0371, beta=0.0000\n",
      "Batch 140, loss=0.3003, recon=0.3003, kl=92.3496, beta=0.0000\n",
      "Batch 160, loss=0.1618, recon=0.1618, kl=97.4766, beta=0.0000\n",
      "Batch 180, loss=0.1417, recon=0.1417, kl=103.7426, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3135 (Recon: 0.3135, KL: 59.0212, Current Beta: 0.0000) | Avg Valid Loss: 0.1423 | Avg Valid recon Loss: 0.1423\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1479, recon=0.1479, kl=110.5846, beta=0.0000\n",
      "Batch 40, loss=0.1988, recon=0.1988, kl=113.9912, beta=0.0000\n",
      "Batch 60, loss=0.1166, recon=0.1166, kl=118.6540, beta=0.0000\n",
      "Batch 80, loss=0.1103, recon=0.1103, kl=122.6825, beta=0.0000\n",
      "Batch 100, loss=0.1239, recon=0.1239, kl=126.4701, beta=0.0000\n",
      "Batch 120, loss=0.1010, recon=0.1010, kl=133.5344, beta=0.0000\n",
      "Batch 140, loss=0.1463, recon=0.1463, kl=140.6857, beta=0.0000\n",
      "Batch 160, loss=0.0882, recon=0.0882, kl=144.4917, beta=0.0000\n",
      "Batch 180, loss=0.0619, recon=0.0619, kl=147.7724, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1463 (Recon: 0.1463, KL: 126.5538, Current Beta: 0.0000) | Avg Valid Loss: 0.0977 | Avg Valid recon Loss: 0.0977\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1023, recon=0.1023, kl=149.6931, beta=0.0000\n",
      "Batch 40, loss=0.0772, recon=0.0772, kl=145.6527, beta=0.0000\n",
      "Batch 60, loss=0.0850, recon=0.0850, kl=146.8823, beta=0.0000\n",
      "Batch 80, loss=0.1007, recon=0.1007, kl=147.1423, beta=0.0000\n",
      "Batch 100, loss=0.1427, recon=0.1427, kl=151.2836, beta=0.0000\n",
      "Batch 120, loss=0.0741, recon=0.0741, kl=155.3309, beta=0.0000\n",
      "Batch 140, loss=0.0881, recon=0.0881, kl=158.5690, beta=0.0000\n",
      "Batch 160, loss=0.0840, recon=0.0840, kl=158.4212, beta=0.0000\n",
      "Batch 180, loss=0.0677, recon=0.0677, kl=162.2216, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1096 (Recon: 0.1096, KL: 151.9274, Current Beta: 0.0000) | Avg Valid Loss: 0.0805 | Avg Valid recon Loss: 0.0805\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0960, recon=0.0960, kl=162.2015, beta=0.0000\n",
      "Batch 40, loss=0.0934, recon=0.0934, kl=162.1792, beta=0.0000\n",
      "Batch 60, loss=0.5121, recon=0.5121, kl=158.8659, beta=0.0000\n",
      "Batch 80, loss=0.0928, recon=0.0928, kl=158.3746, beta=0.0000\n",
      "Batch 100, loss=0.0837, recon=0.0837, kl=160.8133, beta=0.0000\n",
      "Batch 120, loss=0.0677, recon=0.0677, kl=166.1743, beta=0.0000\n",
      "Batch 140, loss=0.0707, recon=0.0707, kl=166.3631, beta=0.0000\n",
      "Batch 160, loss=0.1395, recon=0.1395, kl=168.8818, beta=0.0000\n",
      "Batch 180, loss=0.1556, recon=0.1556, kl=169.6541, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0903 (Recon: 0.0903, KL: 163.5449, Current Beta: 0.0000) | Avg Valid Loss: 0.0724 | Avg Valid recon Loss: 0.0724\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0708, recon=0.0708, kl=168.8874, beta=0.0000\n",
      "Batch 40, loss=0.0938, recon=0.0938, kl=172.4529, beta=0.0000\n",
      "Batch 60, loss=0.0524, recon=0.0524, kl=176.9359, beta=0.0000\n",
      "Batch 80, loss=0.0421, recon=0.0421, kl=171.4585, beta=0.0000\n",
      "Batch 100, loss=0.0581, recon=0.0581, kl=171.7431, beta=0.0000\n",
      "Batch 120, loss=0.0576, recon=0.0576, kl=172.3859, beta=0.0000\n",
      "Batch 140, loss=0.0529, recon=0.0529, kl=171.5565, beta=0.0000\n",
      "Batch 160, loss=0.0699, recon=0.0699, kl=170.5472, beta=0.0000\n",
      "Batch 180, loss=0.0752, recon=0.0752, kl=175.1876, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0781 (Recon: 0.0781, KL: 172.2992, Current Beta: 0.0000) | Avg Valid Loss: 0.0637 | Avg Valid recon Loss: 0.0637\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0391, recon=0.0391, kl=174.7504, beta=0.0000\n",
      "Batch 40, loss=0.0597, recon=0.0597, kl=174.2764, beta=0.0000\n",
      "Batch 60, loss=0.1206, recon=0.1206, kl=177.0027, beta=0.0000\n",
      "Batch 80, loss=0.0591, recon=0.0591, kl=174.4212, beta=0.0000\n",
      "Batch 100, loss=0.0385, recon=0.0385, kl=174.4159, beta=0.0000\n",
      "Batch 120, loss=0.0399, recon=0.0399, kl=170.7614, beta=0.0000\n",
      "Batch 140, loss=0.0929, recon=0.0929, kl=170.5285, beta=0.0000\n",
      "Batch 160, loss=0.0697, recon=0.0697, kl=168.8972, beta=0.0000\n",
      "Batch 180, loss=0.0709, recon=0.0709, kl=167.5774, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0706 (Recon: 0.0706, KL: 172.9538, Current Beta: 0.0000) | Avg Valid Loss: 0.0588 | Avg Valid recon Loss: 0.0588\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0531, recon=0.0531, kl=165.8717, beta=0.0000\n",
      "Batch 40, loss=0.0451, recon=0.0451, kl=165.9153, beta=0.0000\n",
      "Batch 60, loss=0.0797, recon=0.0797, kl=156.7486, beta=0.0000\n",
      "Batch 80, loss=0.0365, recon=0.0365, kl=155.6759, beta=0.0000\n",
      "Batch 100, loss=0.0358, recon=0.0358, kl=153.0494, beta=0.0000\n",
      "Batch 120, loss=0.0575, recon=0.0575, kl=149.2071, beta=0.0000\n",
      "Batch 140, loss=0.0373, recon=0.0373, kl=149.6679, beta=0.0000\n",
      "Batch 160, loss=0.0367, recon=0.0367, kl=149.1100, beta=0.0000\n",
      "Batch 180, loss=0.0399, recon=0.0399, kl=146.0191, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0648 (Recon: 0.0647, KL: 155.4549, Current Beta: 0.0000) | Avg Valid Loss: 0.0552 | Avg Valid recon Loss: 0.0552\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0334, recon=0.0334, kl=139.8568, beta=0.0000\n",
      "Batch 40, loss=0.0355, recon=0.0355, kl=138.0947, beta=0.0000\n",
      "Batch 60, loss=0.0390, recon=0.0390, kl=130.2332, beta=0.0000\n",
      "Batch 80, loss=0.0298, recon=0.0298, kl=127.3059, beta=0.0000\n",
      "Batch 100, loss=0.0459, recon=0.0459, kl=121.8971, beta=0.0000\n",
      "Batch 120, loss=0.0495, recon=0.0495, kl=117.8174, beta=0.0000\n",
      "Batch 140, loss=0.0407, recon=0.0406, kl=113.4105, beta=0.0000\n",
      "Batch 160, loss=0.0390, recon=0.0390, kl=108.7939, beta=0.0000\n",
      "Batch 180, loss=0.0482, recon=0.0482, kl=110.0927, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0605 (Recon: 0.0605, KL: 124.8609, Current Beta: 0.0000) | Avg Valid Loss: 0.0525 | Avg Valid recon Loss: 0.0525\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0577, recon=0.0577, kl=100.4278, beta=0.0000\n",
      "Batch 40, loss=0.0272, recon=0.0272, kl=84.1417, beta=0.0000\n",
      "Batch 60, loss=0.0389, recon=0.0389, kl=78.1104, beta=0.0000\n",
      "Batch 80, loss=0.0549, recon=0.0548, kl=73.7523, beta=0.0000\n",
      "Batch 100, loss=0.0393, recon=0.0392, kl=72.2995, beta=0.0000\n",
      "Batch 120, loss=0.0359, recon=0.0359, kl=73.8285, beta=0.0000\n",
      "Batch 140, loss=0.0367, recon=0.0367, kl=72.1846, beta=0.0000\n",
      "Batch 160, loss=0.0250, recon=0.0249, kl=70.6723, beta=0.0000\n",
      "Batch 180, loss=0.0532, recon=0.0532, kl=65.0052, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0574 (Recon: 0.0573, KL: 78.8881, Current Beta: 0.0000) | Avg Valid Loss: 0.0503 | Avg Valid recon Loss: 0.0502\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0339, recon=0.0338, kl=56.3199, beta=0.0000\n",
      "Batch 40, loss=0.0347, recon=0.0347, kl=44.3801, beta=0.0000\n",
      "Batch 60, loss=1.0121, recon=1.0120, kl=41.5270, beta=0.0000\n",
      "Batch 80, loss=0.0568, recon=0.0568, kl=43.1806, beta=0.0000\n",
      "Batch 100, loss=0.0447, recon=0.0446, kl=40.6025, beta=0.0000\n",
      "Batch 120, loss=0.0310, recon=0.0309, kl=41.1048, beta=0.0000\n",
      "Batch 140, loss=0.0643, recon=0.0643, kl=37.9276, beta=0.0000\n",
      "Batch 160, loss=0.0280, recon=0.0280, kl=37.6230, beta=0.0000\n",
      "Batch 180, loss=0.0344, recon=0.0343, kl=35.6188, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0550 (Recon: 0.0550, KL: 43.6043, Current Beta: 0.0000) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0478\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0428, recon=0.0427, kl=18.8713, beta=0.0000\n",
      "Batch 40, loss=0.0831, recon=0.0830, kl=21.1205, beta=0.0000\n",
      "Batch 60, loss=0.0597, recon=0.0596, kl=20.3367, beta=0.0000\n",
      "Batch 80, loss=0.0429, recon=0.0428, kl=19.0037, beta=0.0000\n",
      "Batch 100, loss=0.0495, recon=0.0494, kl=17.0659, beta=0.0000\n",
      "Batch 120, loss=0.0337, recon=0.0336, kl=18.8004, beta=0.0000\n",
      "Batch 140, loss=0.0374, recon=0.0374, kl=15.8012, beta=0.0000\n",
      "Batch 160, loss=0.0308, recon=0.0307, kl=15.5677, beta=0.0000\n",
      "Batch 180, loss=0.2412, recon=0.2411, kl=14.3342, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0526, KL: 18.8143, Current Beta: 0.0000) | Avg Valid Loss: 0.0467 | Avg Valid recon Loss: 0.0467\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0361, recon=0.0361, kl=6.9925, beta=0.0000\n",
      "Batch 40, loss=0.0349, recon=0.0349, kl=7.0606, beta=0.0000\n",
      "Batch 60, loss=0.0413, recon=0.0413, kl=6.3774, beta=0.0000\n",
      "Batch 80, loss=0.0256, recon=0.0256, kl=6.4937, beta=0.0000\n",
      "Batch 100, loss=0.0282, recon=0.0282, kl=5.8276, beta=0.0000\n",
      "Batch 120, loss=0.0312, recon=0.0311, kl=5.9157, beta=0.0000\n",
      "Batch 140, loss=0.0330, recon=0.0330, kl=5.0163, beta=0.0000\n",
      "Batch 160, loss=0.0314, recon=0.0313, kl=5.7892, beta=0.0000\n",
      "Batch 180, loss=0.0361, recon=0.0361, kl=5.4520, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0509 (Recon: 0.0509, KL: 6.5675, Current Beta: 0.0000) | Avg Valid Loss: 0.0451 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0393, recon=0.0392, kl=2.2466, beta=0.0000\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=2.6958, beta=0.0000\n",
      "Batch 60, loss=0.0353, recon=0.0353, kl=2.3483, beta=0.0000\n",
      "Batch 80, loss=0.0351, recon=0.0351, kl=2.0324, beta=0.0000\n",
      "Batch 100, loss=0.0326, recon=0.0326, kl=1.8360, beta=0.0000\n",
      "Batch 120, loss=0.0282, recon=0.0282, kl=2.4443, beta=0.0000\n",
      "Batch 140, loss=0.0300, recon=0.0299, kl=2.9683, beta=0.0000\n",
      "Batch 160, loss=0.0266, recon=0.0266, kl=2.0873, beta=0.0000\n",
      "Batch 180, loss=0.0491, recon=0.0491, kl=1.7825, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0495, KL: 2.4413, Current Beta: 0.0000) | Avg Valid Loss: 0.0429 | Avg Valid recon Loss: 0.0429\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0535, recon=0.0535, kl=0.9840, beta=0.0000\n",
      "Batch 40, loss=0.0285, recon=0.0285, kl=0.9820, beta=0.0000\n",
      "Batch 60, loss=0.0274, recon=0.0273, kl=0.9164, beta=0.0000\n",
      "Batch 80, loss=0.0356, recon=0.0355, kl=1.0651, beta=0.0000\n",
      "Batch 100, loss=0.0343, recon=0.0342, kl=0.8854, beta=0.0000\n",
      "Batch 120, loss=0.0404, recon=0.0403, kl=1.3039, beta=0.0000\n",
      "Batch 140, loss=0.0268, recon=0.0268, kl=0.8203, beta=0.0000\n",
      "Batch 160, loss=0.0341, recon=0.0341, kl=0.6312, beta=0.0000\n",
      "Batch 180, loss=0.0295, recon=0.0294, kl=0.5135, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0480, KL: 0.9619, Current Beta: 0.0000) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0619, recon=0.0619, kl=0.3547, beta=0.0001\n",
      "Batch 40, loss=0.0274, recon=0.0274, kl=0.3628, beta=0.0001\n",
      "Batch 60, loss=0.0393, recon=0.0393, kl=0.2900, beta=0.0001\n",
      "Batch 80, loss=0.0489, recon=0.0489, kl=0.3225, beta=0.0001\n",
      "Batch 100, loss=0.0333, recon=0.0333, kl=0.3311, beta=0.0001\n",
      "Batch 120, loss=0.0279, recon=0.0279, kl=0.3041, beta=0.0001\n",
      "Batch 140, loss=0.0292, recon=0.0292, kl=0.2938, beta=0.0001\n",
      "Batch 160, loss=0.0300, recon=0.0300, kl=0.1892, beta=0.0001\n",
      "Batch 180, loss=0.0282, recon=0.0282, kl=0.2504, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 0.3194, Current Beta: 0.0001) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0324, recon=0.0324, kl=0.0935, beta=0.0001\n",
      "Batch 40, loss=0.0440, recon=0.0440, kl=0.0888, beta=0.0001\n",
      "Batch 60, loss=0.0388, recon=0.0388, kl=0.0807, beta=0.0001\n",
      "Batch 80, loss=0.0305, recon=0.0305, kl=0.0783, beta=0.0001\n",
      "Batch 100, loss=0.0388, recon=0.0388, kl=0.0616, beta=0.0001\n",
      "Batch 120, loss=0.0198, recon=0.0198, kl=0.0527, beta=0.0001\n",
      "Batch 140, loss=0.0229, recon=0.0229, kl=0.0598, beta=0.0001\n",
      "Batch 160, loss=0.0443, recon=0.0443, kl=0.0473, beta=0.0001\n",
      "Batch 180, loss=0.0286, recon=0.0286, kl=0.0482, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0456 (Recon: 0.0456, KL: 0.0783, Current Beta: 0.0001) | Avg Valid Loss: 0.0400 | Avg Valid recon Loss: 0.0400\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0376, recon=0.0376, kl=0.0476, beta=0.0001\n",
      "Batch 40, loss=0.0267, recon=0.0266, kl=0.0491, beta=0.0001\n",
      "Batch 60, loss=0.0288, recon=0.0288, kl=0.0341, beta=0.0001\n",
      "Batch 80, loss=0.0278, recon=0.0278, kl=0.0293, beta=0.0001\n",
      "Batch 100, loss=0.0438, recon=0.0438, kl=0.0209, beta=0.0001\n",
      "Batch 120, loss=0.0362, recon=0.0362, kl=0.0319, beta=0.0001\n",
      "Batch 140, loss=0.0191, recon=0.0191, kl=0.0273, beta=0.0001\n",
      "Batch 160, loss=0.0515, recon=0.0515, kl=0.0218, beta=0.0001\n",
      "Batch 180, loss=0.0242, recon=0.0242, kl=0.0263, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0445, KL: 0.0331, Current Beta: 0.0001) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0652, recon=0.0652, kl=0.0240, beta=0.0001\n",
      "Batch 40, loss=0.1558, recon=0.1558, kl=0.0210, beta=0.0001\n",
      "Batch 60, loss=0.0379, recon=0.0379, kl=0.0315, beta=0.0001\n",
      "Batch 80, loss=0.0375, recon=0.0375, kl=0.0172, beta=0.0001\n",
      "Batch 100, loss=0.0281, recon=0.0281, kl=0.0173, beta=0.0001\n",
      "Batch 120, loss=0.0658, recon=0.0658, kl=0.0159, beta=0.0001\n",
      "Batch 140, loss=0.0324, recon=0.0324, kl=0.0164, beta=0.0001\n",
      "Batch 160, loss=0.0321, recon=0.0321, kl=0.0116, beta=0.0001\n",
      "Batch 180, loss=0.0308, recon=0.0308, kl=0.0143, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0438, KL: 0.0208, Current Beta: 0.0001) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=0.0133, beta=0.0001\n",
      "Batch 40, loss=0.0286, recon=0.0286, kl=0.0177, beta=0.0001\n",
      "Batch 60, loss=0.1588, recon=0.1588, kl=0.0132, beta=0.0001\n",
      "Batch 80, loss=0.0273, recon=0.0273, kl=0.0118, beta=0.0001\n",
      "Batch 100, loss=0.0420, recon=0.0420, kl=0.0081, beta=0.0001\n",
      "Batch 120, loss=0.0203, recon=0.0203, kl=0.0093, beta=0.0001\n",
      "Batch 140, loss=0.0279, recon=0.0279, kl=0.0082, beta=0.0001\n",
      "Batch 160, loss=0.0349, recon=0.0349, kl=0.0081, beta=0.0001\n",
      "Batch 180, loss=0.0408, recon=0.0408, kl=0.0135, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0431, KL: 0.0120, Current Beta: 0.0001) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0260, recon=0.0260, kl=0.0092, beta=0.0001\n",
      "Batch 40, loss=0.0357, recon=0.0357, kl=0.0102, beta=0.0001\n",
      "Batch 60, loss=0.0292, recon=0.0292, kl=0.0088, beta=0.0001\n",
      "Batch 80, loss=0.0760, recon=0.0760, kl=0.0182, beta=0.0001\n",
      "Batch 100, loss=0.0262, recon=0.0262, kl=0.0112, beta=0.0001\n",
      "Batch 120, loss=0.0346, recon=0.0346, kl=0.0087, beta=0.0001\n",
      "Batch 140, loss=0.0500, recon=0.0500, kl=0.0084, beta=0.0001\n",
      "Batch 160, loss=0.0235, recon=0.0235, kl=0.0085, beta=0.0001\n",
      "Batch 180, loss=0.0383, recon=0.0383, kl=0.0075, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 0.0104, Current Beta: 0.0001) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0364\n",
      "\n",
      "[VRAE Run 12/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3635, recon=0.3635, kl=63.6726, beta=0.0000\n",
      "Batch 40, loss=0.1366, recon=0.1366, kl=74.0416, beta=0.0000\n",
      "Batch 60, loss=0.1019, recon=0.1019, kl=66.8284, beta=0.0000\n",
      "Batch 80, loss=0.0769, recon=0.0769, kl=91.0818, beta=0.0000\n",
      "Batch 100, loss=0.0730, recon=0.0730, kl=118.5096, beta=0.0000\n",
      "Batch 120, loss=0.2439, recon=0.2439, kl=122.8759, beta=0.0000\n",
      "Batch 140, loss=0.0764, recon=0.0764, kl=101.6907, beta=0.0000\n",
      "Batch 160, loss=0.0700, recon=0.0700, kl=93.3173, beta=0.0000\n",
      "Batch 180, loss=0.0638, recon=0.0638, kl=109.1306, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1371 (Recon: 0.1371, KL: 88.3260, Current Beta: 0.0000) | Avg Valid Loss: 0.0578 | Avg Valid recon Loss: 0.0578\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=120.6607, beta=0.0000\n",
      "Batch 40, loss=0.0710, recon=0.0710, kl=121.3466, beta=0.0000\n",
      "Batch 60, loss=0.0391, recon=0.0391, kl=119.2483, beta=0.0000\n",
      "Batch 80, loss=0.0495, recon=0.0495, kl=125.1497, beta=0.0000\n",
      "Batch 100, loss=0.0529, recon=0.0529, kl=123.9243, beta=0.0000\n",
      "Batch 120, loss=0.0382, recon=0.0382, kl=121.8950, beta=0.0000\n",
      "Batch 140, loss=0.0517, recon=0.0517, kl=84.0127, beta=0.0000\n",
      "Batch 160, loss=0.0646, recon=0.0646, kl=85.4049, beta=0.0000\n",
      "Batch 180, loss=0.0694, recon=0.0694, kl=101.9651, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0660 (Recon: 0.0660, KL: 112.4008, Current Beta: 0.0000) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0469, recon=0.0469, kl=115.2660, beta=0.0000\n",
      "Batch 40, loss=0.1680, recon=0.1680, kl=117.3437, beta=0.0000\n",
      "Batch 60, loss=0.0332, recon=0.0332, kl=116.6683, beta=0.0000\n",
      "Batch 80, loss=0.0623, recon=0.0623, kl=119.8211, beta=0.0000\n",
      "Batch 100, loss=0.0550, recon=0.0550, kl=123.9646, beta=0.0000\n",
      "Batch 120, loss=0.0428, recon=0.0428, kl=120.7946, beta=0.0000\n",
      "Batch 140, loss=0.0457, recon=0.0457, kl=120.3554, beta=0.0000\n",
      "Batch 160, loss=0.0330, recon=0.0330, kl=127.2791, beta=0.0000\n",
      "Batch 180, loss=0.0440, recon=0.0440, kl=120.9741, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0581, KL: 119.7254, Current Beta: 0.0000) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0400, recon=0.0400, kl=110.9199, beta=0.0000\n",
      "Batch 40, loss=0.0382, recon=0.0382, kl=111.2646, beta=0.0000\n",
      "Batch 60, loss=0.0396, recon=0.0396, kl=115.8128, beta=0.0000\n",
      "Batch 80, loss=0.0477, recon=0.0477, kl=117.5669, beta=0.0000\n",
      "Batch 100, loss=0.0604, recon=0.0604, kl=126.5881, beta=0.0000\n",
      "Batch 120, loss=0.0550, recon=0.0550, kl=122.1350, beta=0.0000\n",
      "Batch 140, loss=0.0415, recon=0.0415, kl=122.7429, beta=0.0000\n",
      "Batch 160, loss=0.0657, recon=0.0657, kl=125.3128, beta=0.0000\n",
      "Batch 180, loss=0.0603, recon=0.0603, kl=135.4386, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0518, KL: 120.2831, Current Beta: 0.0000) | Avg Valid Loss: 0.0521 | Avg Valid recon Loss: 0.0521\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0330, recon=0.0330, kl=145.5491, beta=0.0000\n",
      "Batch 40, loss=0.0370, recon=0.0370, kl=141.2626, beta=0.0000\n",
      "Batch 60, loss=0.0291, recon=0.0291, kl=134.2305, beta=0.0000\n",
      "Batch 80, loss=0.0432, recon=0.0432, kl=124.4400, beta=0.0000\n",
      "Batch 100, loss=0.0398, recon=0.0398, kl=129.3833, beta=0.0000\n",
      "Batch 120, loss=0.0474, recon=0.0474, kl=136.1816, beta=0.0000\n",
      "Batch 140, loss=0.0391, recon=0.0391, kl=122.4017, beta=0.0000\n",
      "Batch 160, loss=0.0301, recon=0.0301, kl=138.0736, beta=0.0000\n",
      "Batch 180, loss=0.0388, recon=0.0388, kl=169.2589, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0532 (Recon: 0.0532, KL: 137.0006, Current Beta: 0.0000) | Avg Valid Loss: 0.0459 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0265, recon=0.0265, kl=213.4880, beta=0.0000\n",
      "Batch 40, loss=0.0460, recon=0.0460, kl=218.0900, beta=0.0000\n",
      "Batch 60, loss=0.0254, recon=0.0254, kl=213.4892, beta=0.0000\n",
      "Batch 80, loss=0.0388, recon=0.0388, kl=216.4000, beta=0.0000\n",
      "Batch 100, loss=0.0404, recon=0.0404, kl=214.5295, beta=0.0000\n",
      "Batch 120, loss=0.0452, recon=0.0452, kl=219.1288, beta=0.0000\n",
      "Batch 140, loss=0.0358, recon=0.0358, kl=222.3877, beta=0.0000\n",
      "Batch 160, loss=0.0395, recon=0.0394, kl=216.8152, beta=0.0000\n",
      "Batch 180, loss=0.0949, recon=0.0949, kl=215.6503, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0493 (Recon: 0.0493, KL: 214.5713, Current Beta: 0.0000) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0470, recon=0.0470, kl=224.5632, beta=0.0000\n",
      "Batch 40, loss=0.6185, recon=0.6185, kl=225.2752, beta=0.0000\n",
      "Batch 60, loss=0.0480, recon=0.0480, kl=225.2177, beta=0.0000\n",
      "Batch 80, loss=0.0265, recon=0.0264, kl=217.1680, beta=0.0000\n",
      "Batch 100, loss=0.0356, recon=0.0356, kl=226.8054, beta=0.0000\n",
      "Batch 120, loss=0.0271, recon=0.0271, kl=217.0692, beta=0.0000\n",
      "Batch 140, loss=0.0286, recon=0.0286, kl=223.4499, beta=0.0000\n",
      "Batch 160, loss=0.0248, recon=0.0248, kl=218.1539, beta=0.0000\n",
      "Batch 180, loss=0.0312, recon=0.0312, kl=219.0723, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0468 (Recon: 0.0468, KL: 221.5289, Current Beta: 0.0000) | Avg Valid Loss: 0.0434 | Avg Valid recon Loss: 0.0434\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0304, recon=0.0303, kl=215.3301, beta=0.0000\n",
      "Batch 40, loss=0.0363, recon=0.0363, kl=215.8920, beta=0.0000\n",
      "Batch 60, loss=0.0298, recon=0.0298, kl=213.3116, beta=0.0000\n",
      "Batch 80, loss=0.0473, recon=0.0473, kl=205.6499, beta=0.0000\n",
      "Batch 100, loss=0.0301, recon=0.0301, kl=206.6732, beta=0.0000\n",
      "Batch 120, loss=0.0370, recon=0.0370, kl=204.5042, beta=0.0000\n",
      "Batch 140, loss=0.0321, recon=0.0321, kl=205.8879, beta=0.0000\n",
      "Batch 160, loss=0.0297, recon=0.0297, kl=204.9807, beta=0.0000\n",
      "Batch 180, loss=0.0290, recon=0.0290, kl=202.5114, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0434, KL: 209.4839, Current Beta: 0.0000) | Avg Valid Loss: 0.3754 | Avg Valid recon Loss: 0.3753\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0357, recon=0.0357, kl=197.0692, beta=0.0000\n",
      "Batch 40, loss=0.0381, recon=0.0380, kl=190.8058, beta=0.0000\n",
      "Batch 60, loss=0.5238, recon=0.5237, kl=186.3972, beta=0.0000\n",
      "Batch 80, loss=0.0468, recon=0.0468, kl=158.7071, beta=0.0000\n",
      "Batch 100, loss=0.0463, recon=0.0462, kl=154.7463, beta=0.0000\n",
      "Batch 120, loss=0.0269, recon=0.0268, kl=151.9612, beta=0.0000\n",
      "Batch 140, loss=0.0324, recon=0.0324, kl=156.8800, beta=0.0000\n",
      "Batch 160, loss=0.0378, recon=0.0377, kl=149.6617, beta=0.0000\n",
      "Batch 180, loss=0.0698, recon=0.0698, kl=153.4296, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0473, KL: 167.6223, Current Beta: 0.0000) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0472, recon=0.0470, kl=146.9614, beta=0.0000\n",
      "Batch 40, loss=0.0389, recon=0.0388, kl=138.5890, beta=0.0000\n",
      "Batch 60, loss=0.0794, recon=0.0793, kl=133.7884, beta=0.0000\n",
      "Batch 80, loss=0.0332, recon=0.0331, kl=131.3555, beta=0.0000\n",
      "Batch 100, loss=0.0434, recon=0.0432, kl=125.4275, beta=0.0000\n",
      "Batch 120, loss=0.0596, recon=0.0594, kl=121.3813, beta=0.0000\n",
      "Batch 140, loss=0.0196, recon=0.0195, kl=116.3105, beta=0.0000\n",
      "Batch 160, loss=0.0821, recon=0.0820, kl=110.9394, beta=0.0000\n",
      "Batch 180, loss=0.0252, recon=0.0251, kl=109.3671, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0441 (Recon: 0.0439, KL: 128.3904, Current Beta: 0.0000) | Avg Valid Loss: 0.0349 | Avg Valid recon Loss: 0.0348\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0398, recon=0.0396, kl=101.7528, beta=0.0000\n",
      "Batch 40, loss=0.0245, recon=0.0243, kl=86.3235, beta=0.0000\n",
      "Batch 60, loss=0.0262, recon=0.0259, kl=80.6513, beta=0.0000\n",
      "Batch 80, loss=0.0246, recon=0.0244, kl=72.8857, beta=0.0000\n",
      "Batch 100, loss=0.0344, recon=0.0342, kl=73.2332, beta=0.0000\n",
      "Batch 120, loss=0.0279, recon=0.0277, kl=68.4896, beta=0.0000\n",
      "Batch 140, loss=0.0599, recon=0.0597, kl=61.9656, beta=0.0000\n",
      "Batch 160, loss=0.0253, recon=0.0252, kl=55.5205, beta=0.0000\n",
      "Batch 180, loss=0.1020, recon=0.1018, kl=56.5986, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0413 (Recon: 0.0410, KL: 75.6000, Current Beta: 0.0000) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0273, recon=0.0270, kl=36.3494, beta=0.0000\n",
      "Batch 40, loss=0.0396, recon=0.0393, kl=36.7879, beta=0.0000\n",
      "Batch 60, loss=0.0340, recon=0.0337, kl=36.1284, beta=0.0000\n",
      "Batch 80, loss=0.0511, recon=0.0509, kl=28.2433, beta=0.0000\n",
      "Batch 100, loss=0.0418, recon=0.0416, kl=30.5575, beta=0.0000\n",
      "Batch 120, loss=0.0479, recon=0.0477, kl=26.1953, beta=0.0000\n",
      "Batch 140, loss=0.0273, recon=0.0270, kl=46.7788, beta=0.0000\n",
      "Batch 160, loss=0.0314, recon=0.0310, kl=51.3677, beta=0.0000\n",
      "Batch 180, loss=0.0393, recon=0.0389, kl=45.4869, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0439 (Recon: 0.0436, KL: 36.9773, Current Beta: 0.0000) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0456, recon=0.0450, kl=33.0678, beta=0.0000\n",
      "Batch 40, loss=0.0506, recon=0.0500, kl=29.4080, beta=0.0000\n",
      "Batch 60, loss=0.0304, recon=0.0299, kl=27.3572, beta=0.0000\n",
      "Batch 80, loss=0.0319, recon=0.0315, kl=19.4081, beta=0.0000\n",
      "Batch 100, loss=0.0561, recon=0.0558, kl=15.4281, beta=0.0000\n",
      "Batch 120, loss=0.0526, recon=0.0524, kl=16.1251, beta=0.0000\n",
      "Batch 140, loss=0.0633, recon=0.0630, kl=14.1462, beta=0.0000\n",
      "Batch 160, loss=0.0203, recon=0.0201, kl=12.7595, beta=0.0000\n",
      "Batch 180, loss=0.0354, recon=0.0351, kl=12.7440, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0415, KL: 21.4750, Current Beta: 0.0000) | Avg Valid Loss: 0.0360 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0708, recon=0.0705, kl=9.3351, beta=0.0000\n",
      "Batch 40, loss=0.0260, recon=0.0256, kl=9.4048, beta=0.0000\n",
      "Batch 60, loss=0.0266, recon=0.0262, kl=12.0988, beta=0.0000\n",
      "Batch 80, loss=0.0322, recon=0.0318, kl=9.5138, beta=0.0000\n",
      "Batch 100, loss=0.0244, recon=0.0242, kl=7.3037, beta=0.0000\n",
      "Batch 120, loss=0.0241, recon=0.0238, kl=8.4806, beta=0.0000\n",
      "Batch 140, loss=0.0310, recon=0.0307, kl=7.6217, beta=0.0000\n",
      "Batch 160, loss=0.0391, recon=0.0389, kl=5.2255, beta=0.0000\n",
      "Batch 180, loss=0.0524, recon=0.0514, kl=26.4320, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0421, KL: 10.1562, Current Beta: 0.0000) | Avg Valid Loss: 0.0462 | Avg Valid recon Loss: 0.0453\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0345, recon=0.0334, kl=18.0473, beta=0.0001\n",
      "Batch 40, loss=0.0394, recon=0.0386, kl=13.0450, beta=0.0001\n",
      "Batch 60, loss=0.0494, recon=0.0487, kl=11.5978, beta=0.0001\n",
      "Batch 80, loss=0.0544, recon=0.0537, kl=10.6134, beta=0.0001\n",
      "Batch 100, loss=0.0576, recon=0.0571, kl=8.0486, beta=0.0001\n",
      "Batch 120, loss=0.0298, recon=0.0288, kl=15.3396, beta=0.0001\n",
      "Batch 140, loss=0.0294, recon=0.0277, kl=26.5384, beta=0.0001\n",
      "Batch 160, loss=0.0601, recon=0.0558, kl=69.2034, beta=0.0001\n",
      "Batch 180, loss=0.0333, recon=0.0286, kl=75.0481, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1286 (Recon: 0.1271, KL: 25.0283, Current Beta: 0.0001) | Avg Valid Loss: 0.0419 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0585, recon=0.0560, kl=24.8270, beta=0.0001\n",
      "Batch 40, loss=0.0434, recon=0.0415, kl=19.3727, beta=0.0001\n",
      "Batch 60, loss=0.0349, recon=0.0305, kl=43.4684, beta=0.0001\n",
      "Batch 80, loss=0.0523, recon=0.0496, kl=27.1197, beta=0.0001\n",
      "Batch 100, loss=0.0280, recon=0.0264, kl=16.7368, beta=0.0001\n",
      "Batch 120, loss=0.0380, recon=0.0362, kl=17.7395, beta=0.0001\n",
      "Batch 140, loss=0.0518, recon=0.0443, kl=75.0042, beta=0.0001\n",
      "Batch 160, loss=0.0395, recon=0.0334, kl=60.9657, beta=0.0001\n",
      "Batch 180, loss=0.0327, recon=0.0274, kl=53.3089, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0464 (Recon: 0.0423, KL: 41.3670, Current Beta: 0.0001) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0359\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0323, recon=0.0278, kl=44.6557, beta=0.0001\n",
      "Batch 40, loss=0.0377, recon=0.0347, kl=29.6314, beta=0.0001\n",
      "Batch 60, loss=0.0569, recon=0.0553, kl=15.5891, beta=0.0001\n",
      "Batch 80, loss=0.0373, recon=0.0359, kl=14.2450, beta=0.0001\n",
      "Batch 100, loss=0.0420, recon=0.0411, kl=8.9574, beta=0.0001\n",
      "Batch 120, loss=0.0284, recon=0.0275, kl=9.1828, beta=0.0001\n",
      "Batch 140, loss=0.0220, recon=0.0204, kl=16.1337, beta=0.0001\n",
      "Batch 160, loss=0.0292, recon=0.0274, kl=17.6017, beta=0.0001\n",
      "Batch 180, loss=0.1590, recon=0.1576, kl=13.7530, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0416, KL: 20.5931, Current Beta: 0.0001) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0393, recon=0.0382, kl=10.8749, beta=0.0001\n",
      "Batch 40, loss=0.0378, recon=0.0362, kl=15.9417, beta=0.0001\n",
      "Batch 60, loss=0.0399, recon=0.0375, kl=24.1976, beta=0.0001\n",
      "Batch 80, loss=0.0449, recon=0.0432, kl=16.4642, beta=0.0001\n",
      "Batch 100, loss=0.0308, recon=0.0295, kl=12.9429, beta=0.0001\n",
      "Batch 120, loss=0.0255, recon=0.0244, kl=10.9825, beta=0.0001\n",
      "Batch 140, loss=0.0313, recon=0.0300, kl=12.7816, beta=0.0001\n",
      "Batch 160, loss=0.0374, recon=0.0363, kl=11.1470, beta=0.0001\n",
      "Batch 180, loss=0.0434, recon=0.0418, kl=15.5343, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0467 (Recon: 0.0453, KL: 14.6336, Current Beta: 0.0001) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0601, recon=0.0586, kl=14.9964, beta=0.0001\n",
      "Batch 40, loss=0.0384, recon=0.0371, kl=12.7256, beta=0.0001\n",
      "Batch 60, loss=0.0323, recon=0.0313, kl=9.9016, beta=0.0001\n",
      "Batch 80, loss=0.0393, recon=0.0385, kl=8.9523, beta=0.0001\n",
      "Batch 100, loss=0.0923, recon=0.0878, kl=45.2998, beta=0.0001\n",
      "Batch 120, loss=0.0801, recon=0.0741, kl=59.9854, beta=0.0001\n",
      "Batch 140, loss=0.0468, recon=0.0411, kl=57.6339, beta=0.0001\n",
      "Batch 160, loss=0.0458, recon=0.0406, kl=52.4924, beta=0.0001\n",
      "Batch 180, loss=0.0674, recon=0.0630, kl=44.5449, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0670 (Recon: 0.0637, KL: 32.5730, Current Beta: 0.0001) | Avg Valid Loss: 0.0532 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0394, recon=0.0366, kl=27.8017, beta=0.0001\n",
      "Batch 40, loss=0.0621, recon=0.0606, kl=15.0056, beta=0.0001\n",
      "Batch 60, loss=0.0365, recon=0.0348, kl=16.6320, beta=0.0001\n",
      "Batch 80, loss=0.0336, recon=0.0325, kl=11.3961, beta=0.0001\n",
      "Batch 100, loss=0.0671, recon=0.0661, kl=10.3092, beta=0.0001\n",
      "Batch 120, loss=0.0418, recon=0.0408, kl=10.1267, beta=0.0001\n",
      "Batch 140, loss=0.0727, recon=0.0720, kl=7.5440, beta=0.0001\n",
      "Batch 160, loss=0.0430, recon=0.0419, kl=10.6170, beta=0.0001\n",
      "Batch 180, loss=0.0521, recon=0.0511, kl=10.1800, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0522 (Recon: 0.0506, KL: 15.3061, Current Beta: 0.0001) | Avg Valid Loss: 0.0526 | Avg Valid recon Loss: 0.0515\n",
      "\n",
      "[VRAE Run 13/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4091, recon=0.4091, kl=0.3551, beta=0.0000\n",
      "Batch 40, loss=0.2529, recon=0.2529, kl=11.9379, beta=0.0000\n",
      "Batch 60, loss=0.1751, recon=0.1751, kl=26.4557, beta=0.0000\n",
      "Batch 80, loss=0.2109, recon=0.2109, kl=29.4808, beta=0.0000\n",
      "Batch 100, loss=0.8078, recon=0.8078, kl=28.0757, beta=0.0000\n",
      "Batch 120, loss=0.1045, recon=0.1045, kl=31.6801, beta=0.0000\n",
      "Batch 140, loss=0.1283, recon=0.1283, kl=34.2040, beta=0.0000\n",
      "Batch 160, loss=0.1354, recon=0.1354, kl=36.4038, beta=0.0000\n",
      "Batch 180, loss=0.1267, recon=0.1267, kl=38.4275, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2299 (Recon: 0.2299, KL: 24.1954, Current Beta: 0.0000) | Avg Valid Loss: 0.0955 | Avg Valid recon Loss: 0.0955\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1241, recon=0.1241, kl=40.1755, beta=0.0000\n",
      "Batch 40, loss=0.0792, recon=0.0792, kl=42.2214, beta=0.0000\n",
      "Batch 60, loss=0.1113, recon=0.1113, kl=40.7003, beta=0.0000\n",
      "Batch 80, loss=0.0810, recon=0.0810, kl=51.2981, beta=0.0000\n",
      "Batch 100, loss=0.0718, recon=0.0718, kl=48.4493, beta=0.0000\n",
      "Batch 120, loss=0.1320, recon=0.1320, kl=49.7610, beta=0.0000\n",
      "Batch 140, loss=0.1069, recon=0.1069, kl=43.4684, beta=0.0000\n",
      "Batch 160, loss=0.0593, recon=0.0593, kl=38.9807, beta=0.0000\n",
      "Batch 180, loss=0.0589, recon=0.0589, kl=40.3402, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1102 (Recon: 0.1102, KL: 43.7641, Current Beta: 0.0000) | Avg Valid Loss: 0.0699 | Avg Valid recon Loss: 0.0699\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0563, recon=0.0563, kl=40.5577, beta=0.0000\n",
      "Batch 40, loss=0.0745, recon=0.0745, kl=41.6448, beta=0.0000\n",
      "Batch 60, loss=0.0596, recon=0.0596, kl=43.6955, beta=0.0000\n",
      "Batch 80, loss=0.0638, recon=0.0638, kl=42.1214, beta=0.0000\n",
      "Batch 100, loss=0.0517, recon=0.0517, kl=40.3165, beta=0.0000\n",
      "Batch 120, loss=0.0471, recon=0.0471, kl=42.3861, beta=0.0000\n",
      "Batch 140, loss=0.0560, recon=0.0560, kl=42.9871, beta=0.0000\n",
      "Batch 160, loss=1.4225, recon=1.4225, kl=43.6405, beta=0.0000\n",
      "Batch 180, loss=0.0600, recon=0.0600, kl=42.3068, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0832 (Recon: 0.0832, KL: 42.0581, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0577, recon=0.0577, kl=46.0533, beta=0.0000\n",
      "Batch 40, loss=0.0505, recon=0.0505, kl=48.8467, beta=0.0000\n",
      "Batch 60, loss=0.0785, recon=0.0785, kl=47.8089, beta=0.0000\n",
      "Batch 80, loss=0.0925, recon=0.0925, kl=45.0164, beta=0.0000\n",
      "Batch 100, loss=0.0564, recon=0.0564, kl=43.0402, beta=0.0000\n",
      "Batch 120, loss=0.0357, recon=0.0357, kl=44.7888, beta=0.0000\n",
      "Batch 140, loss=0.0837, recon=0.0837, kl=43.2921, beta=0.0000\n",
      "Batch 160, loss=0.0616, recon=0.0616, kl=45.5842, beta=0.0000\n",
      "Batch 180, loss=0.0592, recon=0.0592, kl=45.5229, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0700 (Recon: 0.0700, KL: 45.6882, Current Beta: 0.0000) | Avg Valid Loss: 0.0551 | Avg Valid recon Loss: 0.0551\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0411, recon=0.0411, kl=47.6248, beta=0.0000\n",
      "Batch 40, loss=0.1994, recon=0.1994, kl=49.1322, beta=0.0000\n",
      "Batch 60, loss=0.0658, recon=0.0658, kl=47.3063, beta=0.0000\n",
      "Batch 80, loss=0.0639, recon=0.0639, kl=47.2583, beta=0.0000\n",
      "Batch 100, loss=0.0540, recon=0.0540, kl=45.1764, beta=0.0000\n",
      "Batch 120, loss=0.0326, recon=0.0326, kl=46.1113, beta=0.0000\n",
      "Batch 140, loss=0.0566, recon=0.0566, kl=46.5606, beta=0.0000\n",
      "Batch 160, loss=0.0392, recon=0.0392, kl=44.9172, beta=0.0000\n",
      "Batch 180, loss=1.0345, recon=1.0345, kl=46.3475, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0619 (Recon: 0.0619, KL: 46.9166, Current Beta: 0.0000) | Avg Valid Loss: 0.0517 | Avg Valid recon Loss: 0.0517\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0886, recon=0.0886, kl=47.9892, beta=0.0000\n",
      "Batch 40, loss=0.0365, recon=0.0365, kl=48.6905, beta=0.0000\n",
      "Batch 60, loss=0.0424, recon=0.0424, kl=46.8343, beta=0.0000\n",
      "Batch 80, loss=0.0381, recon=0.0381, kl=47.6145, beta=0.0000\n",
      "Batch 100, loss=0.0348, recon=0.0348, kl=46.8849, beta=0.0000\n",
      "Batch 120, loss=0.0577, recon=0.0577, kl=46.4352, beta=0.0000\n",
      "Batch 140, loss=0.0375, recon=0.0375, kl=45.1796, beta=0.0000\n",
      "Batch 160, loss=0.0517, recon=0.0517, kl=45.3791, beta=0.0000\n",
      "Batch 180, loss=0.0502, recon=0.0502, kl=44.1464, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0560 (Recon: 0.0560, KL: 46.5443, Current Beta: 0.0000) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0466\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0449, recon=0.0449, kl=43.8757, beta=0.0000\n",
      "Batch 40, loss=0.0520, recon=0.0520, kl=43.3208, beta=0.0000\n",
      "Batch 60, loss=0.0353, recon=0.0353, kl=43.4583, beta=0.0000\n",
      "Batch 80, loss=0.0254, recon=0.0254, kl=48.1207, beta=0.0000\n",
      "Batch 100, loss=0.0329, recon=0.0329, kl=43.3181, beta=0.0000\n",
      "Batch 120, loss=0.0282, recon=0.0281, kl=41.5977, beta=0.0000\n",
      "Batch 140, loss=0.1339, recon=0.1339, kl=41.7442, beta=0.0000\n",
      "Batch 160, loss=0.0547, recon=0.0547, kl=41.3129, beta=0.0000\n",
      "Batch 180, loss=0.0541, recon=0.0541, kl=39.9053, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0521 (Recon: 0.0521, KL: 43.0598, Current Beta: 0.0000) | Avg Valid Loss: 0.0428 | Avg Valid recon Loss: 0.0428\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0440, recon=0.0439, kl=39.7077, beta=0.0000\n",
      "Batch 40, loss=0.0488, recon=0.0488, kl=36.8817, beta=0.0000\n",
      "Batch 60, loss=0.0312, recon=0.0312, kl=35.0314, beta=0.0000\n",
      "Batch 80, loss=0.0381, recon=0.0381, kl=33.7075, beta=0.0000\n",
      "Batch 100, loss=0.0274, recon=0.0274, kl=32.4558, beta=0.0000\n",
      "Batch 120, loss=0.0316, recon=0.0316, kl=32.1902, beta=0.0000\n",
      "Batch 140, loss=0.0552, recon=0.0552, kl=32.0308, beta=0.0000\n",
      "Batch 160, loss=0.0358, recon=0.0358, kl=32.6394, beta=0.0000\n",
      "Batch 180, loss=0.0373, recon=0.0373, kl=33.0962, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0487 (Recon: 0.0487, KL: 34.1050, Current Beta: 0.0000) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0364, recon=0.0364, kl=32.6294, beta=0.0000\n",
      "Batch 40, loss=0.0324, recon=0.0324, kl=28.2696, beta=0.0000\n",
      "Batch 60, loss=0.0359, recon=0.0358, kl=27.2671, beta=0.0000\n",
      "Batch 80, loss=0.0333, recon=0.0333, kl=25.1284, beta=0.0000\n",
      "Batch 100, loss=0.0228, recon=0.0228, kl=25.4260, beta=0.0000\n",
      "Batch 120, loss=0.0475, recon=0.0475, kl=24.9085, beta=0.0000\n",
      "Batch 140, loss=0.0446, recon=0.0446, kl=26.0404, beta=0.0000\n",
      "Batch 160, loss=0.0405, recon=0.0405, kl=25.4558, beta=0.0000\n",
      "Batch 180, loss=0.0196, recon=0.0196, kl=25.1748, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0465 (Recon: 0.0465, KL: 27.0607, Current Beta: 0.0000) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0270, recon=0.0270, kl=20.5853, beta=0.0000\n",
      "Batch 40, loss=0.0443, recon=0.0443, kl=17.7339, beta=0.0000\n",
      "Batch 60, loss=0.0359, recon=0.0359, kl=14.7638, beta=0.0000\n",
      "Batch 80, loss=0.0217, recon=0.0217, kl=16.1352, beta=0.0000\n",
      "Batch 100, loss=0.0278, recon=0.0278, kl=17.5013, beta=0.0000\n",
      "Batch 120, loss=0.0479, recon=0.0478, kl=17.7908, beta=0.0000\n",
      "Batch 140, loss=0.0388, recon=0.0388, kl=15.5474, beta=0.0000\n",
      "Batch 160, loss=0.0295, recon=0.0295, kl=14.8746, beta=0.0000\n",
      "Batch 180, loss=0.0494, recon=0.0494, kl=15.5564, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0445 (Recon: 0.0445, KL: 17.2864, Current Beta: 0.0000) | Avg Valid Loss: 0.0378 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0409, recon=0.0408, kl=11.9039, beta=0.0000\n",
      "Batch 40, loss=0.0250, recon=0.0250, kl=9.2324, beta=0.0000\n",
      "Batch 60, loss=0.0267, recon=0.0266, kl=8.9671, beta=0.0000\n",
      "Batch 80, loss=0.0313, recon=0.0313, kl=9.1277, beta=0.0000\n",
      "Batch 100, loss=0.0367, recon=0.0366, kl=11.3953, beta=0.0000\n",
      "Batch 120, loss=0.0400, recon=0.0400, kl=9.8701, beta=0.0000\n",
      "Batch 140, loss=0.0338, recon=0.0338, kl=9.0006, beta=0.0000\n",
      "Batch 160, loss=0.0350, recon=0.0350, kl=8.4927, beta=0.0000\n",
      "Batch 180, loss=0.0304, recon=0.0304, kl=8.1350, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0429, KL: 9.9369, Current Beta: 0.0000) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0290, recon=0.0289, kl=5.6466, beta=0.0000\n",
      "Batch 40, loss=0.0279, recon=0.0279, kl=4.5291, beta=0.0000\n",
      "Batch 60, loss=0.0399, recon=0.0399, kl=4.2739, beta=0.0000\n",
      "Batch 80, loss=0.1126, recon=0.1125, kl=4.7566, beta=0.0000\n",
      "Batch 100, loss=0.0291, recon=0.0291, kl=3.8787, beta=0.0000\n",
      "Batch 120, loss=0.0284, recon=0.0284, kl=3.7014, beta=0.0000\n",
      "Batch 140, loss=0.0403, recon=0.0402, kl=3.6603, beta=0.0000\n",
      "Batch 160, loss=0.0546, recon=0.0546, kl=3.9805, beta=0.0000\n",
      "Batch 180, loss=0.0248, recon=0.0247, kl=3.4019, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0414, KL: 4.3720, Current Beta: 0.0000) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0346\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0362, recon=0.0362, kl=1.7571, beta=0.0000\n",
      "Batch 40, loss=0.0434, recon=0.0433, kl=2.0765, beta=0.0000\n",
      "Batch 60, loss=0.0199, recon=0.0199, kl=2.3074, beta=0.0000\n",
      "Batch 80, loss=0.0214, recon=0.0214, kl=1.8479, beta=0.0000\n",
      "Batch 100, loss=0.0294, recon=0.0294, kl=1.6030, beta=0.0000\n",
      "Batch 120, loss=0.0217, recon=0.0217, kl=1.5657, beta=0.0000\n",
      "Batch 140, loss=0.0476, recon=0.0476, kl=1.6491, beta=0.0000\n",
      "Batch 160, loss=0.0352, recon=0.0352, kl=1.3645, beta=0.0000\n",
      "Batch 180, loss=0.0391, recon=0.0391, kl=1.5206, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0403 (Recon: 0.0403, KL: 1.8474, Current Beta: 0.0000) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0343, recon=0.0343, kl=0.8995, beta=0.0000\n",
      "Batch 40, loss=0.0358, recon=0.0357, kl=0.6673, beta=0.0000\n",
      "Batch 60, loss=0.0312, recon=0.0312, kl=0.5422, beta=0.0000\n",
      "Batch 80, loss=0.0253, recon=0.0253, kl=0.5829, beta=0.0000\n",
      "Batch 100, loss=0.0303, recon=0.0303, kl=0.5279, beta=0.0000\n",
      "Batch 120, loss=0.0227, recon=0.0227, kl=0.9763, beta=0.0000\n",
      "Batch 140, loss=0.0422, recon=0.0422, kl=0.5722, beta=0.0000\n",
      "Batch 160, loss=0.0239, recon=0.0239, kl=0.6086, beta=0.0000\n",
      "Batch 180, loss=0.0322, recon=0.0322, kl=0.6495, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0392, KL: 0.7029, Current Beta: 0.0000) | Avg Valid Loss: 0.0331 | Avg Valid recon Loss: 0.0331\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0294, recon=0.0294, kl=0.3102, beta=0.0001\n",
      "Batch 40, loss=0.0208, recon=0.0208, kl=0.2816, beta=0.0001\n",
      "Batch 60, loss=0.0231, recon=0.0231, kl=0.2405, beta=0.0001\n",
      "Batch 80, loss=0.0454, recon=0.0454, kl=0.1728, beta=0.0001\n",
      "Batch 100, loss=0.0203, recon=0.0203, kl=0.1494, beta=0.0001\n",
      "Batch 120, loss=0.0399, recon=0.0399, kl=0.3703, beta=0.0001\n",
      "Batch 140, loss=0.0284, recon=0.0283, kl=0.2120, beta=0.0001\n",
      "Batch 160, loss=0.0324, recon=0.0324, kl=0.1112, beta=0.0001\n",
      "Batch 180, loss=0.0225, recon=0.0224, kl=0.1413, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0384 (Recon: 0.0384, KL: 0.2380, Current Beta: 0.0001) | Avg Valid Loss: 0.0325 | Avg Valid recon Loss: 0.0324\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0300, recon=0.0300, kl=0.1619, beta=0.0001\n",
      "Batch 40, loss=0.0412, recon=0.0411, kl=0.0362, beta=0.0001\n",
      "Batch 60, loss=0.0314, recon=0.0314, kl=0.1212, beta=0.0001\n",
      "Batch 80, loss=0.0176, recon=0.0176, kl=0.0531, beta=0.0001\n",
      "Batch 100, loss=0.0348, recon=0.0348, kl=0.0180, beta=0.0001\n",
      "Batch 120, loss=0.0274, recon=0.0274, kl=0.0731, beta=0.0001\n",
      "Batch 140, loss=0.0282, recon=0.0282, kl=0.0309, beta=0.0001\n",
      "Batch 160, loss=0.0185, recon=0.0185, kl=0.0294, beta=0.0001\n",
      "Batch 180, loss=0.0303, recon=0.0303, kl=0.0251, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0376, KL: 0.0678, Current Beta: 0.0001) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0251, recon=0.0251, kl=0.0225, beta=0.0001\n",
      "Batch 40, loss=0.0375, recon=0.0375, kl=0.0339, beta=0.0001\n",
      "Batch 60, loss=0.0308, recon=0.0308, kl=0.0241, beta=0.0001\n",
      "Batch 80, loss=0.0164, recon=0.0164, kl=0.0342, beta=0.0001\n",
      "Batch 100, loss=0.0697, recon=0.0697, kl=0.0302, beta=0.0001\n",
      "Batch 120, loss=0.0228, recon=0.0228, kl=0.0148, beta=0.0001\n",
      "Batch 140, loss=0.0272, recon=0.0272, kl=0.0164, beta=0.0001\n",
      "Batch 160, loss=0.0306, recon=0.0306, kl=0.0091, beta=0.0001\n",
      "Batch 180, loss=0.0352, recon=0.0352, kl=0.0655, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0367 (Recon: 0.0367, KL: 0.0259, Current Beta: 0.0001) | Avg Valid Loss: 0.0311 | Avg Valid recon Loss: 0.0311\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0220, recon=0.0220, kl=0.0122, beta=0.0001\n",
      "Batch 40, loss=0.0240, recon=0.0240, kl=0.0148, beta=0.0001\n",
      "Batch 60, loss=0.0286, recon=0.0286, kl=0.0077, beta=0.0001\n",
      "Batch 80, loss=0.0252, recon=0.0252, kl=0.0116, beta=0.0001\n",
      "Batch 100, loss=0.0304, recon=0.0304, kl=0.0097, beta=0.0001\n",
      "Batch 120, loss=0.0386, recon=0.0386, kl=0.0139, beta=0.0001\n",
      "Batch 140, loss=0.0695, recon=0.0695, kl=0.0059, beta=0.0001\n",
      "Batch 160, loss=0.0245, recon=0.0245, kl=0.0116, beta=0.0001\n",
      "Batch 180, loss=0.0407, recon=0.0407, kl=0.0094, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0362, KL: 0.0147, Current Beta: 0.0001) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0304\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0654, recon=0.0654, kl=0.0123, beta=0.0001\n",
      "Batch 40, loss=0.0347, recon=0.0347, kl=0.0083, beta=0.0001\n",
      "Batch 60, loss=0.0276, recon=0.0276, kl=0.0371, beta=0.0001\n",
      "Batch 80, loss=0.0254, recon=0.0254, kl=0.0135, beta=0.0001\n",
      "Batch 100, loss=0.0221, recon=0.0221, kl=0.0074, beta=0.0001\n",
      "Batch 120, loss=0.0438, recon=0.0438, kl=0.0063, beta=0.0001\n",
      "Batch 140, loss=0.0420, recon=0.0420, kl=0.0090, beta=0.0001\n",
      "Batch 160, loss=0.0313, recon=0.0313, kl=0.0071, beta=0.0001\n",
      "Batch 180, loss=0.0233, recon=0.0233, kl=0.0082, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0357 (Recon: 0.0357, KL: 0.0116, Current Beta: 0.0001) | Avg Valid Loss: 0.0305 | Avg Valid recon Loss: 0.0305\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0406, recon=0.0406, kl=0.0077, beta=0.0001\n",
      "Batch 40, loss=0.0231, recon=0.0231, kl=0.0032, beta=0.0001\n",
      "Batch 60, loss=0.0290, recon=0.0290, kl=0.0118, beta=0.0001\n",
      "Batch 80, loss=0.0350, recon=0.0350, kl=0.0199, beta=0.0001\n",
      "Batch 100, loss=0.0278, recon=0.0278, kl=0.0032, beta=0.0001\n",
      "Batch 120, loss=0.0247, recon=0.0247, kl=0.0087, beta=0.0001\n",
      "Batch 140, loss=0.0421, recon=0.0421, kl=0.0137, beta=0.0001\n",
      "Batch 160, loss=0.1680, recon=0.1680, kl=0.0028, beta=0.0001\n",
      "Batch 180, loss=0.0506, recon=0.0506, kl=0.0087, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0350 (Recon: 0.0350, KL: 0.0097, Current Beta: 0.0001) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0304\n",
      " New best VRAE model found with validation loss: 0.0304\n",
      "   Model saved to ./ecg_model_logs\\best_vrae_model.pth\n",
      "\n",
      "[VRAE Run 14/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1506, recon=0.1506, kl=25.3097, beta=0.0000\n",
      "Batch 40, loss=0.1034, recon=0.1034, kl=27.7297, beta=0.0000\n",
      "Batch 60, loss=0.0473, recon=0.0473, kl=22.0931, beta=0.0000\n",
      "Batch 80, loss=0.0723, recon=0.0723, kl=24.3202, beta=0.0000\n",
      "Batch 100, loss=0.0733, recon=0.0733, kl=28.1782, beta=0.0000\n",
      "Batch 120, loss=0.0420, recon=0.0420, kl=24.7360, beta=0.0000\n",
      "Batch 140, loss=0.0516, recon=0.0516, kl=29.8235, beta=0.0000\n",
      "Batch 160, loss=0.0430, recon=0.0430, kl=30.2283, beta=0.0000\n",
      "Batch 180, loss=0.0643, recon=0.0643, kl=28.1102, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1157 (Recon: 0.1157, KL: 25.2381, Current Beta: 0.0000) | Avg Valid Loss: 0.0551 | Avg Valid recon Loss: 0.0551\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0437, recon=0.0437, kl=29.0374, beta=0.0000\n",
      "Batch 40, loss=0.0288, recon=0.0288, kl=28.4195, beta=0.0000\n",
      "Batch 60, loss=0.0548, recon=0.0548, kl=30.0677, beta=0.0000\n",
      "Batch 80, loss=0.0575, recon=0.0575, kl=32.7818, beta=0.0000\n",
      "Batch 100, loss=0.0684, recon=0.0684, kl=30.2734, beta=0.0000\n",
      "Batch 120, loss=0.0400, recon=0.0400, kl=29.8294, beta=0.0000\n",
      "Batch 140, loss=0.0330, recon=0.0330, kl=30.5479, beta=0.0000\n",
      "Batch 160, loss=0.0564, recon=0.0564, kl=32.4993, beta=0.0000\n",
      "Batch 180, loss=0.0390, recon=0.0390, kl=37.0182, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0581, KL: 30.6134, Current Beta: 0.0000) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0266, recon=0.0266, kl=35.7685, beta=0.0000\n",
      "Batch 40, loss=0.0712, recon=0.0712, kl=37.8351, beta=0.0000\n",
      "Batch 60, loss=0.7295, recon=0.7295, kl=36.9892, beta=0.0000\n",
      "Batch 80, loss=0.0462, recon=0.0462, kl=37.9478, beta=0.0000\n",
      "Batch 100, loss=0.0345, recon=0.0345, kl=38.1277, beta=0.0000\n",
      "Batch 120, loss=0.0291, recon=0.0291, kl=37.3106, beta=0.0000\n",
      "Batch 140, loss=0.0275, recon=0.0275, kl=35.8180, beta=0.0000\n",
      "Batch 160, loss=0.0422, recon=0.0422, kl=39.3114, beta=0.0000\n",
      "Batch 180, loss=0.0434, recon=0.0434, kl=35.4088, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0506 (Recon: 0.0506, KL: 37.1381, Current Beta: 0.0000) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0401, recon=0.0401, kl=37.5386, beta=0.0000\n",
      "Batch 40, loss=0.0351, recon=0.0351, kl=41.2746, beta=0.0000\n",
      "Batch 60, loss=0.0356, recon=0.0356, kl=40.7826, beta=0.0000\n",
      "Batch 80, loss=0.0252, recon=0.0252, kl=34.5481, beta=0.0000\n",
      "Batch 100, loss=0.0396, recon=0.0396, kl=30.5081, beta=0.0000\n",
      "Batch 120, loss=0.0290, recon=0.0290, kl=32.2737, beta=0.0000\n",
      "Batch 140, loss=0.0356, recon=0.0356, kl=32.8738, beta=0.0000\n",
      "Batch 160, loss=0.0603, recon=0.0603, kl=53.9201, beta=0.0000\n",
      "Batch 180, loss=0.0347, recon=0.0347, kl=73.1254, beta=0.0000\n",
      "  â†’ Avg Train Loss: 80065.8852 (Recon: 80065.8852, KL: 506337.0587, Current Beta: 0.0000) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0281, recon=0.0281, kl=79.6884, beta=0.0000\n",
      "Batch 40, loss=0.0504, recon=0.0504, kl=78.3923, beta=0.0000\n",
      "Batch 60, loss=0.0365, recon=0.0365, kl=76.0643, beta=0.0000\n",
      "Batch 80, loss=0.0892, recon=0.0892, kl=73.6655, beta=0.0000\n",
      "Batch 100, loss=0.0316, recon=0.0316, kl=78.2106, beta=0.0000\n",
      "Batch 120, loss=0.0309, recon=0.0309, kl=73.5774, beta=0.0000\n",
      "Batch 140, loss=0.0314, recon=0.0314, kl=76.5307, beta=0.0000\n",
      "Batch 160, loss=0.0308, recon=0.0308, kl=73.4376, beta=0.0000\n",
      "Batch 180, loss=0.0399, recon=0.0399, kl=72.4625, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0828 (Recon: 0.0828, KL: 75.5138, Current Beta: 0.0000) | Avg Valid Loss: 0.0513 | Avg Valid recon Loss: 0.0513\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0439, recon=0.0439, kl=71.0728, beta=0.0000\n",
      "Batch 40, loss=0.0517, recon=0.0517, kl=70.8818, beta=0.0000\n",
      "Batch 60, loss=0.0664, recon=0.0664, kl=74.3628, beta=0.0000\n",
      "Batch 80, loss=0.0359, recon=0.0359, kl=72.3013, beta=0.0000\n",
      "Batch 100, loss=0.0358, recon=0.0358, kl=75.0733, beta=0.0000\n",
      "Batch 120, loss=0.0327, recon=0.0327, kl=76.9384, beta=0.0000\n",
      "Batch 140, loss=0.0422, recon=0.0422, kl=71.9661, beta=0.0000\n",
      "Batch 160, loss=0.0468, recon=0.0468, kl=65.7263, beta=0.0000\n",
      "Batch 180, loss=0.0643, recon=0.0643, kl=68.2628, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 71.3149, Current Beta: 0.0000) | Avg Valid Loss: 0.0861 | Avg Valid recon Loss: 0.0861\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0250, recon=0.0250, kl=69.4645, beta=0.0000\n",
      "Batch 40, loss=0.0315, recon=0.0315, kl=67.9490, beta=0.0000\n",
      "Batch 60, loss=0.0471, recon=0.0471, kl=70.5102, beta=0.0000\n",
      "Batch 80, loss=0.0460, recon=0.0460, kl=68.7632, beta=0.0000\n",
      "Batch 100, loss=0.0614, recon=0.0614, kl=82.3012, beta=0.0000\n",
      "Batch 120, loss=0.0887, recon=0.0887, kl=83.8365, beta=0.0000\n",
      "Batch 140, loss=0.0706, recon=0.0706, kl=82.2770, beta=0.0000\n",
      "Batch 160, loss=0.0428, recon=0.0428, kl=80.8402, beta=0.0000\n",
      "Batch 180, loss=0.0705, recon=0.0705, kl=80.4681, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1489 (Recon: 0.1489, KL: 75.6764, Current Beta: 0.0000) | Avg Valid Loss: 0.0571 | Avg Valid recon Loss: 0.0571\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0404, recon=0.0404, kl=80.5041, beta=0.0000\n",
      "Batch 40, loss=0.0329, recon=0.0329, kl=79.6753, beta=0.0000\n",
      "Batch 60, loss=0.0582, recon=0.0582, kl=81.3211, beta=0.0000\n",
      "Batch 80, loss=0.0652, recon=0.0652, kl=81.2488, beta=0.0000\n",
      "Batch 100, loss=0.1268, recon=0.1268, kl=81.0525, beta=0.0000\n",
      "Batch 120, loss=0.0480, recon=0.0480, kl=79.5576, beta=0.0000\n",
      "Batch 140, loss=0.0687, recon=0.0687, kl=79.7908, beta=0.0000\n",
      "Batch 160, loss=0.0280, recon=0.0280, kl=79.9913, beta=0.0000\n",
      "Batch 180, loss=0.0285, recon=0.0285, kl=78.1717, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 80.0640, Current Beta: 0.0000) | Avg Valid Loss: 0.0505 | Avg Valid recon Loss: 0.0505\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0474, recon=0.0473, kl=78.2296, beta=0.0000\n",
      "Batch 40, loss=0.0483, recon=0.0483, kl=78.6192, beta=0.0000\n",
      "Batch 60, loss=0.0558, recon=0.0557, kl=76.1216, beta=0.0000\n",
      "Batch 80, loss=0.1020, recon=0.1020, kl=102.1088, beta=0.0000\n",
      "Batch 100, loss=0.0601, recon=0.0601, kl=124.0193, beta=0.0000\n",
      "Batch 120, loss=0.0547, recon=0.0547, kl=119.9482, beta=0.0000\n",
      "Batch 140, loss=0.0409, recon=0.0409, kl=132.0421, beta=0.0000\n",
      "Batch 160, loss=0.0365, recon=0.0364, kl=121.1935, beta=0.0000\n",
      "Batch 180, loss=0.0427, recon=0.0427, kl=125.6443, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.7208 (Recon: 0.7208, KL: 104.3323, Current Beta: 0.0000) | Avg Valid Loss: 0.0532 | Avg Valid recon Loss: 0.0531\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0476, recon=0.0475, kl=120.7132, beta=0.0000\n",
      "Batch 40, loss=0.0420, recon=0.0419, kl=117.5787, beta=0.0000\n",
      "Batch 60, loss=0.0293, recon=0.0292, kl=119.9701, beta=0.0000\n",
      "Batch 80, loss=0.0612, recon=0.0610, kl=124.7122, beta=0.0000\n",
      "Batch 100, loss=0.0303, recon=0.0302, kl=119.7973, beta=0.0000\n",
      "Batch 120, loss=0.0544, recon=0.0543, kl=115.7205, beta=0.0000\n",
      "Batch 140, loss=0.0340, recon=0.0339, kl=112.0185, beta=0.0000\n",
      "Batch 160, loss=0.0521, recon=0.0520, kl=117.2462, beta=0.0000\n",
      "Batch 180, loss=0.0524, recon=0.0523, kl=112.5892, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0520 (Recon: 0.0519, KL: 119.2406, Current Beta: 0.0000) | Avg Valid Loss: 0.2044 | Avg Valid recon Loss: 0.2043\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.6387, recon=0.6384, kl=105.9184, beta=0.0000\n",
      "Batch 40, loss=0.0648, recon=0.0645, kl=101.6231, beta=0.0000\n",
      "Batch 60, loss=0.0417, recon=0.0414, kl=103.0841, beta=0.0000\n",
      "Batch 80, loss=0.0397, recon=0.0394, kl=97.5392, beta=0.0000\n",
      "Batch 100, loss=0.0459, recon=0.0456, kl=96.8875, beta=0.0000\n",
      "Batch 120, loss=0.0460, recon=0.0457, kl=93.2338, beta=0.0000\n",
      "Batch 140, loss=0.0355, recon=0.0352, kl=96.8396, beta=0.0000\n",
      "Batch 160, loss=0.0275, recon=0.0272, kl=94.2084, beta=0.0000\n",
      "Batch 180, loss=0.0709, recon=0.0707, kl=91.3399, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0860 (Recon: 0.0857, KL: 97.9229, Current Beta: 0.0000) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0447\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0323, recon=0.0317, kl=87.9016, beta=0.0000\n",
      "Batch 40, loss=0.0582, recon=0.0576, kl=84.5592, beta=0.0000\n",
      "Batch 60, loss=0.0277, recon=0.0271, kl=81.7491, beta=0.0000\n",
      "Batch 80, loss=0.0511, recon=0.0505, kl=82.1322, beta=0.0000\n",
      "Batch 100, loss=0.0596, recon=0.0590, kl=76.9987, beta=0.0000\n",
      "Batch 120, loss=0.0563, recon=0.0558, kl=75.6802, beta=0.0000\n",
      "Batch 140, loss=0.0442, recon=0.0437, kl=69.5124, beta=0.0000\n",
      "Batch 160, loss=0.0371, recon=0.0366, kl=67.9940, beta=0.0000\n",
      "Batch 180, loss=0.0311, recon=0.0306, kl=66.3417, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0530 (Recon: 0.0524, KL: 78.0438, Current Beta: 0.0000) | Avg Valid Loss: 0.0504 | Avg Valid recon Loss: 0.0499\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0360, recon=0.0349, kl=60.1174, beta=0.0000\n",
      "Batch 40, loss=0.0588, recon=0.0578, kl=54.2193, beta=0.0000\n",
      "Batch 60, loss=0.0632, recon=0.0622, kl=51.0871, beta=0.0000\n",
      "Batch 80, loss=0.0452, recon=0.0443, kl=46.5046, beta=0.0000\n",
      "Batch 100, loss=0.1578, recon=0.1570, kl=44.4246, beta=0.0000\n",
      "Batch 120, loss=0.0556, recon=0.0549, kl=41.6192, beta=0.0000\n",
      "Batch 140, loss=0.0277, recon=0.0270, kl=39.4191, beta=0.0000\n",
      "Batch 160, loss=0.0348, recon=0.0341, kl=38.1297, beta=0.0000\n",
      "Batch 180, loss=0.0274, recon=0.0268, kl=35.9219, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0563 (Recon: 0.0554, KL: 47.4054, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0446\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0423, recon=0.0410, kl=33.4452, beta=0.0000\n",
      "Batch 40, loss=0.0511, recon=0.0500, kl=27.8036, beta=0.0000\n",
      "Batch 60, loss=0.0418, recon=0.0408, kl=26.4306, beta=0.0000\n",
      "Batch 80, loss=0.0376, recon=0.0367, kl=25.4556, beta=0.0000\n",
      "Batch 100, loss=0.0351, recon=0.0341, kl=25.0588, beta=0.0000\n",
      "Batch 120, loss=0.0568, recon=0.0559, kl=22.8427, beta=0.0000\n",
      "Batch 140, loss=0.0454, recon=0.0446, kl=20.8662, beta=0.0000\n",
      "Batch 160, loss=0.0554, recon=0.0547, kl=20.2173, beta=0.0000\n",
      "Batch 180, loss=0.0307, recon=0.0301, kl=17.9896, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0548 (Recon: 0.0538, KL: 25.6635, Current Beta: 0.0000) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0473\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0300, recon=0.0289, kl=17.0418, beta=0.0001\n",
      "Batch 40, loss=0.0398, recon=0.0388, kl=15.5748, beta=0.0001\n",
      "Batch 60, loss=0.0470, recon=0.0463, kl=11.6777, beta=0.0001\n",
      "Batch 80, loss=0.1285, recon=0.1276, kl=14.9487, beta=0.0001\n",
      "Batch 100, loss=0.1067, recon=0.1057, kl=16.8546, beta=0.0001\n",
      "Batch 120, loss=0.0830, recon=0.0817, kl=20.7037, beta=0.0001\n",
      "Batch 140, loss=0.0796, recon=0.0776, kl=31.8771, beta=0.0001\n",
      "Batch 160, loss=0.1647, recon=0.1624, kl=35.7705, beta=0.0001\n",
      "Batch 180, loss=0.0604, recon=0.0580, kl=37.9918, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0758 (Recon: 0.0745, KL: 21.7401, Current Beta: 0.0001) | Avg Valid Loss: 0.0673 | Avg Valid recon Loss: 0.0652\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.4786, recon=0.4756, kl=29.7465, beta=0.0001\n",
      "Batch 40, loss=0.6901, recon=0.6868, kl=33.2924, beta=0.0001\n",
      "Batch 60, loss=93.9693, recon=93.9635, kl=57.8010, beta=0.0001\n",
      "Batch 80, loss=8.7049, recon=8.7012, kl=36.6018, beta=0.0001\n",
      "Batch 100, loss=5.3722, recon=5.3695, kl=27.6400, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 15/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2487, recon=0.2487, kl=1.1252, beta=0.0000\n",
      "Batch 40, loss=0.1947, recon=0.1947, kl=36.4000, beta=0.0000\n",
      "Batch 60, loss=0.2134, recon=0.2134, kl=51.1356, beta=0.0000\n",
      "Batch 80, loss=0.1821, recon=0.1821, kl=59.9539, beta=0.0000\n",
      "Batch 100, loss=0.1776, recon=0.1776, kl=60.1143, beta=0.0000\n",
      "Batch 120, loss=0.1555, recon=0.1555, kl=61.7519, beta=0.0000\n",
      "Batch 140, loss=0.1604, recon=0.1604, kl=66.1711, beta=0.0000\n",
      "Batch 160, loss=0.1922, recon=0.1922, kl=72.2073, beta=0.0000\n",
      "Batch 180, loss=0.1050, recon=0.1050, kl=75.1130, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2226 (Recon: 0.2226, KL: 50.2747, Current Beta: 0.0000) | Avg Valid Loss: 0.0967 | Avg Valid recon Loss: 0.0967\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0809, recon=0.0809, kl=78.1055, beta=0.0000\n",
      "Batch 40, loss=0.0984, recon=0.0984, kl=91.3844, beta=0.0000\n",
      "Batch 60, loss=0.2380, recon=0.2380, kl=90.8389, beta=0.0000\n",
      "Batch 80, loss=0.1493, recon=0.1493, kl=92.1158, beta=0.0000\n",
      "Batch 100, loss=0.1439, recon=0.1439, kl=88.5210, beta=0.0000\n",
      "Batch 120, loss=0.0795, recon=0.0795, kl=88.4994, beta=0.0000\n",
      "Batch 140, loss=0.0838, recon=0.0838, kl=86.5156, beta=0.0000\n",
      "Batch 160, loss=0.0889, recon=0.0889, kl=87.1395, beta=0.0000\n",
      "Batch 180, loss=0.1119, recon=0.1119, kl=88.9411, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1114 (Recon: 0.1114, KL: 87.0843, Current Beta: 0.0000) | Avg Valid Loss: 0.0742 | Avg Valid recon Loss: 0.0742\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1188, recon=0.1188, kl=91.9053, beta=0.0000\n",
      "Batch 40, loss=0.0579, recon=0.0579, kl=93.4429, beta=0.0000\n",
      "Batch 60, loss=0.0785, recon=0.0785, kl=91.6341, beta=0.0000\n",
      "Batch 80, loss=0.0526, recon=0.0526, kl=91.4850, beta=0.0000\n",
      "Batch 100, loss=0.0579, recon=0.0579, kl=93.0533, beta=0.0000\n",
      "Batch 120, loss=0.0645, recon=0.0645, kl=88.7106, beta=0.0000\n",
      "Batch 140, loss=0.0504, recon=0.0504, kl=88.4917, beta=0.0000\n",
      "Batch 160, loss=0.0836, recon=0.0836, kl=89.8421, beta=0.0000\n",
      "Batch 180, loss=0.1378, recon=0.1378, kl=85.1977, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0841 (Recon: 0.0841, KL: 90.7236, Current Beta: 0.0000) | Avg Valid Loss: 0.0613 | Avg Valid recon Loss: 0.0613\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0682, recon=0.0682, kl=84.1044, beta=0.0000\n",
      "Batch 40, loss=0.0513, recon=0.0513, kl=88.0364, beta=0.0000\n",
      "Batch 60, loss=0.0506, recon=0.0506, kl=90.1800, beta=0.0000\n",
      "Batch 80, loss=0.0400, recon=0.0400, kl=90.1135, beta=0.0000\n",
      "Batch 100, loss=0.0433, recon=0.0433, kl=90.0150, beta=0.0000\n",
      "Batch 120, loss=0.0659, recon=0.0659, kl=92.2800, beta=0.0000\n",
      "Batch 140, loss=0.0682, recon=0.0682, kl=94.5399, beta=0.0000\n",
      "Batch 160, loss=0.0840, recon=0.0840, kl=93.5479, beta=0.0000\n",
      "Batch 180, loss=0.0744, recon=0.0744, kl=92.5226, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0690 (Recon: 0.0690, KL: 89.6950, Current Beta: 0.0000) | Avg Valid Loss: 0.0555 | Avg Valid recon Loss: 0.0555\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0379, recon=0.0379, kl=93.6222, beta=0.0000\n",
      "Batch 40, loss=0.0443, recon=0.0443, kl=90.1241, beta=0.0000\n",
      "Batch 60, loss=0.0539, recon=0.0539, kl=91.3786, beta=0.0000\n",
      "Batch 80, loss=0.0299, recon=0.0299, kl=89.5879, beta=0.0000\n",
      "Batch 100, loss=0.2656, recon=0.2656, kl=85.7942, beta=0.0000\n",
      "Batch 120, loss=0.0357, recon=0.0357, kl=86.6787, beta=0.0000\n",
      "Batch 140, loss=0.0549, recon=0.0549, kl=88.2001, beta=0.0000\n",
      "Batch 160, loss=0.0368, recon=0.0368, kl=85.6889, beta=0.0000\n",
      "Batch 180, loss=0.0870, recon=0.0870, kl=84.3602, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0608 (Recon: 0.0608, KL: 88.8616, Current Beta: 0.0000) | Avg Valid Loss: 0.0505 | Avg Valid recon Loss: 0.0505\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=83.7770, beta=0.0000\n",
      "Batch 40, loss=0.0531, recon=0.0531, kl=84.5336, beta=0.0000\n",
      "Batch 60, loss=0.0563, recon=0.0563, kl=84.3009, beta=0.0000\n",
      "Batch 80, loss=0.0276, recon=0.0276, kl=80.4125, beta=0.0000\n",
      "Batch 100, loss=0.0517, recon=0.0517, kl=83.7402, beta=0.0000\n",
      "Batch 120, loss=0.0371, recon=0.0371, kl=83.3179, beta=0.0000\n",
      "Batch 140, loss=0.0298, recon=0.0298, kl=81.5618, beta=0.0000\n",
      "Batch 160, loss=0.0652, recon=0.0652, kl=81.7629, beta=0.0000\n",
      "Batch 180, loss=0.0391, recon=0.0391, kl=82.3028, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0553 (Recon: 0.0553, KL: 83.1185, Current Beta: 0.0000) | Avg Valid Loss: 0.0467 | Avg Valid recon Loss: 0.0467\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0369, recon=0.0369, kl=76.0430, beta=0.0000\n",
      "Batch 40, loss=0.0333, recon=0.0333, kl=75.5967, beta=0.0000\n",
      "Batch 60, loss=0.0434, recon=0.0434, kl=72.3925, beta=0.0000\n",
      "Batch 80, loss=0.0324, recon=0.0324, kl=72.8317, beta=0.0000\n",
      "Batch 100, loss=0.0321, recon=0.0321, kl=74.5873, beta=0.0000\n",
      "Batch 120, loss=0.0439, recon=0.0439, kl=73.4034, beta=0.0000\n",
      "Batch 140, loss=0.0840, recon=0.0840, kl=70.3790, beta=0.0000\n",
      "Batch 160, loss=0.0520, recon=0.0519, kl=69.4748, beta=0.0000\n",
      "Batch 180, loss=0.0536, recon=0.0536, kl=68.1650, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0509 (Recon: 0.0508, KL: 73.1219, Current Beta: 0.0000) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0354, recon=0.0354, kl=63.3171, beta=0.0000\n",
      "Batch 40, loss=0.0303, recon=0.0303, kl=61.7364, beta=0.0000\n",
      "Batch 60, loss=0.0403, recon=0.0403, kl=54.7774, beta=0.0000\n",
      "Batch 80, loss=0.0272, recon=0.0272, kl=54.4875, beta=0.0000\n",
      "Batch 100, loss=0.0485, recon=0.0485, kl=53.6937, beta=0.0000\n",
      "Batch 120, loss=0.0430, recon=0.0430, kl=51.5580, beta=0.0000\n",
      "Batch 140, loss=0.0243, recon=0.0243, kl=51.9381, beta=0.0000\n",
      "Batch 160, loss=0.0218, recon=0.0218, kl=53.3104, beta=0.0000\n",
      "Batch 180, loss=0.0386, recon=0.0386, kl=55.5446, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0480, KL: 56.4404, Current Beta: 0.0000) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0502, recon=0.0502, kl=48.0993, beta=0.0000\n",
      "Batch 40, loss=0.0303, recon=0.0302, kl=41.1888, beta=0.0000\n",
      "Batch 60, loss=0.0381, recon=0.0381, kl=37.2583, beta=0.0000\n",
      "Batch 80, loss=0.0439, recon=0.0439, kl=36.9769, beta=0.0000\n",
      "Batch 100, loss=0.7541, recon=0.7541, kl=37.3035, beta=0.0000\n",
      "Batch 120, loss=0.0274, recon=0.0274, kl=38.6695, beta=0.0000\n",
      "Batch 140, loss=0.0327, recon=0.0327, kl=37.2698, beta=0.0000\n",
      "Batch 160, loss=0.0232, recon=0.0232, kl=37.2179, beta=0.0000\n",
      "Batch 180, loss=0.0643, recon=0.0643, kl=36.5969, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 39.9546, Current Beta: 0.0000) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0484, recon=0.0483, kl=31.9823, beta=0.0000\n",
      "Batch 40, loss=0.0371, recon=0.0371, kl=24.5687, beta=0.0000\n",
      "Batch 60, loss=0.0288, recon=0.0288, kl=22.8893, beta=0.0000\n",
      "Batch 80, loss=0.0366, recon=0.0365, kl=22.6822, beta=0.0000\n",
      "Batch 100, loss=0.0236, recon=0.0236, kl=20.8098, beta=0.0000\n",
      "Batch 120, loss=0.0271, recon=0.0271, kl=21.0218, beta=0.0000\n",
      "Batch 140, loss=0.0351, recon=0.0350, kl=20.9073, beta=0.0000\n",
      "Batch 160, loss=0.0367, recon=0.0367, kl=20.2882, beta=0.0000\n",
      "Batch 180, loss=0.0337, recon=0.0337, kl=19.3214, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0439 (Recon: 0.0439, KL: 23.6545, Current Beta: 0.0000) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=12.5251, beta=0.0000\n",
      "Batch 40, loss=0.0351, recon=0.0350, kl=10.0506, beta=0.0000\n",
      "Batch 60, loss=0.2115, recon=0.2115, kl=9.9221, beta=0.0000\n",
      "Batch 80, loss=0.0278, recon=0.0277, kl=13.6522, beta=0.0000\n",
      "Batch 100, loss=0.0291, recon=0.0291, kl=12.0059, beta=0.0000\n",
      "Batch 120, loss=0.0361, recon=0.0361, kl=9.5047, beta=0.0000\n",
      "Batch 140, loss=0.0277, recon=0.0277, kl=10.5988, beta=0.0000\n",
      "Batch 160, loss=0.0333, recon=0.0333, kl=9.9633, beta=0.0000\n",
      "Batch 180, loss=0.0334, recon=0.0334, kl=8.9310, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0423, KL: 11.4435, Current Beta: 0.0000) | Avg Valid Loss: 0.0365 | Avg Valid recon Loss: 0.0365\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0291, recon=0.0291, kl=4.9295, beta=0.0000\n",
      "Batch 40, loss=0.0295, recon=0.0295, kl=5.0287, beta=0.0000\n",
      "Batch 60, loss=0.0326, recon=0.0326, kl=4.2159, beta=0.0000\n",
      "Batch 80, loss=0.0315, recon=0.0315, kl=5.1511, beta=0.0000\n",
      "Batch 100, loss=0.0254, recon=0.0254, kl=4.0317, beta=0.0000\n",
      "Batch 120, loss=0.0367, recon=0.0367, kl=3.1711, beta=0.0000\n",
      "Batch 140, loss=0.0295, recon=0.0295, kl=3.5169, beta=0.0000\n",
      "Batch 160, loss=0.0353, recon=0.0353, kl=3.5823, beta=0.0000\n",
      "Batch 180, loss=0.0294, recon=0.0294, kl=3.5425, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0410, KL: 4.3748, Current Beta: 0.0000) | Avg Valid Loss: 0.0356 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0277, recon=0.0276, kl=2.4323, beta=0.0000\n",
      "Batch 40, loss=0.0496, recon=0.0495, kl=1.8136, beta=0.0000\n",
      "Batch 60, loss=0.0280, recon=0.0280, kl=1.4284, beta=0.0000\n",
      "Batch 80, loss=0.0417, recon=0.0417, kl=2.0901, beta=0.0000\n",
      "Batch 100, loss=0.0291, recon=0.0291, kl=1.9369, beta=0.0000\n",
      "Batch 120, loss=0.0267, recon=0.0267, kl=2.2191, beta=0.0000\n",
      "Batch 140, loss=0.0269, recon=0.0269, kl=1.5754, beta=0.0000\n",
      "Batch 160, loss=0.0745, recon=0.0745, kl=1.7623, beta=0.0000\n",
      "Batch 180, loss=0.0401, recon=0.0401, kl=1.2950, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0400, KL: 1.9317, Current Beta: 0.0000) | Avg Valid Loss: 0.0350 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0475, recon=0.0474, kl=0.8190, beta=0.0000\n",
      "Batch 40, loss=0.5257, recon=0.5257, kl=0.9307, beta=0.0000\n",
      "Batch 60, loss=0.0208, recon=0.0207, kl=0.9720, beta=0.0000\n",
      "Batch 80, loss=0.0509, recon=0.0509, kl=0.7556, beta=0.0000\n",
      "Batch 100, loss=0.0215, recon=0.0215, kl=0.5643, beta=0.0000\n",
      "Batch 120, loss=0.0289, recon=0.0288, kl=0.7698, beta=0.0000\n",
      "Batch 140, loss=0.0479, recon=0.0479, kl=0.8148, beta=0.0000\n",
      "Batch 160, loss=0.0448, recon=0.0447, kl=0.6459, beta=0.0000\n",
      "Batch 180, loss=0.0328, recon=0.0328, kl=0.6007, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0391, KL: 0.8239, Current Beta: 0.0000) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0333, recon=0.0333, kl=0.1673, beta=0.0001\n",
      "Batch 40, loss=0.0295, recon=0.0295, kl=0.2865, beta=0.0001\n",
      "Batch 60, loss=0.0270, recon=0.0270, kl=0.2559, beta=0.0001\n",
      "Batch 80, loss=0.0282, recon=0.0281, kl=0.1298, beta=0.0001\n",
      "Batch 100, loss=0.0617, recon=0.0617, kl=0.1174, beta=0.0001\n",
      "Batch 120, loss=0.0278, recon=0.0278, kl=0.1173, beta=0.0001\n",
      "Batch 140, loss=0.0247, recon=0.0247, kl=0.1161, beta=0.0001\n",
      "Batch 160, loss=0.1240, recon=0.1240, kl=0.1009, beta=0.0001\n",
      "Batch 180, loss=0.0331, recon=0.0331, kl=0.4157, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0383 (Recon: 0.0382, KL: 0.1888, Current Beta: 0.0001) | Avg Valid Loss: 0.0337 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0246, recon=0.0246, kl=0.3104, beta=0.0001\n",
      "Batch 40, loss=0.0232, recon=0.0232, kl=0.0889, beta=0.0001\n",
      "Batch 60, loss=0.0254, recon=0.0254, kl=0.0462, beta=0.0001\n",
      "Batch 80, loss=0.0563, recon=0.0563, kl=0.0385, beta=0.0001\n",
      "Batch 100, loss=0.0246, recon=0.0246, kl=0.0373, beta=0.0001\n",
      "Batch 120, loss=0.0234, recon=0.0234, kl=0.0243, beta=0.0001\n",
      "Batch 140, loss=0.0233, recon=0.0233, kl=0.0143, beta=0.0001\n",
      "Batch 160, loss=0.0303, recon=0.0303, kl=0.0674, beta=0.0001\n",
      "Batch 180, loss=0.0161, recon=0.0161, kl=0.0679, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0377, KL: 0.1030, Current Beta: 0.0001) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0318\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=0.0376, beta=0.0001\n",
      "Batch 40, loss=0.1005, recon=0.1005, kl=0.0359, beta=0.0001\n",
      "Batch 60, loss=0.0377, recon=0.0377, kl=0.1180, beta=0.0001\n",
      "Batch 80, loss=0.0227, recon=0.0227, kl=0.0475, beta=0.0001\n",
      "Batch 100, loss=0.0259, recon=0.0259, kl=0.0283, beta=0.0001\n",
      "Batch 120, loss=0.1215, recon=0.1215, kl=0.1494, beta=0.0001\n",
      "Batch 140, loss=0.0329, recon=0.0329, kl=0.1329, beta=0.0001\n",
      "Batch 160, loss=0.0325, recon=0.0325, kl=0.0977, beta=0.0001\n",
      "Batch 180, loss=0.0273, recon=0.0273, kl=0.0536, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0365 (Recon: 0.0365, KL: 0.0782, Current Beta: 0.0001) | Avg Valid Loss: 0.0316 | Avg Valid recon Loss: 0.0316\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=0.0283, beta=0.0001\n",
      "Batch 40, loss=0.0252, recon=0.0252, kl=0.0319, beta=0.0001\n",
      "Batch 60, loss=0.0244, recon=0.0244, kl=0.0195, beta=0.0001\n",
      "Batch 80, loss=0.0246, recon=0.0246, kl=0.0218, beta=0.0001\n",
      "Batch 100, loss=0.0239, recon=0.0239, kl=0.0208, beta=0.0001\n",
      "Batch 120, loss=0.0276, recon=0.0276, kl=0.0219, beta=0.0001\n",
      "Batch 140, loss=0.0265, recon=0.0265, kl=0.1020, beta=0.0001\n",
      "Batch 160, loss=0.0475, recon=0.0475, kl=0.0438, beta=0.0001\n",
      "Batch 180, loss=0.0371, recon=0.0371, kl=0.0161, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0360 (Recon: 0.0360, KL: 0.0327, Current Beta: 0.0001) | Avg Valid Loss: 0.0310 | Avg Valid recon Loss: 0.0310\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0283, recon=0.0283, kl=0.0528, beta=0.0001\n",
      "Batch 40, loss=0.0504, recon=0.0504, kl=0.0515, beta=0.0001\n",
      "Batch 60, loss=0.0615, recon=0.0615, kl=0.0140, beta=0.0001\n",
      "Batch 80, loss=0.0228, recon=0.0228, kl=0.0088, beta=0.0001\n",
      "Batch 100, loss=0.0221, recon=0.0221, kl=0.0144, beta=0.0001\n",
      "Batch 120, loss=0.0318, recon=0.0318, kl=0.0131, beta=0.0001\n",
      "Batch 140, loss=0.0386, recon=0.0386, kl=0.0261, beta=0.0001\n",
      "Batch 160, loss=0.0181, recon=0.0181, kl=0.0217, beta=0.0001\n",
      "Batch 180, loss=0.0265, recon=0.0265, kl=0.0154, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0353 (Recon: 0.0353, KL: 0.0209, Current Beta: 0.0001) | Avg Valid Loss: 0.0308 | Avg Valid recon Loss: 0.0307\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0768, recon=0.0768, kl=0.0133, beta=0.0001\n",
      "Batch 40, loss=0.0258, recon=0.0258, kl=0.0215, beta=0.0001\n",
      "Batch 60, loss=0.0251, recon=0.0251, kl=0.0268, beta=0.0001\n",
      "Batch 80, loss=0.0231, recon=0.0231, kl=0.0089, beta=0.0001\n",
      "Batch 100, loss=0.0366, recon=0.0366, kl=0.0200, beta=0.0001\n",
      "Batch 120, loss=0.0300, recon=0.0300, kl=0.0097, beta=0.0001\n",
      "Batch 140, loss=0.0355, recon=0.0355, kl=0.0202, beta=0.0001\n",
      "Batch 160, loss=0.0327, recon=0.0327, kl=0.0185, beta=0.0001\n",
      "Batch 180, loss=0.0328, recon=0.0328, kl=0.0099, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0347 (Recon: 0.0347, KL: 0.0172, Current Beta: 0.0001) | Avg Valid Loss: 0.0300 | Avg Valid recon Loss: 0.0300\n",
      " New best VRAE model found with validation loss: 0.0300\n",
      "   Model saved to ./ecg_model_logs\\best_vrae_model.pth\n",
      "\n",
      "[VRAE Run 16/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1716, recon=0.1716, kl=34.7842, beta=0.0000\n",
      "Batch 40, loss=0.0840, recon=0.0840, kl=39.8710, beta=0.0000\n",
      "Batch 60, loss=0.0803, recon=0.0803, kl=46.7373, beta=0.0000\n",
      "Batch 80, loss=0.0664, recon=0.0664, kl=52.6458, beta=0.0000\n",
      "Batch 100, loss=0.0526, recon=0.0526, kl=46.9041, beta=0.0000\n",
      "Batch 120, loss=0.0417, recon=0.0417, kl=52.8512, beta=0.0000\n",
      "Batch 140, loss=0.0518, recon=0.0518, kl=55.2377, beta=0.0000\n",
      "Batch 160, loss=0.0409, recon=0.0409, kl=54.5337, beta=0.0000\n",
      "Batch 180, loss=0.3074, recon=0.3074, kl=64.2258, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1098 (Recon: 0.1098, KL: 45.8651, Current Beta: 0.0000) | Avg Valid Loss: 0.0536 | Avg Valid recon Loss: 0.0536\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0596, recon=0.0596, kl=56.8929, beta=0.0000\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=50.5853, beta=0.0000\n",
      "Batch 60, loss=0.0581, recon=0.0581, kl=50.7085, beta=0.0000\n",
      "Batch 80, loss=0.0338, recon=0.0338, kl=57.3306, beta=0.0000\n",
      "Batch 100, loss=0.0578, recon=0.0578, kl=51.2999, beta=0.0000\n",
      "Batch 120, loss=0.1530, recon=0.1530, kl=57.8879, beta=0.0000\n",
      "Batch 140, loss=0.0323, recon=0.0323, kl=61.6698, beta=0.0000\n",
      "Batch 160, loss=0.0482, recon=0.0482, kl=61.1153, beta=0.0000\n",
      "Batch 180, loss=0.0298, recon=0.0298, kl=56.7843, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0590 (Recon: 0.0590, KL: 56.3921, Current Beta: 0.0000) | Avg Valid Loss: 0.0451 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0306, recon=0.0306, kl=62.5900, beta=0.0000\n",
      "Batch 40, loss=0.0912, recon=0.0912, kl=65.8941, beta=0.0000\n",
      "Batch 60, loss=0.0373, recon=0.0373, kl=64.5256, beta=0.0000\n",
      "Batch 80, loss=0.0399, recon=0.0399, kl=61.5181, beta=0.0000\n",
      "Batch 100, loss=0.0299, recon=0.0299, kl=63.2082, beta=0.0000\n",
      "Batch 120, loss=0.0356, recon=0.0356, kl=61.4292, beta=0.0000\n",
      "Batch 140, loss=0.0344, recon=0.0344, kl=59.6492, beta=0.0000\n",
      "Batch 160, loss=0.0351, recon=0.0351, kl=60.9265, beta=0.0000\n",
      "Batch 180, loss=0.0349, recon=0.0349, kl=68.2058, beta=0.0000\n",
      "  â†’ Avg Train Loss: 2413652.3818 (Recon: 2413652.0282, KL: 329878324.3323, Current Beta: 0.0000) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0460\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0514, recon=0.0514, kl=66.9479, beta=0.0000\n",
      "Batch 40, loss=0.0357, recon=0.0357, kl=94.0765, beta=0.0000\n",
      "Batch 60, loss=0.0441, recon=0.0441, kl=90.0945, beta=0.0000\n",
      "Batch 80, loss=0.0254, recon=0.0254, kl=72.7122, beta=0.0000\n",
      "Batch 100, loss=0.0417, recon=0.0417, kl=78.9135, beta=0.0000\n",
      "Batch 120, loss=0.0305, recon=0.0305, kl=84.9728, beta=0.0000\n",
      "Batch 140, loss=0.0299, recon=0.0299, kl=86.9063, beta=0.0000\n",
      "Batch 160, loss=0.0281, recon=0.0281, kl=90.9361, beta=0.0000\n",
      "Batch 180, loss=0.0307, recon=0.0307, kl=91.4258, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0454 (Recon: 0.0454, KL: 81.4647, Current Beta: 0.0000) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0295, recon=0.0295, kl=92.2792, beta=0.0000\n",
      "Batch 40, loss=0.0410, recon=0.0410, kl=92.6297, beta=0.0000\n",
      "Batch 60, loss=0.0330, recon=0.0330, kl=92.3241, beta=0.0000\n",
      "Batch 80, loss=0.0374, recon=0.0374, kl=96.8989, beta=0.0000\n",
      "Batch 100, loss=0.0435, recon=0.0435, kl=96.8954, beta=0.0000\n",
      "Batch 120, loss=0.0330, recon=0.0330, kl=98.3334, beta=0.0000\n",
      "Batch 140, loss=0.0528, recon=0.0528, kl=99.6486, beta=0.0000\n",
      "Batch 160, loss=0.0314, recon=0.0314, kl=101.5580, beta=0.0000\n",
      "Batch 180, loss=0.0271, recon=0.0270, kl=102.9755, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 96.9954, Current Beta: 0.0000) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0504, recon=0.0504, kl=106.3980, beta=0.0000\n",
      "Batch 40, loss=0.0540, recon=0.0540, kl=105.4049, beta=0.0000\n",
      "Batch 60, loss=0.0406, recon=0.0405, kl=121.8972, beta=0.0000\n",
      "Batch 80, loss=0.0630, recon=0.0630, kl=136.8220, beta=0.0000\n",
      "Batch 100, loss=0.0555, recon=0.0555, kl=137.4897, beta=0.0000\n",
      "Batch 120, loss=0.0473, recon=0.0473, kl=144.0105, beta=0.0000\n",
      "Batch 140, loss=0.0254, recon=0.0254, kl=140.8907, beta=0.0000\n",
      "Batch 160, loss=0.0507, recon=0.0506, kl=138.7378, beta=0.0000\n",
      "Batch 180, loss=0.0273, recon=0.0273, kl=140.6713, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0539 (Recon: 0.0539, KL: 128.7244, Current Beta: 0.0000) | Avg Valid Loss: 0.0469 | Avg Valid recon Loss: 0.0469\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0341, recon=0.0341, kl=140.7845, beta=0.0000\n",
      "Batch 40, loss=0.0241, recon=0.0241, kl=139.0718, beta=0.0000\n",
      "Batch 60, loss=0.0223, recon=0.0223, kl=140.3879, beta=0.0000\n",
      "Batch 80, loss=0.0457, recon=0.0457, kl=135.7084, beta=0.0000\n",
      "Batch 100, loss=0.6203, recon=0.6203, kl=148.9398, beta=0.0000\n",
      "Batch 120, loss=0.0612, recon=0.0612, kl=189.6003, beta=0.0000\n",
      "Batch 140, loss=0.0635, recon=0.0635, kl=195.5394, beta=0.0000\n",
      "Batch 160, loss=0.0402, recon=0.0402, kl=191.8869, beta=0.0000\n",
      "Batch 180, loss=0.0484, recon=0.0484, kl=176.2961, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1088 (Recon: 0.1088, KL: 160.6268, Current Beta: 0.0000) | Avg Valid Loss: 0.0635 | Avg Valid recon Loss: 0.0635\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0623, recon=0.0623, kl=194.0063, beta=0.0000\n",
      "Batch 40, loss=0.0750, recon=0.0750, kl=216.9515, beta=0.0000\n",
      "Batch 60, loss=0.0413, recon=0.0413, kl=217.1226, beta=0.0000\n",
      "Batch 80, loss=0.0809, recon=0.0809, kl=225.3907, beta=0.0000\n",
      "Batch 100, loss=0.0502, recon=0.0501, kl=225.6627, beta=0.0000\n",
      "Batch 120, loss=0.0668, recon=0.0668, kl=228.0395, beta=0.0000\n",
      "Batch 140, loss=0.0508, recon=0.0507, kl=222.2180, beta=0.0000\n",
      "Batch 160, loss=0.0680, recon=0.0680, kl=189.5100, beta=0.0000\n",
      "Batch 180, loss=0.0505, recon=0.0505, kl=155.7744, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.7578 (Recon: 0.7578, KL: 210.5637, Current Beta: 0.0000) | Avg Valid Loss: 24.1096 | Avg Valid recon Loss: 24.1096\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.3231, recon=0.3231, kl=142.5141, beta=0.0000\n",
      "Batch 40, loss=1.4623, recon=1.4623, kl=134.4584, beta=0.0000\n",
      "Batch 60, loss=0.1705, recon=0.1705, kl=191.8192, beta=0.0000\n",
      "Batch 80, loss=0.4116, recon=0.4115, kl=193.4007, beta=0.0000\n",
      "Batch 100, loss=0.1846, recon=0.1845, kl=188.4719, beta=0.0000\n",
      "Batch 120, loss=0.1562, recon=0.1562, kl=184.2370, beta=0.0000\n",
      "Batch 140, loss=0.1186, recon=0.1185, kl=183.9675, beta=0.0000\n",
      "Batch 160, loss=0.0828, recon=0.0828, kl=181.6214, beta=0.0000\n",
      "Batch 180, loss=0.1076, recon=0.1075, kl=184.5796, beta=0.0000\n",
      "  â†’ Avg Train Loss: 4.2421 (Recon: 4.2420, KL: 175.8693, Current Beta: 0.0000) | Avg Valid Loss: 0.1182 | Avg Valid recon Loss: 0.1182\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0809, recon=0.0807, kl=183.9675, beta=0.0000\n",
      "Batch 40, loss=0.0875, recon=0.0873, kl=182.8782, beta=0.0000\n",
      "Batch 60, loss=0.1010, recon=0.1008, kl=181.9620, beta=0.0000\n",
      "Batch 80, loss=0.0838, recon=0.0836, kl=183.3232, beta=0.0000\n",
      "Batch 100, loss=0.0622, recon=0.0620, kl=185.7579, beta=0.0000\n",
      "Batch 120, loss=0.1168, recon=0.1166, kl=184.0626, beta=0.0000\n",
      "Batch 140, loss=0.0846, recon=0.0844, kl=209.7081, beta=0.0000\n",
      "Batch 160, loss=0.3606, recon=0.3603, kl=209.2523, beta=0.0000\n",
      "Batch 180, loss=0.2410, recon=0.2408, kl=201.5567, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1277 (Recon: 0.1275, KL: 190.7551, Current Beta: 0.0000) | Avg Valid Loss: 0.2901 | Avg Valid recon Loss: 0.2899\n",
      "Epoch 11/20\n",
      "Batch 20, loss=20.6242, recon=20.6237, kl=187.5527, beta=0.0000\n",
      "Batch 40, loss=0.7848, recon=0.7844, kl=139.7741, beta=0.0000\n",
      "Batch 60, loss=72.0865, recon=72.0861, kl=127.0578, beta=0.0000\n",
      "Batch 80, loss=5.5890, recon=5.5886, kl=142.7276, beta=0.0000\n",
      "Batch 100, loss=1.3447, recon=1.3443, kl=144.9942, beta=0.0000\n",
      "Batch 120, loss=0.6385, recon=0.6381, kl=139.4538, beta=0.0000\n",
      "Batch 140, loss=1.0421, recon=1.0417, kl=133.6717, beta=0.0000\n",
      "Batch 160, loss=0.4388, recon=0.4384, kl=126.5203, beta=0.0000\n",
      "Batch 180, loss=0.3452, recon=0.3448, kl=131.6706, beta=0.0000\n",
      "  â†’ Avg Train Loss: 10.8272 (Recon: 10.8268, KL: 146.1654, Current Beta: 0.0000) | Avg Valid Loss: 0.2943 | Avg Valid recon Loss: 0.2939\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.2441, recon=0.2431, kl=134.8862, beta=0.0000\n",
      "Batch 40, loss=0.1390, recon=0.1380, kl=133.4194, beta=0.0000\n",
      "Batch 60, loss=0.1778, recon=0.1768, kl=133.5413, beta=0.0000\n",
      "Batch 80, loss=0.1315, recon=0.1304, kl=135.3984, beta=0.0000\n",
      "Batch 100, loss=0.1401, recon=0.1390, kl=137.7675, beta=0.0000\n",
      "Batch 120, loss=0.1059, recon=0.1049, kl=138.2886, beta=0.0000\n",
      "Batch 140, loss=0.1298, recon=0.1287, kl=140.0316, beta=0.0000\n",
      "Batch 160, loss=0.1279, recon=0.1269, kl=138.2070, beta=0.0000\n",
      "Batch 180, loss=0.1205, recon=0.1194, kl=138.0651, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6928 (Recon: 0.6918, KL: 136.3394, Current Beta: 0.0000) | Avg Valid Loss: 0.1555 | Avg Valid recon Loss: 0.1545\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1861, recon=0.1835, kl=138.4219, beta=0.0000\n",
      "Batch 40, loss=0.1378, recon=0.1353, kl=137.0287, beta=0.0000\n",
      "Batch 60, loss=8.2732, recon=8.2707, kl=136.6594, beta=0.0000\n",
      "Batch 80, loss=0.1206, recon=0.1180, kl=141.1746, beta=0.0000\n",
      "Batch 100, loss=0.1635, recon=0.1609, kl=141.2041, beta=0.0000\n",
      "Batch 120, loss=0.1111, recon=0.1085, kl=139.7289, beta=0.0000\n",
      "Batch 140, loss=0.1389, recon=0.1363, kl=140.1105, beta=0.0000\n",
      "Batch 160, loss=0.1322, recon=0.1296, kl=139.3880, beta=0.0000\n",
      "Batch 180, loss=0.0961, recon=0.0936, kl=139.5209, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1987 (Recon: 0.1961, KL: 139.5126, Current Beta: 0.0000) | Avg Valid Loss: 0.1576 | Avg Valid recon Loss: 0.1550\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1202, recon=0.1150, kl=138.7076, beta=0.0000\n",
      "Batch 40, loss=0.2155, recon=0.2103, kl=137.4615, beta=0.0000\n",
      "Batch 60, loss=0.0904, recon=0.0852, kl=137.2498, beta=0.0000\n",
      "Batch 80, loss=0.0942, recon=0.0890, kl=137.2533, beta=0.0000\n",
      "Batch 100, loss=0.0663, recon=0.0612, kl=136.0515, beta=0.0000\n",
      "Batch 120, loss=0.1176, recon=0.1125, kl=134.2550, beta=0.0000\n",
      "Batch 140, loss=0.1155, recon=0.1105, kl=134.2219, beta=0.0000\n",
      "Batch 160, loss=0.0694, recon=0.0644, kl=133.4934, beta=0.0000\n",
      "Batch 180, loss=0.0928, recon=0.0878, kl=133.3140, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1353 (Recon: 0.1302, KL: 136.0824, Current Beta: 0.0000) | Avg Valid Loss: 0.1586 | Avg Valid recon Loss: 0.1536\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1169, recon=0.1088, kl=130.2438, beta=0.0001\n",
      "Batch 40, loss=0.1706, recon=0.1625, kl=129.8438, beta=0.0001\n",
      "Batch 60, loss=0.0962, recon=0.0881, kl=130.2598, beta=0.0001\n",
      "Batch 80, loss=0.0895, recon=0.0816, kl=127.8202, beta=0.0001\n",
      "Batch 100, loss=0.1126, recon=0.1048, kl=126.0556, beta=0.0001\n",
      "Batch 120, loss=0.1507, recon=0.1430, kl=124.5705, beta=0.0001\n",
      "Batch 140, loss=0.1345, recon=0.1269, kl=122.1901, beta=0.0001\n",
      "Batch 160, loss=0.0865, recon=0.0790, kl=121.1130, beta=0.0001\n",
      "Batch 180, loss=0.1351, recon=0.1276, kl=120.1107, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1553 (Recon: 0.1471, KL: 131.1193, Current Beta: 0.0001) | Avg Valid Loss: 0.1529 | Avg Valid recon Loss: 0.1454\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0744, recon=0.0627, kl=117.5934, beta=0.0001\n",
      "Batch 40, loss=0.1287, recon=0.1173, kl=113.9857, beta=0.0001\n",
      "Batch 60, loss=0.0949, recon=0.0838, kl=111.4296, beta=0.0001\n",
      "Batch 80, loss=0.0837, recon=0.0727, kl=110.2870, beta=0.0001\n",
      "Batch 100, loss=0.0755, recon=0.0646, kl=108.4373, beta=0.0001\n",
      "Batch 120, loss=0.0594, recon=0.0486, kl=107.6955, beta=0.0001\n",
      "Batch 140, loss=0.0856, recon=0.0750, kl=105.6324, beta=0.0001\n",
      "Batch 160, loss=0.1464, recon=0.1359, kl=105.3949, beta=0.0001\n",
      "Batch 180, loss=0.0733, recon=0.0625, kl=107.6522, beta=0.0001\n",
      "  â†’ Avg Train Loss: 2923.1024 (Recon: 2918.9395, KL: 41629.9057, Current Beta: 0.0001) | Avg Valid Loss: 0.2849 | Avg Valid recon Loss: 0.2741\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1391, recon=0.1282, kl=109.2802, beta=0.0001\n",
      "Batch 40, loss=0.0837, recon=0.0730, kl=106.8796, beta=0.0001\n",
      "Batch 60, loss=0.0671, recon=0.0565, kl=106.3730, beta=0.0001\n",
      "Batch 80, loss=0.0719, recon=0.0615, kl=104.4550, beta=0.0001\n",
      "Batch 100, loss=97.2447, recon=97.2190, kl=256.9285, beta=0.0001\n",
      "Batch 120, loss=0.1188, recon=0.1086, kl=101.9408, beta=0.0001\n",
      "Batch 140, loss=0.0971, recon=0.0869, kl=101.9432, beta=0.0001\n",
      "Batch 160, loss=0.0792, recon=0.0692, kl=100.0171, beta=0.0001\n",
      "Batch 180, loss=0.1014, recon=0.0915, kl=99.3259, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.6838 (Recon: 0.6733, KL: 104.9229, Current Beta: 0.0001) | Avg Valid Loss: 0.1185 | Avg Valid recon Loss: 0.1078\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0806, recon=0.0704, kl=101.6591, beta=0.0001\n",
      "Batch 40, loss=0.1286, recon=0.1185, kl=101.2675, beta=0.0001\n",
      "Batch 60, loss=0.0742, recon=0.0645, kl=97.6225, beta=0.0001\n",
      "Batch 80, loss=0.1284, recon=0.1188, kl=95.6554, beta=0.0001\n",
      "Batch 100, loss=0.0924, recon=0.0829, kl=95.0634, beta=0.0001\n",
      "Batch 120, loss=0.0624, recon=0.0531, kl=93.7010, beta=0.0001\n",
      "Batch 140, loss=0.0708, recon=0.0616, kl=92.5245, beta=0.0001\n",
      "Batch 160, loss=0.0935, recon=0.0843, kl=91.8054, beta=0.0001\n",
      "Batch 180, loss=0.0767, recon=0.0677, kl=90.1375, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.4872 (Recon: 0.4621, KL: 251.4596, Current Beta: 0.0001) | Avg Valid Loss: 0.1553 | Avg Valid recon Loss: 0.1459\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0775, recon=0.0686, kl=88.6896, beta=0.0001\n",
      "Batch 40, loss=0.0852, recon=0.0765, kl=86.7309, beta=0.0001\n",
      "Batch 60, loss=0.0912, recon=0.0826, kl=85.7539, beta=0.0001\n",
      "Batch 80, loss=0.0725, recon=0.0640, kl=84.6345, beta=0.0001\n",
      "Batch 100, loss=0.0723, recon=0.0640, kl=83.5602, beta=0.0001\n",
      "Batch 120, loss=0.0857, recon=0.0775, kl=82.2548, beta=0.0001\n",
      "Batch 140, loss=1.1935, recon=1.1853, kl=81.8147, beta=0.0001\n",
      "Batch 160, loss=0.0901, recon=0.0821, kl=79.9010, beta=0.0001\n",
      "Batch 180, loss=0.1668, recon=0.1588, kl=79.9662, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.3165 (Recon: 0.3068, KL: 96.9904, Current Beta: 0.0001) | Avg Valid Loss: 0.1135 | Avg Valid recon Loss: 0.1019\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0581, recon=0.0501, kl=79.5644, beta=0.0001\n",
      "Batch 40, loss=0.0963, recon=0.0885, kl=77.8429, beta=0.0001\n",
      "Batch 60, loss=0.0695, recon=0.0619, kl=76.4198, beta=0.0001\n",
      "Batch 80, loss=0.0903, recon=0.0827, kl=76.1329, beta=0.0001\n",
      "Batch 100, loss=0.0801, recon=0.0725, kl=76.5438, beta=0.0001\n",
      "Batch 120, loss=0.0741, recon=0.0666, kl=75.0617, beta=0.0001\n",
      "Batch 140, loss=0.1083, recon=0.1009, kl=73.5733, beta=0.0001\n",
      "Batch 160, loss=0.0837, recon=0.0764, kl=72.6172, beta=0.0001\n",
      "Batch 180, loss=0.2158, recon=0.2085, kl=73.7200, beta=0.0001\n",
      "  â†’ Avg Train Loss: 13.4779 (Recon: 13.4156, KL: 623.3934, Current Beta: 0.0001) | Avg Valid Loss: 0.1228 | Avg Valid recon Loss: 0.1152\n",
      "\n",
      "[VRAE Run 17/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3807, recon=0.3807, kl=1.2400, beta=0.0000\n",
      "Batch 40, loss=0.2272, recon=0.2272, kl=52.1172, beta=0.0000\n",
      "Batch 60, loss=0.1190, recon=0.1190, kl=91.0109, beta=0.0000\n",
      "Batch 80, loss=0.1503, recon=0.1503, kl=100.8473, beta=0.0000\n",
      "Batch 100, loss=0.0899, recon=0.0899, kl=99.5734, beta=0.0000\n",
      "Batch 120, loss=0.1118, recon=0.1118, kl=108.3917, beta=0.0000\n",
      "Batch 140, loss=0.0887, recon=0.0887, kl=118.9278, beta=0.0000\n",
      "Batch 160, loss=0.1193, recon=0.1193, kl=133.4127, beta=0.0000\n",
      "Batch 180, loss=0.1181, recon=0.1181, kl=138.2735, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2394 (Recon: 0.2394, KL: 86.5766, Current Beta: 0.0000) | Avg Valid Loss: 0.0998 | Avg Valid recon Loss: 0.0998\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0872, recon=0.0872, kl=137.2823, beta=0.0000\n",
      "Batch 40, loss=0.0993, recon=0.0993, kl=140.6722, beta=0.0000\n",
      "Batch 60, loss=0.0893, recon=0.0893, kl=142.5883, beta=0.0000\n",
      "Batch 80, loss=0.1213, recon=0.1213, kl=148.1526, beta=0.0000\n",
      "Batch 100, loss=0.1115, recon=0.1115, kl=145.4737, beta=0.0000\n",
      "Batch 120, loss=0.0602, recon=0.0602, kl=151.0087, beta=0.0000\n",
      "Batch 140, loss=0.0757, recon=0.0757, kl=142.4196, beta=0.0000\n",
      "Batch 160, loss=0.1329, recon=0.1329, kl=152.5182, beta=0.0000\n",
      "Batch 180, loss=0.0689, recon=0.0689, kl=156.8129, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1132 (Recon: 0.1132, KL: 145.4908, Current Beta: 0.0000) | Avg Valid Loss: 0.0739 | Avg Valid recon Loss: 0.0739\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0653, recon=0.0653, kl=158.8134, beta=0.0000\n",
      "Batch 40, loss=0.0628, recon=0.0628, kl=159.3524, beta=0.0000\n",
      "Batch 60, loss=0.1164, recon=0.1164, kl=162.3546, beta=0.0000\n",
      "Batch 80, loss=0.2834, recon=0.2834, kl=165.3800, beta=0.0000\n",
      "Batch 100, loss=0.0568, recon=0.0568, kl=163.3647, beta=0.0000\n",
      "Batch 120, loss=0.0539, recon=0.0539, kl=157.8144, beta=0.0000\n",
      "Batch 140, loss=0.0776, recon=0.0776, kl=162.9378, beta=0.0000\n",
      "Batch 160, loss=0.0647, recon=0.0647, kl=159.4168, beta=0.0000\n",
      "Batch 180, loss=0.2398, recon=0.2398, kl=154.0137, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0868 (Recon: 0.0868, KL: 160.5770, Current Beta: 0.0000) | Avg Valid Loss: 0.0629 | Avg Valid recon Loss: 0.0629\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0679, recon=0.0679, kl=159.7461, beta=0.0000\n",
      "Batch 40, loss=0.0731, recon=0.0731, kl=164.5416, beta=0.0000\n",
      "Batch 60, loss=0.0508, recon=0.0508, kl=158.8250, beta=0.0000\n",
      "Batch 80, loss=0.0505, recon=0.0505, kl=165.5251, beta=0.0000\n",
      "Batch 100, loss=0.0791, recon=0.0791, kl=159.2100, beta=0.0000\n",
      "Batch 120, loss=0.0316, recon=0.0316, kl=161.2984, beta=0.0000\n",
      "Batch 140, loss=0.0659, recon=0.0659, kl=158.7904, beta=0.0000\n",
      "Batch 160, loss=0.0564, recon=0.0564, kl=160.6242, beta=0.0000\n",
      "Batch 180, loss=0.0414, recon=0.0414, kl=159.4290, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0720 (Recon: 0.0720, KL: 160.3346, Current Beta: 0.0000) | Avg Valid Loss: 0.0573 | Avg Valid recon Loss: 0.0573\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0588, recon=0.0588, kl=156.6444, beta=0.0000\n",
      "Batch 40, loss=0.0393, recon=0.0393, kl=156.6179, beta=0.0000\n",
      "Batch 60, loss=0.0488, recon=0.0488, kl=160.1043, beta=0.0000\n",
      "Batch 80, loss=0.0423, recon=0.0423, kl=160.8813, beta=0.0000\n",
      "Batch 100, loss=0.0417, recon=0.0417, kl=159.1445, beta=0.0000\n",
      "Batch 120, loss=0.0328, recon=0.0328, kl=157.7829, beta=0.0000\n",
      "Batch 140, loss=0.0430, recon=0.0430, kl=161.0055, beta=0.0000\n",
      "Batch 160, loss=0.0310, recon=0.0310, kl=155.7142, beta=0.0000\n",
      "Batch 180, loss=0.0316, recon=0.0316, kl=155.7131, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0633 (Recon: 0.0633, KL: 158.7503, Current Beta: 0.0000) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0505, recon=0.0505, kl=154.5016, beta=0.0000\n",
      "Batch 40, loss=0.0364, recon=0.0364, kl=148.5276, beta=0.0000\n",
      "Batch 60, loss=0.0625, recon=0.0625, kl=149.8519, beta=0.0000\n",
      "Batch 80, loss=0.0464, recon=0.0464, kl=150.7448, beta=0.0000\n",
      "Batch 100, loss=0.0510, recon=0.0510, kl=153.1748, beta=0.0000\n",
      "Batch 120, loss=0.0327, recon=0.0327, kl=154.3100, beta=0.0000\n",
      "Batch 140, loss=0.0393, recon=0.0393, kl=151.1399, beta=0.0000\n",
      "Batch 160, loss=0.0383, recon=0.0383, kl=150.1721, beta=0.0000\n",
      "Batch 180, loss=0.0405, recon=0.0405, kl=148.5248, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0574 (Recon: 0.0574, KL: 151.3169, Current Beta: 0.0000) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0806, recon=0.0806, kl=144.7543, beta=0.0000\n",
      "Batch 40, loss=0.0448, recon=0.0448, kl=136.8201, beta=0.0000\n",
      "Batch 60, loss=0.0312, recon=0.0312, kl=130.5407, beta=0.0000\n",
      "Batch 80, loss=0.0401, recon=0.0401, kl=128.3368, beta=0.0000\n",
      "Batch 100, loss=0.0415, recon=0.0415, kl=116.6273, beta=0.0000\n",
      "Batch 120, loss=0.0390, recon=0.0390, kl=115.3150, beta=0.0000\n",
      "Batch 140, loss=0.0319, recon=0.0319, kl=123.0771, beta=0.0000\n",
      "Batch 160, loss=0.0335, recon=0.0335, kl=119.7334, beta=0.0000\n",
      "Batch 180, loss=0.0308, recon=0.0308, kl=118.8357, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 127.3912, Current Beta: 0.0000) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0456\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0440, recon=0.0440, kl=112.7198, beta=0.0000\n",
      "Batch 40, loss=0.0395, recon=0.0395, kl=104.9015, beta=0.0000\n",
      "Batch 60, loss=0.0543, recon=0.0543, kl=101.7126, beta=0.0000\n",
      "Batch 80, loss=0.0391, recon=0.0391, kl=99.0385, beta=0.0000\n",
      "Batch 100, loss=0.0748, recon=0.0748, kl=91.6541, beta=0.0000\n",
      "Batch 120, loss=0.0247, recon=0.0247, kl=90.9742, beta=0.0000\n",
      "Batch 140, loss=0.0232, recon=0.0232, kl=87.5529, beta=0.0000\n",
      "Batch 160, loss=0.0371, recon=0.0371, kl=84.2691, beta=0.0000\n",
      "Batch 180, loss=0.0287, recon=0.0287, kl=85.3655, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0494, KL: 96.5323, Current Beta: 0.0000) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0409, recon=0.0409, kl=75.2104, beta=0.0000\n",
      "Batch 40, loss=0.0259, recon=0.0259, kl=65.2495, beta=0.0000\n",
      "Batch 60, loss=0.0272, recon=0.0271, kl=59.9661, beta=0.0000\n",
      "Batch 80, loss=0.0526, recon=0.0525, kl=59.1349, beta=0.0000\n",
      "Batch 100, loss=0.0537, recon=0.0537, kl=58.3155, beta=0.0000\n",
      "Batch 120, loss=0.0469, recon=0.0469, kl=57.5239, beta=0.0000\n",
      "Batch 140, loss=0.0333, recon=0.0332, kl=59.4990, beta=0.0000\n",
      "Batch 160, loss=0.0393, recon=0.0393, kl=57.0780, beta=0.0000\n",
      "Batch 180, loss=0.0333, recon=0.0332, kl=57.8521, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0472, KL: 62.3653, Current Beta: 0.0000) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1415, recon=0.1415, kl=43.6633, beta=0.0000\n",
      "Batch 40, loss=0.0394, recon=0.0394, kl=32.8537, beta=0.0000\n",
      "Batch 60, loss=0.0238, recon=0.0237, kl=33.2289, beta=0.0000\n",
      "Batch 80, loss=0.0416, recon=0.0416, kl=29.8440, beta=0.0000\n",
      "Batch 100, loss=0.0462, recon=0.0462, kl=34.7003, beta=0.0000\n",
      "Batch 120, loss=0.0244, recon=0.0244, kl=34.6624, beta=0.0000\n",
      "Batch 140, loss=0.0448, recon=0.0448, kl=32.7456, beta=0.0000\n",
      "Batch 160, loss=0.0372, recon=0.0371, kl=34.1392, beta=0.0000\n",
      "Batch 180, loss=0.0419, recon=0.0418, kl=31.1825, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0450, KL: 35.6587, Current Beta: 0.0000) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0278, recon=0.0278, kl=18.4361, beta=0.0000\n",
      "Batch 40, loss=0.0226, recon=0.0226, kl=13.7945, beta=0.0000\n",
      "Batch 60, loss=0.0272, recon=0.0271, kl=15.4914, beta=0.0000\n",
      "Batch 80, loss=0.0517, recon=0.0517, kl=13.4060, beta=0.0000\n",
      "Batch 100, loss=0.0922, recon=0.0922, kl=14.5133, beta=0.0000\n",
      "Batch 120, loss=0.0216, recon=0.0216, kl=13.2867, beta=0.0000\n",
      "Batch 140, loss=0.0293, recon=0.0292, kl=11.8836, beta=0.0000\n",
      "Batch 160, loss=0.0597, recon=0.0597, kl=11.6915, beta=0.0000\n",
      "Batch 180, loss=0.0328, recon=0.0328, kl=12.3006, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 14.7952, Current Beta: 0.0000) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0239, recon=0.0239, kl=4.4896, beta=0.0000\n",
      "Batch 40, loss=0.0626, recon=0.0626, kl=5.6743, beta=0.0000\n",
      "Batch 60, loss=0.0248, recon=0.0248, kl=4.9192, beta=0.0000\n",
      "Batch 80, loss=0.0255, recon=0.0254, kl=5.4032, beta=0.0000\n",
      "Batch 100, loss=0.0240, recon=0.0240, kl=5.7620, beta=0.0000\n",
      "Batch 120, loss=0.0219, recon=0.0219, kl=5.2291, beta=0.0000\n",
      "Batch 140, loss=0.0281, recon=0.0281, kl=5.3209, beta=0.0000\n",
      "Batch 160, loss=0.0341, recon=0.0341, kl=4.5505, beta=0.0000\n",
      "Batch 180, loss=0.0778, recon=0.0777, kl=4.3718, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0419, KL: 5.4609, Current Beta: 0.0000) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0366, recon=0.0366, kl=1.7956, beta=0.0000\n",
      "Batch 40, loss=0.0326, recon=0.0325, kl=3.2672, beta=0.0000\n",
      "Batch 60, loss=0.0308, recon=0.0308, kl=2.2963, beta=0.0000\n",
      "Batch 80, loss=0.0240, recon=0.0240, kl=2.0597, beta=0.0000\n",
      "Batch 100, loss=0.0271, recon=0.0270, kl=2.1038, beta=0.0000\n",
      "Batch 120, loss=0.0240, recon=0.0240, kl=2.1902, beta=0.0000\n",
      "Batch 140, loss=0.0826, recon=0.0826, kl=1.6898, beta=0.0000\n",
      "Batch 160, loss=0.1242, recon=0.1242, kl=1.5421, beta=0.0000\n",
      "Batch 180, loss=0.0253, recon=0.0252, kl=1.7377, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0405, KL: 2.1866, Current Beta: 0.0000) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0231, recon=0.0230, kl=1.1981, beta=0.0000\n",
      "Batch 40, loss=0.0250, recon=0.0250, kl=0.7803, beta=0.0000\n",
      "Batch 60, loss=0.0241, recon=0.0241, kl=1.0176, beta=0.0000\n",
      "Batch 80, loss=0.0265, recon=0.0264, kl=0.8618, beta=0.0000\n",
      "Batch 100, loss=0.0465, recon=0.0464, kl=1.0067, beta=0.0000\n",
      "Batch 120, loss=0.0277, recon=0.0277, kl=0.8751, beta=0.0000\n",
      "Batch 140, loss=0.0276, recon=0.0275, kl=0.8296, beta=0.0000\n",
      "Batch 160, loss=0.0474, recon=0.0474, kl=0.6572, beta=0.0000\n",
      "Batch 180, loss=0.0355, recon=0.0354, kl=0.7446, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0398 (Recon: 0.0398, KL: 0.9457, Current Beta: 0.0000) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=0.4777, beta=0.0001\n",
      "Batch 40, loss=0.0276, recon=0.0276, kl=0.3333, beta=0.0001\n",
      "Batch 60, loss=0.0325, recon=0.0324, kl=0.3078, beta=0.0001\n",
      "Batch 80, loss=0.0295, recon=0.0295, kl=0.2728, beta=0.0001\n",
      "Batch 100, loss=0.0217, recon=0.0217, kl=0.2171, beta=0.0001\n",
      "Batch 120, loss=0.0308, recon=0.0307, kl=0.2444, beta=0.0001\n",
      "Batch 140, loss=0.0418, recon=0.0418, kl=0.1754, beta=0.0001\n",
      "Batch 160, loss=0.0288, recon=0.0288, kl=0.2389, beta=0.0001\n",
      "Batch 180, loss=0.0398, recon=0.0398, kl=0.1563, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0386, KL: 0.2991, Current Beta: 0.0001) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0331\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0287, recon=0.0287, kl=0.0727, beta=0.0001\n",
      "Batch 40, loss=0.0244, recon=0.0244, kl=0.1152, beta=0.0001\n",
      "Batch 60, loss=0.0280, recon=0.0280, kl=0.0718, beta=0.0001\n",
      "Batch 80, loss=0.0250, recon=0.0250, kl=0.0479, beta=0.0001\n",
      "Batch 100, loss=0.0384, recon=0.0384, kl=0.0470, beta=0.0001\n",
      "Batch 120, loss=0.0753, recon=0.0753, kl=0.0512, beta=0.0001\n",
      "Batch 140, loss=0.0203, recon=0.0203, kl=0.0938, beta=0.0001\n",
      "Batch 160, loss=0.0353, recon=0.0353, kl=0.0306, beta=0.0001\n",
      "Batch 180, loss=0.0286, recon=0.0286, kl=0.0394, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0379 (Recon: 0.0378, KL: 0.0622, Current Beta: 0.0001) | Avg Valid Loss: 0.0337 | Avg Valid recon Loss: 0.0337\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0204, recon=0.0204, kl=0.0483, beta=0.0001\n",
      "Batch 40, loss=0.0261, recon=0.0261, kl=0.0278, beta=0.0001\n",
      "Batch 60, loss=0.0310, recon=0.0310, kl=0.0540, beta=0.0001\n",
      "Batch 80, loss=0.1287, recon=0.1287, kl=0.0485, beta=0.0001\n",
      "Batch 100, loss=0.0363, recon=0.0363, kl=0.0315, beta=0.0001\n",
      "Batch 120, loss=0.0551, recon=0.0551, kl=0.0236, beta=0.0001\n",
      "Batch 140, loss=0.0368, recon=0.0368, kl=0.0291, beta=0.0001\n",
      "Batch 160, loss=0.0283, recon=0.0283, kl=0.0231, beta=0.0001\n",
      "Batch 180, loss=0.0291, recon=0.0291, kl=0.0271, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0369 (Recon: 0.0369, KL: 0.0360, Current Beta: 0.0001) | Avg Valid Loss: 0.0326 | Avg Valid recon Loss: 0.0326\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0702, recon=0.0702, kl=0.0203, beta=0.0001\n",
      "Batch 40, loss=0.0384, recon=0.0384, kl=0.0314, beta=0.0001\n",
      "Batch 60, loss=0.0209, recon=0.0209, kl=0.0283, beta=0.0001\n",
      "Batch 80, loss=0.0219, recon=0.0219, kl=0.0218, beta=0.0001\n",
      "Batch 100, loss=0.0343, recon=0.0343, kl=0.0193, beta=0.0001\n",
      "Batch 120, loss=0.0324, recon=0.0324, kl=0.0221, beta=0.0001\n",
      "Batch 140, loss=0.0228, recon=0.0228, kl=0.0185, beta=0.0001\n",
      "Batch 160, loss=0.0285, recon=0.0285, kl=0.0158, beta=0.0001\n",
      "Batch 180, loss=0.0184, recon=0.0184, kl=0.0180, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0363 (Recon: 0.0363, KL: 0.0229, Current Beta: 0.0001) | Avg Valid Loss: 0.0312 | Avg Valid recon Loss: 0.0312\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0238, recon=0.0238, kl=0.0108, beta=0.0001\n",
      "Batch 40, loss=0.0230, recon=0.0230, kl=0.0140, beta=0.0001\n",
      "Batch 60, loss=0.0215, recon=0.0215, kl=0.0158, beta=0.0001\n",
      "Batch 80, loss=0.0370, recon=0.0370, kl=0.0110, beta=0.0001\n",
      "Batch 100, loss=0.0254, recon=0.0254, kl=0.0103, beta=0.0001\n",
      "Batch 120, loss=0.0254, recon=0.0254, kl=0.0257, beta=0.0001\n",
      "Batch 140, loss=0.0252, recon=0.0252, kl=0.0132, beta=0.0001\n",
      "Batch 160, loss=0.0439, recon=0.0439, kl=0.0131, beta=0.0001\n",
      "Batch 180, loss=0.0350, recon=0.0350, kl=0.0136, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0361 (Recon: 0.0361, KL: 0.0153, Current Beta: 0.0001) | Avg Valid Loss: 0.0315 | Avg Valid recon Loss: 0.0315\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0500, recon=0.0500, kl=0.0289, beta=0.0001\n",
      "Batch 40, loss=0.0258, recon=0.0258, kl=0.0206, beta=0.0001\n",
      "Batch 60, loss=0.0233, recon=0.0233, kl=0.0161, beta=0.0001\n",
      "Batch 80, loss=0.0383, recon=0.0383, kl=0.0147, beta=0.0001\n",
      "Batch 100, loss=0.0259, recon=0.0259, kl=0.0142, beta=0.0001\n",
      "Batch 120, loss=0.0284, recon=0.0284, kl=0.0107, beta=0.0001\n",
      "Batch 140, loss=0.0285, recon=0.0285, kl=0.0092, beta=0.0001\n",
      "Batch 160, loss=0.0380, recon=0.0380, kl=0.0134, beta=0.0001\n",
      "Batch 180, loss=0.0338, recon=0.0338, kl=0.0346, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0351 (Recon: 0.0351, KL: 0.0140, Current Beta: 0.0001) | Avg Valid Loss: 0.0305 | Avg Valid recon Loss: 0.0305\n",
      "\n",
      "[VRAE Run 18/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1257, recon=0.1257, kl=71.0399, beta=0.0000\n",
      "Batch 40, loss=0.0614, recon=0.0614, kl=81.6167, beta=0.0000\n",
      "Batch 60, loss=0.0584, recon=0.0584, kl=96.0434, beta=0.0000\n",
      "Batch 80, loss=0.0420, recon=0.0420, kl=99.2856, beta=0.0000\n",
      "Batch 100, loss=0.0479, recon=0.0479, kl=89.0298, beta=0.0000\n",
      "Batch 120, loss=0.1043, recon=0.1043, kl=104.3815, beta=0.0000\n",
      "Batch 140, loss=0.0754, recon=0.0754, kl=124.5069, beta=0.0000\n",
      "Batch 160, loss=0.0699, recon=0.0699, kl=141.6986, beta=0.0000\n",
      "Batch 180, loss=0.0616, recon=0.0616, kl=126.1751, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1079 (Recon: 0.1079, KL: 97.0868, Current Beta: 0.0000) | Avg Valid Loss: 0.0531 | Avg Valid recon Loss: 0.0531\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0347, recon=0.0347, kl=119.2862, beta=0.0000\n",
      "Batch 40, loss=0.0592, recon=0.0592, kl=116.8279, beta=0.0000\n",
      "Batch 60, loss=0.1456, recon=0.1456, kl=120.8260, beta=0.0000\n",
      "Batch 80, loss=0.0936, recon=0.0936, kl=131.9229, beta=0.0000\n",
      "Batch 100, loss=0.0528, recon=0.0528, kl=119.0797, beta=0.0000\n",
      "Batch 120, loss=0.0494, recon=0.0494, kl=116.5247, beta=0.0000\n",
      "Batch 140, loss=0.0379, recon=0.0379, kl=123.9854, beta=0.0000\n",
      "Batch 160, loss=0.0326, recon=0.0326, kl=119.1284, beta=0.0000\n",
      "Batch 180, loss=0.0358, recon=0.0358, kl=127.2103, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0578 (Recon: 0.0578, KL: 121.4389, Current Beta: 0.0000) | Avg Valid Loss: 0.0475 | Avg Valid recon Loss: 0.0475\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0371, recon=0.0370, kl=128.7788, beta=0.0000\n",
      "Batch 40, loss=0.0271, recon=0.0271, kl=135.5201, beta=0.0000\n",
      "Batch 60, loss=0.0430, recon=0.0430, kl=129.3325, beta=0.0000\n",
      "Batch 80, loss=0.1549, recon=0.1549, kl=127.5240, beta=0.0000\n",
      "Batch 100, loss=0.0764, recon=0.0764, kl=119.3518, beta=0.0000\n",
      "Batch 120, loss=0.0388, recon=0.0388, kl=114.1009, beta=0.0000\n",
      "Batch 140, loss=0.0388, recon=0.0388, kl=130.4060, beta=0.0000\n",
      "Batch 160, loss=0.0580, recon=0.0580, kl=126.0232, beta=0.0000\n",
      "Batch 180, loss=0.0480, recon=0.0480, kl=131.8178, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0550 (Recon: 0.0550, KL: 126.2172, Current Beta: 0.0000) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=144.4187, beta=0.0000\n",
      "Batch 40, loss=0.0573, recon=0.0573, kl=147.5587, beta=0.0000\n",
      "Batch 60, loss=0.0444, recon=0.0444, kl=119.5139, beta=0.0000\n",
      "Batch 80, loss=0.0526, recon=0.0526, kl=105.6810, beta=0.0000\n",
      "Batch 100, loss=0.0534, recon=0.0534, kl=122.4706, beta=0.0000\n",
      "Batch 120, loss=0.0344, recon=0.0344, kl=131.9243, beta=0.0000\n",
      "Batch 140, loss=0.0286, recon=0.0286, kl=141.6189, beta=0.0000\n",
      "Batch 160, loss=0.0563, recon=0.0563, kl=133.5592, beta=0.0000\n",
      "Batch 180, loss=0.0254, recon=0.0254, kl=137.3795, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0503 (Recon: 0.0503, KL: 131.6214, Current Beta: 0.0000) | Avg Valid Loss: 0.0429 | Avg Valid recon Loss: 0.0429\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0237, recon=0.0237, kl=144.9236, beta=0.0000\n",
      "Batch 40, loss=0.1707, recon=0.1707, kl=146.1031, beta=0.0000\n",
      "Batch 60, loss=0.0225, recon=0.0225, kl=142.1310, beta=0.0000\n",
      "Batch 80, loss=0.0248, recon=0.0248, kl=136.5585, beta=0.0000\n",
      "Batch 100, loss=0.0377, recon=0.0377, kl=137.8250, beta=0.0000\n",
      "Batch 120, loss=0.0414, recon=0.0414, kl=129.1892, beta=0.0000\n",
      "Batch 140, loss=0.0317, recon=0.0317, kl=128.0563, beta=0.0000\n",
      "Batch 160, loss=0.0372, recon=0.0372, kl=140.8272, beta=0.0000\n",
      "Batch 180, loss=0.0339, recon=0.0339, kl=141.6703, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0464 (Recon: 0.0464, KL: 139.4084, Current Beta: 0.0000) | Avg Valid Loss: 0.0396 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0407, recon=0.0407, kl=123.7327, beta=0.0000\n",
      "Batch 40, loss=0.0330, recon=0.0330, kl=132.6735, beta=0.0000\n",
      "Batch 60, loss=0.0319, recon=0.0319, kl=138.1331, beta=0.0000\n",
      "Batch 80, loss=0.0236, recon=0.0236, kl=142.4140, beta=0.0000\n",
      "Batch 100, loss=0.0390, recon=0.0390, kl=118.1592, beta=0.0000\n",
      "Batch 120, loss=0.0469, recon=0.0469, kl=124.8515, beta=0.0000\n",
      "Batch 140, loss=0.1563, recon=0.1563, kl=137.0795, beta=0.0000\n",
      "Batch 160, loss=0.0260, recon=0.0260, kl=147.3947, beta=0.0000\n",
      "Batch 180, loss=0.0330, recon=0.0330, kl=151.5122, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0411 (Recon: 0.0410, KL: 135.0211, Current Beta: 0.0000) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0708, recon=0.0708, kl=148.6744, beta=0.0000\n",
      "Batch 40, loss=0.0446, recon=0.0446, kl=149.6373, beta=0.0000\n",
      "Batch 60, loss=0.0529, recon=0.0529, kl=142.5479, beta=0.0000\n",
      "Batch 80, loss=0.0300, recon=0.0300, kl=136.9486, beta=0.0000\n",
      "Batch 100, loss=0.0320, recon=0.0320, kl=143.8877, beta=0.0000\n",
      "Batch 120, loss=0.0519, recon=0.0519, kl=138.5890, beta=0.0000\n",
      "Batch 140, loss=0.0293, recon=0.0292, kl=142.3326, beta=0.0000\n",
      "Batch 160, loss=0.0235, recon=0.0235, kl=145.5774, beta=0.0000\n",
      "Batch 180, loss=0.0262, recon=0.0262, kl=149.1212, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0390, KL: 143.6017, Current Beta: 0.0000) | Avg Valid Loss: 0.0331 | Avg Valid recon Loss: 0.0331\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0241, recon=0.0240, kl=151.4531, beta=0.0000\n",
      "Batch 40, loss=0.0186, recon=0.0186, kl=154.9454, beta=0.0000\n",
      "Batch 60, loss=0.0387, recon=0.0387, kl=155.2808, beta=0.0000\n",
      "Batch 80, loss=0.0729, recon=0.0729, kl=153.8362, beta=0.0000\n",
      "Batch 100, loss=0.0299, recon=0.0299, kl=154.2472, beta=0.0000\n",
      "Batch 120, loss=0.0230, recon=0.0230, kl=150.1693, beta=0.0000\n",
      "Batch 140, loss=0.0228, recon=0.0228, kl=153.3723, beta=0.0000\n",
      "Batch 160, loss=0.0390, recon=0.0390, kl=153.2814, beta=0.0000\n",
      "Batch 180, loss=0.0476, recon=0.0476, kl=152.4090, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0353 (Recon: 0.0353, KL: 152.7767, Current Beta: 0.0000) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0382, recon=0.0382, kl=125.5101, beta=0.0000\n",
      "Batch 40, loss=0.0332, recon=0.0332, kl=128.2173, beta=0.0000\n",
      "Batch 60, loss=0.3177, recon=0.3176, kl=145.5237, beta=0.0000\n",
      "Batch 80, loss=0.0384, recon=0.0384, kl=140.7122, beta=0.0000\n",
      "Batch 100, loss=0.0206, recon=0.0205, kl=141.9729, beta=0.0000\n",
      "Batch 120, loss=0.0180, recon=0.0180, kl=143.4363, beta=0.0000\n",
      "Batch 140, loss=0.0365, recon=0.0364, kl=145.2282, beta=0.0000\n",
      "Batch 160, loss=0.0333, recon=0.0332, kl=151.6299, beta=0.0000\n",
      "Batch 180, loss=0.0406, recon=0.0406, kl=152.0927, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0361 (Recon: 0.0361, KL: 142.3871, Current Beta: 0.0000) | Avg Valid Loss: 0.0320 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0177, recon=0.0175, kl=139.9101, beta=0.0000\n",
      "Batch 40, loss=0.0252, recon=0.0250, kl=130.9106, beta=0.0000\n",
      "Batch 60, loss=0.0437, recon=0.0435, kl=131.3422, beta=0.0000\n",
      "Batch 80, loss=0.0255, recon=0.0253, kl=132.0488, beta=0.0000\n",
      "Batch 100, loss=0.0349, recon=0.0348, kl=129.4263, beta=0.0000\n",
      "Batch 120, loss=0.0180, recon=0.0179, kl=127.9336, beta=0.0000\n",
      "Batch 140, loss=0.0319, recon=0.0318, kl=128.0078, beta=0.0000\n",
      "Batch 160, loss=0.0278, recon=0.0276, kl=129.3452, beta=0.0000\n",
      "Batch 180, loss=0.0713, recon=0.0712, kl=138.1942, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0338 (Recon: 0.0336, KL: 132.3721, Current Beta: 0.0000) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0269, recon=0.0265, kl=132.6313, beta=0.0000\n",
      "Batch 40, loss=0.0355, recon=0.0351, kl=135.4036, beta=0.0000\n",
      "Batch 60, loss=0.0356, recon=0.0352, kl=137.5031, beta=0.0000\n",
      "Batch 80, loss=0.0277, recon=0.0273, kl=132.0609, beta=0.0000\n",
      "Batch 100, loss=0.0337, recon=0.0334, kl=130.3591, beta=0.0000\n",
      "Batch 120, loss=0.0427, recon=0.0423, kl=130.7805, beta=0.0000\n",
      "Batch 140, loss=0.0288, recon=0.0284, kl=138.5435, beta=0.0000\n",
      "Batch 160, loss=0.0387, recon=0.0383, kl=130.9952, beta=0.0000\n",
      "Batch 180, loss=0.0720, recon=0.0715, kl=160.6653, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0415, KL: 135.5986, Current Beta: 0.0000) | Avg Valid Loss: 0.1764 | Avg Valid recon Loss: 0.1760\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0634, recon=0.0621, kl=171.8889, beta=0.0000\n",
      "Batch 40, loss=0.1226, recon=0.1214, kl=163.3987, beta=0.0000\n",
      "Batch 60, loss=0.1155, recon=0.1142, kl=173.9354, beta=0.0000\n",
      "Batch 80, loss=0.1035, recon=0.1020, kl=202.7858, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 13/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 14/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 19/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6944, recon=0.6944, kl=0.3035, beta=0.0000\n",
      "Batch 40, loss=0.4983, recon=0.4983, kl=1.2183, beta=0.0000\n",
      "Batch 60, loss=0.5848, recon=0.5848, kl=5.7944, beta=0.0000\n",
      "Batch 80, loss=0.3597, recon=0.3597, kl=9.6442, beta=0.0000\n",
      "Batch 100, loss=0.4324, recon=0.4324, kl=13.5694, beta=0.0000\n",
      "Batch 120, loss=0.3133, recon=0.3133, kl=16.4015, beta=0.0000\n",
      "Batch 140, loss=0.3721, recon=0.3721, kl=18.3442, beta=0.0000\n",
      "Batch 160, loss=0.2264, recon=0.2264, kl=20.2858, beta=0.0000\n",
      "Batch 180, loss=0.1881, recon=0.1881, kl=22.2972, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4638 (Recon: 0.4638, KL: 10.8944, Current Beta: 0.0000) | Avg Valid Loss: 0.2303 | Avg Valid recon Loss: 0.2303\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.4425, recon=0.4425, kl=24.0282, beta=0.0000\n",
      "Batch 40, loss=0.2203, recon=0.2203, kl=25.5016, beta=0.0000\n",
      "Batch 60, loss=0.1550, recon=0.1550, kl=26.6894, beta=0.0000\n",
      "Batch 80, loss=0.1641, recon=0.1641, kl=27.7197, beta=0.0000\n",
      "Batch 100, loss=0.1498, recon=0.1498, kl=29.5079, beta=0.0000\n",
      "Batch 120, loss=0.1292, recon=0.1292, kl=30.2016, beta=0.0000\n",
      "Batch 140, loss=0.1108, recon=0.1108, kl=30.6175, beta=0.0000\n",
      "Batch 160, loss=0.1075, recon=0.1075, kl=31.1690, beta=0.0000\n",
      "Batch 180, loss=0.1442, recon=0.1442, kl=32.2031, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1923 (Recon: 0.1923, KL: 28.1785, Current Beta: 0.0000) | Avg Valid Loss: 0.1418 | Avg Valid recon Loss: 0.1418\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1234, recon=0.1234, kl=33.3660, beta=0.0000\n",
      "Batch 40, loss=0.1071, recon=0.1071, kl=34.3481, beta=0.0000\n",
      "Batch 60, loss=0.1361, recon=0.1361, kl=35.8236, beta=0.0000\n",
      "Batch 80, loss=0.1035, recon=0.1035, kl=35.6874, beta=0.0000\n",
      "Batch 100, loss=0.1184, recon=0.1184, kl=36.4843, beta=0.0000\n",
      "Batch 120, loss=0.0790, recon=0.0790, kl=37.2377, beta=0.0000\n",
      "Batch 140, loss=0.0907, recon=0.0907, kl=38.4261, beta=0.0000\n",
      "Batch 160, loss=0.3918, recon=0.3918, kl=38.8587, beta=0.0000\n",
      "Batch 180, loss=0.1404, recon=0.1404, kl=39.6969, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1368 (Recon: 0.1368, KL: 36.2342, Current Beta: 0.0000) | Avg Valid Loss: 0.1109 | Avg Valid recon Loss: 0.1109\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0826, recon=0.0826, kl=40.3493, beta=0.0000\n",
      "Batch 40, loss=0.0853, recon=0.0853, kl=40.3801, beta=0.0000\n",
      "Batch 60, loss=0.1262, recon=0.1262, kl=40.9793, beta=0.0000\n",
      "Batch 80, loss=0.0641, recon=0.0641, kl=41.5000, beta=0.0000\n",
      "Batch 100, loss=0.0681, recon=0.0681, kl=41.7479, beta=0.0000\n",
      "Batch 120, loss=0.0529, recon=0.0529, kl=42.6719, beta=0.0000\n",
      "Batch 140, loss=0.0755, recon=0.0755, kl=42.9981, beta=0.0000\n",
      "Batch 160, loss=0.1173, recon=0.1173, kl=43.3836, beta=0.0000\n",
      "Batch 180, loss=0.1112, recon=0.1112, kl=44.2273, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1125 (Recon: 0.1125, KL: 41.8121, Current Beta: 0.0000) | Avg Valid Loss: 0.0943 | Avg Valid recon Loss: 0.0943\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0703, recon=0.0703, kl=44.7233, beta=0.0000\n",
      "Batch 40, loss=0.0607, recon=0.0607, kl=45.2303, beta=0.0000\n",
      "Batch 60, loss=0.0634, recon=0.0634, kl=45.2370, beta=0.0000\n",
      "Batch 80, loss=0.0702, recon=0.0702, kl=45.3386, beta=0.0000\n",
      "Batch 100, loss=0.1164, recon=0.1164, kl=45.5232, beta=0.0000\n",
      "Batch 120, loss=0.0471, recon=0.0471, kl=46.0789, beta=0.0000\n",
      "Batch 140, loss=0.0855, recon=0.0855, kl=46.3906, beta=0.0000\n",
      "Batch 160, loss=0.2067, recon=0.2067, kl=45.7124, beta=0.0000\n",
      "Batch 180, loss=0.0681, recon=0.0681, kl=46.3198, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0988 (Recon: 0.0988, KL: 45.5669, Current Beta: 0.0000) | Avg Valid Loss: 0.0869 | Avg Valid recon Loss: 0.0869\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0458, recon=0.0458, kl=46.8092, beta=0.0000\n",
      "Batch 40, loss=0.1032, recon=0.1032, kl=46.9793, beta=0.0000\n",
      "Batch 60, loss=0.0787, recon=0.0787, kl=46.7984, beta=0.0000\n",
      "Batch 80, loss=0.0482, recon=0.0482, kl=46.9432, beta=0.0000\n",
      "Batch 100, loss=0.0862, recon=0.0862, kl=47.0396, beta=0.0000\n",
      "Batch 120, loss=0.0452, recon=0.0452, kl=47.3931, beta=0.0000\n",
      "Batch 140, loss=0.0479, recon=0.0479, kl=48.0170, beta=0.0000\n",
      "Batch 160, loss=0.0574, recon=0.0574, kl=48.5110, beta=0.0000\n",
      "Batch 180, loss=0.0596, recon=0.0596, kl=48.4447, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0898 (Recon: 0.0898, KL: 47.3139, Current Beta: 0.0000) | Avg Valid Loss: 0.0782 | Avg Valid recon Loss: 0.0782\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0708, recon=0.0708, kl=49.1981, beta=0.0000\n",
      "Batch 40, loss=0.0488, recon=0.0488, kl=48.5108, beta=0.0000\n",
      "Batch 60, loss=0.0778, recon=0.0778, kl=48.3168, beta=0.0000\n",
      "Batch 80, loss=0.0614, recon=0.0614, kl=48.4203, beta=0.0000\n",
      "Batch 100, loss=0.0732, recon=0.0732, kl=47.7560, beta=0.0000\n",
      "Batch 120, loss=0.0808, recon=0.0808, kl=47.0392, beta=0.0000\n",
      "Batch 140, loss=0.0811, recon=0.0811, kl=47.8054, beta=0.0000\n",
      "Batch 160, loss=0.1162, recon=0.1162, kl=48.0772, beta=0.0000\n",
      "Batch 180, loss=0.0947, recon=0.0947, kl=48.7666, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0834 (Recon: 0.0834, KL: 48.2777, Current Beta: 0.0000) | Avg Valid Loss: 0.0737 | Avg Valid recon Loss: 0.0737\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0505, recon=0.0505, kl=48.3455, beta=0.0000\n",
      "Batch 40, loss=0.0693, recon=0.0693, kl=47.9633, beta=0.0000\n",
      "Batch 60, loss=0.0513, recon=0.0513, kl=47.7607, beta=0.0000\n",
      "Batch 80, loss=0.0525, recon=0.0524, kl=47.6066, beta=0.0000\n",
      "Batch 100, loss=0.0508, recon=0.0508, kl=46.0349, beta=0.0000\n",
      "Batch 120, loss=0.0546, recon=0.0546, kl=46.3664, beta=0.0000\n",
      "Batch 140, loss=0.0790, recon=0.0790, kl=46.2946, beta=0.0000\n",
      "Batch 160, loss=0.0611, recon=0.0611, kl=45.6048, beta=0.0000\n",
      "Batch 180, loss=0.0727, recon=0.0726, kl=45.6264, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0784 (Recon: 0.0784, KL: 47.0138, Current Beta: 0.0000) | Avg Valid Loss: 0.0701 | Avg Valid recon Loss: 0.0701\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0645, recon=0.0645, kl=44.3599, beta=0.0000\n",
      "Batch 40, loss=0.1098, recon=0.1098, kl=43.2077, beta=0.0000\n",
      "Batch 60, loss=0.0434, recon=0.0434, kl=42.0313, beta=0.0000\n",
      "Batch 80, loss=0.0562, recon=0.0562, kl=40.1530, beta=0.0000\n",
      "Batch 100, loss=0.0508, recon=0.0508, kl=39.2834, beta=0.0000\n",
      "Batch 120, loss=0.0465, recon=0.0464, kl=38.9392, beta=0.0000\n",
      "Batch 140, loss=0.0656, recon=0.0656, kl=38.3533, beta=0.0000\n",
      "Batch 160, loss=0.0676, recon=0.0676, kl=37.5636, beta=0.0000\n",
      "Batch 180, loss=0.0894, recon=0.0894, kl=37.5315, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0746 (Recon: 0.0746, KL: 40.5737, Current Beta: 0.0000) | Avg Valid Loss: 0.0667 | Avg Valid recon Loss: 0.0666\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0642, recon=0.0641, kl=35.4407, beta=0.0000\n",
      "Batch 40, loss=0.0973, recon=0.0973, kl=32.3179, beta=0.0000\n",
      "Batch 60, loss=0.0355, recon=0.0355, kl=29.4759, beta=0.0000\n",
      "Batch 80, loss=0.0393, recon=0.0392, kl=29.2003, beta=0.0000\n",
      "Batch 100, loss=0.0626, recon=0.0626, kl=28.3413, beta=0.0000\n",
      "Batch 120, loss=0.0463, recon=0.0463, kl=27.7118, beta=0.0000\n",
      "Batch 140, loss=0.0567, recon=0.0566, kl=27.1074, beta=0.0000\n",
      "Batch 160, loss=0.0545, recon=0.0544, kl=26.9779, beta=0.0000\n",
      "Batch 180, loss=0.1502, recon=0.1502, kl=26.5969, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0714 (Recon: 0.0713, KL: 29.7680, Current Beta: 0.0000) | Avg Valid Loss: 0.0633 | Avg Valid recon Loss: 0.0632\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0452, recon=0.0451, kl=23.0211, beta=0.0000\n",
      "Batch 40, loss=0.0612, recon=0.0612, kl=19.0671, beta=0.0000\n",
      "Batch 60, loss=0.0353, recon=0.0353, kl=17.5465, beta=0.0000\n",
      "Batch 80, loss=0.0702, recon=0.0702, kl=17.3522, beta=0.0000\n",
      "Batch 100, loss=0.0633, recon=0.0632, kl=16.9886, beta=0.0000\n",
      "Batch 120, loss=0.0642, recon=0.0642, kl=17.7254, beta=0.0000\n",
      "Batch 140, loss=0.0340, recon=0.0339, kl=17.4772, beta=0.0000\n",
      "Batch 160, loss=0.0685, recon=0.0684, kl=16.5905, beta=0.0000\n",
      "Batch 180, loss=0.0472, recon=0.0471, kl=17.0315, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0686 (Recon: 0.0686, KL: 18.5973, Current Beta: 0.0000) | Avg Valid Loss: 0.0607 | Avg Valid recon Loss: 0.0607\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0372, recon=0.0371, kl=13.4773, beta=0.0000\n",
      "Batch 40, loss=0.0367, recon=0.0366, kl=10.3258, beta=0.0000\n",
      "Batch 60, loss=0.0369, recon=0.0368, kl=10.0551, beta=0.0000\n",
      "Batch 80, loss=0.0407, recon=0.0406, kl=9.8322, beta=0.0000\n",
      "Batch 100, loss=0.0383, recon=0.0383, kl=9.1919, beta=0.0000\n",
      "Batch 120, loss=0.0389, recon=0.0388, kl=8.9811, beta=0.0000\n",
      "Batch 140, loss=0.0518, recon=0.0518, kl=8.5087, beta=0.0000\n",
      "Batch 160, loss=0.0581, recon=0.0580, kl=9.3298, beta=0.0000\n",
      "Batch 180, loss=0.0590, recon=0.0589, kl=8.4053, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0664 (Recon: 0.0664, KL: 10.2391, Current Beta: 0.0000) | Avg Valid Loss: 0.0589 | Avg Valid recon Loss: 0.0588\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0565, recon=0.0564, kl=5.0914, beta=0.0000\n",
      "Batch 40, loss=0.0385, recon=0.0384, kl=4.8504, beta=0.0000\n",
      "Batch 60, loss=0.0595, recon=0.0594, kl=4.3178, beta=0.0000\n",
      "Batch 80, loss=0.0424, recon=0.0424, kl=4.2861, beta=0.0000\n",
      "Batch 100, loss=0.0842, recon=0.0841, kl=3.9245, beta=0.0000\n",
      "Batch 120, loss=0.0714, recon=0.0713, kl=3.5916, beta=0.0000\n",
      "Batch 140, loss=0.0345, recon=0.0344, kl=3.7598, beta=0.0000\n",
      "Batch 160, loss=0.0396, recon=0.0395, kl=3.2781, beta=0.0000\n",
      "Batch 180, loss=0.1758, recon=0.1757, kl=3.5818, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0641 (Recon: 0.0640, KL: 4.3129, Current Beta: 0.0000) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0565\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0880, recon=0.0879, kl=1.8834, beta=0.0000\n",
      "Batch 40, loss=0.0289, recon=0.0288, kl=1.7992, beta=0.0000\n",
      "Batch 60, loss=0.0402, recon=0.0401, kl=1.9902, beta=0.0000\n",
      "Batch 80, loss=0.0529, recon=0.0528, kl=1.4335, beta=0.0000\n",
      "Batch 100, loss=1.1306, recon=1.1306, kl=1.5835, beta=0.0000\n",
      "Batch 120, loss=0.0455, recon=0.0454, kl=1.3395, beta=0.0000\n",
      "Batch 140, loss=0.0374, recon=0.0374, kl=1.5098, beta=0.0000\n",
      "Batch 160, loss=0.1108, recon=0.1107, kl=1.1340, beta=0.0000\n",
      "Batch 180, loss=0.0367, recon=0.0366, kl=1.4831, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0624 (Recon: 0.0624, KL: 1.6881, Current Beta: 0.0000) | Avg Valid Loss: 0.0549 | Avg Valid recon Loss: 0.0548\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0414, recon=0.0413, kl=0.7273, beta=0.0001\n",
      "Batch 40, loss=0.0379, recon=0.0379, kl=0.6935, beta=0.0001\n",
      "Batch 60, loss=0.0612, recon=0.0612, kl=0.7886, beta=0.0001\n",
      "Batch 80, loss=0.0518, recon=0.0518, kl=0.7774, beta=0.0001\n",
      "Batch 100, loss=0.0410, recon=0.0409, kl=0.8539, beta=0.0001\n",
      "Batch 120, loss=0.0286, recon=0.0286, kl=0.5003, beta=0.0001\n",
      "Batch 140, loss=0.0466, recon=0.0466, kl=0.5726, beta=0.0001\n",
      "Batch 160, loss=0.0380, recon=0.0379, kl=0.7646, beta=0.0001\n",
      "Batch 180, loss=0.0496, recon=0.0495, kl=0.5585, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0605 (Recon: 0.0604, KL: 0.7373, Current Beta: 0.0001) | Avg Valid Loss: 0.0543 | Avg Valid recon Loss: 0.0542\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0478, recon=0.0478, kl=0.2506, beta=0.0001\n",
      "Batch 40, loss=0.0364, recon=0.0363, kl=0.2720, beta=0.0001\n",
      "Batch 60, loss=0.0419, recon=0.0419, kl=0.1388, beta=0.0001\n",
      "Batch 80, loss=0.0363, recon=0.0362, kl=0.2678, beta=0.0001\n",
      "Batch 100, loss=0.0499, recon=0.0499, kl=0.1467, beta=0.0001\n",
      "Batch 120, loss=0.0699, recon=0.0699, kl=0.1790, beta=0.0001\n",
      "Batch 140, loss=0.0600, recon=0.0599, kl=0.1842, beta=0.0001\n",
      "Batch 160, loss=0.0555, recon=0.0555, kl=0.1362, beta=0.0001\n",
      "Batch 180, loss=0.0693, recon=0.0693, kl=0.0743, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0590 (Recon: 0.0590, KL: 0.2081, Current Beta: 0.0001) | Avg Valid Loss: 0.0521 | Avg Valid recon Loss: 0.0521\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0579, recon=0.0579, kl=0.1307, beta=0.0001\n",
      "Batch 40, loss=0.0379, recon=0.0379, kl=0.0951, beta=0.0001\n",
      "Batch 60, loss=0.0362, recon=0.0362, kl=0.0471, beta=0.0001\n",
      "Batch 80, loss=0.0495, recon=0.0495, kl=0.0731, beta=0.0001\n",
      "Batch 100, loss=0.2381, recon=0.2381, kl=0.1083, beta=0.0001\n",
      "Batch 120, loss=0.0541, recon=0.0541, kl=0.0953, beta=0.0001\n",
      "Batch 140, loss=0.0413, recon=0.0413, kl=0.0868, beta=0.0001\n",
      "Batch 160, loss=0.0617, recon=0.0617, kl=0.0455, beta=0.0001\n",
      "Batch 180, loss=0.0585, recon=0.0585, kl=0.0605, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0577 (Recon: 0.0577, KL: 0.0817, Current Beta: 0.0001) | Avg Valid Loss: 0.0508 | Avg Valid recon Loss: 0.0508\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0439, recon=0.0439, kl=0.0661, beta=0.0001\n",
      "Batch 40, loss=0.0562, recon=0.0562, kl=0.0536, beta=0.0001\n",
      "Batch 60, loss=0.0369, recon=0.0369, kl=0.0462, beta=0.0001\n",
      "Batch 80, loss=0.0452, recon=0.0452, kl=0.0278, beta=0.0001\n",
      "Batch 100, loss=0.2458, recon=0.2458, kl=0.0556, beta=0.0001\n",
      "Batch 120, loss=0.0357, recon=0.0357, kl=0.0671, beta=0.0001\n",
      "Batch 140, loss=0.0481, recon=0.0481, kl=0.0463, beta=0.0001\n",
      "Batch 160, loss=0.0279, recon=0.0279, kl=0.0178, beta=0.0001\n",
      "Batch 180, loss=0.0423, recon=0.0423, kl=0.0345, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0564 (Recon: 0.0564, KL: 0.0478, Current Beta: 0.0001) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0499\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0287, recon=0.0287, kl=0.0141, beta=0.0001\n",
      "Batch 40, loss=0.0413, recon=0.0413, kl=0.0325, beta=0.0001\n",
      "Batch 60, loss=0.0479, recon=0.0479, kl=0.0181, beta=0.0001\n",
      "Batch 80, loss=0.0605, recon=0.0605, kl=0.0364, beta=0.0001\n",
      "Batch 100, loss=0.0368, recon=0.0368, kl=0.0382, beta=0.0001\n",
      "Batch 120, loss=0.0327, recon=0.0327, kl=0.0154, beta=0.0001\n",
      "Batch 140, loss=0.0362, recon=0.0362, kl=0.0134, beta=0.0001\n",
      "Batch 160, loss=0.0543, recon=0.0543, kl=0.0168, beta=0.0001\n",
      "Batch 180, loss=0.0434, recon=0.0434, kl=0.0204, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0551 (Recon: 0.0551, KL: 0.0228, Current Beta: 0.0001) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0316, recon=0.0316, kl=0.0098, beta=0.0001\n",
      "Batch 40, loss=0.0419, recon=0.0419, kl=0.0292, beta=0.0001\n",
      "Batch 60, loss=0.0309, recon=0.0309, kl=0.0122, beta=0.0001\n",
      "Batch 80, loss=0.0598, recon=0.0598, kl=0.0248, beta=0.0001\n",
      "Batch 100, loss=0.0490, recon=0.0490, kl=0.0246, beta=0.0001\n",
      "Batch 120, loss=0.0587, recon=0.0587, kl=0.0268, beta=0.0001\n",
      "Batch 140, loss=0.0400, recon=0.0400, kl=0.0195, beta=0.0001\n",
      "Batch 160, loss=0.0350, recon=0.0350, kl=0.0117, beta=0.0001\n",
      "Batch 180, loss=0.0413, recon=0.0413, kl=0.0077, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0542 (Recon: 0.0542, KL: 0.0180, Current Beta: 0.0001) | Avg Valid Loss: 0.0476 | Avg Valid recon Loss: 0.0476\n",
      "\n",
      "[VRAE Run 20/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1941, recon=0.1941, kl=14.8093, beta=0.0000\n",
      "Batch 40, loss=0.1103, recon=0.1103, kl=21.0526, beta=0.0000\n",
      "Batch 60, loss=0.1443, recon=0.1443, kl=24.5763, beta=0.0000\n",
      "Batch 80, loss=0.0714, recon=0.0714, kl=29.5150, beta=0.0000\n",
      "Batch 100, loss=0.1202, recon=0.1202, kl=32.0860, beta=0.0000\n",
      "Batch 120, loss=0.1243, recon=0.1243, kl=32.6570, beta=0.0000\n",
      "Batch 140, loss=0.1246, recon=0.1246, kl=32.8253, beta=0.0000\n",
      "Batch 160, loss=0.0838, recon=0.0838, kl=31.8632, beta=0.0000\n",
      "Batch 180, loss=0.5250, recon=0.5250, kl=33.0187, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1759 (Recon: 0.1759, KL: 26.1004, Current Beta: 0.0000) | Avg Valid Loss: 0.0866 | Avg Valid recon Loss: 0.0866\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1096, recon=0.1096, kl=36.4871, beta=0.0000\n",
      "Batch 40, loss=0.2202, recon=0.2202, kl=39.2997, beta=0.0000\n",
      "Batch 60, loss=0.1201, recon=0.1201, kl=34.8671, beta=0.0000\n",
      "Batch 80, loss=0.0430, recon=0.0430, kl=38.4091, beta=0.0000\n",
      "Batch 100, loss=0.0479, recon=0.0479, kl=33.1517, beta=0.0000\n",
      "Batch 120, loss=0.2785, recon=0.2785, kl=34.8149, beta=0.0000\n",
      "Batch 140, loss=0.0687, recon=0.0687, kl=37.6665, beta=0.0000\n",
      "Batch 160, loss=0.0687, recon=0.0687, kl=39.1468, beta=0.0000\n",
      "Batch 180, loss=0.0801, recon=0.0801, kl=41.0661, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0803 (Recon: 0.0803, KL: 36.8343, Current Beta: 0.0000) | Avg Valid Loss: 0.0576 | Avg Valid recon Loss: 0.0576\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0862, recon=0.0862, kl=30.6999, beta=0.0000\n",
      "Batch 40, loss=0.0340, recon=0.0340, kl=30.9874, beta=0.0000\n",
      "Batch 60, loss=0.0630, recon=0.0630, kl=34.4297, beta=0.0000\n",
      "Batch 80, loss=0.0401, recon=0.0401, kl=35.6412, beta=0.0000\n",
      "Batch 100, loss=0.0362, recon=0.0362, kl=37.4568, beta=0.0000\n",
      "Batch 120, loss=0.0242, recon=0.0242, kl=38.0967, beta=0.0000\n",
      "Batch 140, loss=0.2067, recon=0.2067, kl=40.4803, beta=0.0000\n",
      "Batch 160, loss=0.0422, recon=0.0422, kl=39.5095, beta=0.0000\n",
      "Batch 180, loss=0.0570, recon=0.0570, kl=40.0512, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0610 (Recon: 0.0610, KL: 36.3766, Current Beta: 0.0000) | Avg Valid Loss: 0.0589 | Avg Valid recon Loss: 0.0589\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0456, recon=0.0456, kl=39.9470, beta=0.0000\n",
      "Batch 40, loss=0.0509, recon=0.0509, kl=40.7483, beta=0.0000\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=40.5130, beta=0.0000\n",
      "Batch 80, loss=0.0376, recon=0.0376, kl=41.5860, beta=0.0000\n",
      "Batch 100, loss=0.0428, recon=0.0428, kl=41.7605, beta=0.0000\n",
      "Batch 120, loss=0.0361, recon=0.0361, kl=40.9434, beta=0.0000\n",
      "Batch 140, loss=0.0509, recon=0.0509, kl=36.9447, beta=0.0000\n",
      "Batch 160, loss=0.0317, recon=0.0317, kl=35.0106, beta=0.0000\n",
      "Batch 180, loss=0.0667, recon=0.0667, kl=34.5535, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0583 (Recon: 0.0583, KL: 39.3570, Current Beta: 0.0000) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=35.5997, beta=0.0000\n",
      "Batch 40, loss=0.0305, recon=0.0305, kl=38.5432, beta=0.0000\n",
      "Batch 60, loss=0.0520, recon=0.0520, kl=40.3882, beta=0.0000\n",
      "Batch 80, loss=0.0496, recon=0.0496, kl=40.8455, beta=0.0000\n",
      "Batch 100, loss=0.0338, recon=0.0338, kl=41.5572, beta=0.0000\n",
      "Batch 120, loss=0.0320, recon=0.0320, kl=41.6069, beta=0.0000\n",
      "Batch 140, loss=0.0294, recon=0.0294, kl=42.1893, beta=0.0000\n",
      "Batch 160, loss=0.0395, recon=0.0395, kl=44.4575, beta=0.0000\n",
      "Batch 180, loss=0.0312, recon=0.0312, kl=39.2435, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0526 (Recon: 0.0526, KL: 40.2214, Current Beta: 0.0000) | Avg Valid Loss: 0.0471 | Avg Valid recon Loss: 0.0471\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0637, recon=0.0637, kl=39.8774, beta=0.0000\n",
      "Batch 40, loss=0.0620, recon=0.0620, kl=41.6121, beta=0.0000\n",
      "Batch 60, loss=0.0716, recon=0.0716, kl=45.9734, beta=0.0000\n",
      "Batch 80, loss=0.0485, recon=0.0485, kl=46.6849, beta=0.0000\n",
      "Batch 100, loss=0.0438, recon=0.0438, kl=48.5220, beta=0.0000\n",
      "Batch 120, loss=0.1795, recon=0.1795, kl=49.8081, beta=0.0000\n",
      "Batch 140, loss=0.0338, recon=0.0338, kl=49.4609, beta=0.0000\n",
      "Batch 160, loss=0.0275, recon=0.0275, kl=46.7374, beta=0.0000\n",
      "Batch 180, loss=0.0325, recon=0.0325, kl=45.7400, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0531 (Recon: 0.0531, KL: 45.6745, Current Beta: 0.0000) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0411, recon=0.0411, kl=46.1005, beta=0.0000\n",
      "Batch 40, loss=0.0342, recon=0.0342, kl=46.4676, beta=0.0000\n",
      "Batch 60, loss=0.0370, recon=0.0370, kl=45.0375, beta=0.0000\n",
      "Batch 80, loss=0.0561, recon=0.0561, kl=43.3811, beta=0.0000\n",
      "Batch 100, loss=0.0316, recon=0.0316, kl=42.8715, beta=0.0000\n",
      "Batch 120, loss=0.0367, recon=0.0367, kl=42.2280, beta=0.0000\n",
      "Batch 140, loss=0.0296, recon=0.0296, kl=41.5083, beta=0.0000\n",
      "Batch 160, loss=0.0406, recon=0.0406, kl=42.3913, beta=0.0000\n",
      "Batch 180, loss=0.0395, recon=0.0395, kl=40.9329, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0464 (Recon: 0.0464, KL: 43.6354, Current Beta: 0.0000) | Avg Valid Loss: 0.0503 | Avg Valid recon Loss: 0.0503\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0395, recon=0.0395, kl=40.3932, beta=0.0000\n",
      "Batch 40, loss=0.0544, recon=0.0544, kl=37.9463, beta=0.0000\n",
      "Batch 60, loss=0.0208, recon=0.0208, kl=38.2013, beta=0.0000\n",
      "Batch 80, loss=0.0257, recon=0.0257, kl=38.6788, beta=0.0000\n",
      "Batch 100, loss=0.0778, recon=0.0778, kl=38.6131, beta=0.0000\n",
      "Batch 120, loss=0.0481, recon=0.0481, kl=36.3517, beta=0.0000\n",
      "Batch 140, loss=0.0418, recon=0.0418, kl=39.3473, beta=0.0000\n",
      "Batch 160, loss=0.0475, recon=0.0475, kl=37.5030, beta=0.0000\n",
      "Batch 180, loss=0.0501, recon=0.0501, kl=40.4027, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0627 (Recon: 0.0627, KL: 38.7971, Current Beta: 0.0000) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0256, recon=0.0256, kl=39.2080, beta=0.0000\n",
      "Batch 40, loss=0.0378, recon=0.0378, kl=38.8191, beta=0.0000\n",
      "Batch 60, loss=0.0690, recon=0.0690, kl=37.1338, beta=0.0000\n",
      "Batch 80, loss=0.0438, recon=0.0437, kl=36.7185, beta=0.0000\n",
      "Batch 100, loss=0.0545, recon=0.0545, kl=35.3236, beta=0.0000\n",
      "Batch 120, loss=0.0328, recon=0.0328, kl=35.2707, beta=0.0000\n",
      "Batch 140, loss=0.0241, recon=0.0241, kl=33.1117, beta=0.0000\n",
      "Batch 160, loss=0.0262, recon=0.0262, kl=28.6849, beta=0.0000\n",
      "Batch 180, loss=0.0300, recon=0.0300, kl=31.1345, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0498 (Recon: 0.0498, KL: 35.5846, Current Beta: 0.0000) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0484, recon=0.0484, kl=30.0549, beta=0.0000\n",
      "Batch 40, loss=0.0539, recon=0.0539, kl=26.0602, beta=0.0000\n",
      "Batch 60, loss=0.0350, recon=0.0350, kl=21.7041, beta=0.0000\n",
      "Batch 80, loss=0.1578, recon=0.1578, kl=19.4583, beta=0.0000\n",
      "Batch 100, loss=0.0239, recon=0.0239, kl=25.3301, beta=0.0000\n",
      "Batch 120, loss=0.0308, recon=0.0308, kl=25.5865, beta=0.0000\n",
      "Batch 140, loss=0.0439, recon=0.0439, kl=25.1707, beta=0.0000\n",
      "Batch 160, loss=0.0477, recon=0.0476, kl=25.2606, beta=0.0000\n",
      "Batch 180, loss=0.0444, recon=0.0443, kl=23.2917, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0446, KL: 25.2504, Current Beta: 0.0000) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0330, recon=0.0330, kl=19.6744, beta=0.0000\n",
      "Batch 40, loss=0.4865, recon=0.4865, kl=15.5243, beta=0.0000\n",
      "Batch 60, loss=0.0350, recon=0.0349, kl=20.9405, beta=0.0000\n",
      "Batch 80, loss=0.0247, recon=0.0246, kl=20.5751, beta=0.0000\n",
      "Batch 100, loss=0.0307, recon=0.0307, kl=17.9358, beta=0.0000\n",
      "Batch 120, loss=0.0362, recon=0.0361, kl=18.5502, beta=0.0000\n",
      "Batch 140, loss=0.0436, recon=0.0436, kl=17.0138, beta=0.0000\n",
      "Batch 160, loss=0.0285, recon=0.0284, kl=15.5878, beta=0.0000\n",
      "Batch 180, loss=0.0344, recon=0.0343, kl=15.5290, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0419, KL: 18.3429, Current Beta: 0.0000) | Avg Valid Loss: 0.0343 | Avg Valid recon Loss: 0.0343\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0228, recon=0.0227, kl=9.9551, beta=0.0000\n",
      "Batch 40, loss=0.0828, recon=0.0827, kl=8.5782, beta=0.0000\n",
      "Batch 60, loss=0.0308, recon=0.0307, kl=12.2445, beta=0.0000\n",
      "Batch 80, loss=0.0419, recon=0.0419, kl=10.8443, beta=0.0000\n",
      "Batch 100, loss=0.0326, recon=0.0325, kl=15.9677, beta=0.0000\n",
      "Batch 120, loss=0.0363, recon=0.0362, kl=11.6873, beta=0.0000\n",
      "Batch 140, loss=0.0424, recon=0.0424, kl=8.5067, beta=0.0000\n",
      "Batch 160, loss=0.0229, recon=0.0229, kl=7.2595, beta=0.0000\n",
      "Batch 180, loss=0.0368, recon=0.0367, kl=5.8231, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0475 (Recon: 0.0475, KL: 10.5064, Current Beta: 0.0000) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=3.6601, beta=0.0000\n",
      "Batch 40, loss=0.0222, recon=0.0221, kl=5.3933, beta=0.0000\n",
      "Batch 60, loss=0.0399, recon=0.0398, kl=4.3850, beta=0.0000\n",
      "Batch 80, loss=0.0489, recon=0.0488, kl=2.6581, beta=0.0000\n",
      "Batch 100, loss=0.4331, recon=0.4330, kl=2.0809, beta=0.0000\n",
      "Batch 120, loss=0.1098, recon=0.1097, kl=8.1053, beta=0.0000\n",
      "Batch 140, loss=0.0641, recon=0.0640, kl=8.0709, beta=0.0000\n",
      "Batch 160, loss=0.0418, recon=0.0417, kl=4.2983, beta=0.0000\n",
      "Batch 180, loss=0.0357, recon=0.0356, kl=4.4465, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0623 (Recon: 0.0622, KL: 4.7778, Current Beta: 0.0000) | Avg Valid Loss: 0.0484 | Avg Valid recon Loss: 0.0483\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0434, recon=0.0432, kl=5.5649, beta=0.0000\n",
      "Batch 40, loss=0.0766, recon=0.0764, kl=4.5165, beta=0.0000\n",
      "Batch 60, loss=0.0281, recon=0.0280, kl=2.9033, beta=0.0000\n",
      "Batch 80, loss=0.0341, recon=0.0340, kl=2.2908, beta=0.0000\n",
      "Batch 100, loss=0.0365, recon=0.0364, kl=1.6789, beta=0.0000\n",
      "Batch 120, loss=0.0328, recon=0.0328, kl=1.2622, beta=0.0000\n",
      "Batch 140, loss=0.0294, recon=0.0293, kl=1.1115, beta=0.0000\n",
      "Batch 160, loss=0.0465, recon=0.0465, kl=0.9498, beta=0.0000\n",
      "Batch 180, loss=0.0330, recon=0.0330, kl=0.8478, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0493 (Recon: 0.0492, KL: 2.5700, Current Beta: 0.0000) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0466, recon=0.0465, kl=0.7358, beta=0.0001\n",
      "Batch 40, loss=0.0528, recon=0.0528, kl=0.3555, beta=0.0001\n",
      "Batch 60, loss=0.1400, recon=0.1400, kl=0.4565, beta=0.0001\n",
      "Batch 80, loss=0.0376, recon=0.0375, kl=0.2974, beta=0.0001\n",
      "Batch 100, loss=0.0236, recon=0.0236, kl=0.3293, beta=0.0001\n",
      "Batch 120, loss=0.0563, recon=0.0562, kl=0.6504, beta=0.0001\n",
      "Batch 140, loss=0.0239, recon=0.0238, kl=0.6828, beta=0.0001\n",
      "Batch 160, loss=0.0263, recon=0.0263, kl=0.5167, beta=0.0001\n",
      "Batch 180, loss=0.0560, recon=0.0560, kl=0.2964, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 0.5139, Current Beta: 0.0001) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0363, recon=0.0363, kl=0.1381, beta=0.0001\n",
      "Batch 40, loss=0.0250, recon=0.0250, kl=0.0815, beta=0.0001\n",
      "Batch 60, loss=0.0759, recon=0.0759, kl=0.1543, beta=0.0001\n",
      "Batch 80, loss=0.0636, recon=0.0636, kl=0.2356, beta=0.0001\n",
      "Batch 100, loss=0.0275, recon=0.0275, kl=0.1468, beta=0.0001\n",
      "Batch 120, loss=0.0341, recon=0.0341, kl=0.0696, beta=0.0001\n",
      "Batch 140, loss=0.0336, recon=0.0336, kl=0.0266, beta=0.0001\n",
      "Batch 160, loss=0.0381, recon=0.0381, kl=0.0140, beta=0.0001\n",
      "Batch 180, loss=0.0634, recon=0.0633, kl=0.0276, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0407 (Recon: 0.0407, KL: 0.1106, Current Beta: 0.0001) | Avg Valid Loss: 0.0489 | Avg Valid recon Loss: 0.0489\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0547, recon=0.0547, kl=0.1211, beta=0.0001\n",
      "Batch 40, loss=0.0481, recon=0.0481, kl=0.0947, beta=0.0001\n",
      "Batch 60, loss=0.1362, recon=0.1362, kl=0.0638, beta=0.0001\n",
      "Batch 80, loss=0.0256, recon=0.0256, kl=0.0389, beta=0.0001\n",
      "Batch 100, loss=0.0281, recon=0.0281, kl=0.0285, beta=0.0001\n",
      "Batch 120, loss=0.0338, recon=0.0337, kl=0.0820, beta=0.0001\n",
      "Batch 140, loss=0.0634, recon=0.0634, kl=0.0829, beta=0.0001\n",
      "Batch 160, loss=0.0314, recon=0.0314, kl=0.0695, beta=0.0001\n",
      "Batch 180, loss=0.0287, recon=0.0287, kl=0.2248, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 0.0784, Current Beta: 0.0001) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0366, recon=0.0366, kl=0.2587, beta=0.0001\n",
      "Batch 40, loss=0.0431, recon=0.0430, kl=0.1987, beta=0.0001\n",
      "Batch 60, loss=0.0336, recon=0.0336, kl=0.0962, beta=0.0001\n",
      "Batch 80, loss=0.0255, recon=0.0255, kl=0.0657, beta=0.0001\n",
      "Batch 100, loss=0.0311, recon=0.0311, kl=0.0795, beta=0.0001\n",
      "Batch 120, loss=0.0495, recon=0.0495, kl=0.0526, beta=0.0001\n",
      "Batch 140, loss=0.0275, recon=0.0275, kl=0.0217, beta=0.0001\n",
      "Batch 160, loss=0.0314, recon=0.0314, kl=0.0124, beta=0.0001\n",
      "Batch 180, loss=0.0506, recon=0.0506, kl=0.0178, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 0.1020, Current Beta: 0.0001) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0377, recon=0.0377, kl=0.0271, beta=0.0001\n",
      "Batch 40, loss=0.0326, recon=0.0326, kl=0.0326, beta=0.0001\n",
      "Batch 60, loss=0.0296, recon=0.0296, kl=0.0753, beta=0.0001\n",
      "Batch 80, loss=0.0357, recon=0.0357, kl=0.3556, beta=0.0001\n",
      "Batch 100, loss=0.0343, recon=0.0343, kl=0.2931, beta=0.0001\n",
      "Batch 120, loss=0.0525, recon=0.0525, kl=0.1424, beta=0.0001\n",
      "Batch 140, loss=0.0330, recon=0.0330, kl=0.0530, beta=0.0001\n",
      "Batch 160, loss=0.0315, recon=0.0315, kl=0.1244, beta=0.0001\n",
      "Batch 180, loss=0.0288, recon=0.0288, kl=0.2085, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0431, KL: 0.1364, Current Beta: 0.0001) | Avg Valid Loss: 0.0319 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0303, recon=0.0303, kl=0.1764, beta=0.0001\n",
      "Batch 40, loss=0.0305, recon=0.0305, kl=0.1551, beta=0.0001\n",
      "Batch 60, loss=0.0420, recon=0.0420, kl=0.1103, beta=0.0001\n",
      "Batch 80, loss=0.0217, recon=0.0217, kl=0.0685, beta=0.0001\n",
      "Batch 100, loss=0.0668, recon=0.0668, kl=0.4031, beta=0.0001\n",
      "Batch 120, loss=0.0250, recon=0.0249, kl=0.6744, beta=0.0001\n",
      "Batch 140, loss=0.0372, recon=0.0372, kl=0.5310, beta=0.0001\n",
      "Batch 160, loss=0.0366, recon=0.0365, kl=0.3580, beta=0.0001\n",
      "Batch 180, loss=0.0302, recon=0.0301, kl=0.2403, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0388, KL: 0.3009, Current Beta: 0.0001) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0327\n",
      "\n",
      "[VRAE Run 21/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.9021, recon=0.9021, kl=0.5612, beta=0.0000\n",
      "Batch 40, loss=0.4476, recon=0.4476, kl=3.3428, beta=0.0000\n",
      "Batch 60, loss=0.4101, recon=0.4101, kl=13.3089, beta=0.0000\n",
      "Batch 80, loss=0.5468, recon=0.5468, kl=20.7903, beta=0.0000\n",
      "Batch 100, loss=0.2826, recon=0.2826, kl=28.7441, beta=0.0000\n",
      "Batch 120, loss=0.1719, recon=0.1719, kl=35.2271, beta=0.0000\n",
      "Batch 140, loss=0.1889, recon=0.1889, kl=40.2826, beta=0.0000\n",
      "Batch 160, loss=0.2330, recon=0.2330, kl=45.3816, beta=0.0000\n",
      "Batch 180, loss=0.1517, recon=0.1517, kl=49.3579, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4342 (Recon: 0.4342, KL: 23.8411, Current Beta: 0.0000) | Avg Valid Loss: 0.2256 | Avg Valid recon Loss: 0.2256\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2072, recon=0.2072, kl=52.8791, beta=0.0000\n",
      "Batch 40, loss=0.1395, recon=0.1395, kl=55.5337, beta=0.0000\n",
      "Batch 60, loss=0.1711, recon=0.1711, kl=58.3189, beta=0.0000\n",
      "Batch 80, loss=0.1509, recon=0.1509, kl=60.7716, beta=0.0000\n",
      "Batch 100, loss=0.1829, recon=0.1829, kl=62.6375, beta=0.0000\n",
      "Batch 120, loss=0.1550, recon=0.1550, kl=63.7603, beta=0.0000\n",
      "Batch 140, loss=0.1130, recon=0.1130, kl=65.5491, beta=0.0000\n",
      "Batch 160, loss=0.2692, recon=0.2692, kl=67.1722, beta=0.0000\n",
      "Batch 180, loss=0.1490, recon=0.1490, kl=68.8959, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1918 (Recon: 0.1918, KL: 60.7884, Current Beta: 0.0000) | Avg Valid Loss: 0.1384 | Avg Valid recon Loss: 0.1384\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1778, recon=0.1778, kl=69.7611, beta=0.0000\n",
      "Batch 40, loss=0.0808, recon=0.0808, kl=70.6187, beta=0.0000\n",
      "Batch 60, loss=0.1072, recon=0.1072, kl=72.0518, beta=0.0000\n",
      "Batch 80, loss=0.0759, recon=0.0759, kl=73.0176, beta=0.0000\n",
      "Batch 100, loss=0.0923, recon=0.0923, kl=73.3478, beta=0.0000\n",
      "Batch 120, loss=0.1086, recon=0.1086, kl=74.2575, beta=0.0000\n",
      "Batch 140, loss=0.1021, recon=0.1021, kl=75.4134, beta=0.0000\n",
      "Batch 160, loss=0.1251, recon=0.1251, kl=76.8544, beta=0.0000\n",
      "Batch 180, loss=0.0879, recon=0.0879, kl=77.9164, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1376 (Recon: 0.1376, KL: 73.2194, Current Beta: 0.0000) | Avg Valid Loss: 0.1090 | Avg Valid recon Loss: 0.1090\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0867, recon=0.0867, kl=78.6175, beta=0.0000\n",
      "Batch 40, loss=0.0570, recon=0.0570, kl=79.0783, beta=0.0000\n",
      "Batch 60, loss=0.0624, recon=0.0624, kl=79.7545, beta=0.0000\n",
      "Batch 80, loss=0.1102, recon=0.1102, kl=80.3271, beta=0.0000\n",
      "Batch 100, loss=0.0713, recon=0.0713, kl=79.9933, beta=0.0000\n",
      "Batch 120, loss=0.0749, recon=0.0749, kl=79.8262, beta=0.0000\n",
      "Batch 140, loss=0.0827, recon=0.0827, kl=80.2141, beta=0.0000\n",
      "Batch 160, loss=0.0652, recon=0.0652, kl=80.5967, beta=0.0000\n",
      "Batch 180, loss=0.1317, recon=0.1317, kl=81.2428, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1115 (Recon: 0.1115, KL: 79.8125, Current Beta: 0.0000) | Avg Valid Loss: 0.0939 | Avg Valid recon Loss: 0.0939\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0830, recon=0.0830, kl=82.0162, beta=0.0000\n",
      "Batch 40, loss=0.1641, recon=0.1641, kl=83.4598, beta=0.0000\n",
      "Batch 60, loss=0.0658, recon=0.0658, kl=84.0703, beta=0.0000\n",
      "Batch 80, loss=0.1856, recon=0.1856, kl=85.0208, beta=0.0000\n",
      "Batch 100, loss=0.0722, recon=0.0722, kl=85.3382, beta=0.0000\n",
      "Batch 120, loss=0.0651, recon=0.0651, kl=85.3199, beta=0.0000\n",
      "Batch 140, loss=0.0593, recon=0.0593, kl=87.2948, beta=0.0000\n",
      "Batch 160, loss=0.0630, recon=0.0630, kl=88.1005, beta=0.0000\n",
      "Batch 180, loss=0.0537, recon=0.0537, kl=88.9910, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0974 (Recon: 0.0974, KL: 85.2021, Current Beta: 0.0000) | Avg Valid Loss: 0.0832 | Avg Valid recon Loss: 0.0832\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0914, recon=0.0914, kl=89.3943, beta=0.0000\n",
      "Batch 40, loss=0.0417, recon=0.0417, kl=89.6670, beta=0.0000\n",
      "Batch 60, loss=0.0927, recon=0.0927, kl=90.1414, beta=0.0000\n",
      "Batch 80, loss=0.0631, recon=0.0631, kl=90.8884, beta=0.0000\n",
      "Batch 100, loss=0.0673, recon=0.0673, kl=90.8788, beta=0.0000\n",
      "Batch 120, loss=0.0725, recon=0.0725, kl=91.1625, beta=0.0000\n",
      "Batch 140, loss=0.0835, recon=0.0835, kl=92.0822, beta=0.0000\n",
      "Batch 160, loss=0.0753, recon=0.0753, kl=92.8674, beta=0.0000\n",
      "Batch 180, loss=0.1269, recon=0.1269, kl=93.0779, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0881 (Recon: 0.0881, KL: 90.9289, Current Beta: 0.0000) | Avg Valid Loss: 0.0769 | Avg Valid recon Loss: 0.0769\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1741, recon=0.1741, kl=93.2970, beta=0.0000\n",
      "Batch 40, loss=0.0539, recon=0.0539, kl=93.6838, beta=0.0000\n",
      "Batch 60, loss=0.0978, recon=0.0978, kl=93.0371, beta=0.0000\n",
      "Batch 80, loss=0.0755, recon=0.0755, kl=92.9138, beta=0.0000\n",
      "Batch 100, loss=0.1020, recon=0.1020, kl=93.8263, beta=0.0000\n",
      "Batch 120, loss=0.0482, recon=0.0482, kl=94.7265, beta=0.0000\n",
      "Batch 140, loss=0.0422, recon=0.0422, kl=94.3545, beta=0.0000\n",
      "Batch 160, loss=0.0540, recon=0.0540, kl=93.5755, beta=0.0000\n",
      "Batch 180, loss=0.0420, recon=0.0420, kl=93.2809, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0812 (Recon: 0.0811, KL: 93.6137, Current Beta: 0.0000) | Avg Valid Loss: 0.0711 | Avg Valid recon Loss: 0.0711\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0674, recon=0.0673, kl=92.8874, beta=0.0000\n",
      "Batch 40, loss=0.0447, recon=0.0447, kl=91.5327, beta=0.0000\n",
      "Batch 60, loss=0.0631, recon=0.0631, kl=88.9695, beta=0.0000\n",
      "Batch 80, loss=0.0605, recon=0.0605, kl=89.4486, beta=0.0000\n",
      "Batch 100, loss=0.0647, recon=0.0646, kl=88.7452, beta=0.0000\n",
      "Batch 120, loss=0.0521, recon=0.0521, kl=86.5099, beta=0.0000\n",
      "Batch 140, loss=0.0564, recon=0.0564, kl=86.0748, beta=0.0000\n",
      "Batch 160, loss=0.1152, recon=0.1152, kl=84.8288, beta=0.0000\n",
      "Batch 180, loss=0.0473, recon=0.0473, kl=84.5756, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0761 (Recon: 0.0761, KL: 88.7446, Current Beta: 0.0000) | Avg Valid Loss: 0.0668 | Avg Valid recon Loss: 0.0668\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0425, recon=0.0424, kl=82.3931, beta=0.0000\n",
      "Batch 40, loss=0.0561, recon=0.0561, kl=79.8779, beta=0.0000\n",
      "Batch 60, loss=0.0653, recon=0.0652, kl=75.2089, beta=0.0000\n",
      "Batch 80, loss=0.0561, recon=0.0561, kl=73.0036, beta=0.0000\n",
      "Batch 100, loss=0.0481, recon=0.0481, kl=70.2477, beta=0.0000\n",
      "Batch 120, loss=0.0466, recon=0.0466, kl=67.8365, beta=0.0000\n",
      "Batch 140, loss=0.0616, recon=0.0616, kl=67.2782, beta=0.0000\n",
      "Batch 160, loss=0.0515, recon=0.0515, kl=65.7355, beta=0.0000\n",
      "Batch 180, loss=0.0533, recon=0.0533, kl=64.1078, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0721 (Recon: 0.0721, KL: 72.7544, Current Beta: 0.0000) | Avg Valid Loss: 0.0648 | Avg Valid recon Loss: 0.0647\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0411, recon=0.0410, kl=57.1786, beta=0.0000\n",
      "Batch 40, loss=0.0712, recon=0.0712, kl=48.3837, beta=0.0000\n",
      "Batch 60, loss=0.0539, recon=0.0538, kl=44.3594, beta=0.0000\n",
      "Batch 80, loss=0.0309, recon=0.0309, kl=42.9368, beta=0.0000\n",
      "Batch 100, loss=0.0552, recon=0.0552, kl=46.2727, beta=0.0000\n",
      "Batch 120, loss=0.0418, recon=0.0418, kl=44.5344, beta=0.0000\n",
      "Batch 140, loss=0.0534, recon=0.0533, kl=41.1494, beta=0.0000\n",
      "Batch 160, loss=0.0572, recon=0.0571, kl=40.0708, beta=0.0000\n",
      "Batch 180, loss=0.0391, recon=0.0391, kl=39.2193, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0689 (Recon: 0.0688, KL: 46.1475, Current Beta: 0.0000) | Avg Valid Loss: 0.0614 | Avg Valid recon Loss: 0.0614\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0366, recon=0.0365, kl=28.9126, beta=0.0000\n",
      "Batch 40, loss=0.0546, recon=0.0545, kl=23.9843, beta=0.0000\n",
      "Batch 60, loss=0.0640, recon=0.0640, kl=23.3311, beta=0.0000\n",
      "Batch 80, loss=0.0491, recon=0.0490, kl=23.7654, beta=0.0000\n",
      "Batch 100, loss=0.0343, recon=0.0343, kl=23.9815, beta=0.0000\n",
      "Batch 120, loss=0.0445, recon=0.0444, kl=23.1437, beta=0.0000\n",
      "Batch 140, loss=0.0571, recon=0.0571, kl=21.2512, beta=0.0000\n",
      "Batch 160, loss=0.0417, recon=0.0416, kl=20.7698, beta=0.0000\n",
      "Batch 180, loss=0.0410, recon=0.0409, kl=20.4204, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0663 (Recon: 0.0663, KL: 24.3155, Current Beta: 0.0000) | Avg Valid Loss: 0.0588 | Avg Valid recon Loss: 0.0587\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0399, recon=0.0398, kl=12.3890, beta=0.0000\n",
      "Batch 40, loss=0.0633, recon=0.0632, kl=11.6635, beta=0.0000\n",
      "Batch 60, loss=0.0453, recon=0.0452, kl=10.9337, beta=0.0000\n",
      "Batch 80, loss=0.0421, recon=0.0420, kl=9.9064, beta=0.0000\n",
      "Batch 100, loss=0.0507, recon=0.0506, kl=9.5099, beta=0.0000\n",
      "Batch 120, loss=0.0741, recon=0.0741, kl=8.7629, beta=0.0000\n",
      "Batch 140, loss=0.0346, recon=0.0345, kl=8.7105, beta=0.0000\n",
      "Batch 160, loss=0.0385, recon=0.0384, kl=8.1721, beta=0.0000\n",
      "Batch 180, loss=0.0764, recon=0.0763, kl=8.5239, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0640 (Recon: 0.0639, KL: 10.4126, Current Beta: 0.0000) | Avg Valid Loss: 0.0571 | Avg Valid recon Loss: 0.0571\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1126, recon=0.1125, kl=3.6951, beta=0.0000\n",
      "Batch 40, loss=0.0486, recon=0.0485, kl=4.1624, beta=0.0000\n",
      "Batch 60, loss=0.0639, recon=0.0638, kl=3.6103, beta=0.0000\n",
      "Batch 80, loss=0.0611, recon=0.0610, kl=3.2515, beta=0.0000\n",
      "Batch 100, loss=0.0533, recon=0.0532, kl=3.5034, beta=0.0000\n",
      "Batch 120, loss=0.0526, recon=0.0525, kl=2.9047, beta=0.0000\n",
      "Batch 140, loss=0.2123, recon=0.2123, kl=2.7175, beta=0.0000\n",
      "Batch 160, loss=0.0329, recon=0.0328, kl=2.5224, beta=0.0000\n",
      "Batch 180, loss=0.0760, recon=0.0759, kl=2.5985, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0622 (Recon: 0.0622, KL: 3.5071, Current Beta: 0.0000) | Avg Valid Loss: 0.0557 | Avg Valid recon Loss: 0.0557\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0655, recon=0.0655, kl=1.4948, beta=0.0000\n",
      "Batch 40, loss=0.0385, recon=0.0385, kl=1.1010, beta=0.0000\n",
      "Batch 60, loss=0.0337, recon=0.0336, kl=1.3974, beta=0.0000\n",
      "Batch 80, loss=0.0653, recon=0.0653, kl=1.0499, beta=0.0000\n",
      "Batch 100, loss=0.0416, recon=0.0416, kl=1.0899, beta=0.0000\n",
      "Batch 120, loss=0.1262, recon=0.1261, kl=0.9368, beta=0.0000\n",
      "Batch 140, loss=0.0557, recon=0.0557, kl=0.9467, beta=0.0000\n",
      "Batch 160, loss=0.0327, recon=0.0327, kl=0.8075, beta=0.0000\n",
      "Batch 180, loss=0.0445, recon=0.0444, kl=0.8683, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0605 (Recon: 0.0605, KL: 1.1714, Current Beta: 0.0000) | Avg Valid Loss: 0.0536 | Avg Valid recon Loss: 0.0535\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0487, recon=0.0487, kl=0.5252, beta=0.0001\n",
      "Batch 40, loss=0.0551, recon=0.0551, kl=0.4668, beta=0.0001\n",
      "Batch 60, loss=0.0488, recon=0.0488, kl=0.4231, beta=0.0001\n",
      "Batch 80, loss=0.2862, recon=0.2861, kl=0.3704, beta=0.0001\n",
      "Batch 100, loss=0.0343, recon=0.0342, kl=0.3438, beta=0.0001\n",
      "Batch 120, loss=0.0724, recon=0.0724, kl=0.3496, beta=0.0001\n",
      "Batch 140, loss=0.0559, recon=0.0559, kl=0.2823, beta=0.0001\n",
      "Batch 160, loss=0.0347, recon=0.0347, kl=0.2827, beta=0.0001\n",
      "Batch 180, loss=0.0417, recon=0.0417, kl=0.2427, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0591 (Recon: 0.0591, KL: 0.3923, Current Beta: 0.0001) | Avg Valid Loss: 0.0526 | Avg Valid recon Loss: 0.0526\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0297, recon=0.0297, kl=0.1230, beta=0.0001\n",
      "Batch 40, loss=0.0374, recon=0.0374, kl=0.1422, beta=0.0001\n",
      "Batch 60, loss=0.0395, recon=0.0395, kl=0.1054, beta=0.0001\n",
      "Batch 80, loss=0.0506, recon=0.0506, kl=0.0697, beta=0.0001\n",
      "Batch 100, loss=0.0336, recon=0.0336, kl=0.0917, beta=0.0001\n",
      "Batch 120, loss=0.1451, recon=0.1451, kl=0.0685, beta=0.0001\n",
      "Batch 140, loss=0.0516, recon=0.0516, kl=0.0808, beta=0.0001\n",
      "Batch 160, loss=0.0344, recon=0.0344, kl=0.0598, beta=0.0001\n",
      "Batch 180, loss=0.0323, recon=0.0323, kl=0.0665, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0577 (Recon: 0.0577, KL: 0.0994, Current Beta: 0.0001) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0509\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0772, recon=0.0772, kl=0.0408, beta=0.0001\n",
      "Batch 40, loss=0.0384, recon=0.0384, kl=0.0499, beta=0.0001\n",
      "Batch 60, loss=0.0595, recon=0.0595, kl=0.0407, beta=0.0001\n",
      "Batch 80, loss=0.0326, recon=0.0326, kl=0.0751, beta=0.0001\n",
      "Batch 100, loss=0.0293, recon=0.0293, kl=0.0721, beta=0.0001\n",
      "Batch 120, loss=0.0525, recon=0.0525, kl=0.0426, beta=0.0001\n",
      "Batch 140, loss=0.0414, recon=0.0414, kl=0.0321, beta=0.0001\n",
      "Batch 160, loss=0.0370, recon=0.0370, kl=0.0300, beta=0.0001\n",
      "Batch 180, loss=0.1427, recon=0.1427, kl=0.0327, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0565 (Recon: 0.0565, KL: 0.0476, Current Beta: 0.0001) | Avg Valid Loss: 0.0503 | Avg Valid recon Loss: 0.0503\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0283, recon=0.0283, kl=0.0241, beta=0.0001\n",
      "Batch 40, loss=0.0397, recon=0.0397, kl=0.0269, beta=0.0001\n",
      "Batch 60, loss=0.0500, recon=0.0500, kl=0.0237, beta=0.0001\n",
      "Batch 80, loss=0.0452, recon=0.0452, kl=0.0211, beta=0.0001\n",
      "Batch 100, loss=0.0573, recon=0.0573, kl=0.0181, beta=0.0001\n",
      "Batch 120, loss=0.0486, recon=0.0486, kl=0.0238, beta=0.0001\n",
      "Batch 140, loss=0.0295, recon=0.0295, kl=0.0364, beta=0.0001\n",
      "Batch 160, loss=0.0310, recon=0.0310, kl=0.0175, beta=0.0001\n",
      "Batch 180, loss=0.0651, recon=0.0651, kl=0.0161, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 0.0224, Current Beta: 0.0001) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0487\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0492, recon=0.0492, kl=0.0169, beta=0.0001\n",
      "Batch 40, loss=0.0791, recon=0.0791, kl=0.0136, beta=0.0001\n",
      "Batch 60, loss=0.0337, recon=0.0337, kl=0.0129, beta=0.0001\n",
      "Batch 80, loss=0.0329, recon=0.0329, kl=0.0136, beta=0.0001\n",
      "Batch 100, loss=0.1859, recon=0.1859, kl=0.0107, beta=0.0001\n",
      "Batch 120, loss=0.0512, recon=0.0512, kl=0.0109, beta=0.0001\n",
      "Batch 140, loss=0.0299, recon=0.0299, kl=0.0147, beta=0.0001\n",
      "Batch 160, loss=0.0366, recon=0.0366, kl=0.0235, beta=0.0001\n",
      "Batch 180, loss=0.0493, recon=0.0493, kl=0.0111, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0543 (Recon: 0.0543, KL: 0.0144, Current Beta: 0.0001) | Avg Valid Loss: 0.0475 | Avg Valid recon Loss: 0.0475\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0964, recon=0.0964, kl=0.0094, beta=0.0001\n",
      "Batch 40, loss=0.0338, recon=0.0338, kl=0.0073, beta=0.0001\n",
      "Batch 60, loss=0.0459, recon=0.0459, kl=0.0089, beta=0.0001\n",
      "Batch 80, loss=0.0390, recon=0.0390, kl=0.0085, beta=0.0001\n",
      "Batch 100, loss=0.0281, recon=0.0281, kl=0.0116, beta=0.0001\n",
      "Batch 120, loss=0.0272, recon=0.0272, kl=0.0077, beta=0.0001\n",
      "Batch 140, loss=0.2155, recon=0.2155, kl=0.0119, beta=0.0001\n",
      "Batch 160, loss=0.0306, recon=0.0306, kl=0.0057, beta=0.0001\n",
      "Batch 180, loss=0.0365, recon=0.0365, kl=0.0062, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0532 (Recon: 0.0532, KL: 0.0084, Current Beta: 0.0001) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0465\n",
      "\n",
      "[VRAE Run 22/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2391, recon=0.2391, kl=38.6322, beta=0.0000\n",
      "Batch 40, loss=0.1328, recon=0.1328, kl=51.2506, beta=0.0000\n",
      "Batch 60, loss=0.1316, recon=0.1316, kl=55.4784, beta=0.0000\n",
      "Batch 80, loss=0.0935, recon=0.0935, kl=63.2648, beta=0.0000\n",
      "Batch 100, loss=0.0763, recon=0.0763, kl=66.5779, beta=0.0000\n",
      "Batch 120, loss=0.0610, recon=0.0610, kl=73.7073, beta=0.0000\n",
      "Batch 140, loss=0.0517, recon=0.0517, kl=76.4492, beta=0.0000\n",
      "Batch 160, loss=0.0647, recon=0.0647, kl=78.8379, beta=0.0000\n",
      "Batch 180, loss=0.0498, recon=0.0498, kl=83.7316, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1659 (Recon: 0.1659, KL: 60.8651, Current Beta: 0.0000) | Avg Valid Loss: 0.0796 | Avg Valid recon Loss: 0.0796\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0687, recon=0.0687, kl=81.1235, beta=0.0000\n",
      "Batch 40, loss=0.0405, recon=0.0405, kl=73.5595, beta=0.0000\n",
      "Batch 60, loss=0.0674, recon=0.0674, kl=69.8179, beta=0.0000\n",
      "Batch 80, loss=0.0574, recon=0.0574, kl=73.8145, beta=0.0000\n",
      "Batch 100, loss=0.0420, recon=0.0420, kl=77.8057, beta=0.0000\n",
      "Batch 120, loss=0.0739, recon=0.0739, kl=79.8442, beta=0.0000\n",
      "Batch 140, loss=0.0388, recon=0.0388, kl=82.7077, beta=0.0000\n",
      "Batch 160, loss=0.0393, recon=0.0393, kl=74.3859, beta=0.0000\n",
      "Batch 180, loss=0.2012, recon=0.2012, kl=73.5955, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0733 (Recon: 0.0733, KL: 76.5258, Current Beta: 0.0000) | Avg Valid Loss: 0.0570 | Avg Valid recon Loss: 0.0570\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0808, recon=0.0808, kl=67.1665, beta=0.0000\n",
      "Batch 40, loss=0.0632, recon=0.0632, kl=71.0753, beta=0.0000\n",
      "Batch 60, loss=0.0278, recon=0.0278, kl=76.5970, beta=0.0000\n",
      "Batch 80, loss=0.0431, recon=0.0431, kl=80.5512, beta=0.0000\n",
      "Batch 100, loss=0.0342, recon=0.0342, kl=82.5827, beta=0.0000\n",
      "Batch 120, loss=0.0433, recon=0.0433, kl=79.8993, beta=0.0000\n",
      "Batch 140, loss=0.0728, recon=0.0728, kl=79.4471, beta=0.0000\n",
      "Batch 160, loss=0.0370, recon=0.0370, kl=75.7705, beta=0.0000\n",
      "Batch 180, loss=0.0495, recon=0.0495, kl=77.2000, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0612 (Recon: 0.0612, KL: 76.8545, Current Beta: 0.0000) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0534, recon=0.0534, kl=80.6809, beta=0.0000\n",
      "Batch 40, loss=0.0363, recon=0.0363, kl=83.5242, beta=0.0000\n",
      "Batch 60, loss=0.0332, recon=0.0332, kl=82.6218, beta=0.0000\n",
      "Batch 80, loss=0.0389, recon=0.0389, kl=81.7627, beta=0.0000\n",
      "Batch 100, loss=0.0352, recon=0.0352, kl=73.9553, beta=0.0000\n",
      "Batch 120, loss=0.0433, recon=0.0433, kl=68.0086, beta=0.0000\n",
      "Batch 140, loss=0.0421, recon=0.0421, kl=78.5699, beta=0.0000\n",
      "Batch 160, loss=0.0521, recon=0.0521, kl=78.4583, beta=0.0000\n",
      "Batch 180, loss=0.0327, recon=0.0327, kl=79.3638, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0550 (Recon: 0.0550, KL: 78.7275, Current Beta: 0.0000) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0474\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0371, recon=0.0371, kl=80.2676, beta=0.0000\n",
      "Batch 40, loss=0.1027, recon=0.1027, kl=74.4286, beta=0.0000\n",
      "Batch 60, loss=0.0268, recon=0.0268, kl=55.1792, beta=0.0000\n",
      "Batch 80, loss=0.0263, recon=0.0263, kl=64.3046, beta=0.0000\n",
      "Batch 100, loss=0.0550, recon=0.0550, kl=70.2520, beta=0.0000\n",
      "Batch 120, loss=0.0420, recon=0.0420, kl=72.9321, beta=0.0000\n",
      "Batch 140, loss=0.0588, recon=0.0588, kl=74.9673, beta=0.0000\n",
      "Batch 160, loss=0.0424, recon=0.0424, kl=68.6480, beta=0.0000\n",
      "Batch 180, loss=0.0769, recon=0.0769, kl=70.3723, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0538 (Recon: 0.0538, KL: 70.1031, Current Beta: 0.0000) | Avg Valid Loss: 0.0591 | Avg Valid recon Loss: 0.0591\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0718, recon=0.0718, kl=71.8532, beta=0.0000\n",
      "Batch 40, loss=0.0366, recon=0.0366, kl=74.1307, beta=0.0000\n",
      "Batch 60, loss=0.0821, recon=0.0821, kl=75.0927, beta=0.0000\n",
      "Batch 80, loss=0.0701, recon=0.0701, kl=75.8394, beta=0.0000\n",
      "Batch 100, loss=0.0258, recon=0.0258, kl=71.8888, beta=0.0000\n",
      "Batch 120, loss=0.0590, recon=0.0590, kl=71.7370, beta=0.0000\n",
      "Batch 140, loss=0.0398, recon=0.0398, kl=74.7519, beta=0.0000\n",
      "Batch 160, loss=0.0584, recon=0.0584, kl=72.5096, beta=0.0000\n",
      "Batch 180, loss=0.0369, recon=0.0369, kl=57.8431, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0653 (Recon: 0.0653, KL: 72.5965, Current Beta: 0.0000) | Avg Valid Loss: 0.0584 | Avg Valid recon Loss: 0.0584\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0490, recon=0.0490, kl=62.2650, beta=0.0000\n",
      "Batch 40, loss=0.0291, recon=0.0291, kl=68.1601, beta=0.0000\n",
      "Batch 60, loss=0.0374, recon=0.0373, kl=71.7427, beta=0.0000\n",
      "Batch 80, loss=0.0323, recon=0.0323, kl=74.7541, beta=0.0000\n",
      "Batch 100, loss=0.0237, recon=0.0237, kl=78.2985, beta=0.0000\n",
      "Batch 120, loss=0.0376, recon=0.0376, kl=79.2945, beta=0.0000\n",
      "Batch 140, loss=0.1857, recon=0.1857, kl=78.2601, beta=0.0000\n",
      "Batch 160, loss=0.0637, recon=0.0637, kl=76.2887, beta=0.0000\n",
      "Batch 180, loss=0.0408, recon=0.0408, kl=74.0936, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0530 (Recon: 0.0530, KL: 72.5152, Current Beta: 0.0000) | Avg Valid Loss: 0.0483 | Avg Valid recon Loss: 0.0483\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=70.0081, beta=0.0000\n",
      "Batch 40, loss=0.0231, recon=0.0231, kl=68.4604, beta=0.0000\n",
      "Batch 60, loss=0.0283, recon=0.0283, kl=68.5512, beta=0.0000\n",
      "Batch 80, loss=0.0384, recon=0.0384, kl=68.2094, beta=0.0000\n",
      "Batch 100, loss=0.0259, recon=0.0258, kl=66.5795, beta=0.0000\n",
      "Batch 120, loss=0.0825, recon=0.0825, kl=71.5861, beta=0.0000\n",
      "Batch 140, loss=0.1359, recon=0.1358, kl=72.9470, beta=0.0000\n",
      "Batch 160, loss=0.0323, recon=0.0322, kl=68.2368, beta=0.0000\n",
      "Batch 180, loss=0.0243, recon=0.0243, kl=67.3679, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 68.9985, Current Beta: 0.0000) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0329, recon=0.0329, kl=62.2267, beta=0.0000\n",
      "Batch 40, loss=0.0387, recon=0.0387, kl=55.0844, beta=0.0000\n",
      "Batch 60, loss=0.0658, recon=0.0658, kl=55.2322, beta=0.0000\n",
      "Batch 80, loss=0.0308, recon=0.0308, kl=55.1782, beta=0.0000\n",
      "Batch 100, loss=0.0270, recon=0.0269, kl=53.6894, beta=0.0000\n",
      "Batch 120, loss=0.0222, recon=0.0222, kl=52.5360, beta=0.0000\n",
      "Batch 140, loss=0.0281, recon=0.0280, kl=55.8381, beta=0.0000\n",
      "Batch 160, loss=0.0221, recon=0.0221, kl=57.1064, beta=0.0000\n",
      "Batch 180, loss=0.0421, recon=0.0420, kl=56.1234, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0455, KL: 56.4824, Current Beta: 0.0000) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0246, recon=0.0245, kl=50.2947, beta=0.0000\n",
      "Batch 40, loss=0.0506, recon=0.0506, kl=44.3569, beta=0.0000\n",
      "Batch 60, loss=0.0489, recon=0.0488, kl=42.2441, beta=0.0000\n",
      "Batch 80, loss=0.0420, recon=0.0420, kl=43.8831, beta=0.0000\n",
      "Batch 100, loss=0.0389, recon=0.0389, kl=42.7015, beta=0.0000\n",
      "Batch 120, loss=0.0311, recon=0.0310, kl=47.5738, beta=0.0000\n",
      "Batch 140, loss=0.0363, recon=0.0363, kl=45.2984, beta=0.0000\n",
      "Batch 160, loss=0.0503, recon=0.0502, kl=47.0185, beta=0.0000\n",
      "Batch 180, loss=0.0477, recon=0.0477, kl=43.8547, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0427, KL: 45.8957, Current Beta: 0.0000) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0375, recon=0.0374, kl=27.7883, beta=0.0000\n",
      "Batch 40, loss=0.0331, recon=0.0330, kl=31.1840, beta=0.0000\n",
      "Batch 60, loss=0.0205, recon=0.0204, kl=34.7760, beta=0.0000\n",
      "Batch 80, loss=0.0483, recon=0.0482, kl=31.0259, beta=0.0000\n",
      "Batch 100, loss=0.1504, recon=0.1504, kl=27.1722, beta=0.0000\n",
      "Batch 120, loss=0.0380, recon=0.0379, kl=28.7393, beta=0.0000\n",
      "Batch 140, loss=0.0335, recon=0.0334, kl=31.1576, beta=0.0000\n",
      "Batch 160, loss=0.0239, recon=0.0238, kl=28.0882, beta=0.0000\n",
      "Batch 180, loss=0.1522, recon=0.1521, kl=25.3260, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0449, KL: 30.0705, Current Beta: 0.0000) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0396, recon=0.0395, kl=13.2247, beta=0.0000\n",
      "Batch 40, loss=0.0324, recon=0.0323, kl=15.2954, beta=0.0000\n",
      "Batch 60, loss=0.0331, recon=0.0330, kl=13.6790, beta=0.0000\n",
      "Batch 80, loss=0.0201, recon=0.0200, kl=11.9548, beta=0.0000\n",
      "Batch 100, loss=0.0400, recon=0.0399, kl=14.2722, beta=0.0000\n",
      "Batch 120, loss=0.0523, recon=0.0522, kl=13.2709, beta=0.0000\n",
      "Batch 140, loss=0.0279, recon=0.0278, kl=9.2573, beta=0.0000\n",
      "Batch 160, loss=0.0239, recon=0.0238, kl=10.3976, beta=0.0000\n",
      "Batch 180, loss=0.0239, recon=0.0238, kl=11.2307, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0393 (Recon: 0.0392, KL: 13.0703, Current Beta: 0.0000) | Avg Valid Loss: 0.0320 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0371, recon=0.0370, kl=5.0073, beta=0.0000\n",
      "Batch 40, loss=0.0326, recon=0.0325, kl=3.4495, beta=0.0000\n",
      "Batch 60, loss=0.0296, recon=0.0295, kl=3.9873, beta=0.0000\n",
      "Batch 80, loss=0.0376, recon=0.0375, kl=7.4781, beta=0.0000\n",
      "Batch 100, loss=0.0201, recon=0.0200, kl=4.9598, beta=0.0000\n",
      "Batch 120, loss=0.0215, recon=0.0214, kl=3.6166, beta=0.0000\n",
      "Batch 140, loss=0.0234, recon=0.0233, kl=2.9518, beta=0.0000\n",
      "Batch 160, loss=0.0259, recon=0.0259, kl=2.3018, beta=0.0000\n",
      "Batch 180, loss=0.0208, recon=0.0208, kl=1.8019, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0376, KL: 4.3957, Current Beta: 0.0000) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0180, recon=0.0179, kl=1.6838, beta=0.0000\n",
      "Batch 40, loss=0.0510, recon=0.0509, kl=2.4287, beta=0.0000\n",
      "Batch 60, loss=0.0408, recon=0.0407, kl=3.0148, beta=0.0000\n",
      "Batch 80, loss=0.0437, recon=0.0436, kl=2.0666, beta=0.0000\n",
      "Batch 100, loss=0.0233, recon=0.0232, kl=1.1681, beta=0.0000\n",
      "Batch 120, loss=0.0459, recon=0.0458, kl=0.6673, beta=0.0000\n",
      "Batch 140, loss=0.0268, recon=0.0268, kl=0.3786, beta=0.0000\n",
      "Batch 160, loss=0.1160, recon=0.1160, kl=0.4415, beta=0.0000\n",
      "Batch 180, loss=0.0288, recon=0.0288, kl=0.4803, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0397 (Recon: 0.0396, KL: 1.4246, Current Beta: 0.0000) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0194, recon=0.0194, kl=0.2314, beta=0.0001\n",
      "Batch 40, loss=0.0375, recon=0.0375, kl=0.0729, beta=0.0001\n",
      "Batch 60, loss=0.0185, recon=0.0185, kl=0.1046, beta=0.0001\n",
      "Batch 80, loss=0.0349, recon=0.0349, kl=0.1680, beta=0.0001\n",
      "Batch 100, loss=0.0234, recon=0.0234, kl=0.1769, beta=0.0001\n",
      "Batch 120, loss=0.0227, recon=0.0227, kl=0.2272, beta=0.0001\n",
      "Batch 140, loss=0.0598, recon=0.0598, kl=0.1781, beta=0.0001\n",
      "Batch 160, loss=0.0709, recon=0.0709, kl=0.0761, beta=0.0001\n",
      "Batch 180, loss=0.1074, recon=0.1074, kl=0.1548, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0428, KL: 0.1686, Current Beta: 0.0001) | Avg Valid Loss: 0.0727 | Avg Valid recon Loss: 0.0727\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0798, recon=0.0798, kl=0.4295, beta=0.0001\n",
      "Batch 40, loss=0.0339, recon=0.0337, kl=2.5918, beta=0.0001\n",
      "Batch 60, loss=0.0317, recon=0.0315, kl=2.0096, beta=0.0001\n",
      "Batch 80, loss=0.0341, recon=0.0340, kl=0.8724, beta=0.0001\n",
      "Batch 100, loss=0.0334, recon=0.0333, kl=0.3067, beta=0.0001\n",
      "Batch 120, loss=0.3244, recon=0.3243, kl=0.1334, beta=0.0001\n",
      "Batch 140, loss=0.0540, recon=0.0539, kl=0.3114, beta=0.0001\n",
      "Batch 160, loss=0.0517, recon=0.0516, kl=0.9488, beta=0.0001\n",
      "Batch 180, loss=0.0786, recon=0.0785, kl=0.9115, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0737 (Recon: 0.0736, KL: 0.9150, Current Beta: 0.0001) | Avg Valid Loss: 0.0487 | Avg Valid recon Loss: 0.0486\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0481, recon=0.0479, kl=1.2261, beta=0.0001\n",
      "Batch 40, loss=0.2316, recon=0.2315, kl=1.0357, beta=0.0001\n",
      "Batch 60, loss=0.0325, recon=0.0324, kl=0.6456, beta=0.0001\n",
      "Batch 80, loss=0.0438, recon=0.0438, kl=0.4286, beta=0.0001\n",
      "Batch 100, loss=0.0516, recon=0.0515, kl=0.2901, beta=0.0001\n",
      "Batch 120, loss=0.0608, recon=0.0608, kl=0.1974, beta=0.0001\n",
      "Batch 140, loss=0.0387, recon=0.0387, kl=0.1378, beta=0.0001\n",
      "Batch 160, loss=0.0330, recon=0.0330, kl=0.0774, beta=0.0001\n",
      "Batch 180, loss=0.0380, recon=0.0380, kl=0.0464, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0563 (Recon: 0.0563, KL: 0.4957, Current Beta: 0.0001) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0433, recon=0.0433, kl=0.2700, beta=0.0001\n",
      "Batch 40, loss=0.0300, recon=0.0299, kl=1.1021, beta=0.0001\n",
      "Batch 60, loss=0.0209, recon=0.0208, kl=1.6897, beta=0.0001\n",
      "Batch 80, loss=0.1134, recon=0.1132, kl=1.4809, beta=0.0001\n",
      "Batch 100, loss=0.0220, recon=0.0219, kl=1.0982, beta=0.0001\n",
      "Batch 120, loss=0.0218, recon=0.0217, kl=0.7146, beta=0.0001\n",
      "Batch 140, loss=0.0248, recon=0.0248, kl=0.4664, beta=0.0001\n",
      "Batch 160, loss=0.0308, recon=0.0307, kl=0.3153, beta=0.0001\n",
      "Batch 180, loss=0.0347, recon=0.0347, kl=0.2245, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0429, KL: 0.8023, Current Beta: 0.0001) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0351, recon=0.0351, kl=0.1641, beta=0.0001\n",
      "Batch 40, loss=0.0299, recon=0.0299, kl=0.1279, beta=0.0001\n",
      "Batch 60, loss=0.0543, recon=0.0543, kl=0.0976, beta=0.0001\n",
      "Batch 80, loss=0.0424, recon=0.0424, kl=0.0842, beta=0.0001\n",
      "Batch 100, loss=0.0388, recon=0.0388, kl=0.0861, beta=0.0001\n",
      "Batch 120, loss=0.0283, recon=0.0283, kl=0.0744, beta=0.0001\n",
      "Batch 140, loss=0.0616, recon=0.0616, kl=0.0567, beta=0.0001\n",
      "Batch 160, loss=0.0248, recon=0.0248, kl=0.0447, beta=0.0001\n",
      "Batch 180, loss=0.0440, recon=0.0440, kl=0.0380, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0427 (Recon: 0.0427, KL: 0.0947, Current Beta: 0.0001) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0402, recon=0.0402, kl=0.0324, beta=0.0001\n",
      "Batch 40, loss=0.0175, recon=0.0175, kl=0.0293, beta=0.0001\n",
      "Batch 60, loss=0.0356, recon=0.0356, kl=0.0345, beta=0.0001\n",
      "Batch 80, loss=0.0562, recon=0.0562, kl=0.0432, beta=0.0001\n",
      "Batch 100, loss=0.0281, recon=0.0281, kl=0.0405, beta=0.0001\n",
      "Batch 120, loss=0.0310, recon=0.0310, kl=0.0426, beta=0.0001\n",
      "Batch 140, loss=0.0253, recon=0.0253, kl=0.0404, beta=0.0001\n",
      "Batch 160, loss=0.0217, recon=0.0217, kl=0.0320, beta=0.0001\n",
      "Batch 180, loss=0.0555, recon=0.0555, kl=0.0222, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0398 (Recon: 0.0398, KL: 0.0359, Current Beta: 0.0001) | Avg Valid Loss: 0.0328 | Avg Valid recon Loss: 0.0328\n",
      "\n",
      "[VRAE Run 23/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=1.8632, recon=1.8632, kl=0.7346, beta=0.0000\n",
      "Batch 40, loss=0.5114, recon=0.5114, kl=7.2953, beta=0.0000\n",
      "Batch 60, loss=0.4908, recon=0.4908, kl=30.3665, beta=0.0000\n",
      "Batch 80, loss=0.4254, recon=0.4254, kl=46.4265, beta=0.0000\n",
      "Batch 100, loss=0.3477, recon=0.3477, kl=57.7546, beta=0.0000\n",
      "Batch 120, loss=0.4345, recon=0.4345, kl=67.0784, beta=0.0000\n",
      "Batch 140, loss=0.1808, recon=0.1808, kl=73.4301, beta=0.0000\n",
      "Batch 160, loss=0.1748, recon=0.1748, kl=79.7969, beta=0.0000\n",
      "Batch 180, loss=0.3749, recon=0.3749, kl=85.6828, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4640 (Recon: 0.4640, KL: 45.6398, Current Beta: 0.0000) | Avg Valid Loss: 0.2354 | Avg Valid recon Loss: 0.2354\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1400, recon=0.1400, kl=91.3418, beta=0.0000\n",
      "Batch 40, loss=0.1766, recon=0.1766, kl=95.0442, beta=0.0000\n",
      "Batch 60, loss=0.1246, recon=0.1246, kl=99.2456, beta=0.0000\n",
      "Batch 80, loss=0.1497, recon=0.1497, kl=103.2532, beta=0.0000\n",
      "Batch 100, loss=0.1251, recon=0.1251, kl=106.2772, beta=0.0000\n",
      "Batch 120, loss=0.1704, recon=0.1704, kl=108.5042, beta=0.0000\n",
      "Batch 140, loss=0.1614, recon=0.1614, kl=112.8597, beta=0.0000\n",
      "Batch 160, loss=0.1365, recon=0.1365, kl=115.9427, beta=0.0000\n",
      "Batch 180, loss=0.1155, recon=0.1155, kl=119.7920, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1939 (Recon: 0.1939, KL: 104.1308, Current Beta: 0.0000) | Avg Valid Loss: 0.1425 | Avg Valid recon Loss: 0.1425\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1071, recon=0.1071, kl=123.5678, beta=0.0000\n",
      "Batch 40, loss=0.1111, recon=0.1111, kl=128.0199, beta=0.0000\n",
      "Batch 60, loss=0.1024, recon=0.1024, kl=129.5355, beta=0.0000\n",
      "Batch 80, loss=0.0712, recon=0.0712, kl=133.1937, beta=0.0000\n",
      "Batch 100, loss=0.0871, recon=0.0871, kl=135.7027, beta=0.0000\n",
      "Batch 120, loss=0.0980, recon=0.0980, kl=137.5881, beta=0.0000\n",
      "Batch 140, loss=0.0947, recon=0.0947, kl=140.1406, beta=0.0000\n",
      "Batch 160, loss=0.1008, recon=0.1008, kl=141.8641, beta=0.0000\n",
      "Batch 180, loss=0.0941, recon=0.0941, kl=143.0106, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1372 (Recon: 0.1372, KL: 133.5815, Current Beta: 0.0000) | Avg Valid Loss: 0.1096 | Avg Valid recon Loss: 0.1096\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1550, recon=0.1550, kl=143.9507, beta=0.0000\n",
      "Batch 40, loss=0.1039, recon=0.1039, kl=146.1277, beta=0.0000\n",
      "Batch 60, loss=0.0528, recon=0.0528, kl=148.9772, beta=0.0000\n",
      "Batch 80, loss=0.0939, recon=0.0939, kl=149.7805, beta=0.0000\n",
      "Batch 100, loss=0.0586, recon=0.0586, kl=152.0267, beta=0.0000\n",
      "Batch 120, loss=0.0866, recon=0.0866, kl=154.1144, beta=0.0000\n",
      "Batch 140, loss=0.0700, recon=0.0700, kl=156.5401, beta=0.0000\n",
      "Batch 160, loss=0.0892, recon=0.0892, kl=158.0739, beta=0.0000\n",
      "Batch 180, loss=0.0853, recon=0.0853, kl=158.8889, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1107 (Recon: 0.1107, KL: 151.2188, Current Beta: 0.0000) | Avg Valid Loss: 0.0934 | Avg Valid recon Loss: 0.0934\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0834, recon=0.0834, kl=160.6065, beta=0.0000\n",
      "Batch 40, loss=0.1136, recon=0.1136, kl=162.0259, beta=0.0000\n",
      "Batch 60, loss=0.0553, recon=0.0553, kl=163.4200, beta=0.0000\n",
      "Batch 80, loss=0.0553, recon=0.0553, kl=164.6106, beta=0.0000\n",
      "Batch 100, loss=0.0763, recon=0.0763, kl=165.8159, beta=0.0000\n",
      "Batch 120, loss=0.0569, recon=0.0569, kl=167.2629, beta=0.0000\n",
      "Batch 140, loss=0.0595, recon=0.0595, kl=168.1899, beta=0.0000\n",
      "Batch 160, loss=0.0824, recon=0.0824, kl=169.1503, beta=0.0000\n",
      "Batch 180, loss=0.0632, recon=0.0632, kl=169.9609, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0957 (Recon: 0.0957, KL: 165.1308, Current Beta: 0.0000) | Avg Valid Loss: 0.0847 | Avg Valid recon Loss: 0.0847\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0743, recon=0.0743, kl=170.9466, beta=0.0000\n",
      "Batch 40, loss=0.1354, recon=0.1354, kl=171.8912, beta=0.0000\n",
      "Batch 60, loss=0.0595, recon=0.0595, kl=172.7404, beta=0.0000\n",
      "Batch 80, loss=0.0969, recon=0.0969, kl=172.7000, beta=0.0000\n",
      "Batch 100, loss=0.0437, recon=0.0437, kl=174.1401, beta=0.0000\n",
      "Batch 120, loss=0.1093, recon=0.1093, kl=175.0218, beta=0.0000\n",
      "Batch 140, loss=0.0843, recon=0.0843, kl=175.4779, beta=0.0000\n",
      "Batch 160, loss=0.0981, recon=0.0981, kl=176.1087, beta=0.0000\n",
      "Batch 180, loss=0.0543, recon=0.0543, kl=177.3556, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0858 (Recon: 0.0858, KL: 173.6609, Current Beta: 0.0000) | Avg Valid Loss: 0.0761 | Avg Valid recon Loss: 0.0761\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0579, recon=0.0579, kl=177.3485, beta=0.0000\n",
      "Batch 40, loss=0.0709, recon=0.0709, kl=176.7738, beta=0.0000\n",
      "Batch 60, loss=0.0395, recon=0.0394, kl=175.5329, beta=0.0000\n",
      "Batch 80, loss=0.0522, recon=0.0522, kl=174.9915, beta=0.0000\n",
      "Batch 100, loss=0.0725, recon=0.0725, kl=175.1322, beta=0.0000\n",
      "Batch 120, loss=0.0383, recon=0.0383, kl=175.5797, beta=0.0000\n",
      "Batch 140, loss=0.0665, recon=0.0665, kl=175.5041, beta=0.0000\n",
      "Batch 160, loss=0.0303, recon=0.0303, kl=174.7681, beta=0.0000\n",
      "Batch 180, loss=0.1575, recon=0.1575, kl=174.5309, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0794 (Recon: 0.0794, KL: 175.6495, Current Beta: 0.0000) | Avg Valid Loss: 0.0725 | Avg Valid recon Loss: 0.0725\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0599, recon=0.0599, kl=172.7640, beta=0.0000\n",
      "Batch 40, loss=0.0671, recon=0.0671, kl=170.3755, beta=0.0000\n",
      "Batch 60, loss=0.0345, recon=0.0345, kl=167.7142, beta=0.0000\n",
      "Batch 80, loss=0.0501, recon=0.0500, kl=164.3947, beta=0.0000\n",
      "Batch 100, loss=0.0642, recon=0.0642, kl=161.2252, beta=0.0000\n",
      "Batch 120, loss=0.2086, recon=0.2085, kl=159.1724, beta=0.0000\n",
      "Batch 140, loss=0.0464, recon=0.0464, kl=157.0841, beta=0.0000\n",
      "Batch 160, loss=0.0417, recon=0.0417, kl=155.3614, beta=0.0000\n",
      "Batch 180, loss=0.0665, recon=0.0665, kl=152.9957, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0744 (Recon: 0.0743, KL: 163.4295, Current Beta: 0.0000) | Avg Valid Loss: 0.0675 | Avg Valid recon Loss: 0.0675\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0462, recon=0.0461, kl=145.1258, beta=0.0000\n",
      "Batch 40, loss=0.0485, recon=0.0485, kl=136.7062, beta=0.0000\n",
      "Batch 60, loss=0.0615, recon=0.0614, kl=126.0720, beta=0.0000\n",
      "Batch 80, loss=0.1008, recon=0.1008, kl=116.7897, beta=0.0000\n",
      "Batch 100, loss=0.0422, recon=0.0422, kl=109.1582, beta=0.0000\n",
      "Batch 120, loss=0.0403, recon=0.0402, kl=107.0895, beta=0.0000\n",
      "Batch 140, loss=0.0353, recon=0.0353, kl=107.0031, beta=0.0000\n",
      "Batch 160, loss=0.1074, recon=0.1073, kl=103.5832, beta=0.0000\n",
      "Batch 180, loss=0.0527, recon=0.0526, kl=102.5844, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0703 (Recon: 0.0703, KL: 119.5187, Current Beta: 0.0000) | Avg Valid Loss: 0.0639 | Avg Valid recon Loss: 0.0639\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0581, recon=0.0580, kl=87.9912, beta=0.0000\n",
      "Batch 40, loss=0.0469, recon=0.0468, kl=71.6759, beta=0.0000\n",
      "Batch 60, loss=0.0384, recon=0.0383, kl=66.2478, beta=0.0000\n",
      "Batch 80, loss=0.0365, recon=0.0365, kl=61.5710, beta=0.0000\n",
      "Batch 100, loss=0.0609, recon=0.0608, kl=60.9857, beta=0.0000\n",
      "Batch 120, loss=0.0527, recon=0.0526, kl=56.8165, beta=0.0000\n",
      "Batch 140, loss=0.0510, recon=0.0509, kl=55.3236, beta=0.0000\n",
      "Batch 160, loss=0.0518, recon=0.0518, kl=57.2975, beta=0.0000\n",
      "Batch 180, loss=0.0372, recon=0.0371, kl=55.6934, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0670 (Recon: 0.0669, KL: 65.8749, Current Beta: 0.0000) | Avg Valid Loss: 0.0613 | Avg Valid recon Loss: 0.0613\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0388, recon=0.0387, kl=42.2568, beta=0.0000\n",
      "Batch 40, loss=0.0434, recon=0.0433, kl=31.6170, beta=0.0000\n",
      "Batch 60, loss=0.0725, recon=0.0724, kl=32.1159, beta=0.0000\n",
      "Batch 80, loss=0.0575, recon=0.0575, kl=31.4945, beta=0.0000\n",
      "Batch 100, loss=0.0533, recon=0.0532, kl=29.6483, beta=0.0000\n",
      "Batch 120, loss=0.1384, recon=0.1384, kl=27.3917, beta=0.0000\n",
      "Batch 140, loss=0.0317, recon=0.0316, kl=26.1102, beta=0.0000\n",
      "Batch 160, loss=0.0533, recon=0.0532, kl=25.8114, beta=0.0000\n",
      "Batch 180, loss=0.0649, recon=0.0648, kl=25.6297, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0644 (Recon: 0.0643, KL: 31.7065, Current Beta: 0.0000) | Avg Valid Loss: 0.0583 | Avg Valid recon Loss: 0.0582\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0501, recon=0.0500, kl=15.9307, beta=0.0000\n",
      "Batch 40, loss=0.0953, recon=0.0952, kl=12.6111, beta=0.0000\n",
      "Batch 60, loss=0.0304, recon=0.0303, kl=13.0785, beta=0.0000\n",
      "Batch 80, loss=0.0504, recon=0.0503, kl=11.0702, beta=0.0000\n",
      "Batch 100, loss=0.0549, recon=0.0548, kl=10.3483, beta=0.0000\n",
      "Batch 120, loss=0.0329, recon=0.0328, kl=10.5292, beta=0.0000\n",
      "Batch 140, loss=0.0462, recon=0.0462, kl=9.9428, beta=0.0000\n",
      "Batch 160, loss=0.0856, recon=0.0855, kl=9.0701, beta=0.0000\n",
      "Batch 180, loss=0.0365, recon=0.0364, kl=9.4031, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0622 (Recon: 0.0621, KL: 12.1177, Current Beta: 0.0000) | Avg Valid Loss: 0.0563 | Avg Valid recon Loss: 0.0563\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0506, recon=0.0505, kl=4.8650, beta=0.0000\n",
      "Batch 40, loss=0.0792, recon=0.0791, kl=4.9915, beta=0.0000\n",
      "Batch 60, loss=0.0405, recon=0.0404, kl=4.7552, beta=0.0000\n",
      "Batch 80, loss=0.0494, recon=0.0494, kl=4.0481, beta=0.0000\n",
      "Batch 100, loss=0.0334, recon=0.0333, kl=4.0931, beta=0.0000\n",
      "Batch 120, loss=0.0421, recon=0.0420, kl=3.7272, beta=0.0000\n",
      "Batch 140, loss=0.0488, recon=0.0487, kl=3.9537, beta=0.0000\n",
      "Batch 160, loss=0.0488, recon=0.0487, kl=3.7324, beta=0.0000\n",
      "Batch 180, loss=0.0465, recon=0.0465, kl=3.4416, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0600 (Recon: 0.0599, KL: 4.4665, Current Beta: 0.0000) | Avg Valid Loss: 0.0549 | Avg Valid recon Loss: 0.0549\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0527, recon=0.0526, kl=2.5270, beta=0.0000\n",
      "Batch 40, loss=0.0347, recon=0.0346, kl=2.0360, beta=0.0000\n",
      "Batch 60, loss=0.0411, recon=0.0410, kl=1.9280, beta=0.0000\n",
      "Batch 80, loss=0.0412, recon=0.0411, kl=2.4806, beta=0.0000\n",
      "Batch 100, loss=0.0533, recon=0.0532, kl=1.9374, beta=0.0000\n",
      "Batch 120, loss=0.0670, recon=0.0669, kl=1.7869, beta=0.0000\n",
      "Batch 140, loss=0.0364, recon=0.0363, kl=1.7783, beta=0.0000\n",
      "Batch 160, loss=0.0280, recon=0.0279, kl=1.9608, beta=0.0000\n",
      "Batch 180, loss=0.0476, recon=0.0476, kl=1.5620, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0584 (Recon: 0.0584, KL: 2.1163, Current Beta: 0.0000) | Avg Valid Loss: 0.0530 | Avg Valid recon Loss: 0.0530\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0577, recon=0.0576, kl=1.3174, beta=0.0001\n",
      "Batch 40, loss=0.0378, recon=0.0377, kl=1.2627, beta=0.0001\n",
      "Batch 60, loss=0.0416, recon=0.0415, kl=1.0385, beta=0.0001\n",
      "Batch 80, loss=0.0638, recon=0.0637, kl=1.5571, beta=0.0001\n",
      "Batch 100, loss=0.0329, recon=0.0328, kl=1.1109, beta=0.0001\n",
      "Batch 120, loss=0.0372, recon=0.0371, kl=0.8854, beta=0.0001\n",
      "Batch 140, loss=0.0760, recon=0.0760, kl=1.0556, beta=0.0001\n",
      "Batch 160, loss=0.0285, recon=0.0284, kl=1.0687, beta=0.0001\n",
      "Batch 180, loss=0.0363, recon=0.0363, kl=0.8656, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 1.1681, Current Beta: 0.0001) | Avg Valid Loss: 0.0516 | Avg Valid recon Loss: 0.0515\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0414, recon=0.0414, kl=0.6139, beta=0.0001\n",
      "Batch 40, loss=0.0427, recon=0.0427, kl=0.4982, beta=0.0001\n",
      "Batch 60, loss=0.0354, recon=0.0354, kl=0.5192, beta=0.0001\n",
      "Batch 80, loss=0.0402, recon=0.0402, kl=0.3885, beta=0.0001\n",
      "Batch 100, loss=0.0427, recon=0.0426, kl=0.3788, beta=0.0001\n",
      "Batch 120, loss=0.0295, recon=0.0294, kl=0.4314, beta=0.0001\n",
      "Batch 140, loss=0.0362, recon=0.0362, kl=0.4404, beta=0.0001\n",
      "Batch 160, loss=0.0897, recon=0.0897, kl=0.2546, beta=0.0001\n",
      "Batch 180, loss=0.0412, recon=0.0412, kl=0.2519, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0553, KL: 0.4539, Current Beta: 0.0001) | Avg Valid Loss: 0.0501 | Avg Valid recon Loss: 0.0501\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0312, recon=0.0312, kl=0.2127, beta=0.0001\n",
      "Batch 40, loss=0.0443, recon=0.0443, kl=0.2232, beta=0.0001\n",
      "Batch 60, loss=0.0604, recon=0.0603, kl=0.2360, beta=0.0001\n",
      "Batch 80, loss=0.0290, recon=0.0290, kl=0.1918, beta=0.0001\n",
      "Batch 100, loss=0.9462, recon=0.9462, kl=0.1332, beta=0.0001\n",
      "Batch 120, loss=0.0324, recon=0.0324, kl=0.1156, beta=0.0001\n",
      "Batch 140, loss=0.0339, recon=0.0339, kl=0.1073, beta=0.0001\n",
      "Batch 160, loss=0.0387, recon=0.0387, kl=0.1354, beta=0.0001\n",
      "Batch 180, loss=0.0380, recon=0.0380, kl=0.1247, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0543 (Recon: 0.0543, KL: 0.1728, Current Beta: 0.0001) | Avg Valid Loss: 0.0490 | Avg Valid recon Loss: 0.0490\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0468, recon=0.0468, kl=0.1172, beta=0.0001\n",
      "Batch 40, loss=0.0268, recon=0.0268, kl=0.1150, beta=0.0001\n",
      "Batch 60, loss=0.0394, recon=0.0394, kl=0.1229, beta=0.0001\n",
      "Batch 80, loss=0.0247, recon=0.0247, kl=0.0962, beta=0.0001\n",
      "Batch 100, loss=0.0537, recon=0.0537, kl=0.0748, beta=0.0001\n",
      "Batch 120, loss=0.0600, recon=0.0600, kl=0.0604, beta=0.0001\n",
      "Batch 140, loss=0.0373, recon=0.0372, kl=0.0635, beta=0.0001\n",
      "Batch 160, loss=0.0497, recon=0.0497, kl=0.0515, beta=0.0001\n",
      "Batch 180, loss=0.0401, recon=0.0401, kl=0.0591, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 0.0872, Current Beta: 0.0001) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0474\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0476, recon=0.0476, kl=0.0497, beta=0.0001\n",
      "Batch 40, loss=0.0387, recon=0.0387, kl=0.0492, beta=0.0001\n",
      "Batch 60, loss=0.0485, recon=0.0485, kl=0.0520, beta=0.0001\n",
      "Batch 80, loss=0.0371, recon=0.0371, kl=0.0645, beta=0.0001\n",
      "Batch 100, loss=0.0567, recon=0.0567, kl=0.0388, beta=0.0001\n",
      "Batch 120, loss=0.0359, recon=0.0359, kl=0.0358, beta=0.0001\n",
      "Batch 140, loss=0.0341, recon=0.0340, kl=0.0344, beta=0.0001\n",
      "Batch 160, loss=0.0387, recon=0.0387, kl=0.0297, beta=0.0001\n",
      "Batch 180, loss=0.0336, recon=0.0336, kl=0.0267, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0518, KL: 0.0448, Current Beta: 0.0001) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0466\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0424, recon=0.0424, kl=0.0237, beta=0.0001\n",
      "Batch 40, loss=0.0267, recon=0.0267, kl=0.0208, beta=0.0001\n",
      "Batch 60, loss=0.0812, recon=0.0812, kl=0.0190, beta=0.0001\n",
      "Batch 80, loss=0.0619, recon=0.0619, kl=0.0168, beta=0.0001\n",
      "Batch 100, loss=0.0315, recon=0.0315, kl=0.0147, beta=0.0001\n",
      "Batch 120, loss=0.0440, recon=0.0440, kl=0.0173, beta=0.0001\n",
      "Batch 140, loss=0.0342, recon=0.0342, kl=0.0163, beta=0.0001\n",
      "Batch 160, loss=0.0445, recon=0.0445, kl=0.0156, beta=0.0001\n",
      "Batch 180, loss=0.0355, recon=0.0355, kl=0.0134, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0509 (Recon: 0.0509, KL: 0.0184, Current Beta: 0.0001) | Avg Valid Loss: 0.0461 | Avg Valid recon Loss: 0.0461\n",
      "\n",
      "[VRAE Run 24/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3673, recon=0.3673, kl=62.5679, beta=0.0000\n",
      "Batch 40, loss=0.1227, recon=0.1227, kl=83.7542, beta=0.0000\n",
      "Batch 60, loss=0.1250, recon=0.1250, kl=95.4318, beta=0.0000\n",
      "Batch 80, loss=0.0907, recon=0.0907, kl=101.4072, beta=0.0000\n",
      "Batch 100, loss=0.0643, recon=0.0643, kl=118.6896, beta=0.0000\n",
      "Batch 120, loss=0.0682, recon=0.0682, kl=116.2778, beta=0.0000\n",
      "Batch 140, loss=0.0831, recon=0.0831, kl=101.3412, beta=0.0000\n",
      "Batch 160, loss=0.0806, recon=0.0806, kl=104.7879, beta=0.0000\n",
      "Batch 180, loss=0.1609, recon=0.1609, kl=122.2288, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1620 (Recon: 0.1620, KL: 94.4134, Current Beta: 0.0000) | Avg Valid Loss: 0.0994 | Avg Valid recon Loss: 0.0994\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1318, recon=0.1318, kl=121.8730, beta=0.0000\n",
      "Batch 40, loss=0.0658, recon=0.0658, kl=126.0216, beta=0.0000\n",
      "Batch 60, loss=0.1031, recon=0.1031, kl=86.2819, beta=0.0000\n",
      "Batch 80, loss=1.2005, recon=1.2005, kl=110.2938, beta=0.0000\n",
      "Batch 100, loss=0.0700, recon=0.0700, kl=126.1569, beta=0.0000\n",
      "Batch 120, loss=0.0504, recon=0.0504, kl=134.4035, beta=0.0000\n",
      "Batch 140, loss=0.0510, recon=0.0510, kl=143.3458, beta=0.0000\n",
      "Batch 160, loss=0.0405, recon=0.0405, kl=145.2542, beta=0.0000\n",
      "Batch 180, loss=0.0640, recon=0.0640, kl=147.0619, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0748 (Recon: 0.0748, KL: 125.3092, Current Beta: 0.0000) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0574\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=149.2136, beta=0.0000\n",
      "Batch 40, loss=0.0358, recon=0.0358, kl=153.7093, beta=0.0000\n",
      "Batch 60, loss=0.0530, recon=0.0530, kl=140.4791, beta=0.0000\n",
      "Batch 80, loss=0.0440, recon=0.0440, kl=137.9953, beta=0.0000\n",
      "Batch 100, loss=0.0684, recon=0.0684, kl=136.3350, beta=0.0000\n",
      "Batch 120, loss=0.0384, recon=0.0384, kl=127.5209, beta=0.0000\n",
      "Batch 140, loss=0.0321, recon=0.0321, kl=127.3097, beta=0.0000\n",
      "Batch 160, loss=0.0438, recon=0.0438, kl=131.3558, beta=0.0000\n",
      "Batch 180, loss=0.0494, recon=0.0494, kl=135.9640, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0640 (Recon: 0.0640, KL: 138.9919, Current Beta: 0.0000) | Avg Valid Loss: 0.0489 | Avg Valid recon Loss: 0.0489\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0356, recon=0.0356, kl=137.2062, beta=0.0000\n",
      "Batch 40, loss=0.0309, recon=0.0309, kl=136.2083, beta=0.0000\n",
      "Batch 60, loss=0.0328, recon=0.0328, kl=143.7547, beta=0.0000\n",
      "Batch 80, loss=0.0450, recon=0.0450, kl=150.1037, beta=0.0000\n",
      "Batch 100, loss=0.0346, recon=0.0346, kl=151.4758, beta=0.0000\n",
      "Batch 120, loss=0.0512, recon=0.0512, kl=138.2959, beta=0.0000\n",
      "Batch 140, loss=0.0590, recon=0.0590, kl=127.7611, beta=0.0000\n",
      "Batch 160, loss=0.0375, recon=0.0375, kl=128.6888, beta=0.0000\n",
      "Batch 180, loss=0.0384, recon=0.0384, kl=144.9952, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0564 (Recon: 0.0564, KL: 139.4215, Current Beta: 0.0000) | Avg Valid Loss: 0.0469 | Avg Valid recon Loss: 0.0469\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0705, recon=0.0705, kl=142.6131, beta=0.0000\n",
      "Batch 40, loss=0.0438, recon=0.0438, kl=148.6948, beta=0.0000\n",
      "Batch 60, loss=0.0664, recon=0.0664, kl=139.1709, beta=0.0000\n",
      "Batch 80, loss=0.0288, recon=0.0288, kl=130.4711, beta=0.0000\n",
      "Batch 100, loss=0.0348, recon=0.0348, kl=123.4793, beta=0.0000\n",
      "Batch 120, loss=0.0318, recon=0.0318, kl=123.6388, beta=0.0000\n",
      "Batch 140, loss=0.0386, recon=0.0386, kl=133.3058, beta=0.0000\n",
      "Batch 160, loss=0.0339, recon=0.0339, kl=144.6990, beta=0.0000\n",
      "Batch 180, loss=0.0287, recon=0.0287, kl=135.8263, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0518, KL: 136.7841, Current Beta: 0.0000) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0444, recon=0.0444, kl=132.8638, beta=0.0000\n",
      "Batch 40, loss=0.0613, recon=0.0613, kl=131.6246, beta=0.0000\n",
      "Batch 60, loss=0.0614, recon=0.0614, kl=133.7270, beta=0.0000\n",
      "Batch 80, loss=0.0461, recon=0.0461, kl=130.8880, beta=0.0000\n",
      "Batch 100, loss=0.0572, recon=0.0572, kl=130.4999, beta=0.0000\n",
      "Batch 120, loss=0.0368, recon=0.0368, kl=109.1601, beta=0.0000\n",
      "Batch 140, loss=0.0369, recon=0.0369, kl=126.5015, beta=0.0000\n",
      "Batch 160, loss=0.0481, recon=0.0481, kl=142.2826, beta=0.0000\n",
      "Batch 180, loss=0.0269, recon=0.0269, kl=150.9254, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0496, KL: 132.0305, Current Beta: 0.0000) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0350, recon=0.0350, kl=151.3539, beta=0.0000\n",
      "Batch 40, loss=0.0742, recon=0.0742, kl=149.2084, beta=0.0000\n",
      "Batch 60, loss=0.0325, recon=0.0325, kl=144.2891, beta=0.0000\n",
      "Batch 80, loss=0.0382, recon=0.0382, kl=146.1537, beta=0.0000\n",
      "Batch 100, loss=0.0304, recon=0.0304, kl=140.9124, beta=0.0000\n",
      "Batch 120, loss=0.0313, recon=0.0313, kl=142.5063, beta=0.0000\n",
      "Batch 140, loss=0.0708, recon=0.0708, kl=137.1507, beta=0.0000\n",
      "Batch 160, loss=0.1695, recon=0.1695, kl=140.8899, beta=0.0000\n",
      "Batch 180, loss=0.0341, recon=0.0341, kl=67.6889, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0450, KL: 140.3077, Current Beta: 0.0000) | Avg Valid Loss: 0.0404 | Avg Valid recon Loss: 0.0404\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0309, recon=0.0309, kl=138.0284, beta=0.0000\n",
      "Batch 40, loss=0.0522, recon=0.0521, kl=137.6494, beta=0.0000\n",
      "Batch 60, loss=0.0282, recon=0.0282, kl=145.9236, beta=0.0000\n",
      "Batch 80, loss=0.0293, recon=0.0293, kl=154.9612, beta=0.0000\n",
      "Batch 100, loss=0.0439, recon=0.0438, kl=156.1403, beta=0.0000\n",
      "Batch 120, loss=0.0342, recon=0.0342, kl=147.2518, beta=0.0000\n",
      "Batch 140, loss=0.0262, recon=0.0262, kl=137.8296, beta=0.0000\n",
      "Batch 160, loss=0.0341, recon=0.0341, kl=143.4619, beta=0.0000\n",
      "Batch 180, loss=0.0321, recon=0.0320, kl=144.6294, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0467 (Recon: 0.0467, KL: 141.8026, Current Beta: 0.0000) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0688, recon=0.0688, kl=135.4520, beta=0.0000\n",
      "Batch 40, loss=0.0431, recon=0.0431, kl=132.6299, beta=0.0000\n",
      "Batch 60, loss=0.0674, recon=0.0674, kl=128.0285, beta=0.0000\n",
      "Batch 80, loss=0.0419, recon=0.0418, kl=126.7385, beta=0.0000\n",
      "Batch 100, loss=0.0607, recon=0.0607, kl=129.6697, beta=0.0000\n",
      "Batch 120, loss=0.0282, recon=0.0281, kl=125.6535, beta=0.0000\n",
      "Batch 140, loss=0.0311, recon=0.0310, kl=120.7217, beta=0.0000\n",
      "Batch 160, loss=0.0319, recon=0.0318, kl=116.5999, beta=0.0000\n",
      "Batch 180, loss=0.0511, recon=0.0510, kl=117.3523, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 127.1998, Current Beta: 0.0000) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0474, recon=0.0473, kl=105.0463, beta=0.0000\n",
      "Batch 40, loss=0.0319, recon=0.0318, kl=94.9728, beta=0.0000\n",
      "Batch 60, loss=0.0299, recon=0.0298, kl=85.6147, beta=0.0000\n",
      "Batch 80, loss=0.0400, recon=0.0399, kl=100.9183, beta=0.0000\n",
      "Batch 100, loss=0.0442, recon=0.0441, kl=102.3364, beta=0.0000\n",
      "Batch 120, loss=0.0457, recon=0.0456, kl=96.9296, beta=0.0000\n",
      "Batch 140, loss=0.0409, recon=0.0408, kl=100.0232, beta=0.0000\n",
      "Batch 160, loss=0.0538, recon=0.0537, kl=100.9327, beta=0.0000\n",
      "Batch 180, loss=0.0606, recon=0.0605, kl=97.7003, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0477 (Recon: 0.0476, KL: 99.6086, Current Beta: 0.0000) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0477\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1027, recon=0.1025, kl=82.6212, beta=0.0000\n",
      "Batch 40, loss=0.0932, recon=0.0930, kl=85.5977, beta=0.0000\n",
      "Batch 60, loss=0.0387, recon=0.0385, kl=76.4220, beta=0.0000\n",
      "Batch 80, loss=0.1780, recon=0.1778, kl=70.9054, beta=0.0000\n",
      "Batch 100, loss=0.0562, recon=0.0560, kl=67.2992, beta=0.0000\n",
      "Batch 120, loss=0.1104, recon=0.1102, kl=64.5397, beta=0.0000\n",
      "Batch 140, loss=0.0841, recon=0.0839, kl=68.4880, beta=0.0000\n",
      "Batch 160, loss=0.0327, recon=0.0325, kl=86.8736, beta=0.0000\n",
      "Batch 180, loss=0.0343, recon=0.0341, kl=77.0091, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0585 (Recon: 0.0583, KL: 76.6915, Current Beta: 0.0000) | Avg Valid Loss: 0.0428 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0347, recon=0.0343, kl=46.5135, beta=0.0000\n",
      "Batch 40, loss=0.0248, recon=0.0244, kl=48.7253, beta=0.0000\n",
      "Batch 60, loss=0.0703, recon=0.0700, kl=38.4446, beta=0.0000\n",
      "Batch 80, loss=0.0633, recon=0.0630, kl=41.1169, beta=0.0000\n",
      "Batch 100, loss=0.0411, recon=0.0407, kl=49.9992, beta=0.0000\n",
      "Batch 120, loss=0.0339, recon=0.0336, kl=46.9146, beta=0.0000\n",
      "Batch 140, loss=0.0324, recon=0.0320, kl=50.7886, beta=0.0000\n",
      "Batch 160, loss=0.0303, recon=0.0299, kl=45.1670, beta=0.0000\n",
      "Batch 180, loss=0.0398, recon=0.0395, kl=36.6780, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0543, KL: 46.9930, Current Beta: 0.0000) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0365, recon=0.0361, kl=20.8155, beta=0.0000\n",
      "Batch 40, loss=0.1034, recon=0.1031, kl=17.6356, beta=0.0000\n",
      "Batch 60, loss=0.0538, recon=0.0534, kl=19.6174, beta=0.0000\n",
      "Batch 80, loss=0.0292, recon=0.0288, kl=23.7397, beta=0.0000\n",
      "Batch 100, loss=0.1286, recon=0.1281, kl=24.4876, beta=0.0000\n",
      "Batch 120, loss=0.0443, recon=0.0439, kl=22.5940, beta=0.0000\n",
      "Batch 140, loss=0.0359, recon=0.0356, kl=20.2655, beta=0.0000\n",
      "Batch 160, loss=0.0274, recon=0.0271, kl=17.4878, beta=0.0000\n",
      "Batch 180, loss=0.0315, recon=0.0312, kl=15.9021, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0452 (Recon: 0.0448, KL: 21.0417, Current Beta: 0.0000) | Avg Valid Loss: 0.0386 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0281, recon=0.0276, kl=14.5071, beta=0.0000\n",
      "Batch 40, loss=0.0336, recon=0.0332, kl=11.5729, beta=0.0000\n",
      "Batch 60, loss=0.0427, recon=0.0423, kl=9.5522, beta=0.0000\n",
      "Batch 80, loss=0.0417, recon=0.0413, kl=9.5318, beta=0.0000\n",
      "Batch 100, loss=0.0332, recon=0.0328, kl=11.9793, beta=0.0000\n",
      "Batch 120, loss=0.0232, recon=0.0228, kl=12.2025, beta=0.0000\n",
      "Batch 140, loss=0.0761, recon=0.0757, kl=10.8328, beta=0.0000\n",
      "Batch 160, loss=0.0288, recon=0.0284, kl=9.6420, beta=0.0000\n",
      "Batch 180, loss=0.0297, recon=0.0293, kl=9.8424, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0448 (Recon: 0.0444, KL: 11.3523, Current Beta: 0.0000) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0320, recon=0.0315, kl=7.9880, beta=0.0001\n",
      "Batch 40, loss=0.0294, recon=0.0291, kl=5.0096, beta=0.0001\n",
      "Batch 60, loss=0.0287, recon=0.0285, kl=2.4447, beta=0.0001\n",
      "Batch 80, loss=0.0250, recon=0.0248, kl=1.8865, beta=0.0001\n",
      "Batch 100, loss=0.0295, recon=0.0294, kl=1.1448, beta=0.0001\n",
      "Batch 120, loss=0.0264, recon=0.0263, kl=1.7179, beta=0.0001\n",
      "Batch 140, loss=0.0629, recon=0.0628, kl=1.3807, beta=0.0001\n",
      "Batch 160, loss=0.0260, recon=0.0259, kl=1.2878, beta=0.0001\n",
      "Batch 180, loss=0.0459, recon=0.0458, kl=1.8986, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0418, KL: 3.1281, Current Beta: 0.0001) | Avg Valid Loss: 0.0468 | Avg Valid recon Loss: 0.0467\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0426, recon=0.0425, kl=0.8819, beta=0.0001\n",
      "Batch 40, loss=0.0435, recon=0.0434, kl=0.6431, beta=0.0001\n",
      "Batch 60, loss=0.0560, recon=0.0559, kl=0.7016, beta=0.0001\n",
      "Batch 80, loss=0.0345, recon=0.0345, kl=0.4682, beta=0.0001\n",
      "Batch 100, loss=0.0521, recon=0.0521, kl=0.2970, beta=0.0001\n",
      "Batch 120, loss=0.0303, recon=0.0302, kl=0.2138, beta=0.0001\n",
      "Batch 140, loss=0.0219, recon=0.0218, kl=0.1633, beta=0.0001\n",
      "Batch 160, loss=0.0313, recon=0.0313, kl=0.1598, beta=0.0001\n",
      "Batch 180, loss=0.0481, recon=0.0481, kl=0.0809, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0479, KL: 0.4956, Current Beta: 0.0001) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0304, recon=0.0304, kl=0.0613, beta=0.0001\n",
      "Batch 40, loss=0.0226, recon=0.0226, kl=0.0265, beta=0.0001\n",
      "Batch 60, loss=0.0492, recon=0.0492, kl=0.0397, beta=0.0001\n",
      "Batch 80, loss=0.0261, recon=0.0261, kl=0.0402, beta=0.0001\n",
      "Batch 100, loss=0.0291, recon=0.0291, kl=0.0646, beta=0.0001\n",
      "Batch 120, loss=0.0357, recon=0.0357, kl=0.2519, beta=0.0001\n",
      "Batch 140, loss=0.0242, recon=0.0240, kl=1.3453, beta=0.0001\n",
      "Batch 160, loss=0.0431, recon=0.0429, kl=1.3964, beta=0.0001\n",
      "Batch 180, loss=0.0362, recon=0.0361, kl=0.8774, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 0.4122, Current Beta: 0.0001) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0429\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0305, recon=0.0305, kl=0.5324, beta=0.0001\n",
      "Batch 40, loss=0.0206, recon=0.0206, kl=0.2769, beta=0.0001\n",
      "Batch 60, loss=0.0248, recon=0.0248, kl=0.0819, beta=0.0001\n",
      "Batch 80, loss=0.0350, recon=0.0349, kl=0.0740, beta=0.0001\n",
      "Batch 100, loss=0.0440, recon=0.0440, kl=0.0970, beta=0.0001\n",
      "Batch 120, loss=0.0819, recon=0.0819, kl=0.1152, beta=0.0001\n",
      "Batch 140, loss=0.0271, recon=0.0271, kl=0.0574, beta=0.0001\n",
      "Batch 160, loss=0.0269, recon=0.0269, kl=0.0621, beta=0.0001\n",
      "Batch 180, loss=0.0414, recon=0.0414, kl=0.0710, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0428, KL: 0.1895, Current Beta: 0.0001) | Avg Valid Loss: 0.0462 | Avg Valid recon Loss: 0.0462\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0513, recon=0.0513, kl=0.1449, beta=0.0001\n",
      "Batch 40, loss=0.4272, recon=0.4272, kl=0.2360, beta=0.0001\n",
      "Batch 60, loss=0.0280, recon=0.0280, kl=0.1463, beta=0.0001\n",
      "Batch 80, loss=0.1454, recon=0.1454, kl=0.0628, beta=0.0001\n",
      "Batch 100, loss=0.0278, recon=0.0278, kl=0.0825, beta=0.0001\n",
      "Batch 120, loss=0.1165, recon=0.1165, kl=0.2871, beta=0.0001\n",
      "Batch 140, loss=0.0389, recon=0.0388, kl=0.3070, beta=0.0001\n",
      "Batch 160, loss=0.0482, recon=0.0482, kl=0.1790, beta=0.0001\n",
      "Batch 180, loss=0.0307, recon=0.0307, kl=0.0929, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0422, KL: 0.1706, Current Beta: 0.0001) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0334\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0302, recon=0.0302, kl=0.0818, beta=0.0001\n",
      "Batch 40, loss=0.0265, recon=0.0265, kl=0.0626, beta=0.0001\n",
      "Batch 60, loss=0.0277, recon=0.0277, kl=0.1029, beta=0.0001\n",
      "Batch 80, loss=0.0273, recon=0.0273, kl=0.1291, beta=0.0001\n",
      "Batch 100, loss=0.0273, recon=0.0273, kl=0.3003, beta=0.0001\n",
      "Batch 120, loss=0.0467, recon=0.0466, kl=0.7060, beta=0.0001\n",
      "Batch 140, loss=0.0266, recon=0.0264, kl=1.7106, beta=0.0001\n",
      "Batch 160, loss=0.0262, recon=0.0260, kl=1.6800, beta=0.0001\n",
      "Batch 180, loss=0.0654, recon=0.0653, kl=1.0095, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0374 (Recon: 0.0374, KL: 0.6037, Current Beta: 0.0001) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0368\n",
      "\n",
      "[VRAE Run 25/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3443, recon=0.3443, kl=0.8835, beta=0.0000\n",
      "Batch 40, loss=0.2979, recon=0.2979, kl=10.5106, beta=0.0000\n",
      "Batch 60, loss=0.1824, recon=0.1824, kl=16.1572, beta=0.0000\n",
      "Batch 80, loss=0.1612, recon=0.1612, kl=20.8619, beta=0.0000\n",
      "Batch 100, loss=0.1575, recon=0.1575, kl=23.4440, beta=0.0000\n",
      "Batch 120, loss=0.1372, recon=0.1372, kl=25.4582, beta=0.0000\n",
      "Batch 140, loss=0.2327, recon=0.2327, kl=27.8708, beta=0.0000\n",
      "Batch 160, loss=0.2006, recon=0.2006, kl=30.9278, beta=0.0000\n",
      "Batch 180, loss=0.1267, recon=0.1267, kl=32.1301, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3004 (Recon: 0.3004, KL: 19.2303, Current Beta: 0.0000) | Avg Valid Loss: 0.1266 | Avg Valid recon Loss: 0.1266\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1012, recon=0.1012, kl=35.2180, beta=0.0000\n",
      "Batch 40, loss=0.1006, recon=0.1006, kl=37.1458, beta=0.0000\n",
      "Batch 60, loss=0.1022, recon=0.1022, kl=37.2843, beta=0.0000\n",
      "Batch 80, loss=0.0795, recon=0.0795, kl=37.3222, beta=0.0000\n",
      "Batch 100, loss=0.1022, recon=0.1022, kl=39.4672, beta=0.0000\n",
      "Batch 120, loss=0.3590, recon=0.3590, kl=39.8274, beta=0.0000\n",
      "Batch 140, loss=0.0714, recon=0.0714, kl=41.5972, beta=0.0000\n",
      "Batch 160, loss=0.1084, recon=0.1084, kl=41.4254, beta=0.0000\n",
      "Batch 180, loss=0.0683, recon=0.0683, kl=41.2068, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1243 (Recon: 0.1243, KL: 38.4748, Current Beta: 0.0000) | Avg Valid Loss: 0.0891 | Avg Valid recon Loss: 0.0891\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0565, recon=0.0565, kl=43.8835, beta=0.0000\n",
      "Batch 40, loss=0.1365, recon=0.1365, kl=44.2436, beta=0.0000\n",
      "Batch 60, loss=0.1366, recon=0.1366, kl=45.0824, beta=0.0000\n",
      "Batch 80, loss=0.0732, recon=0.0732, kl=44.7553, beta=0.0000\n",
      "Batch 100, loss=0.0603, recon=0.0603, kl=45.1945, beta=0.0000\n",
      "Batch 120, loss=0.0494, recon=0.0494, kl=45.5157, beta=0.0000\n",
      "Batch 140, loss=0.0652, recon=0.0652, kl=45.7375, beta=0.0000\n",
      "Batch 160, loss=0.0606, recon=0.0606, kl=45.3075, beta=0.0000\n",
      "Batch 180, loss=0.0527, recon=0.0527, kl=45.2033, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0943 (Recon: 0.0943, KL: 44.7993, Current Beta: 0.0000) | Avg Valid Loss: 0.0741 | Avg Valid recon Loss: 0.0741\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0558, recon=0.0558, kl=46.7591, beta=0.0000\n",
      "Batch 40, loss=0.0730, recon=0.0730, kl=47.1442, beta=0.0000\n",
      "Batch 60, loss=0.0979, recon=0.0979, kl=49.1059, beta=0.0000\n",
      "Batch 80, loss=0.0450, recon=0.0450, kl=51.6816, beta=0.0000\n",
      "Batch 100, loss=0.0499, recon=0.0499, kl=50.6233, beta=0.0000\n",
      "Batch 120, loss=0.0510, recon=0.0510, kl=50.8494, beta=0.0000\n",
      "Batch 140, loss=0.0592, recon=0.0592, kl=53.5733, beta=0.0000\n",
      "Batch 160, loss=0.0554, recon=0.0554, kl=55.4697, beta=0.0000\n",
      "Batch 180, loss=0.0411, recon=0.0411, kl=56.1442, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0793 (Recon: 0.0793, KL: 50.5978, Current Beta: 0.0000) | Avg Valid Loss: 0.0656 | Avg Valid recon Loss: 0.0656\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0642, recon=0.0642, kl=53.7495, beta=0.0000\n",
      "Batch 40, loss=0.1511, recon=0.1511, kl=55.3611, beta=0.0000\n",
      "Batch 60, loss=0.0495, recon=0.0495, kl=56.8997, beta=0.0000\n",
      "Batch 80, loss=0.0553, recon=0.0553, kl=56.3857, beta=0.0000\n",
      "Batch 100, loss=0.0612, recon=0.0612, kl=55.8806, beta=0.0000\n",
      "Batch 120, loss=0.0535, recon=0.0535, kl=55.3672, beta=0.0000\n",
      "Batch 140, loss=0.0406, recon=0.0406, kl=56.9114, beta=0.0000\n",
      "Batch 160, loss=0.0504, recon=0.0504, kl=57.5413, beta=0.0000\n",
      "Batch 180, loss=0.0383, recon=0.0383, kl=56.4492, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0705 (Recon: 0.0705, KL: 56.2308, Current Beta: 0.0000) | Avg Valid Loss: 0.0591 | Avg Valid recon Loss: 0.0591\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0548, recon=0.0548, kl=56.3805, beta=0.0000\n",
      "Batch 40, loss=0.0430, recon=0.0430, kl=56.5701, beta=0.0000\n",
      "Batch 60, loss=0.0359, recon=0.0359, kl=59.8484, beta=0.0000\n",
      "Batch 80, loss=0.0426, recon=0.0426, kl=58.3204, beta=0.0000\n",
      "Batch 100, loss=0.0403, recon=0.0403, kl=58.5199, beta=0.0000\n",
      "Batch 120, loss=0.0779, recon=0.0779, kl=58.6827, beta=0.0000\n",
      "Batch 140, loss=0.0386, recon=0.0386, kl=57.1251, beta=0.0000\n",
      "Batch 160, loss=0.0313, recon=0.0313, kl=57.3712, beta=0.0000\n",
      "Batch 180, loss=0.0386, recon=0.0386, kl=57.2718, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0649 (Recon: 0.0649, KL: 57.5837, Current Beta: 0.0000) | Avg Valid Loss: 0.0562 | Avg Valid recon Loss: 0.0562\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=56.7460, beta=0.0000\n",
      "Batch 40, loss=0.0422, recon=0.0422, kl=57.5318, beta=0.0000\n",
      "Batch 60, loss=0.0686, recon=0.0686, kl=57.3303, beta=0.0000\n",
      "Batch 80, loss=0.0335, recon=0.0335, kl=55.5488, beta=0.0000\n",
      "Batch 100, loss=0.0393, recon=0.0393, kl=57.0876, beta=0.0000\n",
      "Batch 120, loss=0.0404, recon=0.0404, kl=56.2310, beta=0.0000\n",
      "Batch 140, loss=0.0341, recon=0.0341, kl=54.2592, beta=0.0000\n",
      "Batch 160, loss=0.0306, recon=0.0306, kl=53.8478, beta=0.0000\n",
      "Batch 180, loss=0.0622, recon=0.0622, kl=53.1692, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0605 (Recon: 0.0605, KL: 55.9635, Current Beta: 0.0000) | Avg Valid Loss: 0.0527 | Avg Valid recon Loss: 0.0527\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1663, recon=0.1663, kl=52.0931, beta=0.0000\n",
      "Batch 40, loss=0.0349, recon=0.0349, kl=51.4089, beta=0.0000\n",
      "Batch 60, loss=0.0415, recon=0.0414, kl=48.8252, beta=0.0000\n",
      "Batch 80, loss=0.0504, recon=0.0503, kl=47.0629, beta=0.0000\n",
      "Batch 100, loss=0.0381, recon=0.0381, kl=44.9111, beta=0.0000\n",
      "Batch 120, loss=0.1003, recon=0.1003, kl=46.5227, beta=0.0000\n",
      "Batch 140, loss=0.0436, recon=0.0436, kl=47.4630, beta=0.0000\n",
      "Batch 160, loss=0.0629, recon=0.0629, kl=45.3351, beta=0.0000\n",
      "Batch 180, loss=0.0504, recon=0.0504, kl=44.9069, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0573 (Recon: 0.0573, KL: 48.1372, Current Beta: 0.0000) | Avg Valid Loss: 0.0500 | Avg Valid recon Loss: 0.0500\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0378, recon=0.0378, kl=41.1091, beta=0.0000\n",
      "Batch 40, loss=0.0261, recon=0.0261, kl=38.2449, beta=0.0000\n",
      "Batch 60, loss=0.0597, recon=0.0596, kl=37.1478, beta=0.0000\n",
      "Batch 80, loss=0.0334, recon=0.0333, kl=38.6611, beta=0.0000\n",
      "Batch 100, loss=0.0442, recon=0.0442, kl=36.4569, beta=0.0000\n",
      "Batch 120, loss=0.0429, recon=0.0429, kl=33.1101, beta=0.0000\n",
      "Batch 140, loss=0.0337, recon=0.0337, kl=35.1061, beta=0.0000\n",
      "Batch 160, loss=0.0529, recon=0.0529, kl=34.3128, beta=0.0000\n",
      "Batch 180, loss=0.0488, recon=0.0488, kl=33.3264, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0546, KL: 37.0501, Current Beta: 0.0000) | Avg Valid Loss: 0.0471 | Avg Valid recon Loss: 0.0471\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0476, recon=0.0476, kl=30.3791, beta=0.0000\n",
      "Batch 40, loss=0.0473, recon=0.0473, kl=25.1561, beta=0.0000\n",
      "Batch 60, loss=0.0386, recon=0.0385, kl=24.1143, beta=0.0000\n",
      "Batch 80, loss=0.0275, recon=0.0275, kl=25.4132, beta=0.0000\n",
      "Batch 100, loss=0.0270, recon=0.0270, kl=25.5700, beta=0.0000\n",
      "Batch 120, loss=0.0615, recon=0.0615, kl=24.4738, beta=0.0000\n",
      "Batch 140, loss=0.0396, recon=0.0396, kl=23.6357, beta=0.0000\n",
      "Batch 160, loss=0.0748, recon=0.0748, kl=22.6031, beta=0.0000\n",
      "Batch 180, loss=0.2740, recon=0.2740, kl=21.7756, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0523, KL: 25.3159, Current Beta: 0.0000) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0454\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0309, recon=0.0309, kl=15.9102, beta=0.0000\n",
      "Batch 40, loss=0.0347, recon=0.0346, kl=14.9281, beta=0.0000\n",
      "Batch 60, loss=0.0506, recon=0.0505, kl=15.4779, beta=0.0000\n",
      "Batch 80, loss=0.0442, recon=0.0442, kl=15.0697, beta=0.0000\n",
      "Batch 100, loss=0.0299, recon=0.0298, kl=12.3213, beta=0.0000\n",
      "Batch 120, loss=0.0245, recon=0.0245, kl=12.2538, beta=0.0000\n",
      "Batch 140, loss=0.0319, recon=0.0319, kl=12.7469, beta=0.0000\n",
      "Batch 160, loss=0.0375, recon=0.0374, kl=12.2524, beta=0.0000\n",
      "Batch 180, loss=0.0380, recon=0.0380, kl=12.8526, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0501, KL: 14.2965, Current Beta: 0.0000) | Avg Valid Loss: 0.0437 | Avg Valid recon Loss: 0.0437\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0546, recon=0.0545, kl=7.7020, beta=0.0000\n",
      "Batch 40, loss=0.0315, recon=0.0314, kl=8.9639, beta=0.0000\n",
      "Batch 60, loss=0.0383, recon=0.0383, kl=7.7033, beta=0.0000\n",
      "Batch 80, loss=0.0282, recon=0.0282, kl=6.8241, beta=0.0000\n",
      "Batch 100, loss=0.0648, recon=0.0647, kl=7.4677, beta=0.0000\n",
      "Batch 120, loss=0.0818, recon=0.0817, kl=5.1498, beta=0.0000\n",
      "Batch 140, loss=0.0308, recon=0.0307, kl=7.0370, beta=0.0000\n",
      "Batch 160, loss=0.0501, recon=0.0500, kl=5.8655, beta=0.0000\n",
      "Batch 180, loss=0.0265, recon=0.0265, kl=7.0756, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0486 (Recon: 0.0486, KL: 7.3049, Current Beta: 0.0000) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0270, recon=0.0270, kl=3.2687, beta=0.0000\n",
      "Batch 40, loss=0.0393, recon=0.0392, kl=6.0647, beta=0.0000\n",
      "Batch 60, loss=0.0391, recon=0.0390, kl=4.1189, beta=0.0000\n",
      "Batch 80, loss=0.0345, recon=0.0344, kl=2.9668, beta=0.0000\n",
      "Batch 100, loss=0.0294, recon=0.0294, kl=3.1499, beta=0.0000\n",
      "Batch 120, loss=0.0578, recon=0.0578, kl=2.6972, beta=0.0000\n",
      "Batch 140, loss=0.0342, recon=0.0341, kl=2.7687, beta=0.0000\n",
      "Batch 160, loss=0.0595, recon=0.0594, kl=2.6731, beta=0.0000\n",
      "Batch 180, loss=0.0594, recon=0.0594, kl=2.8815, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0472, KL: 3.5217, Current Beta: 0.0000) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0409\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0229, recon=0.0229, kl=1.8682, beta=0.0000\n",
      "Batch 40, loss=0.0384, recon=0.0383, kl=1.6108, beta=0.0000\n",
      "Batch 60, loss=0.0281, recon=0.0281, kl=1.5898, beta=0.0000\n",
      "Batch 80, loss=0.0363, recon=0.0363, kl=1.2821, beta=0.0000\n",
      "Batch 100, loss=0.0700, recon=0.0699, kl=1.4573, beta=0.0000\n",
      "Batch 120, loss=0.0480, recon=0.0480, kl=1.5362, beta=0.0000\n",
      "Batch 140, loss=0.0338, recon=0.0338, kl=1.0029, beta=0.0000\n",
      "Batch 160, loss=0.0260, recon=0.0259, kl=1.6134, beta=0.0000\n",
      "Batch 180, loss=0.0418, recon=0.0418, kl=1.0840, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0460, KL: 1.5209, Current Beta: 0.0000) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0410, recon=0.0410, kl=0.7583, beta=0.0001\n",
      "Batch 40, loss=0.0359, recon=0.0359, kl=0.5530, beta=0.0001\n",
      "Batch 60, loss=0.0394, recon=0.0393, kl=1.1561, beta=0.0001\n",
      "Batch 80, loss=0.0402, recon=0.0401, kl=0.8081, beta=0.0001\n",
      "Batch 100, loss=0.0341, recon=0.0341, kl=0.4828, beta=0.0001\n",
      "Batch 120, loss=0.0334, recon=0.0334, kl=0.8074, beta=0.0001\n",
      "Batch 140, loss=0.0545, recon=0.0544, kl=0.4750, beta=0.0001\n",
      "Batch 160, loss=0.0441, recon=0.0441, kl=0.4585, beta=0.0001\n",
      "Batch 180, loss=0.0384, recon=0.0384, kl=0.3527, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0448 (Recon: 0.0447, KL: 0.6900, Current Beta: 0.0001) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0291, recon=0.0291, kl=0.1568, beta=0.0001\n",
      "Batch 40, loss=0.0524, recon=0.0523, kl=0.2544, beta=0.0001\n",
      "Batch 60, loss=0.0243, recon=0.0243, kl=0.1980, beta=0.0001\n",
      "Batch 80, loss=0.1533, recon=0.1533, kl=0.1639, beta=0.0001\n",
      "Batch 100, loss=0.0220, recon=0.0220, kl=0.1355, beta=0.0001\n",
      "Batch 120, loss=0.0299, recon=0.0299, kl=0.3090, beta=0.0001\n",
      "Batch 140, loss=0.0356, recon=0.0355, kl=0.1263, beta=0.0001\n",
      "Batch 160, loss=0.0607, recon=0.0607, kl=0.0891, beta=0.0001\n",
      "Batch 180, loss=0.0357, recon=0.0357, kl=0.4325, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 0.2013, Current Beta: 0.0001) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0444, recon=0.0443, kl=0.1050, beta=0.0001\n",
      "Batch 40, loss=0.0256, recon=0.0256, kl=0.1632, beta=0.0001\n",
      "Batch 60, loss=0.0342, recon=0.0341, kl=0.0652, beta=0.0001\n",
      "Batch 80, loss=0.0450, recon=0.0449, kl=0.1718, beta=0.0001\n",
      "Batch 100, loss=0.0204, recon=0.0204, kl=0.0427, beta=0.0001\n",
      "Batch 120, loss=0.0297, recon=0.0297, kl=0.0930, beta=0.0001\n",
      "Batch 140, loss=0.0293, recon=0.0293, kl=0.0437, beta=0.0001\n",
      "Batch 160, loss=0.0284, recon=0.0284, kl=0.0815, beta=0.0001\n",
      "Batch 180, loss=0.0263, recon=0.0263, kl=0.0352, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0428, KL: 0.1105, Current Beta: 0.0001) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0329, recon=0.0329, kl=0.0544, beta=0.0001\n",
      "Batch 40, loss=0.0219, recon=0.0218, kl=0.0278, beta=0.0001\n",
      "Batch 60, loss=0.0333, recon=0.0333, kl=0.0344, beta=0.0001\n",
      "Batch 80, loss=0.0924, recon=0.0924, kl=0.0604, beta=0.0001\n",
      "Batch 100, loss=0.0224, recon=0.0223, kl=0.1135, beta=0.0001\n",
      "Batch 120, loss=0.0697, recon=0.0697, kl=0.0163, beta=0.0001\n",
      "Batch 140, loss=0.0269, recon=0.0269, kl=0.0509, beta=0.0001\n",
      "Batch 160, loss=0.0279, recon=0.0279, kl=0.0842, beta=0.0001\n",
      "Batch 180, loss=0.0245, recon=0.0245, kl=0.0791, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0417, KL: 0.0625, Current Beta: 0.0001) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0261, recon=0.0261, kl=0.0450, beta=0.0001\n",
      "Batch 40, loss=0.0291, recon=0.0291, kl=0.0581, beta=0.0001\n",
      "Batch 60, loss=0.0312, recon=0.0312, kl=0.0161, beta=0.0001\n",
      "Batch 80, loss=0.0220, recon=0.0220, kl=0.0263, beta=0.0001\n",
      "Batch 100, loss=0.0565, recon=0.0565, kl=0.1323, beta=0.0001\n",
      "Batch 120, loss=0.0564, recon=0.0564, kl=0.0107, beta=0.0001\n",
      "Batch 140, loss=0.0304, recon=0.0304, kl=0.0522, beta=0.0001\n",
      "Batch 160, loss=0.0268, recon=0.0267, kl=0.0672, beta=0.0001\n",
      "Batch 180, loss=0.0312, recon=0.0312, kl=0.0924, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0412 (Recon: 0.0412, KL: 0.0487, Current Beta: 0.0001) | Avg Valid Loss: 0.0359 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0283, recon=0.0283, kl=0.0140, beta=0.0001\n",
      "Batch 40, loss=0.0286, recon=0.0286, kl=0.0713, beta=0.0001\n",
      "Batch 60, loss=0.0194, recon=0.0194, kl=0.0333, beta=0.0001\n",
      "Batch 80, loss=0.0301, recon=0.0301, kl=0.0243, beta=0.0001\n",
      "Batch 100, loss=0.0243, recon=0.0243, kl=0.0435, beta=0.0001\n",
      "Batch 120, loss=0.0271, recon=0.0271, kl=0.0329, beta=0.0001\n",
      "Batch 140, loss=0.0361, recon=0.0361, kl=0.0266, beta=0.0001\n",
      "Batch 160, loss=0.0496, recon=0.0495, kl=0.0392, beta=0.0001\n",
      "Batch 180, loss=0.0312, recon=0.0312, kl=0.0452, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0401 (Recon: 0.0401, KL: 0.0433, Current Beta: 0.0001) | Avg Valid Loss: 0.0350 | Avg Valid recon Loss: 0.0350\n",
      "\n",
      "[VRAE Run 26/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3081, recon=0.3081, kl=20.7359, beta=0.0000\n",
      "Batch 40, loss=0.1030, recon=0.1030, kl=26.2652, beta=0.0000\n",
      "Batch 60, loss=0.4821, recon=0.4821, kl=29.6824, beta=0.0000\n",
      "Batch 80, loss=0.0632, recon=0.0632, kl=28.1489, beta=0.0000\n",
      "Batch 100, loss=0.0703, recon=0.0703, kl=31.3563, beta=0.0000\n",
      "Batch 120, loss=0.0654, recon=0.0654, kl=32.6966, beta=0.0000\n",
      "Batch 140, loss=0.0593, recon=0.0593, kl=34.9497, beta=0.0000\n",
      "Batch 160, loss=0.0573, recon=0.0573, kl=34.9659, beta=0.0000\n",
      "Batch 180, loss=0.0379, recon=0.0379, kl=33.6925, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1376 (Recon: 0.1376, KL: 28.3094, Current Beta: 0.0000) | Avg Valid Loss: 0.0634 | Avg Valid recon Loss: 0.0634\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0520, recon=0.0520, kl=34.3115, beta=0.0000\n",
      "Batch 40, loss=0.0519, recon=0.0519, kl=28.3936, beta=0.0000\n",
      "Batch 60, loss=0.2940, recon=0.2940, kl=26.6934, beta=0.0000\n",
      "Batch 80, loss=0.0787, recon=0.0787, kl=33.8689, beta=0.0000\n",
      "Batch 100, loss=0.0433, recon=0.0433, kl=36.7488, beta=0.0000\n",
      "Batch 120, loss=0.0433, recon=0.0433, kl=36.1466, beta=0.0000\n",
      "Batch 140, loss=0.1954, recon=0.1954, kl=33.9224, beta=0.0000\n",
      "Batch 160, loss=0.0477, recon=0.0477, kl=34.6141, beta=0.0000\n",
      "Batch 180, loss=0.0393, recon=0.0393, kl=35.3847, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0671 (Recon: 0.0671, KL: 33.4786, Current Beta: 0.0000) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0480\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0325, recon=0.0325, kl=35.8572, beta=0.0000\n",
      "Batch 40, loss=0.0488, recon=0.0488, kl=39.5497, beta=0.0000\n",
      "Batch 60, loss=0.0334, recon=0.0334, kl=40.4655, beta=0.0000\n",
      "Batch 80, loss=0.0410, recon=0.0410, kl=37.8270, beta=0.0000\n",
      "Batch 100, loss=0.0387, recon=0.0387, kl=36.6953, beta=0.0000\n",
      "Batch 120, loss=0.0340, recon=0.0340, kl=36.4851, beta=0.0000\n",
      "Batch 140, loss=0.0535, recon=0.0535, kl=29.8851, beta=0.0000\n",
      "Batch 160, loss=0.0611, recon=0.0611, kl=24.7746, beta=0.0000\n",
      "Batch 180, loss=0.0326, recon=0.0326, kl=38.1046, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0562 (Recon: 0.0562, KL: 35.3510, Current Beta: 0.0000) | Avg Valid Loss: 0.0463 | Avg Valid recon Loss: 0.0463\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0627, recon=0.0627, kl=39.7366, beta=0.0000\n",
      "Batch 40, loss=0.0450, recon=0.0450, kl=30.0854, beta=0.0000\n",
      "Batch 60, loss=0.0308, recon=0.0308, kl=23.3812, beta=0.0000\n",
      "Batch 80, loss=0.0544, recon=0.0544, kl=35.1171, beta=0.0000\n",
      "Batch 100, loss=0.0451, recon=0.0451, kl=36.0927, beta=0.0000\n",
      "Batch 120, loss=0.0333, recon=0.0333, kl=36.3860, beta=0.0000\n",
      "Batch 140, loss=0.0501, recon=0.0501, kl=36.5675, beta=0.0000\n",
      "Batch 160, loss=0.0226, recon=0.0226, kl=36.8083, beta=0.0000\n",
      "Batch 180, loss=0.1436, recon=0.1436, kl=40.0159, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0500 (Recon: 0.0500, KL: 34.8867, Current Beta: 0.0000) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0274, recon=0.0274, kl=39.7792, beta=0.0000\n",
      "Batch 40, loss=0.1477, recon=0.1477, kl=42.0228, beta=0.0000\n",
      "Batch 60, loss=0.0245, recon=0.0245, kl=41.0410, beta=0.0000\n",
      "Batch 80, loss=0.1218, recon=0.1218, kl=36.7320, beta=0.0000\n",
      "Batch 100, loss=0.0393, recon=0.0393, kl=40.0437, beta=0.0000\n",
      "Batch 120, loss=0.0866, recon=0.0866, kl=40.3205, beta=0.0000\n",
      "Batch 140, loss=0.0451, recon=0.0451, kl=41.4947, beta=0.0000\n",
      "Batch 160, loss=0.0371, recon=0.0371, kl=42.2510, beta=0.0000\n",
      "Batch 180, loss=0.0390, recon=0.0390, kl=37.1958, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0472, KL: 40.1444, Current Beta: 0.0000) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0223, recon=0.0223, kl=36.4682, beta=0.0000\n",
      "Batch 40, loss=0.1285, recon=0.1285, kl=40.2501, beta=0.0000\n",
      "Batch 60, loss=0.0873, recon=0.0873, kl=42.5263, beta=0.0000\n",
      "Batch 80, loss=0.0393, recon=0.0393, kl=42.9133, beta=0.0000\n",
      "Batch 100, loss=0.0310, recon=0.0310, kl=38.8497, beta=0.0000\n",
      "Batch 120, loss=0.0247, recon=0.0247, kl=39.0880, beta=0.0000\n",
      "Batch 140, loss=0.1478, recon=0.1478, kl=39.5456, beta=0.0000\n",
      "Batch 160, loss=0.0314, recon=0.0314, kl=38.7467, beta=0.0000\n",
      "Batch 180, loss=0.0166, recon=0.0166, kl=39.6520, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0457, KL: 39.6487, Current Beta: 0.0000) | Avg Valid Loss: 0.0336 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0476, recon=0.0476, kl=30.1006, beta=0.0000\n",
      "Batch 40, loss=0.0237, recon=0.0237, kl=34.1864, beta=0.0000\n",
      "Batch 60, loss=0.0282, recon=0.0282, kl=38.9554, beta=0.0000\n",
      "Batch 80, loss=0.1239, recon=0.1239, kl=34.9838, beta=0.0000\n",
      "Batch 100, loss=0.0160, recon=0.0160, kl=29.0056, beta=0.0000\n",
      "Batch 120, loss=0.1293, recon=0.1293, kl=32.8729, beta=0.0000\n",
      "Batch 140, loss=0.0402, recon=0.0402, kl=37.4234, beta=0.0000\n",
      "Batch 160, loss=0.0417, recon=0.0417, kl=40.2790, beta=0.0000\n",
      "Batch 180, loss=0.0378, recon=0.0378, kl=41.6952, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 35.1792, Current Beta: 0.0000) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0342, recon=0.0342, kl=39.6573, beta=0.0000\n",
      "Batch 40, loss=0.0896, recon=0.0896, kl=39.3115, beta=0.0000\n",
      "Batch 60, loss=0.0275, recon=0.0275, kl=38.7884, beta=0.0000\n",
      "Batch 80, loss=0.0210, recon=0.0210, kl=35.2216, beta=0.0000\n",
      "Batch 100, loss=0.0407, recon=0.0407, kl=32.5067, beta=0.0000\n",
      "Batch 120, loss=0.0730, recon=0.0730, kl=30.4285, beta=0.0000\n",
      "Batch 140, loss=0.0904, recon=0.0904, kl=26.3162, beta=0.0000\n",
      "Batch 160, loss=0.0618, recon=0.0618, kl=37.1639, beta=0.0000\n",
      "Batch 180, loss=0.0362, recon=0.0362, kl=40.6148, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0535 (Recon: 0.0535, KL: 35.5191, Current Beta: 0.0000) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0499\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0510, recon=0.0509, kl=39.1280, beta=0.0000\n",
      "Batch 40, loss=0.0320, recon=0.0320, kl=34.0600, beta=0.0000\n",
      "Batch 60, loss=0.0628, recon=0.0628, kl=36.3735, beta=0.0000\n",
      "Batch 80, loss=0.0296, recon=0.0296, kl=32.9618, beta=0.0000\n",
      "Batch 100, loss=0.0830, recon=0.0830, kl=34.8869, beta=0.0000\n",
      "Batch 120, loss=0.0515, recon=0.0515, kl=26.1208, beta=0.0000\n",
      "Batch 140, loss=0.0435, recon=0.0435, kl=28.9550, beta=0.0000\n",
      "Batch 160, loss=0.0520, recon=0.0520, kl=33.4999, beta=0.0000\n",
      "Batch 180, loss=0.0304, recon=0.0304, kl=33.6543, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0571 (Recon: 0.0571, KL: 33.4941, Current Beta: 0.0000) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0233, recon=0.0233, kl=35.1876, beta=0.0000\n",
      "Batch 40, loss=0.0343, recon=0.0342, kl=33.3457, beta=0.0000\n",
      "Batch 60, loss=0.0339, recon=0.0339, kl=35.4089, beta=0.0000\n",
      "Batch 80, loss=0.0281, recon=0.0281, kl=35.2449, beta=0.0000\n",
      "Batch 100, loss=0.0242, recon=0.0242, kl=31.5919, beta=0.0000\n",
      "Batch 120, loss=0.0248, recon=0.0248, kl=27.2642, beta=0.0000\n",
      "Batch 140, loss=0.0200, recon=0.0199, kl=27.3916, beta=0.0000\n",
      "Batch 160, loss=0.0211, recon=0.0210, kl=31.3874, beta=0.0000\n",
      "Batch 180, loss=0.0464, recon=0.0464, kl=32.1418, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0383 (Recon: 0.0383, KL: 32.2887, Current Beta: 0.0000) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0840, recon=0.0839, kl=29.8546, beta=0.0000\n",
      "Batch 40, loss=0.0223, recon=0.0222, kl=25.7537, beta=0.0000\n",
      "Batch 60, loss=0.0297, recon=0.0296, kl=23.1021, beta=0.0000\n",
      "Batch 80, loss=0.0330, recon=0.0329, kl=26.0979, beta=0.0000\n",
      "Batch 100, loss=0.0260, recon=0.0259, kl=24.7945, beta=0.0000\n",
      "Batch 120, loss=0.0263, recon=0.0262, kl=20.6826, beta=0.0000\n",
      "Batch 140, loss=0.0385, recon=0.0384, kl=22.4004, beta=0.0000\n",
      "Batch 160, loss=0.0599, recon=0.0598, kl=22.8928, beta=0.0000\n",
      "Batch 180, loss=0.0203, recon=0.0202, kl=23.4956, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0364 (Recon: 0.0363, KL: 24.7390, Current Beta: 0.0000) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0331\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0618, recon=0.0617, kl=14.8698, beta=0.0000\n",
      "Batch 40, loss=0.0296, recon=0.0294, kl=25.5278, beta=0.0000\n",
      "Batch 60, loss=0.0299, recon=0.0297, kl=22.0004, beta=0.0000\n",
      "Batch 80, loss=0.0273, recon=0.0271, kl=19.2292, beta=0.0000\n",
      "Batch 100, loss=0.0527, recon=0.0525, kl=18.1609, beta=0.0000\n",
      "Batch 120, loss=0.0604, recon=0.0602, kl=16.2928, beta=0.0000\n",
      "Batch 140, loss=0.1087, recon=0.1086, kl=20.0131, beta=0.0000\n",
      "Batch 160, loss=0.0328, recon=0.0326, kl=23.4689, beta=0.0000\n",
      "Batch 180, loss=0.0618, recon=0.0617, kl=19.3971, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0461, KL: 20.1965, Current Beta: 0.0000) | Avg Valid Loss: 0.0406 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.5405, recon=0.5402, kl=15.3473, beta=0.0000\n",
      "Batch 40, loss=0.0370, recon=0.0367, kl=13.7590, beta=0.0000\n",
      "Batch 60, loss=0.0225, recon=0.0223, kl=13.2532, beta=0.0000\n",
      "Batch 80, loss=0.0388, recon=0.0386, kl=12.5227, beta=0.0000\n",
      "Batch 100, loss=0.0549, recon=0.0547, kl=12.2638, beta=0.0000\n",
      "Batch 120, loss=0.0533, recon=0.0531, kl=10.2967, beta=0.0000\n",
      "Batch 140, loss=0.0242, recon=0.0240, kl=9.9786, beta=0.0000\n",
      "Batch 160, loss=0.0256, recon=0.0254, kl=9.9688, beta=0.0000\n",
      "Batch 180, loss=0.0240, recon=0.0239, kl=9.6703, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0398, KL: 12.3506, Current Beta: 0.0000) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0315\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0300, recon=0.0297, kl=8.3303, beta=0.0000\n",
      "Batch 40, loss=0.0200, recon=0.0198, kl=6.9206, beta=0.0000\n",
      "Batch 60, loss=0.0214, recon=0.0212, kl=4.5501, beta=0.0000\n",
      "Batch 80, loss=0.0296, recon=0.0293, kl=5.8832, beta=0.0000\n",
      "Batch 100, loss=0.0248, recon=0.0246, kl=5.7258, beta=0.0000\n",
      "Batch 120, loss=0.0419, recon=0.0417, kl=3.9356, beta=0.0000\n",
      "Batch 140, loss=0.0431, recon=0.0430, kl=4.9474, beta=0.0000\n",
      "Batch 160, loss=0.1318, recon=0.1316, kl=4.8338, beta=0.0000\n",
      "Batch 180, loss=0.0326, recon=0.0324, kl=4.4719, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0381 (Recon: 0.0378, KL: 5.6452, Current Beta: 0.0000) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1131, recon=0.1130, kl=2.4376, beta=0.0001\n",
      "Batch 40, loss=0.0372, recon=0.0370, kl=2.4264, beta=0.0001\n",
      "Batch 60, loss=0.0324, recon=0.0323, kl=1.4054, beta=0.0001\n",
      "Batch 80, loss=0.0436, recon=0.0433, kl=4.0712, beta=0.0001\n",
      "Batch 100, loss=0.0250, recon=0.0247, kl=4.2489, beta=0.0001\n",
      "Batch 120, loss=0.0293, recon=0.0290, kl=4.0398, beta=0.0001\n",
      "Batch 140, loss=0.0332, recon=0.0330, kl=3.5647, beta=0.0001\n",
      "Batch 160, loss=0.0237, recon=0.0236, kl=1.5921, beta=0.0001\n",
      "Batch 180, loss=0.0257, recon=0.0257, kl=1.0895, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0414, KL: 3.0342, Current Beta: 0.0001) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0499, recon=0.0498, kl=1.0263, beta=0.0001\n",
      "Batch 40, loss=0.0247, recon=0.0246, kl=1.1698, beta=0.0001\n",
      "Batch 60, loss=0.0229, recon=0.0229, kl=0.6141, beta=0.0001\n",
      "Batch 80, loss=0.0239, recon=0.0239, kl=0.4548, beta=0.0001\n",
      "Batch 100, loss=0.0395, recon=0.0395, kl=0.3323, beta=0.0001\n",
      "Batch 120, loss=0.1687, recon=0.1685, kl=2.1654, beta=0.0001\n",
      "Batch 140, loss=0.0907, recon=0.0902, kl=5.0161, beta=0.0001\n",
      "Batch 160, loss=0.0397, recon=0.0390, kl=6.8780, beta=0.0001\n",
      "Batch 180, loss=0.0556, recon=0.0550, kl=5.8842, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0618 (Recon: 0.0615, KL: 2.4213, Current Beta: 0.0001) | Avg Valid Loss: 0.0594 | Avg Valid recon Loss: 0.0588\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0445, recon=0.0440, kl=5.6246, beta=0.0001\n",
      "Batch 40, loss=0.0258, recon=0.0253, kl=5.2094, beta=0.0001\n",
      "Batch 60, loss=0.0414, recon=0.0409, kl=4.7880, beta=0.0001\n",
      "Batch 80, loss=0.0297, recon=0.0293, kl=4.4797, beta=0.0001\n",
      "Batch 100, loss=0.0464, recon=0.0460, kl=4.1008, beta=0.0001\n",
      "Batch 120, loss=0.0500, recon=0.0496, kl=3.9551, beta=0.0001\n",
      "Batch 140, loss=0.0475, recon=0.0471, kl=3.7091, beta=0.0001\n",
      "Batch 160, loss=0.0513, recon=0.0510, kl=3.3336, beta=0.0001\n",
      "Batch 180, loss=0.0358, recon=0.0355, kl=3.1612, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0551 (Recon: 0.0547, KL: 4.4063, Current Beta: 0.0001) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0496\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0524, recon=0.0521, kl=3.0498, beta=0.0001\n",
      "Batch 40, loss=0.0375, recon=0.0372, kl=3.0305, beta=0.0001\n",
      "Batch 60, loss=0.1775, recon=0.1772, kl=2.8766, beta=0.0001\n",
      "Batch 80, loss=0.0207, recon=0.0204, kl=2.6220, beta=0.0001\n",
      "Batch 100, loss=0.0924, recon=0.0922, kl=2.3841, beta=0.0001\n",
      "Batch 120, loss=0.0637, recon=0.0635, kl=2.2675, beta=0.0001\n",
      "Batch 140, loss=0.0493, recon=0.0491, kl=2.2979, beta=0.0001\n",
      "Batch 160, loss=0.0278, recon=0.0275, kl=2.3052, beta=0.0001\n",
      "Batch 180, loss=0.0316, recon=0.0314, kl=2.3172, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0521, KL: 2.6148, Current Beta: 0.0001) | Avg Valid Loss: 0.0427 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0393, recon=0.0391, kl=2.2694, beta=0.0001\n",
      "Batch 40, loss=0.0429, recon=0.0427, kl=2.1037, beta=0.0001\n",
      "Batch 60, loss=0.0324, recon=0.0322, kl=2.0007, beta=0.0001\n",
      "Batch 80, loss=0.0440, recon=0.0438, kl=1.8883, beta=0.0001\n",
      "Batch 100, loss=0.0255, recon=0.0254, kl=1.7443, beta=0.0001\n",
      "Batch 120, loss=0.0287, recon=0.0285, kl=1.5392, beta=0.0001\n",
      "Batch 140, loss=0.0252, recon=0.0250, kl=1.2911, beta=0.0001\n",
      "Batch 160, loss=0.0219, recon=0.0218, kl=1.0643, beta=0.0001\n",
      "Batch 180, loss=0.0524, recon=0.0523, kl=0.9544, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0435, KL: 1.7279, Current Beta: 0.0001) | Avg Valid Loss: 0.0654 | Avg Valid recon Loss: 0.0653\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0726, recon=0.0725, kl=1.5480, beta=0.0001\n",
      "Batch 40, loss=0.0500, recon=0.0498, kl=2.3871, beta=0.0001\n",
      "Batch 60, loss=0.0214, recon=0.0211, kl=2.8571, beta=0.0001\n",
      "Batch 80, loss=0.0276, recon=0.0274, kl=2.7573, beta=0.0001\n",
      "Batch 100, loss=0.0272, recon=0.0269, kl=2.5236, beta=0.0001\n",
      "Batch 120, loss=0.0283, recon=0.0281, kl=2.3373, beta=0.0001\n",
      "Batch 140, loss=0.0319, recon=0.0317, kl=2.1115, beta=0.0001\n",
      "Batch 160, loss=0.0464, recon=0.0462, kl=1.9321, beta=0.0001\n",
      "Batch 180, loss=0.0305, recon=0.0303, kl=1.9224, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0474 (Recon: 0.0471, KL: 2.2190, Current Beta: 0.0001) | Avg Valid Loss: 0.0386 | Avg Valid recon Loss: 0.0384\n",
      "\n",
      "[VRAE Run 27/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5204, recon=0.5204, kl=2.2948, beta=0.0000\n",
      "Batch 40, loss=0.3444, recon=0.3444, kl=19.9781, beta=0.0000\n",
      "Batch 60, loss=0.1565, recon=0.1565, kl=36.5611, beta=0.0000\n",
      "Batch 80, loss=0.1810, recon=0.1810, kl=43.8411, beta=0.0000\n",
      "Batch 100, loss=0.1995, recon=0.1995, kl=52.2028, beta=0.0000\n",
      "Batch 120, loss=0.3398, recon=0.3398, kl=58.9672, beta=0.0000\n",
      "Batch 140, loss=0.1502, recon=0.1502, kl=66.4625, beta=0.0000\n",
      "Batch 160, loss=0.1043, recon=0.1043, kl=70.5957, beta=0.0000\n",
      "Batch 180, loss=0.2026, recon=0.2026, kl=73.0769, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2910 (Recon: 0.2910, KL: 43.5779, Current Beta: 0.0000) | Avg Valid Loss: 0.1198 | Avg Valid recon Loss: 0.1198\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2277, recon=0.2277, kl=73.9319, beta=0.0000\n",
      "Batch 40, loss=0.6323, recon=0.6323, kl=74.2977, beta=0.0000\n",
      "Batch 60, loss=0.0718, recon=0.0718, kl=75.6056, beta=0.0000\n",
      "Batch 80, loss=0.1029, recon=0.1029, kl=76.2001, beta=0.0000\n",
      "Batch 100, loss=0.0946, recon=0.0946, kl=78.1887, beta=0.0000\n",
      "Batch 120, loss=0.0880, recon=0.0880, kl=78.9633, beta=0.0000\n",
      "Batch 140, loss=0.1097, recon=0.1097, kl=79.5449, beta=0.0000\n",
      "Batch 160, loss=0.0518, recon=0.0518, kl=81.4033, beta=0.0000\n",
      "Batch 180, loss=0.0777, recon=0.0777, kl=84.1518, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1239 (Recon: 0.1239, KL: 77.3331, Current Beta: 0.0000) | Avg Valid Loss: 0.0889 | Avg Valid recon Loss: 0.0889\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0858, recon=0.0858, kl=84.5479, beta=0.0000\n",
      "Batch 40, loss=0.1041, recon=0.1041, kl=85.3997, beta=0.0000\n",
      "Batch 60, loss=0.0625, recon=0.0625, kl=87.2681, beta=0.0000\n",
      "Batch 80, loss=0.1033, recon=0.1033, kl=91.1359, beta=0.0000\n",
      "Batch 100, loss=0.0557, recon=0.0557, kl=91.8540, beta=0.0000\n",
      "Batch 120, loss=0.0748, recon=0.0748, kl=94.0699, beta=0.0000\n",
      "Batch 140, loss=0.0809, recon=0.0809, kl=93.8430, beta=0.0000\n",
      "Batch 160, loss=0.0494, recon=0.0494, kl=96.0376, beta=0.0000\n",
      "Batch 180, loss=0.0850, recon=0.0850, kl=97.7952, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0948 (Recon: 0.0948, KL: 90.5961, Current Beta: 0.0000) | Avg Valid Loss: 0.0753 | Avg Valid recon Loss: 0.0753\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0527, recon=0.0527, kl=98.9041, beta=0.0000\n",
      "Batch 40, loss=0.0637, recon=0.0637, kl=99.6567, beta=0.0000\n",
      "Batch 60, loss=0.0485, recon=0.0485, kl=99.5668, beta=0.0000\n",
      "Batch 80, loss=0.0625, recon=0.0625, kl=99.5306, beta=0.0000\n",
      "Batch 100, loss=0.0433, recon=0.0433, kl=101.3188, beta=0.0000\n",
      "Batch 120, loss=0.0519, recon=0.0519, kl=102.3774, beta=0.0000\n",
      "Batch 140, loss=0.0615, recon=0.0615, kl=103.9934, beta=0.0000\n",
      "Batch 160, loss=0.0971, recon=0.0971, kl=103.2701, beta=0.0000\n",
      "Batch 180, loss=0.0589, recon=0.0589, kl=101.7708, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0799 (Recon: 0.0799, KL: 101.0616, Current Beta: 0.0000) | Avg Valid Loss: 0.0659 | Avg Valid recon Loss: 0.0659\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0963, recon=0.0963, kl=102.7526, beta=0.0000\n",
      "Batch 40, loss=0.0523, recon=0.0523, kl=104.7029, beta=0.0000\n",
      "Batch 60, loss=0.0498, recon=0.0498, kl=104.8277, beta=0.0000\n",
      "Batch 80, loss=0.0524, recon=0.0524, kl=105.1732, beta=0.0000\n",
      "Batch 100, loss=0.0546, recon=0.0546, kl=105.1454, beta=0.0000\n",
      "Batch 120, loss=0.1049, recon=0.1049, kl=105.2393, beta=0.0000\n",
      "Batch 140, loss=0.0486, recon=0.0486, kl=106.0671, beta=0.0000\n",
      "Batch 160, loss=0.0482, recon=0.0482, kl=107.6853, beta=0.0000\n",
      "Batch 180, loss=0.0614, recon=0.0614, kl=108.2482, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0711 (Recon: 0.0711, KL: 105.2442, Current Beta: 0.0000) | Avg Valid Loss: 0.0611 | Avg Valid recon Loss: 0.0611\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0509, recon=0.0509, kl=107.6539, beta=0.0000\n",
      "Batch 40, loss=0.0404, recon=0.0404, kl=105.8735, beta=0.0000\n",
      "Batch 60, loss=0.0366, recon=0.0366, kl=105.4864, beta=0.0000\n",
      "Batch 80, loss=0.0344, recon=0.0344, kl=104.4831, beta=0.0000\n",
      "Batch 100, loss=0.0500, recon=0.0500, kl=104.5778, beta=0.0000\n",
      "Batch 120, loss=0.0477, recon=0.0477, kl=103.3044, beta=0.0000\n",
      "Batch 140, loss=0.0993, recon=0.0993, kl=104.5551, beta=0.0000\n",
      "Batch 160, loss=0.0695, recon=0.0695, kl=105.4293, beta=0.0000\n",
      "Batch 180, loss=0.0634, recon=0.0634, kl=102.0910, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0648 (Recon: 0.0648, KL: 105.2485, Current Beta: 0.0000) | Avg Valid Loss: 0.0554 | Avg Valid recon Loss: 0.0554\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0418, recon=0.0418, kl=105.3602, beta=0.0000\n",
      "Batch 40, loss=0.0493, recon=0.0493, kl=103.3488, beta=0.0000\n",
      "Batch 60, loss=0.0460, recon=0.0460, kl=100.3274, beta=0.0000\n",
      "Batch 80, loss=0.0418, recon=0.0418, kl=99.9292, beta=0.0000\n",
      "Batch 100, loss=0.0402, recon=0.0402, kl=100.5419, beta=0.0000\n",
      "Batch 120, loss=0.0491, recon=0.0491, kl=99.6312, beta=0.0000\n",
      "Batch 140, loss=0.0553, recon=0.0553, kl=96.5696, beta=0.0000\n",
      "Batch 160, loss=0.0498, recon=0.0498, kl=94.7145, beta=0.0000\n",
      "Batch 180, loss=0.0468, recon=0.0468, kl=95.2252, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0609 (Recon: 0.0609, KL: 100.5231, Current Beta: 0.0000) | Avg Valid Loss: 0.0540 | Avg Valid recon Loss: 0.0540\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0594, recon=0.0593, kl=92.8242, beta=0.0000\n",
      "Batch 40, loss=0.2513, recon=0.2513, kl=89.9490, beta=0.0000\n",
      "Batch 60, loss=0.0500, recon=0.0499, kl=86.9015, beta=0.0000\n",
      "Batch 80, loss=0.0469, recon=0.0469, kl=84.2947, beta=0.0000\n",
      "Batch 100, loss=0.0417, recon=0.0416, kl=81.7720, beta=0.0000\n",
      "Batch 120, loss=0.0247, recon=0.0247, kl=81.3722, beta=0.0000\n",
      "Batch 140, loss=0.0311, recon=0.0311, kl=78.8642, beta=0.0000\n",
      "Batch 160, loss=0.0353, recon=0.0353, kl=75.2737, beta=0.0000\n",
      "Batch 180, loss=0.0618, recon=0.0618, kl=75.8388, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0576 (Recon: 0.0576, KL: 84.0394, Current Beta: 0.0000) | Avg Valid Loss: 0.0494 | Avg Valid recon Loss: 0.0494\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0434, recon=0.0434, kl=70.6038, beta=0.0000\n",
      "Batch 40, loss=0.0337, recon=0.0337, kl=64.0821, beta=0.0000\n",
      "Batch 60, loss=0.0442, recon=0.0442, kl=58.1746, beta=0.0000\n",
      "Batch 80, loss=0.0288, recon=0.0288, kl=56.0639, beta=0.0000\n",
      "Batch 100, loss=0.2953, recon=0.2953, kl=54.2788, beta=0.0000\n",
      "Batch 120, loss=0.0419, recon=0.0418, kl=54.1001, beta=0.0000\n",
      "Batch 140, loss=0.0472, recon=0.0471, kl=53.1183, beta=0.0000\n",
      "Batch 160, loss=0.0548, recon=0.0548, kl=53.5585, beta=0.0000\n",
      "Batch 180, loss=0.0517, recon=0.0517, kl=53.1351, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0549 (Recon: 0.0549, KL: 58.5638, Current Beta: 0.0000) | Avg Valid Loss: 0.0473 | Avg Valid recon Loss: 0.0473\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0359, recon=0.0358, kl=44.7306, beta=0.0000\n",
      "Batch 40, loss=0.0404, recon=0.0403, kl=36.8420, beta=0.0000\n",
      "Batch 60, loss=0.0376, recon=0.0376, kl=33.6643, beta=0.0000\n",
      "Batch 80, loss=0.0434, recon=0.0434, kl=33.8534, beta=0.0000\n",
      "Batch 100, loss=0.0567, recon=0.0567, kl=34.2549, beta=0.0000\n",
      "Batch 120, loss=0.0372, recon=0.0372, kl=33.3153, beta=0.0000\n",
      "Batch 140, loss=0.0594, recon=0.0594, kl=33.9142, beta=0.0000\n",
      "Batch 160, loss=0.0340, recon=0.0339, kl=31.5242, beta=0.0000\n",
      "Batch 180, loss=0.0481, recon=0.0480, kl=30.5864, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0531 (Recon: 0.0530, KL: 35.8005, Current Beta: 0.0000) | Avg Valid Loss: 0.0461 | Avg Valid recon Loss: 0.0461\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0451, recon=0.0450, kl=21.1037, beta=0.0000\n",
      "Batch 40, loss=0.0368, recon=0.0368, kl=17.4079, beta=0.0000\n",
      "Batch 60, loss=0.0848, recon=0.0848, kl=19.6804, beta=0.0000\n",
      "Batch 80, loss=0.0333, recon=0.0333, kl=19.9886, beta=0.0000\n",
      "Batch 100, loss=0.0359, recon=0.0358, kl=19.6884, beta=0.0000\n",
      "Batch 120, loss=0.0435, recon=0.0434, kl=17.5504, beta=0.0000\n",
      "Batch 140, loss=0.0442, recon=0.0442, kl=15.8754, beta=0.0000\n",
      "Batch 160, loss=0.0358, recon=0.0358, kl=15.9504, beta=0.0000\n",
      "Batch 180, loss=0.0295, recon=0.0295, kl=15.8818, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0512 (Recon: 0.0511, KL: 18.8605, Current Beta: 0.0000) | Avg Valid Loss: 0.0446 | Avg Valid recon Loss: 0.0446\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0525, recon=0.0525, kl=8.2119, beta=0.0000\n",
      "Batch 40, loss=0.0457, recon=0.0456, kl=8.8718, beta=0.0000\n",
      "Batch 60, loss=0.0384, recon=0.0383, kl=8.4256, beta=0.0000\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=7.7962, beta=0.0000\n",
      "Batch 100, loss=0.0318, recon=0.0317, kl=7.3649, beta=0.0000\n",
      "Batch 120, loss=0.0535, recon=0.0535, kl=7.7363, beta=0.0000\n",
      "Batch 140, loss=0.2187, recon=0.2186, kl=7.0283, beta=0.0000\n",
      "Batch 160, loss=0.0317, recon=0.0316, kl=7.8836, beta=0.0000\n",
      "Batch 180, loss=0.0326, recon=0.0325, kl=6.8517, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0498 (Recon: 0.0497, KL: 8.3269, Current Beta: 0.0000) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0359, recon=0.0358, kl=3.3955, beta=0.0000\n",
      "Batch 40, loss=0.0323, recon=0.0322, kl=4.8761, beta=0.0000\n",
      "Batch 60, loss=0.0451, recon=0.0450, kl=4.5336, beta=0.0000\n",
      "Batch 80, loss=0.0276, recon=0.0275, kl=3.4312, beta=0.0000\n",
      "Batch 100, loss=0.0417, recon=0.0416, kl=3.4123, beta=0.0000\n",
      "Batch 120, loss=0.0486, recon=0.0485, kl=3.0551, beta=0.0000\n",
      "Batch 140, loss=0.0378, recon=0.0378, kl=3.2272, beta=0.0000\n",
      "Batch 160, loss=0.0281, recon=0.0281, kl=2.2082, beta=0.0000\n",
      "Batch 180, loss=0.0230, recon=0.0229, kl=3.0039, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0484 (Recon: 0.0483, KL: 3.6552, Current Beta: 0.0000) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0329, recon=0.0328, kl=1.3590, beta=0.0000\n",
      "Batch 40, loss=0.0324, recon=0.0323, kl=1.5808, beta=0.0000\n",
      "Batch 60, loss=0.0521, recon=0.0520, kl=1.7873, beta=0.0000\n",
      "Batch 80, loss=0.0245, recon=0.0244, kl=1.6260, beta=0.0000\n",
      "Batch 100, loss=0.0321, recon=0.0321, kl=1.5265, beta=0.0000\n",
      "Batch 120, loss=0.0258, recon=0.0258, kl=1.1578, beta=0.0000\n",
      "Batch 140, loss=0.0258, recon=0.0257, kl=1.6644, beta=0.0000\n",
      "Batch 160, loss=0.1492, recon=0.1492, kl=1.5731, beta=0.0000\n",
      "Batch 180, loss=0.0285, recon=0.0284, kl=2.0265, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0469, KL: 1.5788, Current Beta: 0.0000) | Avg Valid Loss: 0.0405 | Avg Valid recon Loss: 0.0404\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0279, recon=0.0279, kl=0.6235, beta=0.0001\n",
      "Batch 40, loss=0.0256, recon=0.0255, kl=0.8602, beta=0.0001\n",
      "Batch 60, loss=0.0478, recon=0.0477, kl=0.8310, beta=0.0001\n",
      "Batch 80, loss=0.0716, recon=0.0715, kl=1.2350, beta=0.0001\n",
      "Batch 100, loss=0.0617, recon=0.0617, kl=0.5285, beta=0.0001\n",
      "Batch 120, loss=0.0338, recon=0.0338, kl=0.3721, beta=0.0001\n",
      "Batch 140, loss=0.0332, recon=0.0331, kl=0.4618, beta=0.0001\n",
      "Batch 160, loss=0.0452, recon=0.0451, kl=0.6278, beta=0.0001\n",
      "Batch 180, loss=0.0289, recon=0.0289, kl=0.2436, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0457, KL: 0.6894, Current Beta: 0.0001) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0394\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0246, recon=0.0245, kl=0.1691, beta=0.0001\n",
      "Batch 40, loss=0.0295, recon=0.0295, kl=0.2370, beta=0.0001\n",
      "Batch 60, loss=0.0325, recon=0.0325, kl=0.1530, beta=0.0001\n",
      "Batch 80, loss=0.0624, recon=0.0623, kl=0.1562, beta=0.0001\n",
      "Batch 100, loss=0.0346, recon=0.0346, kl=0.1063, beta=0.0001\n",
      "Batch 120, loss=0.0491, recon=0.0491, kl=0.1157, beta=0.0001\n",
      "Batch 140, loss=0.0701, recon=0.0701, kl=0.0992, beta=0.0001\n",
      "Batch 160, loss=0.1414, recon=0.1414, kl=0.0813, beta=0.0001\n",
      "Batch 180, loss=0.0249, recon=0.0249, kl=0.1111, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0448 (Recon: 0.0447, KL: 0.1808, Current Beta: 0.0001) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0463, recon=0.0463, kl=0.0988, beta=0.0001\n",
      "Batch 40, loss=0.0404, recon=0.0404, kl=0.0568, beta=0.0001\n",
      "Batch 60, loss=0.0420, recon=0.0420, kl=0.1213, beta=0.0001\n",
      "Batch 80, loss=0.0490, recon=0.0489, kl=0.1064, beta=0.0001\n",
      "Batch 100, loss=0.0249, recon=0.0249, kl=0.0722, beta=0.0001\n",
      "Batch 120, loss=0.0525, recon=0.0525, kl=0.0500, beta=0.0001\n",
      "Batch 140, loss=0.0423, recon=0.0423, kl=0.2339, beta=0.0001\n",
      "Batch 160, loss=0.0640, recon=0.0640, kl=0.1172, beta=0.0001\n",
      "Batch 180, loss=0.0268, recon=0.0267, kl=0.0526, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0437, KL: 0.1023, Current Beta: 0.0001) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0315, recon=0.0315, kl=0.0564, beta=0.0001\n",
      "Batch 40, loss=0.0286, recon=0.0286, kl=0.0155, beta=0.0001\n",
      "Batch 60, loss=0.0315, recon=0.0315, kl=0.0341, beta=0.0001\n",
      "Batch 80, loss=0.0306, recon=0.0306, kl=0.0715, beta=0.0001\n",
      "Batch 100, loss=0.0496, recon=0.0496, kl=0.0372, beta=0.0001\n",
      "Batch 120, loss=0.0278, recon=0.0278, kl=0.0335, beta=0.0001\n",
      "Batch 140, loss=0.0223, recon=0.0223, kl=0.0229, beta=0.0001\n",
      "Batch 160, loss=0.0319, recon=0.0319, kl=0.0628, beta=0.0001\n",
      "Batch 180, loss=0.0450, recon=0.0450, kl=0.0646, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0432, KL: 0.0598, Current Beta: 0.0001) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0250, recon=0.0250, kl=0.0627, beta=0.0001\n",
      "Batch 40, loss=0.0382, recon=0.0382, kl=0.0481, beta=0.0001\n",
      "Batch 60, loss=0.0356, recon=0.0356, kl=0.0430, beta=0.0001\n",
      "Batch 80, loss=0.0257, recon=0.0257, kl=0.0339, beta=0.0001\n",
      "Batch 100, loss=0.0226, recon=0.0226, kl=0.0235, beta=0.0001\n",
      "Batch 120, loss=0.0371, recon=0.0371, kl=0.0490, beta=0.0001\n",
      "Batch 140, loss=0.0387, recon=0.0387, kl=0.0143, beta=0.0001\n",
      "Batch 160, loss=0.0261, recon=0.0261, kl=0.0166, beta=0.0001\n",
      "Batch 180, loss=0.0348, recon=0.0348, kl=0.0282, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0424, KL: 0.0467, Current Beta: 0.0001) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0318, recon=0.0318, kl=0.0191, beta=0.0001\n",
      "Batch 40, loss=0.0287, recon=0.0287, kl=0.1918, beta=0.0001\n",
      "Batch 60, loss=0.0297, recon=0.0297, kl=0.0338, beta=0.0001\n",
      "Batch 80, loss=0.0386, recon=0.0386, kl=0.0134, beta=0.0001\n",
      "Batch 100, loss=0.0426, recon=0.0426, kl=0.0736, beta=0.0001\n",
      "Batch 120, loss=0.0275, recon=0.0275, kl=0.0087, beta=0.0001\n",
      "Batch 140, loss=0.0313, recon=0.0313, kl=0.0225, beta=0.0001\n",
      "Batch 160, loss=0.0370, recon=0.0370, kl=0.0352, beta=0.0001\n",
      "Batch 180, loss=0.0267, recon=0.0267, kl=0.0152, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0417, KL: 0.0390, Current Beta: 0.0001) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0370\n",
      "\n",
      "[VRAE Run 28/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1966, recon=0.1966, kl=30.8349, beta=0.0000\n",
      "Batch 40, loss=0.2594, recon=0.2594, kl=45.5322, beta=0.0000\n",
      "Batch 60, loss=0.1272, recon=0.1272, kl=54.6472, beta=0.0000\n",
      "Batch 80, loss=0.1100, recon=0.1100, kl=63.6048, beta=0.0000\n",
      "Batch 100, loss=0.0678, recon=0.0678, kl=64.0443, beta=0.0000\n",
      "Batch 120, loss=0.0820, recon=0.0820, kl=64.5417, beta=0.0000\n",
      "Batch 140, loss=0.0524, recon=0.0524, kl=54.3327, beta=0.0000\n",
      "Batch 160, loss=0.0617, recon=0.0617, kl=61.3458, beta=0.0000\n",
      "Batch 180, loss=0.0648, recon=0.0648, kl=69.5680, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1341 (Recon: 0.1341, KL: 53.0322, Current Beta: 0.0000) | Avg Valid Loss: 0.0601 | Avg Valid recon Loss: 0.0601\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0438, recon=0.0438, kl=56.3396, beta=0.0000\n",
      "Batch 40, loss=0.0677, recon=0.0677, kl=58.7846, beta=0.0000\n",
      "Batch 60, loss=0.0352, recon=0.0352, kl=66.1225, beta=0.0000\n",
      "Batch 80, loss=0.0589, recon=0.0589, kl=71.7211, beta=0.0000\n",
      "Batch 100, loss=0.0861, recon=0.0861, kl=68.4314, beta=0.0000\n",
      "Batch 120, loss=0.0512, recon=0.0512, kl=64.8586, beta=0.0000\n",
      "Batch 140, loss=0.0554, recon=0.0554, kl=70.1551, beta=0.0000\n",
      "Batch 160, loss=0.0560, recon=0.0560, kl=73.8121, beta=0.0000\n",
      "Batch 180, loss=0.0414, recon=0.0414, kl=72.1424, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0642 (Recon: 0.0642, KL: 66.6540, Current Beta: 0.0000) | Avg Valid Loss: 0.0506 | Avg Valid recon Loss: 0.0506\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0603, recon=0.0603, kl=69.6317, beta=0.0000\n",
      "Batch 40, loss=0.0673, recon=0.0673, kl=74.8467, beta=0.0000\n",
      "Batch 60, loss=0.0391, recon=0.0391, kl=79.3334, beta=0.0000\n",
      "Batch 80, loss=0.0291, recon=0.0291, kl=81.3364, beta=0.0000\n",
      "Batch 100, loss=0.0750, recon=0.0750, kl=66.9932, beta=0.0000\n",
      "Batch 120, loss=0.0283, recon=0.0283, kl=65.3086, beta=0.0000\n",
      "Batch 140, loss=0.0526, recon=0.0526, kl=66.6971, beta=0.0000\n",
      "Batch 160, loss=0.0698, recon=0.0698, kl=61.6706, beta=0.0000\n",
      "Batch 180, loss=0.0502, recon=0.0502, kl=62.2762, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0549 (Recon: 0.0549, KL: 70.2254, Current Beta: 0.0000) | Avg Valid Loss: 0.0509 | Avg Valid recon Loss: 0.0509\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0379, recon=0.0379, kl=68.0870, beta=0.0000\n",
      "Batch 40, loss=0.0377, recon=0.0377, kl=74.7697, beta=0.0000\n",
      "Batch 60, loss=0.0258, recon=0.0258, kl=77.1326, beta=0.0000\n",
      "Batch 80, loss=0.0317, recon=0.0317, kl=74.9145, beta=0.0000\n",
      "Batch 100, loss=0.0499, recon=0.0499, kl=74.5756, beta=0.0000\n",
      "Batch 120, loss=0.0502, recon=0.0502, kl=73.4395, beta=0.0000\n",
      "Batch 140, loss=0.0366, recon=0.0366, kl=62.7231, beta=0.0000\n",
      "Batch 160, loss=0.0401, recon=0.0401, kl=70.3238, beta=0.0000\n",
      "Batch 180, loss=0.0444, recon=0.0444, kl=79.8294, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0501 (Recon: 0.0501, KL: 71.7688, Current Beta: 0.0000) | Avg Valid Loss: 0.0676 | Avg Valid recon Loss: 0.0676\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0301, recon=0.0301, kl=74.9481, beta=0.0000\n",
      "Batch 40, loss=0.0555, recon=0.0555, kl=72.4878, beta=0.0000\n",
      "Batch 60, loss=0.0475, recon=0.0475, kl=70.3351, beta=0.0000\n",
      "Batch 80, loss=0.0370, recon=0.0370, kl=70.4779, beta=0.0000\n",
      "Batch 100, loss=0.0328, recon=0.0328, kl=72.4427, beta=0.0000\n",
      "Batch 120, loss=0.0276, recon=0.0276, kl=77.8147, beta=0.0000\n",
      "Batch 140, loss=0.0574, recon=0.0574, kl=80.8436, beta=0.0000\n",
      "Batch 160, loss=0.0274, recon=0.0274, kl=82.4457, beta=0.0000\n",
      "Batch 180, loss=0.0607, recon=0.0607, kl=73.8728, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0524, KL: 75.5244, Current Beta: 0.0000) | Avg Valid Loss: 0.0712 | Avg Valid recon Loss: 0.0712\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1658, recon=0.1658, kl=74.1026, beta=0.0000\n",
      "Batch 40, loss=0.0819, recon=0.0819, kl=80.6993, beta=0.0000\n",
      "Batch 60, loss=0.0523, recon=0.0523, kl=73.0377, beta=0.0000\n",
      "Batch 80, loss=0.0376, recon=0.0376, kl=76.9184, beta=0.0000\n",
      "Batch 100, loss=0.0408, recon=0.0408, kl=82.2093, beta=0.0000\n",
      "Batch 120, loss=0.0385, recon=0.0385, kl=79.8428, beta=0.0000\n",
      "Batch 140, loss=0.0252, recon=0.0252, kl=75.5150, beta=0.0000\n",
      "Batch 160, loss=0.0247, recon=0.0247, kl=74.5398, beta=0.0000\n",
      "Batch 180, loss=0.0273, recon=0.0273, kl=74.7945, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0558 (Recon: 0.0558, KL: 76.6012, Current Beta: 0.0000) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0207, recon=0.0207, kl=78.7730, beta=0.0000\n",
      "Batch 40, loss=0.0490, recon=0.0490, kl=83.0036, beta=0.0000\n",
      "Batch 60, loss=0.0328, recon=0.0328, kl=67.2311, beta=0.0000\n",
      "Batch 80, loss=0.1327, recon=0.1326, kl=66.3991, beta=0.0000\n",
      "Batch 100, loss=0.0351, recon=0.0351, kl=70.5114, beta=0.0000\n",
      "Batch 120, loss=0.0482, recon=0.0482, kl=74.6731, beta=0.0000\n",
      "Batch 140, loss=0.0675, recon=0.0675, kl=78.1164, beta=0.0000\n",
      "Batch 160, loss=0.1350, recon=0.1350, kl=81.6790, beta=0.0000\n",
      "Batch 180, loss=0.0311, recon=0.0311, kl=82.8442, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0483 (Recon: 0.0483, KL: 75.5819, Current Beta: 0.0000) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0382, recon=0.0382, kl=84.7474, beta=0.0000\n",
      "Batch 40, loss=0.0558, recon=0.0557, kl=76.1203, beta=0.0000\n",
      "Batch 60, loss=0.0276, recon=0.0276, kl=71.0930, beta=0.0000\n",
      "Batch 80, loss=0.0311, recon=0.0311, kl=72.8893, beta=0.0000\n",
      "Batch 100, loss=0.0522, recon=0.0522, kl=76.6152, beta=0.0000\n",
      "Batch 120, loss=0.0262, recon=0.0262, kl=78.5785, beta=0.0000\n",
      "Batch 140, loss=0.0366, recon=0.0365, kl=78.8266, beta=0.0000\n",
      "Batch 160, loss=0.0310, recon=0.0310, kl=72.7838, beta=0.0000\n",
      "Batch 180, loss=0.0258, recon=0.0258, kl=73.4494, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0494, KL: 76.3993, Current Beta: 0.0000) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0304, recon=0.0304, kl=70.6556, beta=0.0000\n",
      "Batch 40, loss=0.0240, recon=0.0240, kl=74.9864, beta=0.0000\n",
      "Batch 60, loss=0.0458, recon=0.0457, kl=76.1168, beta=0.0000\n",
      "Batch 80, loss=0.0279, recon=0.0279, kl=71.6206, beta=0.0000\n",
      "Batch 100, loss=0.0600, recon=0.0600, kl=73.5601, beta=0.0000\n",
      "Batch 120, loss=0.0315, recon=0.0315, kl=75.0597, beta=0.0000\n",
      "Batch 140, loss=0.0385, recon=0.0385, kl=75.8925, beta=0.0000\n",
      "Batch 160, loss=0.0355, recon=0.0354, kl=70.0489, beta=0.0000\n",
      "Batch 180, loss=0.1568, recon=0.1568, kl=67.4159, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0404, KL: 73.6037, Current Beta: 0.0000) | Avg Valid Loss: 0.0504 | Avg Valid recon Loss: 0.0504\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0261, recon=0.0260, kl=61.9445, beta=0.0000\n",
      "Batch 40, loss=0.0376, recon=0.0375, kl=59.7960, beta=0.0000\n",
      "Batch 60, loss=0.0289, recon=0.0288, kl=59.3303, beta=0.0000\n",
      "Batch 80, loss=0.0302, recon=0.0301, kl=63.0952, beta=0.0000\n",
      "Batch 100, loss=0.0388, recon=0.0388, kl=63.1669, beta=0.0000\n",
      "Batch 120, loss=0.0245, recon=0.0244, kl=64.0703, beta=0.0000\n",
      "Batch 140, loss=0.0262, recon=0.0261, kl=60.8983, beta=0.0000\n",
      "Batch 160, loss=0.0320, recon=0.0320, kl=59.8496, beta=0.0000\n",
      "Batch 180, loss=0.0353, recon=0.0352, kl=59.7902, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0408, KL: 61.5148, Current Beta: 0.0000) | Avg Valid Loss: 0.0316 | Avg Valid recon Loss: 0.0315\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0321, recon=0.0320, kl=49.0856, beta=0.0000\n",
      "Batch 40, loss=0.0263, recon=0.0261, kl=53.7704, beta=0.0000\n",
      "Batch 60, loss=0.0244, recon=0.0242, kl=51.7562, beta=0.0000\n",
      "Batch 80, loss=0.0285, recon=0.0284, kl=47.7014, beta=0.0000\n",
      "Batch 100, loss=0.0242, recon=0.0241, kl=47.5187, beta=0.0000\n",
      "Batch 120, loss=0.0222, recon=0.0220, kl=48.4014, beta=0.0000\n",
      "Batch 140, loss=0.0180, recon=0.0179, kl=50.4980, beta=0.0000\n",
      "Batch 160, loss=0.0237, recon=0.0235, kl=46.9122, beta=0.0000\n",
      "Batch 180, loss=0.0230, recon=0.0229, kl=47.8944, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0350 (Recon: 0.0348, KL: 49.5361, Current Beta: 0.0000) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0248, recon=0.0246, kl=31.0306, beta=0.0000\n",
      "Batch 40, loss=0.0189, recon=0.0187, kl=29.3779, beta=0.0000\n",
      "Batch 60, loss=0.0263, recon=0.0261, kl=29.8228, beta=0.0000\n",
      "Batch 80, loss=0.0204, recon=0.0202, kl=27.6186, beta=0.0000\n",
      "Batch 100, loss=0.0189, recon=0.0186, kl=33.0605, beta=0.0000\n",
      "Batch 120, loss=0.0907, recon=0.0905, kl=33.9585, beta=0.0000\n",
      "Batch 140, loss=0.0664, recon=0.0660, kl=48.1333, beta=0.0000\n",
      "Batch 160, loss=0.0646, recon=0.0642, kl=45.3743, beta=0.0000\n",
      "Batch 180, loss=0.0265, recon=0.0262, kl=42.5449, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0456, KL: 35.7318, Current Beta: 0.0000) | Avg Valid Loss: 0.0365 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0234, recon=0.0229, kl=26.0892, beta=0.0000\n",
      "Batch 40, loss=0.0176, recon=0.0172, kl=24.2193, beta=0.0000\n",
      "Batch 60, loss=0.0377, recon=0.0372, kl=23.5832, beta=0.0000\n",
      "Batch 80, loss=0.0247, recon=0.0243, kl=19.8731, beta=0.0000\n",
      "Batch 100, loss=0.0289, recon=0.0285, kl=21.5717, beta=0.0000\n",
      "Batch 120, loss=0.0646, recon=0.0642, kl=19.9007, beta=0.0000\n",
      "Batch 140, loss=0.0423, recon=0.0419, kl=22.9526, beta=0.0000\n",
      "Batch 160, loss=0.0239, recon=0.0235, kl=22.1775, beta=0.0000\n",
      "Batch 180, loss=0.0325, recon=0.0321, kl=20.2797, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0404 (Recon: 0.0399, KL: 23.4826, Current Beta: 0.0000) | Avg Valid Loss: 0.0320 | Avg Valid recon Loss: 0.0316\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0240, recon=0.0235, kl=14.6332, beta=0.0000\n",
      "Batch 40, loss=0.0297, recon=0.0293, kl=9.8792, beta=0.0000\n",
      "Batch 60, loss=0.0343, recon=0.0339, kl=9.2032, beta=0.0000\n",
      "Batch 80, loss=0.0217, recon=0.0215, kl=6.1952, beta=0.0000\n",
      "Batch 100, loss=0.0218, recon=0.0216, kl=6.9224, beta=0.0000\n",
      "Batch 120, loss=0.0171, recon=0.0169, kl=5.6240, beta=0.0000\n",
      "Batch 140, loss=0.0522, recon=0.0520, kl=5.7385, beta=0.0000\n",
      "Batch 160, loss=0.0444, recon=0.0441, kl=8.5563, beta=0.0000\n",
      "Batch 180, loss=0.0341, recon=0.0337, kl=11.1225, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0360 (Recon: 0.0357, KL: 9.3135, Current Beta: 0.0000) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0385\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0305, recon=0.0298, kl=10.3392, beta=0.0001\n",
      "Batch 40, loss=0.0271, recon=0.0268, kl=5.5696, beta=0.0001\n",
      "Batch 60, loss=0.0363, recon=0.0360, kl=3.9332, beta=0.0001\n",
      "Batch 80, loss=0.0208, recon=0.0206, kl=3.6431, beta=0.0001\n",
      "Batch 100, loss=0.0194, recon=0.0192, kl=4.0686, beta=0.0001\n",
      "Batch 120, loss=0.0415, recon=0.0414, kl=2.2463, beta=0.0001\n",
      "Batch 140, loss=0.1194, recon=0.1192, kl=2.5901, beta=0.0001\n",
      "Batch 160, loss=0.0421, recon=0.0419, kl=3.3513, beta=0.0001\n",
      "Batch 180, loss=0.0688, recon=0.0686, kl=3.9195, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0367, KL: 4.7730, Current Beta: 0.0001) | Avg Valid Loss: 0.0760 | Avg Valid recon Loss: 0.0757\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0368, recon=0.0361, kl=7.1654, beta=0.0001\n",
      "Batch 40, loss=0.0253, recon=0.0246, kl=7.1608, beta=0.0001\n",
      "Batch 60, loss=0.0345, recon=0.0340, kl=5.5040, beta=0.0001\n",
      "Batch 80, loss=0.0322, recon=0.0319, kl=3.0320, beta=0.0001\n",
      "Batch 100, loss=0.0381, recon=0.0378, kl=3.1698, beta=0.0001\n",
      "Batch 120, loss=0.0268, recon=0.0264, kl=3.1669, beta=0.0001\n",
      "Batch 140, loss=0.0338, recon=0.0334, kl=3.5893, beta=0.0001\n",
      "Batch 160, loss=0.0263, recon=0.0260, kl=2.6058, beta=0.0001\n",
      "Batch 180, loss=0.0470, recon=0.0469, kl=1.1240, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0492, KL: 4.2464, Current Beta: 0.0001) | Avg Valid Loss: 0.0712 | Avg Valid recon Loss: 0.0711\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0428, recon=0.0426, kl=2.6837, beta=0.0001\n",
      "Batch 40, loss=0.0359, recon=0.0356, kl=3.3038, beta=0.0001\n",
      "Batch 60, loss=0.0561, recon=0.0559, kl=2.3623, beta=0.0001\n",
      "Batch 80, loss=0.0975, recon=0.0974, kl=1.2448, beta=0.0001\n",
      "Batch 100, loss=0.0719, recon=0.0717, kl=2.7539, beta=0.0001\n",
      "Batch 120, loss=0.0258, recon=0.0254, kl=4.0256, beta=0.0001\n",
      "Batch 140, loss=0.0304, recon=0.0300, kl=3.8883, beta=0.0001\n",
      "Batch 160, loss=0.0407, recon=0.0404, kl=3.0409, beta=0.0001\n",
      "Batch 180, loss=0.0307, recon=0.0304, kl=2.3644, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0578, KL: 2.7985, Current Beta: 0.0001) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0318, recon=0.0315, kl=2.2433, beta=0.0001\n",
      "Batch 40, loss=0.0359, recon=0.0356, kl=2.3261, beta=0.0001\n",
      "Batch 60, loss=0.0194, recon=0.0192, kl=2.1995, beta=0.0001\n",
      "Batch 80, loss=0.0243, recon=0.0241, kl=1.6827, beta=0.0001\n",
      "Batch 100, loss=0.0154, recon=0.0153, kl=1.1923, beta=0.0001\n",
      "Batch 120, loss=0.0305, recon=0.0304, kl=0.7677, beta=0.0001\n",
      "Batch 140, loss=0.5923, recon=0.5922, kl=0.3826, beta=0.0001\n",
      "Batch 160, loss=0.0396, recon=0.0395, kl=1.1067, beta=0.0001\n",
      "Batch 180, loss=0.0282, recon=0.0280, kl=2.0214, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0411 (Recon: 0.0409, KL: 1.5609, Current Beta: 0.0001) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0478\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0714, recon=0.0711, kl=2.6856, beta=0.0001\n",
      "Batch 40, loss=0.0254, recon=0.0251, kl=2.7066, beta=0.0001\n",
      "Batch 60, loss=0.0199, recon=0.0197, kl=2.2470, beta=0.0001\n",
      "Batch 80, loss=0.0743, recon=0.0741, kl=2.1100, beta=0.0001\n",
      "Batch 100, loss=0.0238, recon=0.0235, kl=2.9131, beta=0.0001\n",
      "Batch 120, loss=0.0287, recon=0.0284, kl=2.7808, beta=0.0001\n",
      "Batch 140, loss=0.0241, recon=0.0239, kl=2.2915, beta=0.0001\n",
      "Batch 160, loss=0.0284, recon=0.0282, kl=1.7954, beta=0.0001\n",
      "Batch 180, loss=0.0244, recon=0.0242, kl=1.4444, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0426, KL: 2.3755, Current Beta: 0.0001) | Avg Valid Loss: 0.0378 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0281, recon=0.0280, kl=1.1815, beta=0.0001\n",
      "Batch 40, loss=0.0353, recon=0.0352, kl=0.9780, beta=0.0001\n",
      "Batch 60, loss=0.0246, recon=0.0245, kl=0.8485, beta=0.0001\n",
      "Batch 80, loss=0.0594, recon=0.0593, kl=0.9452, beta=0.0001\n",
      "Batch 100, loss=0.0415, recon=0.0414, kl=0.8182, beta=0.0001\n",
      "Batch 120, loss=0.0495, recon=0.0494, kl=0.7508, beta=0.0001\n",
      "Batch 140, loss=0.0431, recon=0.0429, kl=1.6324, beta=0.0001\n",
      "Batch 160, loss=0.0591, recon=0.0588, kl=2.5943, beta=0.0001\n",
      "Batch 180, loss=0.0242, recon=0.0239, kl=2.6602, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0427, KL: 1.3200, Current Beta: 0.0001) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0349\n",
      "\n",
      "[VRAE Run 29/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3699, recon=0.3699, kl=1.4119, beta=0.0000\n",
      "Batch 40, loss=2.5489, recon=2.5489, kl=32.6722, beta=0.0000\n",
      "Batch 60, loss=0.2415, recon=0.2415, kl=75.5586, beta=0.0000\n",
      "Batch 80, loss=0.2152, recon=0.2152, kl=99.7376, beta=0.0000\n",
      "Batch 100, loss=0.2468, recon=0.2468, kl=115.3200, beta=0.0000\n",
      "Batch 120, loss=0.1360, recon=0.1360, kl=127.3842, beta=0.0000\n",
      "Batch 140, loss=0.1270, recon=0.1270, kl=133.4220, beta=0.0000\n",
      "Batch 160, loss=0.1465, recon=0.1465, kl=137.8269, beta=0.0000\n",
      "Batch 180, loss=0.1143, recon=0.1143, kl=141.2590, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2923 (Recon: 0.2923, KL: 88.9039, Current Beta: 0.0000) | Avg Valid Loss: 0.1275 | Avg Valid recon Loss: 0.1275\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1485, recon=0.1485, kl=144.5795, beta=0.0000\n",
      "Batch 40, loss=0.1334, recon=0.1334, kl=146.8648, beta=0.0000\n",
      "Batch 60, loss=0.0986, recon=0.0986, kl=147.1826, beta=0.0000\n",
      "Batch 80, loss=0.1104, recon=0.1104, kl=148.1491, beta=0.0000\n",
      "Batch 100, loss=0.1021, recon=0.1021, kl=150.3486, beta=0.0000\n",
      "Batch 120, loss=0.0899, recon=0.0899, kl=154.1856, beta=0.0000\n",
      "Batch 140, loss=0.1035, recon=0.1035, kl=155.7406, beta=0.0000\n",
      "Batch 160, loss=0.1067, recon=0.1067, kl=157.3916, beta=0.0000\n",
      "Batch 180, loss=0.0701, recon=0.0701, kl=159.8166, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1247 (Recon: 0.1247, KL: 150.5943, Current Beta: 0.0000) | Avg Valid Loss: 0.0901 | Avg Valid recon Loss: 0.0901\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0880, recon=0.0880, kl=164.6216, beta=0.0000\n",
      "Batch 40, loss=0.0962, recon=0.0962, kl=166.9391, beta=0.0000\n",
      "Batch 60, loss=0.0613, recon=0.0613, kl=168.2394, beta=0.0000\n",
      "Batch 80, loss=0.0797, recon=0.0797, kl=169.4521, beta=0.0000\n",
      "Batch 100, loss=0.0614, recon=0.0614, kl=170.4264, beta=0.0000\n",
      "Batch 120, loss=0.0713, recon=0.0713, kl=170.6931, beta=0.0000\n",
      "Batch 140, loss=0.0737, recon=0.0737, kl=171.4876, beta=0.0000\n",
      "Batch 160, loss=0.0683, recon=0.0683, kl=172.3522, beta=0.0000\n",
      "Batch 180, loss=0.0648, recon=0.0648, kl=175.8264, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0940 (Recon: 0.0940, KL: 169.3303, Current Beta: 0.0000) | Avg Valid Loss: 0.0730 | Avg Valid recon Loss: 0.0730\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0866, recon=0.0866, kl=177.2293, beta=0.0000\n",
      "Batch 40, loss=0.0579, recon=0.0579, kl=177.3364, beta=0.0000\n",
      "Batch 60, loss=0.0786, recon=0.0786, kl=178.9997, beta=0.0000\n",
      "Batch 80, loss=0.0905, recon=0.0905, kl=180.6851, beta=0.0000\n",
      "Batch 100, loss=0.0698, recon=0.0698, kl=182.3812, beta=0.0000\n",
      "Batch 120, loss=0.0564, recon=0.0564, kl=184.2863, beta=0.0000\n",
      "Batch 140, loss=0.0625, recon=0.0625, kl=189.1350, beta=0.0000\n",
      "Batch 160, loss=0.0599, recon=0.0599, kl=188.3374, beta=0.0000\n",
      "Batch 180, loss=0.0606, recon=0.0606, kl=188.6124, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0794 (Recon: 0.0794, KL: 182.3719, Current Beta: 0.0000) | Avg Valid Loss: 0.0672 | Avg Valid recon Loss: 0.0672\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0792, recon=0.0792, kl=189.3928, beta=0.0000\n",
      "Batch 40, loss=0.0382, recon=0.0382, kl=190.3289, beta=0.0000\n",
      "Batch 60, loss=0.0429, recon=0.0429, kl=190.7936, beta=0.0000\n",
      "Batch 80, loss=0.0848, recon=0.0848, kl=193.0128, beta=0.0000\n",
      "Batch 100, loss=0.0523, recon=0.0523, kl=195.7666, beta=0.0000\n",
      "Batch 120, loss=0.0520, recon=0.0520, kl=196.7828, beta=0.0000\n",
      "Batch 140, loss=0.0388, recon=0.0388, kl=197.4375, beta=0.0000\n",
      "Batch 160, loss=0.0645, recon=0.0645, kl=198.6115, beta=0.0000\n",
      "Batch 180, loss=0.0371, recon=0.0371, kl=198.8822, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0709 (Recon: 0.0709, KL: 194.0329, Current Beta: 0.0000) | Avg Valid Loss: 0.0602 | Avg Valid recon Loss: 0.0602\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0431, recon=0.0431, kl=198.2618, beta=0.0000\n",
      "Batch 40, loss=0.0439, recon=0.0439, kl=198.5409, beta=0.0000\n",
      "Batch 60, loss=0.0360, recon=0.0360, kl=198.8466, beta=0.0000\n",
      "Batch 80, loss=0.0484, recon=0.0484, kl=200.1948, beta=0.0000\n",
      "Batch 100, loss=0.0656, recon=0.0656, kl=199.2278, beta=0.0000\n",
      "Batch 120, loss=0.0519, recon=0.0519, kl=196.7919, beta=0.0000\n",
      "Batch 140, loss=0.0361, recon=0.0361, kl=197.5397, beta=0.0000\n",
      "Batch 160, loss=0.0442, recon=0.0442, kl=196.7422, beta=0.0000\n",
      "Batch 180, loss=1.1406, recon=1.1406, kl=195.9610, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0651 (Recon: 0.0651, KL: 198.2055, Current Beta: 0.0000) | Avg Valid Loss: 0.0599 | Avg Valid recon Loss: 0.0599\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0430, recon=0.0429, kl=194.0802, beta=0.0000\n",
      "Batch 40, loss=0.0314, recon=0.0314, kl=191.1812, beta=0.0000\n",
      "Batch 60, loss=0.0437, recon=0.0437, kl=188.3112, beta=0.0000\n",
      "Batch 80, loss=0.0438, recon=0.0437, kl=185.6702, beta=0.0000\n",
      "Batch 100, loss=0.0403, recon=0.0402, kl=184.4274, beta=0.0000\n",
      "Batch 120, loss=0.1048, recon=0.1048, kl=180.6955, beta=0.0000\n",
      "Batch 140, loss=0.0429, recon=0.0429, kl=178.4488, beta=0.0000\n",
      "Batch 160, loss=0.0550, recon=0.0550, kl=177.9183, beta=0.0000\n",
      "Batch 180, loss=0.0628, recon=0.0628, kl=176.8131, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0611 (Recon: 0.0611, KL: 185.2750, Current Beta: 0.0000) | Avg Valid Loss: 0.0530 | Avg Valid recon Loss: 0.0530\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0451, recon=0.0451, kl=169.3756, beta=0.0000\n",
      "Batch 40, loss=0.0354, recon=0.0354, kl=163.8534, beta=0.0000\n",
      "Batch 60, loss=0.0423, recon=0.0422, kl=155.6177, beta=0.0000\n",
      "Batch 80, loss=0.0446, recon=0.0445, kl=147.8685, beta=0.0000\n",
      "Batch 100, loss=0.0673, recon=0.0673, kl=142.0630, beta=0.0000\n",
      "Batch 120, loss=0.0333, recon=0.0333, kl=137.4543, beta=0.0000\n",
      "Batch 140, loss=0.0346, recon=0.0346, kl=133.3775, beta=0.0000\n",
      "Batch 160, loss=0.0422, recon=0.0422, kl=131.1416, beta=0.0000\n",
      "Batch 180, loss=0.0538, recon=0.0537, kl=129.8135, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 148.0564, Current Beta: 0.0000) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0499\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0529, recon=0.0528, kl=117.9209, beta=0.0000\n",
      "Batch 40, loss=0.0473, recon=0.0473, kl=104.6360, beta=0.0000\n",
      "Batch 60, loss=0.0407, recon=0.0406, kl=99.4293, beta=0.0000\n",
      "Batch 80, loss=0.0488, recon=0.0487, kl=97.4565, beta=0.0000\n",
      "Batch 100, loss=0.0354, recon=0.0354, kl=93.3982, beta=0.0000\n",
      "Batch 120, loss=0.0885, recon=0.0885, kl=88.1978, beta=0.0000\n",
      "Batch 140, loss=0.0565, recon=0.0564, kl=86.2297, beta=0.0000\n",
      "Batch 160, loss=0.0267, recon=0.0267, kl=85.5932, beta=0.0000\n",
      "Batch 180, loss=0.0474, recon=0.0474, kl=88.4481, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 97.9269, Current Beta: 0.0000) | Avg Valid Loss: 0.0483 | Avg Valid recon Loss: 0.0483\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0340, recon=0.0340, kl=66.7956, beta=0.0000\n",
      "Batch 40, loss=0.0301, recon=0.0301, kl=55.2487, beta=0.0000\n",
      "Batch 60, loss=0.0455, recon=0.0455, kl=56.6112, beta=0.0000\n",
      "Batch 80, loss=0.0725, recon=0.0725, kl=55.0709, beta=0.0000\n",
      "Batch 100, loss=0.0401, recon=0.0400, kl=52.6142, beta=0.0000\n",
      "Batch 120, loss=0.0373, recon=0.0373, kl=52.3426, beta=0.0000\n",
      "Batch 140, loss=0.0334, recon=0.0334, kl=54.2339, beta=0.0000\n",
      "Batch 160, loss=0.0311, recon=0.0310, kl=54.6978, beta=0.0000\n",
      "Batch 180, loss=0.0329, recon=0.0329, kl=50.9248, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0532, KL: 57.5127, Current Beta: 0.0000) | Avg Valid Loss: 0.0464 | Avg Valid recon Loss: 0.0463\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0383, recon=0.0382, kl=32.6322, beta=0.0000\n",
      "Batch 40, loss=0.0493, recon=0.0492, kl=27.7451, beta=0.0000\n",
      "Batch 60, loss=0.0322, recon=0.0321, kl=29.1522, beta=0.0000\n",
      "Batch 80, loss=0.0631, recon=0.0630, kl=26.6931, beta=0.0000\n",
      "Batch 100, loss=0.0332, recon=0.0331, kl=28.8689, beta=0.0000\n",
      "Batch 120, loss=0.0357, recon=0.0356, kl=27.5054, beta=0.0000\n",
      "Batch 140, loss=0.0345, recon=0.0344, kl=26.4295, beta=0.0000\n",
      "Batch 160, loss=0.0434, recon=0.0433, kl=24.1233, beta=0.0000\n",
      "Batch 180, loss=0.0286, recon=0.0285, kl=22.0583, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0515 (Recon: 0.0514, KL: 28.8129, Current Beta: 0.0000) | Avg Valid Loss: 0.0448 | Avg Valid recon Loss: 0.0447\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0387, recon=0.0386, kl=13.4974, beta=0.0000\n",
      "Batch 40, loss=0.0534, recon=0.0533, kl=11.7087, beta=0.0000\n",
      "Batch 60, loss=0.2428, recon=0.2427, kl=11.2177, beta=0.0000\n",
      "Batch 80, loss=0.0597, recon=0.0597, kl=10.8402, beta=0.0000\n",
      "Batch 100, loss=0.0409, recon=0.0408, kl=10.1395, beta=0.0000\n",
      "Batch 120, loss=0.0300, recon=0.0299, kl=9.8705, beta=0.0000\n",
      "Batch 140, loss=0.0268, recon=0.0267, kl=9.2145, beta=0.0000\n",
      "Batch 160, loss=0.0270, recon=0.0269, kl=9.2966, beta=0.0000\n",
      "Batch 180, loss=0.0659, recon=0.0658, kl=8.9876, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0501, KL: 11.1945, Current Beta: 0.0000) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0292, recon=0.0291, kl=4.5475, beta=0.0000\n",
      "Batch 40, loss=0.0405, recon=0.0404, kl=4.4448, beta=0.0000\n",
      "Batch 60, loss=0.0578, recon=0.0577, kl=5.2382, beta=0.0000\n",
      "Batch 80, loss=0.0396, recon=0.0395, kl=4.3957, beta=0.0000\n",
      "Batch 100, loss=0.0346, recon=0.0345, kl=4.1416, beta=0.0000\n",
      "Batch 120, loss=0.0618, recon=0.0617, kl=3.6778, beta=0.0000\n",
      "Batch 140, loss=0.0367, recon=0.0367, kl=4.0712, beta=0.0000\n",
      "Batch 160, loss=0.0774, recon=0.0773, kl=3.6943, beta=0.0000\n",
      "Batch 180, loss=0.0340, recon=0.0339, kl=2.8071, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0488 (Recon: 0.0487, KL: 4.2866, Current Beta: 0.0000) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0719, recon=0.0718, kl=1.8872, beta=0.0000\n",
      "Batch 40, loss=0.0421, recon=0.0420, kl=1.8844, beta=0.0000\n",
      "Batch 60, loss=0.0742, recon=0.0741, kl=1.8592, beta=0.0000\n",
      "Batch 80, loss=0.0316, recon=0.0315, kl=2.1666, beta=0.0000\n",
      "Batch 100, loss=0.0405, recon=0.0404, kl=1.9603, beta=0.0000\n",
      "Batch 120, loss=0.0422, recon=0.0421, kl=1.9164, beta=0.0000\n",
      "Batch 140, loss=0.0487, recon=0.0487, kl=1.9549, beta=0.0000\n",
      "Batch 160, loss=0.0394, recon=0.0393, kl=1.4702, beta=0.0000\n",
      "Batch 180, loss=0.0250, recon=0.0250, kl=1.6189, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0471 (Recon: 0.0470, KL: 1.9472, Current Beta: 0.0000) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0349, recon=0.0349, kl=1.2082, beta=0.0001\n",
      "Batch 40, loss=0.0334, recon=0.0333, kl=1.3049, beta=0.0001\n",
      "Batch 60, loss=0.0276, recon=0.0275, kl=1.2179, beta=0.0001\n",
      "Batch 80, loss=0.0247, recon=0.0247, kl=0.9339, beta=0.0001\n",
      "Batch 100, loss=0.0281, recon=0.0281, kl=0.8735, beta=0.0001\n",
      "Batch 120, loss=0.0265, recon=0.0265, kl=0.8878, beta=0.0001\n",
      "Batch 140, loss=0.0359, recon=0.0358, kl=0.8064, beta=0.0001\n",
      "Batch 160, loss=0.0284, recon=0.0283, kl=0.6679, beta=0.0001\n",
      "Batch 180, loss=0.0289, recon=0.0289, kl=0.7504, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0460 (Recon: 0.0460, KL: 1.0132, Current Beta: 0.0001) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0400\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0279, recon=0.0279, kl=0.4126, beta=0.0001\n",
      "Batch 40, loss=0.0381, recon=0.0381, kl=0.3587, beta=0.0001\n",
      "Batch 60, loss=0.0364, recon=0.0364, kl=0.1824, beta=0.0001\n",
      "Batch 80, loss=0.0321, recon=0.0320, kl=0.3624, beta=0.0001\n",
      "Batch 100, loss=0.0351, recon=0.0351, kl=0.2934, beta=0.0001\n",
      "Batch 120, loss=0.0273, recon=0.0273, kl=0.2153, beta=0.0001\n",
      "Batch 140, loss=0.0374, recon=0.0373, kl=0.1774, beta=0.0001\n",
      "Batch 160, loss=0.0313, recon=0.0312, kl=0.2295, beta=0.0001\n",
      "Batch 180, loss=0.0349, recon=0.0348, kl=0.1976, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0449, KL: 0.2977, Current Beta: 0.0001) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0298, recon=0.0298, kl=0.1566, beta=0.0001\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=0.1500, beta=0.0001\n",
      "Batch 60, loss=0.0358, recon=0.0358, kl=0.1547, beta=0.0001\n",
      "Batch 80, loss=0.0354, recon=0.0354, kl=0.1028, beta=0.0001\n",
      "Batch 100, loss=0.0323, recon=0.0323, kl=0.1394, beta=0.0001\n",
      "Batch 120, loss=0.0295, recon=0.0295, kl=0.1862, beta=0.0001\n",
      "Batch 140, loss=0.0252, recon=0.0252, kl=0.1203, beta=0.0001\n",
      "Batch 160, loss=0.0272, recon=0.0272, kl=0.0793, beta=0.0001\n",
      "Batch 180, loss=0.0361, recon=0.0361, kl=0.0884, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0441 (Recon: 0.0441, KL: 0.1332, Current Beta: 0.0001) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0411, recon=0.0411, kl=0.0620, beta=0.0001\n",
      "Batch 40, loss=0.0314, recon=0.0314, kl=0.0577, beta=0.0001\n",
      "Batch 60, loss=0.0356, recon=0.0356, kl=0.0534, beta=0.0001\n",
      "Batch 80, loss=0.0307, recon=0.0307, kl=0.0383, beta=0.0001\n",
      "Batch 100, loss=0.0285, recon=0.0285, kl=0.2685, beta=0.0001\n",
      "Batch 120, loss=0.0339, recon=0.0339, kl=0.0845, beta=0.0001\n",
      "Batch 140, loss=0.0613, recon=0.0613, kl=0.0587, beta=0.0001\n",
      "Batch 160, loss=0.0512, recon=0.0512, kl=0.0521, beta=0.0001\n",
      "Batch 180, loss=0.0299, recon=0.0299, kl=0.0340, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0431, KL: 0.0759, Current Beta: 0.0001) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0318, recon=0.0318, kl=0.0683, beta=0.0001\n",
      "Batch 40, loss=0.0289, recon=0.0289, kl=0.0444, beta=0.0001\n",
      "Batch 60, loss=0.0360, recon=0.0360, kl=0.0710, beta=0.0001\n",
      "Batch 80, loss=0.0322, recon=0.0322, kl=0.0466, beta=0.0001\n",
      "Batch 100, loss=0.0228, recon=0.0228, kl=0.0235, beta=0.0001\n",
      "Batch 120, loss=0.0453, recon=0.0453, kl=0.0435, beta=0.0001\n",
      "Batch 140, loss=0.0316, recon=0.0316, kl=0.0392, beta=0.0001\n",
      "Batch 160, loss=0.0387, recon=0.0387, kl=0.0265, beta=0.0001\n",
      "Batch 180, loss=0.0226, recon=0.0226, kl=0.0194, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 0.0439, Current Beta: 0.0001) | Avg Valid Loss: 0.0367 | Avg Valid recon Loss: 0.0367\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0351, recon=0.0351, kl=0.0225, beta=0.0001\n",
      "Batch 40, loss=0.0270, recon=0.0270, kl=0.0280, beta=0.0001\n",
      "Batch 60, loss=0.0310, recon=0.0310, kl=0.0167, beta=0.0001\n",
      "Batch 80, loss=0.0356, recon=0.0356, kl=0.0232, beta=0.0001\n",
      "Batch 100, loss=0.0270, recon=0.0270, kl=0.0261, beta=0.0001\n",
      "Batch 120, loss=0.0289, recon=0.0289, kl=0.0138, beta=0.0001\n",
      "Batch 140, loss=0.5898, recon=0.5898, kl=0.0385, beta=0.0001\n",
      "Batch 160, loss=0.0367, recon=0.0367, kl=0.0270, beta=0.0001\n",
      "Batch 180, loss=0.0264, recon=0.0264, kl=0.0183, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0416, KL: 0.0227, Current Beta: 0.0001) | Avg Valid Loss: 0.0356 | Avg Valid recon Loss: 0.0356\n",
      "\n",
      "[VRAE Run 30/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2248, recon=0.2248, kl=47.7718, beta=0.0000\n",
      "Batch 40, loss=0.1283, recon=0.1283, kl=96.0067, beta=0.0000\n",
      "Batch 60, loss=0.1753, recon=0.1753, kl=100.2029, beta=0.0000\n",
      "Batch 80, loss=0.0817, recon=0.0817, kl=90.1459, beta=0.0000\n",
      "Batch 100, loss=0.0489, recon=0.0489, kl=107.2236, beta=0.0000\n",
      "Batch 120, loss=0.0548, recon=0.0548, kl=89.6497, beta=0.0000\n",
      "Batch 140, loss=0.0385, recon=0.0385, kl=110.1185, beta=0.0000\n",
      "Batch 160, loss=0.0552, recon=0.0552, kl=121.9782, beta=0.0000\n",
      "Batch 180, loss=0.0573, recon=0.0573, kl=126.9400, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1357 (Recon: 0.1357, KL: 92.4579, Current Beta: 0.0000) | Avg Valid Loss: 0.0638 | Avg Valid recon Loss: 0.0638\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0371, recon=0.0371, kl=130.4513, beta=0.0000\n",
      "Batch 40, loss=0.0494, recon=0.0494, kl=133.8968, beta=0.0000\n",
      "Batch 60, loss=0.0846, recon=0.0846, kl=120.4219, beta=0.0000\n",
      "Batch 80, loss=0.0377, recon=0.0377, kl=100.5853, beta=0.0000\n",
      "Batch 100, loss=0.1892, recon=0.1892, kl=115.1392, beta=0.0000\n",
      "Batch 120, loss=0.0987, recon=0.0987, kl=123.2564, beta=0.0000\n",
      "Batch 140, loss=0.0359, recon=0.0359, kl=128.0895, beta=0.0000\n",
      "Batch 160, loss=0.0307, recon=0.0307, kl=114.4346, beta=0.0000\n",
      "Batch 180, loss=0.0288, recon=0.0288, kl=87.4690, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0656 (Recon: 0.0656, KL: 118.5873, Current Beta: 0.0000) | Avg Valid Loss: 0.0498 | Avg Valid recon Loss: 0.0498\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0425, recon=0.0425, kl=108.5372, beta=0.0000\n",
      "Batch 40, loss=0.0372, recon=0.0372, kl=129.7456, beta=0.0000\n",
      "Batch 60, loss=0.0421, recon=0.0421, kl=141.4251, beta=0.0000\n",
      "Batch 80, loss=0.0305, recon=0.0305, kl=139.6583, beta=0.0000\n",
      "Batch 100, loss=0.0326, recon=0.0326, kl=107.5079, beta=0.0000\n",
      "Batch 120, loss=0.1517, recon=0.1517, kl=114.9655, beta=0.0000\n",
      "Batch 140, loss=0.0590, recon=0.0590, kl=123.1704, beta=0.0000\n",
      "Batch 160, loss=0.0626, recon=0.0626, kl=127.1319, beta=0.0000\n",
      "Batch 180, loss=0.0458, recon=0.0458, kl=125.6057, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0517 (Recon: 0.0517, KL: 122.5391, Current Beta: 0.0000) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0315, recon=0.0315, kl=131.7148, beta=0.0000\n",
      "Batch 40, loss=0.0421, recon=0.0421, kl=137.6499, beta=0.0000\n",
      "Batch 60, loss=0.0530, recon=0.0530, kl=148.2399, beta=0.0000\n",
      "Batch 80, loss=0.0435, recon=0.0435, kl=153.8607, beta=0.0000\n",
      "Batch 100, loss=0.0329, recon=0.0329, kl=149.5013, beta=0.0000\n",
      "Batch 120, loss=0.0561, recon=0.0561, kl=138.6165, beta=0.0000\n",
      "Batch 140, loss=0.0480, recon=0.0480, kl=127.0287, beta=0.0000\n",
      "Batch 160, loss=0.0255, recon=0.0255, kl=134.9634, beta=0.0000\n",
      "Batch 180, loss=0.0601, recon=0.0601, kl=136.6165, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0494, KL: 139.0308, Current Beta: 0.0000) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=137.1416, beta=0.0000\n",
      "Batch 40, loss=0.0355, recon=0.0355, kl=147.2734, beta=0.0000\n",
      "Batch 60, loss=0.0310, recon=0.0310, kl=152.0353, beta=0.0000\n",
      "Batch 80, loss=0.0778, recon=0.0778, kl=146.3364, beta=0.0000\n",
      "Batch 100, loss=0.0481, recon=0.0481, kl=132.4199, beta=0.0000\n",
      "Batch 120, loss=0.0623, recon=0.0623, kl=133.9223, beta=0.0000\n",
      "Batch 140, loss=0.0296, recon=0.0296, kl=136.8988, beta=0.0000\n",
      "Batch 160, loss=0.0270, recon=0.0270, kl=133.3524, beta=0.0000\n",
      "Batch 180, loss=0.0272, recon=0.0272, kl=133.3256, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0472, KL: 139.6680, Current Beta: 0.0000) | Avg Valid Loss: 0.0385 | Avg Valid recon Loss: 0.0385\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2378, recon=0.2378, kl=142.7657, beta=0.0000\n",
      "Batch 40, loss=0.0571, recon=0.0571, kl=143.2487, beta=0.0000\n",
      "Batch 60, loss=0.0388, recon=0.0388, kl=143.7130, beta=0.0000\n",
      "Batch 80, loss=0.0222, recon=0.0222, kl=144.0916, beta=0.0000\n",
      "Batch 100, loss=0.0708, recon=0.0708, kl=144.3660, beta=0.0000\n",
      "Batch 120, loss=0.0353, recon=0.0353, kl=119.8450, beta=0.0000\n",
      "Batch 140, loss=0.0327, recon=0.0327, kl=124.7737, beta=0.0000\n",
      "Batch 160, loss=0.0667, recon=0.0667, kl=131.2962, beta=0.0000\n",
      "Batch 180, loss=0.0367, recon=0.0367, kl=138.0209, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0534, KL: 136.5344, Current Beta: 0.0000) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0273, recon=0.0273, kl=130.9883, beta=0.0000\n",
      "Batch 40, loss=0.0276, recon=0.0276, kl=139.6586, beta=0.0000\n",
      "Batch 60, loss=0.1868, recon=0.1868, kl=153.1920, beta=0.0000\n",
      "Batch 80, loss=0.0344, recon=0.0344, kl=150.3658, beta=0.0000\n",
      "Batch 100, loss=0.0260, recon=0.0260, kl=102.2573, beta=0.0000\n",
      "Batch 120, loss=0.0788, recon=0.0788, kl=118.2820, beta=0.0000\n",
      "Batch 140, loss=0.0484, recon=0.0483, kl=133.4123, beta=0.0000\n",
      "Batch 160, loss=0.0508, recon=0.0508, kl=130.3026, beta=0.0000\n",
      "Batch 180, loss=0.2132, recon=0.2132, kl=136.0001, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0461, KL: 133.5292, Current Beta: 0.0000) | Avg Valid Loss: 0.0477 | Avg Valid recon Loss: 0.0477\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0439, recon=0.0439, kl=142.2720, beta=0.0000\n",
      "Batch 40, loss=0.0252, recon=0.0251, kl=145.7408, beta=0.0000\n",
      "Batch 60, loss=0.0254, recon=0.0254, kl=145.9438, beta=0.0000\n",
      "Batch 80, loss=0.0340, recon=0.0339, kl=149.3900, beta=0.0000\n",
      "Batch 100, loss=0.0484, recon=0.0483, kl=152.6648, beta=0.0000\n",
      "Batch 120, loss=0.0540, recon=0.0540, kl=121.8360, beta=0.0000\n",
      "Batch 140, loss=0.0445, recon=0.0445, kl=125.7704, beta=0.0000\n",
      "Batch 160, loss=0.0444, recon=0.0444, kl=140.0786, beta=0.0000\n",
      "Batch 180, loss=0.0335, recon=0.0335, kl=150.3803, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0489 (Recon: 0.0488, KL: 140.4588, Current Beta: 0.0000) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0372, recon=0.0372, kl=146.8145, beta=0.0000\n",
      "Batch 40, loss=0.0219, recon=0.0218, kl=149.3869, beta=0.0000\n",
      "Batch 60, loss=0.0259, recon=0.0259, kl=136.8162, beta=0.0000\n",
      "Batch 80, loss=0.0200, recon=0.0199, kl=136.3883, beta=0.0000\n",
      "Batch 100, loss=0.0338, recon=0.0337, kl=141.2451, beta=0.0000\n",
      "Batch 120, loss=0.0249, recon=0.0248, kl=141.6806, beta=0.0000\n",
      "Batch 140, loss=0.0259, recon=0.0258, kl=141.3018, beta=0.0000\n",
      "Batch 160, loss=0.0640, recon=0.0639, kl=138.3377, beta=0.0000\n",
      "Batch 180, loss=0.0525, recon=0.0525, kl=69.1118, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 138.8884, Current Beta: 0.0000) | Avg Valid Loss: 0.0558 | Avg Valid recon Loss: 0.0558\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0447, recon=0.0446, kl=105.0674, beta=0.0000\n",
      "Batch 40, loss=0.0394, recon=0.0393, kl=116.3502, beta=0.0000\n",
      "Batch 60, loss=0.0229, recon=0.0228, kl=109.4541, beta=0.0000\n",
      "Batch 80, loss=0.0254, recon=0.0252, kl=119.2545, beta=0.0000\n",
      "Batch 100, loss=0.0392, recon=0.0391, kl=122.2087, beta=0.0000\n",
      "Batch 120, loss=0.0245, recon=0.0244, kl=124.2629, beta=0.0000\n",
      "Batch 140, loss=0.0351, recon=0.0350, kl=125.7401, beta=0.0000\n",
      "Batch 160, loss=0.0182, recon=0.0181, kl=128.2350, beta=0.0000\n",
      "Batch 180, loss=0.0355, recon=0.0354, kl=130.5653, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0420, KL: 117.5574, Current Beta: 0.0000) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0224, recon=0.0221, kl=106.2296, beta=0.0000\n",
      "Batch 40, loss=0.0159, recon=0.0156, kl=100.5105, beta=0.0000\n",
      "Batch 60, loss=0.0288, recon=0.0285, kl=97.1785, beta=0.0000\n",
      "Batch 80, loss=0.0375, recon=0.0372, kl=89.8208, beta=0.0000\n",
      "Batch 100, loss=0.0396, recon=0.0393, kl=102.1708, beta=0.0000\n",
      "Batch 120, loss=0.0414, recon=0.0411, kl=97.6029, beta=0.0000\n",
      "Batch 140, loss=0.0245, recon=0.0242, kl=101.0533, beta=0.0000\n",
      "Batch 160, loss=0.0279, recon=0.0276, kl=99.1639, beta=0.0000\n",
      "Batch 180, loss=0.0268, recon=0.0265, kl=98.1490, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0383 (Recon: 0.0380, KL: 101.0189, Current Beta: 0.0000) | Avg Valid Loss: 0.0419 | Avg Valid recon Loss: 0.0416\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0301, recon=0.0294, kl=82.8586, beta=0.0000\n",
      "Batch 40, loss=0.0273, recon=0.0268, kl=73.5099, beta=0.0000\n",
      "Batch 60, loss=0.0256, recon=0.0250, kl=70.4443, beta=0.0000\n",
      "Batch 80, loss=0.0276, recon=0.0270, kl=74.6966, beta=0.0000\n",
      "Batch 100, loss=0.0393, recon=0.0388, kl=68.6833, beta=0.0000\n",
      "Batch 120, loss=0.0392, recon=0.0386, kl=87.8432, beta=0.0000\n",
      "Batch 140, loss=0.0427, recon=0.0420, kl=87.0303, beta=0.0000\n",
      "Batch 160, loss=0.0282, recon=0.0275, kl=90.3230, beta=0.0000\n",
      "Batch 180, loss=0.0694, recon=0.0687, kl=85.8045, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0398, KL: 80.8625, Current Beta: 0.0000) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0290, recon=0.0280, kl=55.3823, beta=0.0000\n",
      "Batch 40, loss=0.0527, recon=0.0517, kl=56.3547, beta=0.0000\n",
      "Batch 60, loss=0.0222, recon=0.0213, kl=47.0876, beta=0.0000\n",
      "Batch 80, loss=0.0280, recon=0.0271, kl=47.1384, beta=0.0000\n",
      "Batch 100, loss=0.0483, recon=0.0475, kl=44.5270, beta=0.0000\n",
      "Batch 120, loss=0.0263, recon=0.0255, kl=43.5621, beta=0.0000\n",
      "Batch 140, loss=0.0314, recon=0.0306, kl=42.1797, beta=0.0000\n",
      "Batch 160, loss=0.0288, recon=0.0281, kl=40.3276, beta=0.0000\n",
      "Batch 180, loss=0.0280, recon=0.0273, kl=39.5736, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0347 (Recon: 0.0338, KL: 48.2368, Current Beta: 0.0000) | Avg Valid Loss: 0.0289 | Avg Valid recon Loss: 0.0281\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0189, recon=0.0175, kl=37.1983, beta=0.0000\n",
      "Batch 40, loss=0.0243, recon=0.0230, kl=34.0213, beta=0.0000\n",
      "Batch 60, loss=0.0227, recon=0.0216, kl=30.4374, beta=0.0000\n",
      "Batch 80, loss=0.0288, recon=0.0278, kl=26.9474, beta=0.0000\n",
      "Batch 100, loss=0.0413, recon=0.0404, kl=23.6854, beta=0.0000\n",
      "Batch 120, loss=0.1078, recon=0.1070, kl=22.9766, beta=0.0000\n",
      "Batch 140, loss=0.0569, recon=0.0560, kl=22.7890, beta=0.0000\n",
      "Batch 160, loss=0.0312, recon=0.0303, kl=23.0896, beta=0.0000\n",
      "Batch 180, loss=0.0251, recon=0.0239, kl=30.8106, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0367 (Recon: 0.0356, KL: 28.5016, Current Beta: 0.0000) | Avg Valid Loss: 0.0348 | Avg Valid recon Loss: 0.0337\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0189, recon=0.0174, kl=23.6410, beta=0.0001\n",
      "Batch 40, loss=0.0526, recon=0.0513, kl=20.8252, beta=0.0001\n",
      "Batch 60, loss=0.0318, recon=0.0306, kl=20.2307, beta=0.0001\n",
      "Batch 80, loss=0.0245, recon=0.0234, kl=18.1668, beta=0.0001\n",
      "Batch 100, loss=0.0392, recon=0.0380, kl=19.0215, beta=0.0001\n",
      "Batch 120, loss=0.0478, recon=0.0465, kl=20.4459, beta=0.0001\n",
      "Batch 140, loss=0.0333, recon=0.0321, kl=19.0868, beta=0.0001\n",
      "Batch 160, loss=0.0280, recon=0.0269, kl=17.1257, beta=0.0001\n",
      "Batch 180, loss=0.0309, recon=0.0300, kl=14.2693, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0409, KL: 19.6132, Current Beta: 0.0001) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0241, recon=0.0230, kl=10.2288, beta=0.0001\n",
      "Batch 40, loss=0.0194, recon=0.0185, kl=8.9276, beta=0.0001\n",
      "Batch 60, loss=0.0276, recon=0.0263, kl=13.1501, beta=0.0001\n",
      "Batch 80, loss=0.0321, recon=0.0304, kl=16.9581, beta=0.0001\n",
      "Batch 100, loss=0.0256, recon=0.0238, kl=18.2400, beta=0.0001\n",
      "Batch 120, loss=0.0339, recon=0.0323, kl=16.5186, beta=0.0001\n",
      "Batch 140, loss=0.0261, recon=0.0247, kl=14.5271, beta=0.0001\n",
      "Batch 160, loss=0.1323, recon=0.1310, kl=12.9586, beta=0.0001\n",
      "Batch 180, loss=0.0952, recon=0.0938, kl=13.8028, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0494, KL: 13.8705, Current Beta: 0.0001) | Avg Valid Loss: 0.0917 | Avg Valid recon Loss: 0.0903\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0855, recon=0.0836, kl=18.1571, beta=0.0001\n",
      "Batch 40, loss=0.0641, recon=0.0619, kl=22.2174, beta=0.0001\n",
      "Batch 60, loss=0.0397, recon=0.0374, kl=23.3041, beta=0.0001\n",
      "Batch 80, loss=0.1214, recon=0.1192, kl=22.8204, beta=0.0001\n",
      "Batch 100, loss=0.0298, recon=0.0276, kl=21.6998, beta=0.0001\n",
      "Batch 120, loss=0.0329, recon=0.0309, kl=20.0559, beta=0.0001\n",
      "Batch 140, loss=0.0304, recon=0.0285, kl=18.5652, beta=0.0001\n",
      "Batch 160, loss=0.0702, recon=0.0685, kl=17.0749, beta=0.0001\n",
      "Batch 180, loss=0.0683, recon=0.0667, kl=15.9912, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0573 (Recon: 0.0553, KL: 19.9169, Current Beta: 0.0001) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0340, recon=0.0326, kl=14.9026, beta=0.0001\n",
      "Batch 40, loss=0.0319, recon=0.0305, kl=13.7701, beta=0.0001\n",
      "Batch 60, loss=0.0285, recon=0.0272, kl=12.5852, beta=0.0001\n",
      "Batch 80, loss=0.0429, recon=0.0417, kl=11.4968, beta=0.0001\n",
      "Batch 100, loss=0.0275, recon=0.0264, kl=10.5575, beta=0.0001\n",
      "Batch 120, loss=0.0352, recon=0.0345, kl=6.5837, beta=0.0001\n",
      "Batch 140, loss=0.0235, recon=0.0230, kl=5.1137, beta=0.0001\n",
      "Batch 160, loss=0.0362, recon=0.0357, kl=4.7257, beta=0.0001\n",
      "Batch 180, loss=0.0283, recon=0.0279, kl=3.8230, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0382, KL: 9.7480, Current Beta: 0.0001) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0397\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0537, recon=0.0529, kl=8.2241, beta=0.0001\n",
      "Batch 40, loss=0.0356, recon=0.0347, kl=9.1443, beta=0.0001\n",
      "Batch 60, loss=0.0283, recon=0.0275, kl=8.1587, beta=0.0001\n",
      "Batch 80, loss=0.0189, recon=0.0183, kl=5.2609, beta=0.0001\n",
      "Batch 100, loss=0.0203, recon=0.0198, kl=5.4961, beta=0.0001\n",
      "Batch 120, loss=0.0309, recon=0.0304, kl=4.7649, beta=0.0001\n",
      "Batch 140, loss=0.0328, recon=0.0321, kl=7.2521, beta=0.0001\n",
      "Batch 160, loss=0.0604, recon=0.0599, kl=4.6640, beta=0.0001\n",
      "Batch 180, loss=0.0205, recon=0.0201, kl=4.3197, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0449, KL: 5.8367, Current Beta: 0.0001) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0340\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0226, recon=0.0218, kl=7.6802, beta=0.0001\n",
      "Batch 40, loss=0.0652, recon=0.0647, kl=5.0662, beta=0.0001\n",
      "Batch 60, loss=0.0218, recon=0.0214, kl=4.3584, beta=0.0001\n",
      "Batch 80, loss=0.0381, recon=0.0379, kl=2.4437, beta=0.0001\n",
      "Batch 100, loss=0.0247, recon=0.0243, kl=3.8405, beta=0.0001\n",
      "Batch 120, loss=0.0674, recon=0.0671, kl=2.5156, beta=0.0001\n",
      "Batch 140, loss=0.0256, recon=0.0253, kl=2.6040, beta=0.0001\n",
      "Batch 160, loss=0.0391, recon=0.0389, kl=2.2772, beta=0.0001\n",
      "Batch 180, loss=0.1309, recon=0.1307, kl=2.3436, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0436 (Recon: 0.0432, KL: 3.9634, Current Beta: 0.0001) | Avg Valid Loss: 0.0301 | Avg Valid recon Loss: 0.0299\n",
      "\n",
      "[VRAE Run 31/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2944, recon=0.2944, kl=2.7723, beta=0.0000\n",
      "Batch 40, loss=0.1903, recon=0.1903, kl=19.7126, beta=0.0000\n",
      "Batch 60, loss=0.1392, recon=0.1392, kl=25.2928, beta=0.0000\n",
      "Batch 80, loss=0.1278, recon=0.1278, kl=28.9086, beta=0.0000\n",
      "Batch 100, loss=0.1341, recon=0.1341, kl=34.1307, beta=0.0000\n",
      "Batch 120, loss=0.0916, recon=0.0916, kl=36.1907, beta=0.0000\n",
      "Batch 140, loss=0.0962, recon=0.0962, kl=38.9421, beta=0.0000\n",
      "Batch 160, loss=0.0946, recon=0.0946, kl=37.8318, beta=0.0000\n",
      "Batch 180, loss=0.1070, recon=0.1070, kl=41.6030, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2070 (Recon: 0.2070, KL: 27.3493, Current Beta: 0.0000) | Avg Valid Loss: 0.0863 | Avg Valid recon Loss: 0.0863\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1092, recon=0.1092, kl=47.3777, beta=0.0000\n",
      "Batch 40, loss=0.0893, recon=0.0893, kl=41.4556, beta=0.0000\n",
      "Batch 60, loss=0.4787, recon=0.4787, kl=44.4832, beta=0.0000\n",
      "Batch 80, loss=0.0862, recon=0.0862, kl=46.8397, beta=0.0000\n",
      "Batch 100, loss=0.0884, recon=0.0884, kl=46.4668, beta=0.0000\n",
      "Batch 120, loss=0.0786, recon=0.0786, kl=47.7064, beta=0.0000\n",
      "Batch 140, loss=0.0759, recon=0.0759, kl=51.1977, beta=0.0000\n",
      "Batch 160, loss=0.0564, recon=0.0564, kl=49.5301, beta=0.0000\n",
      "Batch 180, loss=0.0686, recon=0.0686, kl=51.9396, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0952 (Recon: 0.0952, KL: 47.1919, Current Beta: 0.0000) | Avg Valid Loss: 0.0668 | Avg Valid recon Loss: 0.0668\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0596, recon=0.0596, kl=56.5391, beta=0.0000\n",
      "Batch 40, loss=0.0674, recon=0.0674, kl=53.1504, beta=0.0000\n",
      "Batch 60, loss=0.2303, recon=0.2303, kl=52.9938, beta=0.0000\n",
      "Batch 80, loss=0.0703, recon=0.0703, kl=50.6794, beta=0.0000\n",
      "Batch 100, loss=0.0685, recon=0.0685, kl=51.8306, beta=0.0000\n",
      "Batch 120, loss=0.1562, recon=0.1562, kl=52.3820, beta=0.0000\n",
      "Batch 140, loss=0.0802, recon=0.0802, kl=52.3956, beta=0.0000\n",
      "Batch 160, loss=0.0454, recon=0.0454, kl=54.8829, beta=0.0000\n",
      "Batch 180, loss=0.0967, recon=0.0967, kl=55.4305, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0733 (Recon: 0.0733, KL: 53.2295, Current Beta: 0.0000) | Avg Valid Loss: 0.0573 | Avg Valid recon Loss: 0.0573\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0480, recon=0.0480, kl=57.8954, beta=0.0000\n",
      "Batch 40, loss=0.0582, recon=0.0582, kl=58.9134, beta=0.0000\n",
      "Batch 60, loss=0.0460, recon=0.0460, kl=55.3762, beta=0.0000\n",
      "Batch 80, loss=0.0626, recon=0.0626, kl=56.9938, beta=0.0000\n",
      "Batch 100, loss=0.0443, recon=0.0443, kl=56.6426, beta=0.0000\n",
      "Batch 120, loss=0.2521, recon=0.2521, kl=53.7138, beta=0.0000\n",
      "Batch 140, loss=0.0362, recon=0.0362, kl=52.0840, beta=0.0000\n",
      "Batch 160, loss=0.0700, recon=0.0700, kl=53.5757, beta=0.0000\n",
      "Batch 180, loss=0.0337, recon=0.0337, kl=56.1855, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0618 (Recon: 0.0618, KL: 55.6001, Current Beta: 0.0000) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0496\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0667, recon=0.0667, kl=57.0272, beta=0.0000\n",
      "Batch 40, loss=0.0485, recon=0.0485, kl=58.7854, beta=0.0000\n",
      "Batch 60, loss=0.0324, recon=0.0324, kl=55.3878, beta=0.0000\n",
      "Batch 80, loss=0.0400, recon=0.0400, kl=53.9375, beta=0.0000\n",
      "Batch 100, loss=0.0402, recon=0.0402, kl=56.1084, beta=0.0000\n",
      "Batch 120, loss=0.0315, recon=0.0315, kl=55.5301, beta=0.0000\n",
      "Batch 140, loss=0.0851, recon=0.0851, kl=52.8019, beta=0.0000\n",
      "Batch 160, loss=0.0515, recon=0.0515, kl=54.0133, beta=0.0000\n",
      "Batch 180, loss=0.1349, recon=0.1349, kl=53.7556, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 55.2300, Current Beta: 0.0000) | Avg Valid Loss: 0.0442 | Avg Valid recon Loss: 0.0442\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0491, recon=0.0491, kl=52.7265, beta=0.0000\n",
      "Batch 40, loss=0.2106, recon=0.2106, kl=52.9510, beta=0.0000\n",
      "Batch 60, loss=0.0340, recon=0.0340, kl=53.8737, beta=0.0000\n",
      "Batch 80, loss=0.0435, recon=0.0435, kl=54.0913, beta=0.0000\n",
      "Batch 100, loss=0.0379, recon=0.0379, kl=55.1471, beta=0.0000\n",
      "Batch 120, loss=0.0397, recon=0.0397, kl=49.8895, beta=0.0000\n",
      "Batch 140, loss=0.1138, recon=0.1138, kl=49.8332, beta=0.0000\n",
      "Batch 160, loss=0.0305, recon=0.0305, kl=51.1516, beta=0.0000\n",
      "Batch 180, loss=0.0311, recon=0.0311, kl=49.0497, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0498 (Recon: 0.0498, KL: 52.2778, Current Beta: 0.0000) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0686, recon=0.0686, kl=49.7013, beta=0.0000\n",
      "Batch 40, loss=0.0378, recon=0.0378, kl=49.4180, beta=0.0000\n",
      "Batch 60, loss=0.0298, recon=0.0298, kl=50.0773, beta=0.0000\n",
      "Batch 80, loss=0.0311, recon=0.0311, kl=48.6513, beta=0.0000\n",
      "Batch 100, loss=0.0303, recon=0.0303, kl=48.9191, beta=0.0000\n",
      "Batch 120, loss=0.0217, recon=0.0217, kl=47.2521, beta=0.0000\n",
      "Batch 140, loss=0.0260, recon=0.0260, kl=46.9552, beta=0.0000\n",
      "Batch 160, loss=0.0319, recon=0.0319, kl=45.1904, beta=0.0000\n",
      "Batch 180, loss=0.0256, recon=0.0256, kl=44.2648, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 48.0999, Current Beta: 0.0000) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0356, recon=0.0356, kl=43.7169, beta=0.0000\n",
      "Batch 40, loss=0.0395, recon=0.0395, kl=39.7224, beta=0.0000\n",
      "Batch 60, loss=0.0342, recon=0.0342, kl=36.2355, beta=0.0000\n",
      "Batch 80, loss=0.0256, recon=0.0256, kl=38.7473, beta=0.0000\n",
      "Batch 100, loss=0.0309, recon=0.0309, kl=38.2452, beta=0.0000\n",
      "Batch 120, loss=0.0392, recon=0.0392, kl=37.9608, beta=0.0000\n",
      "Batch 140, loss=0.0295, recon=0.0295, kl=36.1155, beta=0.0000\n",
      "Batch 160, loss=0.0254, recon=0.0254, kl=35.6474, beta=0.0000\n",
      "Batch 180, loss=0.0380, recon=0.0380, kl=35.2400, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0434, KL: 38.5306, Current Beta: 0.0000) | Avg Valid Loss: 0.0362 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0346, recon=0.0346, kl=36.1053, beta=0.0000\n",
      "Batch 40, loss=0.0216, recon=0.0216, kl=31.6596, beta=0.0000\n",
      "Batch 60, loss=0.0181, recon=0.0181, kl=29.2642, beta=0.0000\n",
      "Batch 80, loss=0.0546, recon=0.0546, kl=26.9029, beta=0.0000\n",
      "Batch 100, loss=0.0406, recon=0.0406, kl=27.4699, beta=0.0000\n",
      "Batch 120, loss=0.0329, recon=0.0329, kl=26.5939, beta=0.0000\n",
      "Batch 140, loss=0.0214, recon=0.0214, kl=27.5035, beta=0.0000\n",
      "Batch 160, loss=0.0285, recon=0.0284, kl=28.2338, beta=0.0000\n",
      "Batch 180, loss=0.0276, recon=0.0276, kl=27.5420, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0407 (Recon: 0.0407, KL: 29.3824, Current Beta: 0.0000) | Avg Valid Loss: 0.0344 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0270, recon=0.0269, kl=22.6714, beta=0.0000\n",
      "Batch 40, loss=0.0221, recon=0.0221, kl=18.9320, beta=0.0000\n",
      "Batch 60, loss=0.0334, recon=0.0334, kl=17.9726, beta=0.0000\n",
      "Batch 80, loss=0.0307, recon=0.0307, kl=16.6347, beta=0.0000\n",
      "Batch 100, loss=0.0250, recon=0.0250, kl=16.6942, beta=0.0000\n",
      "Batch 120, loss=0.0221, recon=0.0221, kl=17.2764, beta=0.0000\n",
      "Batch 140, loss=0.0447, recon=0.0447, kl=16.8779, beta=0.0000\n",
      "Batch 160, loss=0.1244, recon=0.1244, kl=17.8083, beta=0.0000\n",
      "Batch 180, loss=0.0304, recon=0.0304, kl=18.5005, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0391, KL: 18.5944, Current Beta: 0.0000) | Avg Valid Loss: 0.0335 | Avg Valid recon Loss: 0.0335\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0291, recon=0.0290, kl=14.2844, beta=0.0000\n",
      "Batch 40, loss=0.0212, recon=0.0212, kl=9.7638, beta=0.0000\n",
      "Batch 60, loss=0.0364, recon=0.0364, kl=9.8832, beta=0.0000\n",
      "Batch 80, loss=0.0525, recon=0.0525, kl=9.9885, beta=0.0000\n",
      "Batch 100, loss=0.0349, recon=0.0349, kl=10.4205, beta=0.0000\n",
      "Batch 120, loss=0.0311, recon=0.0311, kl=9.5605, beta=0.0000\n",
      "Batch 140, loss=0.5060, recon=0.5059, kl=10.7913, beta=0.0000\n",
      "Batch 160, loss=0.0390, recon=0.0390, kl=10.6429, beta=0.0000\n",
      "Batch 180, loss=0.0492, recon=0.0492, kl=9.6560, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0372 (Recon: 0.0372, KL: 11.0174, Current Beta: 0.0000) | Avg Valid Loss: 0.0319 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0212, recon=0.0212, kl=5.6054, beta=0.0000\n",
      "Batch 40, loss=0.0301, recon=0.0301, kl=4.2018, beta=0.0000\n",
      "Batch 60, loss=0.0529, recon=0.0529, kl=5.0762, beta=0.0000\n",
      "Batch 80, loss=0.0297, recon=0.0297, kl=6.7080, beta=0.0000\n",
      "Batch 100, loss=0.0176, recon=0.0176, kl=4.9621, beta=0.0000\n",
      "Batch 120, loss=0.0385, recon=0.0384, kl=5.1237, beta=0.0000\n",
      "Batch 140, loss=0.0225, recon=0.0225, kl=3.4332, beta=0.0000\n",
      "Batch 160, loss=0.0277, recon=0.0277, kl=4.3666, beta=0.0000\n",
      "Batch 180, loss=0.0240, recon=0.0239, kl=4.7274, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0362, KL: 5.0478, Current Beta: 0.0000) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0301, recon=0.0300, kl=1.9312, beta=0.0000\n",
      "Batch 40, loss=0.0230, recon=0.0230, kl=3.4890, beta=0.0000\n",
      "Batch 60, loss=0.0200, recon=0.0200, kl=2.1811, beta=0.0000\n",
      "Batch 80, loss=0.0205, recon=0.0204, kl=2.4884, beta=0.0000\n",
      "Batch 100, loss=0.1239, recon=0.1239, kl=1.6149, beta=0.0000\n",
      "Batch 120, loss=0.0288, recon=0.0288, kl=1.6593, beta=0.0000\n",
      "Batch 140, loss=0.0261, recon=0.0261, kl=2.0388, beta=0.0000\n",
      "Batch 160, loss=0.0230, recon=0.0229, kl=3.6119, beta=0.0000\n",
      "Batch 180, loss=0.0204, recon=0.0203, kl=1.7397, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0362, KL: 2.4444, Current Beta: 0.0000) | Avg Valid Loss: 0.0310 | Avg Valid recon Loss: 0.0309\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0208, recon=0.0207, kl=1.3448, beta=0.0000\n",
      "Batch 40, loss=0.0217, recon=0.0216, kl=0.8672, beta=0.0000\n",
      "Batch 60, loss=0.0230, recon=0.0230, kl=0.9501, beta=0.0000\n",
      "Batch 80, loss=0.0320, recon=0.0320, kl=0.8420, beta=0.0000\n",
      "Batch 100, loss=0.0210, recon=0.0209, kl=0.8618, beta=0.0000\n",
      "Batch 120, loss=0.0239, recon=0.0239, kl=0.7503, beta=0.0000\n",
      "Batch 140, loss=0.0274, recon=0.0274, kl=0.7074, beta=0.0000\n",
      "Batch 160, loss=0.0304, recon=0.0304, kl=0.9167, beta=0.0000\n",
      "Batch 180, loss=0.0369, recon=0.0368, kl=0.9689, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0344 (Recon: 0.0344, KL: 0.9679, Current Beta: 0.0000) | Avg Valid Loss: 0.0292 | Avg Valid recon Loss: 0.0292\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0258, recon=0.0258, kl=0.5362, beta=0.0001\n",
      "Batch 40, loss=0.0267, recon=0.0267, kl=0.3120, beta=0.0001\n",
      "Batch 60, loss=0.0479, recon=0.0479, kl=0.3134, beta=0.0001\n",
      "Batch 80, loss=0.0209, recon=0.0209, kl=0.4263, beta=0.0001\n",
      "Batch 100, loss=0.0286, recon=0.0286, kl=0.2637, beta=0.0001\n",
      "Batch 120, loss=0.0262, recon=0.0262, kl=0.3851, beta=0.0001\n",
      "Batch 140, loss=0.0911, recon=0.0911, kl=0.1457, beta=0.0001\n",
      "Batch 160, loss=0.0204, recon=0.0204, kl=0.2331, beta=0.0001\n",
      "Batch 180, loss=0.0309, recon=0.0309, kl=0.1821, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0332 (Recon: 0.0332, KL: 0.3666, Current Beta: 0.0001) | Avg Valid Loss: 0.0289 | Avg Valid recon Loss: 0.0289\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0257, recon=0.0257, kl=0.0833, beta=0.0001\n",
      "Batch 40, loss=0.0207, recon=0.0207, kl=0.0702, beta=0.0001\n",
      "Batch 60, loss=0.0247, recon=0.0247, kl=0.1175, beta=0.0001\n",
      "Batch 80, loss=0.0166, recon=0.0166, kl=0.0600, beta=0.0001\n",
      "Batch 100, loss=0.0185, recon=0.0184, kl=0.0352, beta=0.0001\n",
      "Batch 120, loss=0.0198, recon=0.0198, kl=0.0374, beta=0.0001\n",
      "Batch 140, loss=0.0561, recon=0.0561, kl=0.0737, beta=0.0001\n",
      "Batch 160, loss=0.0169, recon=0.0169, kl=0.0367, beta=0.0001\n",
      "Batch 180, loss=0.0183, recon=0.0183, kl=0.0243, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0325 (Recon: 0.0325, KL: 0.0711, Current Beta: 0.0001) | Avg Valid Loss: 0.0284 | Avg Valid recon Loss: 0.0284\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=0.0227, beta=0.0001\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=0.0347, beta=0.0001\n",
      "Batch 60, loss=0.1185, recon=0.1185, kl=0.0454, beta=0.0001\n",
      "Batch 80, loss=0.0220, recon=0.0220, kl=0.0247, beta=0.0001\n",
      "Batch 100, loss=0.0165, recon=0.0165, kl=0.0474, beta=0.0001\n",
      "Batch 120, loss=0.0245, recon=0.0245, kl=0.0288, beta=0.0001\n",
      "Batch 140, loss=0.0169, recon=0.0169, kl=0.0132, beta=0.0001\n",
      "Batch 160, loss=0.0250, recon=0.0249, kl=0.0384, beta=0.0001\n",
      "Batch 180, loss=0.0215, recon=0.0215, kl=0.0081, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0320 (Recon: 0.0320, KL: 0.0327, Current Beta: 0.0001) | Avg Valid Loss: 0.0282 | Avg Valid recon Loss: 0.0282\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0231, recon=0.0231, kl=0.0140, beta=0.0001\n",
      "Batch 40, loss=0.0274, recon=0.0274, kl=0.0321, beta=0.0001\n",
      "Batch 60, loss=0.0233, recon=0.0233, kl=0.0146, beta=0.0001\n",
      "Batch 80, loss=0.0419, recon=0.0419, kl=0.0151, beta=0.0001\n",
      "Batch 100, loss=0.0187, recon=0.0187, kl=0.0161, beta=0.0001\n",
      "Batch 120, loss=0.0204, recon=0.0204, kl=0.0618, beta=0.0001\n",
      "Batch 140, loss=0.0277, recon=0.0277, kl=0.0207, beta=0.0001\n",
      "Batch 160, loss=0.0201, recon=0.0201, kl=0.0358, beta=0.0001\n",
      "Batch 180, loss=0.0514, recon=0.0514, kl=0.0074, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0314 (Recon: 0.0314, KL: 0.0285, Current Beta: 0.0001) | Avg Valid Loss: 0.0274 | Avg Valid recon Loss: 0.0274\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0324, recon=0.0324, kl=0.0190, beta=0.0001\n",
      "Batch 40, loss=0.0405, recon=0.0405, kl=0.0177, beta=0.0001\n",
      "Batch 60, loss=0.0249, recon=0.0249, kl=0.0086, beta=0.0001\n",
      "Batch 80, loss=0.0162, recon=0.0162, kl=0.0239, beta=0.0001\n",
      "Batch 100, loss=0.0205, recon=0.0205, kl=0.0269, beta=0.0001\n",
      "Batch 120, loss=0.0224, recon=0.0224, kl=0.0408, beta=0.0001\n",
      "Batch 140, loss=0.0183, recon=0.0183, kl=0.0091, beta=0.0001\n",
      "Batch 160, loss=0.1068, recon=0.1068, kl=0.0096, beta=0.0001\n",
      "Batch 180, loss=0.0206, recon=0.0206, kl=0.0275, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0308 (Recon: 0.0308, KL: 0.0208, Current Beta: 0.0001) | Avg Valid Loss: 0.0265 | Avg Valid recon Loss: 0.0265\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0153, recon=0.0153, kl=0.0079, beta=0.0001\n",
      "Batch 40, loss=0.0174, recon=0.0174, kl=0.0466, beta=0.0001\n",
      "Batch 60, loss=0.0176, recon=0.0176, kl=0.0184, beta=0.0001\n",
      "Batch 80, loss=0.0423, recon=0.0423, kl=0.0142, beta=0.0001\n",
      "Batch 100, loss=0.0206, recon=0.0206, kl=0.0164, beta=0.0001\n",
      "Batch 120, loss=0.0204, recon=0.0204, kl=0.0090, beta=0.0001\n",
      "Batch 140, loss=0.0301, recon=0.0301, kl=0.0170, beta=0.0001\n",
      "Batch 160, loss=0.0167, recon=0.0167, kl=0.0084, beta=0.0001\n",
      "Batch 180, loss=0.0331, recon=0.0331, kl=0.0142, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0303 (Recon: 0.0303, KL: 0.0165, Current Beta: 0.0001) | Avg Valid Loss: 0.0276 | Avg Valid recon Loss: 0.0276\n",
      " New best VRAE model found with validation loss: 0.0276\n",
      "   Model saved to ./ecg_model_logs\\best_vrae_model.pth\n",
      "\n",
      "[VRAE Run 32/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1628, recon=0.1628, kl=22.5564, beta=0.0000\n",
      "Batch 40, loss=0.1844, recon=0.1844, kl=23.0133, beta=0.0000\n",
      "Batch 60, loss=0.1934, recon=0.1934, kl=27.1131, beta=0.0000\n",
      "Batch 80, loss=0.0537, recon=0.0537, kl=30.7756, beta=0.0000\n",
      "Batch 100, loss=0.0785, recon=0.0785, kl=29.7058, beta=0.0000\n",
      "Batch 120, loss=0.0490, recon=0.0490, kl=32.8320, beta=0.0000\n",
      "Batch 140, loss=0.0521, recon=0.0521, kl=33.0020, beta=0.0000\n",
      "Batch 160, loss=0.0383, recon=0.0383, kl=31.3372, beta=0.0000\n",
      "Batch 180, loss=0.0632, recon=0.0632, kl=31.7208, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1166 (Recon: 0.1166, KL: 27.6474, Current Beta: 0.0000) | Avg Valid Loss: 0.0568 | Avg Valid recon Loss: 0.0568\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0565, recon=0.0565, kl=33.8403, beta=0.0000\n",
      "Batch 40, loss=0.0420, recon=0.0420, kl=34.3469, beta=0.0000\n",
      "Batch 60, loss=0.0542, recon=0.0542, kl=36.6700, beta=0.0000\n",
      "Batch 80, loss=0.0402, recon=0.0402, kl=39.3876, beta=0.0000\n",
      "Batch 100, loss=0.0425, recon=0.0425, kl=35.4282, beta=0.0000\n",
      "Batch 120, loss=0.0730, recon=0.0730, kl=33.4088, beta=0.0000\n",
      "Batch 140, loss=0.0705, recon=0.0705, kl=50.0678, beta=0.0000\n",
      "Batch 160, loss=0.0345, recon=0.0345, kl=41.9268, beta=0.0000\n",
      "Batch 180, loss=0.0827, recon=0.0827, kl=39.6377, beta=0.0000\n",
      "  â†’ Avg Train Loss: 460.3234 (Recon: 460.3234, KL: 75227.9897, Current Beta: 0.0000) | Avg Valid Loss: 0.0543 | Avg Valid recon Loss: 0.0543\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0497, recon=0.0497, kl=36.9998, beta=0.0000\n",
      "Batch 40, loss=0.0445, recon=0.0445, kl=37.6196, beta=0.0000\n",
      "Batch 60, loss=0.0383, recon=0.0383, kl=32.0549, beta=0.0000\n",
      "Batch 80, loss=0.0798, recon=0.0798, kl=37.6854, beta=0.0000\n",
      "Batch 100, loss=0.0414, recon=0.0414, kl=37.7154, beta=0.0000\n",
      "Batch 120, loss=0.0263, recon=0.0263, kl=39.3502, beta=0.0000\n",
      "Batch 140, loss=0.0305, recon=0.0305, kl=42.5326, beta=0.0000\n",
      "Batch 160, loss=0.0265, recon=0.0265, kl=28.4175, beta=0.0000\n",
      "Batch 180, loss=0.0321, recon=0.0321, kl=31.1434, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0494, KL: 36.0117, Current Beta: 0.0000) | Avg Valid Loss: 0.0349 | Avg Valid recon Loss: 0.0349\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=34.9706, beta=0.0000\n",
      "Batch 40, loss=0.0224, recon=0.0224, kl=34.1669, beta=0.0000\n",
      "Batch 60, loss=0.0237, recon=0.0237, kl=37.3046, beta=0.0000\n",
      "Batch 80, loss=0.0520, recon=0.0520, kl=37.7251, beta=0.0000\n",
      "Batch 100, loss=0.1316, recon=0.1316, kl=40.6439, beta=0.0000\n",
      "Batch 120, loss=0.0224, recon=0.0224, kl=36.2249, beta=0.0000\n",
      "Batch 140, loss=0.0260, recon=0.0260, kl=37.4941, beta=0.0000\n",
      "Batch 160, loss=0.0411, recon=0.0411, kl=40.1586, beta=0.0000\n",
      "Batch 180, loss=0.1396, recon=0.1396, kl=41.0372, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0402 (Recon: 0.0402, KL: 37.2937, Current Beta: 0.0000) | Avg Valid Loss: 0.0599 | Avg Valid recon Loss: 0.0599\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0381, recon=0.0381, kl=39.5384, beta=0.0000\n",
      "Batch 40, loss=0.0425, recon=0.0425, kl=40.2943, beta=0.0000\n",
      "Batch 60, loss=0.0268, recon=0.0268, kl=33.8793, beta=0.0000\n",
      "Batch 80, loss=0.0461, recon=0.0461, kl=35.8970, beta=0.0000\n",
      "Batch 100, loss=0.0505, recon=0.0505, kl=36.5691, beta=0.0000\n",
      "Batch 120, loss=0.0576, recon=0.0576, kl=42.0532, beta=0.0000\n",
      "Batch 140, loss=0.0365, recon=0.0365, kl=28.5891, beta=0.0000\n",
      "Batch 160, loss=0.1800, recon=0.1800, kl=31.1926, beta=0.0000\n",
      "Batch 180, loss=0.0459, recon=0.0459, kl=32.5878, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0585 (Recon: 0.0585, KL: 35.8753, Current Beta: 0.0000) | Avg Valid Loss: 0.0538 | Avg Valid recon Loss: 0.0538\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0452, recon=0.0452, kl=31.1908, beta=0.0000\n",
      "Batch 40, loss=0.0268, recon=0.0268, kl=32.6032, beta=0.0000\n",
      "Batch 60, loss=0.0386, recon=0.0386, kl=33.0909, beta=0.0000\n",
      "Batch 80, loss=0.0436, recon=0.0436, kl=33.7327, beta=0.0000\n",
      "Batch 100, loss=0.0297, recon=0.0297, kl=34.0967, beta=0.0000\n",
      "Batch 120, loss=0.0280, recon=0.0280, kl=35.1649, beta=0.0000\n",
      "Batch 140, loss=0.0509, recon=0.0509, kl=35.5979, beta=0.0000\n",
      "Batch 160, loss=0.0612, recon=0.0612, kl=36.9411, beta=0.0000\n",
      "Batch 180, loss=0.0262, recon=0.0262, kl=38.5880, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0489 (Recon: 0.0489, KL: 33.9573, Current Beta: 0.0000) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0619, recon=0.0619, kl=41.2782, beta=0.0000\n",
      "Batch 40, loss=0.0331, recon=0.0331, kl=40.2974, beta=0.0000\n",
      "Batch 60, loss=0.0232, recon=0.0232, kl=40.4950, beta=0.0000\n",
      "Batch 80, loss=0.0653, recon=0.0653, kl=41.1837, beta=0.0000\n",
      "Batch 100, loss=0.0485, recon=0.0485, kl=41.5356, beta=0.0000\n",
      "Batch 120, loss=0.0680, recon=0.0680, kl=41.0019, beta=0.0000\n",
      "Batch 140, loss=0.2854, recon=0.2854, kl=41.3641, beta=0.0000\n",
      "Batch 160, loss=0.0524, recon=0.0524, kl=42.2527, beta=0.0000\n",
      "Batch 180, loss=0.0325, recon=0.0325, kl=42.9048, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0558 (Recon: 0.0558, KL: 41.1045, Current Beta: 0.0000) | Avg Valid Loss: 0.0576 | Avg Valid recon Loss: 0.0576\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0326, recon=0.0326, kl=43.5292, beta=0.0000\n",
      "Batch 40, loss=0.0389, recon=0.0389, kl=44.4457, beta=0.0000\n",
      "Batch 60, loss=0.0456, recon=0.0456, kl=44.8659, beta=0.0000\n",
      "Batch 80, loss=0.0488, recon=0.0488, kl=45.3734, beta=0.0000\n",
      "Batch 100, loss=0.0316, recon=0.0316, kl=46.0907, beta=0.0000\n",
      "Batch 120, loss=0.0277, recon=0.0277, kl=46.2658, beta=0.0000\n",
      "Batch 140, loss=0.0797, recon=0.0797, kl=46.2880, beta=0.0000\n",
      "Batch 160, loss=0.0582, recon=0.0582, kl=46.8381, beta=0.0000\n",
      "Batch 180, loss=0.0397, recon=0.0397, kl=47.2947, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0588 (Recon: 0.0588, KL: 45.4656, Current Beta: 0.0000) | Avg Valid Loss: 0.0429 | Avg Valid recon Loss: 0.0429\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.6007, recon=0.6006, kl=47.2408, beta=0.0000\n",
      "Batch 40, loss=0.0484, recon=0.0484, kl=47.8430, beta=0.0000\n",
      "Batch 60, loss=0.0599, recon=0.0599, kl=48.5536, beta=0.0000\n",
      "Batch 80, loss=0.0449, recon=0.0449, kl=49.3943, beta=0.0000\n",
      "Batch 100, loss=0.0760, recon=0.0760, kl=50.2703, beta=0.0000\n",
      "Batch 120, loss=0.1764, recon=0.1763, kl=52.0167, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 10/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 11/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 12/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 13/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 14/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 33/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2086, recon=0.2086, kl=4.6844, beta=0.0000\n",
      "Batch 40, loss=0.1663, recon=0.1663, kl=41.5528, beta=0.0000\n",
      "Batch 60, loss=0.2342, recon=0.2342, kl=54.3177, beta=0.0000\n",
      "Batch 80, loss=0.1679, recon=0.1679, kl=60.0476, beta=0.0000\n",
      "Batch 100, loss=0.1322, recon=0.1322, kl=65.9811, beta=0.0000\n",
      "Batch 120, loss=0.1347, recon=0.1347, kl=73.0499, beta=0.0000\n",
      "Batch 140, loss=0.0866, recon=0.0866, kl=83.3051, beta=0.0000\n",
      "Batch 160, loss=0.0950, recon=0.0950, kl=89.4645, beta=0.0000\n",
      "Batch 180, loss=0.0969, recon=0.0969, kl=89.1674, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2014 (Recon: 0.2014, KL: 57.9787, Current Beta: 0.0000) | Avg Valid Loss: 0.0880 | Avg Valid recon Loss: 0.0880\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0562, recon=0.0562, kl=93.4382, beta=0.0000\n",
      "Batch 40, loss=0.4417, recon=0.4417, kl=100.0523, beta=0.0000\n",
      "Batch 60, loss=0.1507, recon=0.1507, kl=95.9578, beta=0.0000\n",
      "Batch 80, loss=0.1072, recon=0.1072, kl=102.8868, beta=0.0000\n",
      "Batch 100, loss=0.0762, recon=0.0762, kl=95.8374, beta=0.0000\n",
      "Batch 120, loss=0.0803, recon=0.0803, kl=95.4488, beta=0.0000\n",
      "Batch 140, loss=0.2270, recon=0.2270, kl=103.5160, beta=0.0000\n",
      "Batch 160, loss=0.0810, recon=0.0810, kl=111.3882, beta=0.0000\n",
      "Batch 180, loss=0.0977, recon=0.0977, kl=102.7768, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0916 (Recon: 0.0916, KL: 99.2724, Current Beta: 0.0000) | Avg Valid Loss: 0.0648 | Avg Valid recon Loss: 0.0648\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0422, recon=0.0422, kl=99.7626, beta=0.0000\n",
      "Batch 40, loss=0.0623, recon=0.0623, kl=100.2388, beta=0.0000\n",
      "Batch 60, loss=0.0788, recon=0.0788, kl=106.7314, beta=0.0000\n",
      "Batch 80, loss=0.0442, recon=0.0442, kl=116.2194, beta=0.0000\n",
      "Batch 100, loss=0.0595, recon=0.0595, kl=110.1218, beta=0.0000\n",
      "Batch 120, loss=0.0396, recon=0.0396, kl=114.9170, beta=0.0000\n",
      "Batch 140, loss=0.0581, recon=0.0581, kl=110.7769, beta=0.0000\n",
      "Batch 160, loss=0.0524, recon=0.0524, kl=114.5768, beta=0.0000\n",
      "Batch 180, loss=0.0874, recon=0.0874, kl=110.8928, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0715 (Recon: 0.0715, KL: 109.3086, Current Beta: 0.0000) | Avg Valid Loss: 0.0538 | Avg Valid recon Loss: 0.0538\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0594, recon=0.0594, kl=115.9793, beta=0.0000\n",
      "Batch 40, loss=0.0448, recon=0.0448, kl=111.5440, beta=0.0000\n",
      "Batch 60, loss=0.0482, recon=0.0482, kl=110.3102, beta=0.0000\n",
      "Batch 80, loss=0.0402, recon=0.0402, kl=109.6136, beta=0.0000\n",
      "Batch 100, loss=0.0391, recon=0.0391, kl=112.5065, beta=0.0000\n",
      "Batch 120, loss=0.0399, recon=0.0399, kl=110.7086, beta=0.0000\n",
      "Batch 140, loss=0.0368, recon=0.0368, kl=110.0152, beta=0.0000\n",
      "Batch 160, loss=0.0330, recon=0.0330, kl=114.2688, beta=0.0000\n",
      "Batch 180, loss=0.0578, recon=0.0578, kl=118.5490, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0601 (Recon: 0.0601, KL: 112.2753, Current Beta: 0.0000) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0311, recon=0.0311, kl=115.9145, beta=0.0000\n",
      "Batch 40, loss=0.0482, recon=0.0482, kl=112.9128, beta=0.0000\n",
      "Batch 60, loss=0.0356, recon=0.0356, kl=114.0535, beta=0.0000\n",
      "Batch 80, loss=0.0766, recon=0.0766, kl=114.0229, beta=0.0000\n",
      "Batch 100, loss=0.0379, recon=0.0379, kl=111.4946, beta=0.0000\n",
      "Batch 120, loss=0.0623, recon=0.0623, kl=110.3115, beta=0.0000\n",
      "Batch 140, loss=0.0626, recon=0.0626, kl=110.2621, beta=0.0000\n",
      "Batch 160, loss=0.0320, recon=0.0319, kl=118.8309, beta=0.0000\n",
      "Batch 180, loss=0.0439, recon=0.0439, kl=109.6569, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0529, KL: 113.8649, Current Beta: 0.0000) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0524, recon=0.0524, kl=110.0660, beta=0.0000\n",
      "Batch 40, loss=0.0352, recon=0.0352, kl=108.9595, beta=0.0000\n",
      "Batch 60, loss=0.0429, recon=0.0429, kl=110.2110, beta=0.0000\n",
      "Batch 80, loss=0.0353, recon=0.0353, kl=109.1769, beta=0.0000\n",
      "Batch 100, loss=0.0335, recon=0.0335, kl=106.8404, beta=0.0000\n",
      "Batch 120, loss=0.0528, recon=0.0528, kl=106.3742, beta=0.0000\n",
      "Batch 140, loss=0.0256, recon=0.0256, kl=107.7035, beta=0.0000\n",
      "Batch 160, loss=0.0392, recon=0.0392, kl=107.4625, beta=0.0000\n",
      "Batch 180, loss=0.0293, recon=0.0293, kl=105.5555, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0477 (Recon: 0.0477, KL: 108.0545, Current Beta: 0.0000) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0392\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0438, recon=0.0438, kl=103.2510, beta=0.0000\n",
      "Batch 40, loss=0.0374, recon=0.0374, kl=95.4104, beta=0.0000\n",
      "Batch 60, loss=0.0241, recon=0.0241, kl=96.6032, beta=0.0000\n",
      "Batch 80, loss=0.0370, recon=0.0370, kl=94.1490, beta=0.0000\n",
      "Batch 100, loss=0.0250, recon=0.0250, kl=94.9716, beta=0.0000\n",
      "Batch 120, loss=0.0219, recon=0.0219, kl=88.6139, beta=0.0000\n",
      "Batch 140, loss=0.0398, recon=0.0398, kl=86.5414, beta=0.0000\n",
      "Batch 160, loss=0.0246, recon=0.0246, kl=82.9630, beta=0.0000\n",
      "Batch 180, loss=0.1640, recon=0.1640, kl=85.3742, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 93.1791, Current Beta: 0.0000) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0380, recon=0.0380, kl=79.0222, beta=0.0000\n",
      "Batch 40, loss=0.0279, recon=0.0279, kl=75.2709, beta=0.0000\n",
      "Batch 60, loss=0.0362, recon=0.0361, kl=70.7479, beta=0.0000\n",
      "Batch 80, loss=0.0380, recon=0.0380, kl=73.8415, beta=0.0000\n",
      "Batch 100, loss=0.1658, recon=0.1658, kl=73.2720, beta=0.0000\n",
      "Batch 120, loss=0.0217, recon=0.0217, kl=68.8080, beta=0.0000\n",
      "Batch 140, loss=0.0245, recon=0.0245, kl=66.9224, beta=0.0000\n",
      "Batch 160, loss=0.0311, recon=0.0311, kl=66.3585, beta=0.0000\n",
      "Batch 180, loss=0.0627, recon=0.0627, kl=65.8236, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0409, KL: 72.2737, Current Beta: 0.0000) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0544, recon=0.0544, kl=56.5873, beta=0.0000\n",
      "Batch 40, loss=0.0472, recon=0.0472, kl=49.9854, beta=0.0000\n",
      "Batch 60, loss=0.0630, recon=0.0630, kl=45.3183, beta=0.0000\n",
      "Batch 80, loss=0.0367, recon=0.0367, kl=46.1177, beta=0.0000\n",
      "Batch 100, loss=0.0210, recon=0.0209, kl=45.4470, beta=0.0000\n",
      "Batch 120, loss=0.0342, recon=0.0342, kl=45.0439, beta=0.0000\n",
      "Batch 140, loss=0.0206, recon=0.0206, kl=46.3997, beta=0.0000\n",
      "Batch 160, loss=0.0320, recon=0.0319, kl=45.3698, beta=0.0000\n",
      "Batch 180, loss=0.0275, recon=0.0274, kl=43.4539, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0386, KL: 48.4460, Current Beta: 0.0000) | Avg Valid Loss: 0.0331 | Avg Valid recon Loss: 0.0331\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0372, recon=0.0372, kl=43.4877, beta=0.0000\n",
      "Batch 40, loss=0.0268, recon=0.0267, kl=36.0137, beta=0.0000\n",
      "Batch 60, loss=0.0223, recon=0.0223, kl=31.9831, beta=0.0000\n",
      "Batch 80, loss=0.0253, recon=0.0253, kl=29.9878, beta=0.0000\n",
      "Batch 100, loss=0.0287, recon=0.0287, kl=28.4888, beta=0.0000\n",
      "Batch 120, loss=0.0323, recon=0.0322, kl=28.1332, beta=0.0000\n",
      "Batch 140, loss=0.0300, recon=0.0300, kl=24.4576, beta=0.0000\n",
      "Batch 160, loss=0.0275, recon=0.0275, kl=26.4711, beta=0.0000\n",
      "Batch 180, loss=0.0225, recon=0.0225, kl=24.8674, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0373 (Recon: 0.0372, KL: 31.0376, Current Beta: 0.0000) | Avg Valid Loss: 0.0326 | Avg Valid recon Loss: 0.0326\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0258, recon=0.0257, kl=17.9925, beta=0.0000\n",
      "Batch 40, loss=0.0506, recon=0.0506, kl=14.3508, beta=0.0000\n",
      "Batch 60, loss=0.0253, recon=0.0252, kl=17.4735, beta=0.0000\n",
      "Batch 80, loss=0.1272, recon=0.1271, kl=13.2366, beta=0.0000\n",
      "Batch 100, loss=0.0218, recon=0.0218, kl=14.7377, beta=0.0000\n",
      "Batch 120, loss=0.0447, recon=0.0446, kl=11.2059, beta=0.0000\n",
      "Batch 140, loss=0.0395, recon=0.0395, kl=14.7172, beta=0.0000\n",
      "Batch 160, loss=0.0550, recon=0.0549, kl=13.0221, beta=0.0000\n",
      "Batch 180, loss=0.0226, recon=0.0226, kl=11.9709, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0360 (Recon: 0.0360, KL: 14.9515, Current Beta: 0.0000) | Avg Valid Loss: 0.0312 | Avg Valid recon Loss: 0.0312\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0263, recon=0.0263, kl=7.3046, beta=0.0000\n",
      "Batch 40, loss=0.0232, recon=0.0231, kl=6.8315, beta=0.0000\n",
      "Batch 60, loss=0.1481, recon=0.1480, kl=6.0058, beta=0.0000\n",
      "Batch 80, loss=0.0259, recon=0.0258, kl=9.6127, beta=0.0000\n",
      "Batch 100, loss=0.0299, recon=0.0298, kl=6.9088, beta=0.0000\n",
      "Batch 120, loss=0.0225, recon=0.0225, kl=6.9003, beta=0.0000\n",
      "Batch 140, loss=0.0248, recon=0.0247, kl=7.8395, beta=0.0000\n",
      "Batch 160, loss=0.0202, recon=0.0201, kl=6.0417, beta=0.0000\n",
      "Batch 180, loss=0.0255, recon=0.0255, kl=5.8364, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0347 (Recon: 0.0346, KL: 7.2117, Current Beta: 0.0000) | Avg Valid Loss: 0.0303 | Avg Valid recon Loss: 0.0302\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0269, recon=0.0268, kl=2.8338, beta=0.0000\n",
      "Batch 40, loss=0.0178, recon=0.0177, kl=2.9778, beta=0.0000\n",
      "Batch 60, loss=0.0193, recon=0.0192, kl=3.4105, beta=0.0000\n",
      "Batch 80, loss=0.0270, recon=0.0269, kl=3.1287, beta=0.0000\n",
      "Batch 100, loss=0.0229, recon=0.0229, kl=3.6785, beta=0.0000\n",
      "Batch 120, loss=0.0252, recon=0.0251, kl=2.3141, beta=0.0000\n",
      "Batch 140, loss=0.0253, recon=0.0253, kl=2.8257, beta=0.0000\n",
      "Batch 160, loss=0.0263, recon=0.0263, kl=2.4177, beta=0.0000\n",
      "Batch 180, loss=0.0276, recon=0.0275, kl=1.8708, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0339 (Recon: 0.0339, KL: 2.9936, Current Beta: 0.0000) | Avg Valid Loss: 0.0295 | Avg Valid recon Loss: 0.0295\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0268, recon=0.0267, kl=1.1383, beta=0.0000\n",
      "Batch 40, loss=0.0178, recon=0.0177, kl=1.0367, beta=0.0000\n",
      "Batch 60, loss=0.0201, recon=0.0200, kl=3.5524, beta=0.0000\n",
      "Batch 80, loss=0.0260, recon=0.0260, kl=0.9627, beta=0.0000\n",
      "Batch 100, loss=0.0203, recon=0.0203, kl=1.0647, beta=0.0000\n",
      "Batch 120, loss=0.0549, recon=0.0549, kl=0.9796, beta=0.0000\n",
      "Batch 140, loss=0.0221, recon=0.0220, kl=1.9481, beta=0.0000\n",
      "Batch 160, loss=0.0294, recon=0.0294, kl=0.7648, beta=0.0000\n",
      "Batch 180, loss=0.0307, recon=0.0307, kl=1.3248, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0331 (Recon: 0.0331, KL: 1.4121, Current Beta: 0.0000) | Avg Valid Loss: 0.0291 | Avg Valid recon Loss: 0.0290\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0330, recon=0.0330, kl=0.7276, beta=0.0001\n",
      "Batch 40, loss=0.0406, recon=0.0406, kl=0.6504, beta=0.0001\n",
      "Batch 60, loss=0.0268, recon=0.0267, kl=0.7251, beta=0.0001\n",
      "Batch 80, loss=0.0227, recon=0.0226, kl=0.7183, beta=0.0001\n",
      "Batch 100, loss=0.0253, recon=0.0253, kl=0.4525, beta=0.0001\n",
      "Batch 120, loss=0.0199, recon=0.0198, kl=0.8425, beta=0.0001\n",
      "Batch 140, loss=0.0249, recon=0.0249, kl=0.3608, beta=0.0001\n",
      "Batch 160, loss=0.0239, recon=0.0239, kl=0.5381, beta=0.0001\n",
      "Batch 180, loss=0.0348, recon=0.0348, kl=0.4087, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0337 (Recon: 0.0337, KL: 0.6429, Current Beta: 0.0001) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0307\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0286, recon=0.0286, kl=0.1810, beta=0.0001\n",
      "Batch 40, loss=0.0349, recon=0.0349, kl=0.2538, beta=0.0001\n",
      "Batch 60, loss=0.0262, recon=0.0262, kl=0.2524, beta=0.0001\n",
      "Batch 80, loss=0.0331, recon=0.0330, kl=0.4048, beta=0.0001\n",
      "Batch 100, loss=0.0165, recon=0.0165, kl=0.1075, beta=0.0001\n",
      "Batch 120, loss=0.0510, recon=0.0509, kl=0.1900, beta=0.0001\n",
      "Batch 140, loss=0.0236, recon=0.0236, kl=0.1943, beta=0.0001\n",
      "Batch 160, loss=0.0262, recon=0.0262, kl=0.1309, beta=0.0001\n",
      "Batch 180, loss=0.0230, recon=0.0230, kl=0.1125, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0341 (Recon: 0.0340, KL: 0.2158, Current Beta: 0.0001) | Avg Valid Loss: 0.0290 | Avg Valid recon Loss: 0.0290\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0436, recon=0.0436, kl=0.0822, beta=0.0001\n",
      "Batch 40, loss=0.0270, recon=0.0270, kl=0.1062, beta=0.0001\n",
      "Batch 60, loss=0.0235, recon=0.0235, kl=0.0677, beta=0.0001\n",
      "Batch 80, loss=0.0331, recon=0.0331, kl=0.1678, beta=0.0001\n",
      "Batch 100, loss=0.0262, recon=0.0262, kl=0.0951, beta=0.0001\n",
      "Batch 120, loss=0.0177, recon=0.0177, kl=0.0424, beta=0.0001\n",
      "Batch 140, loss=0.0313, recon=0.0313, kl=0.1806, beta=0.0001\n",
      "Batch 160, loss=0.0256, recon=0.0255, kl=0.2546, beta=0.0001\n",
      "Batch 180, loss=0.0282, recon=0.0281, kl=0.0738, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0318 (Recon: 0.0318, KL: 0.1182, Current Beta: 0.0001) | Avg Valid Loss: 0.0274 | Avg Valid recon Loss: 0.0274\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0174, recon=0.0174, kl=0.0583, beta=0.0001\n",
      "Batch 40, loss=0.0351, recon=0.0351, kl=0.3690, beta=0.0001\n",
      "Batch 60, loss=0.0228, recon=0.0228, kl=0.1458, beta=0.0001\n",
      "Batch 80, loss=0.0235, recon=0.0235, kl=0.0432, beta=0.0001\n",
      "Batch 100, loss=0.0337, recon=0.0337, kl=0.0406, beta=0.0001\n",
      "Batch 120, loss=0.0183, recon=0.0183, kl=0.0329, beta=0.0001\n",
      "Batch 140, loss=0.0488, recon=0.0488, kl=0.0304, beta=0.0001\n",
      "Batch 160, loss=0.0777, recon=0.0777, kl=0.0318, beta=0.0001\n",
      "Batch 180, loss=0.0470, recon=0.0470, kl=0.0629, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0313 (Recon: 0.0313, KL: 0.0842, Current Beta: 0.0001) | Avg Valid Loss: 0.0270 | Avg Valid recon Loss: 0.0270\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0202, recon=0.0202, kl=0.0780, beta=0.0001\n",
      "Batch 40, loss=0.0370, recon=0.0370, kl=0.0604, beta=0.0001\n",
      "Batch 60, loss=0.0239, recon=0.0239, kl=0.0493, beta=0.0001\n",
      "Batch 80, loss=0.0223, recon=0.0223, kl=0.0338, beta=0.0001\n",
      "Batch 100, loss=0.0225, recon=0.0225, kl=0.0294, beta=0.0001\n",
      "Batch 120, loss=0.0305, recon=0.0305, kl=0.0244, beta=0.0001\n",
      "Batch 140, loss=0.0202, recon=0.0202, kl=0.0267, beta=0.0001\n",
      "Batch 160, loss=0.0222, recon=0.0222, kl=0.0284, beta=0.0001\n",
      "Batch 180, loss=0.0313, recon=0.0313, kl=0.0388, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0305 (Recon: 0.0305, KL: 0.0437, Current Beta: 0.0001) | Avg Valid Loss: 0.0276 | Avg Valid recon Loss: 0.0275\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0370, recon=0.0370, kl=0.0357, beta=0.0001\n",
      "Batch 40, loss=0.1337, recon=0.1337, kl=0.0233, beta=0.0001\n",
      "Batch 60, loss=0.0255, recon=0.0255, kl=0.0178, beta=0.0001\n",
      "Batch 80, loss=0.0154, recon=0.0154, kl=0.0198, beta=0.0001\n",
      "Batch 100, loss=0.0233, recon=0.0233, kl=0.0163, beta=0.0001\n",
      "Batch 120, loss=0.0164, recon=0.0164, kl=0.0253, beta=0.0001\n",
      "Batch 140, loss=0.0209, recon=0.0209, kl=0.0245, beta=0.0001\n",
      "Batch 160, loss=0.0185, recon=0.0185, kl=0.0232, beta=0.0001\n",
      "Batch 180, loss=0.0230, recon=0.0230, kl=0.0204, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0301 (Recon: 0.0300, KL: 0.0241, Current Beta: 0.0001) | Avg Valid Loss: 0.0265 | Avg Valid recon Loss: 0.0265\n",
      " New best VRAE model found with validation loss: 0.0265\n",
      "   Model saved to ./ecg_model_logs\\best_vrae_model.pth\n",
      "\n",
      "[VRAE Run 34/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1216, recon=0.1216, kl=14.1159, beta=0.0000\n",
      "Batch 40, loss=0.0997, recon=0.0997, kl=40.7128, beta=0.0000\n",
      "Batch 60, loss=0.2257, recon=0.2257, kl=45.2314, beta=0.0000\n",
      "Batch 80, loss=0.0534, recon=0.0534, kl=40.7674, beta=0.0000\n",
      "Batch 100, loss=0.0595, recon=0.0595, kl=52.0078, beta=0.0000\n",
      "Batch 120, loss=0.0673, recon=0.0673, kl=40.8368, beta=0.0000\n",
      "Batch 140, loss=0.0732, recon=0.0732, kl=52.6508, beta=0.0000\n",
      "Batch 160, loss=0.0631, recon=0.0631, kl=55.2462, beta=0.0000\n",
      "Batch 180, loss=0.0591, recon=0.0591, kl=51.7279, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1276 (Recon: 0.1276, KL: 41.1486, Current Beta: 0.0000) | Avg Valid Loss: 0.0687 | Avg Valid recon Loss: 0.0687\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0496, recon=0.0496, kl=61.5059, beta=0.0000\n",
      "Batch 40, loss=0.1081, recon=0.1081, kl=82.0146, beta=0.0000\n",
      "Batch 60, loss=0.0311, recon=0.0311, kl=39.5395, beta=0.0000\n",
      "Batch 80, loss=0.0714, recon=0.0714, kl=64.9710, beta=0.0000\n",
      "Batch 100, loss=0.0274, recon=0.0274, kl=68.1792, beta=0.0000\n",
      "Batch 120, loss=0.0598, recon=0.0598, kl=70.5413, beta=0.0000\n",
      "Batch 140, loss=0.0512, recon=0.0512, kl=70.8221, beta=0.0000\n",
      "Batch 160, loss=0.0726, recon=0.0726, kl=71.3334, beta=0.0000\n",
      "Batch 180, loss=0.1007, recon=0.1007, kl=72.8448, beta=0.0000\n",
      "  â†’ Avg Train Loss: 3.8721 (Recon: 3.8721, KL: 218.1395, Current Beta: 0.0000) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0408, recon=0.0408, kl=74.0773, beta=0.0000\n",
      "Batch 40, loss=0.0301, recon=0.0301, kl=76.4961, beta=0.0000\n",
      "Batch 60, loss=0.0277, recon=0.0277, kl=76.6377, beta=0.0000\n",
      "Batch 80, loss=0.0327, recon=0.0327, kl=77.6364, beta=0.0000\n",
      "Batch 100, loss=0.0335, recon=0.0335, kl=80.2015, beta=0.0000\n",
      "Batch 120, loss=0.0254, recon=0.0254, kl=81.1423, beta=0.0000\n",
      "Batch 140, loss=0.0634, recon=0.0634, kl=82.5489, beta=0.0000\n",
      "Batch 160, loss=0.0449, recon=0.0449, kl=82.4786, beta=0.0000\n",
      "Batch 180, loss=0.0371, recon=0.0371, kl=82.3495, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 78.8297, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0234, recon=0.0234, kl=83.1899, beta=0.0000\n",
      "Batch 40, loss=0.0344, recon=0.0344, kl=84.3520, beta=0.0000\n",
      "Batch 60, loss=0.0402, recon=0.0402, kl=84.0314, beta=0.0000\n",
      "Batch 80, loss=0.0306, recon=0.0306, kl=84.1201, beta=0.0000\n",
      "Batch 100, loss=0.0376, recon=0.0376, kl=83.9432, beta=0.0000\n",
      "Batch 120, loss=0.0270, recon=0.0270, kl=85.7280, beta=0.0000\n",
      "Batch 140, loss=0.0523, recon=0.0523, kl=85.3275, beta=0.0000\n",
      "Batch 160, loss=0.0527, recon=0.0527, kl=85.4279, beta=0.0000\n",
      "Batch 180, loss=0.0672, recon=0.0672, kl=87.7755, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0516, KL: 84.5762, Current Beta: 0.0000) | Avg Valid Loss: 0.0669 | Avg Valid recon Loss: 0.0669\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0502, recon=0.0502, kl=84.1807, beta=0.0000\n",
      "Batch 40, loss=0.0445, recon=0.0445, kl=84.6037, beta=0.0000\n",
      "Batch 60, loss=0.0328, recon=0.0328, kl=85.6580, beta=0.0000\n",
      "Batch 80, loss=0.0396, recon=0.0396, kl=86.7274, beta=0.0000\n",
      "Batch 100, loss=0.0270, recon=0.0270, kl=87.2430, beta=0.0000\n",
      "Batch 120, loss=0.0246, recon=0.0246, kl=88.3125, beta=0.0000\n",
      "Batch 140, loss=0.0268, recon=0.0268, kl=88.6461, beta=0.0000\n",
      "Batch 160, loss=0.0600, recon=0.0600, kl=89.3039, beta=0.0000\n",
      "Batch 180, loss=0.0328, recon=0.0328, kl=89.3282, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0520 (Recon: 0.0520, KL: 86.8924, Current Beta: 0.0000) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0653, recon=0.0653, kl=90.4254, beta=0.0000\n",
      "Batch 40, loss=0.0212, recon=0.0212, kl=90.0327, beta=0.0000\n",
      "Batch 60, loss=0.0343, recon=0.0343, kl=90.8817, beta=0.0000\n",
      "Batch 80, loss=0.0518, recon=0.0518, kl=91.1447, beta=0.0000\n",
      "Batch 100, loss=0.0219, recon=0.0219, kl=91.2900, beta=0.0000\n",
      "Batch 120, loss=0.0338, recon=0.0338, kl=91.4759, beta=0.0000\n",
      "Batch 140, loss=0.0341, recon=0.0341, kl=91.3903, beta=0.0000\n",
      "Batch 160, loss=0.0366, recon=0.0366, kl=90.6681, beta=0.0000\n",
      "Batch 180, loss=0.0416, recon=0.0416, kl=89.8999, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0426 (Recon: 0.0426, KL: 90.8814, Current Beta: 0.0000) | Avg Valid Loss: 0.0416 | Avg Valid recon Loss: 0.0416\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0321, recon=0.0321, kl=89.3089, beta=0.0000\n",
      "Batch 40, loss=0.0324, recon=0.0324, kl=88.1518, beta=0.0000\n",
      "Batch 60, loss=0.0540, recon=0.0540, kl=88.8565, beta=0.0000\n",
      "Batch 80, loss=0.0325, recon=0.0325, kl=84.9871, beta=0.0000\n",
      "Batch 100, loss=0.0294, recon=0.0294, kl=85.3677, beta=0.0000\n",
      "Batch 120, loss=0.0273, recon=0.0273, kl=87.3684, beta=0.0000\n",
      "Batch 140, loss=0.0298, recon=0.0298, kl=88.3961, beta=0.0000\n",
      "Batch 160, loss=0.0276, recon=0.0276, kl=88.9416, beta=0.0000\n",
      "Batch 180, loss=0.0375, recon=0.0375, kl=88.8483, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0473, KL: 87.9749, Current Beta: 0.0000) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0410, recon=0.0410, kl=88.7814, beta=0.0000\n",
      "Batch 40, loss=0.0370, recon=0.0370, kl=84.8116, beta=0.0000\n",
      "Batch 60, loss=0.0334, recon=0.0333, kl=83.6977, beta=0.0000\n",
      "Batch 80, loss=0.0417, recon=0.0417, kl=84.7333, beta=0.0000\n",
      "Batch 100, loss=0.0359, recon=0.0359, kl=83.4100, beta=0.0000\n",
      "Batch 120, loss=0.0447, recon=0.0447, kl=84.1160, beta=0.0000\n",
      "Batch 140, loss=0.0268, recon=0.0268, kl=86.0406, beta=0.0000\n",
      "Batch 160, loss=0.0733, recon=0.0733, kl=85.8519, beta=0.0000\n",
      "Batch 180, loss=0.0266, recon=0.0266, kl=79.1042, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0542 (Recon: 0.0542, KL: 84.8338, Current Beta: 0.0000) | Avg Valid Loss: 0.0512 | Avg Valid recon Loss: 0.0512\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0304, recon=0.0304, kl=81.6954, beta=0.0000\n",
      "Batch 40, loss=0.0279, recon=0.0278, kl=81.3762, beta=0.0000\n",
      "Batch 60, loss=0.0302, recon=0.0302, kl=84.3941, beta=0.0000\n",
      "Batch 80, loss=0.0644, recon=0.0644, kl=74.4625, beta=0.0000\n",
      "Batch 100, loss=0.0289, recon=0.0288, kl=82.7458, beta=0.0000\n",
      "Batch 120, loss=0.0319, recon=0.0318, kl=84.9814, beta=0.0000\n",
      "Batch 140, loss=0.0491, recon=0.0491, kl=86.1658, beta=0.0000\n",
      "Batch 160, loss=0.0473, recon=0.0472, kl=78.1159, beta=0.0000\n",
      "Batch 180, loss=0.0520, recon=0.0520, kl=82.4946, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0534, KL: 81.6981, Current Beta: 0.0000) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0401, recon=0.0400, kl=81.6159, beta=0.0000\n",
      "Batch 40, loss=0.0253, recon=0.0252, kl=79.2161, beta=0.0000\n",
      "Batch 60, loss=0.0311, recon=0.0310, kl=79.0092, beta=0.0000\n",
      "Batch 80, loss=0.0311, recon=0.0311, kl=78.9295, beta=0.0000\n",
      "Batch 100, loss=0.0257, recon=0.0257, kl=69.9785, beta=0.0000\n",
      "Batch 120, loss=0.1319, recon=0.1318, kl=59.9854, beta=0.0000\n",
      "Batch 140, loss=0.0495, recon=0.0494, kl=66.1606, beta=0.0000\n",
      "Batch 160, loss=0.1035, recon=0.1034, kl=66.5970, beta=0.0000\n",
      "Batch 180, loss=0.0499, recon=0.0498, kl=71.1352, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0591 (Recon: 0.0590, KL: 73.0829, Current Beta: 0.0000) | Avg Valid Loss: 0.0633 | Avg Valid recon Loss: 0.0632\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0341, recon=0.0338, kl=73.0898, beta=0.0000\n",
      "Batch 40, loss=0.0700, recon=0.0698, kl=79.9971, beta=0.0000\n",
      "Batch 60, loss=0.1369, recon=0.1366, kl=80.6665, beta=0.0000\n",
      "Batch 80, loss=0.0485, recon=0.0482, kl=82.0162, beta=0.0000\n",
      "Batch 100, loss=0.0245, recon=0.0243, kl=82.0445, beta=0.0000\n",
      "Batch 120, loss=0.0323, recon=0.0320, kl=82.2491, beta=0.0000\n",
      "Batch 140, loss=0.0396, recon=0.0394, kl=82.6915, beta=0.0000\n",
      "Batch 160, loss=0.0454, recon=0.0451, kl=82.9906, beta=0.0000\n",
      "Batch 180, loss=0.0400, recon=0.0398, kl=84.2865, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0471, KL: 80.6192, Current Beta: 0.0000) | Avg Valid Loss: 0.0611 | Avg Valid recon Loss: 0.0609\n",
      "Epoch 12/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 13/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 14/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 35/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3978, recon=0.3978, kl=8.6244, beta=0.0000\n",
      "Batch 40, loss=0.1755, recon=0.1755, kl=51.7819, beta=0.0000\n",
      "Batch 60, loss=0.2064, recon=0.2064, kl=85.3299, beta=0.0000\n",
      "Batch 80, loss=0.1302, recon=0.1302, kl=105.7099, beta=0.0000\n",
      "Batch 100, loss=0.1351, recon=0.1351, kl=112.7059, beta=0.0000\n",
      "Batch 120, loss=0.1918, recon=0.1918, kl=125.4174, beta=0.0000\n",
      "Batch 140, loss=0.1074, recon=0.1074, kl=132.9967, beta=0.0000\n",
      "Batch 160, loss=0.0861, recon=0.0861, kl=133.6124, beta=0.0000\n",
      "Batch 180, loss=0.0900, recon=0.0900, kl=129.1090, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2043 (Recon: 0.2043, KL: 92.0477, Current Beta: 0.0000) | Avg Valid Loss: 0.0913 | Avg Valid recon Loss: 0.0913\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1409, recon=0.1409, kl=138.1691, beta=0.0000\n",
      "Batch 40, loss=0.0695, recon=0.0695, kl=139.0964, beta=0.0000\n",
      "Batch 60, loss=0.0599, recon=0.0599, kl=141.7813, beta=0.0000\n",
      "Batch 80, loss=0.0892, recon=0.0892, kl=142.1157, beta=0.0000\n",
      "Batch 100, loss=0.0740, recon=0.0740, kl=146.3317, beta=0.0000\n",
      "Batch 120, loss=0.0562, recon=0.0562, kl=150.8832, beta=0.0000\n",
      "Batch 140, loss=0.1047, recon=0.1047, kl=151.8837, beta=0.0000\n",
      "Batch 160, loss=0.0543, recon=0.0543, kl=154.9171, beta=0.0000\n",
      "Batch 180, loss=0.0735, recon=0.0735, kl=156.4831, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0933 (Recon: 0.0933, KL: 145.5907, Current Beta: 0.0000) | Avg Valid Loss: 0.0639 | Avg Valid recon Loss: 0.0639\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0551, recon=0.0551, kl=157.0855, beta=0.0000\n",
      "Batch 40, loss=0.0791, recon=0.0791, kl=152.5412, beta=0.0000\n",
      "Batch 60, loss=0.0505, recon=0.0505, kl=156.9141, beta=0.0000\n",
      "Batch 80, loss=0.0522, recon=0.0522, kl=161.1636, beta=0.0000\n",
      "Batch 100, loss=0.0632, recon=0.0632, kl=167.3658, beta=0.0000\n",
      "Batch 120, loss=0.0530, recon=0.0530, kl=167.2434, beta=0.0000\n",
      "Batch 140, loss=0.0301, recon=0.0301, kl=171.1690, beta=0.0000\n",
      "Batch 160, loss=0.0575, recon=0.0575, kl=159.6260, beta=0.0000\n",
      "Batch 180, loss=0.0505, recon=0.0505, kl=164.2428, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0708 (Recon: 0.0708, KL: 161.7151, Current Beta: 0.0000) | Avg Valid Loss: 0.0550 | Avg Valid recon Loss: 0.0550\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0388, recon=0.0388, kl=165.4221, beta=0.0000\n",
      "Batch 40, loss=0.0474, recon=0.0474, kl=170.9682, beta=0.0000\n",
      "Batch 60, loss=0.0335, recon=0.0335, kl=173.9560, beta=0.0000\n",
      "Batch 80, loss=0.0873, recon=0.0873, kl=168.8945, beta=0.0000\n",
      "Batch 100, loss=0.0454, recon=0.0454, kl=174.8735, beta=0.0000\n",
      "Batch 120, loss=0.0252, recon=0.0252, kl=177.7081, beta=0.0000\n",
      "Batch 140, loss=0.0481, recon=0.0481, kl=186.1695, beta=0.0000\n",
      "Batch 160, loss=0.0566, recon=0.0566, kl=169.7620, beta=0.0000\n",
      "Batch 180, loss=0.0371, recon=0.0371, kl=170.7734, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0599 (Recon: 0.0599, KL: 172.2747, Current Beta: 0.0000) | Avg Valid Loss: 0.0481 | Avg Valid recon Loss: 0.0481\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0430, recon=0.0430, kl=173.5953, beta=0.0000\n",
      "Batch 40, loss=0.1861, recon=0.1861, kl=169.9417, beta=0.0000\n",
      "Batch 60, loss=0.0380, recon=0.0380, kl=168.1548, beta=0.0000\n",
      "Batch 80, loss=0.0299, recon=0.0299, kl=166.4929, beta=0.0000\n",
      "Batch 100, loss=0.0323, recon=0.0322, kl=165.8407, beta=0.0000\n",
      "Batch 120, loss=0.0666, recon=0.0666, kl=166.9612, beta=0.0000\n",
      "Batch 140, loss=0.0485, recon=0.0485, kl=163.1623, beta=0.0000\n",
      "Batch 160, loss=0.0449, recon=0.0449, kl=171.5258, beta=0.0000\n",
      "Batch 180, loss=0.0628, recon=0.0628, kl=167.2699, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0533, KL: 167.9226, Current Beta: 0.0000) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0450\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0494, recon=0.0494, kl=163.6952, beta=0.0000\n",
      "Batch 40, loss=0.7942, recon=0.7942, kl=165.3486, beta=0.0000\n",
      "Batch 60, loss=0.0397, recon=0.0397, kl=167.7444, beta=0.0000\n",
      "Batch 80, loss=0.0323, recon=0.0323, kl=166.2453, beta=0.0000\n",
      "Batch 100, loss=0.0329, recon=0.0329, kl=163.4261, beta=0.0000\n",
      "Batch 120, loss=0.0306, recon=0.0306, kl=162.9711, beta=0.0000\n",
      "Batch 140, loss=0.0331, recon=0.0331, kl=161.6298, beta=0.0000\n",
      "Batch 160, loss=0.0286, recon=0.0286, kl=161.6779, beta=0.0000\n",
      "Batch 180, loss=0.0369, recon=0.0369, kl=159.2375, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0480, KL: 163.9435, Current Beta: 0.0000) | Avg Valid Loss: 0.0396 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0231, recon=0.0231, kl=157.1532, beta=0.0000\n",
      "Batch 40, loss=0.0286, recon=0.0286, kl=153.4599, beta=0.0000\n",
      "Batch 60, loss=0.0417, recon=0.0417, kl=149.5409, beta=0.0000\n",
      "Batch 80, loss=0.0413, recon=0.0413, kl=145.0724, beta=0.0000\n",
      "Batch 100, loss=0.0309, recon=0.0309, kl=142.7483, beta=0.0000\n",
      "Batch 120, loss=0.0284, recon=0.0284, kl=146.9829, beta=0.0000\n",
      "Batch 140, loss=0.0538, recon=0.0538, kl=140.3412, beta=0.0000\n",
      "Batch 160, loss=0.0441, recon=0.0441, kl=136.4104, beta=0.0000\n",
      "Batch 180, loss=0.0216, recon=0.0216, kl=140.4709, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0440, KL: 146.3787, Current Beta: 0.0000) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0319, recon=0.0319, kl=126.7074, beta=0.0000\n",
      "Batch 40, loss=0.0362, recon=0.0362, kl=120.5092, beta=0.0000\n",
      "Batch 60, loss=0.0286, recon=0.0286, kl=113.6633, beta=0.0000\n",
      "Batch 80, loss=0.0270, recon=0.0270, kl=111.6581, beta=0.0000\n",
      "Batch 100, loss=0.0302, recon=0.0302, kl=106.8798, beta=0.0000\n",
      "Batch 120, loss=0.0183, recon=0.0182, kl=106.5748, beta=0.0000\n",
      "Batch 140, loss=0.0515, recon=0.0515, kl=102.3427, beta=0.0000\n",
      "Batch 160, loss=0.0372, recon=0.0372, kl=104.5708, beta=0.0000\n",
      "Batch 180, loss=0.0295, recon=0.0295, kl=100.0783, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0410, KL: 112.1132, Current Beta: 0.0000) | Avg Valid Loss: 0.0348 | Avg Valid recon Loss: 0.0348\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0694, recon=0.0693, kl=90.4973, beta=0.0000\n",
      "Batch 40, loss=0.0358, recon=0.0358, kl=84.0662, beta=0.0000\n",
      "Batch 60, loss=0.0436, recon=0.0436, kl=74.8707, beta=0.0000\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=70.8334, beta=0.0000\n",
      "Batch 100, loss=0.0267, recon=0.0267, kl=70.3398, beta=0.0000\n",
      "Batch 120, loss=0.0238, recon=0.0238, kl=69.9372, beta=0.0000\n",
      "Batch 140, loss=0.0417, recon=0.0417, kl=70.5595, beta=0.0000\n",
      "Batch 160, loss=0.0208, recon=0.0208, kl=66.9470, beta=0.0000\n",
      "Batch 180, loss=0.0282, recon=0.0282, kl=64.7495, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0389, KL: 75.4286, Current Beta: 0.0000) | Avg Valid Loss: 0.0331 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0240, recon=0.0239, kl=51.2102, beta=0.0000\n",
      "Batch 40, loss=0.0211, recon=0.0211, kl=35.8351, beta=0.0000\n",
      "Batch 60, loss=0.0268, recon=0.0268, kl=41.7202, beta=0.0000\n",
      "Batch 80, loss=0.1049, recon=0.1049, kl=40.1996, beta=0.0000\n",
      "Batch 100, loss=0.0383, recon=0.0383, kl=38.8402, beta=0.0000\n",
      "Batch 120, loss=0.0311, recon=0.0310, kl=39.8033, beta=0.0000\n",
      "Batch 140, loss=0.0300, recon=0.0300, kl=35.7587, beta=0.0000\n",
      "Batch 160, loss=0.0432, recon=0.0432, kl=36.1611, beta=0.0000\n",
      "Batch 180, loss=0.0503, recon=0.0503, kl=34.8405, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0369, KL: 41.1181, Current Beta: 0.0000) | Avg Valid Loss: 0.0323 | Avg Valid recon Loss: 0.0322\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0258, recon=0.0258, kl=20.6502, beta=0.0000\n",
      "Batch 40, loss=0.0310, recon=0.0309, kl=17.1579, beta=0.0000\n",
      "Batch 60, loss=0.0519, recon=0.0518, kl=20.7651, beta=0.0000\n",
      "Batch 80, loss=0.0249, recon=0.0249, kl=16.0210, beta=0.0000\n",
      "Batch 100, loss=0.0261, recon=0.0260, kl=18.4390, beta=0.0000\n",
      "Batch 120, loss=0.0238, recon=0.0238, kl=18.8268, beta=0.0000\n",
      "Batch 140, loss=0.0174, recon=0.0174, kl=16.2196, beta=0.0000\n",
      "Batch 160, loss=0.0280, recon=0.0280, kl=16.1962, beta=0.0000\n",
      "Batch 180, loss=0.0273, recon=0.0272, kl=15.6970, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0357 (Recon: 0.0357, KL: 18.9845, Current Beta: 0.0000) | Avg Valid Loss: 0.0310 | Avg Valid recon Loss: 0.0310\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0277, recon=0.0277, kl=6.5660, beta=0.0000\n",
      "Batch 40, loss=0.0582, recon=0.0581, kl=7.7483, beta=0.0000\n",
      "Batch 60, loss=0.0599, recon=0.0598, kl=6.9008, beta=0.0000\n",
      "Batch 80, loss=0.1251, recon=0.1251, kl=6.7932, beta=0.0000\n",
      "Batch 100, loss=0.0269, recon=0.0268, kl=6.5438, beta=0.0000\n",
      "Batch 120, loss=0.0228, recon=0.0227, kl=5.9747, beta=0.0000\n",
      "Batch 140, loss=0.0181, recon=0.0181, kl=5.3020, beta=0.0000\n",
      "Batch 160, loss=0.0229, recon=0.0229, kl=5.9073, beta=0.0000\n",
      "Batch 180, loss=0.0859, recon=0.0859, kl=5.5749, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0345 (Recon: 0.0345, KL: 6.8578, Current Beta: 0.0000) | Avg Valid Loss: 0.0311 | Avg Valid recon Loss: 0.0311\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0218, recon=0.0217, kl=4.1113, beta=0.0000\n",
      "Batch 40, loss=0.0242, recon=0.0241, kl=3.5146, beta=0.0000\n",
      "Batch 60, loss=0.0232, recon=0.0232, kl=2.6540, beta=0.0000\n",
      "Batch 80, loss=0.0204, recon=0.0204, kl=2.5720, beta=0.0000\n",
      "Batch 100, loss=0.0250, recon=0.0249, kl=2.7281, beta=0.0000\n",
      "Batch 120, loss=0.0323, recon=0.0323, kl=3.1938, beta=0.0000\n",
      "Batch 140, loss=0.0224, recon=0.0223, kl=2.2647, beta=0.0000\n",
      "Batch 160, loss=0.0210, recon=0.0210, kl=2.6619, beta=0.0000\n",
      "Batch 180, loss=0.0267, recon=0.0267, kl=2.6188, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0338 (Recon: 0.0337, KL: 3.0720, Current Beta: 0.0000) | Avg Valid Loss: 0.0299 | Avg Valid recon Loss: 0.0299\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0202, recon=0.0201, kl=1.0739, beta=0.0000\n",
      "Batch 40, loss=0.0466, recon=0.0466, kl=1.9922, beta=0.0000\n",
      "Batch 60, loss=0.0297, recon=0.0296, kl=1.0591, beta=0.0000\n",
      "Batch 80, loss=0.0346, recon=0.0346, kl=1.7015, beta=0.0000\n",
      "Batch 100, loss=0.0218, recon=0.0218, kl=1.0397, beta=0.0000\n",
      "Batch 120, loss=0.0163, recon=0.0163, kl=1.1481, beta=0.0000\n",
      "Batch 140, loss=0.0380, recon=0.0379, kl=1.2882, beta=0.0000\n",
      "Batch 160, loss=0.0378, recon=0.0377, kl=1.2214, beta=0.0000\n",
      "Batch 180, loss=0.0631, recon=0.0631, kl=0.9684, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0331 (Recon: 0.0331, KL: 1.3592, Current Beta: 0.0000) | Avg Valid Loss: 0.0287 | Avg Valid recon Loss: 0.0287\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0207, recon=0.0207, kl=0.5477, beta=0.0001\n",
      "Batch 40, loss=0.0211, recon=0.0211, kl=0.9032, beta=0.0001\n",
      "Batch 60, loss=0.0396, recon=0.0395, kl=0.6341, beta=0.0001\n",
      "Batch 80, loss=0.0222, recon=0.0222, kl=0.5098, beta=0.0001\n",
      "Batch 100, loss=0.0242, recon=0.0242, kl=0.4097, beta=0.0001\n",
      "Batch 120, loss=0.0185, recon=0.0185, kl=0.6635, beta=0.0001\n",
      "Batch 140, loss=0.0273, recon=0.0272, kl=0.7105, beta=0.0001\n",
      "Batch 160, loss=0.0285, recon=0.0284, kl=0.4195, beta=0.0001\n",
      "Batch 180, loss=0.0290, recon=0.0290, kl=0.3233, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0322 (Recon: 0.0322, KL: 0.6321, Current Beta: 0.0001) | Avg Valid Loss: 0.0290 | Avg Valid recon Loss: 0.0290\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0421, recon=0.0421, kl=0.2765, beta=0.0001\n",
      "Batch 40, loss=0.0199, recon=0.0199, kl=0.2135, beta=0.0001\n",
      "Batch 60, loss=0.0235, recon=0.0235, kl=0.2137, beta=0.0001\n",
      "Batch 80, loss=0.0191, recon=0.0191, kl=0.3213, beta=0.0001\n",
      "Batch 100, loss=0.0271, recon=0.0271, kl=0.2176, beta=0.0001\n",
      "Batch 120, loss=0.0213, recon=0.0213, kl=0.2396, beta=0.0001\n",
      "Batch 140, loss=0.0241, recon=0.0240, kl=0.1516, beta=0.0001\n",
      "Batch 160, loss=0.0517, recon=0.0517, kl=0.1616, beta=0.0001\n",
      "Batch 180, loss=0.0268, recon=0.0268, kl=0.1496, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0324 (Recon: 0.0323, KL: 0.2210, Current Beta: 0.0001) | Avg Valid Loss: 0.0282 | Avg Valid recon Loss: 0.0282\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0327, recon=0.0327, kl=0.0735, beta=0.0001\n",
      "Batch 40, loss=0.0251, recon=0.0251, kl=0.0872, beta=0.0001\n",
      "Batch 60, loss=0.0677, recon=0.0676, kl=0.0945, beta=0.0001\n",
      "Batch 80, loss=0.0230, recon=0.0230, kl=0.1430, beta=0.0001\n",
      "Batch 100, loss=0.0219, recon=0.0219, kl=0.1024, beta=0.0001\n",
      "Batch 120, loss=0.0292, recon=0.0292, kl=0.0705, beta=0.0001\n",
      "Batch 140, loss=0.0182, recon=0.0181, kl=0.1799, beta=0.0001\n",
      "Batch 160, loss=0.0401, recon=0.0401, kl=0.0921, beta=0.0001\n",
      "Batch 180, loss=0.0234, recon=0.0234, kl=0.0748, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0321 (Recon: 0.0321, KL: 0.1041, Current Beta: 0.0001) | Avg Valid Loss: 0.0276 | Avg Valid recon Loss: 0.0276\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0323, recon=0.0323, kl=0.0639, beta=0.0001\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=0.0483, beta=0.0001\n",
      "Batch 60, loss=0.0284, recon=0.0284, kl=0.0958, beta=0.0001\n",
      "Batch 80, loss=0.0881, recon=0.0881, kl=0.0975, beta=0.0001\n",
      "Batch 100, loss=0.0229, recon=0.0229, kl=0.0660, beta=0.0001\n",
      "Batch 120, loss=0.0488, recon=0.0488, kl=0.0597, beta=0.0001\n",
      "Batch 140, loss=0.0305, recon=0.0305, kl=0.0498, beta=0.0001\n",
      "Batch 160, loss=0.0357, recon=0.0357, kl=0.0366, beta=0.0001\n",
      "Batch 180, loss=0.0290, recon=0.0289, kl=0.0430, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0307 (Recon: 0.0307, KL: 0.0624, Current Beta: 0.0001) | Avg Valid Loss: 0.0266 | Avg Valid recon Loss: 0.0266\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0265, recon=0.0265, kl=0.0426, beta=0.0001\n",
      "Batch 40, loss=0.0244, recon=0.0244, kl=0.0304, beta=0.0001\n",
      "Batch 60, loss=0.0207, recon=0.0207, kl=0.0282, beta=0.0001\n",
      "Batch 80, loss=0.0326, recon=0.0326, kl=0.0244, beta=0.0001\n",
      "Batch 100, loss=0.0255, recon=0.0255, kl=0.0310, beta=0.0001\n",
      "Batch 120, loss=0.0317, recon=0.0317, kl=0.0761, beta=0.0001\n",
      "Batch 140, loss=0.0218, recon=0.0218, kl=0.0585, beta=0.0001\n",
      "Batch 160, loss=0.0161, recon=0.0161, kl=0.0429, beta=0.0001\n",
      "Batch 180, loss=0.0440, recon=0.0440, kl=0.0350, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0305 (Recon: 0.0305, KL: 0.0426, Current Beta: 0.0001) | Avg Valid Loss: 0.0266 | Avg Valid recon Loss: 0.0266\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0336, recon=0.0336, kl=0.0602, beta=0.0001\n",
      "Batch 40, loss=0.0226, recon=0.0226, kl=0.0485, beta=0.0001\n",
      "Batch 60, loss=0.0309, recon=0.0309, kl=0.0363, beta=0.0001\n",
      "Batch 80, loss=0.0181, recon=0.0181, kl=0.0314, beta=0.0001\n",
      "Batch 100, loss=0.0224, recon=0.0224, kl=0.0270, beta=0.0001\n",
      "Batch 120, loss=0.0274, recon=0.0274, kl=0.0266, beta=0.0001\n",
      "Batch 140, loss=0.0183, recon=0.0183, kl=0.0215, beta=0.0001\n",
      "Batch 160, loss=0.0321, recon=0.0321, kl=0.0221, beta=0.0001\n",
      "Batch 180, loss=0.0221, recon=0.0221, kl=0.0226, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0295 (Recon: 0.0295, KL: 0.0331, Current Beta: 0.0001) | Avg Valid Loss: 0.0273 | Avg Valid recon Loss: 0.0273\n",
      "\n",
      "[VRAE Run 36/324] Training with params: {'batch_size': 32, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1101, recon=0.1101, kl=71.2243, beta=0.0000\n",
      "Batch 40, loss=0.3645, recon=0.3645, kl=73.4122, beta=0.0000\n",
      "Batch 60, loss=0.0632, recon=0.0632, kl=101.6310, beta=0.0000\n",
      "Batch 80, loss=0.0807, recon=0.0807, kl=101.6851, beta=0.0000\n",
      "Batch 100, loss=0.0768, recon=0.0768, kl=117.3946, beta=0.0000\n",
      "Batch 120, loss=0.0522, recon=0.0522, kl=101.8896, beta=0.0000\n",
      "Batch 140, loss=0.0567, recon=0.0567, kl=121.4172, beta=0.0000\n",
      "Batch 160, loss=0.0446, recon=0.0446, kl=133.4456, beta=0.0000\n",
      "Batch 180, loss=0.0414, recon=0.0414, kl=127.5390, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1131 (Recon: 0.1131, KL: 98.8805, Current Beta: 0.0000) | Avg Valid Loss: 0.0533 | Avg Valid recon Loss: 0.0533\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0648, recon=0.0648, kl=99.0790, beta=0.0000\n",
      "Batch 40, loss=0.0324, recon=0.0324, kl=102.5274, beta=0.0000\n",
      "Batch 60, loss=0.0658, recon=0.0658, kl=100.5336, beta=0.0000\n",
      "Batch 80, loss=0.0734, recon=0.0734, kl=94.3781, beta=0.0000\n",
      "Batch 100, loss=0.0380, recon=0.0380, kl=131.1945, beta=0.0000\n",
      "Batch 120, loss=0.0379, recon=0.0379, kl=138.8116, beta=0.0000\n",
      "Batch 140, loss=0.0290, recon=0.0290, kl=141.9271, beta=0.0000\n",
      "Batch 160, loss=0.0412, recon=0.0412, kl=149.0971, beta=0.0000\n",
      "Batch 180, loss=0.0389, recon=0.0389, kl=150.2451, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0605 (Recon: 0.0605, KL: 121.6340, Current Beta: 0.0000) | Avg Valid Loss: 0.0582 | Avg Valid recon Loss: 0.0582\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0809, recon=0.0809, kl=143.6512, beta=0.0000\n",
      "Batch 40, loss=0.0461, recon=0.0461, kl=122.7483, beta=0.0000\n",
      "Batch 60, loss=0.0394, recon=0.0394, kl=124.9291, beta=0.0000\n",
      "Batch 80, loss=0.0382, recon=0.0382, kl=122.0187, beta=0.0000\n",
      "Batch 100, loss=0.0390, recon=0.0390, kl=136.2094, beta=0.0000\n",
      "Batch 120, loss=0.0306, recon=0.0306, kl=144.5112, beta=0.0000\n",
      "Batch 140, loss=0.0327, recon=0.0327, kl=141.2974, beta=0.0000\n",
      "Batch 160, loss=0.0298, recon=0.0298, kl=113.6761, beta=0.0000\n",
      "Batch 180, loss=0.0327, recon=0.0327, kl=121.6522, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0545, KL: 130.8625, Current Beta: 0.0000) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0275, recon=0.0275, kl=140.2149, beta=0.0000\n",
      "Batch 40, loss=0.0300, recon=0.0300, kl=126.1324, beta=0.0000\n",
      "Batch 60, loss=0.0553, recon=0.0553, kl=109.2848, beta=0.0000\n",
      "Batch 80, loss=0.0335, recon=0.0335, kl=168.4640, beta=0.0000\n",
      "Batch 100, loss=0.0305, recon=0.0305, kl=126.7901, beta=0.0000\n",
      "Batch 120, loss=0.0310, recon=0.0310, kl=125.0993, beta=0.0000\n",
      "Batch 140, loss=0.0338, recon=0.0338, kl=134.5517, beta=0.0000\n",
      "Batch 160, loss=0.0415, recon=0.0415, kl=147.5908, beta=0.0000\n",
      "Batch 180, loss=0.8190, recon=0.8190, kl=151.7010, beta=0.0000\n",
      "  â†’ Avg Train Loss: 1255.4736 (Recon: 1255.4735, KL: 39031.0835, Current Beta: 0.0000) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0572, recon=0.0572, kl=155.4063, beta=0.0000\n",
      "Batch 40, loss=0.0347, recon=0.0347, kl=154.6768, beta=0.0000\n",
      "Batch 60, loss=0.7040, recon=0.7040, kl=155.9773, beta=0.0000\n",
      "Batch 80, loss=0.0395, recon=0.0395, kl=158.2148, beta=0.0000\n",
      "Batch 100, loss=0.0381, recon=0.0381, kl=159.1973, beta=0.0000\n",
      "Batch 120, loss=0.0215, recon=0.0215, kl=160.4787, beta=0.0000\n",
      "Batch 140, loss=0.0691, recon=0.0691, kl=168.2511, beta=0.0000\n",
      "Batch 160, loss=0.0326, recon=0.0326, kl=168.0426, beta=0.0000\n",
      "Batch 180, loss=0.0637, recon=0.0637, kl=170.8109, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0530 (Recon: 0.0530, KL: 160.0282, Current Beta: 0.0000) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0334, recon=0.0334, kl=165.6661, beta=0.0000\n",
      "Batch 40, loss=0.0368, recon=0.0368, kl=166.4531, beta=0.0000\n",
      "Batch 60, loss=0.0543, recon=0.0543, kl=130.4228, beta=0.0000\n",
      "Batch 80, loss=0.0419, recon=0.0419, kl=129.2015, beta=0.0000\n",
      "Batch 100, loss=0.0346, recon=0.0346, kl=138.6368, beta=0.0000\n",
      "Batch 120, loss=0.0216, recon=0.0216, kl=146.8276, beta=0.0000\n",
      "Batch 140, loss=0.0254, recon=0.0254, kl=150.5599, beta=0.0000\n",
      "Batch 160, loss=0.0335, recon=0.0335, kl=151.7068, beta=0.0000\n",
      "Batch 180, loss=0.0240, recon=0.0240, kl=153.4373, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0477 (Recon: 0.0477, KL: 149.5142, Current Beta: 0.0000) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0210, recon=0.0210, kl=155.2232, beta=0.0000\n",
      "Batch 40, loss=0.0346, recon=0.0346, kl=157.8861, beta=0.0000\n",
      "Batch 60, loss=0.0325, recon=0.0325, kl=158.5939, beta=0.0000\n",
      "Batch 80, loss=0.0472, recon=0.0472, kl=161.2023, beta=0.0000\n",
      "Batch 100, loss=0.0266, recon=0.0266, kl=164.2824, beta=0.0000\n",
      "Batch 120, loss=0.0278, recon=0.0278, kl=164.8380, beta=0.0000\n",
      "Batch 140, loss=0.0292, recon=0.0292, kl=165.7165, beta=0.0000\n",
      "Batch 160, loss=0.0387, recon=0.0387, kl=167.9023, beta=0.0000\n",
      "Batch 180, loss=0.0289, recon=0.0289, kl=167.6723, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0397 (Recon: 0.0396, KL: 162.1184, Current Beta: 0.0000) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0518, recon=0.0517, kl=167.9720, beta=0.0000\n",
      "Batch 40, loss=0.9001, recon=0.9001, kl=116.6110, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 9/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 10/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 11/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 12/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 13/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 14/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 37/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.8871, recon=0.8871, kl=0.2778, beta=0.0000\n",
      "Batch 40, loss=1.5383, recon=1.5383, kl=0.6793, beta=0.0000\n",
      "Batch 60, loss=0.5136, recon=0.5136, kl=3.7166, beta=0.0000\n",
      "Batch 80, loss=0.4528, recon=0.4528, kl=10.9070, beta=0.0000\n",
      "Batch 100, loss=0.3422, recon=0.3422, kl=13.8562, beta=0.0000\n",
      "Batch 120, loss=0.2482, recon=0.2482, kl=16.1402, beta=0.0000\n",
      "Batch 140, loss=0.1824, recon=0.1824, kl=18.2314, beta=0.0000\n",
      "Batch 160, loss=0.1802, recon=0.1802, kl=19.3520, beta=0.0000\n",
      "Batch 180, loss=0.2853, recon=0.2853, kl=20.7208, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4717 (Recon: 0.4717, KL: 10.5520, Current Beta: 0.0000) | Avg Valid Loss: 0.2506 | Avg Valid recon Loss: 0.2506\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1854, recon=0.1854, kl=22.8163, beta=0.0000\n",
      "Batch 40, loss=0.1913, recon=0.1913, kl=23.5750, beta=0.0000\n",
      "Batch 60, loss=0.2018, recon=0.2018, kl=25.6432, beta=0.0000\n",
      "Batch 80, loss=0.1612, recon=0.1612, kl=26.5277, beta=0.0000\n",
      "Batch 100, loss=0.3030, recon=0.3030, kl=26.9921, beta=0.0000\n",
      "Batch 120, loss=0.1886, recon=0.1886, kl=27.9622, beta=0.0000\n",
      "Batch 140, loss=0.1378, recon=0.1378, kl=28.6162, beta=0.0000\n",
      "Batch 160, loss=0.1160, recon=0.1160, kl=29.5253, beta=0.0000\n",
      "Batch 180, loss=0.3324, recon=0.3324, kl=30.2346, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2211 (Recon: 0.2211, KL: 26.4078, Current Beta: 0.0000) | Avg Valid Loss: 0.1589 | Avg Valid recon Loss: 0.1589\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.4364, recon=0.4364, kl=30.6644, beta=0.0000\n",
      "Batch 40, loss=0.1573, recon=0.1573, kl=31.5869, beta=0.0000\n",
      "Batch 60, loss=0.2922, recon=0.2922, kl=32.8065, beta=0.0000\n",
      "Batch 80, loss=0.1403, recon=0.1403, kl=34.2983, beta=0.0000\n",
      "Batch 100, loss=0.2619, recon=0.2619, kl=33.8757, beta=0.0000\n",
      "Batch 120, loss=0.1288, recon=0.1288, kl=35.3138, beta=0.0000\n",
      "Batch 140, loss=0.1428, recon=0.1428, kl=36.6370, beta=0.0000\n",
      "Batch 160, loss=0.1194, recon=0.1194, kl=37.2118, beta=0.0000\n",
      "Batch 180, loss=0.0808, recon=0.0808, kl=37.5648, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1632 (Recon: 0.1632, KL: 34.2039, Current Beta: 0.0000) | Avg Valid Loss: 0.1236 | Avg Valid recon Loss: 0.1236\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1167, recon=0.1167, kl=38.3178, beta=0.0000\n",
      "Batch 40, loss=0.1313, recon=0.1313, kl=39.0029, beta=0.0000\n",
      "Batch 60, loss=0.4443, recon=0.4443, kl=40.2541, beta=0.0000\n",
      "Batch 80, loss=0.1637, recon=0.1637, kl=39.8181, beta=0.0000\n",
      "Batch 100, loss=0.1285, recon=0.1285, kl=39.9250, beta=0.0000\n",
      "Batch 120, loss=0.2417, recon=0.2417, kl=40.1360, beta=0.0000\n",
      "Batch 140, loss=0.1451, recon=0.1451, kl=40.5859, beta=0.0000\n",
      "Batch 160, loss=0.0894, recon=0.0894, kl=40.6219, beta=0.0000\n",
      "Batch 180, loss=0.0970, recon=0.0970, kl=40.1584, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1334 (Recon: 0.1334, KL: 39.6614, Current Beta: 0.0000) | Avg Valid Loss: 0.1032 | Avg Valid recon Loss: 0.1032\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1269, recon=0.1269, kl=39.9498, beta=0.0000\n",
      "Batch 40, loss=0.0690, recon=0.0690, kl=39.7793, beta=0.0000\n",
      "Batch 60, loss=0.0683, recon=0.0683, kl=40.0038, beta=0.0000\n",
      "Batch 80, loss=0.0549, recon=0.0549, kl=39.2462, beta=0.0000\n",
      "Batch 100, loss=0.0996, recon=0.0996, kl=38.9266, beta=0.0000\n",
      "Batch 120, loss=0.0935, recon=0.0935, kl=38.6815, beta=0.0000\n",
      "Batch 140, loss=0.0646, recon=0.0646, kl=38.1612, beta=0.0000\n",
      "Batch 160, loss=0.0817, recon=0.0817, kl=37.7433, beta=0.0000\n",
      "Batch 180, loss=0.0563, recon=0.0563, kl=37.5908, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1145 (Recon: 0.1145, KL: 38.9807, Current Beta: 0.0000) | Avg Valid Loss: 0.0913 | Avg Valid recon Loss: 0.0913\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0834, recon=0.0834, kl=37.2230, beta=0.0000\n",
      "Batch 40, loss=0.0777, recon=0.0777, kl=36.5206, beta=0.0000\n",
      "Batch 60, loss=0.0555, recon=0.0555, kl=35.4939, beta=0.0000\n",
      "Batch 80, loss=0.0719, recon=0.0719, kl=34.0666, beta=0.0000\n",
      "Batch 100, loss=0.0856, recon=0.0855, kl=33.3980, beta=0.0000\n",
      "Batch 120, loss=0.0674, recon=0.0674, kl=33.3108, beta=0.0000\n",
      "Batch 140, loss=0.1190, recon=0.1189, kl=32.7449, beta=0.0000\n",
      "Batch 160, loss=0.1011, recon=0.1011, kl=31.9177, beta=0.0000\n",
      "Batch 180, loss=0.0498, recon=0.0498, kl=32.3353, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1013 (Recon: 0.1013, KL: 34.3810, Current Beta: 0.0000) | Avg Valid Loss: 0.0826 | Avg Valid recon Loss: 0.0826\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0686, recon=0.0686, kl=30.3786, beta=0.0000\n",
      "Batch 40, loss=0.0784, recon=0.0784, kl=28.5247, beta=0.0000\n",
      "Batch 60, loss=0.0710, recon=0.0710, kl=27.3011, beta=0.0000\n",
      "Batch 80, loss=0.0913, recon=0.0913, kl=25.3950, beta=0.0000\n",
      "Batch 100, loss=0.0950, recon=0.0950, kl=24.1245, beta=0.0000\n",
      "Batch 120, loss=0.0856, recon=0.0856, kl=23.4299, beta=0.0000\n",
      "Batch 140, loss=0.0649, recon=0.0649, kl=23.1877, beta=0.0000\n",
      "Batch 160, loss=0.0696, recon=0.0696, kl=21.9238, beta=0.0000\n",
      "Batch 180, loss=0.0656, recon=0.0656, kl=21.7579, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0920 (Recon: 0.0919, KL: 25.6549, Current Beta: 0.0000) | Avg Valid Loss: 0.0767 | Avg Valid recon Loss: 0.0767\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1788, recon=0.1787, kl=20.1973, beta=0.0000\n",
      "Batch 40, loss=0.0589, recon=0.0589, kl=17.7386, beta=0.0000\n",
      "Batch 60, loss=0.0561, recon=0.0561, kl=15.6274, beta=0.0000\n",
      "Batch 80, loss=0.1227, recon=0.1227, kl=13.7462, beta=0.0000\n",
      "Batch 100, loss=0.0590, recon=0.0589, kl=12.8801, beta=0.0000\n",
      "Batch 120, loss=0.1189, recon=0.1189, kl=12.6020, beta=0.0000\n",
      "Batch 140, loss=0.0603, recon=0.0603, kl=12.7439, beta=0.0000\n",
      "Batch 160, loss=0.0529, recon=0.0529, kl=12.3978, beta=0.0000\n",
      "Batch 180, loss=0.0602, recon=0.0602, kl=11.6680, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0850 (Recon: 0.0850, KL: 14.9775, Current Beta: 0.0000) | Avg Valid Loss: 0.0728 | Avg Valid recon Loss: 0.0727\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0895, recon=0.0895, kl=9.3330, beta=0.0000\n",
      "Batch 40, loss=0.1713, recon=0.1712, kl=6.7176, beta=0.0000\n",
      "Batch 60, loss=0.0564, recon=0.0563, kl=5.6096, beta=0.0000\n",
      "Batch 80, loss=0.1103, recon=0.1103, kl=6.2986, beta=0.0000\n",
      "Batch 100, loss=0.0426, recon=0.0426, kl=6.0143, beta=0.0000\n",
      "Batch 120, loss=0.0574, recon=0.0574, kl=5.7593, beta=0.0000\n",
      "Batch 140, loss=0.0487, recon=0.0487, kl=5.5421, beta=0.0000\n",
      "Batch 160, loss=0.0616, recon=0.0616, kl=5.8445, beta=0.0000\n",
      "Batch 180, loss=0.0503, recon=0.0503, kl=5.8999, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0797 (Recon: 0.0797, KL: 6.6407, Current Beta: 0.0000) | Avg Valid Loss: 0.0684 | Avg Valid recon Loss: 0.0683\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0619, recon=0.0619, kl=3.5564, beta=0.0000\n",
      "Batch 40, loss=0.0452, recon=0.0452, kl=2.5158, beta=0.0000\n",
      "Batch 60, loss=0.0604, recon=0.0604, kl=2.0271, beta=0.0000\n",
      "Batch 80, loss=0.0506, recon=0.0505, kl=1.9754, beta=0.0000\n",
      "Batch 100, loss=0.0474, recon=0.0473, kl=2.0846, beta=0.0000\n",
      "Batch 120, loss=0.3894, recon=0.3894, kl=1.7758, beta=0.0000\n",
      "Batch 140, loss=0.0571, recon=0.0571, kl=1.7640, beta=0.0000\n",
      "Batch 160, loss=0.0595, recon=0.0594, kl=1.7133, beta=0.0000\n",
      "Batch 180, loss=0.0530, recon=0.0530, kl=1.4740, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0755 (Recon: 0.0755, KL: 2.3371, Current Beta: 0.0000) | Avg Valid Loss: 0.0671 | Avg Valid recon Loss: 0.0671\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0659, recon=0.0659, kl=0.4721, beta=0.0000\n",
      "Batch 40, loss=0.0716, recon=0.0716, kl=0.4320, beta=0.0000\n",
      "Batch 60, loss=0.1592, recon=0.1592, kl=0.4196, beta=0.0000\n",
      "Batch 80, loss=0.1051, recon=0.1051, kl=0.3427, beta=0.0000\n",
      "Batch 100, loss=1.2936, recon=1.2936, kl=0.2653, beta=0.0000\n",
      "Batch 120, loss=0.0484, recon=0.0484, kl=0.2482, beta=0.0000\n",
      "Batch 140, loss=0.0879, recon=0.0879, kl=0.3060, beta=0.0000\n",
      "Batch 160, loss=0.0557, recon=0.0557, kl=0.2082, beta=0.0000\n",
      "Batch 180, loss=0.0456, recon=0.0456, kl=0.2367, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0721 (Recon: 0.0721, KL: 0.3917, Current Beta: 0.0000) | Avg Valid Loss: 0.0628 | Avg Valid recon Loss: 0.0628\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0617, recon=0.0617, kl=0.0531, beta=0.0001\n",
      "Batch 40, loss=0.0951, recon=0.0951, kl=0.0531, beta=0.0001\n",
      "Batch 60, loss=0.2539, recon=0.2539, kl=0.0362, beta=0.0001\n",
      "Batch 80, loss=0.0624, recon=0.0624, kl=0.0417, beta=0.0001\n",
      "Batch 100, loss=0.0474, recon=0.0474, kl=0.0303, beta=0.0001\n",
      "Batch 120, loss=0.0740, recon=0.0740, kl=0.0360, beta=0.0001\n",
      "Batch 140, loss=0.0378, recon=0.0378, kl=0.0225, beta=0.0001\n",
      "Batch 160, loss=0.0832, recon=0.0832, kl=0.0200, beta=0.0001\n",
      "Batch 180, loss=0.2625, recon=0.2625, kl=0.0277, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0688 (Recon: 0.0688, KL: 0.0510, Current Beta: 0.0001) | Avg Valid Loss: 0.0605 | Avg Valid recon Loss: 0.0605\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0386, recon=0.0386, kl=0.0092, beta=0.0002\n",
      "Batch 40, loss=0.0570, recon=0.0570, kl=0.0062, beta=0.0002\n",
      "Batch 60, loss=0.0371, recon=0.0371, kl=0.0052, beta=0.0002\n",
      "Batch 80, loss=0.0377, recon=0.0377, kl=0.0058, beta=0.0002\n",
      "Batch 100, loss=0.0783, recon=0.0783, kl=0.0040, beta=0.0002\n",
      "Batch 120, loss=0.0420, recon=0.0420, kl=0.0044, beta=0.0002\n",
      "Batch 140, loss=0.0300, recon=0.0300, kl=0.0047, beta=0.0002\n",
      "Batch 160, loss=0.0400, recon=0.0400, kl=0.0048, beta=0.0002\n",
      "Batch 180, loss=0.0585, recon=0.0585, kl=0.0047, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0665 (Recon: 0.0665, KL: 0.0080, Current Beta: 0.0002) | Avg Valid Loss: 0.0582 | Avg Valid recon Loss: 0.0582\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0562, recon=0.0562, kl=0.0025, beta=0.0004\n",
      "Batch 40, loss=0.0448, recon=0.0448, kl=0.0017, beta=0.0004\n",
      "Batch 60, loss=0.0456, recon=0.0456, kl=0.0014, beta=0.0004\n",
      "Batch 80, loss=0.0451, recon=0.0451, kl=0.0020, beta=0.0004\n",
      "Batch 100, loss=0.0377, recon=0.0377, kl=0.0015, beta=0.0004\n",
      "Batch 120, loss=0.0298, recon=0.0298, kl=0.0013, beta=0.0004\n",
      "Batch 140, loss=0.0357, recon=0.0357, kl=0.0010, beta=0.0004\n",
      "Batch 160, loss=0.0614, recon=0.0614, kl=0.0023, beta=0.0004\n",
      "Batch 180, loss=0.0442, recon=0.0442, kl=0.0022, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0641 (Recon: 0.0641, KL: 0.0029, Current Beta: 0.0004) | Avg Valid Loss: 0.0561 | Avg Valid recon Loss: 0.0561\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0719, recon=0.0719, kl=0.0005, beta=0.0006\n",
      "Batch 40, loss=0.0446, recon=0.0446, kl=0.0007, beta=0.0006\n",
      "Batch 60, loss=0.0369, recon=0.0369, kl=0.0010, beta=0.0006\n",
      "Batch 80, loss=0.0455, recon=0.0455, kl=0.0007, beta=0.0006\n",
      "Batch 100, loss=0.0792, recon=0.0792, kl=0.0013, beta=0.0006\n",
      "Batch 120, loss=0.0383, recon=0.0383, kl=0.0005, beta=0.0006\n",
      "Batch 140, loss=0.0423, recon=0.0423, kl=0.0005, beta=0.0006\n",
      "Batch 160, loss=0.0461, recon=0.0461, kl=0.0018, beta=0.0006\n",
      "Batch 180, loss=0.0403, recon=0.0403, kl=0.0006, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0621 (Recon: 0.0621, KL: 0.0014, Current Beta: 0.0006) | Avg Valid Loss: 0.0545 | Avg Valid recon Loss: 0.0545\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0694, recon=0.0694, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.0589, recon=0.0589, kl=0.0008, beta=0.0010\n",
      "Batch 60, loss=0.0686, recon=0.0686, kl=0.0144, beta=0.0010\n",
      "Batch 80, loss=0.0470, recon=0.0470, kl=0.0005, beta=0.0010\n",
      "Batch 100, loss=0.0554, recon=0.0554, kl=0.0005, beta=0.0010\n",
      "Batch 120, loss=0.0477, recon=0.0477, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0451, recon=0.0451, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0623, recon=0.0623, kl=0.0005, beta=0.0010\n",
      "Batch 180, loss=0.0753, recon=0.0753, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0603 (Recon: 0.0603, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0536 | Avg Valid recon Loss: 0.0536\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0670, recon=0.0670, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0427, recon=0.0427, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.2849, recon=0.2849, kl=0.0025, beta=0.0010\n",
      "Batch 100, loss=0.0489, recon=0.0489, kl=0.0007, beta=0.0010\n",
      "Batch 120, loss=0.0373, recon=0.0373, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.1203, recon=0.1203, kl=0.0048, beta=0.0010\n",
      "Batch 160, loss=0.1439, recon=0.1439, kl=0.0006, beta=0.0010\n",
      "Batch 180, loss=0.0351, recon=0.0351, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0586 (Recon: 0.0586, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0523 | Avg Valid recon Loss: 0.0523\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.2686, recon=0.2686, kl=0.0016, beta=0.0010\n",
      "Batch 40, loss=0.0476, recon=0.0476, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0898, recon=0.0898, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0426, recon=0.0426, kl=0.0006, beta=0.0010\n",
      "Batch 100, loss=0.1557, recon=0.1557, kl=0.0007, beta=0.0010\n",
      "Batch 120, loss=0.0424, recon=0.0424, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0489, recon=0.0489, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0710, recon=0.0710, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0472, recon=0.0472, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0575 (Recon: 0.0575, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0506 | Avg Valid recon Loss: 0.0506\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0501, recon=0.0501, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0424, recon=0.0424, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0505, recon=0.0505, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0486, recon=0.0486, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0688, recon=0.0688, kl=0.0004, beta=0.0010\n",
      "Batch 120, loss=0.0306, recon=0.0306, kl=0.0001, beta=0.0010\n",
      "Batch 140, loss=0.0424, recon=0.0424, kl=0.0001, beta=0.0010\n",
      "Batch 160, loss=0.0261, recon=0.0261, kl=0.0004, beta=0.0010\n",
      "Batch 180, loss=0.0479, recon=0.0479, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0557 (Recon: 0.0557, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0499\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0576, recon=0.0576, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0550, recon=0.0550, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0523, recon=0.0523, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0342, recon=0.0342, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0401, recon=0.0401, kl=0.0002, beta=0.0010\n",
      "Batch 120, loss=0.0444, recon=0.0444, kl=0.0001, beta=0.0010\n",
      "Batch 140, loss=0.0311, recon=0.0311, kl=0.0007, beta=0.0010\n",
      "Batch 160, loss=0.0373, recon=0.0373, kl=0.0007, beta=0.0010\n",
      "Batch 180, loss=0.0365, recon=0.0365, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0548 (Recon: 0.0548, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0487 | Avg Valid recon Loss: 0.0487\n",
      "\n",
      "[VRAE Run 38/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2111, recon=0.2111, kl=15.6609, beta=0.0000\n",
      "Batch 40, loss=0.2537, recon=0.2537, kl=23.3065, beta=0.0000\n",
      "Batch 60, loss=0.1546, recon=0.1546, kl=24.9875, beta=0.0000\n",
      "Batch 80, loss=0.0865, recon=0.0865, kl=28.1098, beta=0.0000\n",
      "Batch 100, loss=0.1469, recon=0.1469, kl=30.8895, beta=0.0000\n",
      "Batch 120, loss=0.0648, recon=0.0648, kl=34.6635, beta=0.0000\n",
      "Batch 140, loss=0.0788, recon=0.0788, kl=34.7690, beta=0.0000\n",
      "Batch 160, loss=0.0986, recon=0.0986, kl=32.1814, beta=0.0000\n",
      "Batch 180, loss=0.0699, recon=0.0699, kl=32.5443, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1660 (Recon: 0.1660, KL: 26.9467, Current Beta: 0.0000) | Avg Valid Loss: 0.0724 | Avg Valid recon Loss: 0.0724\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0437, recon=0.0437, kl=32.8256, beta=0.0000\n",
      "Batch 40, loss=0.0481, recon=0.0481, kl=31.1943, beta=0.0000\n",
      "Batch 60, loss=0.0547, recon=0.0547, kl=32.6308, beta=0.0000\n",
      "Batch 80, loss=0.0525, recon=0.0525, kl=35.9491, beta=0.0000\n",
      "Batch 100, loss=0.0700, recon=0.0700, kl=35.1441, beta=0.0000\n",
      "Batch 120, loss=0.1042, recon=0.1042, kl=35.2208, beta=0.0000\n",
      "Batch 140, loss=0.0400, recon=0.0400, kl=36.1039, beta=0.0000\n",
      "Batch 160, loss=0.0501, recon=0.0501, kl=36.1613, beta=0.0000\n",
      "Batch 180, loss=0.0878, recon=0.0878, kl=33.8564, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0756 (Recon: 0.0756, KL: 34.2614, Current Beta: 0.0000) | Avg Valid Loss: 0.0637 | Avg Valid recon Loss: 0.0637\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0310, recon=0.0310, kl=31.7676, beta=0.0000\n",
      "Batch 40, loss=0.0645, recon=0.0645, kl=32.3293, beta=0.0000\n",
      "Batch 60, loss=0.3342, recon=0.3342, kl=35.2669, beta=0.0000\n",
      "Batch 80, loss=0.0599, recon=0.0599, kl=33.3920, beta=0.0000\n",
      "Batch 100, loss=0.0649, recon=0.0649, kl=33.2549, beta=0.0000\n",
      "Batch 120, loss=0.0516, recon=0.0516, kl=34.5283, beta=0.0000\n",
      "Batch 140, loss=0.1138, recon=0.1138, kl=32.1201, beta=0.0000\n",
      "Batch 160, loss=0.0924, recon=0.0924, kl=33.4117, beta=0.0000\n",
      "Batch 180, loss=0.0557, recon=0.0557, kl=34.5569, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0660 (Recon: 0.0660, KL: 33.4006, Current Beta: 0.0000) | Avg Valid Loss: 0.0585 | Avg Valid recon Loss: 0.0585\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0383, recon=0.0383, kl=35.9852, beta=0.0000\n",
      "Batch 40, loss=0.2461, recon=0.2461, kl=36.1244, beta=0.0000\n",
      "Batch 60, loss=0.0561, recon=0.0561, kl=37.8547, beta=0.0000\n",
      "Batch 80, loss=0.0534, recon=0.0534, kl=39.4371, beta=0.0000\n",
      "Batch 100, loss=0.0377, recon=0.0377, kl=42.0105, beta=0.0000\n",
      "Batch 120, loss=0.0756, recon=0.0756, kl=42.7771, beta=0.0000\n",
      "Batch 140, loss=0.0746, recon=0.0746, kl=40.8791, beta=0.0000\n",
      "Batch 160, loss=0.0407, recon=0.0407, kl=37.5575, beta=0.0000\n",
      "Batch 180, loss=0.0366, recon=0.0366, kl=28.4462, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0633 (Recon: 0.0633, KL: 38.0322, Current Beta: 0.0000) | Avg Valid Loss: 0.0515 | Avg Valid recon Loss: 0.0515\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0364, recon=0.0364, kl=30.7398, beta=0.0000\n",
      "Batch 40, loss=0.0399, recon=0.0399, kl=35.7140, beta=0.0000\n",
      "Batch 60, loss=0.0552, recon=0.0552, kl=37.1831, beta=0.0000\n",
      "Batch 80, loss=0.0465, recon=0.0465, kl=37.4078, beta=0.0000\n",
      "Batch 100, loss=0.0355, recon=0.0355, kl=36.3210, beta=0.0000\n",
      "Batch 120, loss=0.0535, recon=0.0535, kl=34.9745, beta=0.0000\n",
      "Batch 140, loss=0.0486, recon=0.0486, kl=33.4956, beta=0.0000\n",
      "Batch 160, loss=0.0364, recon=0.0364, kl=33.3339, beta=0.0000\n",
      "Batch 180, loss=0.0357, recon=0.0357, kl=33.4851, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0588 (Recon: 0.0588, KL: 34.6186, Current Beta: 0.0000) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0450\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0289, recon=0.0289, kl=30.0158, beta=0.0000\n",
      "Batch 40, loss=0.0481, recon=0.0481, kl=29.9583, beta=0.0000\n",
      "Batch 60, loss=0.0311, recon=0.0311, kl=30.7634, beta=0.0000\n",
      "Batch 80, loss=0.0444, recon=0.0444, kl=30.3683, beta=0.0000\n",
      "Batch 100, loss=0.0893, recon=0.0893, kl=29.9723, beta=0.0000\n",
      "Batch 120, loss=0.0556, recon=0.0556, kl=29.3356, beta=0.0000\n",
      "Batch 140, loss=0.0654, recon=0.0654, kl=29.2011, beta=0.0000\n",
      "Batch 160, loss=0.0512, recon=0.0512, kl=30.0028, beta=0.0000\n",
      "Batch 180, loss=0.0534, recon=0.0534, kl=29.0309, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0545, KL: 30.0666, Current Beta: 0.0000) | Avg Valid Loss: 0.0464 | Avg Valid recon Loss: 0.0464\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0770, recon=0.0770, kl=25.6203, beta=0.0000\n",
      "Batch 40, loss=0.0349, recon=0.0349, kl=24.0254, beta=0.0000\n",
      "Batch 60, loss=0.1765, recon=0.1765, kl=22.7477, beta=0.0000\n",
      "Batch 80, loss=0.0311, recon=0.0310, kl=23.1859, beta=0.0000\n",
      "Batch 100, loss=0.0600, recon=0.0600, kl=23.8275, beta=0.0000\n",
      "Batch 120, loss=0.0449, recon=0.0448, kl=26.2844, beta=0.0000\n",
      "Batch 140, loss=0.0327, recon=0.0327, kl=26.2949, beta=0.0000\n",
      "Batch 160, loss=0.0287, recon=0.0287, kl=25.7772, beta=0.0000\n",
      "Batch 180, loss=0.0540, recon=0.0539, kl=23.4952, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0533, KL: 24.8439, Current Beta: 0.0000) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0457\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0364, recon=0.0363, kl=18.4955, beta=0.0000\n",
      "Batch 40, loss=0.0636, recon=0.0636, kl=14.9144, beta=0.0000\n",
      "Batch 60, loss=0.0307, recon=0.0307, kl=16.2883, beta=0.0000\n",
      "Batch 80, loss=0.0371, recon=0.0371, kl=15.2912, beta=0.0000\n",
      "Batch 100, loss=0.0364, recon=0.0363, kl=16.1098, beta=0.0000\n",
      "Batch 120, loss=0.0445, recon=0.0445, kl=15.9864, beta=0.0000\n",
      "Batch 140, loss=0.0398, recon=0.0397, kl=15.1387, beta=0.0000\n",
      "Batch 160, loss=0.0297, recon=0.0297, kl=15.4855, beta=0.0000\n",
      "Batch 180, loss=0.0530, recon=0.0530, kl=15.1800, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0536 (Recon: 0.0536, KL: 16.3000, Current Beta: 0.0000) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0365, recon=0.0365, kl=11.1692, beta=0.0000\n",
      "Batch 40, loss=0.0390, recon=0.0390, kl=8.6355, beta=0.0000\n",
      "Batch 60, loss=0.0272, recon=0.0272, kl=7.3351, beta=0.0000\n",
      "Batch 80, loss=0.0991, recon=0.0991, kl=9.0788, beta=0.0000\n",
      "Batch 100, loss=0.0380, recon=0.0380, kl=8.6416, beta=0.0000\n",
      "Batch 120, loss=0.7130, recon=0.7130, kl=7.5409, beta=0.0000\n",
      "Batch 140, loss=0.0438, recon=0.0437, kl=6.0513, beta=0.0000\n",
      "Batch 160, loss=0.0283, recon=0.0283, kl=9.2679, beta=0.0000\n",
      "Batch 180, loss=0.0332, recon=0.0332, kl=8.8448, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0487 (Recon: 0.0486, KL: 8.8972, Current Beta: 0.0000) | Avg Valid Loss: 0.0424 | Avg Valid recon Loss: 0.0424\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1136, recon=0.1135, kl=6.5153, beta=0.0000\n",
      "Batch 40, loss=0.0471, recon=0.0471, kl=5.2770, beta=0.0000\n",
      "Batch 60, loss=0.0397, recon=0.0396, kl=3.9014, beta=0.0000\n",
      "Batch 80, loss=0.0331, recon=0.0331, kl=4.5217, beta=0.0000\n",
      "Batch 100, loss=0.0515, recon=0.0515, kl=4.3443, beta=0.0000\n",
      "Batch 120, loss=0.0277, recon=0.0276, kl=3.1351, beta=0.0000\n",
      "Batch 140, loss=0.0381, recon=0.0381, kl=2.7202, beta=0.0000\n",
      "Batch 160, loss=0.0329, recon=0.0329, kl=3.0432, beta=0.0000\n",
      "Batch 180, loss=0.0370, recon=0.0369, kl=1.9128, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0505 (Recon: 0.0504, KL: 4.2251, Current Beta: 0.0000) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0287, recon=0.0287, kl=0.2289, beta=0.0000\n",
      "Batch 40, loss=0.0393, recon=0.0393, kl=0.9388, beta=0.0000\n",
      "Batch 60, loss=0.0523, recon=0.0522, kl=1.5929, beta=0.0000\n",
      "Batch 80, loss=0.0298, recon=0.0298, kl=1.0228, beta=0.0000\n",
      "Batch 100, loss=0.0389, recon=0.0389, kl=0.4289, beta=0.0000\n",
      "Batch 120, loss=0.0404, recon=0.0404, kl=0.4553, beta=0.0000\n",
      "Batch 140, loss=0.0427, recon=0.0427, kl=0.3564, beta=0.0000\n",
      "Batch 160, loss=0.0284, recon=0.0283, kl=0.3878, beta=0.0000\n",
      "Batch 180, loss=0.0418, recon=0.0418, kl=0.6065, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0493 (Recon: 0.0493, KL: 0.7173, Current Beta: 0.0000) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0279, recon=0.0279, kl=0.1462, beta=0.0001\n",
      "Batch 40, loss=0.0328, recon=0.0328, kl=0.0702, beta=0.0001\n",
      "Batch 60, loss=0.0522, recon=0.0522, kl=0.0301, beta=0.0001\n",
      "Batch 80, loss=0.0622, recon=0.0622, kl=0.0309, beta=0.0001\n",
      "Batch 100, loss=0.0381, recon=0.0381, kl=0.0394, beta=0.0001\n",
      "Batch 120, loss=0.0761, recon=0.0761, kl=0.0171, beta=0.0001\n",
      "Batch 140, loss=0.0622, recon=0.0622, kl=0.0855, beta=0.0001\n",
      "Batch 160, loss=0.0286, recon=0.0286, kl=0.1314, beta=0.0001\n",
      "Batch 180, loss=0.0264, recon=0.0263, kl=0.7069, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0467 (Recon: 0.0467, KL: 0.1480, Current Beta: 0.0001) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0397, recon=0.0397, kl=0.0393, beta=0.0002\n",
      "Batch 40, loss=0.1142, recon=0.1142, kl=0.0216, beta=0.0002\n",
      "Batch 60, loss=0.0648, recon=0.0647, kl=0.2729, beta=0.0002\n",
      "Batch 80, loss=0.0298, recon=0.0298, kl=0.0848, beta=0.0002\n",
      "Batch 100, loss=0.0415, recon=0.0415, kl=0.0061, beta=0.0002\n",
      "Batch 120, loss=0.0421, recon=0.0421, kl=0.0101, beta=0.0002\n",
      "Batch 140, loss=0.0320, recon=0.0320, kl=0.0059, beta=0.0002\n",
      "Batch 160, loss=0.0667, recon=0.0667, kl=0.0490, beta=0.0002\n",
      "Batch 180, loss=0.0316, recon=0.0316, kl=0.1052, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0473, KL: 0.0796, Current Beta: 0.0002) | Avg Valid Loss: 0.0378 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=0.0284, beta=0.0004\n",
      "Batch 40, loss=0.0311, recon=0.0311, kl=0.0276, beta=0.0004\n",
      "Batch 60, loss=0.0273, recon=0.0273, kl=0.0055, beta=0.0004\n",
      "Batch 80, loss=0.0404, recon=0.0404, kl=0.0019, beta=0.0004\n",
      "Batch 100, loss=0.0364, recon=0.0364, kl=0.0020, beta=0.0004\n",
      "Batch 120, loss=0.0906, recon=0.0906, kl=0.0011, beta=0.0004\n",
      "Batch 140, loss=0.0325, recon=0.0325, kl=0.0026, beta=0.0004\n",
      "Batch 160, loss=0.0408, recon=0.0407, kl=0.0110, beta=0.0004\n",
      "Batch 180, loss=0.0608, recon=0.0608, kl=0.0068, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0479, KL: 0.0163, Current Beta: 0.0004) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0571, recon=0.0571, kl=0.0008, beta=0.0006\n",
      "Batch 40, loss=0.0578, recon=0.0578, kl=0.0021, beta=0.0006\n",
      "Batch 60, loss=0.0346, recon=0.0346, kl=0.0009, beta=0.0006\n",
      "Batch 80, loss=0.0511, recon=0.0511, kl=0.0007, beta=0.0006\n",
      "Batch 100, loss=0.0504, recon=0.0504, kl=0.0018, beta=0.0006\n",
      "Batch 120, loss=0.0355, recon=0.0355, kl=0.0005, beta=0.0006\n",
      "Batch 140, loss=0.0382, recon=0.0382, kl=0.0005, beta=0.0006\n",
      "Batch 160, loss=0.0499, recon=0.0499, kl=0.0041, beta=0.0006\n",
      "Batch 180, loss=0.0300, recon=0.0300, kl=0.0095, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0509 (Recon: 0.0509, KL: 0.0021, Current Beta: 0.0006) | Avg Valid Loss: 0.0385 | Avg Valid recon Loss: 0.0385\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0269, recon=0.0269, kl=0.0039, beta=0.0010\n",
      "Batch 40, loss=0.0516, recon=0.0516, kl=0.0048, beta=0.0010\n",
      "Batch 60, loss=0.0448, recon=0.0448, kl=0.0014, beta=0.0010\n",
      "Batch 80, loss=0.0264, recon=0.0264, kl=0.0010, beta=0.0010\n",
      "Batch 100, loss=0.0306, recon=0.0306, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0520, recon=0.0520, kl=0.0010, beta=0.0010\n",
      "Batch 140, loss=0.0329, recon=0.0329, kl=0.0011, beta=0.0010\n",
      "Batch 160, loss=0.0441, recon=0.0441, kl=0.0006, beta=0.0010\n",
      "Batch 180, loss=0.0296, recon=0.0296, kl=0.0138, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0461, KL: 0.0040, Current Beta: 0.0010) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0299, recon=0.0299, kl=0.0028, beta=0.0010\n",
      "Batch 40, loss=0.0287, recon=0.0287, kl=0.0009, beta=0.0010\n",
      "Batch 60, loss=0.0296, recon=0.0296, kl=0.0009, beta=0.0010\n",
      "Batch 80, loss=0.0211, recon=0.0211, kl=0.0003, beta=0.0010\n",
      "Batch 100, loss=0.0263, recon=0.0263, kl=0.0037, beta=0.0010\n",
      "Batch 120, loss=0.0332, recon=0.0332, kl=0.0018, beta=0.0010\n",
      "Batch 140, loss=0.0452, recon=0.0452, kl=0.0008, beta=0.0010\n",
      "Batch 160, loss=0.0302, recon=0.0302, kl=0.0004, beta=0.0010\n",
      "Batch 180, loss=0.0312, recon=0.0312, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0456, KL: 0.0044, Current Beta: 0.0010) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0472\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0421, recon=0.0420, kl=0.0423, beta=0.0010\n",
      "Batch 40, loss=0.0247, recon=0.0247, kl=0.0024, beta=0.0010\n",
      "Batch 60, loss=0.0399, recon=0.0399, kl=0.0009, beta=0.0010\n",
      "Batch 80, loss=0.0412, recon=0.0412, kl=0.0006, beta=0.0010\n",
      "Batch 100, loss=0.0334, recon=0.0334, kl=0.0004, beta=0.0010\n",
      "Batch 120, loss=0.0309, recon=0.0309, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0322, recon=0.0322, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0571, recon=0.0571, kl=0.0056, beta=0.0010\n",
      "Batch 180, loss=0.0548, recon=0.0548, kl=0.0030, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0529, KL: 0.0058, Current Beta: 0.0010) | Avg Valid Loss: 0.0446 | Avg Valid recon Loss: 0.0446\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0436, recon=0.0436, kl=0.0018, beta=0.0010\n",
      "Batch 40, loss=0.0314, recon=0.0314, kl=0.0038, beta=0.0010\n",
      "Batch 60, loss=0.0243, recon=0.0243, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.0649, recon=0.0649, kl=0.0009, beta=0.0010\n",
      "Batch 100, loss=0.0350, recon=0.0350, kl=0.0005, beta=0.0010\n",
      "Batch 120, loss=0.0380, recon=0.0380, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0338, recon=0.0338, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0470, recon=0.0470, kl=0.0009, beta=0.0010\n",
      "Batch 180, loss=0.0281, recon=0.0281, kl=0.0036, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0464 (Recon: 0.0464, KL: 0.0017, Current Beta: 0.0010) | Avg Valid Loss: 0.0462 | Avg Valid recon Loss: 0.0462\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0437, recon=0.0437, kl=0.0012, beta=0.0010\n",
      "Batch 40, loss=0.0449, recon=0.0449, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0305, recon=0.0305, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.0522, recon=0.0522, kl=0.0028, beta=0.0010\n",
      "Batch 100, loss=0.0253, recon=0.0253, kl=0.0035, beta=0.0010\n",
      "Batch 120, loss=0.0333, recon=0.0332, kl=0.0012, beta=0.0010\n",
      "Batch 140, loss=0.0390, recon=0.0390, kl=0.0012, beta=0.0010\n",
      "Batch 160, loss=0.0399, recon=0.0399, kl=0.0004, beta=0.0010\n",
      "Batch 180, loss=0.0414, recon=0.0414, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0485, KL: 0.0015, Current Beta: 0.0010) | Avg Valid Loss: 0.0367 | Avg Valid recon Loss: 0.0366\n",
      "\n",
      "[VRAE Run 39/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5524, recon=0.5524, kl=0.6900, beta=0.0000\n",
      "Batch 40, loss=0.7371, recon=0.7371, kl=1.6170, beta=0.0000\n",
      "Batch 60, loss=0.3306, recon=0.3306, kl=7.9038, beta=0.0000\n",
      "Batch 80, loss=0.3554, recon=0.3554, kl=21.1308, beta=0.0000\n",
      "Batch 100, loss=0.3797, recon=0.3797, kl=29.1773, beta=0.0000\n",
      "Batch 120, loss=0.3550, recon=0.3550, kl=33.2895, beta=0.0000\n",
      "Batch 140, loss=0.2285, recon=0.2285, kl=35.7878, beta=0.0000\n",
      "Batch 160, loss=0.2709, recon=0.2709, kl=38.3695, beta=0.0000\n",
      "Batch 180, loss=0.2185, recon=0.2185, kl=40.4396, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4492 (Recon: 0.4492, KL: 21.1499, Current Beta: 0.0000) | Avg Valid Loss: 0.2387 | Avg Valid recon Loss: 0.2387\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.4263, recon=0.4263, kl=42.6151, beta=0.0000\n",
      "Batch 40, loss=0.1838, recon=0.1838, kl=44.5976, beta=0.0000\n",
      "Batch 60, loss=0.1803, recon=0.1803, kl=46.9708, beta=0.0000\n",
      "Batch 80, loss=0.2442, recon=0.2442, kl=48.8715, beta=0.0000\n",
      "Batch 100, loss=0.1455, recon=0.1455, kl=50.7070, beta=0.0000\n",
      "Batch 120, loss=0.0993, recon=0.0993, kl=52.4941, beta=0.0000\n",
      "Batch 140, loss=0.1140, recon=0.1140, kl=53.9202, beta=0.0000\n",
      "Batch 160, loss=0.1533, recon=0.1533, kl=55.3979, beta=0.0000\n",
      "Batch 180, loss=0.1524, recon=0.1524, kl=57.6980, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2174 (Recon: 0.2174, KL: 49.4256, Current Beta: 0.0000) | Avg Valid Loss: 0.1543 | Avg Valid recon Loss: 0.1543\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1595, recon=0.1595, kl=58.0233, beta=0.0000\n",
      "Batch 40, loss=0.1933, recon=0.1933, kl=58.5569, beta=0.0000\n",
      "Batch 60, loss=0.1282, recon=0.1282, kl=59.1796, beta=0.0000\n",
      "Batch 80, loss=0.1958, recon=0.1958, kl=60.1505, beta=0.0000\n",
      "Batch 100, loss=0.1222, recon=0.1222, kl=60.7049, beta=0.0000\n",
      "Batch 120, loss=0.1089, recon=0.1089, kl=62.0911, beta=0.0000\n",
      "Batch 140, loss=0.2345, recon=0.2345, kl=63.5779, beta=0.0000\n",
      "Batch 160, loss=0.1439, recon=0.1439, kl=64.0748, beta=0.0000\n",
      "Batch 180, loss=0.1898, recon=0.1898, kl=64.4218, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1618 (Recon: 0.1618, KL: 60.8272, Current Beta: 0.0000) | Avg Valid Loss: 0.1214 | Avg Valid recon Loss: 0.1214\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1712, recon=0.1712, kl=64.9238, beta=0.0000\n",
      "Batch 40, loss=0.1347, recon=0.1347, kl=65.1703, beta=0.0000\n",
      "Batch 60, loss=0.0973, recon=0.0973, kl=65.3594, beta=0.0000\n",
      "Batch 80, loss=0.0947, recon=0.0947, kl=65.7027, beta=0.0000\n",
      "Batch 100, loss=0.0980, recon=0.0980, kl=65.9662, beta=0.0000\n",
      "Batch 120, loss=0.1255, recon=0.1255, kl=66.0162, beta=0.0000\n",
      "Batch 140, loss=0.0910, recon=0.0910, kl=65.8147, beta=0.0000\n",
      "Batch 160, loss=0.0730, recon=0.0730, kl=66.3153, beta=0.0000\n",
      "Batch 180, loss=0.0729, recon=0.0729, kl=67.1241, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1317 (Recon: 0.1317, KL: 65.6953, Current Beta: 0.0000) | Avg Valid Loss: 0.1009 | Avg Valid recon Loss: 0.1009\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1077, recon=0.1077, kl=67.7224, beta=0.0000\n",
      "Batch 40, loss=0.1022, recon=0.1022, kl=68.0065, beta=0.0000\n",
      "Batch 60, loss=0.0599, recon=0.0599, kl=67.8865, beta=0.0000\n",
      "Batch 80, loss=0.1239, recon=0.1239, kl=67.5540, beta=0.0000\n",
      "Batch 100, loss=0.0544, recon=0.0544, kl=67.8669, beta=0.0000\n",
      "Batch 120, loss=0.6040, recon=0.6040, kl=67.1276, beta=0.0000\n",
      "Batch 140, loss=0.0769, recon=0.0768, kl=68.8959, beta=0.0000\n",
      "Batch 160, loss=0.0856, recon=0.0856, kl=69.3080, beta=0.0000\n",
      "Batch 180, loss=0.0818, recon=0.0818, kl=69.5090, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1120 (Recon: 0.1120, KL: 68.2064, Current Beta: 0.0000) | Avg Valid Loss: 0.0900 | Avg Valid recon Loss: 0.0900\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1459, recon=0.1458, kl=68.0167, beta=0.0000\n",
      "Batch 40, loss=0.1134, recon=0.1134, kl=67.5076, beta=0.0000\n",
      "Batch 60, loss=0.0694, recon=0.0694, kl=65.8159, beta=0.0000\n",
      "Batch 80, loss=0.0781, recon=0.0781, kl=66.6717, beta=0.0000\n",
      "Batch 100, loss=0.0731, recon=0.0731, kl=66.1795, beta=0.0000\n",
      "Batch 120, loss=0.0631, recon=0.0631, kl=66.2259, beta=0.0000\n",
      "Batch 140, loss=0.0615, recon=0.0615, kl=65.1161, beta=0.0000\n",
      "Batch 160, loss=0.0630, recon=0.0630, kl=64.0423, beta=0.0000\n",
      "Batch 180, loss=0.0556, recon=0.0556, kl=64.0129, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0986 (Recon: 0.0986, KL: 66.3254, Current Beta: 0.0000) | Avg Valid Loss: 0.0811 | Avg Valid recon Loss: 0.0811\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0774, recon=0.0774, kl=62.1598, beta=0.0000\n",
      "Batch 40, loss=0.0677, recon=0.0677, kl=59.1305, beta=0.0000\n",
      "Batch 60, loss=0.0720, recon=0.0720, kl=54.6990, beta=0.0000\n",
      "Batch 80, loss=0.0557, recon=0.0557, kl=50.9846, beta=0.0000\n",
      "Batch 100, loss=0.0739, recon=0.0739, kl=47.7762, beta=0.0000\n",
      "Batch 120, loss=0.0714, recon=0.0714, kl=46.3344, beta=0.0000\n",
      "Batch 140, loss=0.0455, recon=0.0455, kl=45.9603, beta=0.0000\n",
      "Batch 160, loss=0.1144, recon=0.1144, kl=46.0350, beta=0.0000\n",
      "Batch 180, loss=0.0564, recon=0.0564, kl=44.8171, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0894 (Recon: 0.0893, KL: 51.7554, Current Beta: 0.0000) | Avg Valid Loss: 0.0763 | Avg Valid recon Loss: 0.0762\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0502, recon=0.0501, kl=40.3357, beta=0.0000\n",
      "Batch 40, loss=0.0459, recon=0.0458, kl=32.6951, beta=0.0000\n",
      "Batch 60, loss=0.0894, recon=0.0893, kl=27.3007, beta=0.0000\n",
      "Batch 80, loss=0.0600, recon=0.0600, kl=26.2708, beta=0.0000\n",
      "Batch 100, loss=0.0452, recon=0.0451, kl=25.2070, beta=0.0000\n",
      "Batch 120, loss=0.0802, recon=0.0801, kl=26.7940, beta=0.0000\n",
      "Batch 140, loss=0.0509, recon=0.0509, kl=24.4144, beta=0.0000\n",
      "Batch 160, loss=0.1152, recon=0.1152, kl=23.7011, beta=0.0000\n",
      "Batch 180, loss=0.0658, recon=0.0658, kl=23.9700, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0826 (Recon: 0.0826, KL: 28.9571, Current Beta: 0.0000) | Avg Valid Loss: 0.0710 | Avg Valid recon Loss: 0.0709\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0388, recon=0.0387, kl=15.9909, beta=0.0000\n",
      "Batch 40, loss=0.0449, recon=0.0449, kl=11.5262, beta=0.0000\n",
      "Batch 60, loss=0.0550, recon=0.0549, kl=10.6282, beta=0.0000\n",
      "Batch 80, loss=1.4299, recon=1.4298, kl=10.3451, beta=0.0000\n",
      "Batch 100, loss=0.0362, recon=0.0362, kl=9.7360, beta=0.0000\n",
      "Batch 120, loss=0.0447, recon=0.0447, kl=10.3179, beta=0.0000\n",
      "Batch 140, loss=0.1054, recon=0.1053, kl=10.5190, beta=0.0000\n",
      "Batch 160, loss=0.0420, recon=0.0420, kl=8.8789, beta=0.0000\n",
      "Batch 180, loss=0.3977, recon=0.3977, kl=7.6841, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0780 (Recon: 0.0780, KL: 11.4790, Current Beta: 0.0000) | Avg Valid Loss: 0.0673 | Avg Valid recon Loss: 0.0673\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0605, recon=0.0605, kl=3.6076, beta=0.0000\n",
      "Batch 40, loss=0.0434, recon=0.0434, kl=3.3312, beta=0.0000\n",
      "Batch 60, loss=0.0525, recon=0.0525, kl=3.3723, beta=0.0000\n",
      "Batch 80, loss=0.0536, recon=0.0536, kl=2.9713, beta=0.0000\n",
      "Batch 100, loss=0.0453, recon=0.0452, kl=2.8588, beta=0.0000\n",
      "Batch 120, loss=0.0508, recon=0.0508, kl=2.7473, beta=0.0000\n",
      "Batch 140, loss=0.0528, recon=0.0528, kl=1.8039, beta=0.0000\n",
      "Batch 160, loss=0.0410, recon=0.0410, kl=3.1902, beta=0.0000\n",
      "Batch 180, loss=0.2041, recon=0.2040, kl=2.6047, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0739 (Recon: 0.0738, KL: 3.1861, Current Beta: 0.0000) | Avg Valid Loss: 0.0639 | Avg Valid recon Loss: 0.0639\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0347, recon=0.0347, kl=1.0943, beta=0.0000\n",
      "Batch 40, loss=0.0744, recon=0.0744, kl=0.8316, beta=0.0000\n",
      "Batch 60, loss=0.0685, recon=0.0685, kl=0.7516, beta=0.0000\n",
      "Batch 80, loss=0.0700, recon=0.0700, kl=0.7891, beta=0.0000\n",
      "Batch 100, loss=0.0364, recon=0.0363, kl=0.7985, beta=0.0000\n",
      "Batch 120, loss=0.0476, recon=0.0476, kl=0.6121, beta=0.0000\n",
      "Batch 140, loss=0.0339, recon=0.0339, kl=0.5735, beta=0.0000\n",
      "Batch 160, loss=0.0478, recon=0.0478, kl=0.5445, beta=0.0000\n",
      "Batch 180, loss=0.0640, recon=0.0640, kl=0.6245, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0705 (Recon: 0.0705, KL: 0.8252, Current Beta: 0.0000) | Avg Valid Loss: 0.0619 | Avg Valid recon Loss: 0.0618\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0397, recon=0.0397, kl=0.2078, beta=0.0001\n",
      "Batch 40, loss=0.0475, recon=0.0475, kl=0.1555, beta=0.0001\n",
      "Batch 60, loss=0.0452, recon=0.0452, kl=0.1731, beta=0.0001\n",
      "Batch 80, loss=0.0830, recon=0.0830, kl=0.1222, beta=0.0001\n",
      "Batch 100, loss=0.0393, recon=0.0393, kl=0.1130, beta=0.0001\n",
      "Batch 120, loss=0.0392, recon=0.0392, kl=0.0916, beta=0.0001\n",
      "Batch 140, loss=0.0797, recon=0.0797, kl=0.1083, beta=0.0001\n",
      "Batch 160, loss=0.0519, recon=0.0519, kl=0.0762, beta=0.0001\n",
      "Batch 180, loss=0.0488, recon=0.0488, kl=0.1187, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0676 (Recon: 0.0676, KL: 0.1539, Current Beta: 0.0001) | Avg Valid Loss: 0.0592 | Avg Valid recon Loss: 0.0591\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0788, recon=0.0788, kl=0.0314, beta=0.0002\n",
      "Batch 40, loss=0.0702, recon=0.0702, kl=0.0275, beta=0.0002\n",
      "Batch 60, loss=0.0365, recon=0.0365, kl=0.0156, beta=0.0002\n",
      "Batch 80, loss=0.0366, recon=0.0366, kl=0.0231, beta=0.0002\n",
      "Batch 100, loss=0.0411, recon=0.0411, kl=0.0241, beta=0.0002\n",
      "Batch 120, loss=0.0716, recon=0.0716, kl=0.0208, beta=0.0002\n",
      "Batch 140, loss=0.0341, recon=0.0341, kl=0.0189, beta=0.0002\n",
      "Batch 160, loss=0.0681, recon=0.0681, kl=0.0124, beta=0.0002\n",
      "Batch 180, loss=0.0652, recon=0.0652, kl=0.0097, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0652 (Recon: 0.0652, KL: 0.0261, Current Beta: 0.0002) | Avg Valid Loss: 0.0572 | Avg Valid recon Loss: 0.0572\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0698, recon=0.0698, kl=0.0088, beta=0.0004\n",
      "Batch 40, loss=0.0489, recon=0.0489, kl=0.0042, beta=0.0004\n",
      "Batch 60, loss=0.0734, recon=0.0734, kl=0.0037, beta=0.0004\n",
      "Batch 80, loss=0.0388, recon=0.0388, kl=0.0026, beta=0.0004\n",
      "Batch 100, loss=0.0661, recon=0.0661, kl=0.0018, beta=0.0004\n",
      "Batch 120, loss=0.0738, recon=0.0738, kl=0.0090, beta=0.0004\n",
      "Batch 140, loss=0.0579, recon=0.0579, kl=0.0033, beta=0.0004\n",
      "Batch 160, loss=0.0695, recon=0.0695, kl=0.0038, beta=0.0004\n",
      "Batch 180, loss=0.0435, recon=0.0435, kl=0.0172, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0632 (Recon: 0.0632, KL: 0.0041, Current Beta: 0.0004) | Avg Valid Loss: 0.0558 | Avg Valid recon Loss: 0.0558\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0393, recon=0.0393, kl=0.0018, beta=0.0006\n",
      "Batch 40, loss=0.0797, recon=0.0797, kl=0.0020, beta=0.0006\n",
      "Batch 60, loss=0.0322, recon=0.0322, kl=0.0004, beta=0.0006\n",
      "Batch 80, loss=0.0480, recon=0.0480, kl=0.0007, beta=0.0006\n",
      "Batch 100, loss=0.0434, recon=0.0434, kl=0.0007, beta=0.0006\n",
      "Batch 120, loss=0.0346, recon=0.0346, kl=0.0005, beta=0.0006\n",
      "Batch 140, loss=0.0478, recon=0.0478, kl=0.0009, beta=0.0006\n",
      "Batch 160, loss=0.0591, recon=0.0591, kl=0.0007, beta=0.0006\n",
      "Batch 180, loss=0.0479, recon=0.0479, kl=0.0009, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0613 (Recon: 0.0613, KL: 0.0012, Current Beta: 0.0006) | Avg Valid Loss: 0.0538 | Avg Valid recon Loss: 0.0538\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0496, recon=0.0496, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0398, recon=0.0398, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0472, recon=0.0472, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.0401, recon=0.0401, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0833, recon=0.0833, kl=0.0002, beta=0.0010\n",
      "Batch 120, loss=0.0308, recon=0.0308, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0349, recon=0.0349, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0391, recon=0.0391, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0390, recon=0.0390, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0595 (Recon: 0.0595, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0522 | Avg Valid recon Loss: 0.0522\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0480, recon=0.0480, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0418, recon=0.0418, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0384, recon=0.0384, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.0668, recon=0.0668, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0301, recon=0.0301, kl=0.0002, beta=0.0010\n",
      "Batch 120, loss=0.0572, recon=0.0572, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0350, recon=0.0350, kl=0.0001, beta=0.0010\n",
      "Batch 160, loss=0.0641, recon=0.0641, kl=0.0004, beta=0.0010\n",
      "Batch 180, loss=0.0470, recon=0.0470, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0582 (Recon: 0.0582, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0517 | Avg Valid recon Loss: 0.0517\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0500, recon=0.0500, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0411, recon=0.0411, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0413, recon=0.0413, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0399, recon=0.0399, kl=0.0006, beta=0.0010\n",
      "Batch 120, loss=0.1422, recon=0.1422, kl=0.0001, beta=0.0010\n",
      "Batch 140, loss=0.0532, recon=0.0532, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0368, recon=0.0368, kl=0.0001, beta=0.0010\n",
      "Batch 180, loss=0.0465, recon=0.0465, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0299, recon=0.0299, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0867, recon=0.0867, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0366, recon=0.0366, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.1042, recon=0.1042, kl=0.0008, beta=0.0010\n",
      "Batch 100, loss=0.0291, recon=0.0291, kl=0.0002, beta=0.0010\n",
      "Batch 120, loss=0.0359, recon=0.0359, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0469, recon=0.0469, kl=0.0009, beta=0.0010\n",
      "Batch 160, loss=0.0446, recon=0.0446, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0361, recon=0.0361, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0557 (Recon: 0.0557, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0386, recon=0.0386, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0454, recon=0.0454, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.9561, recon=0.9561, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0264, recon=0.0264, kl=0.0001, beta=0.0010\n",
      "Batch 120, loss=0.0565, recon=0.0565, kl=0.0007, beta=0.0010\n",
      "Batch 140, loss=0.0289, recon=0.0289, kl=0.0001, beta=0.0010\n",
      "Batch 160, loss=0.0419, recon=0.0419, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0282, recon=0.0282, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0544 (Recon: 0.0544, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0480\n",
      "\n",
      "[VRAE Run 40/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3125, recon=0.3125, kl=33.5493, beta=0.0000\n",
      "Batch 40, loss=0.2233, recon=0.2233, kl=35.8285, beta=0.0000\n",
      "Batch 60, loss=0.1175, recon=0.1175, kl=45.1648, beta=0.0000\n",
      "Batch 80, loss=0.1053, recon=0.1053, kl=56.2184, beta=0.0000\n",
      "Batch 100, loss=0.0636, recon=0.0636, kl=53.9267, beta=0.0000\n",
      "Batch 120, loss=0.1631, recon=0.1631, kl=61.7617, beta=0.0000\n",
      "Batch 140, loss=0.1260, recon=0.1260, kl=58.1521, beta=0.0000\n",
      "Batch 160, loss=0.0506, recon=0.0506, kl=61.7146, beta=0.0000\n",
      "Batch 180, loss=0.0804, recon=0.0804, kl=60.0287, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1697 (Recon: 0.1697, KL: 48.4688, Current Beta: 0.0000) | Avg Valid Loss: 0.0719 | Avg Valid recon Loss: 0.0719\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0605, recon=0.0605, kl=60.6194, beta=0.0000\n",
      "Batch 40, loss=0.0903, recon=0.0903, kl=62.3008, beta=0.0000\n",
      "Batch 60, loss=0.0801, recon=0.0801, kl=63.1719, beta=0.0000\n",
      "Batch 80, loss=0.0611, recon=0.0611, kl=60.0861, beta=0.0000\n",
      "Batch 100, loss=0.0552, recon=0.0552, kl=56.6737, beta=0.0000\n",
      "Batch 120, loss=0.0825, recon=0.0825, kl=64.1104, beta=0.0000\n",
      "Batch 140, loss=0.0452, recon=0.0452, kl=70.6501, beta=0.0000\n",
      "Batch 160, loss=0.0538, recon=0.0538, kl=73.8600, beta=0.0000\n",
      "Batch 180, loss=0.0378, recon=0.0378, kl=73.8226, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0755 (Recon: 0.0755, KL: 64.2418, Current Beta: 0.0000) | Avg Valid Loss: 0.0579 | Avg Valid recon Loss: 0.0579\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0571, recon=0.0571, kl=71.3899, beta=0.0000\n",
      "Batch 40, loss=0.0332, recon=0.0332, kl=68.2840, beta=0.0000\n",
      "Batch 60, loss=0.0577, recon=0.0577, kl=63.0402, beta=0.0000\n",
      "Batch 80, loss=0.0377, recon=0.0376, kl=64.4698, beta=0.0000\n",
      "Batch 100, loss=0.0630, recon=0.0630, kl=69.9094, beta=0.0000\n",
      "Batch 120, loss=0.1048, recon=0.1048, kl=70.3737, beta=0.0000\n",
      "Batch 140, loss=0.0411, recon=0.0411, kl=66.2073, beta=0.0000\n",
      "Batch 160, loss=0.0630, recon=0.0630, kl=69.2582, beta=0.0000\n",
      "Batch 180, loss=0.0468, recon=0.0468, kl=69.8802, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0668 (Recon: 0.0668, KL: 68.4257, Current Beta: 0.0000) | Avg Valid Loss: 0.0528 | Avg Valid recon Loss: 0.0528\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0908, recon=0.0908, kl=70.3647, beta=0.0000\n",
      "Batch 40, loss=0.0409, recon=0.0409, kl=70.6887, beta=0.0000\n",
      "Batch 60, loss=0.0313, recon=0.0313, kl=70.5317, beta=0.0000\n",
      "Batch 80, loss=0.0375, recon=0.0375, kl=67.3247, beta=0.0000\n",
      "Batch 100, loss=0.0359, recon=0.0359, kl=66.4410, beta=0.0000\n",
      "Batch 120, loss=0.0370, recon=0.0370, kl=67.8891, beta=0.0000\n",
      "Batch 140, loss=0.0469, recon=0.0469, kl=67.7599, beta=0.0000\n",
      "Batch 160, loss=0.0442, recon=0.0442, kl=65.4776, beta=0.0000\n",
      "Batch 180, loss=0.0514, recon=0.0514, kl=60.7890, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0613 (Recon: 0.0613, KL: 67.6520, Current Beta: 0.0000) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0537\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=65.9228, beta=0.0000\n",
      "Batch 40, loss=0.0389, recon=0.0389, kl=70.2126, beta=0.0000\n",
      "Batch 60, loss=0.0461, recon=0.0461, kl=69.3973, beta=0.0000\n",
      "Batch 80, loss=0.0357, recon=0.0357, kl=71.7630, beta=0.0000\n",
      "Batch 100, loss=0.0546, recon=0.0546, kl=69.2246, beta=0.0000\n",
      "Batch 120, loss=0.0630, recon=0.0630, kl=69.4643, beta=0.0000\n",
      "Batch 140, loss=0.0441, recon=0.0441, kl=65.0218, beta=0.0000\n",
      "Batch 160, loss=0.0333, recon=0.0333, kl=61.5282, beta=0.0000\n",
      "Batch 180, loss=0.0854, recon=0.0854, kl=62.9223, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0567 (Recon: 0.0567, KL: 66.9888, Current Beta: 0.0000) | Avg Valid Loss: 0.0544 | Avg Valid recon Loss: 0.0544\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0395, recon=0.0394, kl=62.0840, beta=0.0000\n",
      "Batch 40, loss=0.0749, recon=0.0749, kl=58.0360, beta=0.0000\n",
      "Batch 60, loss=0.0303, recon=0.0303, kl=56.3312, beta=0.0000\n",
      "Batch 80, loss=0.0480, recon=0.0480, kl=58.9525, beta=0.0000\n",
      "Batch 100, loss=0.0374, recon=0.0374, kl=58.2090, beta=0.0000\n",
      "Batch 120, loss=0.0408, recon=0.0408, kl=58.1218, beta=0.0000\n",
      "Batch 140, loss=0.0431, recon=0.0431, kl=56.2125, beta=0.0000\n",
      "Batch 160, loss=0.0847, recon=0.0847, kl=56.1131, beta=0.0000\n",
      "Batch 180, loss=0.0412, recon=0.0412, kl=56.5680, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0567 (Recon: 0.0567, KL: 58.0696, Current Beta: 0.0000) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0452, recon=0.0451, kl=53.4444, beta=0.0000\n",
      "Batch 40, loss=0.0472, recon=0.0472, kl=47.1258, beta=0.0000\n",
      "Batch 60, loss=0.0489, recon=0.0489, kl=45.1270, beta=0.0000\n",
      "Batch 80, loss=0.0536, recon=0.0535, kl=45.4189, beta=0.0000\n",
      "Batch 100, loss=0.0432, recon=0.0432, kl=46.8210, beta=0.0000\n",
      "Batch 120, loss=0.0311, recon=0.0311, kl=46.5864, beta=0.0000\n",
      "Batch 140, loss=0.0429, recon=0.0428, kl=48.7590, beta=0.0000\n",
      "Batch 160, loss=0.0345, recon=0.0344, kl=51.8351, beta=0.0000\n",
      "Batch 180, loss=0.0571, recon=0.0570, kl=49.7930, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0576 (Recon: 0.0576, KL: 48.6420, Current Beta: 0.0000) | Avg Valid Loss: 0.0457 | Avg Valid recon Loss: 0.0457\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0691, recon=0.0690, kl=45.3854, beta=0.0000\n",
      "Batch 40, loss=0.0368, recon=0.0368, kl=38.4297, beta=0.0000\n",
      "Batch 60, loss=0.0278, recon=0.0277, kl=35.2021, beta=0.0000\n",
      "Batch 80, loss=0.0344, recon=0.0343, kl=32.1404, beta=0.0000\n",
      "Batch 100, loss=0.0774, recon=0.0774, kl=33.4633, beta=0.0000\n",
      "Batch 120, loss=0.0317, recon=0.0316, kl=34.0185, beta=0.0000\n",
      "Batch 140, loss=0.0545, recon=0.0544, kl=35.1865, beta=0.0000\n",
      "Batch 160, loss=0.0364, recon=0.0363, kl=33.4116, beta=0.0000\n",
      "Batch 180, loss=0.0389, recon=0.0389, kl=35.3400, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0549 (Recon: 0.0548, KL: 36.6760, Current Beta: 0.0000) | Avg Valid Loss: 0.0469 | Avg Valid recon Loss: 0.0469\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0312, recon=0.0311, kl=23.5541, beta=0.0000\n",
      "Batch 40, loss=0.0365, recon=0.0364, kl=18.3450, beta=0.0000\n",
      "Batch 60, loss=0.0237, recon=0.0236, kl=21.3339, beta=0.0000\n",
      "Batch 80, loss=0.0317, recon=0.0316, kl=25.2764, beta=0.0000\n",
      "Batch 100, loss=0.0334, recon=0.0333, kl=22.4863, beta=0.0000\n",
      "Batch 120, loss=0.0507, recon=0.0507, kl=19.9451, beta=0.0000\n",
      "Batch 140, loss=0.0436, recon=0.0435, kl=20.2414, beta=0.0000\n",
      "Batch 160, loss=0.0226, recon=0.0225, kl=17.7195, beta=0.0000\n",
      "Batch 180, loss=0.0323, recon=0.0322, kl=17.8935, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0522, KL: 21.7653, Current Beta: 0.0000) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0400, recon=0.0399, kl=8.4829, beta=0.0000\n",
      "Batch 40, loss=0.0325, recon=0.0324, kl=7.7392, beta=0.0000\n",
      "Batch 60, loss=0.0257, recon=0.0256, kl=8.8526, beta=0.0000\n",
      "Batch 80, loss=0.0290, recon=0.0289, kl=8.9075, beta=0.0000\n",
      "Batch 100, loss=0.0692, recon=0.0691, kl=7.0827, beta=0.0000\n",
      "Batch 120, loss=0.0509, recon=0.0508, kl=6.8763, beta=0.0000\n",
      "Batch 140, loss=0.0465, recon=0.0465, kl=7.5459, beta=0.0000\n",
      "Batch 160, loss=0.0577, recon=0.0577, kl=6.4373, beta=0.0000\n",
      "Batch 180, loss=0.0527, recon=0.0526, kl=4.9445, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0531 (Recon: 0.0530, KL: 8.0999, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0316, recon=0.0316, kl=0.8134, beta=0.0000\n",
      "Batch 40, loss=0.0432, recon=0.0431, kl=1.9348, beta=0.0000\n",
      "Batch 60, loss=0.0388, recon=0.0388, kl=2.1792, beta=0.0000\n",
      "Batch 80, loss=0.2862, recon=0.2861, kl=3.8747, beta=0.0000\n",
      "Batch 100, loss=0.0440, recon=0.0438, kl=8.9893, beta=0.0000\n",
      "Batch 120, loss=0.0271, recon=0.0269, kl=8.1934, beta=0.0000\n",
      "Batch 140, loss=0.0464, recon=0.0463, kl=4.4276, beta=0.0000\n",
      "Batch 160, loss=0.0414, recon=0.0413, kl=2.6225, beta=0.0000\n",
      "Batch 180, loss=0.0500, recon=0.0500, kl=1.6790, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0516, KL: 4.1810, Current Beta: 0.0000) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0478\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0466, recon=0.0466, kl=0.5127, beta=0.0001\n",
      "Batch 40, loss=0.0494, recon=0.0492, kl=3.0552, beta=0.0001\n",
      "Batch 60, loss=0.0366, recon=0.0364, kl=2.9184, beta=0.0001\n",
      "Batch 80, loss=0.0334, recon=0.0333, kl=1.3006, beta=0.0001\n",
      "Batch 100, loss=0.0273, recon=0.0272, kl=0.5666, beta=0.0001\n",
      "Batch 120, loss=0.0555, recon=0.0555, kl=0.2853, beta=0.0001\n",
      "Batch 140, loss=0.0332, recon=0.0331, kl=0.1705, beta=0.0001\n",
      "Batch 160, loss=0.0272, recon=0.0272, kl=0.1528, beta=0.0001\n",
      "Batch 180, loss=0.0766, recon=0.0766, kl=0.1389, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0515 (Recon: 0.0514, KL: 1.0807, Current Beta: 0.0001) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0290, recon=0.0290, kl=0.0381, beta=0.0002\n",
      "Batch 40, loss=0.0277, recon=0.0277, kl=0.0124, beta=0.0002\n",
      "Batch 60, loss=0.0316, recon=0.0316, kl=0.0159, beta=0.0002\n",
      "Batch 80, loss=0.0320, recon=0.0320, kl=0.0359, beta=0.0002\n",
      "Batch 100, loss=0.0649, recon=0.0649, kl=0.0339, beta=0.0002\n",
      "Batch 120, loss=0.0432, recon=0.0432, kl=0.0129, beta=0.0002\n",
      "Batch 140, loss=0.0294, recon=0.0294, kl=0.0154, beta=0.0002\n",
      "Batch 160, loss=0.0311, recon=0.0311, kl=0.0160, beta=0.0002\n",
      "Batch 180, loss=0.0589, recon=0.0589, kl=0.0164, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0481 (Recon: 0.0481, KL: 0.0299, Current Beta: 0.0002) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0321, recon=0.0321, kl=0.0039, beta=0.0004\n",
      "Batch 40, loss=0.0614, recon=0.0614, kl=0.0069, beta=0.0004\n",
      "Batch 60, loss=0.0270, recon=0.0270, kl=0.0024, beta=0.0004\n",
      "Batch 80, loss=0.0323, recon=0.0323, kl=0.0026, beta=0.0004\n",
      "Batch 100, loss=0.0362, recon=0.0362, kl=0.0041, beta=0.0004\n",
      "Batch 120, loss=0.0320, recon=0.0320, kl=0.0013, beta=0.0004\n",
      "Batch 140, loss=0.0355, recon=0.0355, kl=0.0054, beta=0.0004\n",
      "Batch 160, loss=0.0228, recon=0.0228, kl=0.0122, beta=0.0004\n",
      "Batch 180, loss=0.0277, recon=0.0277, kl=0.0064, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0478 (Recon: 0.0478, KL: 0.0066, Current Beta: 0.0004) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0542, recon=0.0542, kl=0.0029, beta=0.0006\n",
      "Batch 40, loss=0.0532, recon=0.0532, kl=0.0078, beta=0.0006\n",
      "Batch 60, loss=0.0427, recon=0.0427, kl=0.0209, beta=0.0006\n",
      "Batch 80, loss=0.1301, recon=0.1301, kl=0.0054, beta=0.0006\n",
      "Batch 100, loss=0.0474, recon=0.0474, kl=0.0054, beta=0.0006\n",
      "Batch 120, loss=0.0216, recon=0.0216, kl=0.0019, beta=0.0006\n",
      "Batch 140, loss=0.0386, recon=0.0385, kl=0.0010, beta=0.0006\n",
      "Batch 160, loss=0.0584, recon=0.0584, kl=0.0007, beta=0.0006\n",
      "Batch 180, loss=0.0376, recon=0.0376, kl=0.0006, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0462, KL: 0.0060, Current Beta: 0.0006) | Avg Valid Loss: 0.0439 | Avg Valid recon Loss: 0.0439\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0242, recon=0.0242, kl=0.0005, beta=0.0010\n",
      "Batch 40, loss=0.0353, recon=0.0353, kl=0.0008, beta=0.0010\n",
      "Batch 60, loss=0.0482, recon=0.0482, kl=0.0031, beta=0.0010\n",
      "Batch 80, loss=0.0444, recon=0.0444, kl=0.0036, beta=0.0010\n",
      "Batch 100, loss=0.0403, recon=0.0403, kl=0.0025, beta=0.0010\n",
      "Batch 120, loss=0.0505, recon=0.0505, kl=0.0021, beta=0.0010\n",
      "Batch 140, loss=0.0452, recon=0.0452, kl=0.0012, beta=0.0010\n",
      "Batch 160, loss=0.0524, recon=0.0524, kl=0.0013, beta=0.0010\n",
      "Batch 180, loss=0.0298, recon=0.0298, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0497, KL: 0.0027, Current Beta: 0.0010) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1704, recon=0.1704, kl=0.0020, beta=0.0010\n",
      "Batch 40, loss=0.0307, recon=0.0307, kl=0.0023, beta=0.0010\n",
      "Batch 60, loss=0.0376, recon=0.0376, kl=0.0009, beta=0.0010\n",
      "Batch 80, loss=0.0300, recon=0.0300, kl=0.0060, beta=0.0010\n",
      "Batch 100, loss=0.0392, recon=0.0392, kl=0.0011, beta=0.0010\n",
      "Batch 120, loss=0.0474, recon=0.0474, kl=0.0013, beta=0.0010\n",
      "Batch 140, loss=0.1700, recon=0.1700, kl=0.0007, beta=0.0010\n",
      "Batch 160, loss=0.0393, recon=0.0393, kl=0.0093, beta=0.0010\n",
      "Batch 180, loss=0.0544, recon=0.0544, kl=0.0071, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0492 (Recon: 0.0492, KL: 0.0042, Current Beta: 0.0010) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0355, recon=0.0355, kl=0.0023, beta=0.0010\n",
      "Batch 40, loss=0.1403, recon=0.1403, kl=0.0016, beta=0.0010\n",
      "Batch 60, loss=0.0373, recon=0.0373, kl=0.0015, beta=0.0010\n",
      "Batch 80, loss=0.6171, recon=0.6171, kl=0.0008, beta=0.0010\n",
      "Batch 100, loss=0.0553, recon=0.0553, kl=0.0151, beta=0.0010\n",
      "Batch 120, loss=0.0359, recon=0.0359, kl=0.0063, beta=0.0010\n",
      "Batch 140, loss=0.0348, recon=0.0348, kl=0.0067, beta=0.0010\n",
      "Batch 160, loss=0.0844, recon=0.0844, kl=0.0038, beta=0.0010\n",
      "Batch 180, loss=0.0339, recon=0.0339, kl=0.0012, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0550 (Recon: 0.0550, KL: 0.0059, Current Beta: 0.0010) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0346, recon=0.0346, kl=0.0026, beta=0.0010\n",
      "Batch 40, loss=0.0534, recon=0.0531, kl=0.3203, beta=0.0010\n",
      "Batch 60, loss=0.0548, recon=0.0528, kl=1.9497, beta=0.0010\n",
      "Batch 80, loss=0.0384, recon=0.0376, kl=0.7638, beta=0.0010\n",
      "Batch 100, loss=0.0658, recon=0.0654, kl=0.4165, beta=0.0010\n",
      "Batch 120, loss=0.0395, recon=0.0393, kl=0.2030, beta=0.0010\n",
      "Batch 140, loss=0.0283, recon=0.0283, kl=0.0319, beta=0.0010\n",
      "Batch 160, loss=0.0655, recon=0.0655, kl=0.0154, beta=0.0010\n",
      "Batch 180, loss=0.0435, recon=0.0435, kl=0.0088, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0525, KL: 0.4207, Current Beta: 0.0010) | Avg Valid Loss: 0.0447 | Avg Valid recon Loss: 0.0447\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=0.0038, beta=0.0010\n",
      "Batch 40, loss=0.0380, recon=0.0379, kl=0.0041, beta=0.0010\n",
      "Batch 60, loss=0.0863, recon=0.0863, kl=0.0026, beta=0.0010\n",
      "Batch 80, loss=0.0480, recon=0.0480, kl=0.0023, beta=0.0010\n",
      "Batch 100, loss=0.0381, recon=0.0381, kl=0.0021, beta=0.0010\n",
      "Batch 120, loss=0.0376, recon=0.0376, kl=0.0014, beta=0.0010\n",
      "Batch 140, loss=0.0495, recon=0.0495, kl=0.0009, beta=0.0010\n",
      "Batch 160, loss=0.0261, recon=0.0261, kl=0.0006, beta=0.0010\n",
      "Batch 180, loss=0.0368, recon=0.0368, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0508, KL: 0.0027, Current Beta: 0.0010) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0395\n",
      "\n",
      "[VRAE Run 41/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7475, recon=0.7475, kl=0.8503, beta=0.0000\n",
      "Batch 40, loss=0.4996, recon=0.4996, kl=2.3733, beta=0.0000\n",
      "Batch 60, loss=0.3999, recon=0.3999, kl=15.8680, beta=0.0000\n",
      "Batch 80, loss=0.4723, recon=0.4723, kl=33.0543, beta=0.0000\n",
      "Batch 100, loss=0.6220, recon=0.6220, kl=51.5200, beta=0.0000\n",
      "Batch 120, loss=0.2154, recon=0.2154, kl=63.2632, beta=0.0000\n",
      "Batch 140, loss=0.2793, recon=0.2793, kl=70.3605, beta=0.0000\n",
      "Batch 160, loss=0.4279, recon=0.4279, kl=77.1197, beta=0.0000\n",
      "Batch 180, loss=0.2818, recon=0.2818, kl=83.9628, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4517 (Recon: 0.4517, KL: 40.1720, Current Beta: 0.0000) | Avg Valid Loss: 0.2440 | Avg Valid recon Loss: 0.2440\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2111, recon=0.2111, kl=90.6220, beta=0.0000\n",
      "Batch 40, loss=0.1375, recon=0.1375, kl=95.9625, beta=0.0000\n",
      "Batch 60, loss=0.2673, recon=0.2673, kl=100.6848, beta=0.0000\n",
      "Batch 80, loss=0.1721, recon=0.1721, kl=105.6242, beta=0.0000\n",
      "Batch 100, loss=0.2872, recon=0.2872, kl=109.5273, beta=0.0000\n",
      "Batch 120, loss=0.2495, recon=0.2495, kl=112.4462, beta=0.0000\n",
      "Batch 140, loss=0.2159, recon=0.2159, kl=114.7762, beta=0.0000\n",
      "Batch 160, loss=0.1363, recon=0.1363, kl=117.9542, beta=0.0000\n",
      "Batch 180, loss=0.1537, recon=0.1537, kl=119.9371, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2206 (Recon: 0.2206, KL: 105.8205, Current Beta: 0.0000) | Avg Valid Loss: 0.1538 | Avg Valid recon Loss: 0.1538\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1502, recon=0.1502, kl=121.0003, beta=0.0000\n",
      "Batch 40, loss=0.1498, recon=0.1498, kl=124.2448, beta=0.0000\n",
      "Batch 60, loss=0.1673, recon=0.1673, kl=126.1883, beta=0.0000\n",
      "Batch 80, loss=0.1108, recon=0.1108, kl=127.5192, beta=0.0000\n",
      "Batch 100, loss=0.2476, recon=0.2476, kl=129.2070, beta=0.0000\n",
      "Batch 120, loss=0.1433, recon=0.1433, kl=131.5175, beta=0.0000\n",
      "Batch 140, loss=0.1462, recon=0.1462, kl=132.4576, beta=0.0000\n",
      "Batch 160, loss=0.1253, recon=0.1252, kl=134.0048, beta=0.0000\n",
      "Batch 180, loss=0.1706, recon=0.1706, kl=134.8018, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1647 (Recon: 0.1647, KL: 128.2152, Current Beta: 0.0000) | Avg Valid Loss: 0.1211 | Avg Valid recon Loss: 0.1211\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0993, recon=0.0993, kl=136.7688, beta=0.0000\n",
      "Batch 40, loss=0.1168, recon=0.1168, kl=137.0007, beta=0.0000\n",
      "Batch 60, loss=0.1323, recon=0.1323, kl=138.4837, beta=0.0000\n",
      "Batch 80, loss=0.2635, recon=0.2635, kl=138.4075, beta=0.0000\n",
      "Batch 100, loss=0.1145, recon=0.1145, kl=140.5572, beta=0.0000\n",
      "Batch 120, loss=0.1095, recon=0.1095, kl=141.5695, beta=0.0000\n",
      "Batch 140, loss=0.2399, recon=0.2399, kl=139.6139, beta=0.0000\n",
      "Batch 160, loss=0.1539, recon=0.1539, kl=139.0939, beta=0.0000\n",
      "Batch 180, loss=0.0772, recon=0.0772, kl=139.1911, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1345 (Recon: 0.1345, KL: 138.6030, Current Beta: 0.0000) | Avg Valid Loss: 0.1028 | Avg Valid recon Loss: 0.1028\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1539, recon=0.1538, kl=137.1049, beta=0.0000\n",
      "Batch 40, loss=0.1159, recon=0.1159, kl=138.0130, beta=0.0000\n",
      "Batch 60, loss=0.1513, recon=0.1513, kl=136.2250, beta=0.0000\n",
      "Batch 80, loss=0.1870, recon=0.1870, kl=135.9223, beta=0.0000\n",
      "Batch 100, loss=0.0622, recon=0.0622, kl=133.1389, beta=0.0000\n",
      "Batch 120, loss=0.1030, recon=0.1030, kl=131.5374, beta=0.0000\n",
      "Batch 140, loss=0.0911, recon=0.0911, kl=131.8674, beta=0.0000\n",
      "Batch 160, loss=0.1091, recon=0.1090, kl=131.4879, beta=0.0000\n",
      "Batch 180, loss=0.0636, recon=0.0636, kl=131.4997, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1153 (Recon: 0.1153, KL: 134.5759, Current Beta: 0.0000) | Avg Valid Loss: 0.0906 | Avg Valid recon Loss: 0.0906\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0624, recon=0.0624, kl=128.0914, beta=0.0000\n",
      "Batch 40, loss=0.0958, recon=0.0957, kl=123.8342, beta=0.0000\n",
      "Batch 60, loss=0.0956, recon=0.0956, kl=117.0398, beta=0.0000\n",
      "Batch 80, loss=0.0780, recon=0.0780, kl=110.8837, beta=0.0000\n",
      "Batch 100, loss=0.0839, recon=0.0839, kl=108.5079, beta=0.0000\n",
      "Batch 120, loss=0.0721, recon=0.0721, kl=103.6951, beta=0.0000\n",
      "Batch 140, loss=0.1556, recon=0.1556, kl=100.0179, beta=0.0000\n",
      "Batch 160, loss=0.0604, recon=0.0604, kl=97.5198, beta=0.0000\n",
      "Batch 180, loss=0.0582, recon=0.0582, kl=99.4225, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1018 (Recon: 0.1018, KL: 111.8275, Current Beta: 0.0000) | Avg Valid Loss: 0.0828 | Avg Valid recon Loss: 0.0828\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0759, recon=0.0759, kl=94.4697, beta=0.0000\n",
      "Batch 40, loss=0.0472, recon=0.0471, kl=81.1131, beta=0.0000\n",
      "Batch 60, loss=0.5386, recon=0.5385, kl=76.9359, beta=0.0000\n",
      "Batch 80, loss=0.0503, recon=0.0503, kl=73.3356, beta=0.0000\n",
      "Batch 100, loss=0.0916, recon=0.0916, kl=66.5345, beta=0.0000\n",
      "Batch 120, loss=0.0511, recon=0.0511, kl=67.4359, beta=0.0000\n",
      "Batch 140, loss=0.0940, recon=0.0939, kl=64.3867, beta=0.0000\n",
      "Batch 160, loss=0.0650, recon=0.0650, kl=65.8979, beta=0.0000\n",
      "Batch 180, loss=0.0812, recon=0.0812, kl=62.9413, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0921 (Recon: 0.0920, KL: 74.2387, Current Beta: 0.0000) | Avg Valid Loss: 0.0763 | Avg Valid recon Loss: 0.0763\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0923, recon=0.0922, kl=43.9066, beta=0.0000\n",
      "Batch 40, loss=0.1070, recon=0.1070, kl=37.8676, beta=0.0000\n",
      "Batch 60, loss=0.0813, recon=0.0812, kl=34.7825, beta=0.0000\n",
      "Batch 80, loss=0.0524, recon=0.0523, kl=33.9718, beta=0.0000\n",
      "Batch 100, loss=0.0638, recon=0.0637, kl=32.0420, beta=0.0000\n",
      "Batch 120, loss=0.0705, recon=0.0705, kl=28.1997, beta=0.0000\n",
      "Batch 140, loss=0.0650, recon=0.0649, kl=28.4983, beta=0.0000\n",
      "Batch 160, loss=0.0370, recon=0.0369, kl=28.6648, beta=0.0000\n",
      "Batch 180, loss=0.0578, recon=0.0578, kl=25.3126, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0850 (Recon: 0.0850, KL: 34.3609, Current Beta: 0.0000) | Avg Valid Loss: 0.0713 | Avg Valid recon Loss: 0.0712\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0546, recon=0.0545, kl=14.2998, beta=0.0000\n",
      "Batch 40, loss=0.0803, recon=0.0802, kl=14.4843, beta=0.0000\n",
      "Batch 60, loss=0.0795, recon=0.0794, kl=12.8304, beta=0.0000\n",
      "Batch 80, loss=0.0526, recon=0.0526, kl=12.0162, beta=0.0000\n",
      "Batch 100, loss=0.0555, recon=0.0555, kl=10.2780, beta=0.0000\n",
      "Batch 120, loss=0.0507, recon=0.0507, kl=11.7035, beta=0.0000\n",
      "Batch 140, loss=0.0448, recon=0.0447, kl=8.4906, beta=0.0000\n",
      "Batch 160, loss=0.0611, recon=0.0610, kl=10.3684, beta=0.0000\n",
      "Batch 180, loss=0.0437, recon=0.0437, kl=8.2245, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0798 (Recon: 0.0798, KL: 12.3317, Current Beta: 0.0000) | Avg Valid Loss: 0.0685 | Avg Valid recon Loss: 0.0684\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0474, recon=0.0473, kl=3.3299, beta=0.0000\n",
      "Batch 40, loss=0.0376, recon=0.0376, kl=4.0416, beta=0.0000\n",
      "Batch 60, loss=0.0726, recon=0.0726, kl=3.8970, beta=0.0000\n",
      "Batch 80, loss=0.0754, recon=0.0753, kl=2.9177, beta=0.0000\n",
      "Batch 100, loss=0.0460, recon=0.0460, kl=3.5342, beta=0.0000\n",
      "Batch 120, loss=0.0427, recon=0.0427, kl=2.5353, beta=0.0000\n",
      "Batch 140, loss=0.0367, recon=0.0367, kl=3.0900, beta=0.0000\n",
      "Batch 160, loss=0.1110, recon=0.1110, kl=2.4804, beta=0.0000\n",
      "Batch 180, loss=0.0694, recon=0.0694, kl=2.7699, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0755 (Recon: 0.0754, KL: 3.4830, Current Beta: 0.0000) | Avg Valid Loss: 0.0654 | Avg Valid recon Loss: 0.0654\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0403, recon=0.0403, kl=0.7158, beta=0.0000\n",
      "Batch 40, loss=0.0612, recon=0.0611, kl=1.2403, beta=0.0000\n",
      "Batch 60, loss=0.0414, recon=0.0413, kl=0.7509, beta=0.0000\n",
      "Batch 80, loss=0.0874, recon=0.0874, kl=0.6254, beta=0.0000\n",
      "Batch 100, loss=0.0535, recon=0.0535, kl=0.8052, beta=0.0000\n",
      "Batch 120, loss=0.0419, recon=0.0419, kl=0.8118, beta=0.0000\n",
      "Batch 140, loss=0.0726, recon=0.0725, kl=0.6330, beta=0.0000\n",
      "Batch 160, loss=0.0595, recon=0.0595, kl=0.6369, beta=0.0000\n",
      "Batch 180, loss=0.0400, recon=0.0399, kl=0.4562, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0725 (Recon: 0.0725, KL: 0.8393, Current Beta: 0.0000) | Avg Valid Loss: 0.0629 | Avg Valid recon Loss: 0.0628\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0629, recon=0.0628, kl=0.2239, beta=0.0001\n",
      "Batch 40, loss=0.0483, recon=0.0483, kl=0.1856, beta=0.0001\n",
      "Batch 60, loss=0.0521, recon=0.0521, kl=0.1772, beta=0.0001\n",
      "Batch 80, loss=0.0519, recon=0.0519, kl=0.1388, beta=0.0001\n",
      "Batch 100, loss=0.0360, recon=0.0360, kl=0.1142, beta=0.0001\n",
      "Batch 120, loss=0.0489, recon=0.0489, kl=0.1030, beta=0.0001\n",
      "Batch 140, loss=0.0359, recon=0.0359, kl=0.0843, beta=0.0001\n",
      "Batch 160, loss=0.0423, recon=0.0423, kl=0.0658, beta=0.0001\n",
      "Batch 180, loss=0.0712, recon=0.0712, kl=0.0924, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0696 (Recon: 0.0696, KL: 0.1493, Current Beta: 0.0001) | Avg Valid Loss: 0.0603 | Avg Valid recon Loss: 0.0603\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0685, recon=0.0685, kl=0.0202, beta=0.0002\n",
      "Batch 40, loss=0.0351, recon=0.0351, kl=0.0144, beta=0.0002\n",
      "Batch 60, loss=0.0510, recon=0.0510, kl=0.0156, beta=0.0002\n",
      "Batch 80, loss=0.0464, recon=0.0464, kl=0.0082, beta=0.0002\n",
      "Batch 100, loss=0.0393, recon=0.0393, kl=0.0154, beta=0.0002\n",
      "Batch 120, loss=0.0619, recon=0.0619, kl=0.0111, beta=0.0002\n",
      "Batch 140, loss=0.0493, recon=0.0493, kl=0.0073, beta=0.0002\n",
      "Batch 160, loss=0.0518, recon=0.0518, kl=0.0046, beta=0.0002\n",
      "Batch 180, loss=0.0738, recon=0.0738, kl=0.0039, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0667 (Recon: 0.0667, KL: 0.0161, Current Beta: 0.0002) | Avg Valid Loss: 0.0586 | Avg Valid recon Loss: 0.0586\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.2441, recon=0.2441, kl=0.0024, beta=0.0004\n",
      "Batch 40, loss=0.0349, recon=0.0349, kl=0.0019, beta=0.0004\n",
      "Batch 60, loss=0.0373, recon=0.0373, kl=0.0016, beta=0.0004\n",
      "Batch 80, loss=0.0523, recon=0.0523, kl=0.0012, beta=0.0004\n",
      "Batch 100, loss=0.0817, recon=0.0817, kl=0.0009, beta=0.0004\n",
      "Batch 120, loss=0.0503, recon=0.0503, kl=0.0022, beta=0.0004\n",
      "Batch 140, loss=0.0601, recon=0.0601, kl=0.0015, beta=0.0004\n",
      "Batch 160, loss=0.0365, recon=0.0365, kl=0.0029, beta=0.0004\n",
      "Batch 180, loss=0.0976, recon=0.0976, kl=0.0013, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0646 (Recon: 0.0646, KL: 0.0023, Current Beta: 0.0004) | Avg Valid Loss: 0.0562 | Avg Valid recon Loss: 0.0562\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0479, recon=0.0479, kl=0.0006, beta=0.0006\n",
      "Batch 40, loss=0.0530, recon=0.0530, kl=0.0009, beta=0.0006\n",
      "Batch 60, loss=0.0379, recon=0.0379, kl=0.0009, beta=0.0006\n",
      "Batch 80, loss=0.0346, recon=0.0346, kl=0.0008, beta=0.0006\n",
      "Batch 100, loss=0.0345, recon=0.0345, kl=0.0005, beta=0.0006\n",
      "Batch 120, loss=0.0297, recon=0.0297, kl=0.0006, beta=0.0006\n",
      "Batch 140, loss=0.0541, recon=0.0541, kl=0.0010, beta=0.0006\n",
      "Batch 160, loss=0.0478, recon=0.0478, kl=0.0005, beta=0.0006\n",
      "Batch 180, loss=0.0391, recon=0.0391, kl=0.0006, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0627 (Recon: 0.0627, KL: 0.0009, Current Beta: 0.0006) | Avg Valid Loss: 0.0545 | Avg Valid recon Loss: 0.0545\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0463, recon=0.0463, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0556, recon=0.0556, kl=0.0007, beta=0.0010\n",
      "Batch 60, loss=0.0781, recon=0.0781, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0554, recon=0.0554, kl=0.0005, beta=0.0010\n",
      "Batch 100, loss=0.0388, recon=0.0388, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0304, recon=0.0304, kl=0.0001, beta=0.0010\n",
      "Batch 140, loss=0.0686, recon=0.0686, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0368, recon=0.0368, kl=0.0006, beta=0.0010\n",
      "Batch 180, loss=0.0528, recon=0.0528, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0609 (Recon: 0.0609, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0534 | Avg Valid recon Loss: 0.0534\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0364, recon=0.0364, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0480, recon=0.0480, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0327, recon=0.0327, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.3132, recon=0.3132, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0422, recon=0.0422, kl=0.0002, beta=0.0010\n",
      "Batch 120, loss=0.0436, recon=0.0436, kl=0.0001, beta=0.0010\n",
      "Batch 140, loss=0.0340, recon=0.0340, kl=0.0005, beta=0.0010\n",
      "Batch 160, loss=0.0631, recon=0.0631, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0376, recon=0.0376, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0595 (Recon: 0.0595, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0518 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0368, recon=0.0368, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0522, recon=0.0522, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0336, recon=0.0336, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0385, recon=0.0385, kl=0.0003, beta=0.0010\n",
      "Batch 100, loss=0.0424, recon=0.0424, kl=0.0002, beta=0.0010\n",
      "Batch 120, loss=0.0303, recon=0.0303, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0487, recon=0.0487, kl=0.0006, beta=0.0010\n",
      "Batch 160, loss=0.0337, recon=0.0337, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=1.0477, recon=1.0477, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0513 | Avg Valid recon Loss: 0.0513\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0504, recon=0.0504, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0506, recon=0.0506, kl=0.0007, beta=0.0010\n",
      "Batch 60, loss=0.0473, recon=0.0473, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.2217, recon=0.2217, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0317, recon=0.0317, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0450, recon=0.0450, kl=0.0001, beta=0.0010\n",
      "Batch 140, loss=0.0347, recon=0.0347, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0800, recon=0.0800, kl=0.0001, beta=0.0010\n",
      "Batch 180, loss=0.0589, recon=0.0589, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0565 (Recon: 0.0565, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0495 | Avg Valid recon Loss: 0.0495\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0456, recon=0.0456, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0519, recon=0.0519, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0336, recon=0.0336, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0257, recon=0.0257, kl=0.0001, beta=0.0010\n",
      "Batch 100, loss=0.1136, recon=0.1136, kl=0.0006, beta=0.0010\n",
      "Batch 120, loss=0.0442, recon=0.0442, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0435, recon=0.0435, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0479, recon=0.0479, kl=0.0004, beta=0.0010\n",
      "Batch 180, loss=0.0391, recon=0.0391, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0491 | Avg Valid recon Loss: 0.0491\n",
      "\n",
      "[VRAE Run 42/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2199, recon=0.2199, kl=50.5936, beta=0.0000\n",
      "Batch 40, loss=0.2389, recon=0.2389, kl=89.7168, beta=0.0000\n",
      "Batch 60, loss=0.1167, recon=0.1167, kl=95.7070, beta=0.0000\n",
      "Batch 80, loss=0.2073, recon=0.2073, kl=97.9520, beta=0.0000\n",
      "Batch 100, loss=0.1335, recon=0.1335, kl=113.3673, beta=0.0000\n",
      "Batch 120, loss=0.0958, recon=0.0958, kl=112.2042, beta=0.0000\n",
      "Batch 140, loss=0.0872, recon=0.0872, kl=107.7966, beta=0.0000\n",
      "Batch 160, loss=0.0763, recon=0.0763, kl=121.1563, beta=0.0000\n",
      "Batch 180, loss=0.0695, recon=0.0695, kl=114.4939, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1736 (Recon: 0.1736, KL: 94.4156, Current Beta: 0.0000) | Avg Valid Loss: 0.0760 | Avg Valid recon Loss: 0.0760\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0654, recon=0.0654, kl=87.4932, beta=0.0000\n",
      "Batch 40, loss=0.0898, recon=0.0898, kl=106.6942, beta=0.0000\n",
      "Batch 60, loss=0.0557, recon=0.0557, kl=128.0339, beta=0.0000\n",
      "Batch 80, loss=0.0634, recon=0.0634, kl=135.9405, beta=0.0000\n",
      "Batch 100, loss=0.0519, recon=0.0519, kl=133.3940, beta=0.0000\n",
      "Batch 120, loss=0.0409, recon=0.0409, kl=132.0561, beta=0.0000\n",
      "Batch 140, loss=0.0526, recon=0.0526, kl=130.2273, beta=0.0000\n",
      "Batch 160, loss=0.0550, recon=0.0550, kl=114.9181, beta=0.0000\n",
      "Batch 180, loss=0.0406, recon=0.0406, kl=113.1531, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0750 (Recon: 0.0750, KL: 119.9722, Current Beta: 0.0000) | Avg Valid Loss: 0.0599 | Avg Valid recon Loss: 0.0599\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0878, recon=0.0878, kl=123.7029, beta=0.0000\n",
      "Batch 40, loss=0.0354, recon=0.0353, kl=125.4296, beta=0.0000\n",
      "Batch 60, loss=0.0365, recon=0.0365, kl=132.3844, beta=0.0000\n",
      "Batch 80, loss=0.0532, recon=0.0532, kl=125.8544, beta=0.0000\n",
      "Batch 100, loss=0.0437, recon=0.0437, kl=114.2035, beta=0.0000\n",
      "Batch 120, loss=0.0505, recon=0.0505, kl=109.7349, beta=0.0000\n",
      "Batch 140, loss=0.0612, recon=0.0612, kl=115.7203, beta=0.0000\n",
      "Batch 160, loss=0.1233, recon=0.1233, kl=118.1389, beta=0.0000\n",
      "Batch 180, loss=0.0342, recon=0.0342, kl=108.2075, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0657 (Recon: 0.0657, KL: 119.7657, Current Beta: 0.0000) | Avg Valid Loss: 0.0526 | Avg Valid recon Loss: 0.0526\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0443, recon=0.0443, kl=108.6259, beta=0.0000\n",
      "Batch 40, loss=0.0279, recon=0.0279, kl=115.0872, beta=0.0000\n",
      "Batch 60, loss=0.0383, recon=0.0383, kl=121.3059, beta=0.0000\n",
      "Batch 80, loss=0.0605, recon=0.0605, kl=133.3077, beta=0.0000\n",
      "Batch 100, loss=0.0501, recon=0.0501, kl=112.8248, beta=0.0000\n",
      "Batch 120, loss=0.0614, recon=0.0614, kl=93.2766, beta=0.0000\n",
      "Batch 140, loss=0.0989, recon=0.0989, kl=100.0577, beta=0.0000\n",
      "Batch 160, loss=0.0538, recon=0.0538, kl=115.4461, beta=0.0000\n",
      "Batch 180, loss=0.0248, recon=0.0248, kl=119.6786, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0609 (Recon: 0.0609, KL: 111.8742, Current Beta: 0.0000) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0953, recon=0.0953, kl=120.2729, beta=0.0000\n",
      "Batch 40, loss=0.0337, recon=0.0337, kl=119.7010, beta=0.0000\n",
      "Batch 60, loss=0.0474, recon=0.0474, kl=117.5614, beta=0.0000\n",
      "Batch 80, loss=0.0288, recon=0.0288, kl=105.5957, beta=0.0000\n",
      "Batch 100, loss=0.0321, recon=0.0321, kl=98.0501, beta=0.0000\n",
      "Batch 120, loss=0.0530, recon=0.0530, kl=106.0925, beta=0.0000\n",
      "Batch 140, loss=0.0309, recon=0.0309, kl=120.3827, beta=0.0000\n",
      "Batch 160, loss=0.0448, recon=0.0448, kl=118.1370, beta=0.0000\n",
      "Batch 180, loss=0.0543, recon=0.0543, kl=109.4995, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0561 (Recon: 0.0560, KL: 113.0559, Current Beta: 0.0000) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0541\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0495, recon=0.0495, kl=107.3931, beta=0.0000\n",
      "Batch 40, loss=0.0519, recon=0.0519, kl=110.7208, beta=0.0000\n",
      "Batch 60, loss=0.0332, recon=0.0332, kl=111.7604, beta=0.0000\n",
      "Batch 80, loss=0.1691, recon=0.1691, kl=115.9119, beta=0.0000\n",
      "Batch 100, loss=0.0639, recon=0.0638, kl=113.7457, beta=0.0000\n",
      "Batch 120, loss=0.0370, recon=0.0370, kl=108.9437, beta=0.0000\n",
      "Batch 140, loss=0.0355, recon=0.0355, kl=103.4398, beta=0.0000\n",
      "Batch 160, loss=0.0558, recon=0.0558, kl=106.6322, beta=0.0000\n",
      "Batch 180, loss=0.0594, recon=0.0594, kl=111.0911, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0565 (Recon: 0.0565, KL: 109.1862, Current Beta: 0.0000) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0356, recon=0.0355, kl=107.0286, beta=0.0000\n",
      "Batch 40, loss=0.0645, recon=0.0644, kl=95.2425, beta=0.0000\n",
      "Batch 60, loss=0.0311, recon=0.0311, kl=93.6633, beta=0.0000\n",
      "Batch 80, loss=0.0409, recon=0.0409, kl=89.5945, beta=0.0000\n",
      "Batch 100, loss=0.1762, recon=0.1761, kl=87.5154, beta=0.0000\n",
      "Batch 120, loss=0.0515, recon=0.0514, kl=99.3843, beta=0.0000\n",
      "Batch 140, loss=0.0488, recon=0.0487, kl=110.7429, beta=0.0000\n",
      "Batch 160, loss=0.0491, recon=0.0490, kl=98.3716, beta=0.0000\n",
      "Batch 180, loss=0.0540, recon=0.0539, kl=96.9702, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0551 (Recon: 0.0550, KL: 98.0536, Current Beta: 0.0000) | Avg Valid Loss: 0.0487 | Avg Valid recon Loss: 0.0486\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1807, recon=0.1806, kl=85.0301, beta=0.0000\n",
      "Batch 40, loss=0.0448, recon=0.0447, kl=81.0868, beta=0.0000\n",
      "Batch 60, loss=0.0469, recon=0.0468, kl=76.0598, beta=0.0000\n",
      "Batch 80, loss=0.0751, recon=0.0750, kl=67.7880, beta=0.0000\n",
      "Batch 100, loss=0.0416, recon=0.0415, kl=71.6871, beta=0.0000\n",
      "Batch 120, loss=0.0694, recon=0.0693, kl=72.5721, beta=0.0000\n",
      "Batch 140, loss=0.0271, recon=0.0270, kl=68.7753, beta=0.0000\n",
      "Batch 160, loss=0.0398, recon=0.0397, kl=62.1653, beta=0.0000\n",
      "Batch 180, loss=0.0264, recon=0.0263, kl=63.6291, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0544, KL: 74.1626, Current Beta: 0.0000) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0322, recon=0.0320, kl=44.8799, beta=0.0000\n",
      "Batch 40, loss=0.0439, recon=0.0437, kl=45.0287, beta=0.0000\n",
      "Batch 60, loss=0.0578, recon=0.0576, kl=44.6222, beta=0.0000\n",
      "Batch 80, loss=0.0513, recon=0.0511, kl=37.8878, beta=0.0000\n",
      "Batch 100, loss=0.0291, recon=0.0290, kl=40.2795, beta=0.0000\n",
      "Batch 120, loss=0.0293, recon=0.0292, kl=36.0225, beta=0.0000\n",
      "Batch 140, loss=0.0476, recon=0.0475, kl=37.3563, beta=0.0000\n",
      "Batch 160, loss=0.0276, recon=0.0274, kl=33.5484, beta=0.0000\n",
      "Batch 180, loss=0.0689, recon=0.0688, kl=38.4247, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0509 (Recon: 0.0507, KL: 41.2984, Current Beta: 0.0000) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0273, recon=0.0271, kl=19.1770, beta=0.0000\n",
      "Batch 40, loss=0.0468, recon=0.0465, kl=29.7111, beta=0.0000\n",
      "Batch 60, loss=0.0340, recon=0.0336, kl=36.4668, beta=0.0000\n",
      "Batch 80, loss=0.0313, recon=0.0310, kl=29.4865, beta=0.0000\n",
      "Batch 100, loss=0.0356, recon=0.0354, kl=18.3663, beta=0.0000\n",
      "Batch 120, loss=0.0505, recon=0.0504, kl=15.1676, beta=0.0000\n",
      "Batch 140, loss=0.0568, recon=0.0564, kl=34.3965, beta=0.0000\n",
      "Batch 160, loss=0.0376, recon=0.0370, kl=59.7155, beta=0.0000\n",
      "Batch 180, loss=0.0346, recon=0.0340, kl=50.8409, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0501 (Recon: 0.0497, KL: 32.6618, Current Beta: 0.0000) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0305, recon=0.0298, kl=24.1658, beta=0.0000\n",
      "Batch 40, loss=0.0467, recon=0.0463, kl=14.7346, beta=0.0000\n",
      "Batch 60, loss=0.0303, recon=0.0294, kl=31.6938, beta=0.0000\n",
      "Batch 80, loss=0.0936, recon=0.0925, kl=39.5611, beta=0.0000\n",
      "Batch 100, loss=0.0656, recon=0.0646, kl=31.9054, beta=0.0000\n",
      "Batch 120, loss=0.1245, recon=0.1237, kl=27.3158, beta=0.0000\n",
      "Batch 140, loss=0.0499, recon=0.0492, kl=24.4495, beta=0.0000\n",
      "Batch 160, loss=0.0540, recon=0.0534, kl=20.9671, beta=0.0000\n",
      "Batch 180, loss=0.0345, recon=0.0340, kl=17.6508, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0505 (Recon: 0.0496, KL: 27.5657, Current Beta: 0.0000) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0335, recon=0.0329, kl=8.9827, beta=0.0001\n",
      "Batch 40, loss=0.1655, recon=0.1649, kl=8.5105, beta=0.0001\n",
      "Batch 60, loss=0.1777, recon=0.1765, kl=16.0948, beta=0.0001\n",
      "Batch 80, loss=0.0479, recon=0.0465, kl=17.5585, beta=0.0001\n",
      "Batch 100, loss=0.0265, recon=0.0253, kl=16.0022, beta=0.0001\n",
      "Batch 120, loss=0.1563, recon=0.1554, kl=12.0468, beta=0.0001\n",
      "Batch 140, loss=0.0331, recon=0.0323, kl=9.6165, beta=0.0001\n",
      "Batch 160, loss=0.0453, recon=0.0441, kl=16.2174, beta=0.0001\n",
      "Batch 180, loss=0.0510, recon=0.0496, kl=17.9694, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0484 (Recon: 0.0473, KL: 13.6767, Current Beta: 0.0001) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0397, recon=0.0365, kl=17.1986, beta=0.0002\n",
      "Batch 40, loss=0.0362, recon=0.0342, kl=10.5526, beta=0.0002\n",
      "Batch 60, loss=0.0666, recon=0.0637, kl=15.6643, beta=0.0002\n",
      "Batch 80, loss=0.0273, recon=0.0243, kl=16.6419, beta=0.0002\n",
      "Batch 100, loss=0.0720, recon=0.0695, kl=13.6868, beta=0.0002\n",
      "Batch 120, loss=0.0314, recon=0.0290, kl=12.9661, beta=0.0002\n",
      "Batch 140, loss=0.0305, recon=0.0281, kl=13.3252, beta=0.0002\n",
      "Batch 160, loss=0.0348, recon=0.0327, kl=11.5275, beta=0.0002\n",
      "Batch 180, loss=0.0493, recon=0.0475, kl=9.8183, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0510 (Recon: 0.0485, KL: 13.5890, Current Beta: 0.0002) | Avg Valid Loss: 0.0397 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0354, recon=0.0325, kl=7.5492, beta=0.0004\n",
      "Batch 40, loss=0.0458, recon=0.0435, kl=5.8533, beta=0.0004\n",
      "Batch 60, loss=0.0332, recon=0.0308, kl=6.4857, beta=0.0004\n",
      "Batch 80, loss=0.0344, recon=0.0325, kl=5.1367, beta=0.0004\n",
      "Batch 100, loss=0.0452, recon=0.0433, kl=5.0606, beta=0.0004\n",
      "Batch 120, loss=0.1636, recon=0.1620, kl=4.2635, beta=0.0004\n",
      "Batch 140, loss=0.0356, recon=0.0342, kl=3.8984, beta=0.0004\n",
      "Batch 160, loss=0.0389, recon=0.0374, kl=3.8885, beta=0.0004\n",
      "Batch 180, loss=0.0402, recon=0.0385, kl=4.2965, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0506 (Recon: 0.0485, KL: 5.5156, Current Beta: 0.0004) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0398, recon=0.0378, kl=3.2457, beta=0.0006\n",
      "Batch 40, loss=0.0627, recon=0.0612, kl=2.4222, beta=0.0006\n",
      "Batch 60, loss=0.0382, recon=0.0359, kl=3.6405, beta=0.0006\n",
      "Batch 80, loss=0.0377, recon=0.0363, kl=2.2865, beta=0.0006\n",
      "Batch 100, loss=0.0371, recon=0.0349, kl=3.5302, beta=0.0006\n",
      "Batch 120, loss=0.0689, recon=0.0671, kl=2.7741, beta=0.0006\n",
      "Batch 140, loss=0.0387, recon=0.0351, kl=5.8084, beta=0.0006\n",
      "Batch 160, loss=0.0442, recon=0.0410, kl=5.1299, beta=0.0006\n",
      "Batch 180, loss=0.0508, recon=0.0486, kl=3.6369, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0538 (Recon: 0.0515, KL: 3.6930, Current Beta: 0.0006) | Avg Valid Loss: 0.0477 | Avg Valid recon Loss: 0.0454\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0744, recon=0.0640, kl=10.3818, beta=0.0010\n",
      "Batch 40, loss=0.0398, recon=0.0312, kl=8.5832, beta=0.0010\n",
      "Batch 60, loss=0.0629, recon=0.0546, kl=8.3090, beta=0.0010\n",
      "Batch 80, loss=0.0973, recon=0.0822, kl=15.1432, beta=0.0010\n",
      "Batch 100, loss=0.0690, recon=0.0552, kl=13.7577, beta=0.0010\n",
      "Batch 120, loss=0.0567, recon=0.0454, kl=11.2251, beta=0.0010\n",
      "Batch 140, loss=1.7181, recon=1.7106, kl=7.5331, beta=0.0010\n",
      "Batch 160, loss=0.1333, recon=0.1184, kl=14.9185, beta=0.0010\n",
      "Batch 180, loss=0.0739, recon=0.0547, kl=19.1974, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.5001 (Recon: 0.4888, KL: 11.3024, Current Beta: 0.0010) | Avg Valid Loss: 0.0948 | Avg Valid recon Loss: 0.0753\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0851, recon=0.0633, kl=21.8064, beta=0.0010\n",
      "Batch 40, loss=0.0645, recon=0.0422, kl=22.3415, beta=0.0010\n",
      "Batch 60, loss=0.0769, recon=0.0555, kl=21.3772, beta=0.0010\n",
      "Batch 80, loss=0.0615, recon=0.0421, kl=19.3669, beta=0.0010\n",
      "Batch 100, loss=0.0908, recon=0.0728, kl=18.0692, beta=0.0010\n",
      "Batch 120, loss=0.0847, recon=0.0644, kl=20.3145, beta=0.0010\n",
      "Batch 140, loss=0.1098, recon=0.0898, kl=19.9849, beta=0.0010\n",
      "Batch 160, loss=0.0639, recon=0.0440, kl=19.8692, beta=0.0010\n",
      "Batch 180, loss=0.0628, recon=0.0456, kl=17.1615, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1613 (Recon: 0.1413, KL: 19.9965, Current Beta: 0.0010) | Avg Valid Loss: 0.0719 | Avg Valid recon Loss: 0.0541\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1479, recon=0.1324, kl=15.5233, beta=0.0010\n",
      "Batch 40, loss=0.8138, recon=0.7984, kl=15.3735, beta=0.0010\n",
      "Batch 60, loss=0.0586, recon=0.0416, kl=16.9963, beta=0.0010\n",
      "Batch 80, loss=0.0675, recon=0.0521, kl=15.3984, beta=0.0010\n",
      "Batch 100, loss=0.0460, recon=0.0328, kl=13.2246, beta=0.0010\n",
      "Batch 120, loss=0.0691, recon=0.0577, kl=11.3949, beta=0.0010\n",
      "Batch 140, loss=0.0353, recon=0.0259, kl=9.3940, beta=0.0010\n",
      "Batch 160, loss=0.0651, recon=0.0490, kl=16.0615, beta=0.0010\n",
      "Batch 180, loss=0.1036, recon=0.0833, kl=20.2862, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0799 (Recon: 0.0651, KL: 14.7791, Current Beta: 0.0010) | Avg Valid Loss: 0.0710 | Avg Valid recon Loss: 0.0504\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0673, recon=0.0475, kl=19.8228, beta=0.0010\n",
      "Batch 40, loss=0.0654, recon=0.0463, kl=19.1387, beta=0.0010\n",
      "Batch 60, loss=0.0638, recon=0.0428, kl=20.9972, beta=0.0010\n",
      "Batch 80, loss=0.0749, recon=0.0527, kl=22.1959, beta=0.0010\n",
      "Batch 100, loss=0.0780, recon=0.0576, kl=20.3569, beta=0.0010\n",
      "Batch 120, loss=0.0878, recon=0.0680, kl=19.8269, beta=0.0010\n",
      "Batch 140, loss=0.0478, recon=0.0292, kl=18.6335, beta=0.0010\n",
      "Batch 160, loss=0.0604, recon=0.0426, kl=17.8913, beta=0.0010\n",
      "Batch 180, loss=0.0726, recon=0.0546, kl=18.0046, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0774 (Recon: 0.0575, KL: 19.8811, Current Beta: 0.0010) | Avg Valid Loss: 0.0608 | Avg Valid recon Loss: 0.0429\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0526, recon=0.0366, kl=15.9856, beta=0.0010\n",
      "Batch 40, loss=0.0539, recon=0.0443, kl=9.6149, beta=0.0010\n",
      "Batch 60, loss=0.0475, recon=0.0316, kl=15.8810, beta=0.0010\n",
      "Batch 80, loss=0.0681, recon=0.0447, kl=23.3892, beta=0.0010\n",
      "Batch 100, loss=0.0635, recon=0.0405, kl=22.9894, beta=0.0010\n",
      "Batch 120, loss=0.0660, recon=0.0434, kl=22.5392, beta=0.0010\n",
      "Batch 140, loss=0.0570, recon=0.0367, kl=20.3269, beta=0.0010\n",
      "Batch 160, loss=0.0796, recon=0.0602, kl=19.3915, beta=0.0010\n",
      "Batch 180, loss=0.0608, recon=0.0384, kl=22.3279, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1191 (Recon: 0.1003, KL: 18.7808, Current Beta: 0.0010) | Avg Valid Loss: 0.0627 | Avg Valid recon Loss: 0.0435\n",
      "\n",
      "[VRAE Run 43/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5257, recon=0.5257, kl=0.2795, beta=0.0000\n",
      "Batch 40, loss=0.4279, recon=0.4279, kl=0.9143, beta=0.0000\n",
      "Batch 60, loss=0.2622, recon=0.2622, kl=10.6983, beta=0.0000\n",
      "Batch 80, loss=0.2610, recon=0.2610, kl=18.9618, beta=0.0000\n",
      "Batch 100, loss=0.1494, recon=0.1494, kl=22.4991, beta=0.0000\n",
      "Batch 120, loss=0.1260, recon=0.1260, kl=24.3490, beta=0.0000\n",
      "Batch 140, loss=0.1590, recon=0.1590, kl=27.1323, beta=0.0000\n",
      "Batch 160, loss=0.1383, recon=0.1383, kl=29.6480, beta=0.0000\n",
      "Batch 180, loss=0.1131, recon=0.1131, kl=30.6091, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2984 (Recon: 0.2984, KL: 16.7674, Current Beta: 0.0000) | Avg Valid Loss: 0.1324 | Avg Valid recon Loss: 0.1324\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1660, recon=0.1660, kl=32.6502, beta=0.0000\n",
      "Batch 40, loss=0.1445, recon=0.1445, kl=34.4516, beta=0.0000\n",
      "Batch 60, loss=0.1351, recon=0.1351, kl=33.6734, beta=0.0000\n",
      "Batch 80, loss=0.1116, recon=0.1116, kl=34.6877, beta=0.0000\n",
      "Batch 100, loss=0.1130, recon=0.1130, kl=36.3785, beta=0.0000\n",
      "Batch 120, loss=0.1726, recon=0.1726, kl=36.2545, beta=0.0000\n",
      "Batch 140, loss=0.0901, recon=0.0901, kl=36.3827, beta=0.0000\n",
      "Batch 160, loss=0.1140, recon=0.1140, kl=37.3210, beta=0.0000\n",
      "Batch 180, loss=0.1000, recon=0.1000, kl=37.5867, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1436 (Recon: 0.1436, KL: 35.1084, Current Beta: 0.0000) | Avg Valid Loss: 0.0964 | Avg Valid recon Loss: 0.0964\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1222, recon=0.1222, kl=38.1771, beta=0.0000\n",
      "Batch 40, loss=0.0727, recon=0.0727, kl=38.8613, beta=0.0000\n",
      "Batch 60, loss=0.0554, recon=0.0554, kl=38.8954, beta=0.0000\n",
      "Batch 80, loss=0.0687, recon=0.0687, kl=39.1161, beta=0.0000\n",
      "Batch 100, loss=0.0925, recon=0.0925, kl=40.5466, beta=0.0000\n",
      "Batch 120, loss=0.0656, recon=0.0656, kl=44.9464, beta=0.0000\n",
      "Batch 140, loss=0.0846, recon=0.0846, kl=43.2600, beta=0.0000\n",
      "Batch 160, loss=0.0771, recon=0.0771, kl=43.3426, beta=0.0000\n",
      "Batch 180, loss=1.6769, recon=1.6769, kl=42.6430, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1088 (Recon: 0.1088, KL: 40.8768, Current Beta: 0.0000) | Avg Valid Loss: 0.0796 | Avg Valid recon Loss: 0.0796\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0609, recon=0.0609, kl=44.7509, beta=0.0000\n",
      "Batch 40, loss=0.0703, recon=0.0703, kl=45.5386, beta=0.0000\n",
      "Batch 60, loss=0.1008, recon=0.1007, kl=44.7669, beta=0.0000\n",
      "Batch 80, loss=0.1559, recon=0.1559, kl=45.3150, beta=0.0000\n",
      "Batch 100, loss=0.0747, recon=0.0747, kl=44.8987, beta=0.0000\n",
      "Batch 120, loss=0.0572, recon=0.0572, kl=44.6955, beta=0.0000\n",
      "Batch 140, loss=0.0649, recon=0.0649, kl=43.4157, beta=0.0000\n",
      "Batch 160, loss=0.0451, recon=0.0451, kl=45.0637, beta=0.0000\n",
      "Batch 180, loss=0.0511, recon=0.0511, kl=44.6850, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0892 (Recon: 0.0892, KL: 44.5097, Current Beta: 0.0000) | Avg Valid Loss: 0.0697 | Avg Valid recon Loss: 0.0697\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0503, recon=0.0503, kl=44.3443, beta=0.0000\n",
      "Batch 40, loss=0.0533, recon=0.0533, kl=44.4447, beta=0.0000\n",
      "Batch 60, loss=0.0588, recon=0.0588, kl=43.3776, beta=0.0000\n",
      "Batch 80, loss=0.0592, recon=0.0592, kl=42.3239, beta=0.0000\n",
      "Batch 100, loss=0.0678, recon=0.0678, kl=40.9736, beta=0.0000\n",
      "Batch 120, loss=0.0552, recon=0.0552, kl=40.9661, beta=0.0000\n",
      "Batch 140, loss=0.0585, recon=0.0585, kl=40.5948, beta=0.0000\n",
      "Batch 160, loss=0.0595, recon=0.0595, kl=40.9881, beta=0.0000\n",
      "Batch 180, loss=0.0393, recon=0.0393, kl=40.3977, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0774 (Recon: 0.0774, KL: 42.2448, Current Beta: 0.0000) | Avg Valid Loss: 0.0624 | Avg Valid recon Loss: 0.0624\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0413, recon=0.0413, kl=38.4848, beta=0.0000\n",
      "Batch 40, loss=0.0719, recon=0.0719, kl=35.9035, beta=0.0000\n",
      "Batch 60, loss=0.0706, recon=0.0706, kl=35.4098, beta=0.0000\n",
      "Batch 80, loss=0.0470, recon=0.0470, kl=35.3006, beta=0.0000\n",
      "Batch 100, loss=0.0525, recon=0.0525, kl=32.8201, beta=0.0000\n",
      "Batch 120, loss=0.0510, recon=0.0510, kl=32.0418, beta=0.0000\n",
      "Batch 140, loss=0.0401, recon=0.0401, kl=31.1836, beta=0.0000\n",
      "Batch 160, loss=0.0496, recon=0.0496, kl=31.3528, beta=0.0000\n",
      "Batch 180, loss=0.0519, recon=0.0519, kl=30.2999, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0694 (Recon: 0.0694, KL: 34.1055, Current Beta: 0.0000) | Avg Valid Loss: 0.0586 | Avg Valid recon Loss: 0.0586\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0813, recon=0.0813, kl=28.1720, beta=0.0000\n",
      "Batch 40, loss=0.0787, recon=0.0787, kl=24.7388, beta=0.0000\n",
      "Batch 60, loss=0.0396, recon=0.0395, kl=22.9404, beta=0.0000\n",
      "Batch 80, loss=0.0439, recon=0.0439, kl=21.1650, beta=0.0000\n",
      "Batch 100, loss=0.0347, recon=0.0347, kl=22.1332, beta=0.0000\n",
      "Batch 120, loss=0.0850, recon=0.0850, kl=20.1853, beta=0.0000\n",
      "Batch 140, loss=0.0444, recon=0.0444, kl=20.8995, beta=0.0000\n",
      "Batch 160, loss=0.0364, recon=0.0364, kl=20.4615, beta=0.0000\n",
      "Batch 180, loss=0.0466, recon=0.0466, kl=20.5638, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0642 (Recon: 0.0642, KL: 22.9111, Current Beta: 0.0000) | Avg Valid Loss: 0.0544 | Avg Valid recon Loss: 0.0544\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0589, recon=0.0589, kl=16.9768, beta=0.0000\n",
      "Batch 40, loss=0.0467, recon=0.0467, kl=13.8009, beta=0.0000\n",
      "Batch 60, loss=0.0498, recon=0.0498, kl=13.5127, beta=0.0000\n",
      "Batch 80, loss=0.0508, recon=0.0508, kl=13.0038, beta=0.0000\n",
      "Batch 100, loss=0.0369, recon=0.0369, kl=12.3095, beta=0.0000\n",
      "Batch 120, loss=0.0454, recon=0.0454, kl=10.9794, beta=0.0000\n",
      "Batch 140, loss=0.0499, recon=0.0499, kl=12.1566, beta=0.0000\n",
      "Batch 160, loss=0.3097, recon=0.3096, kl=10.9498, beta=0.0000\n",
      "Batch 180, loss=0.0516, recon=0.0516, kl=10.9402, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0601 (Recon: 0.0601, KL: 13.1841, Current Beta: 0.0000) | Avg Valid Loss: 0.0513 | Avg Valid recon Loss: 0.0513\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0583, recon=0.0583, kl=6.7789, beta=0.0000\n",
      "Batch 40, loss=0.0696, recon=0.0696, kl=6.1865, beta=0.0000\n",
      "Batch 60, loss=0.3226, recon=0.3225, kl=5.6292, beta=0.0000\n",
      "Batch 80, loss=0.0472, recon=0.0472, kl=6.0002, beta=0.0000\n",
      "Batch 100, loss=0.0447, recon=0.0447, kl=5.0733, beta=0.0000\n",
      "Batch 120, loss=0.0500, recon=0.0500, kl=5.1798, beta=0.0000\n",
      "Batch 140, loss=0.0514, recon=0.0514, kl=4.6382, beta=0.0000\n",
      "Batch 160, loss=0.0503, recon=0.0503, kl=5.0122, beta=0.0000\n",
      "Batch 180, loss=0.0334, recon=0.0334, kl=5.2264, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0574 (Recon: 0.0574, KL: 5.9263, Current Beta: 0.0000) | Avg Valid Loss: 0.0495 | Avg Valid recon Loss: 0.0495\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0328, recon=0.0328, kl=2.5438, beta=0.0000\n",
      "Batch 40, loss=0.0436, recon=0.0436, kl=2.0823, beta=0.0000\n",
      "Batch 60, loss=0.0362, recon=0.0362, kl=2.1898, beta=0.0000\n",
      "Batch 80, loss=0.0421, recon=0.0421, kl=2.0271, beta=0.0000\n",
      "Batch 100, loss=0.0332, recon=0.0331, kl=2.7456, beta=0.0000\n",
      "Batch 120, loss=0.0401, recon=0.0401, kl=1.9254, beta=0.0000\n",
      "Batch 140, loss=0.0461, recon=0.0461, kl=1.6202, beta=0.0000\n",
      "Batch 160, loss=0.0319, recon=0.0319, kl=2.1495, beta=0.0000\n",
      "Batch 180, loss=0.0614, recon=0.0614, kl=1.9090, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0548 (Recon: 0.0548, KL: 2.3292, Current Beta: 0.0000) | Avg Valid Loss: 0.0473 | Avg Valid recon Loss: 0.0473\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0284, recon=0.0284, kl=0.6720, beta=0.0000\n",
      "Batch 40, loss=0.0374, recon=0.0373, kl=0.8107, beta=0.0000\n",
      "Batch 60, loss=0.0414, recon=0.0414, kl=0.7984, beta=0.0000\n",
      "Batch 80, loss=0.0622, recon=0.0622, kl=0.6701, beta=0.0000\n",
      "Batch 100, loss=0.0412, recon=0.0412, kl=0.5159, beta=0.0000\n",
      "Batch 120, loss=0.0450, recon=0.0450, kl=0.7812, beta=0.0000\n",
      "Batch 140, loss=0.0258, recon=0.0258, kl=0.5298, beta=0.0000\n",
      "Batch 160, loss=0.0428, recon=0.0428, kl=0.3861, beta=0.0000\n",
      "Batch 180, loss=0.0354, recon=0.0354, kl=0.4026, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0526 (Recon: 0.0525, KL: 0.7137, Current Beta: 0.0000) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0457\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0415, recon=0.0415, kl=0.1054, beta=0.0001\n",
      "Batch 40, loss=0.0707, recon=0.0706, kl=0.2156, beta=0.0001\n",
      "Batch 60, loss=0.0313, recon=0.0313, kl=0.1644, beta=0.0001\n",
      "Batch 80, loss=0.0453, recon=0.0452, kl=0.1396, beta=0.0001\n",
      "Batch 100, loss=0.0262, recon=0.0262, kl=0.1656, beta=0.0001\n",
      "Batch 120, loss=0.2288, recon=0.2288, kl=0.0402, beta=0.0001\n",
      "Batch 140, loss=0.0365, recon=0.0365, kl=0.0645, beta=0.0001\n",
      "Batch 160, loss=0.0318, recon=0.0318, kl=0.0456, beta=0.0001\n",
      "Batch 180, loss=0.0294, recon=0.0294, kl=0.0281, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0513 (Recon: 0.0513, KL: 0.1428, Current Beta: 0.0001) | Avg Valid Loss: 0.0443 | Avg Valid recon Loss: 0.0443\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0313, recon=0.0313, kl=0.0241, beta=0.0002\n",
      "Batch 40, loss=0.0397, recon=0.0397, kl=0.0063, beta=0.0002\n",
      "Batch 60, loss=0.0369, recon=0.0369, kl=0.0109, beta=0.0002\n",
      "Batch 80, loss=0.0500, recon=0.0500, kl=0.0145, beta=0.0002\n",
      "Batch 100, loss=0.0251, recon=0.0251, kl=0.0195, beta=0.0002\n",
      "Batch 120, loss=0.0436, recon=0.0436, kl=0.0077, beta=0.0002\n",
      "Batch 140, loss=0.0398, recon=0.0398, kl=0.0146, beta=0.0002\n",
      "Batch 160, loss=0.0271, recon=0.0271, kl=0.0087, beta=0.0002\n",
      "Batch 180, loss=0.0472, recon=0.0472, kl=0.0052, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0495, KL: 0.0143, Current Beta: 0.0002) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0293, recon=0.0293, kl=0.0044, beta=0.0004\n",
      "Batch 40, loss=0.0271, recon=0.0271, kl=0.0117, beta=0.0004\n",
      "Batch 60, loss=0.0529, recon=0.0529, kl=0.0019, beta=0.0004\n",
      "Batch 80, loss=0.0308, recon=0.0308, kl=0.0015, beta=0.0004\n",
      "Batch 100, loss=0.0315, recon=0.0315, kl=0.0018, beta=0.0004\n",
      "Batch 120, loss=0.0458, recon=0.0458, kl=0.0014, beta=0.0004\n",
      "Batch 140, loss=0.0270, recon=0.0270, kl=0.0022, beta=0.0004\n",
      "Batch 160, loss=0.0465, recon=0.0465, kl=0.0016, beta=0.0004\n",
      "Batch 180, loss=0.0398, recon=0.0398, kl=0.0013, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0484 (Recon: 0.0484, KL: 0.0035, Current Beta: 0.0004) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0392, recon=0.0392, kl=0.0043, beta=0.0006\n",
      "Batch 40, loss=0.0353, recon=0.0353, kl=0.0026, beta=0.0006\n",
      "Batch 60, loss=0.0313, recon=0.0313, kl=0.0026, beta=0.0006\n",
      "Batch 80, loss=0.0289, recon=0.0289, kl=0.0009, beta=0.0006\n",
      "Batch 100, loss=0.0680, recon=0.0680, kl=0.0006, beta=0.0006\n",
      "Batch 120, loss=0.0406, recon=0.0406, kl=0.0012, beta=0.0006\n",
      "Batch 140, loss=0.0222, recon=0.0222, kl=0.0013, beta=0.0006\n",
      "Batch 160, loss=0.0318, recon=0.0318, kl=0.0009, beta=0.0006\n",
      "Batch 180, loss=0.0302, recon=0.0302, kl=0.0003, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0469, KL: 0.0016, Current Beta: 0.0006) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0564, recon=0.0564, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0311, recon=0.0311, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0476, recon=0.0476, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.0318, recon=0.0318, kl=0.0013, beta=0.0010\n",
      "Batch 100, loss=0.0444, recon=0.0444, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0419, recon=0.0419, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0379, recon=0.0379, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0248, recon=0.0248, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0376, recon=0.0376, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0400 | Avg Valid recon Loss: 0.0400\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0385, recon=0.0385, kl=0.0008, beta=0.0010\n",
      "Batch 40, loss=0.0667, recon=0.0667, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0250, recon=0.0250, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0552, recon=0.0552, kl=0.0004, beta=0.0010\n",
      "Batch 100, loss=0.0258, recon=0.0258, kl=0.0006, beta=0.0010\n",
      "Batch 120, loss=0.0524, recon=0.0524, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0312, recon=0.0311, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0240, recon=0.0240, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0231, recon=0.0231, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0450, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0317, recon=0.0317, kl=0.0017, beta=0.0010\n",
      "Batch 40, loss=0.0521, recon=0.0521, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0342, recon=0.0342, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.1638, recon=0.1638, kl=0.0003, beta=0.0010\n",
      "Batch 100, loss=0.0334, recon=0.0334, kl=0.0005, beta=0.0010\n",
      "Batch 120, loss=0.0420, recon=0.0420, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0554, recon=0.0554, kl=0.0006, beta=0.0010\n",
      "Batch 160, loss=0.0282, recon=0.0282, kl=0.0004, beta=0.0010\n",
      "Batch 180, loss=0.0253, recon=0.0253, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0441 (Recon: 0.0441, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0204, recon=0.0204, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0328, recon=0.0328, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0284, recon=0.0284, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.0263, recon=0.0263, kl=0.0007, beta=0.0010\n",
      "Batch 100, loss=0.0419, recon=0.0419, kl=0.0005, beta=0.0010\n",
      "Batch 120, loss=0.0263, recon=0.0263, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0344, recon=0.0344, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0226, recon=0.0226, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0428, recon=0.0428, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0434, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0261, recon=0.0261, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0295, recon=0.0295, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0229, recon=0.0229, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0373, recon=0.0373, kl=0.0022, beta=0.0010\n",
      "Batch 100, loss=0.0304, recon=0.0304, kl=0.0005, beta=0.0010\n",
      "Batch 120, loss=0.0297, recon=0.0297, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0321, recon=0.0321, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0305, recon=0.0305, kl=0.0005, beta=0.0010\n",
      "Batch 180, loss=0.0483, recon=0.0483, kl=0.0009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0425, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0375\n",
      "\n",
      "[VRAE Run 44/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1536, recon=0.1536, kl=18.8083, beta=0.0000\n",
      "Batch 40, loss=0.1040, recon=0.1040, kl=21.4238, beta=0.0000\n",
      "Batch 60, loss=0.0731, recon=0.0731, kl=25.1135, beta=0.0000\n",
      "Batch 80, loss=0.1076, recon=0.1076, kl=32.5947, beta=0.0000\n",
      "Batch 100, loss=0.0785, recon=0.0785, kl=29.4200, beta=0.0000\n",
      "Batch 120, loss=0.0855, recon=0.0855, kl=25.5211, beta=0.0000\n",
      "Batch 140, loss=0.0495, recon=0.0495, kl=26.7036, beta=0.0000\n",
      "Batch 160, loss=0.0360, recon=0.0360, kl=27.1075, beta=0.0000\n",
      "Batch 180, loss=0.0569, recon=0.0569, kl=23.7562, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1312 (Recon: 0.1312, KL: 24.8384, Current Beta: 0.0000) | Avg Valid Loss: 0.0607 | Avg Valid recon Loss: 0.0607\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0280, recon=0.0280, kl=28.4751, beta=0.0000\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=27.8395, beta=0.0000\n",
      "Batch 60, loss=0.0422, recon=0.0422, kl=28.4493, beta=0.0000\n",
      "Batch 80, loss=0.0452, recon=0.0452, kl=29.6075, beta=0.0000\n",
      "Batch 100, loss=0.0635, recon=0.0635, kl=31.0873, beta=0.0000\n",
      "Batch 120, loss=0.0526, recon=0.0526, kl=33.6304, beta=0.0000\n",
      "Batch 140, loss=0.0684, recon=0.0684, kl=35.7841, beta=0.0000\n",
      "Batch 160, loss=0.0304, recon=0.0304, kl=32.7837, beta=0.0000\n",
      "Batch 180, loss=0.0571, recon=0.0571, kl=34.1697, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0634 (Recon: 0.0634, KL: 30.8714, Current Beta: 0.0000) | Avg Valid Loss: 0.0505 | Avg Valid recon Loss: 0.0505\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1737, recon=0.1737, kl=34.4192, beta=0.0000\n",
      "Batch 40, loss=0.0581, recon=0.0581, kl=34.7969, beta=0.0000\n",
      "Batch 60, loss=0.0299, recon=0.0299, kl=35.2890, beta=0.0000\n",
      "Batch 80, loss=0.0909, recon=0.0909, kl=38.3092, beta=0.0000\n",
      "Batch 100, loss=0.0388, recon=0.0388, kl=37.8085, beta=0.0000\n",
      "Batch 120, loss=0.0753, recon=0.0753, kl=36.2768, beta=0.0000\n",
      "Batch 140, loss=0.2377, recon=0.2377, kl=31.6913, beta=0.0000\n",
      "Batch 160, loss=0.0435, recon=0.0435, kl=27.9973, beta=0.0000\n",
      "Batch 180, loss=0.2546, recon=0.2546, kl=30.2859, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 34.5412, Current Beta: 0.0000) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0456\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0410, recon=0.0410, kl=32.9577, beta=0.0000\n",
      "Batch 40, loss=0.0612, recon=0.0612, kl=35.4729, beta=0.0000\n",
      "Batch 60, loss=0.0348, recon=0.0348, kl=34.2375, beta=0.0000\n",
      "Batch 80, loss=0.0427, recon=0.0427, kl=33.9357, beta=0.0000\n",
      "Batch 100, loss=0.0585, recon=0.0585, kl=36.2581, beta=0.0000\n",
      "Batch 120, loss=0.0399, recon=0.0399, kl=33.8843, beta=0.0000\n",
      "Batch 140, loss=0.0286, recon=0.0286, kl=33.9871, beta=0.0000\n",
      "Batch 160, loss=0.0359, recon=0.0359, kl=33.9122, beta=0.0000\n",
      "Batch 180, loss=0.0390, recon=0.0390, kl=34.2603, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 34.1379, Current Beta: 0.0000) | Avg Valid Loss: 0.0511 | Avg Valid recon Loss: 0.0511\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0408, recon=0.0408, kl=32.2999, beta=0.0000\n",
      "Batch 40, loss=0.0517, recon=0.0517, kl=28.0567, beta=0.0000\n",
      "Batch 60, loss=0.0455, recon=0.0455, kl=31.5390, beta=0.0000\n",
      "Batch 80, loss=0.0776, recon=0.0776, kl=31.4288, beta=0.0000\n",
      "Batch 100, loss=0.0328, recon=0.0328, kl=32.7511, beta=0.0000\n",
      "Batch 120, loss=0.0296, recon=0.0296, kl=34.3648, beta=0.0000\n",
      "Batch 140, loss=0.0484, recon=0.0484, kl=34.4129, beta=0.0000\n",
      "Batch 160, loss=0.0264, recon=0.0264, kl=36.0734, beta=0.0000\n",
      "Batch 180, loss=0.0309, recon=0.0309, kl=37.5852, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0528 (Recon: 0.0528, KL: 33.0135, Current Beta: 0.0000) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0243, recon=0.0242, kl=34.1523, beta=0.0000\n",
      "Batch 40, loss=0.0644, recon=0.0644, kl=32.2314, beta=0.0000\n",
      "Batch 60, loss=0.0250, recon=0.0250, kl=31.9572, beta=0.0000\n",
      "Batch 80, loss=0.0320, recon=0.0320, kl=29.6705, beta=0.0000\n",
      "Batch 100, loss=0.0383, recon=0.0383, kl=27.7361, beta=0.0000\n",
      "Batch 120, loss=0.0293, recon=0.0293, kl=26.8719, beta=0.0000\n",
      "Batch 140, loss=0.0297, recon=0.0297, kl=27.1234, beta=0.0000\n",
      "Batch 160, loss=0.0627, recon=0.0627, kl=28.3977, beta=0.0000\n",
      "Batch 180, loss=0.0301, recon=0.0301, kl=29.2481, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0484 (Recon: 0.0484, KL: 30.2768, Current Beta: 0.0000) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0582, recon=0.0582, kl=26.8439, beta=0.0000\n",
      "Batch 40, loss=0.0423, recon=0.0423, kl=25.7583, beta=0.0000\n",
      "Batch 60, loss=0.0393, recon=0.0393, kl=25.2258, beta=0.0000\n",
      "Batch 80, loss=0.0417, recon=0.0417, kl=25.3445, beta=0.0000\n",
      "Batch 100, loss=0.0270, recon=0.0270, kl=26.6882, beta=0.0000\n",
      "Batch 120, loss=0.0360, recon=0.0360, kl=24.6124, beta=0.0000\n",
      "Batch 140, loss=0.0284, recon=0.0284, kl=23.8719, beta=0.0000\n",
      "Batch 160, loss=0.0438, recon=0.0438, kl=23.8214, beta=0.0000\n",
      "Batch 180, loss=0.0239, recon=0.0239, kl=22.9026, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0459, KL: 25.2717, Current Beta: 0.0000) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0478, recon=0.0478, kl=21.6208, beta=0.0000\n",
      "Batch 40, loss=0.0338, recon=0.0338, kl=20.9605, beta=0.0000\n",
      "Batch 60, loss=0.0259, recon=0.0259, kl=18.9894, beta=0.0000\n",
      "Batch 80, loss=0.0603, recon=0.0602, kl=19.3678, beta=0.0000\n",
      "Batch 100, loss=0.0378, recon=0.0378, kl=18.8173, beta=0.0000\n",
      "Batch 120, loss=0.0321, recon=0.0321, kl=18.1568, beta=0.0000\n",
      "Batch 140, loss=0.0309, recon=0.0309, kl=18.8078, beta=0.0000\n",
      "Batch 160, loss=0.0329, recon=0.0329, kl=19.5720, beta=0.0000\n",
      "Batch 180, loss=0.0359, recon=0.0359, kl=18.0259, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0460 (Recon: 0.0460, KL: 19.6561, Current Beta: 0.0000) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0350, recon=0.0349, kl=14.8456, beta=0.0000\n",
      "Batch 40, loss=0.0255, recon=0.0254, kl=12.4879, beta=0.0000\n",
      "Batch 60, loss=0.0767, recon=0.0767, kl=9.5075, beta=0.0000\n",
      "Batch 80, loss=0.0615, recon=0.0614, kl=12.1930, beta=0.0000\n",
      "Batch 100, loss=0.0477, recon=0.0477, kl=8.8668, beta=0.0000\n",
      "Batch 120, loss=0.0656, recon=0.0656, kl=10.0597, beta=0.0000\n",
      "Batch 140, loss=0.0550, recon=0.0549, kl=11.0628, beta=0.0000\n",
      "Batch 160, loss=0.0373, recon=0.0372, kl=12.3626, beta=0.0000\n",
      "Batch 180, loss=0.0351, recon=0.0350, kl=12.8076, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0449, KL: 11.8000, Current Beta: 0.0000) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0373, recon=0.0372, kl=7.7700, beta=0.0000\n",
      "Batch 40, loss=0.0476, recon=0.0476, kl=4.2891, beta=0.0000\n",
      "Batch 60, loss=0.0219, recon=0.0218, kl=4.2176, beta=0.0000\n",
      "Batch 80, loss=0.0484, recon=0.0483, kl=6.5903, beta=0.0000\n",
      "Batch 100, loss=0.0400, recon=0.0399, kl=6.3368, beta=0.0000\n",
      "Batch 120, loss=0.0390, recon=0.0389, kl=7.0429, beta=0.0000\n",
      "Batch 140, loss=0.0294, recon=0.0293, kl=7.0809, beta=0.0000\n",
      "Batch 160, loss=0.0311, recon=0.0310, kl=5.7491, beta=0.0000\n",
      "Batch 180, loss=0.0286, recon=0.0285, kl=4.7048, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0419, KL: 6.4431, Current Beta: 0.0000) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0394\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0430, recon=0.0429, kl=2.9802, beta=0.0000\n",
      "Batch 40, loss=0.0311, recon=0.0310, kl=3.1110, beta=0.0000\n",
      "Batch 60, loss=0.1246, recon=0.1245, kl=4.7341, beta=0.0000\n",
      "Batch 80, loss=0.0282, recon=0.0281, kl=3.3531, beta=0.0000\n",
      "Batch 100, loss=0.0369, recon=0.0369, kl=2.7159, beta=0.0000\n",
      "Batch 120, loss=0.0327, recon=0.0326, kl=1.9936, beta=0.0000\n",
      "Batch 140, loss=0.0314, recon=0.0313, kl=1.7606, beta=0.0000\n",
      "Batch 160, loss=0.0317, recon=0.0317, kl=1.4509, beta=0.0000\n",
      "Batch 180, loss=0.0212, recon=0.0212, kl=1.3810, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0427, KL: 2.7563, Current Beta: 0.0000) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0356, recon=0.0356, kl=0.2531, beta=0.0001\n",
      "Batch 40, loss=0.0327, recon=0.0327, kl=0.2549, beta=0.0001\n",
      "Batch 60, loss=0.0371, recon=0.0370, kl=0.1482, beta=0.0001\n",
      "Batch 80, loss=0.0263, recon=0.0263, kl=0.3815, beta=0.0001\n",
      "Batch 100, loss=0.0252, recon=0.0250, kl=2.2647, beta=0.0001\n",
      "Batch 120, loss=0.0256, recon=0.0254, kl=2.1416, beta=0.0001\n",
      "Batch 140, loss=0.0426, recon=0.0425, kl=1.2431, beta=0.0001\n",
      "Batch 160, loss=0.0358, recon=0.0357, kl=1.1505, beta=0.0001\n",
      "Batch 180, loss=0.0463, recon=0.0463, kl=0.9987, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0419, KL: 1.0101, Current Beta: 0.0001) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0340\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0289, recon=0.0289, kl=0.0375, beta=0.0002\n",
      "Batch 40, loss=0.0246, recon=0.0246, kl=0.0577, beta=0.0002\n",
      "Batch 60, loss=0.0267, recon=0.0267, kl=0.0436, beta=0.0002\n",
      "Batch 80, loss=0.0296, recon=0.0296, kl=0.0240, beta=0.0002\n",
      "Batch 100, loss=0.0286, recon=0.0286, kl=0.0212, beta=0.0002\n",
      "Batch 120, loss=0.0190, recon=0.0189, kl=0.0364, beta=0.0002\n",
      "Batch 140, loss=0.0523, recon=0.0523, kl=0.0797, beta=0.0002\n",
      "Batch 160, loss=0.0264, recon=0.0264, kl=0.0443, beta=0.0002\n",
      "Batch 180, loss=0.0371, recon=0.0371, kl=0.0127, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0394 (Recon: 0.0394, KL: 0.0963, Current Beta: 0.0002) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0513, recon=0.0513, kl=0.0095, beta=0.0004\n",
      "Batch 40, loss=0.0221, recon=0.0221, kl=0.0111, beta=0.0004\n",
      "Batch 60, loss=0.0233, recon=0.0233, kl=0.0150, beta=0.0004\n",
      "Batch 80, loss=0.0303, recon=0.0303, kl=0.0052, beta=0.0004\n",
      "Batch 100, loss=0.0335, recon=0.0335, kl=0.0070, beta=0.0004\n",
      "Batch 120, loss=0.0244, recon=0.0244, kl=0.0305, beta=0.0004\n",
      "Batch 140, loss=0.0484, recon=0.0484, kl=0.0253, beta=0.0004\n",
      "Batch 160, loss=0.0493, recon=0.0493, kl=0.0088, beta=0.0004\n",
      "Batch 180, loss=0.5164, recon=0.5164, kl=0.0335, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0430, KL: 0.0162, Current Beta: 0.0004) | Avg Valid Loss: 0.0548 | Avg Valid recon Loss: 0.0548\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0812, recon=0.0811, kl=0.0268, beta=0.0006\n",
      "Batch 40, loss=0.0456, recon=0.0456, kl=0.0118, beta=0.0006\n",
      "Batch 60, loss=0.0542, recon=0.0542, kl=0.0090, beta=0.0006\n",
      "Batch 80, loss=0.0627, recon=0.0627, kl=0.0111, beta=0.0006\n",
      "Batch 100, loss=0.0716, recon=0.0716, kl=0.0081, beta=0.0006\n",
      "Batch 120, loss=0.0335, recon=0.0335, kl=0.0071, beta=0.0006\n",
      "Batch 140, loss=0.0417, recon=0.0416, kl=0.1783, beta=0.0006\n",
      "Batch 160, loss=0.0386, recon=0.0381, kl=0.7845, beta=0.0006\n",
      "Batch 180, loss=0.0306, recon=0.0304, kl=0.2232, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0484, KL: 0.1413, Current Beta: 0.0006) | Avg Valid Loss: 0.0397 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0334, recon=0.0334, kl=0.0130, beta=0.0010\n",
      "Batch 40, loss=0.0316, recon=0.0316, kl=0.0054, beta=0.0010\n",
      "Batch 60, loss=0.0303, recon=0.0303, kl=0.0021, beta=0.0010\n",
      "Batch 80, loss=0.0288, recon=0.0288, kl=0.0014, beta=0.0010\n",
      "Batch 100, loss=0.0219, recon=0.0219, kl=0.0027, beta=0.0010\n",
      "Batch 120, loss=0.0379, recon=0.0379, kl=0.0009, beta=0.0010\n",
      "Batch 140, loss=0.0333, recon=0.0333, kl=0.0012, beta=0.0010\n",
      "Batch 160, loss=0.0296, recon=0.0296, kl=0.0011, beta=0.0010\n",
      "Batch 180, loss=0.0606, recon=0.0606, kl=0.0030, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0407 (Recon: 0.0407, KL: 0.0113, Current Beta: 0.0010) | Avg Valid Loss: 0.0344 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0259, recon=0.0259, kl=0.0037, beta=0.0010\n",
      "Batch 40, loss=0.0402, recon=0.0402, kl=0.0010, beta=0.0010\n",
      "Batch 60, loss=0.0403, recon=0.0403, kl=0.0013, beta=0.0010\n",
      "Batch 80, loss=0.1278, recon=0.1278, kl=0.0013, beta=0.0010\n",
      "Batch 100, loss=0.0348, recon=0.0347, kl=0.0048, beta=0.0010\n",
      "Batch 120, loss=0.0344, recon=0.0344, kl=0.0019, beta=0.0010\n",
      "Batch 140, loss=0.0276, recon=0.0276, kl=0.0015, beta=0.0010\n",
      "Batch 160, loss=0.0254, recon=0.0253, kl=0.0026, beta=0.0010\n",
      "Batch 180, loss=0.0336, recon=0.0336, kl=0.0012, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 0.0033, Current Beta: 0.0010) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0299, recon=0.0299, kl=0.0010, beta=0.0010\n",
      "Batch 40, loss=0.0342, recon=0.0342, kl=0.0008, beta=0.0010\n",
      "Batch 60, loss=0.0288, recon=0.0288, kl=0.0023, beta=0.0010\n",
      "Batch 80, loss=0.0442, recon=0.0442, kl=0.0013, beta=0.0010\n",
      "Batch 100, loss=0.0303, recon=0.0303, kl=0.0014, beta=0.0010\n",
      "Batch 120, loss=0.0329, recon=0.0329, kl=0.0008, beta=0.0010\n",
      "Batch 140, loss=0.0328, recon=0.0328, kl=0.0016, beta=0.0010\n",
      "Batch 160, loss=0.0240, recon=0.0240, kl=0.0010, beta=0.0010\n",
      "Batch 180, loss=0.0263, recon=0.0263, kl=0.0041, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0379 (Recon: 0.0379, KL: 0.0017, Current Beta: 0.0010) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0589, recon=0.0589, kl=0.0025, beta=0.0010\n",
      "Batch 40, loss=0.1456, recon=0.1456, kl=0.0012, beta=0.0010\n",
      "Batch 60, loss=0.0306, recon=0.0306, kl=0.0014, beta=0.0010\n",
      "Batch 80, loss=0.0190, recon=0.0190, kl=0.0015, beta=0.0010\n",
      "Batch 100, loss=0.0371, recon=0.0371, kl=0.0031, beta=0.0010\n",
      "Batch 120, loss=0.0232, recon=0.0232, kl=0.0016, beta=0.0010\n",
      "Batch 140, loss=0.0260, recon=0.0260, kl=0.0010, beta=0.0010\n",
      "Batch 160, loss=0.0263, recon=0.0263, kl=0.0026, beta=0.0010\n",
      "Batch 180, loss=0.0197, recon=0.0196, kl=0.0250, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0391, KL: 0.0048, Current Beta: 0.0010) | Avg Valid Loss: 0.0333 | Avg Valid recon Loss: 0.0332\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0220, recon=0.0220, kl=0.0076, beta=0.0010\n",
      "Batch 40, loss=0.0230, recon=0.0230, kl=0.0056, beta=0.0010\n",
      "Batch 60, loss=0.0393, recon=0.0392, kl=0.0021, beta=0.0010\n",
      "Batch 80, loss=0.0348, recon=0.0348, kl=0.0014, beta=0.0010\n",
      "Batch 100, loss=0.0310, recon=0.0310, kl=0.0022, beta=0.0010\n",
      "Batch 120, loss=0.0460, recon=0.0460, kl=0.0016, beta=0.0010\n",
      "Batch 140, loss=0.0310, recon=0.0310, kl=0.0045, beta=0.0010\n",
      "Batch 160, loss=0.0240, recon=0.0240, kl=0.0018, beta=0.0010\n",
      "Batch 180, loss=0.0506, recon=0.0506, kl=0.0061, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0381 (Recon: 0.0381, KL: 0.0043, Current Beta: 0.0010) | Avg Valid Loss: 0.0314 | Avg Valid recon Loss: 0.0314\n",
      "\n",
      "[VRAE Run 45/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7095, recon=0.7095, kl=0.4015, beta=0.0000\n",
      "Batch 40, loss=0.3204, recon=0.3204, kl=2.9763, beta=0.0000\n",
      "Batch 60, loss=0.2256, recon=0.2256, kl=26.8019, beta=0.0000\n",
      "Batch 80, loss=0.2258, recon=0.2258, kl=39.1994, beta=0.0000\n",
      "Batch 100, loss=0.2819, recon=0.2819, kl=45.8088, beta=0.0000\n",
      "Batch 120, loss=0.2390, recon=0.2390, kl=49.7664, beta=0.0000\n",
      "Batch 140, loss=0.1152, recon=0.1152, kl=54.2458, beta=0.0000\n",
      "Batch 160, loss=0.1983, recon=0.1983, kl=57.3404, beta=0.0000\n",
      "Batch 180, loss=0.1764, recon=0.1764, kl=59.8969, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3178 (Recon: 0.3178, KL: 34.4827, Current Beta: 0.0000) | Avg Valid Loss: 0.1406 | Avg Valid recon Loss: 0.1406\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1251, recon=0.1251, kl=62.0141, beta=0.0000\n",
      "Batch 40, loss=0.3129, recon=0.3129, kl=63.3039, beta=0.0000\n",
      "Batch 60, loss=0.1093, recon=0.1093, kl=65.4673, beta=0.0000\n",
      "Batch 80, loss=0.1363, recon=0.1363, kl=67.7046, beta=0.0000\n",
      "Batch 100, loss=0.0989, recon=0.0989, kl=68.7129, beta=0.0000\n",
      "Batch 120, loss=0.1110, recon=0.1110, kl=71.0398, beta=0.0000\n",
      "Batch 140, loss=0.0831, recon=0.0831, kl=73.7171, beta=0.0000\n",
      "Batch 160, loss=0.1082, recon=0.1082, kl=75.6289, beta=0.0000\n",
      "Batch 180, loss=0.0950, recon=0.0950, kl=76.4785, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1465 (Recon: 0.1465, KL: 68.4863, Current Beta: 0.0000) | Avg Valid Loss: 0.0973 | Avg Valid recon Loss: 0.0973\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0847, recon=0.0846, kl=78.2871, beta=0.0000\n",
      "Batch 40, loss=0.0951, recon=0.0950, kl=78.2622, beta=0.0000\n",
      "Batch 60, loss=0.0647, recon=0.0647, kl=79.1670, beta=0.0000\n",
      "Batch 80, loss=0.0714, recon=0.0714, kl=81.0409, beta=0.0000\n",
      "Batch 100, loss=0.0689, recon=0.0689, kl=83.2015, beta=0.0000\n",
      "Batch 120, loss=0.0898, recon=0.0898, kl=82.0310, beta=0.0000\n",
      "Batch 140, loss=0.1102, recon=0.1102, kl=85.0142, beta=0.0000\n",
      "Batch 160, loss=0.0902, recon=0.0902, kl=85.0311, beta=0.0000\n",
      "Batch 180, loss=0.0521, recon=0.0521, kl=85.1912, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1111 (Recon: 0.1111, KL: 81.4190, Current Beta: 0.0000) | Avg Valid Loss: 0.0814 | Avg Valid recon Loss: 0.0814\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0672, recon=0.0672, kl=86.2678, beta=0.0000\n",
      "Batch 40, loss=0.0809, recon=0.0809, kl=88.4473, beta=0.0000\n",
      "Batch 60, loss=0.1121, recon=0.1121, kl=88.6165, beta=0.0000\n",
      "Batch 80, loss=0.0616, recon=0.0616, kl=85.7289, beta=0.0000\n",
      "Batch 100, loss=0.0625, recon=0.0625, kl=84.9200, beta=0.0000\n",
      "Batch 120, loss=0.0942, recon=0.0942, kl=86.9061, beta=0.0000\n",
      "Batch 140, loss=0.0565, recon=0.0564, kl=87.6857, beta=0.0000\n",
      "Batch 160, loss=0.0802, recon=0.0802, kl=87.3103, beta=0.0000\n",
      "Batch 180, loss=0.1201, recon=0.1201, kl=87.3208, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0910 (Recon: 0.0910, KL: 86.8417, Current Beta: 0.0000) | Avg Valid Loss: 0.0698 | Avg Valid recon Loss: 0.0698\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0510, recon=0.0510, kl=88.7771, beta=0.0000\n",
      "Batch 40, loss=0.0701, recon=0.0701, kl=86.4999, beta=0.0000\n",
      "Batch 60, loss=0.0587, recon=0.0587, kl=85.5374, beta=0.0000\n",
      "Batch 80, loss=0.0604, recon=0.0604, kl=84.4455, beta=0.0000\n",
      "Batch 100, loss=0.0819, recon=0.0819, kl=85.1170, beta=0.0000\n",
      "Batch 120, loss=0.0467, recon=0.0467, kl=83.5873, beta=0.0000\n",
      "Batch 140, loss=0.0744, recon=0.0743, kl=82.1316, beta=0.0000\n",
      "Batch 160, loss=0.0432, recon=0.0432, kl=80.8870, beta=0.0000\n",
      "Batch 180, loss=0.0719, recon=0.0719, kl=80.2123, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0785 (Recon: 0.0785, KL: 84.6813, Current Beta: 0.0000) | Avg Valid Loss: 0.0643 | Avg Valid recon Loss: 0.0642\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0440, recon=0.0440, kl=76.1460, beta=0.0000\n",
      "Batch 40, loss=0.1003, recon=0.1003, kl=71.4688, beta=0.0000\n",
      "Batch 60, loss=0.0581, recon=0.0581, kl=68.6965, beta=0.0000\n",
      "Batch 80, loss=0.0462, recon=0.0462, kl=68.9246, beta=0.0000\n",
      "Batch 100, loss=0.0494, recon=0.0494, kl=65.0925, beta=0.0000\n",
      "Batch 120, loss=0.0503, recon=0.0503, kl=60.8486, beta=0.0000\n",
      "Batch 140, loss=0.0448, recon=0.0448, kl=62.4310, beta=0.0000\n",
      "Batch 160, loss=0.0487, recon=0.0487, kl=60.7327, beta=0.0000\n",
      "Batch 180, loss=0.0713, recon=0.0712, kl=61.4863, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0703 (Recon: 0.0703, KL: 67.2508, Current Beta: 0.0000) | Avg Valid Loss: 0.0592 | Avg Valid recon Loss: 0.0592\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0648, recon=0.0648, kl=55.5843, beta=0.0000\n",
      "Batch 40, loss=0.0549, recon=0.0549, kl=49.0182, beta=0.0000\n",
      "Batch 60, loss=0.0551, recon=0.0551, kl=43.8416, beta=0.0000\n",
      "Batch 80, loss=0.0561, recon=0.0560, kl=40.9959, beta=0.0000\n",
      "Batch 100, loss=0.0419, recon=0.0419, kl=41.0072, beta=0.0000\n",
      "Batch 120, loss=0.0388, recon=0.0388, kl=42.2921, beta=0.0000\n",
      "Batch 140, loss=0.3160, recon=0.3159, kl=40.2748, beta=0.0000\n",
      "Batch 160, loss=0.0427, recon=0.0427, kl=40.1323, beta=0.0000\n",
      "Batch 180, loss=0.0440, recon=0.0439, kl=38.3698, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0648 (Recon: 0.0648, KL: 44.6853, Current Beta: 0.0000) | Avg Valid Loss: 0.0555 | Avg Valid recon Loss: 0.0555\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.2459, recon=0.2458, kl=29.2886, beta=0.0000\n",
      "Batch 40, loss=0.0455, recon=0.0455, kl=22.0019, beta=0.0000\n",
      "Batch 60, loss=0.0575, recon=0.0575, kl=23.3254, beta=0.0000\n",
      "Batch 80, loss=0.0409, recon=0.0409, kl=23.9871, beta=0.0000\n",
      "Batch 100, loss=0.0961, recon=0.0961, kl=22.1308, beta=0.0000\n",
      "Batch 120, loss=0.0398, recon=0.0398, kl=21.0512, beta=0.0000\n",
      "Batch 140, loss=0.0638, recon=0.0637, kl=19.5400, beta=0.0000\n",
      "Batch 160, loss=0.0345, recon=0.0345, kl=18.0193, beta=0.0000\n",
      "Batch 180, loss=0.0550, recon=0.0549, kl=19.2030, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0607 (Recon: 0.0607, KL: 23.0869, Current Beta: 0.0000) | Avg Valid Loss: 0.0518 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0432, recon=0.0432, kl=12.5705, beta=0.0000\n",
      "Batch 40, loss=0.0392, recon=0.0392, kl=9.9729, beta=0.0000\n",
      "Batch 60, loss=0.0314, recon=0.0313, kl=10.3495, beta=0.0000\n",
      "Batch 80, loss=0.0492, recon=0.0491, kl=9.3100, beta=0.0000\n",
      "Batch 100, loss=0.0352, recon=0.0351, kl=7.8442, beta=0.0000\n",
      "Batch 120, loss=0.0441, recon=0.0441, kl=8.3958, beta=0.0000\n",
      "Batch 140, loss=0.0454, recon=0.0454, kl=8.0761, beta=0.0000\n",
      "Batch 160, loss=0.0279, recon=0.0279, kl=8.0482, beta=0.0000\n",
      "Batch 180, loss=0.0455, recon=0.0455, kl=7.6562, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0576 (Recon: 0.0575, KL: 9.7544, Current Beta: 0.0000) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0499\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0854, recon=0.0854, kl=3.5387, beta=0.0000\n",
      "Batch 40, loss=0.0665, recon=0.0665, kl=3.3252, beta=0.0000\n",
      "Batch 60, loss=0.0302, recon=0.0301, kl=3.0843, beta=0.0000\n",
      "Batch 80, loss=0.0288, recon=0.0288, kl=2.8697, beta=0.0000\n",
      "Batch 100, loss=0.0657, recon=0.0657, kl=3.3987, beta=0.0000\n",
      "Batch 120, loss=0.0462, recon=0.0462, kl=3.0399, beta=0.0000\n",
      "Batch 140, loss=0.0304, recon=0.0303, kl=2.5458, beta=0.0000\n",
      "Batch 160, loss=0.0832, recon=0.0831, kl=3.3152, beta=0.0000\n",
      "Batch 180, loss=0.0751, recon=0.0751, kl=2.8705, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0548 (Recon: 0.0548, KL: 3.3476, Current Beta: 0.0000) | Avg Valid Loss: 0.0477 | Avg Valid recon Loss: 0.0477\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0397, recon=0.0397, kl=1.0703, beta=0.0000\n",
      "Batch 40, loss=0.0557, recon=0.0557, kl=1.1892, beta=0.0000\n",
      "Batch 60, loss=0.0661, recon=0.0661, kl=0.8794, beta=0.0000\n",
      "Batch 80, loss=0.0327, recon=0.0327, kl=1.4000, beta=0.0000\n",
      "Batch 100, loss=0.0375, recon=0.0375, kl=0.7324, beta=0.0000\n",
      "Batch 120, loss=0.0767, recon=0.0767, kl=0.8074, beta=0.0000\n",
      "Batch 140, loss=0.0426, recon=0.0426, kl=0.6066, beta=0.0000\n",
      "Batch 160, loss=0.0630, recon=0.0629, kl=0.7715, beta=0.0000\n",
      "Batch 180, loss=0.0826, recon=0.0826, kl=0.7846, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0530 (Recon: 0.0530, KL: 1.0081, Current Beta: 0.0000) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0458\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0370, recon=0.0370, kl=0.1750, beta=0.0001\n",
      "Batch 40, loss=0.0348, recon=0.0348, kl=0.2326, beta=0.0001\n",
      "Batch 60, loss=0.0311, recon=0.0311, kl=0.1563, beta=0.0001\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=0.2948, beta=0.0001\n",
      "Batch 100, loss=0.0443, recon=0.0443, kl=0.1460, beta=0.0001\n",
      "Batch 120, loss=0.0362, recon=0.0362, kl=0.1417, beta=0.0001\n",
      "Batch 140, loss=0.0300, recon=0.0300, kl=0.1387, beta=0.0001\n",
      "Batch 160, loss=0.0689, recon=0.0689, kl=0.0664, beta=0.0001\n",
      "Batch 180, loss=0.0300, recon=0.0300, kl=0.1365, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0510 (Recon: 0.0510, KL: 0.1828, Current Beta: 0.0001) | Avg Valid Loss: 0.0451 | Avg Valid recon Loss: 0.0450\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0408, recon=0.0408, kl=0.0188, beta=0.0002\n",
      "Batch 40, loss=0.0558, recon=0.0558, kl=0.0400, beta=0.0002\n",
      "Batch 60, loss=0.0779, recon=0.0779, kl=0.0134, beta=0.0002\n",
      "Batch 80, loss=0.0367, recon=0.0367, kl=0.0185, beta=0.0002\n",
      "Batch 100, loss=0.0312, recon=0.0312, kl=0.0122, beta=0.0002\n",
      "Batch 120, loss=0.0376, recon=0.0376, kl=0.0142, beta=0.0002\n",
      "Batch 140, loss=0.0318, recon=0.0318, kl=0.0115, beta=0.0002\n",
      "Batch 160, loss=0.0363, recon=0.0363, kl=0.0114, beta=0.0002\n",
      "Batch 180, loss=0.0302, recon=0.0302, kl=0.0193, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0494, KL: 0.0220, Current Beta: 0.0002) | Avg Valid Loss: 0.0440 | Avg Valid recon Loss: 0.0440\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0375, recon=0.0374, kl=0.0099, beta=0.0004\n",
      "Batch 40, loss=0.0336, recon=0.0336, kl=0.0032, beta=0.0004\n",
      "Batch 60, loss=0.1752, recon=0.1752, kl=0.0054, beta=0.0004\n",
      "Batch 80, loss=0.0479, recon=0.0479, kl=0.0057, beta=0.0004\n",
      "Batch 100, loss=0.0631, recon=0.0631, kl=0.0036, beta=0.0004\n",
      "Batch 120, loss=0.0503, recon=0.0503, kl=0.0037, beta=0.0004\n",
      "Batch 140, loss=0.0299, recon=0.0299, kl=0.0012, beta=0.0004\n",
      "Batch 160, loss=0.0387, recon=0.0387, kl=0.0021, beta=0.0004\n",
      "Batch 180, loss=0.0280, recon=0.0280, kl=0.0020, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0481 (Recon: 0.0481, KL: 0.0051, Current Beta: 0.0004) | Avg Valid Loss: 0.0427 | Avg Valid recon Loss: 0.0427\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0257, recon=0.0257, kl=0.0013, beta=0.0006\n",
      "Batch 40, loss=0.0745, recon=0.0745, kl=0.0013, beta=0.0006\n",
      "Batch 60, loss=0.0360, recon=0.0360, kl=0.0007, beta=0.0006\n",
      "Batch 80, loss=0.0254, recon=0.0254, kl=0.0012, beta=0.0006\n",
      "Batch 100, loss=0.0378, recon=0.0378, kl=0.0006, beta=0.0006\n",
      "Batch 120, loss=0.0303, recon=0.0303, kl=0.0012, beta=0.0006\n",
      "Batch 140, loss=0.0343, recon=0.0343, kl=0.0012, beta=0.0006\n",
      "Batch 160, loss=0.0287, recon=0.0287, kl=0.0022, beta=0.0006\n",
      "Batch 180, loss=0.0313, recon=0.0313, kl=0.0011, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 0.0016, Current Beta: 0.0006) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0473, recon=0.0473, kl=0.0010, beta=0.0010\n",
      "Batch 40, loss=0.0610, recon=0.0610, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0329, recon=0.0329, kl=0.0011, beta=0.0010\n",
      "Batch 80, loss=0.0259, recon=0.0259, kl=0.0008, beta=0.0010\n",
      "Batch 100, loss=0.0297, recon=0.0297, kl=0.0067, beta=0.0010\n",
      "Batch 120, loss=0.0408, recon=0.0408, kl=0.0009, beta=0.0010\n",
      "Batch 140, loss=0.0329, recon=0.0329, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0308, recon=0.0308, kl=0.0005, beta=0.0010\n",
      "Batch 180, loss=0.0358, recon=0.0358, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0457, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0259, recon=0.0259, kl=0.0008, beta=0.0010\n",
      "Batch 40, loss=0.0326, recon=0.0326, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0304, recon=0.0304, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0526, recon=0.0526, kl=0.0006, beta=0.0010\n",
      "Batch 100, loss=0.0357, recon=0.0357, kl=0.0008, beta=0.0010\n",
      "Batch 120, loss=0.0311, recon=0.0311, kl=0.0009, beta=0.0010\n",
      "Batch 140, loss=0.0639, recon=0.0639, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0237, recon=0.0237, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0314, recon=0.0314, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0451 (Recon: 0.0451, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0397\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0326, recon=0.0326, kl=0.0005, beta=0.0010\n",
      "Batch 40, loss=0.1343, recon=0.1343, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.1475, recon=0.1475, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0233, recon=0.0233, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0463, recon=0.0463, kl=0.0005, beta=0.0010\n",
      "Batch 120, loss=0.0471, recon=0.0471, kl=0.0009, beta=0.0010\n",
      "Batch 140, loss=0.0352, recon=0.0352, kl=0.0005, beta=0.0010\n",
      "Batch 160, loss=0.1044, recon=0.1044, kl=0.0007, beta=0.0010\n",
      "Batch 180, loss=0.0518, recon=0.0518, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0440, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0243, recon=0.0243, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0262, recon=0.0262, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0623, recon=0.0623, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0338, recon=0.0338, kl=0.0007, beta=0.0010\n",
      "Batch 100, loss=0.0559, recon=0.0559, kl=0.0023, beta=0.0010\n",
      "Batch 120, loss=0.0735, recon=0.0735, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0289, recon=0.0289, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0317, recon=0.0317, kl=0.0007, beta=0.0010\n",
      "Batch 180, loss=0.0253, recon=0.0253, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0432, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0548, recon=0.0548, kl=0.0016, beta=0.0010\n",
      "Batch 40, loss=0.0316, recon=0.0316, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0357, recon=0.0357, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0240, recon=0.0240, kl=0.0005, beta=0.0010\n",
      "Batch 100, loss=0.0288, recon=0.0288, kl=0.0007, beta=0.0010\n",
      "Batch 120, loss=0.0316, recon=0.0316, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0605, recon=0.0605, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0594, recon=0.0594, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0338, recon=0.0338, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0425, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0368\n",
      "\n",
      "[VRAE Run 46/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1405, recon=0.1405, kl=42.1201, beta=0.0000\n",
      "Batch 40, loss=0.1388, recon=0.1388, kl=36.6922, beta=0.0000\n",
      "Batch 60, loss=0.0568, recon=0.0568, kl=48.1811, beta=0.0000\n",
      "Batch 80, loss=0.0705, recon=0.0705, kl=58.3051, beta=0.0000\n",
      "Batch 100, loss=0.0613, recon=0.0613, kl=55.2429, beta=0.0000\n",
      "Batch 120, loss=0.0863, recon=0.0863, kl=45.5071, beta=0.0000\n",
      "Batch 140, loss=0.0817, recon=0.0817, kl=54.7130, beta=0.0000\n",
      "Batch 160, loss=0.0534, recon=0.0534, kl=61.5818, beta=0.0000\n",
      "Batch 180, loss=0.0761, recon=0.0761, kl=66.9577, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1311 (Recon: 0.1311, KL: 48.8108, Current Beta: 0.0000) | Avg Valid Loss: 0.0649 | Avg Valid recon Loss: 0.0649\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0566, recon=0.0566, kl=67.8350, beta=0.0000\n",
      "Batch 40, loss=0.0395, recon=0.0395, kl=73.4300, beta=0.0000\n",
      "Batch 60, loss=0.0583, recon=0.0583, kl=72.1490, beta=0.0000\n",
      "Batch 80, loss=0.0525, recon=0.0525, kl=72.7579, beta=0.0000\n",
      "Batch 100, loss=0.0642, recon=0.0642, kl=74.8041, beta=0.0000\n",
      "Batch 120, loss=0.0398, recon=0.0398, kl=66.3722, beta=0.0000\n",
      "Batch 140, loss=0.0475, recon=0.0475, kl=60.9349, beta=0.0000\n",
      "Batch 160, loss=0.0299, recon=0.0299, kl=59.4276, beta=0.0000\n",
      "Batch 180, loss=0.0449, recon=0.0449, kl=61.8025, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0630 (Recon: 0.0630, KL: 67.9665, Current Beta: 0.0000) | Avg Valid Loss: 0.0486 | Avg Valid recon Loss: 0.0486\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0352, recon=0.0352, kl=52.0087, beta=0.0000\n",
      "Batch 40, loss=0.0324, recon=0.0324, kl=47.8960, beta=0.0000\n",
      "Batch 60, loss=0.0481, recon=0.0481, kl=52.4122, beta=0.0000\n",
      "Batch 80, loss=0.0391, recon=0.0391, kl=58.9852, beta=0.0000\n",
      "Batch 100, loss=0.0330, recon=0.0330, kl=57.1912, beta=0.0000\n",
      "Batch 120, loss=0.0334, recon=0.0334, kl=68.2644, beta=0.0000\n",
      "Batch 140, loss=0.0307, recon=0.0307, kl=87.4987, beta=0.0000\n",
      "Batch 160, loss=0.0398, recon=0.0398, kl=68.6651, beta=0.0000\n",
      "Batch 180, loss=0.0252, recon=0.0252, kl=58.0098, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6022 (Recon: 0.6022, KL: 69.1191, Current Beta: 0.0000) | Avg Valid Loss: 0.0469 | Avg Valid recon Loss: 0.0469\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0384, recon=0.0384, kl=58.4409, beta=0.0000\n",
      "Batch 40, loss=0.0340, recon=0.0340, kl=62.8001, beta=0.0000\n",
      "Batch 60, loss=0.1517, recon=0.1517, kl=63.7877, beta=0.0000\n",
      "Batch 80, loss=0.0486, recon=0.0486, kl=63.7865, beta=0.0000\n",
      "Batch 100, loss=0.0318, recon=0.0318, kl=65.7034, beta=0.0000\n",
      "Batch 120, loss=0.0296, recon=0.0296, kl=63.2411, beta=0.0000\n",
      "Batch 140, loss=0.0479, recon=0.0479, kl=62.5297, beta=0.0000\n",
      "Batch 160, loss=0.0279, recon=0.0279, kl=67.2032, beta=0.0000\n",
      "Batch 180, loss=0.0299, recon=0.0299, kl=68.4590, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 63.9435, Current Beta: 0.0000) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0344, recon=0.0344, kl=67.4462, beta=0.0000\n",
      "Batch 40, loss=0.0385, recon=0.0384, kl=70.5439, beta=0.0000\n",
      "Batch 60, loss=0.0371, recon=0.0371, kl=70.1725, beta=0.0000\n",
      "Batch 80, loss=0.0426, recon=0.0426, kl=72.3254, beta=0.0000\n",
      "Batch 100, loss=0.0314, recon=0.0314, kl=72.1691, beta=0.0000\n",
      "Batch 120, loss=0.0256, recon=0.0256, kl=78.9869, beta=0.0000\n",
      "Batch 140, loss=0.0302, recon=0.0302, kl=73.5204, beta=0.0000\n",
      "Batch 160, loss=0.0450, recon=0.0450, kl=78.0681, beta=0.0000\n",
      "Batch 180, loss=0.0670, recon=0.0670, kl=76.6175, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0491 (Recon: 0.0491, KL: 73.3012, Current Beta: 0.0000) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0580, recon=0.0580, kl=76.8848, beta=0.0000\n",
      "Batch 40, loss=0.0410, recon=0.0409, kl=75.7800, beta=0.0000\n",
      "Batch 60, loss=0.0270, recon=0.0270, kl=76.1830, beta=0.0000\n",
      "Batch 80, loss=0.0521, recon=0.0521, kl=78.6287, beta=0.0000\n",
      "Batch 100, loss=0.0314, recon=0.0313, kl=79.8211, beta=0.0000\n",
      "Batch 120, loss=0.0277, recon=0.0277, kl=78.9487, beta=0.0000\n",
      "Batch 140, loss=0.0382, recon=0.0382, kl=77.8250, beta=0.0000\n",
      "Batch 160, loss=0.0350, recon=0.0350, kl=78.1750, beta=0.0000\n",
      "Batch 180, loss=0.0375, recon=0.0375, kl=77.2928, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0468, KL: 77.1440, Current Beta: 0.0000) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0350, recon=0.0349, kl=78.8917, beta=0.0000\n",
      "Batch 40, loss=0.0274, recon=0.0274, kl=73.7626, beta=0.0000\n",
      "Batch 60, loss=0.0341, recon=0.0340, kl=75.9877, beta=0.0000\n",
      "Batch 80, loss=0.0349, recon=0.0349, kl=76.8072, beta=0.0000\n",
      "Batch 100, loss=0.0321, recon=0.0321, kl=77.4271, beta=0.0000\n",
      "Batch 120, loss=0.0388, recon=0.0388, kl=76.0515, beta=0.0000\n",
      "Batch 140, loss=0.0476, recon=0.0475, kl=75.0568, beta=0.0000\n",
      "Batch 160, loss=0.0439, recon=0.0439, kl=73.4111, beta=0.0000\n",
      "Batch 180, loss=0.0279, recon=0.0278, kl=75.3562, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0440, KL: 75.9334, Current Beta: 0.0000) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0298, recon=0.0296, kl=72.4004, beta=0.0000\n",
      "Batch 40, loss=0.0413, recon=0.0412, kl=69.6122, beta=0.0000\n",
      "Batch 60, loss=0.0393, recon=0.0392, kl=68.4548, beta=0.0000\n",
      "Batch 80, loss=0.0349, recon=0.0348, kl=67.4243, beta=0.0000\n",
      "Batch 100, loss=0.0306, recon=0.0305, kl=63.9202, beta=0.0000\n",
      "Batch 120, loss=0.0387, recon=0.0386, kl=63.8278, beta=0.0000\n",
      "Batch 140, loss=0.0306, recon=0.0305, kl=61.6083, beta=0.0000\n",
      "Batch 160, loss=0.0322, recon=0.0321, kl=63.0652, beta=0.0000\n",
      "Batch 180, loss=0.0350, recon=0.0349, kl=60.4505, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0414, KL: 66.4381, Current Beta: 0.0000) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0407, recon=0.0404, kl=56.6764, beta=0.0000\n",
      "Batch 40, loss=0.0483, recon=0.0481, kl=54.3781, beta=0.0000\n",
      "Batch 60, loss=0.0378, recon=0.0376, kl=51.7514, beta=0.0000\n",
      "Batch 80, loss=0.0335, recon=0.0333, kl=51.5056, beta=0.0000\n",
      "Batch 100, loss=0.0273, recon=0.0271, kl=49.0259, beta=0.0000\n",
      "Batch 120, loss=0.0387, recon=0.0385, kl=48.2704, beta=0.0000\n",
      "Batch 140, loss=0.1265, recon=0.1263, kl=48.1749, beta=0.0000\n",
      "Batch 160, loss=0.0281, recon=0.0280, kl=47.1932, beta=0.0000\n",
      "Batch 180, loss=0.0295, recon=0.0293, kl=46.6881, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0447 (Recon: 0.0445, KL: 51.7099, Current Beta: 0.0000) | Avg Valid Loss: 0.0356 | Avg Valid recon Loss: 0.0354\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0520, recon=0.0515, kl=42.3803, beta=0.0000\n",
      "Batch 40, loss=0.0456, recon=0.0452, kl=37.8522, beta=0.0000\n",
      "Batch 60, loss=0.0359, recon=0.0355, kl=35.8391, beta=0.0000\n",
      "Batch 80, loss=0.0287, recon=0.0283, kl=34.4479, beta=0.0000\n",
      "Batch 100, loss=0.0373, recon=0.0369, kl=34.6142, beta=0.0000\n",
      "Batch 120, loss=0.0273, recon=0.0269, kl=33.8871, beta=0.0000\n",
      "Batch 140, loss=0.1606, recon=0.1602, kl=32.4237, beta=0.0000\n",
      "Batch 160, loss=0.0263, recon=0.0259, kl=30.5798, beta=0.0000\n",
      "Batch 180, loss=0.0385, recon=0.0382, kl=28.3745, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0410, KL: 35.7079, Current Beta: 0.0000) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0285, recon=0.0278, kl=24.1194, beta=0.0000\n",
      "Batch 40, loss=0.0292, recon=0.0286, kl=20.6502, beta=0.0000\n",
      "Batch 60, loss=0.0189, recon=0.0184, kl=18.2309, beta=0.0000\n",
      "Batch 80, loss=0.0236, recon=0.0232, kl=16.0554, beta=0.0000\n",
      "Batch 100, loss=0.0465, recon=0.0461, kl=14.5871, beta=0.0000\n",
      "Batch 120, loss=0.1361, recon=0.1356, kl=16.0135, beta=0.0000\n",
      "Batch 140, loss=0.0553, recon=0.0549, kl=15.5767, beta=0.0000\n",
      "Batch 160, loss=0.0286, recon=0.0283, kl=12.6781, beta=0.0000\n",
      "Batch 180, loss=0.0506, recon=0.0503, kl=12.8056, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0420, KL: 17.4238, Current Beta: 0.0000) | Avg Valid Loss: 0.0362 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0276, recon=0.0269, kl=9.3776, beta=0.0001\n",
      "Batch 40, loss=0.0357, recon=0.0352, kl=6.1579, beta=0.0001\n",
      "Batch 60, loss=0.0283, recon=0.0278, kl=6.0911, beta=0.0001\n",
      "Batch 80, loss=0.0284, recon=0.0279, kl=6.8797, beta=0.0001\n",
      "Batch 100, loss=0.0269, recon=0.0265, kl=4.2158, beta=0.0001\n",
      "Batch 120, loss=0.0527, recon=0.0524, kl=4.1960, beta=0.0001\n",
      "Batch 140, loss=0.0261, recon=0.0259, kl=3.5570, beta=0.0001\n",
      "Batch 160, loss=0.0483, recon=0.0480, kl=3.4091, beta=0.0001\n",
      "Batch 180, loss=0.0325, recon=0.0323, kl=3.0007, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0436, KL: 5.8241, Current Beta: 0.0001) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0472\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0502, recon=0.0496, kl=3.5663, beta=0.0002\n",
      "Batch 40, loss=0.0388, recon=0.0385, kl=2.1141, beta=0.0002\n",
      "Batch 60, loss=0.0309, recon=0.0303, kl=3.2234, beta=0.0002\n",
      "Batch 80, loss=0.0327, recon=0.0324, kl=1.5123, beta=0.0002\n",
      "Batch 100, loss=0.0358, recon=0.0355, kl=1.3833, beta=0.0002\n",
      "Batch 120, loss=0.0310, recon=0.0306, kl=1.9474, beta=0.0002\n",
      "Batch 140, loss=0.0577, recon=0.0574, kl=1.4729, beta=0.0002\n",
      "Batch 160, loss=0.0379, recon=0.0376, kl=1.4784, beta=0.0002\n",
      "Batch 180, loss=0.0313, recon=0.0309, kl=2.4180, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0475, KL: 2.0630, Current Beta: 0.0002) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1042, recon=0.1038, kl=0.8941, beta=0.0004\n",
      "Batch 40, loss=0.0676, recon=0.0674, kl=0.6286, beta=0.0004\n",
      "Batch 60, loss=0.0230, recon=0.0227, kl=0.9341, beta=0.0004\n",
      "Batch 80, loss=0.0339, recon=0.0337, kl=0.5420, beta=0.0004\n",
      "Batch 100, loss=0.0424, recon=0.0423, kl=0.3853, beta=0.0004\n",
      "Batch 120, loss=0.0280, recon=0.0278, kl=0.4481, beta=0.0004\n",
      "Batch 140, loss=0.0295, recon=0.0294, kl=0.3020, beta=0.0004\n",
      "Batch 160, loss=0.0281, recon=0.0280, kl=0.2666, beta=0.0004\n",
      "Batch 180, loss=0.0354, recon=0.0353, kl=0.2056, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0415, KL: 0.5556, Current Beta: 0.0004) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0776, recon=0.0774, kl=0.2514, beta=0.0006\n",
      "Batch 40, loss=0.0436, recon=0.0435, kl=0.2389, beta=0.0006\n",
      "Batch 60, loss=0.0345, recon=0.0344, kl=0.1443, beta=0.0006\n",
      "Batch 80, loss=0.0304, recon=0.0303, kl=0.0866, beta=0.0006\n",
      "Batch 100, loss=0.0445, recon=0.0444, kl=0.1400, beta=0.0006\n",
      "Batch 120, loss=0.0290, recon=0.0290, kl=0.0947, beta=0.0006\n",
      "Batch 140, loss=0.0412, recon=0.0412, kl=0.0829, beta=0.0006\n",
      "Batch 160, loss=0.0354, recon=0.0353, kl=0.1028, beta=0.0006\n",
      "Batch 180, loss=0.0304, recon=0.0303, kl=0.0561, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0448, KL: 0.1360, Current Beta: 0.0006) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0287, recon=0.0287, kl=0.0553, beta=0.0010\n",
      "Batch 40, loss=0.0356, recon=0.0355, kl=0.0395, beta=0.0010\n",
      "Batch 60, loss=0.0420, recon=0.0419, kl=0.0233, beta=0.0010\n",
      "Batch 80, loss=0.0237, recon=0.0236, kl=0.0430, beta=0.0010\n",
      "Batch 100, loss=0.0294, recon=0.0293, kl=0.0554, beta=0.0010\n",
      "Batch 120, loss=0.0350, recon=0.0350, kl=0.0340, beta=0.0010\n",
      "Batch 140, loss=0.0658, recon=0.0658, kl=0.0149, beta=0.0010\n",
      "Batch 160, loss=0.0343, recon=0.0343, kl=0.0098, beta=0.0010\n",
      "Batch 180, loss=0.0489, recon=0.0488, kl=0.0086, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0402 (Recon: 0.0402, KL: 0.0368, Current Beta: 0.0010) | Avg Valid Loss: 0.0335 | Avg Valid recon Loss: 0.0335\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0304, recon=0.0303, kl=0.0116, beta=0.0010\n",
      "Batch 40, loss=0.0260, recon=0.0260, kl=0.0107, beta=0.0010\n",
      "Batch 60, loss=0.0403, recon=0.0403, kl=0.0135, beta=0.0010\n",
      "Batch 80, loss=0.0280, recon=0.0280, kl=0.0084, beta=0.0010\n",
      "Batch 100, loss=0.0225, recon=0.0225, kl=0.0053, beta=0.0010\n",
      "Batch 120, loss=0.0591, recon=0.0591, kl=0.0111, beta=0.0010\n",
      "Batch 140, loss=0.0288, recon=0.0288, kl=0.0126, beta=0.0010\n",
      "Batch 160, loss=0.0176, recon=0.0176, kl=0.0108, beta=0.0010\n",
      "Batch 180, loss=0.0554, recon=0.0554, kl=0.0130, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0378 (Recon: 0.0378, KL: 0.0180, Current Beta: 0.0010) | Avg Valid Loss: 0.0309 | Avg Valid recon Loss: 0.0309\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0331, recon=0.0331, kl=0.0158, beta=0.0010\n",
      "Batch 40, loss=0.0302, recon=0.0302, kl=0.0078, beta=0.0010\n",
      "Batch 60, loss=0.0765, recon=0.0765, kl=0.0082, beta=0.0010\n",
      "Batch 80, loss=0.0850, recon=0.0850, kl=0.0101, beta=0.0010\n",
      "Batch 100, loss=0.0347, recon=0.0347, kl=0.0136, beta=0.0010\n",
      "Batch 120, loss=0.0243, recon=0.0243, kl=0.0027, beta=0.0010\n",
      "Batch 140, loss=0.0213, recon=0.0213, kl=0.0050, beta=0.0010\n",
      "Batch 160, loss=0.0171, recon=0.0171, kl=0.0059, beta=0.0010\n",
      "Batch 180, loss=0.0187, recon=0.0187, kl=0.0065, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0362, KL: 0.0139, Current Beta: 0.0010) | Avg Valid Loss: 0.0326 | Avg Valid recon Loss: 0.0325\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0251, recon=0.0251, kl=0.0081, beta=0.0010\n",
      "Batch 40, loss=0.0440, recon=0.0440, kl=0.0102, beta=0.0010\n",
      "Batch 60, loss=0.0472, recon=0.0472, kl=0.0084, beta=0.0010\n",
      "Batch 80, loss=0.0207, recon=0.0207, kl=0.0020, beta=0.0010\n",
      "Batch 100, loss=0.0313, recon=0.0313, kl=0.0097, beta=0.0010\n",
      "Batch 120, loss=0.0650, recon=0.0650, kl=0.0158, beta=0.0010\n",
      "Batch 140, loss=0.0312, recon=0.0312, kl=0.0018, beta=0.0010\n",
      "Batch 160, loss=0.0228, recon=0.0228, kl=0.0035, beta=0.0010\n",
      "Batch 180, loss=0.0225, recon=0.0225, kl=0.0038, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0360 (Recon: 0.0360, KL: 0.0084, Current Beta: 0.0010) | Avg Valid Loss: 0.0293 | Avg Valid recon Loss: 0.0293\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0261, recon=0.0261, kl=0.0027, beta=0.0010\n",
      "Batch 40, loss=0.0237, recon=0.0237, kl=0.0020, beta=0.0010\n",
      "Batch 60, loss=0.0444, recon=0.0444, kl=0.0071, beta=0.0010\n",
      "Batch 80, loss=0.0485, recon=0.0484, kl=0.0071, beta=0.0010\n",
      "Batch 100, loss=0.0292, recon=0.0292, kl=0.0229, beta=0.0010\n",
      "Batch 120, loss=0.0310, recon=0.0310, kl=0.0065, beta=0.0010\n",
      "Batch 140, loss=0.0285, recon=0.0285, kl=0.0037, beta=0.0010\n",
      "Batch 160, loss=0.0281, recon=0.0281, kl=0.0085, beta=0.0010\n",
      "Batch 180, loss=0.0334, recon=0.0334, kl=0.0139, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0358, KL: 0.0071, Current Beta: 0.0010) | Avg Valid Loss: 0.0335 | Avg Valid recon Loss: 0.0335\n",
      "\n",
      "[VRAE Run 47/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5507, recon=0.5507, kl=0.7891, beta=0.0000\n",
      "Batch 40, loss=0.2937, recon=0.2937, kl=28.3510, beta=0.0000\n",
      "Batch 60, loss=0.2365, recon=0.2365, kl=66.2677, beta=0.0000\n",
      "Batch 80, loss=0.1887, recon=0.1887, kl=78.1693, beta=0.0000\n",
      "Batch 100, loss=0.4011, recon=0.4011, kl=86.3653, beta=0.0000\n",
      "Batch 120, loss=0.1904, recon=0.1904, kl=95.4673, beta=0.0000\n",
      "Batch 140, loss=0.1869, recon=0.1869, kl=103.0755, beta=0.0000\n",
      "Batch 160, loss=0.1690, recon=0.1690, kl=110.5276, beta=0.0000\n",
      "Batch 180, loss=0.2502, recon=0.2502, kl=117.7907, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3375 (Recon: 0.3375, KL: 70.0947, Current Beta: 0.0000) | Avg Valid Loss: 0.1510 | Avg Valid recon Loss: 0.1510\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1989, recon=0.1989, kl=123.5624, beta=0.0000\n",
      "Batch 40, loss=0.1301, recon=0.1301, kl=127.6243, beta=0.0000\n",
      "Batch 60, loss=0.1350, recon=0.1350, kl=131.9099, beta=0.0000\n",
      "Batch 80, loss=0.1042, recon=0.1042, kl=136.0812, beta=0.0000\n",
      "Batch 100, loss=0.1737, recon=0.1737, kl=139.9772, beta=0.0000\n",
      "Batch 120, loss=0.0842, recon=0.0842, kl=146.4621, beta=0.0000\n",
      "Batch 140, loss=0.1043, recon=0.1043, kl=147.4322, beta=0.0000\n",
      "Batch 160, loss=0.1141, recon=0.1141, kl=149.8204, beta=0.0000\n",
      "Batch 180, loss=0.0792, recon=0.0792, kl=154.2193, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1522 (Recon: 0.1522, KL: 137.9693, Current Beta: 0.0000) | Avg Valid Loss: 0.1013 | Avg Valid recon Loss: 0.1013\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1443, recon=0.1443, kl=154.5302, beta=0.0000\n",
      "Batch 40, loss=0.0747, recon=0.0747, kl=156.7574, beta=0.0000\n",
      "Batch 60, loss=0.0996, recon=0.0996, kl=156.2739, beta=0.0000\n",
      "Batch 80, loss=0.0972, recon=0.0972, kl=163.7577, beta=0.0000\n",
      "Batch 100, loss=0.1322, recon=0.1322, kl=165.6874, beta=0.0000\n",
      "Batch 120, loss=0.1045, recon=0.1045, kl=159.9316, beta=0.0000\n",
      "Batch 140, loss=0.1238, recon=0.1238, kl=164.4074, beta=0.0000\n",
      "Batch 160, loss=0.0809, recon=0.0809, kl=166.0628, beta=0.0000\n",
      "Batch 180, loss=0.0741, recon=0.0741, kl=169.3779, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1124 (Recon: 0.1124, KL: 160.8967, Current Beta: 0.0000) | Avg Valid Loss: 0.0832 | Avg Valid recon Loss: 0.0832\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0769, recon=0.0769, kl=166.3128, beta=0.0000\n",
      "Batch 40, loss=0.0597, recon=0.0597, kl=164.0980, beta=0.0000\n",
      "Batch 60, loss=0.0626, recon=0.0626, kl=154.8735, beta=0.0000\n",
      "Batch 80, loss=0.0556, recon=0.0556, kl=152.1468, beta=0.0000\n",
      "Batch 100, loss=0.0694, recon=0.0694, kl=154.0901, beta=0.0000\n",
      "Batch 120, loss=0.0741, recon=0.0741, kl=153.7691, beta=0.0000\n",
      "Batch 140, loss=0.0968, recon=0.0968, kl=157.2554, beta=0.0000\n",
      "Batch 160, loss=0.0824, recon=0.0823, kl=161.9786, beta=0.0000\n",
      "Batch 180, loss=0.0757, recon=0.0757, kl=161.5684, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0912 (Recon: 0.0912, KL: 158.8522, Current Beta: 0.0000) | Avg Valid Loss: 0.0705 | Avg Valid recon Loss: 0.0705\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0986, recon=0.0986, kl=156.6740, beta=0.0000\n",
      "Batch 40, loss=0.0422, recon=0.0422, kl=152.8420, beta=0.0000\n",
      "Batch 60, loss=0.0753, recon=0.0753, kl=151.2233, beta=0.0000\n",
      "Batch 80, loss=0.0673, recon=0.0673, kl=146.4851, beta=0.0000\n",
      "Batch 100, loss=0.0752, recon=0.0752, kl=139.4188, beta=0.0000\n",
      "Batch 120, loss=0.0449, recon=0.0449, kl=140.9840, beta=0.0000\n",
      "Batch 140, loss=0.1576, recon=0.1576, kl=140.2643, beta=0.0000\n",
      "Batch 160, loss=0.0570, recon=0.0570, kl=139.8144, beta=0.0000\n",
      "Batch 180, loss=0.0481, recon=0.0481, kl=137.1078, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0788 (Recon: 0.0788, KL: 146.4468, Current Beta: 0.0000) | Avg Valid Loss: 0.0645 | Avg Valid recon Loss: 0.0645\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0572, recon=0.0571, kl=128.3568, beta=0.0000\n",
      "Batch 40, loss=0.0739, recon=0.0739, kl=117.2145, beta=0.0000\n",
      "Batch 60, loss=0.0610, recon=0.0610, kl=108.9774, beta=0.0000\n",
      "Batch 80, loss=0.0499, recon=0.0499, kl=105.7173, beta=0.0000\n",
      "Batch 100, loss=0.0435, recon=0.0435, kl=101.2207, beta=0.0000\n",
      "Batch 120, loss=0.0424, recon=0.0424, kl=97.6628, beta=0.0000\n",
      "Batch 140, loss=0.0430, recon=0.0430, kl=99.9144, beta=0.0000\n",
      "Batch 160, loss=0.0354, recon=0.0354, kl=99.4801, beta=0.0000\n",
      "Batch 180, loss=0.0423, recon=0.0423, kl=92.9778, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0709 (Recon: 0.0709, KL: 108.0369, Current Beta: 0.0000) | Avg Valid Loss: 0.0597 | Avg Valid recon Loss: 0.0596\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0431, recon=0.0431, kl=80.4436, beta=0.0000\n",
      "Batch 40, loss=0.0326, recon=0.0326, kl=66.6488, beta=0.0000\n",
      "Batch 60, loss=0.0615, recon=0.0615, kl=62.1728, beta=0.0000\n",
      "Batch 80, loss=0.0471, recon=0.0471, kl=60.5031, beta=0.0000\n",
      "Batch 100, loss=1.1683, recon=1.1683, kl=62.1437, beta=0.0000\n",
      "Batch 120, loss=0.2067, recon=0.2067, kl=60.9317, beta=0.0000\n",
      "Batch 140, loss=0.0551, recon=0.0550, kl=59.8670, beta=0.0000\n",
      "Batch 160, loss=0.0604, recon=0.0603, kl=56.8575, beta=0.0000\n",
      "Batch 180, loss=0.0413, recon=0.0413, kl=58.8856, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0655 (Recon: 0.0654, KL: 64.7282, Current Beta: 0.0000) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0558\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0524, recon=0.0523, kl=40.9747, beta=0.0000\n",
      "Batch 40, loss=0.0491, recon=0.0491, kl=31.4289, beta=0.0000\n",
      "Batch 60, loss=0.0451, recon=0.0451, kl=32.0646, beta=0.0000\n",
      "Batch 80, loss=0.0371, recon=0.0371, kl=27.9364, beta=0.0000\n",
      "Batch 100, loss=0.0534, recon=0.0534, kl=28.8921, beta=0.0000\n",
      "Batch 120, loss=0.0483, recon=0.0483, kl=24.7764, beta=0.0000\n",
      "Batch 140, loss=0.0402, recon=0.0402, kl=28.9373, beta=0.0000\n",
      "Batch 160, loss=0.0397, recon=0.0397, kl=25.0105, beta=0.0000\n",
      "Batch 180, loss=0.0525, recon=0.0524, kl=26.3682, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0614 (Recon: 0.0614, KL: 31.2286, Current Beta: 0.0000) | Avg Valid Loss: 0.0536 | Avg Valid recon Loss: 0.0536\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0422, recon=0.0422, kl=13.2410, beta=0.0000\n",
      "Batch 40, loss=0.0579, recon=0.0579, kl=11.7626, beta=0.0000\n",
      "Batch 60, loss=0.0865, recon=0.0864, kl=11.0463, beta=0.0000\n",
      "Batch 80, loss=0.0534, recon=0.0534, kl=12.0801, beta=0.0000\n",
      "Batch 100, loss=0.0508, recon=0.0507, kl=10.3371, beta=0.0000\n",
      "Batch 120, loss=0.0596, recon=0.0596, kl=10.3856, beta=0.0000\n",
      "Batch 140, loss=0.0634, recon=0.0633, kl=10.3108, beta=0.0000\n",
      "Batch 160, loss=0.0379, recon=0.0378, kl=10.1452, beta=0.0000\n",
      "Batch 180, loss=0.0349, recon=0.0349, kl=8.5326, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0585 (Recon: 0.0584, KL: 11.7874, Current Beta: 0.0000) | Avg Valid Loss: 0.0506 | Avg Valid recon Loss: 0.0506\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0326, recon=0.0325, kl=3.9774, beta=0.0000\n",
      "Batch 40, loss=0.0771, recon=0.0771, kl=4.1349, beta=0.0000\n",
      "Batch 60, loss=0.0334, recon=0.0334, kl=3.3926, beta=0.0000\n",
      "Batch 80, loss=0.0360, recon=0.0360, kl=4.1572, beta=0.0000\n",
      "Batch 100, loss=0.0408, recon=0.0408, kl=3.3084, beta=0.0000\n",
      "Batch 120, loss=0.0301, recon=0.0301, kl=3.6630, beta=0.0000\n",
      "Batch 140, loss=0.0509, recon=0.0509, kl=2.5228, beta=0.0000\n",
      "Batch 160, loss=0.0686, recon=0.0686, kl=3.5473, beta=0.0000\n",
      "Batch 180, loss=0.0467, recon=0.0466, kl=2.6303, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0557 (Recon: 0.0557, KL: 3.6292, Current Beta: 0.0000) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0356, recon=0.0355, kl=1.8601, beta=0.0000\n",
      "Batch 40, loss=0.0367, recon=0.0367, kl=1.0558, beta=0.0000\n",
      "Batch 60, loss=0.0366, recon=0.0366, kl=1.2616, beta=0.0000\n",
      "Batch 80, loss=0.0463, recon=0.0462, kl=1.4863, beta=0.0000\n",
      "Batch 100, loss=0.0290, recon=0.0290, kl=1.7828, beta=0.0000\n",
      "Batch 120, loss=0.0337, recon=0.0337, kl=1.2135, beta=0.0000\n",
      "Batch 140, loss=0.0594, recon=0.0594, kl=1.2846, beta=0.0000\n",
      "Batch 160, loss=0.0369, recon=0.0369, kl=1.2210, beta=0.0000\n",
      "Batch 180, loss=0.0353, recon=0.0353, kl=1.2088, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0539 (Recon: 0.0539, KL: 1.3867, Current Beta: 0.0000) | Avg Valid Loss: 0.0471 | Avg Valid recon Loss: 0.0471\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0689, recon=0.0689, kl=0.2617, beta=0.0001\n",
      "Batch 40, loss=0.0316, recon=0.0316, kl=0.4070, beta=0.0001\n",
      "Batch 60, loss=0.0320, recon=0.0320, kl=0.2896, beta=0.0001\n",
      "Batch 80, loss=0.0253, recon=0.0252, kl=0.2455, beta=0.0001\n",
      "Batch 100, loss=0.0345, recon=0.0345, kl=0.2373, beta=0.0001\n",
      "Batch 120, loss=0.0408, recon=0.0407, kl=0.2180, beta=0.0001\n",
      "Batch 140, loss=0.0582, recon=0.0582, kl=0.2998, beta=0.0001\n",
      "Batch 160, loss=0.0418, recon=0.0418, kl=0.2313, beta=0.0001\n",
      "Batch 180, loss=0.0285, recon=0.0285, kl=0.1769, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0518, KL: 0.3085, Current Beta: 0.0001) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0420, recon=0.0420, kl=0.0550, beta=0.0002\n",
      "Batch 40, loss=0.0240, recon=0.0240, kl=0.0346, beta=0.0002\n",
      "Batch 60, loss=0.0382, recon=0.0382, kl=0.0520, beta=0.0002\n",
      "Batch 80, loss=0.0246, recon=0.0246, kl=0.0299, beta=0.0002\n",
      "Batch 100, loss=0.0467, recon=0.0467, kl=0.0197, beta=0.0002\n",
      "Batch 120, loss=0.0325, recon=0.0325, kl=0.0230, beta=0.0002\n",
      "Batch 140, loss=0.0315, recon=0.0315, kl=0.0162, beta=0.0002\n",
      "Batch 160, loss=0.0405, recon=0.0405, kl=0.0179, beta=0.0002\n",
      "Batch 180, loss=0.0253, recon=0.0253, kl=0.0200, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0503 (Recon: 0.0503, KL: 0.0417, Current Beta: 0.0002) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0661, recon=0.0661, kl=0.0054, beta=0.0004\n",
      "Batch 40, loss=0.0364, recon=0.0364, kl=0.0052, beta=0.0004\n",
      "Batch 60, loss=0.0239, recon=0.0239, kl=0.0030, beta=0.0004\n",
      "Batch 80, loss=0.0309, recon=0.0309, kl=0.0035, beta=0.0004\n",
      "Batch 100, loss=0.0450, recon=0.0450, kl=0.0068, beta=0.0004\n",
      "Batch 120, loss=0.0611, recon=0.0611, kl=0.0032, beta=0.0004\n",
      "Batch 140, loss=0.0285, recon=0.0285, kl=0.0094, beta=0.0004\n",
      "Batch 160, loss=0.0441, recon=0.0441, kl=0.0028, beta=0.0004\n",
      "Batch 180, loss=0.0259, recon=0.0259, kl=0.0057, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0487 (Recon: 0.0487, KL: 0.0066, Current Beta: 0.0004) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0326, recon=0.0326, kl=0.0013, beta=0.0006\n",
      "Batch 40, loss=0.0396, recon=0.0396, kl=0.0018, beta=0.0006\n",
      "Batch 60, loss=0.0323, recon=0.0323, kl=0.0008, beta=0.0006\n",
      "Batch 80, loss=0.0601, recon=0.0601, kl=0.0010, beta=0.0006\n",
      "Batch 100, loss=0.0417, recon=0.0417, kl=0.0024, beta=0.0006\n",
      "Batch 120, loss=0.0317, recon=0.0317, kl=0.0019, beta=0.0006\n",
      "Batch 140, loss=0.0243, recon=0.0243, kl=0.0007, beta=0.0006\n",
      "Batch 160, loss=0.0287, recon=0.0287, kl=0.0009, beta=0.0006\n",
      "Batch 180, loss=0.0261, recon=0.0261, kl=0.0009, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0477 (Recon: 0.0477, KL: 0.0017, Current Beta: 0.0006) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0591, recon=0.0591, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.0361, recon=0.0361, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0350, recon=0.0350, kl=0.0006, beta=0.0010\n",
      "Batch 80, loss=0.0195, recon=0.0195, kl=0.0005, beta=0.0010\n",
      "Batch 100, loss=0.0391, recon=0.0391, kl=0.0005, beta=0.0010\n",
      "Batch 120, loss=0.0250, recon=0.0250, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0389, recon=0.0389, kl=0.0010, beta=0.0010\n",
      "Batch 160, loss=0.0257, recon=0.0257, kl=0.0004, beta=0.0010\n",
      "Batch 180, loss=0.0412, recon=0.0412, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0464 (Recon: 0.0464, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0479, recon=0.0479, kl=0.0011, beta=0.0010\n",
      "Batch 40, loss=0.0231, recon=0.0231, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0244, recon=0.0244, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0271, recon=0.0271, kl=0.0003, beta=0.0010\n",
      "Batch 100, loss=0.0282, recon=0.0282, kl=0.0004, beta=0.0010\n",
      "Batch 120, loss=0.0373, recon=0.0373, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0267, recon=0.0267, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0897, recon=0.0897, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0248, recon=0.0248, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0452 (Recon: 0.0452, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0393 | Avg Valid recon Loss: 0.0393\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0437, recon=0.0437, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0384, recon=0.0384, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0388, recon=0.0388, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0320, recon=0.0320, kl=0.0005, beta=0.0010\n",
      "Batch 100, loss=0.0288, recon=0.0288, kl=0.0005, beta=0.0010\n",
      "Batch 120, loss=0.0447, recon=0.0447, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0331, recon=0.0331, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0302, recon=0.0302, kl=0.0004, beta=0.0010\n",
      "Batch 180, loss=0.0387, recon=0.0387, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0444 (Recon: 0.0444, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0397 | Avg Valid recon Loss: 0.0397\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0253, recon=0.0253, kl=0.0005, beta=0.0010\n",
      "Batch 40, loss=0.1126, recon=0.1126, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0214, recon=0.0214, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0229, recon=0.0229, kl=0.0005, beta=0.0010\n",
      "Batch 100, loss=0.0312, recon=0.0312, kl=0.0001, beta=0.0010\n",
      "Batch 120, loss=0.0258, recon=0.0258, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0516, recon=0.0516, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0421, recon=0.0421, kl=0.0009, beta=0.0010\n",
      "Batch 180, loss=0.0300, recon=0.0300, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0465, recon=0.0465, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0500, recon=0.0500, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0335, recon=0.0335, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0573, recon=0.0573, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0305, recon=0.0305, kl=0.0004, beta=0.0010\n",
      "Batch 120, loss=0.0259, recon=0.0259, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0266, recon=0.0266, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0184, recon=0.0184, kl=0.0006, beta=0.0010\n",
      "Batch 180, loss=0.1307, recon=0.1307, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0426 (Recon: 0.0426, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "\n",
      "[VRAE Run 48/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2133, recon=0.2133, kl=67.2226, beta=0.0000\n",
      "Batch 40, loss=0.1742, recon=0.1742, kl=90.4459, beta=0.0000\n",
      "Batch 60, loss=0.1388, recon=0.1388, kl=107.3289, beta=0.0000\n",
      "Batch 80, loss=0.0896, recon=0.0896, kl=115.4560, beta=0.0000\n",
      "Batch 100, loss=0.0721, recon=0.0721, kl=101.4111, beta=0.0000\n",
      "Batch 120, loss=0.0609, recon=0.0609, kl=70.4007, beta=0.0000\n",
      "Batch 140, loss=0.0706, recon=0.0706, kl=101.1004, beta=0.0000\n",
      "Batch 160, loss=0.0559, recon=0.0559, kl=112.3118, beta=0.0000\n",
      "Batch 180, loss=0.0747, recon=0.0747, kl=121.0867, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1404 (Recon: 0.1404, KL: 91.9100, Current Beta: 0.0000) | Avg Valid Loss: 0.0631 | Avg Valid recon Loss: 0.0631\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0658, recon=0.0658, kl=121.8874, beta=0.0000\n",
      "Batch 40, loss=0.0637, recon=0.0637, kl=126.8814, beta=0.0000\n",
      "Batch 60, loss=0.0642, recon=0.0642, kl=120.9798, beta=0.0000\n",
      "Batch 80, loss=1.3077, recon=1.3077, kl=126.0402, beta=0.0000\n",
      "Batch 100, loss=0.0621, recon=0.0621, kl=116.5776, beta=0.0000\n",
      "Batch 120, loss=0.0530, recon=0.0530, kl=128.8787, beta=0.0000\n",
      "Batch 140, loss=0.0368, recon=0.0368, kl=129.8127, beta=0.0000\n",
      "Batch 160, loss=0.0456, recon=0.0456, kl=130.5710, beta=0.0000\n",
      "Batch 180, loss=0.0362, recon=0.0362, kl=124.7005, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0651 (Recon: 0.0651, KL: 124.2988, Current Beta: 0.0000) | Avg Valid Loss: 0.0489 | Avg Valid recon Loss: 0.0489\n",
      "Epoch 3/20\n",
      "Batch 20, loss=1.1983, recon=1.1983, kl=126.9054, beta=0.0000\n",
      "Batch 40, loss=0.0366, recon=0.0366, kl=135.3324, beta=0.0000\n",
      "Batch 60, loss=0.0302, recon=0.0301, kl=138.3719, beta=0.0000\n",
      "Batch 80, loss=0.0358, recon=0.0358, kl=139.2082, beta=0.0000\n",
      "Batch 100, loss=0.0372, recon=0.0372, kl=132.1233, beta=0.0000\n",
      "Batch 120, loss=0.0507, recon=0.0507, kl=126.0807, beta=0.0000\n",
      "Batch 140, loss=0.0647, recon=0.0647, kl=126.9458, beta=0.0000\n",
      "Batch 160, loss=0.0325, recon=0.0325, kl=126.9706, beta=0.0000\n",
      "Batch 180, loss=0.0339, recon=0.0339, kl=129.3860, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 131.5559, Current Beta: 0.0000) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0449\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0482, recon=0.0482, kl=133.8891, beta=0.0000\n",
      "Batch 40, loss=0.0410, recon=0.0410, kl=135.1878, beta=0.0000\n",
      "Batch 60, loss=0.0291, recon=0.0291, kl=135.8006, beta=0.0000\n",
      "Batch 80, loss=0.0695, recon=0.0695, kl=133.1823, beta=0.0000\n",
      "Batch 100, loss=0.0364, recon=0.0364, kl=126.3971, beta=0.0000\n",
      "Batch 120, loss=0.0388, recon=0.0388, kl=124.8760, beta=0.0000\n",
      "Batch 140, loss=0.0413, recon=0.0413, kl=130.1331, beta=0.0000\n",
      "Batch 160, loss=0.1654, recon=0.1654, kl=133.9071, beta=0.0000\n",
      "Batch 180, loss=0.0330, recon=0.0330, kl=130.8546, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0517 (Recon: 0.0517, KL: 132.1344, Current Beta: 0.0000) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0472\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0432, recon=0.0432, kl=136.7417, beta=0.0000\n",
      "Batch 40, loss=0.0592, recon=0.0592, kl=128.7857, beta=0.0000\n",
      "Batch 60, loss=0.0300, recon=0.0300, kl=128.5093, beta=0.0000\n",
      "Batch 80, loss=0.0465, recon=0.0465, kl=126.0050, beta=0.0000\n",
      "Batch 100, loss=0.0520, recon=0.0519, kl=124.9268, beta=0.0000\n",
      "Batch 120, loss=0.0576, recon=0.0576, kl=130.8955, beta=0.0000\n",
      "Batch 140, loss=0.0590, recon=0.0590, kl=128.5341, beta=0.0000\n",
      "Batch 160, loss=0.0297, recon=0.0297, kl=124.3639, beta=0.0000\n",
      "Batch 180, loss=0.3128, recon=0.3127, kl=130.7331, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0505 (Recon: 0.0505, KL: 128.2223, Current Beta: 0.0000) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0450\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0427, recon=0.0426, kl=123.0698, beta=0.0000\n",
      "Batch 40, loss=0.0290, recon=0.0290, kl=119.3824, beta=0.0000\n",
      "Batch 60, loss=0.0401, recon=0.0401, kl=105.0244, beta=0.0000\n",
      "Batch 80, loss=0.0296, recon=0.0296, kl=110.8152, beta=0.0000\n",
      "Batch 100, loss=0.0833, recon=0.0833, kl=118.6233, beta=0.0000\n",
      "Batch 120, loss=0.0464, recon=0.0464, kl=120.7038, beta=0.0000\n",
      "Batch 140, loss=0.1373, recon=0.1373, kl=118.2723, beta=0.0000\n",
      "Batch 160, loss=0.0459, recon=0.0459, kl=115.5223, beta=0.0000\n",
      "Batch 180, loss=0.0375, recon=0.0374, kl=114.4650, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0488 (Recon: 0.0487, KL: 116.6388, Current Beta: 0.0000) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0433, recon=0.0432, kl=98.7889, beta=0.0000\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=92.3453, beta=0.0000\n",
      "Batch 60, loss=0.0429, recon=0.0428, kl=97.7244, beta=0.0000\n",
      "Batch 80, loss=0.0891, recon=0.0890, kl=100.4175, beta=0.0000\n",
      "Batch 100, loss=0.0437, recon=0.0436, kl=97.8284, beta=0.0000\n",
      "Batch 120, loss=0.0346, recon=0.0345, kl=97.3456, beta=0.0000\n",
      "Batch 140, loss=0.0425, recon=0.0425, kl=102.9538, beta=0.0000\n",
      "Batch 160, loss=0.0335, recon=0.0334, kl=106.5133, beta=0.0000\n",
      "Batch 180, loss=0.0207, recon=0.0206, kl=109.0165, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0468 (Recon: 0.0467, KL: 100.8403, Current Beta: 0.0000) | Avg Valid Loss: 0.0416 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0279, recon=0.0278, kl=84.2061, beta=0.0000\n",
      "Batch 40, loss=0.0483, recon=0.0482, kl=79.5339, beta=0.0000\n",
      "Batch 60, loss=0.0307, recon=0.0306, kl=82.8502, beta=0.0000\n",
      "Batch 80, loss=0.0361, recon=0.0360, kl=81.2735, beta=0.0000\n",
      "Batch 100, loss=0.0334, recon=0.0333, kl=83.1441, beta=0.0000\n",
      "Batch 120, loss=0.0696, recon=0.0694, kl=82.3654, beta=0.0000\n",
      "Batch 140, loss=0.0363, recon=0.0362, kl=77.5317, beta=0.0000\n",
      "Batch 160, loss=0.0459, recon=0.0458, kl=71.9961, beta=0.0000\n",
      "Batch 180, loss=0.0278, recon=0.0277, kl=73.9868, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0498 (Recon: 0.0497, KL: 81.7421, Current Beta: 0.0000) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0389, recon=0.0387, kl=59.6357, beta=0.0000\n",
      "Batch 40, loss=0.0343, recon=0.0341, kl=49.6282, beta=0.0000\n",
      "Batch 60, loss=0.0312, recon=0.0310, kl=58.8094, beta=0.0000\n",
      "Batch 80, loss=0.0338, recon=0.0335, kl=79.7773, beta=0.0000\n",
      "Batch 100, loss=2.1377, recon=2.1372, kl=110.6440, beta=0.0000\n",
      "Batch 120, loss=0.0664, recon=0.0660, kl=109.6748, beta=0.0000\n",
      "Batch 140, loss=0.0492, recon=0.0488, kl=103.4972, beta=0.0000\n",
      "Batch 160, loss=0.0671, recon=0.0666, kl=108.7993, beta=0.0000\n",
      "Batch 180, loss=0.0362, recon=0.0357, kl=120.7497, beta=0.0000\n",
      "  â†’ Avg Train Loss: 12.9363 (Recon: 12.9354, KL: 202.3912, Current Beta: 0.0000) | Avg Valid Loss: 0.0495 | Avg Valid recon Loss: 0.0490\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0512, recon=0.0500, kl=116.0194, beta=0.0000\n",
      "Batch 40, loss=0.0420, recon=0.0407, kl=115.9780, beta=0.0000\n",
      "Batch 60, loss=0.0318, recon=0.0306, kl=112.5622, beta=0.0000\n",
      "Batch 80, loss=0.0454, recon=0.0442, kl=116.9096, beta=0.0000\n",
      "Batch 100, loss=0.0845, recon=0.0832, kl=115.9294, beta=0.0000\n",
      "Batch 120, loss=0.0276, recon=0.0263, kl=112.3202, beta=0.0000\n",
      "Batch 140, loss=0.0336, recon=0.0324, kl=105.0397, beta=0.0000\n",
      "Batch 160, loss=0.0406, recon=0.0393, kl=121.1197, beta=0.0000\n",
      "Batch 180, loss=0.0330, recon=0.0316, kl=125.6658, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0840 (Recon: 0.0827, KL: 115.5720, Current Beta: 0.0000) | Avg Valid Loss: 0.0462 | Avg Valid recon Loss: 0.0448\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0424, recon=0.0388, kl=124.1995, beta=0.0000\n",
      "Batch 40, loss=0.0313, recon=0.0277, kl=121.7990, beta=0.0000\n",
      "Batch 60, loss=0.0327, recon=0.0292, kl=120.6110, beta=0.0000\n",
      "Batch 80, loss=0.0300, recon=0.0264, kl=121.2109, beta=0.0000\n",
      "Batch 100, loss=0.0302, recon=0.0268, kl=115.2688, beta=0.0000\n",
      "Batch 120, loss=0.0270, recon=0.0238, kl=108.2910, beta=0.0000\n",
      "Batch 140, loss=0.0441, recon=0.0408, kl=114.4678, beta=0.0000\n",
      "Batch 160, loss=0.0580, recon=0.0550, kl=104.9009, beta=0.0000\n",
      "Batch 180, loss=0.0575, recon=0.0541, kl=114.6628, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0467, KL: 117.5783, Current Beta: 0.0000) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0401, recon=0.0323, kl=102.1021, beta=0.0001\n",
      "Batch 40, loss=0.0426, recon=0.0348, kl=101.8667, beta=0.0001\n",
      "Batch 60, loss=0.0536, recon=0.0461, kl=99.0383, beta=0.0001\n",
      "Batch 80, loss=0.0402, recon=0.0327, kl=98.7949, beta=0.0001\n",
      "Batch 100, loss=0.0448, recon=0.0377, kl=93.5540, beta=0.0001\n",
      "Batch 120, loss=0.0297, recon=0.0231, kl=86.7696, beta=0.0001\n",
      "Batch 140, loss=0.0296, recon=0.0230, kl=86.8327, beta=0.0001\n",
      "Batch 160, loss=0.0492, recon=0.0427, kl=85.3916, beta=0.0001\n",
      "Batch 180, loss=0.0463, recon=0.0401, kl=82.2862, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0510 (Recon: 0.0438, KL: 94.8633, Current Beta: 0.0001) | Avg Valid Loss: 0.0494 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0548, recon=0.0401, kl=80.1867, beta=0.0002\n",
      "Batch 40, loss=0.0455, recon=0.0321, kl=73.6980, beta=0.0002\n",
      "Batch 60, loss=0.0416, recon=0.0296, kl=65.6369, beta=0.0002\n",
      "Batch 80, loss=0.0336, recon=0.0217, kl=64.8723, beta=0.0002\n",
      "Batch 100, loss=0.0522, recon=0.0405, kl=64.1440, beta=0.0002\n",
      "Batch 120, loss=0.0356, recon=0.0249, kl=58.7254, beta=0.0002\n",
      "Batch 140, loss=0.0517, recon=0.0419, kl=54.1246, beta=0.0002\n",
      "Batch 160, loss=0.4903, recon=0.4808, kl=52.0060, beta=0.0002\n",
      "Batch 180, loss=0.0384, recon=0.0297, kl=47.8020, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0434, KL: 64.6786, Current Beta: 0.0002) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0681, recon=0.0505, kl=46.5214, beta=0.0004\n",
      "Batch 40, loss=0.0571, recon=0.0426, kl=38.3686, beta=0.0004\n",
      "Batch 60, loss=0.0553, recon=0.0431, kl=32.1074, beta=0.0004\n",
      "Batch 80, loss=0.0425, recon=0.0304, kl=32.0358, beta=0.0004\n",
      "Batch 100, loss=0.0433, recon=0.0321, kl=29.7342, beta=0.0004\n",
      "Batch 120, loss=0.0313, recon=0.0219, kl=24.7244, beta=0.0004\n",
      "Batch 140, loss=0.0502, recon=0.0427, kl=19.6552, beta=0.0004\n",
      "Batch 160, loss=0.0427, recon=0.0360, kl=17.7848, beta=0.0004\n",
      "Batch 180, loss=0.0386, recon=0.0311, kl=19.8258, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0567 (Recon: 0.0452, KL: 30.5780, Current Beta: 0.0004) | Avg Valid Loss: 0.0779 | Avg Valid recon Loss: 0.0702\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0493, recon=0.0321, kl=27.6261, beta=0.0006\n",
      "Batch 40, loss=0.0371, recon=0.0214, kl=25.2788, beta=0.0006\n",
      "Batch 60, loss=0.0534, recon=0.0394, kl=22.4337, beta=0.0006\n",
      "Batch 80, loss=0.1440, recon=0.1344, kl=15.4231, beta=0.0006\n",
      "Batch 100, loss=0.0432, recon=0.0250, kl=29.0913, beta=0.0006\n",
      "Batch 120, loss=0.0475, recon=0.0308, kl=26.8456, beta=0.0006\n",
      "Batch 140, loss=0.0398, recon=0.0260, kl=22.2164, beta=0.0006\n",
      "Batch 160, loss=0.0650, recon=0.0508, kl=22.8811, beta=0.0006\n",
      "Batch 180, loss=0.0413, recon=0.0294, kl=19.0698, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.3332 (Recon: 0.3183, KL: 23.9842, Current Beta: 0.0006) | Avg Valid Loss: 0.0525 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0831, recon=0.0669, kl=16.2160, beta=0.0010\n",
      "Batch 40, loss=0.0483, recon=0.0326, kl=15.6187, beta=0.0010\n",
      "Batch 60, loss=0.0469, recon=0.0359, kl=10.9614, beta=0.0010\n",
      "Batch 80, loss=0.0463, recon=0.0385, kl=7.8219, beta=0.0010\n",
      "Batch 100, loss=0.0407, recon=0.0293, kl=11.3608, beta=0.0010\n",
      "Batch 120, loss=0.0972, recon=0.0858, kl=11.3695, beta=0.0010\n",
      "Batch 140, loss=0.0414, recon=0.0300, kl=11.3752, beta=0.0010\n",
      "Batch 160, loss=0.0420, recon=0.0298, kl=12.1943, beta=0.0010\n",
      "Batch 180, loss=0.1817, recon=0.1652, kl=16.4627, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0606 (Recon: 0.0482, KL: 12.3507, Current Beta: 0.0010) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0434, recon=0.0313, kl=12.1489, beta=0.0010\n",
      "Batch 40, loss=0.0413, recon=0.0330, kl=8.3587, beta=0.0010\n",
      "Batch 60, loss=0.0334, recon=0.0264, kl=6.9716, beta=0.0010\n",
      "Batch 80, loss=0.0929, recon=0.0795, kl=13.3186, beta=0.0010\n",
      "Batch 100, loss=0.0693, recon=0.0498, kl=19.4565, beta=0.0010\n",
      "Batch 120, loss=0.0576, recon=0.0371, kl=20.4752, beta=0.0010\n",
      "Batch 140, loss=0.3679, recon=0.3267, kl=41.1200, beta=0.0010\n",
      "Batch 160, loss=0.0740, recon=0.0349, kl=39.0648, beta=0.0010\n",
      "Batch 180, loss=0.0737, recon=0.0418, kl=31.9487, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.4126 (Recon: 0.3929, KL: 19.7099, Current Beta: 0.0010) | Avg Valid Loss: 0.1372 | Avg Valid recon Loss: 0.1027\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0565, recon=0.0268, kl=29.7755, beta=0.0010\n",
      "Batch 40, loss=0.1027, recon=0.0759, kl=26.8175, beta=0.0010\n",
      "Batch 60, loss=0.0763, recon=0.0542, kl=22.1285, beta=0.0010\n",
      "Batch 80, loss=0.0517, recon=0.0301, kl=21.5936, beta=0.0010\n",
      "Batch 100, loss=0.0463, recon=0.0258, kl=20.4887, beta=0.0010\n",
      "Batch 120, loss=0.0476, recon=0.0286, kl=19.0180, beta=0.0010\n",
      "Batch 140, loss=0.0737, recon=0.0578, kl=15.8794, beta=0.0010\n",
      "Batch 160, loss=0.0392, recon=0.0251, kl=14.1537, beta=0.0010\n",
      "Batch 180, loss=0.0443, recon=0.0262, kl=18.0687, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0698 (Recon: 0.0477, KL: 22.0724, Current Beta: 0.0010) | Avg Valid Loss: 0.0581 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0554, recon=0.0342, kl=21.2082, beta=0.0010\n",
      "Batch 40, loss=0.0429, recon=0.0277, kl=15.2429, beta=0.0010\n",
      "Batch 60, loss=0.0490, recon=0.0342, kl=14.7827, beta=0.0010\n",
      "Batch 80, loss=0.0506, recon=0.0370, kl=13.6312, beta=0.0010\n",
      "Batch 100, loss=0.0525, recon=0.0409, kl=11.5588, beta=0.0010\n",
      "Batch 120, loss=0.0476, recon=0.0364, kl=11.1676, beta=0.0010\n",
      "Batch 140, loss=0.0492, recon=0.0341, kl=15.1656, beta=0.0010\n",
      "Batch 160, loss=0.5317, recon=0.5225, kl=9.2231, beta=0.0010\n",
      "Batch 180, loss=0.0455, recon=0.0372, kl=8.2957, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0593 (Recon: 0.0450, KL: 14.3493, Current Beta: 0.0010) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0514, recon=0.0323, kl=19.0843, beta=0.0010\n",
      "Batch 40, loss=0.0556, recon=0.0323, kl=23.2804, beta=0.0010\n",
      "Batch 60, loss=0.0581, recon=0.0362, kl=21.9632, beta=0.0010\n",
      "Batch 80, loss=0.0371, recon=0.0200, kl=17.0462, beta=0.0010\n",
      "Batch 100, loss=0.0649, recon=0.0482, kl=16.7324, beta=0.0010\n",
      "Batch 120, loss=0.0456, recon=0.0278, kl=17.7664, beta=0.0010\n",
      "Batch 140, loss=0.0386, recon=0.0238, kl=14.8676, beta=0.0010\n",
      "Batch 160, loss=0.0573, recon=0.0434, kl=13.8801, beta=0.0010\n",
      "Batch 180, loss=0.0461, recon=0.0335, kl=12.5567, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0618 (Recon: 0.0446, KL: 17.2327, Current Beta: 0.0010) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0361\n",
      "\n",
      "[VRAE Run 49/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4075, recon=0.4075, kl=1.1296, beta=0.0000\n",
      "Batch 40, loss=0.2880, recon=0.2880, kl=13.4073, beta=0.0000\n",
      "Batch 60, loss=0.1671, recon=0.1671, kl=21.8924, beta=0.0000\n",
      "Batch 80, loss=0.1688, recon=0.1688, kl=26.3651, beta=0.0000\n",
      "Batch 100, loss=0.1424, recon=0.1424, kl=36.2075, beta=0.0000\n",
      "Batch 120, loss=0.1024, recon=0.1024, kl=34.3061, beta=0.0000\n",
      "Batch 140, loss=0.1214, recon=0.1214, kl=39.4365, beta=0.0000\n",
      "Batch 160, loss=0.1267, recon=0.1267, kl=38.8176, beta=0.0000\n",
      "Batch 180, loss=0.1307, recon=0.1307, kl=39.9876, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2273 (Recon: 0.2273, KL: 25.9553, Current Beta: 0.0000) | Avg Valid Loss: 0.0966 | Avg Valid recon Loss: 0.0966\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1286, recon=0.1286, kl=44.3439, beta=0.0000\n",
      "Batch 40, loss=0.0855, recon=0.0855, kl=52.5666, beta=0.0000\n",
      "Batch 60, loss=0.1041, recon=0.1041, kl=51.2572, beta=0.0000\n",
      "Batch 80, loss=0.0873, recon=0.0873, kl=52.6106, beta=0.0000\n",
      "Batch 100, loss=0.0766, recon=0.0766, kl=52.5837, beta=0.0000\n",
      "Batch 120, loss=0.1431, recon=0.1431, kl=51.2327, beta=0.0000\n",
      "Batch 140, loss=0.0668, recon=0.0668, kl=60.3288, beta=0.0000\n",
      "Batch 160, loss=0.0740, recon=0.0740, kl=63.3282, beta=0.0000\n",
      "Batch 180, loss=0.0693, recon=0.0693, kl=62.7604, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1139 (Recon: 0.1139, KL: 54.7693, Current Beta: 0.0000) | Avg Valid Loss: 0.0736 | Avg Valid recon Loss: 0.0736\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0700, recon=0.0700, kl=59.3386, beta=0.0000\n",
      "Batch 40, loss=0.0631, recon=0.0631, kl=59.9259, beta=0.0000\n",
      "Batch 60, loss=0.0850, recon=0.0850, kl=60.1207, beta=0.0000\n",
      "Batch 80, loss=0.0602, recon=0.0602, kl=55.7197, beta=0.0000\n",
      "Batch 100, loss=0.0575, recon=0.0575, kl=56.0820, beta=0.0000\n",
      "Batch 120, loss=0.0480, recon=0.0480, kl=59.7726, beta=0.0000\n",
      "Batch 140, loss=0.0595, recon=0.0595, kl=57.6578, beta=0.0000\n",
      "Batch 160, loss=0.0627, recon=0.0627, kl=60.5565, beta=0.0000\n",
      "Batch 180, loss=0.0746, recon=0.0746, kl=58.9326, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0856 (Recon: 0.0856, KL: 58.8802, Current Beta: 0.0000) | Avg Valid Loss: 0.0614 | Avg Valid recon Loss: 0.0614\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0443, recon=0.0443, kl=57.5194, beta=0.0000\n",
      "Batch 40, loss=0.0624, recon=0.0624, kl=59.8429, beta=0.0000\n",
      "Batch 60, loss=0.0633, recon=0.0633, kl=54.9591, beta=0.0000\n",
      "Batch 80, loss=0.0681, recon=0.0681, kl=63.6396, beta=0.0000\n",
      "Batch 100, loss=0.0434, recon=0.0434, kl=62.1052, beta=0.0000\n",
      "Batch 120, loss=0.0398, recon=0.0398, kl=51.3034, beta=0.0000\n",
      "Batch 140, loss=0.0448, recon=0.0448, kl=49.7698, beta=0.0000\n",
      "Batch 160, loss=0.0359, recon=0.0359, kl=49.7754, beta=0.0000\n",
      "Batch 180, loss=0.0850, recon=0.0850, kl=47.7956, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0700 (Recon: 0.0700, KL: 55.5921, Current Beta: 0.0000) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0541\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0533, recon=0.0533, kl=48.3252, beta=0.0000\n",
      "Batch 40, loss=0.0485, recon=0.0485, kl=45.6082, beta=0.0000\n",
      "Batch 60, loss=0.0434, recon=0.0434, kl=45.8423, beta=0.0000\n",
      "Batch 80, loss=0.0541, recon=0.0541, kl=47.1370, beta=0.0000\n",
      "Batch 100, loss=0.0434, recon=0.0434, kl=51.5524, beta=0.0000\n",
      "Batch 120, loss=0.0408, recon=0.0408, kl=51.5777, beta=0.0000\n",
      "Batch 140, loss=0.0798, recon=0.0798, kl=45.6426, beta=0.0000\n",
      "Batch 160, loss=0.0457, recon=0.0457, kl=46.0887, beta=0.0000\n",
      "Batch 180, loss=0.0521, recon=0.0521, kl=45.4635, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0614 (Recon: 0.0614, KL: 47.7915, Current Beta: 0.0000) | Avg Valid Loss: 0.0494 | Avg Valid recon Loss: 0.0494\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0384, recon=0.0383, kl=39.0850, beta=0.0000\n",
      "Batch 40, loss=0.0535, recon=0.0535, kl=40.0700, beta=0.0000\n",
      "Batch 60, loss=0.0847, recon=0.0847, kl=34.6984, beta=0.0000\n",
      "Batch 80, loss=0.0376, recon=0.0376, kl=35.4149, beta=0.0000\n",
      "Batch 100, loss=0.0375, recon=0.0375, kl=30.7225, beta=0.0000\n",
      "Batch 120, loss=0.0667, recon=0.0667, kl=32.1107, beta=0.0000\n",
      "Batch 140, loss=0.0451, recon=0.0451, kl=32.9418, beta=0.0000\n",
      "Batch 160, loss=0.0866, recon=0.0866, kl=32.3615, beta=0.0000\n",
      "Batch 180, loss=0.0391, recon=0.0391, kl=31.7667, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0557 (Recon: 0.0557, KL: 34.9805, Current Beta: 0.0000) | Avg Valid Loss: 0.0471 | Avg Valid recon Loss: 0.0471\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0314, recon=0.0314, kl=27.8894, beta=0.0000\n",
      "Batch 40, loss=0.0300, recon=0.0300, kl=25.4695, beta=0.0000\n",
      "Batch 60, loss=0.0424, recon=0.0424, kl=22.3689, beta=0.0000\n",
      "Batch 80, loss=0.0348, recon=0.0348, kl=21.1248, beta=0.0000\n",
      "Batch 100, loss=0.0273, recon=0.0273, kl=21.5234, beta=0.0000\n",
      "Batch 120, loss=0.0393, recon=0.0393, kl=21.2531, beta=0.0000\n",
      "Batch 140, loss=0.0397, recon=0.0396, kl=21.8795, beta=0.0000\n",
      "Batch 160, loss=0.0500, recon=0.0500, kl=22.1030, beta=0.0000\n",
      "Batch 180, loss=0.0575, recon=0.0575, kl=23.0220, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0521 (Recon: 0.0521, KL: 23.1260, Current Beta: 0.0000) | Avg Valid Loss: 0.0445 | Avg Valid recon Loss: 0.0445\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=19.2909, beta=0.0000\n",
      "Batch 40, loss=0.0933, recon=0.0932, kl=13.1888, beta=0.0000\n",
      "Batch 60, loss=0.0390, recon=0.0390, kl=11.2433, beta=0.0000\n",
      "Batch 80, loss=0.0451, recon=0.0451, kl=12.5804, beta=0.0000\n",
      "Batch 100, loss=0.0265, recon=0.0265, kl=11.4810, beta=0.0000\n",
      "Batch 120, loss=0.0650, recon=0.0650, kl=12.3681, beta=0.0000\n",
      "Batch 140, loss=0.0256, recon=0.0256, kl=11.3987, beta=0.0000\n",
      "Batch 160, loss=0.0402, recon=0.0402, kl=10.6960, beta=0.0000\n",
      "Batch 180, loss=0.0348, recon=0.0348, kl=11.1258, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0492 (Recon: 0.0492, KL: 13.3138, Current Beta: 0.0000) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0449, recon=0.0449, kl=7.4165, beta=0.0000\n",
      "Batch 40, loss=0.0360, recon=0.0360, kl=6.0549, beta=0.0000\n",
      "Batch 60, loss=0.0331, recon=0.0330, kl=6.7699, beta=0.0000\n",
      "Batch 80, loss=0.0534, recon=0.0534, kl=5.6246, beta=0.0000\n",
      "Batch 100, loss=0.0260, recon=0.0260, kl=6.8670, beta=0.0000\n",
      "Batch 120, loss=0.0512, recon=0.0512, kl=5.0407, beta=0.0000\n",
      "Batch 140, loss=0.0408, recon=0.0408, kl=4.1346, beta=0.0000\n",
      "Batch 160, loss=0.0310, recon=0.0310, kl=4.9109, beta=0.0000\n",
      "Batch 180, loss=0.0352, recon=0.0352, kl=4.3577, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0465 (Recon: 0.0465, KL: 5.8764, Current Beta: 0.0000) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0310, recon=0.0310, kl=3.2242, beta=0.0000\n",
      "Batch 40, loss=0.0346, recon=0.0345, kl=3.0197, beta=0.0000\n",
      "Batch 60, loss=0.0249, recon=0.0249, kl=2.9429, beta=0.0000\n",
      "Batch 80, loss=0.6927, recon=0.6927, kl=2.2267, beta=0.0000\n",
      "Batch 100, loss=0.0582, recon=0.0582, kl=2.2690, beta=0.0000\n",
      "Batch 120, loss=0.0435, recon=0.0435, kl=2.1472, beta=0.0000\n",
      "Batch 140, loss=0.0397, recon=0.0397, kl=2.2305, beta=0.0000\n",
      "Batch 160, loss=0.1260, recon=0.1260, kl=1.8159, beta=0.0000\n",
      "Batch 180, loss=0.1479, recon=0.1479, kl=2.1375, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0449, KL: 2.5389, Current Beta: 0.0000) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0414, recon=0.0414, kl=0.9649, beta=0.0000\n",
      "Batch 40, loss=0.0392, recon=0.0391, kl=0.8643, beta=0.0000\n",
      "Batch 60, loss=0.0249, recon=0.0249, kl=0.9246, beta=0.0000\n",
      "Batch 80, loss=0.0320, recon=0.0320, kl=0.7828, beta=0.0000\n",
      "Batch 100, loss=0.0310, recon=0.0310, kl=0.9330, beta=0.0000\n",
      "Batch 120, loss=0.0256, recon=0.0255, kl=0.8619, beta=0.0000\n",
      "Batch 140, loss=0.0223, recon=0.0222, kl=0.6469, beta=0.0000\n",
      "Batch 160, loss=0.0287, recon=0.0287, kl=0.5091, beta=0.0000\n",
      "Batch 180, loss=0.0266, recon=0.0266, kl=0.5929, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0430, KL: 0.8753, Current Beta: 0.0000) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0361\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0329, recon=0.0328, kl=0.1252, beta=0.0001\n",
      "Batch 40, loss=0.0297, recon=0.0297, kl=0.1487, beta=0.0001\n",
      "Batch 60, loss=0.0324, recon=0.0324, kl=0.1115, beta=0.0001\n",
      "Batch 80, loss=0.0263, recon=0.0263, kl=0.1200, beta=0.0001\n",
      "Batch 100, loss=0.0269, recon=0.0269, kl=0.0801, beta=0.0001\n",
      "Batch 120, loss=0.0355, recon=0.0355, kl=0.1379, beta=0.0001\n",
      "Batch 140, loss=0.0226, recon=0.0226, kl=0.0854, beta=0.0001\n",
      "Batch 160, loss=0.0292, recon=0.0292, kl=0.0690, beta=0.0001\n",
      "Batch 180, loss=0.0222, recon=0.0222, kl=0.0569, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0417, KL: 0.1278, Current Beta: 0.0001) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0329, recon=0.0329, kl=0.0143, beta=0.0002\n",
      "Batch 40, loss=0.0485, recon=0.0485, kl=0.0211, beta=0.0002\n",
      "Batch 60, loss=0.0241, recon=0.0241, kl=0.0079, beta=0.0002\n",
      "Batch 80, loss=0.0262, recon=0.0262, kl=0.0108, beta=0.0002\n",
      "Batch 100, loss=0.0625, recon=0.0625, kl=0.0030, beta=0.0002\n",
      "Batch 120, loss=0.0358, recon=0.0358, kl=0.0073, beta=0.0002\n",
      "Batch 140, loss=0.0430, recon=0.0430, kl=0.0141, beta=0.0002\n",
      "Batch 160, loss=0.0513, recon=0.0513, kl=0.0075, beta=0.0002\n",
      "Batch 180, loss=0.0221, recon=0.0221, kl=0.0066, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0404 (Recon: 0.0404, KL: 0.0127, Current Beta: 0.0002) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0254, recon=0.0254, kl=0.0045, beta=0.0004\n",
      "Batch 40, loss=0.0334, recon=0.0334, kl=0.0037, beta=0.0004\n",
      "Batch 60, loss=0.0469, recon=0.0469, kl=0.0041, beta=0.0004\n",
      "Batch 80, loss=0.0299, recon=0.0299, kl=0.0016, beta=0.0004\n",
      "Batch 100, loss=0.0551, recon=0.0551, kl=0.0016, beta=0.0004\n",
      "Batch 120, loss=0.0337, recon=0.0337, kl=0.0084, beta=0.0004\n",
      "Batch 140, loss=0.0296, recon=0.0296, kl=0.0028, beta=0.0004\n",
      "Batch 160, loss=0.0282, recon=0.0282, kl=0.0015, beta=0.0004\n",
      "Batch 180, loss=0.0343, recon=0.0343, kl=0.0021, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0394 (Recon: 0.0394, KL: 0.0051, Current Beta: 0.0004) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0282, recon=0.0282, kl=0.0012, beta=0.0006\n",
      "Batch 40, loss=0.0213, recon=0.0213, kl=0.0005, beta=0.0006\n",
      "Batch 60, loss=0.0264, recon=0.0264, kl=0.0009, beta=0.0006\n",
      "Batch 80, loss=0.0388, recon=0.0388, kl=0.0005, beta=0.0006\n",
      "Batch 100, loss=0.0284, recon=0.0284, kl=0.0009, beta=0.0006\n",
      "Batch 120, loss=0.0280, recon=0.0280, kl=0.0021, beta=0.0006\n",
      "Batch 140, loss=0.0279, recon=0.0279, kl=0.0007, beta=0.0006\n",
      "Batch 160, loss=0.0278, recon=0.0278, kl=0.0010, beta=0.0006\n",
      "Batch 180, loss=0.0289, recon=0.0289, kl=0.0007, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0387 (Recon: 0.0387, KL: 0.0016, Current Beta: 0.0006) | Avg Valid Loss: 0.0337 | Avg Valid recon Loss: 0.0337\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0248, recon=0.0248, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0229, recon=0.0229, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0205, recon=0.0205, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0242, recon=0.0242, kl=0.0006, beta=0.0010\n",
      "Batch 100, loss=0.0200, recon=0.0200, kl=0.0005, beta=0.0010\n",
      "Batch 120, loss=0.0259, recon=0.0259, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.1518, recon=0.1518, kl=0.0006, beta=0.0010\n",
      "Batch 160, loss=0.0522, recon=0.0522, kl=0.0007, beta=0.0010\n",
      "Batch 180, loss=0.0265, recon=0.0265, kl=0.0018, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0378 (Recon: 0.0378, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0323 | Avg Valid recon Loss: 0.0323\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0230, recon=0.0230, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0502, recon=0.0502, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0261, recon=0.0261, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0253, recon=0.0253, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0315, recon=0.0315, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0285, recon=0.0285, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0237, recon=0.0237, kl=0.0014, beta=0.0010\n",
      "Batch 160, loss=0.0260, recon=0.0260, kl=0.0009, beta=0.0010\n",
      "Batch 180, loss=0.1335, recon=0.1335, kl=0.0030, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0371 (Recon: 0.0371, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0316 | Avg Valid recon Loss: 0.0316\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0250, recon=0.0250, kl=0.0017, beta=0.0010\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0293, recon=0.0293, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0204, recon=0.0204, kl=0.0003, beta=0.0010\n",
      "Batch 100, loss=0.0278, recon=0.0278, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0316, recon=0.0316, kl=0.0005, beta=0.0010\n",
      "Batch 140, loss=0.0298, recon=0.0298, kl=0.0006, beta=0.0010\n",
      "Batch 160, loss=0.0302, recon=0.0302, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0193, recon=0.0193, kl=0.0015, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0363 (Recon: 0.0363, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0314 | Avg Valid recon Loss: 0.0314\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0268, recon=0.0268, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0539, recon=0.0539, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0228, recon=0.0228, kl=0.0015, beta=0.0010\n",
      "Batch 80, loss=0.1317, recon=0.1317, kl=0.0008, beta=0.0010\n",
      "Batch 100, loss=0.0337, recon=0.0336, kl=0.0004, beta=0.0010\n",
      "Batch 120, loss=0.0308, recon=0.0308, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0618, recon=0.0618, kl=0.0018, beta=0.0010\n",
      "Batch 160, loss=0.0273, recon=0.0273, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0222, recon=0.0222, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0356 (Recon: 0.0356, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0306 | Avg Valid recon Loss: 0.0306\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0304, recon=0.0304, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0303, recon=0.0303, kl=0.0047, beta=0.0010\n",
      "Batch 60, loss=0.0255, recon=0.0255, kl=0.0010, beta=0.0010\n",
      "Batch 80, loss=0.0404, recon=0.0404, kl=0.0005, beta=0.0010\n",
      "Batch 100, loss=0.0261, recon=0.0261, kl=0.0004, beta=0.0010\n",
      "Batch 120, loss=0.0358, recon=0.0358, kl=0.0001, beta=0.0010\n",
      "Batch 140, loss=0.0755, recon=0.0755, kl=0.0008, beta=0.0010\n",
      "Batch 160, loss=0.0218, recon=0.0218, kl=0.0010, beta=0.0010\n",
      "Batch 180, loss=0.0494, recon=0.0494, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0353 (Recon: 0.0353, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0305 | Avg Valid recon Loss: 0.0305\n",
      "\n",
      "[VRAE Run 50/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1760, recon=0.1760, kl=19.7505, beta=0.0000\n",
      "Batch 40, loss=0.0734, recon=0.0734, kl=25.4035, beta=0.0000\n",
      "Batch 60, loss=0.1103, recon=0.1103, kl=29.7042, beta=0.0000\n",
      "Batch 80, loss=0.0877, recon=0.0877, kl=26.8641, beta=0.0000\n",
      "Batch 100, loss=0.0656, recon=0.0656, kl=25.2432, beta=0.0000\n",
      "Batch 120, loss=0.0539, recon=0.0539, kl=25.2144, beta=0.0000\n",
      "Batch 140, loss=0.0517, recon=0.0517, kl=31.9874, beta=0.0000\n",
      "Batch 160, loss=0.0529, recon=0.0529, kl=31.8086, beta=0.0000\n",
      "Batch 180, loss=0.0660, recon=0.0660, kl=31.7639, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1117 (Recon: 0.1117, KL: 26.3833, Current Beta: 0.0000) | Avg Valid Loss: 0.0545 | Avg Valid recon Loss: 0.0545\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0395, recon=0.0395, kl=34.8881, beta=0.0000\n",
      "Batch 40, loss=0.0584, recon=0.0584, kl=35.4799, beta=0.0000\n",
      "Batch 60, loss=0.0392, recon=0.0392, kl=35.2045, beta=0.0000\n",
      "Batch 80, loss=0.0290, recon=0.0290, kl=31.0054, beta=0.0000\n",
      "Batch 100, loss=0.0312, recon=0.0312, kl=31.4233, beta=0.0000\n",
      "Batch 120, loss=0.0464, recon=0.0464, kl=32.2731, beta=0.0000\n",
      "Batch 140, loss=0.0683, recon=0.0683, kl=34.2476, beta=0.0000\n",
      "Batch 160, loss=0.0489, recon=0.0489, kl=35.2340, beta=0.0000\n",
      "Batch 180, loss=0.0337, recon=0.0337, kl=30.2140, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0597 (Recon: 0.0597, KL: 33.3308, Current Beta: 0.0000) | Avg Valid Loss: 0.0548 | Avg Valid recon Loss: 0.0548\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0601, recon=0.0601, kl=33.1892, beta=0.0000\n",
      "Batch 40, loss=0.0492, recon=0.0492, kl=35.4389, beta=0.0000\n",
      "Batch 60, loss=0.0582, recon=0.0582, kl=32.7213, beta=0.0000\n",
      "Batch 80, loss=0.0267, recon=0.0267, kl=32.3504, beta=0.0000\n",
      "Batch 100, loss=0.0437, recon=0.0437, kl=35.5587, beta=0.0000\n",
      "Batch 120, loss=0.0253, recon=0.0253, kl=36.2425, beta=0.0000\n",
      "Batch 140, loss=0.0482, recon=0.0482, kl=35.4159, beta=0.0000\n",
      "Batch 160, loss=0.0317, recon=0.0317, kl=33.7814, beta=0.0000\n",
      "Batch 180, loss=0.0383, recon=0.0383, kl=35.1505, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0533, KL: 34.2368, Current Beta: 0.0000) | Avg Valid Loss: 0.0432 | Avg Valid recon Loss: 0.0432\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0495, recon=0.0495, kl=35.5252, beta=0.0000\n",
      "Batch 40, loss=0.0301, recon=0.0301, kl=36.6085, beta=0.0000\n",
      "Batch 60, loss=0.0290, recon=0.0290, kl=38.8349, beta=0.0000\n",
      "Batch 80, loss=0.0234, recon=0.0234, kl=39.8938, beta=0.0000\n",
      "Batch 100, loss=0.0319, recon=0.0319, kl=41.2341, beta=0.0000\n",
      "Batch 120, loss=0.0265, recon=0.0265, kl=43.2108, beta=0.0000\n",
      "Batch 140, loss=0.1610, recon=0.1610, kl=42.4515, beta=0.0000\n",
      "Batch 160, loss=0.0489, recon=0.0489, kl=39.0456, beta=0.0000\n",
      "Batch 180, loss=0.0399, recon=0.0399, kl=40.2845, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0485, KL: 39.2512, Current Beta: 0.0000) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0341, recon=0.0341, kl=37.4356, beta=0.0000\n",
      "Batch 40, loss=0.0303, recon=0.0303, kl=36.6297, beta=0.0000\n",
      "Batch 60, loss=0.0346, recon=0.0346, kl=36.6396, beta=0.0000\n",
      "Batch 80, loss=0.0288, recon=0.0288, kl=36.3144, beta=0.0000\n",
      "Batch 100, loss=0.0551, recon=0.0551, kl=38.7415, beta=0.0000\n",
      "Batch 120, loss=0.0231, recon=0.0231, kl=43.5006, beta=0.0000\n",
      "Batch 140, loss=0.0908, recon=0.0908, kl=38.8303, beta=0.0000\n",
      "Batch 160, loss=0.0780, recon=0.0780, kl=37.5658, beta=0.0000\n",
      "Batch 180, loss=0.0643, recon=0.0643, kl=39.4999, beta=0.0000\n",
      "  â†’ Avg Train Loss: 1491910.4090 (Recon: 1491909.5251, KL: 12225256.2648, Current Beta: 0.0000) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0512, recon=0.0512, kl=40.1964, beta=0.0000\n",
      "Batch 40, loss=0.0262, recon=0.0262, kl=41.9393, beta=0.0000\n",
      "Batch 60, loss=0.0286, recon=0.0286, kl=42.5123, beta=0.0000\n",
      "Batch 80, loss=0.0321, recon=0.0321, kl=42.0239, beta=0.0000\n",
      "Batch 100, loss=0.0420, recon=0.0420, kl=41.9262, beta=0.0000\n",
      "Batch 120, loss=0.0416, recon=0.0416, kl=43.9744, beta=0.0000\n",
      "Batch 140, loss=0.0432, recon=0.0432, kl=43.2563, beta=0.0000\n",
      "Batch 160, loss=0.0280, recon=0.0280, kl=44.3958, beta=0.0000\n",
      "Batch 180, loss=0.0365, recon=0.0365, kl=45.2165, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0438, KL: 42.7523, Current Beta: 0.0000) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0439, recon=0.0439, kl=46.1910, beta=0.0000\n",
      "Batch 40, loss=0.0410, recon=0.0410, kl=44.6021, beta=0.0000\n",
      "Batch 60, loss=0.0279, recon=0.0278, kl=44.0580, beta=0.0000\n",
      "Batch 80, loss=0.0530, recon=0.0530, kl=43.6209, beta=0.0000\n",
      "Batch 100, loss=0.0362, recon=0.0362, kl=43.9413, beta=0.0000\n",
      "Batch 120, loss=0.0353, recon=0.0353, kl=43.1577, beta=0.0000\n",
      "Batch 140, loss=0.0333, recon=0.0333, kl=42.9231, beta=0.0000\n",
      "Batch 160, loss=0.0350, recon=0.0349, kl=43.3775, beta=0.0000\n",
      "Batch 180, loss=0.0327, recon=0.0326, kl=44.5490, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 44.0415, Current Beta: 0.0000) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0389, recon=0.0388, kl=45.7328, beta=0.0000\n",
      "Batch 40, loss=0.0547, recon=0.0546, kl=46.3114, beta=0.0000\n",
      "Batch 60, loss=0.0755, recon=0.0755, kl=44.1780, beta=0.0000\n",
      "Batch 80, loss=0.0512, recon=0.0512, kl=44.4206, beta=0.0000\n",
      "Batch 100, loss=0.0380, recon=0.0379, kl=44.2699, beta=0.0000\n",
      "Batch 120, loss=0.0300, recon=0.0300, kl=44.9621, beta=0.0000\n",
      "Batch 140, loss=0.0743, recon=0.0742, kl=47.6025, beta=0.0000\n",
      "Batch 160, loss=0.0332, recon=0.0332, kl=45.4384, beta=0.0000\n",
      "Batch 180, loss=0.0466, recon=0.0465, kl=46.3937, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0581, KL: 45.4629, Current Beta: 0.0000) | Avg Valid Loss: 0.0904 | Avg Valid recon Loss: 0.0903\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0297, recon=0.0296, kl=46.3879, beta=0.0000\n",
      "Batch 40, loss=0.0536, recon=0.0534, kl=46.2185, beta=0.0000\n",
      "Batch 60, loss=0.0589, recon=0.0587, kl=52.7804, beta=0.0000\n",
      "Batch 80, loss=0.1299, recon=0.1297, kl=50.0979, beta=0.0000\n",
      "Batch 100, loss=0.0789, recon=0.0787, kl=50.1749, beta=0.0000\n",
      "Batch 120, loss=0.0377, recon=0.0375, kl=49.1363, beta=0.0000\n",
      "Batch 140, loss=0.0346, recon=0.0344, kl=48.8094, beta=0.0000\n",
      "Batch 160, loss=0.2064, recon=0.2062, kl=48.2196, beta=0.0000\n",
      "Batch 180, loss=0.0463, recon=0.0461, kl=48.4997, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0715 (Recon: 0.0713, KL: 49.2727, Current Beta: 0.0000) | Avg Valid Loss: 0.0514 | Avg Valid recon Loss: 0.0512\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0656, recon=0.0651, kl=48.3680, beta=0.0000\n",
      "Batch 40, loss=0.0447, recon=0.0442, kl=46.6534, beta=0.0000\n",
      "Batch 60, loss=0.0369, recon=0.0364, kl=46.1173, beta=0.0000\n",
      "Batch 80, loss=0.0687, recon=0.0682, kl=44.3148, beta=0.0000\n",
      "Batch 100, loss=0.0608, recon=0.0604, kl=43.0657, beta=0.0000\n",
      "Batch 120, loss=0.0465, recon=0.0460, kl=43.3626, beta=0.0000\n",
      "Batch 140, loss=0.1066, recon=0.1062, kl=43.9340, beta=0.0000\n",
      "Batch 160, loss=0.0470, recon=0.0466, kl=39.1777, beta=0.0000\n",
      "Batch 180, loss=0.0362, recon=0.0358, kl=38.1645, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0575 (Recon: 0.0570, KL: 44.3283, Current Beta: 0.0000) | Avg Valid Loss: 0.0531 | Avg Valid recon Loss: 0.0527\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0463, recon=0.0452, kl=36.4871, beta=0.0000\n",
      "Batch 40, loss=0.0556, recon=0.0546, kl=34.9481, beta=0.0000\n",
      "Batch 60, loss=0.0575, recon=0.0565, kl=36.8858, beta=0.0000\n",
      "Batch 80, loss=0.0734, recon=0.0724, kl=35.5289, beta=0.0000\n",
      "Batch 100, loss=0.0582, recon=0.0571, kl=37.5311, beta=0.0000\n",
      "Batch 120, loss=1.6444, recon=1.6432, kl=40.4111, beta=0.0000\n",
      "Batch 140, loss=1.6475, recon=1.6460, kl=49.8215, beta=0.0000\n",
      "Batch 160, loss=6.9078, recon=6.9061, kl=58.5103, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 12/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 13/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0002) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 14/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0004) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0006) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 51/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4045, recon=0.4045, kl=0.5758, beta=0.0000\n",
      "Batch 40, loss=0.1711, recon=0.1711, kl=21.9991, beta=0.0000\n",
      "Batch 60, loss=0.1249, recon=0.1249, kl=43.5636, beta=0.0000\n",
      "Batch 80, loss=0.1728, recon=0.1728, kl=51.9147, beta=0.0000\n",
      "Batch 100, loss=0.1559, recon=0.1559, kl=56.9604, beta=0.0000\n",
      "Batch 120, loss=0.1149, recon=0.1149, kl=53.9026, beta=0.0000\n",
      "Batch 140, loss=0.2331, recon=0.2331, kl=51.0285, beta=0.0000\n",
      "Batch 160, loss=0.0745, recon=0.0745, kl=56.9317, beta=0.0000\n",
      "Batch 180, loss=0.1055, recon=0.1055, kl=61.5377, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2263 (Recon: 0.2263, KL: 40.9802, Current Beta: 0.0000) | Avg Valid Loss: 0.0942 | Avg Valid recon Loss: 0.0942\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0699, recon=0.0699, kl=65.9682, beta=0.0000\n",
      "Batch 40, loss=1.8586, recon=1.8586, kl=69.7267, beta=0.0000\n",
      "Batch 60, loss=0.1019, recon=0.1019, kl=73.2764, beta=0.0000\n",
      "Batch 80, loss=0.0719, recon=0.0719, kl=70.6482, beta=0.0000\n",
      "Batch 100, loss=0.0814, recon=0.0814, kl=77.4996, beta=0.0000\n",
      "Batch 120, loss=0.0807, recon=0.0807, kl=78.6540, beta=0.0000\n",
      "Batch 140, loss=0.1768, recon=0.1768, kl=74.7229, beta=0.0000\n",
      "Batch 160, loss=0.0673, recon=0.0673, kl=74.7767, beta=0.0000\n",
      "Batch 180, loss=0.0972, recon=0.0972, kl=83.8891, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1084 (Recon: 0.1084, KL: 72.8541, Current Beta: 0.0000) | Avg Valid Loss: 0.0729 | Avg Valid recon Loss: 0.0729\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0645, recon=0.0645, kl=82.8954, beta=0.0000\n",
      "Batch 40, loss=0.0814, recon=0.0814, kl=85.4358, beta=0.0000\n",
      "Batch 60, loss=0.0656, recon=0.0656, kl=82.9927, beta=0.0000\n",
      "Batch 80, loss=0.0848, recon=0.0848, kl=78.7980, beta=0.0000\n",
      "Batch 100, loss=0.0543, recon=0.0543, kl=82.9057, beta=0.0000\n",
      "Batch 120, loss=0.0543, recon=0.0543, kl=83.7611, beta=0.0000\n",
      "Batch 140, loss=0.0552, recon=0.0552, kl=84.7887, beta=0.0000\n",
      "Batch 160, loss=0.0540, recon=0.0540, kl=80.3720, beta=0.0000\n",
      "Batch 180, loss=0.0628, recon=0.0628, kl=81.2885, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0835 (Recon: 0.0835, KL: 82.5752, Current Beta: 0.0000) | Avg Valid Loss: 0.0611 | Avg Valid recon Loss: 0.0611\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0670, recon=0.0670, kl=82.6401, beta=0.0000\n",
      "Batch 40, loss=0.0487, recon=0.0487, kl=82.1935, beta=0.0000\n",
      "Batch 60, loss=0.0628, recon=0.0628, kl=82.4682, beta=0.0000\n",
      "Batch 80, loss=0.0705, recon=0.0705, kl=79.0023, beta=0.0000\n",
      "Batch 100, loss=0.0422, recon=0.0422, kl=80.4593, beta=0.0000\n",
      "Batch 120, loss=0.0445, recon=0.0445, kl=82.4026, beta=0.0000\n",
      "Batch 140, loss=0.0376, recon=0.0376, kl=80.6103, beta=0.0000\n",
      "Batch 160, loss=0.0636, recon=0.0636, kl=76.6549, beta=0.0000\n",
      "Batch 180, loss=0.1077, recon=0.1077, kl=77.6758, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0698 (Recon: 0.0698, KL: 80.7560, Current Beta: 0.0000) | Avg Valid Loss: 0.0561 | Avg Valid recon Loss: 0.0561\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0589, recon=0.0589, kl=78.4547, beta=0.0000\n",
      "Batch 40, loss=0.0547, recon=0.0547, kl=76.0025, beta=0.0000\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=73.1861, beta=0.0000\n",
      "Batch 80, loss=0.0556, recon=0.0556, kl=71.8131, beta=0.0000\n",
      "Batch 100, loss=0.0348, recon=0.0347, kl=69.9593, beta=0.0000\n",
      "Batch 120, loss=0.0493, recon=0.0493, kl=67.8383, beta=0.0000\n",
      "Batch 140, loss=0.0351, recon=0.0351, kl=68.0495, beta=0.0000\n",
      "Batch 160, loss=0.0397, recon=0.0397, kl=65.5898, beta=0.0000\n",
      "Batch 180, loss=0.0450, recon=0.0450, kl=66.9544, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0618 (Recon: 0.0617, KL: 71.4132, Current Beta: 0.0000) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0332, recon=0.0332, kl=60.8718, beta=0.0000\n",
      "Batch 40, loss=0.0367, recon=0.0367, kl=54.9424, beta=0.0000\n",
      "Batch 60, loss=0.0529, recon=0.0529, kl=53.1554, beta=0.0000\n",
      "Batch 80, loss=0.0483, recon=0.0483, kl=50.4457, beta=0.0000\n",
      "Batch 100, loss=0.0326, recon=0.0326, kl=48.9986, beta=0.0000\n",
      "Batch 120, loss=0.0349, recon=0.0349, kl=47.5366, beta=0.0000\n",
      "Batch 140, loss=0.0354, recon=0.0354, kl=51.5555, beta=0.0000\n",
      "Batch 160, loss=0.0614, recon=0.0614, kl=48.3414, beta=0.0000\n",
      "Batch 180, loss=0.0453, recon=0.0453, kl=46.8912, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0570 (Recon: 0.0570, KL: 52.4075, Current Beta: 0.0000) | Avg Valid Loss: 0.0468 | Avg Valid recon Loss: 0.0468\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0318, recon=0.0317, kl=40.6636, beta=0.0000\n",
      "Batch 40, loss=0.0375, recon=0.0374, kl=34.0151, beta=0.0000\n",
      "Batch 60, loss=0.0994, recon=0.0994, kl=33.6321, beta=0.0000\n",
      "Batch 80, loss=0.0298, recon=0.0298, kl=34.2047, beta=0.0000\n",
      "Batch 100, loss=0.0464, recon=0.0464, kl=33.5661, beta=0.0000\n",
      "Batch 120, loss=0.0372, recon=0.0372, kl=33.3195, beta=0.0000\n",
      "Batch 140, loss=0.0538, recon=0.0538, kl=32.9096, beta=0.0000\n",
      "Batch 160, loss=0.0701, recon=0.0701, kl=30.0965, beta=0.0000\n",
      "Batch 180, loss=0.0332, recon=0.0332, kl=29.1993, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0526 (Recon: 0.0526, KL: 34.5232, Current Beta: 0.0000) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0329, recon=0.0329, kl=24.1095, beta=0.0000\n",
      "Batch 40, loss=0.0339, recon=0.0338, kl=16.7725, beta=0.0000\n",
      "Batch 60, loss=0.0655, recon=0.0655, kl=18.2743, beta=0.0000\n",
      "Batch 80, loss=0.0313, recon=0.0313, kl=19.4323, beta=0.0000\n",
      "Batch 100, loss=0.0266, recon=0.0266, kl=17.2790, beta=0.0000\n",
      "Batch 120, loss=0.0344, recon=0.0344, kl=16.2475, beta=0.0000\n",
      "Batch 140, loss=0.0292, recon=0.0292, kl=16.2464, beta=0.0000\n",
      "Batch 160, loss=0.0384, recon=0.0384, kl=15.9394, beta=0.0000\n",
      "Batch 180, loss=0.0378, recon=0.0378, kl=15.0279, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0494, KL: 18.3851, Current Beta: 0.0000) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0341, recon=0.0341, kl=8.7436, beta=0.0000\n",
      "Batch 40, loss=0.0567, recon=0.0567, kl=7.8308, beta=0.0000\n",
      "Batch 60, loss=0.0485, recon=0.0485, kl=7.4662, beta=0.0000\n",
      "Batch 80, loss=0.0243, recon=0.0243, kl=7.4243, beta=0.0000\n",
      "Batch 100, loss=0.0235, recon=0.0235, kl=6.1985, beta=0.0000\n",
      "Batch 120, loss=0.0344, recon=0.0344, kl=5.6098, beta=0.0000\n",
      "Batch 140, loss=0.0441, recon=0.0440, kl=6.1973, beta=0.0000\n",
      "Batch 160, loss=0.0554, recon=0.0554, kl=5.9578, beta=0.0000\n",
      "Batch 180, loss=0.0347, recon=0.0346, kl=5.5897, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 7.1269, Current Beta: 0.0000) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0394\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0359, recon=0.0358, kl=2.7302, beta=0.0000\n",
      "Batch 40, loss=0.0346, recon=0.0346, kl=3.7292, beta=0.0000\n",
      "Batch 60, loss=0.0327, recon=0.0327, kl=2.5898, beta=0.0000\n",
      "Batch 80, loss=0.0274, recon=0.0274, kl=2.6592, beta=0.0000\n",
      "Batch 100, loss=0.0459, recon=0.0459, kl=2.3778, beta=0.0000\n",
      "Batch 120, loss=0.0392, recon=0.0392, kl=2.9519, beta=0.0000\n",
      "Batch 140, loss=0.0345, recon=0.0344, kl=2.7120, beta=0.0000\n",
      "Batch 160, loss=0.0363, recon=0.0363, kl=2.6865, beta=0.0000\n",
      "Batch 180, loss=0.0333, recon=0.0333, kl=1.8770, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0450, KL: 2.9501, Current Beta: 0.0000) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0529, recon=0.0529, kl=0.9832, beta=0.0000\n",
      "Batch 40, loss=0.0559, recon=0.0559, kl=0.9294, beta=0.0000\n",
      "Batch 60, loss=0.0424, recon=0.0424, kl=0.8424, beta=0.0000\n",
      "Batch 80, loss=0.0279, recon=0.0278, kl=0.9495, beta=0.0000\n",
      "Batch 100, loss=0.0264, recon=0.0263, kl=0.7360, beta=0.0000\n",
      "Batch 120, loss=0.0271, recon=0.0270, kl=0.6261, beta=0.0000\n",
      "Batch 140, loss=0.0273, recon=0.0273, kl=0.6915, beta=0.0000\n",
      "Batch 160, loss=0.0282, recon=0.0282, kl=0.5919, beta=0.0000\n",
      "Batch 180, loss=0.0270, recon=0.0270, kl=0.6611, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 0.8374, Current Beta: 0.0000) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1586, recon=0.1585, kl=0.2302, beta=0.0001\n",
      "Batch 40, loss=0.0263, recon=0.0263, kl=0.1605, beta=0.0001\n",
      "Batch 60, loss=0.0268, recon=0.0268, kl=0.1515, beta=0.0001\n",
      "Batch 80, loss=0.0284, recon=0.0284, kl=0.1101, beta=0.0001\n",
      "Batch 100, loss=0.0303, recon=0.0303, kl=0.1291, beta=0.0001\n",
      "Batch 120, loss=0.0836, recon=0.0836, kl=0.0807, beta=0.0001\n",
      "Batch 140, loss=0.0478, recon=0.0478, kl=0.1410, beta=0.0001\n",
      "Batch 160, loss=0.0332, recon=0.0332, kl=0.1340, beta=0.0001\n",
      "Batch 180, loss=0.0290, recon=0.0290, kl=0.0480, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 0.1757, Current Beta: 0.0001) | Avg Valid Loss: 0.0356 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0284, recon=0.0284, kl=0.0114, beta=0.0002\n",
      "Batch 40, loss=0.0374, recon=0.0374, kl=0.0159, beta=0.0002\n",
      "Batch 60, loss=0.0249, recon=0.0249, kl=0.0612, beta=0.0002\n",
      "Batch 80, loss=0.0413, recon=0.0413, kl=0.0137, beta=0.0002\n",
      "Batch 100, loss=0.0280, recon=0.0279, kl=0.0112, beta=0.0002\n",
      "Batch 120, loss=0.0362, recon=0.0362, kl=0.0117, beta=0.0002\n",
      "Batch 140, loss=0.0300, recon=0.0300, kl=0.0106, beta=0.0002\n",
      "Batch 160, loss=0.0301, recon=0.0301, kl=0.0090, beta=0.0002\n",
      "Batch 180, loss=0.0619, recon=0.0619, kl=0.0285, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0408 (Recon: 0.0408, KL: 0.0131, Current Beta: 0.0002) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0346\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0537, recon=0.0537, kl=0.0068, beta=0.0004\n",
      "Batch 40, loss=0.0273, recon=0.0273, kl=0.0019, beta=0.0004\n",
      "Batch 60, loss=0.0605, recon=0.0605, kl=0.0042, beta=0.0004\n",
      "Batch 80, loss=0.0398, recon=0.0398, kl=0.0019, beta=0.0004\n",
      "Batch 100, loss=0.0301, recon=0.0301, kl=0.0011, beta=0.0004\n",
      "Batch 120, loss=0.1456, recon=0.1456, kl=0.0044, beta=0.0004\n",
      "Batch 140, loss=0.0218, recon=0.0218, kl=0.0048, beta=0.0004\n",
      "Batch 160, loss=0.0239, recon=0.0239, kl=0.0016, beta=0.0004\n",
      "Batch 180, loss=0.0262, recon=0.0262, kl=0.0014, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0395, KL: 0.0039, Current Beta: 0.0004) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0237, recon=0.0237, kl=0.0022, beta=0.0006\n",
      "Batch 40, loss=0.0251, recon=0.0251, kl=0.0007, beta=0.0006\n",
      "Batch 60, loss=0.0263, recon=0.0263, kl=0.0026, beta=0.0006\n",
      "Batch 80, loss=0.0297, recon=0.0297, kl=0.0014, beta=0.0006\n",
      "Batch 100, loss=0.0251, recon=0.0251, kl=0.0017, beta=0.0006\n",
      "Batch 120, loss=0.0203, recon=0.0203, kl=0.0008, beta=0.0006\n",
      "Batch 140, loss=0.0251, recon=0.0251, kl=0.0033, beta=0.0006\n",
      "Batch 160, loss=0.0355, recon=0.0355, kl=0.0016, beta=0.0006\n",
      "Batch 180, loss=0.0235, recon=0.0235, kl=0.0008, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0390, KL: 0.0018, Current Beta: 0.0006) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0671, recon=0.0671, kl=0.0008, beta=0.0010\n",
      "Batch 40, loss=0.0195, recon=0.0195, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0264, recon=0.0264, kl=0.0006, beta=0.0010\n",
      "Batch 80, loss=0.0334, recon=0.0334, kl=0.0009, beta=0.0010\n",
      "Batch 100, loss=0.0292, recon=0.0292, kl=0.0013, beta=0.0010\n",
      "Batch 120, loss=0.0426, recon=0.0426, kl=0.0008, beta=0.0010\n",
      "Batch 140, loss=0.0266, recon=0.0266, kl=0.0009, beta=0.0010\n",
      "Batch 160, loss=0.0276, recon=0.0276, kl=0.0009, beta=0.0010\n",
      "Batch 180, loss=0.1221, recon=0.1221, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0380 (Recon: 0.0380, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0324 | Avg Valid recon Loss: 0.0324\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0255, recon=0.0255, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0482, recon=0.0482, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0371, recon=0.0370, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.1315, recon=0.1315, kl=0.0010, beta=0.0010\n",
      "Batch 100, loss=0.0316, recon=0.0316, kl=0.0009, beta=0.0010\n",
      "Batch 120, loss=0.0924, recon=0.0924, kl=0.0039, beta=0.0010\n",
      "Batch 140, loss=0.0248, recon=0.0248, kl=0.0011, beta=0.0010\n",
      "Batch 160, loss=0.0206, recon=0.0206, kl=0.0006, beta=0.0010\n",
      "Batch 180, loss=0.0268, recon=0.0268, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0373 (Recon: 0.0373, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0222, recon=0.0222, kl=0.0010, beta=0.0010\n",
      "Batch 40, loss=0.0467, recon=0.0467, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0229, recon=0.0229, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0328, recon=0.0328, kl=0.0006, beta=0.0010\n",
      "Batch 100, loss=0.0242, recon=0.0242, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0393, recon=0.0393, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0297, recon=0.0297, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0254, recon=0.0254, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0237, recon=0.0237, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0364 (Recon: 0.0364, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0312 | Avg Valid recon Loss: 0.0312\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0238, recon=0.0238, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0287, recon=0.0287, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0251, recon=0.0251, kl=0.0006, beta=0.0010\n",
      "Batch 80, loss=0.0234, recon=0.0234, kl=0.0001, beta=0.0010\n",
      "Batch 100, loss=0.0425, recon=0.0425, kl=0.0004, beta=0.0010\n",
      "Batch 120, loss=0.0224, recon=0.0224, kl=0.0006, beta=0.0010\n",
      "Batch 140, loss=0.0267, recon=0.0267, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0358, recon=0.0358, kl=0.0029, beta=0.0010\n",
      "Batch 180, loss=0.0504, recon=0.0504, kl=0.0009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0357 (Recon: 0.0357, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0310 | Avg Valid recon Loss: 0.0310\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0301, recon=0.0301, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0199, recon=0.0199, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0352, recon=0.0352, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0250, recon=0.0250, kl=0.0001, beta=0.0010\n",
      "Batch 100, loss=0.0470, recon=0.0470, kl=0.0016, beta=0.0010\n",
      "Batch 120, loss=0.0316, recon=0.0316, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0185, recon=0.0185, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0333, recon=0.0333, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0268, recon=0.0268, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0352 (Recon: 0.0352, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0300 | Avg Valid recon Loss: 0.0300\n",
      "\n",
      "[VRAE Run 52/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1173, recon=0.1173, kl=30.1959, beta=0.0000\n",
      "Batch 40, loss=0.1711, recon=0.1711, kl=48.3197, beta=0.0000\n",
      "Batch 60, loss=0.0898, recon=0.0898, kl=59.4051, beta=0.0000\n",
      "Batch 80, loss=0.0635, recon=0.0635, kl=47.2232, beta=0.0000\n",
      "Batch 100, loss=0.0597, recon=0.0597, kl=48.9974, beta=0.0000\n",
      "Batch 120, loss=0.0625, recon=0.0625, kl=57.2918, beta=0.0000\n",
      "Batch 140, loss=0.0437, recon=0.0437, kl=62.0433, beta=0.0000\n",
      "Batch 160, loss=0.0809, recon=0.0809, kl=62.0300, beta=0.0000\n",
      "Batch 180, loss=0.1076, recon=0.1076, kl=62.4972, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1154 (Recon: 0.1154, KL: 50.2341, Current Beta: 0.0000) | Avg Valid Loss: 0.0548 | Avg Valid recon Loss: 0.0548\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0603, recon=0.0603, kl=60.2446, beta=0.0000\n",
      "Batch 40, loss=0.0374, recon=0.0374, kl=62.6537, beta=0.0000\n",
      "Batch 60, loss=0.0425, recon=0.0425, kl=60.5456, beta=0.0000\n",
      "Batch 80, loss=0.1908, recon=0.1908, kl=58.8440, beta=0.0000\n",
      "Batch 100, loss=0.0356, recon=0.0356, kl=57.3012, beta=0.0000\n",
      "Batch 120, loss=0.0637, recon=0.0637, kl=51.5078, beta=0.0000\n",
      "Batch 140, loss=0.0726, recon=0.0726, kl=42.1373, beta=0.0000\n",
      "Batch 160, loss=0.0419, recon=0.0419, kl=49.0309, beta=0.0000\n",
      "Batch 180, loss=0.0509, recon=0.0509, kl=52.9669, beta=0.0000\n",
      "  â†’ Avg Train Loss: 21.9988 (Recon: 21.9988, KL: 167.1536, Current Beta: 0.0000) | Avg Valid Loss: 0.0596 | Avg Valid recon Loss: 0.0596\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0387, recon=0.0387, kl=53.1562, beta=0.0000\n",
      "Batch 40, loss=0.0300, recon=0.0300, kl=52.8909, beta=0.0000\n",
      "Batch 60, loss=0.0462, recon=0.0462, kl=52.0838, beta=0.0000\n",
      "Batch 80, loss=0.0427, recon=0.0427, kl=55.0389, beta=0.0000\n",
      "Batch 100, loss=0.0410, recon=0.0410, kl=56.0261, beta=0.0000\n",
      "Batch 120, loss=0.1059, recon=0.1059, kl=58.2939, beta=0.0000\n",
      "Batch 140, loss=0.0353, recon=0.0353, kl=59.0360, beta=0.0000\n",
      "Batch 160, loss=0.0249, recon=0.0249, kl=58.6744, beta=0.0000\n",
      "Batch 180, loss=0.0739, recon=0.0739, kl=58.4030, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0585 (Recon: 0.0585, KL: 58.8092, Current Beta: 0.0000) | Avg Valid Loss: 0.0511 | Avg Valid recon Loss: 0.0511\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0330, recon=0.0330, kl=59.0543, beta=0.0000\n",
      "Batch 40, loss=0.0330, recon=0.0330, kl=61.7292, beta=0.0000\n",
      "Batch 60, loss=0.0350, recon=0.0350, kl=60.8419, beta=0.0000\n",
      "Batch 80, loss=0.0476, recon=0.0476, kl=61.4940, beta=0.0000\n",
      "Batch 100, loss=0.0368, recon=0.0368, kl=62.6362, beta=0.0000\n",
      "Batch 120, loss=0.0405, recon=0.0405, kl=63.1769, beta=0.0000\n",
      "Batch 140, loss=0.0369, recon=0.0369, kl=63.6955, beta=0.0000\n",
      "Batch 160, loss=0.0408, recon=0.0408, kl=61.4800, beta=0.0000\n",
      "Batch 180, loss=0.0506, recon=0.0506, kl=63.6442, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0505 (Recon: 0.0505, KL: 60.9984, Current Beta: 0.0000) | Avg Valid Loss: 0.0513 | Avg Valid recon Loss: 0.0513\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0387, recon=0.0387, kl=62.7132, beta=0.0000\n",
      "Batch 40, loss=0.0297, recon=0.0297, kl=63.6294, beta=0.0000\n",
      "Batch 60, loss=0.0355, recon=0.0355, kl=63.3329, beta=0.0000\n",
      "Batch 80, loss=0.0336, recon=0.0336, kl=63.9938, beta=0.0000\n",
      "Batch 100, loss=0.0377, recon=0.0377, kl=63.7874, beta=0.0000\n",
      "Batch 120, loss=0.0279, recon=0.0279, kl=65.2185, beta=0.0000\n",
      "Batch 140, loss=0.0361, recon=0.0361, kl=67.0612, beta=0.0000\n",
      "Batch 160, loss=0.0308, recon=0.0308, kl=64.8448, beta=0.0000\n",
      "Batch 180, loss=0.0281, recon=0.0281, kl=64.5416, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0507 (Recon: 0.0507, KL: 64.4528, Current Beta: 0.0000) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0562, recon=0.0562, kl=65.5889, beta=0.0000\n",
      "Batch 40, loss=0.0667, recon=0.0666, kl=66.7004, beta=0.0000\n",
      "Batch 60, loss=0.1740, recon=0.1740, kl=66.3646, beta=0.0000\n",
      "Batch 80, loss=0.0304, recon=0.0304, kl=66.5980, beta=0.0000\n",
      "Batch 100, loss=0.0380, recon=0.0380, kl=68.0285, beta=0.0000\n",
      "Batch 120, loss=0.0305, recon=0.0305, kl=68.8696, beta=0.0000\n",
      "Batch 140, loss=0.0298, recon=0.0298, kl=68.0350, beta=0.0000\n",
      "Batch 160, loss=0.0547, recon=0.0547, kl=70.5292, beta=0.0000\n",
      "Batch 180, loss=0.0318, recon=0.0318, kl=68.9248, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 67.7803, Current Beta: 0.0000) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0240, recon=0.0240, kl=69.7933, beta=0.0000\n",
      "Batch 40, loss=0.0288, recon=0.0288, kl=68.0587, beta=0.0000\n",
      "Batch 60, loss=0.0353, recon=0.0352, kl=70.5097, beta=0.0000\n",
      "Batch 80, loss=0.0295, recon=0.0295, kl=69.8417, beta=0.0000\n",
      "Batch 100, loss=0.0358, recon=0.0357, kl=69.5743, beta=0.0000\n",
      "Batch 120, loss=0.0567, recon=0.0566, kl=70.3630, beta=0.0000\n",
      "Batch 140, loss=0.0370, recon=0.0370, kl=69.5041, beta=0.0000\n",
      "Batch 160, loss=0.0495, recon=0.0494, kl=70.3214, beta=0.0000\n",
      "Batch 180, loss=0.0398, recon=0.0398, kl=70.5800, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0456, KL: 69.6309, Current Beta: 0.0000) | Avg Valid Loss: 0.0414 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0341, recon=0.0340, kl=69.6988, beta=0.0000\n",
      "Batch 40, loss=0.0245, recon=0.0244, kl=69.2426, beta=0.0000\n",
      "Batch 60, loss=0.0293, recon=0.0292, kl=69.7042, beta=0.0000\n",
      "Batch 80, loss=0.0242, recon=0.0240, kl=68.4337, beta=0.0000\n",
      "Batch 100, loss=0.0186, recon=0.0185, kl=67.6959, beta=0.0000\n",
      "Batch 120, loss=0.0257, recon=0.0256, kl=68.0261, beta=0.0000\n",
      "Batch 140, loss=0.1144, recon=0.1143, kl=67.2444, beta=0.0000\n",
      "Batch 160, loss=0.0836, recon=0.0836, kl=65.5443, beta=0.0000\n",
      "Batch 180, loss=0.0558, recon=0.0557, kl=66.7867, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0428, KL: 68.1117, Current Beta: 0.0000) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0416\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0276, recon=0.0273, kl=68.2492, beta=0.0000\n",
      "Batch 40, loss=0.0201, recon=0.0199, kl=64.3712, beta=0.0000\n",
      "Batch 60, loss=0.0238, recon=0.0236, kl=63.7327, beta=0.0000\n",
      "Batch 80, loss=0.0254, recon=0.0252, kl=61.3723, beta=0.0000\n",
      "Batch 100, loss=0.0275, recon=0.0273, kl=60.6371, beta=0.0000\n",
      "Batch 120, loss=0.0327, recon=0.0325, kl=59.7002, beta=0.0000\n",
      "Batch 140, loss=0.0297, recon=0.0295, kl=58.1625, beta=0.0000\n",
      "Batch 160, loss=0.0530, recon=0.0528, kl=56.7012, beta=0.0000\n",
      "Batch 180, loss=0.0442, recon=0.0440, kl=55.7549, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0394 (Recon: 0.0392, KL: 61.5213, Current Beta: 0.0000) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0446, recon=0.0440, kl=55.4402, beta=0.0000\n",
      "Batch 40, loss=0.0255, recon=0.0250, kl=50.1381, beta=0.0000\n",
      "Batch 60, loss=0.0312, recon=0.0307, kl=49.6014, beta=0.0000\n",
      "Batch 80, loss=0.0280, recon=0.0274, kl=47.0568, beta=0.0000\n",
      "Batch 100, loss=0.0284, recon=0.0279, kl=45.4674, beta=0.0000\n",
      "Batch 120, loss=0.0383, recon=0.0378, kl=43.8178, beta=0.0000\n",
      "Batch 140, loss=0.0383, recon=0.0378, kl=42.9806, beta=0.0000\n",
      "Batch 160, loss=0.0245, recon=0.0240, kl=41.5888, beta=0.0000\n",
      "Batch 180, loss=0.0211, recon=0.0206, kl=41.0900, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0402 (Recon: 0.0397, KL: 46.9917, Current Beta: 0.0000) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0255, recon=0.0244, kl=36.6936, beta=0.0000\n",
      "Batch 40, loss=0.0417, recon=0.0407, kl=32.7295, beta=0.0000\n",
      "Batch 60, loss=0.0429, recon=0.0421, kl=29.8340, beta=0.0000\n",
      "Batch 80, loss=0.0405, recon=0.0396, kl=28.3201, beta=0.0000\n",
      "Batch 100, loss=0.0287, recon=0.0279, kl=26.4630, beta=0.0000\n",
      "Batch 120, loss=0.0220, recon=0.0212, kl=25.2223, beta=0.0000\n",
      "Batch 140, loss=0.0450, recon=0.0442, kl=26.2681, beta=0.0000\n",
      "Batch 160, loss=0.0265, recon=0.0258, kl=23.7978, beta=0.0000\n",
      "Batch 180, loss=0.0300, recon=0.0293, kl=23.8740, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0379 (Recon: 0.0370, KL: 29.3559, Current Beta: 0.0000) | Avg Valid Loss: 0.0326 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0266, recon=0.0253, kl=17.8478, beta=0.0001\n",
      "Batch 40, loss=0.0230, recon=0.0219, kl=14.1642, beta=0.0001\n",
      "Batch 60, loss=0.1230, recon=0.1219, kl=14.2014, beta=0.0001\n",
      "Batch 80, loss=0.0298, recon=0.0289, kl=11.7091, beta=0.0001\n",
      "Batch 100, loss=0.0625, recon=0.0619, kl=8.7020, beta=0.0001\n",
      "Batch 120, loss=0.0289, recon=0.0279, kl=12.7059, beta=0.0001\n",
      "Batch 140, loss=0.0376, recon=0.0369, kl=8.7318, beta=0.0001\n",
      "Batch 160, loss=0.0257, recon=0.0248, kl=12.0788, beta=0.0001\n",
      "Batch 180, loss=0.0249, recon=0.0243, kl=7.8212, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0381 (Recon: 0.0371, KL: 12.7233, Current Beta: 0.0001) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0326\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0264, recon=0.0254, kl=5.8358, beta=0.0002\n",
      "Batch 40, loss=0.0504, recon=0.0496, kl=4.4621, beta=0.0002\n",
      "Batch 60, loss=0.0336, recon=0.0329, kl=4.0128, beta=0.0002\n",
      "Batch 80, loss=0.0305, recon=0.0298, kl=3.3700, beta=0.0002\n",
      "Batch 100, loss=0.0252, recon=0.0243, kl=4.6460, beta=0.0002\n",
      "Batch 120, loss=0.0269, recon=0.0262, kl=4.0541, beta=0.0002\n",
      "Batch 140, loss=0.0417, recon=0.0412, kl=2.7529, beta=0.0002\n",
      "Batch 160, loss=0.0550, recon=0.0525, kl=13.7618, beta=0.0002\n",
      "Batch 180, loss=0.0345, recon=0.0336, kl=5.0816, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0424, KL: 5.4247, Current Beta: 0.0002) | Avg Valid Loss: 0.0406 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0527, recon=0.0511, kl=4.1853, beta=0.0004\n",
      "Batch 40, loss=0.0248, recon=0.0241, kl=2.0093, beta=0.0004\n",
      "Batch 60, loss=0.0340, recon=0.0333, kl=1.9033, beta=0.0004\n",
      "Batch 80, loss=0.0255, recon=0.0250, kl=1.4261, beta=0.0004\n",
      "Batch 100, loss=0.0399, recon=0.0391, kl=1.9331, beta=0.0004\n",
      "Batch 120, loss=0.0381, recon=0.0375, kl=1.6699, beta=0.0004\n",
      "Batch 140, loss=0.0597, recon=0.0591, kl=1.6327, beta=0.0004\n",
      "Batch 160, loss=0.0272, recon=0.0266, kl=1.5625, beta=0.0004\n",
      "Batch 180, loss=0.0281, recon=0.0274, kl=1.8290, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0423, KL: 2.2911, Current Beta: 0.0004) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0461, recon=0.0455, kl=0.9586, beta=0.0006\n",
      "Batch 40, loss=0.0350, recon=0.0343, kl=1.1680, beta=0.0006\n",
      "Batch 60, loss=0.0273, recon=0.0268, kl=0.7990, beta=0.0006\n",
      "Batch 80, loss=0.0365, recon=0.0351, kl=2.3017, beta=0.0006\n",
      "Batch 100, loss=0.0810, recon=0.0803, kl=1.0368, beta=0.0006\n",
      "Batch 120, loss=0.0488, recon=0.0483, kl=0.8614, beta=0.0006\n",
      "Batch 140, loss=0.0348, recon=0.0343, kl=0.6970, beta=0.0006\n",
      "Batch 160, loss=0.0212, recon=0.0202, kl=1.5253, beta=0.0006\n",
      "Batch 180, loss=0.0352, recon=0.0343, kl=1.4121, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0409, KL: 1.2919, Current Beta: 0.0006) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0457\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0427, recon=0.0422, kl=0.5334, beta=0.0010\n",
      "Batch 40, loss=0.0404, recon=0.0397, kl=0.7077, beta=0.0010\n",
      "Batch 60, loss=0.0332, recon=0.0328, kl=0.4375, beta=0.0010\n",
      "Batch 80, loss=0.1009, recon=0.1003, kl=0.5664, beta=0.0010\n",
      "Batch 100, loss=0.0349, recon=0.0345, kl=0.4661, beta=0.0010\n",
      "Batch 120, loss=0.0368, recon=0.0366, kl=0.2132, beta=0.0010\n",
      "Batch 140, loss=0.0330, recon=0.0326, kl=0.3532, beta=0.0010\n",
      "Batch 160, loss=0.0734, recon=0.0731, kl=0.2978, beta=0.0010\n",
      "Batch 180, loss=0.0533, recon=0.0530, kl=0.2749, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0456, KL: 0.4645, Current Beta: 0.0010) | Avg Valid Loss: 0.0405 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0488, recon=0.0484, kl=0.3311, beta=0.0010\n",
      "Batch 40, loss=0.0276, recon=0.0274, kl=0.2028, beta=0.0010\n",
      "Batch 60, loss=0.0537, recon=0.0535, kl=0.2728, beta=0.0010\n",
      "Batch 80, loss=0.0231, recon=0.0229, kl=0.1668, beta=0.0010\n",
      "Batch 100, loss=0.0579, recon=0.0575, kl=0.3774, beta=0.0010\n",
      "Batch 120, loss=0.1617, recon=0.1612, kl=0.4600, beta=0.0010\n",
      "Batch 140, loss=0.0624, recon=0.0620, kl=0.3370, beta=0.0010\n",
      "Batch 160, loss=0.0430, recon=0.0427, kl=0.2653, beta=0.0010\n",
      "Batch 180, loss=0.1494, recon=0.1490, kl=0.3303, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0535 (Recon: 0.0532, KL: 0.2980, Current Beta: 0.0010) | Avg Valid Loss: 0.0483 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0280, recon=0.0278, kl=0.2090, beta=0.0010\n",
      "Batch 40, loss=0.0372, recon=0.0370, kl=0.1286, beta=0.0010\n",
      "Batch 60, loss=0.0715, recon=0.0713, kl=0.2156, beta=0.0010\n",
      "Batch 80, loss=0.0734, recon=0.0723, kl=1.1017, beta=0.0010\n",
      "Batch 100, loss=0.0541, recon=0.0534, kl=0.6384, beta=0.0010\n",
      "Batch 120, loss=0.0518, recon=0.0517, kl=0.1596, beta=0.0010\n",
      "Batch 140, loss=0.0368, recon=0.0366, kl=0.2187, beta=0.0010\n",
      "Batch 160, loss=0.0516, recon=0.0515, kl=0.1052, beta=0.0010\n",
      "Batch 180, loss=0.0340, recon=0.0337, kl=0.2315, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0578 (Recon: 0.0574, KL: 0.3912, Current Beta: 0.0010) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0432\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0517, recon=0.0516, kl=0.1545, beta=0.0010\n",
      "Batch 40, loss=0.0344, recon=0.0343, kl=0.1098, beta=0.0010\n",
      "Batch 60, loss=0.0427, recon=0.0426, kl=0.0594, beta=0.0010\n",
      "Batch 80, loss=0.0306, recon=0.0305, kl=0.0718, beta=0.0010\n",
      "Batch 100, loss=0.0352, recon=0.0351, kl=0.0755, beta=0.0010\n",
      "Batch 120, loss=0.0378, recon=0.0377, kl=0.0625, beta=0.0010\n",
      "Batch 140, loss=0.0345, recon=0.0345, kl=0.0407, beta=0.0010\n",
      "Batch 160, loss=0.0369, recon=0.0368, kl=0.0645, beta=0.0010\n",
      "Batch 180, loss=0.0308, recon=0.0307, kl=0.0313, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0441, KL: 0.0880, Current Beta: 0.0010) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0448\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=0.0484, beta=0.0010\n",
      "Batch 40, loss=0.0263, recon=0.0262, kl=0.0251, beta=0.0010\n",
      "Batch 60, loss=0.0587, recon=0.0586, kl=0.0685, beta=0.0010\n",
      "Batch 80, loss=0.0312, recon=0.0312, kl=0.0277, beta=0.0010\n",
      "Batch 100, loss=0.5489, recon=0.5485, kl=0.3840, beta=0.0010\n",
      "Batch 120, loss=0.0579, recon=0.0578, kl=0.0806, beta=0.0010\n",
      "Batch 140, loss=0.0739, recon=0.0737, kl=0.1218, beta=0.0010\n",
      "Batch 160, loss=0.0745, recon=0.0744, kl=0.1237, beta=0.0010\n",
      "Batch 180, loss=0.0314, recon=0.0313, kl=0.0800, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0550 (Recon: 0.0550, KL: 0.0673, Current Beta: 0.0010) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0509\n",
      "\n",
      "[VRAE Run 53/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3510, recon=0.3510, kl=0.8783, beta=0.0000\n",
      "Batch 40, loss=0.2151, recon=0.2151, kl=53.6406, beta=0.0000\n",
      "Batch 60, loss=0.1856, recon=0.1856, kl=87.2851, beta=0.0000\n",
      "Batch 80, loss=0.1341, recon=0.1341, kl=99.5655, beta=0.0000\n",
      "Batch 100, loss=0.1021, recon=0.1021, kl=106.6501, beta=0.0000\n",
      "Batch 120, loss=0.1009, recon=0.1009, kl=116.2736, beta=0.0000\n",
      "Batch 140, loss=0.1320, recon=0.1320, kl=117.9317, beta=0.0000\n",
      "Batch 160, loss=0.1255, recon=0.1255, kl=118.3054, beta=0.0000\n",
      "Batch 180, loss=0.0808, recon=0.0808, kl=124.4069, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2249 (Recon: 0.2249, KL: 84.7347, Current Beta: 0.0000) | Avg Valid Loss: 0.0975 | Avg Valid recon Loss: 0.0975\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0679, recon=0.0679, kl=123.0945, beta=0.0000\n",
      "Batch 40, loss=0.1498, recon=0.1498, kl=124.6352, beta=0.0000\n",
      "Batch 60, loss=0.0891, recon=0.0891, kl=129.9772, beta=0.0000\n",
      "Batch 80, loss=0.0827, recon=0.0827, kl=138.8470, beta=0.0000\n",
      "Batch 100, loss=0.1196, recon=0.1196, kl=140.9588, beta=0.0000\n",
      "Batch 120, loss=0.1151, recon=0.1151, kl=145.9875, beta=0.0000\n",
      "Batch 140, loss=0.0541, recon=0.0541, kl=140.1920, beta=0.0000\n",
      "Batch 160, loss=0.0774, recon=0.0774, kl=143.8288, beta=0.0000\n",
      "Batch 180, loss=0.0550, recon=0.0550, kl=150.6481, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1113 (Recon: 0.1113, KL: 136.5072, Current Beta: 0.0000) | Avg Valid Loss: 0.0724 | Avg Valid recon Loss: 0.0724\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0664, recon=0.0664, kl=150.2179, beta=0.0000\n",
      "Batch 40, loss=0.0692, recon=0.0692, kl=155.0770, beta=0.0000\n",
      "Batch 60, loss=0.0634, recon=0.0634, kl=155.1626, beta=0.0000\n",
      "Batch 80, loss=0.0954, recon=0.0954, kl=150.6696, beta=0.0000\n",
      "Batch 100, loss=0.0651, recon=0.0651, kl=147.6252, beta=0.0000\n",
      "Batch 120, loss=0.0766, recon=0.0766, kl=156.1224, beta=0.0000\n",
      "Batch 140, loss=0.0674, recon=0.0674, kl=156.6804, beta=0.0000\n",
      "Batch 160, loss=0.0713, recon=0.0713, kl=157.1630, beta=0.0000\n",
      "Batch 180, loss=0.0564, recon=0.0564, kl=159.6909, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0861 (Recon: 0.0861, KL: 154.0543, Current Beta: 0.0000) | Avg Valid Loss: 0.0633 | Avg Valid recon Loss: 0.0633\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0494, recon=0.0494, kl=155.9892, beta=0.0000\n",
      "Batch 40, loss=0.0626, recon=0.0626, kl=156.3971, beta=0.0000\n",
      "Batch 60, loss=0.0424, recon=0.0424, kl=143.3955, beta=0.0000\n",
      "Batch 80, loss=0.0605, recon=0.0605, kl=138.6116, beta=0.0000\n",
      "Batch 100, loss=0.2099, recon=0.2099, kl=144.1716, beta=0.0000\n",
      "Batch 120, loss=0.0446, recon=0.0446, kl=139.9729, beta=0.0000\n",
      "Batch 140, loss=0.0796, recon=0.0796, kl=134.6209, beta=0.0000\n",
      "Batch 160, loss=0.0409, recon=0.0409, kl=139.5638, beta=0.0000\n",
      "Batch 180, loss=0.0565, recon=0.0565, kl=136.1367, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0717 (Recon: 0.0717, KL: 144.5955, Current Beta: 0.0000) | Avg Valid Loss: 0.0565 | Avg Valid recon Loss: 0.0565\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1040, recon=0.1040, kl=132.8784, beta=0.0000\n",
      "Batch 40, loss=0.0560, recon=0.0560, kl=127.4836, beta=0.0000\n",
      "Batch 60, loss=0.0343, recon=0.0342, kl=124.4082, beta=0.0000\n",
      "Batch 80, loss=0.0424, recon=0.0424, kl=126.4333, beta=0.0000\n",
      "Batch 100, loss=0.0646, recon=0.0646, kl=119.5758, beta=0.0000\n",
      "Batch 120, loss=0.0394, recon=0.0394, kl=116.9828, beta=0.0000\n",
      "Batch 140, loss=0.0309, recon=0.0309, kl=118.7037, beta=0.0000\n",
      "Batch 160, loss=0.0704, recon=0.0704, kl=109.6232, beta=0.0000\n",
      "Batch 180, loss=0.0586, recon=0.0586, kl=106.8070, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0629 (Recon: 0.0629, KL: 121.0781, Current Beta: 0.0000) | Avg Valid Loss: 0.0501 | Avg Valid recon Loss: 0.0501\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0404, recon=0.0404, kl=104.5276, beta=0.0000\n",
      "Batch 40, loss=0.0382, recon=0.0382, kl=92.3468, beta=0.0000\n",
      "Batch 60, loss=0.0337, recon=0.0336, kl=87.9656, beta=0.0000\n",
      "Batch 80, loss=0.0508, recon=0.0508, kl=82.1601, beta=0.0000\n",
      "Batch 100, loss=0.0378, recon=0.0378, kl=80.2847, beta=0.0000\n",
      "Batch 120, loss=0.0423, recon=0.0423, kl=79.7277, beta=0.0000\n",
      "Batch 140, loss=0.1051, recon=0.1051, kl=79.7271, beta=0.0000\n",
      "Batch 160, loss=0.0554, recon=0.0554, kl=83.8873, beta=0.0000\n",
      "Batch 180, loss=0.0436, recon=0.0436, kl=80.8610, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0566 (Recon: 0.0566, KL: 87.0003, Current Beta: 0.0000) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0466\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0379, recon=0.0379, kl=71.1889, beta=0.0000\n",
      "Batch 40, loss=0.0310, recon=0.0309, kl=59.0663, beta=0.0000\n",
      "Batch 60, loss=0.1257, recon=0.1256, kl=52.7088, beta=0.0000\n",
      "Batch 80, loss=0.0361, recon=0.0360, kl=49.2892, beta=0.0000\n",
      "Batch 100, loss=0.0358, recon=0.0357, kl=53.8542, beta=0.0000\n",
      "Batch 120, loss=0.0244, recon=0.0243, kl=49.5143, beta=0.0000\n",
      "Batch 140, loss=0.0379, recon=0.0378, kl=50.5396, beta=0.0000\n",
      "Batch 160, loss=0.0596, recon=0.0596, kl=46.0273, beta=0.0000\n",
      "Batch 180, loss=0.0256, recon=0.0255, kl=44.5007, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0525 (Recon: 0.0525, KL: 54.7875, Current Beta: 0.0000) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0650, recon=0.0649, kl=37.4307, beta=0.0000\n",
      "Batch 40, loss=0.0417, recon=0.0417, kl=25.7780, beta=0.0000\n",
      "Batch 60, loss=0.0580, recon=0.0579, kl=22.8021, beta=0.0000\n",
      "Batch 80, loss=0.0562, recon=0.0562, kl=24.6737, beta=0.0000\n",
      "Batch 100, loss=0.1855, recon=0.1855, kl=25.0423, beta=0.0000\n",
      "Batch 120, loss=0.0364, recon=0.0364, kl=21.8573, beta=0.0000\n",
      "Batch 140, loss=0.0304, recon=0.0304, kl=20.7908, beta=0.0000\n",
      "Batch 160, loss=0.0272, recon=0.0272, kl=22.6513, beta=0.0000\n",
      "Batch 180, loss=0.0603, recon=0.0603, kl=24.9534, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0493 (Recon: 0.0493, KL: 26.0654, Current Beta: 0.0000) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0279, recon=0.0279, kl=11.2974, beta=0.0000\n",
      "Batch 40, loss=0.0337, recon=0.0337, kl=10.5760, beta=0.0000\n",
      "Batch 60, loss=0.0329, recon=0.0329, kl=9.8918, beta=0.0000\n",
      "Batch 80, loss=0.0368, recon=0.0367, kl=10.3592, beta=0.0000\n",
      "Batch 100, loss=0.0266, recon=0.0266, kl=10.5766, beta=0.0000\n",
      "Batch 120, loss=0.0386, recon=0.0386, kl=8.9744, beta=0.0000\n",
      "Batch 140, loss=0.0356, recon=0.0356, kl=6.2882, beta=0.0000\n",
      "Batch 160, loss=0.0379, recon=0.0378, kl=10.4229, beta=0.0000\n",
      "Batch 180, loss=0.0283, recon=0.0283, kl=9.7022, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0471, KL: 10.6214, Current Beta: 0.0000) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0393\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0341, recon=0.0340, kl=3.2751, beta=0.0000\n",
      "Batch 40, loss=0.0281, recon=0.0281, kl=5.2603, beta=0.0000\n",
      "Batch 60, loss=0.0566, recon=0.0566, kl=4.4081, beta=0.0000\n",
      "Batch 80, loss=0.0323, recon=0.0322, kl=3.7185, beta=0.0000\n",
      "Batch 100, loss=0.0313, recon=0.0313, kl=4.8175, beta=0.0000\n",
      "Batch 120, loss=0.0308, recon=0.0308, kl=3.7421, beta=0.0000\n",
      "Batch 140, loss=0.0400, recon=0.0399, kl=3.4706, beta=0.0000\n",
      "Batch 160, loss=0.0279, recon=0.0279, kl=3.6337, beta=0.0000\n",
      "Batch 180, loss=0.0499, recon=0.0499, kl=3.1168, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0448, KL: 4.1370, Current Beta: 0.0000) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1255, recon=0.1254, kl=1.4840, beta=0.0000\n",
      "Batch 40, loss=0.0303, recon=0.0302, kl=1.8712, beta=0.0000\n",
      "Batch 60, loss=0.0306, recon=0.0305, kl=1.9000, beta=0.0000\n",
      "Batch 80, loss=0.0414, recon=0.0414, kl=1.3952, beta=0.0000\n",
      "Batch 100, loss=0.6490, recon=0.6490, kl=1.1238, beta=0.0000\n",
      "Batch 120, loss=0.0659, recon=0.0659, kl=1.3782, beta=0.0000\n",
      "Batch 140, loss=0.0242, recon=0.0242, kl=1.1953, beta=0.0000\n",
      "Batch 160, loss=0.0255, recon=0.0254, kl=1.3098, beta=0.0000\n",
      "Batch 180, loss=0.0661, recon=0.0660, kl=1.5078, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0431, KL: 1.5253, Current Beta: 0.0000) | Avg Valid Loss: 0.0365 | Avg Valid recon Loss: 0.0365\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0696, recon=0.0696, kl=0.5118, beta=0.0001\n",
      "Batch 40, loss=0.0282, recon=0.0282, kl=0.5060, beta=0.0001\n",
      "Batch 60, loss=0.0339, recon=0.0338, kl=0.3472, beta=0.0001\n",
      "Batch 80, loss=0.6287, recon=0.6287, kl=0.2485, beta=0.0001\n",
      "Batch 100, loss=0.0369, recon=0.0369, kl=0.3458, beta=0.0001\n",
      "Batch 120, loss=0.0313, recon=0.0313, kl=0.2850, beta=0.0001\n",
      "Batch 140, loss=0.0294, recon=0.0294, kl=0.2274, beta=0.0001\n",
      "Batch 160, loss=0.0587, recon=0.0587, kl=0.2795, beta=0.0001\n",
      "Batch 180, loss=0.0223, recon=0.0223, kl=0.3810, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0417, KL: 0.3937, Current Beta: 0.0001) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0675, recon=0.0675, kl=0.0960, beta=0.0002\n",
      "Batch 40, loss=0.0330, recon=0.0330, kl=0.0587, beta=0.0002\n",
      "Batch 60, loss=0.0236, recon=0.0236, kl=0.0661, beta=0.0002\n",
      "Batch 80, loss=0.0447, recon=0.0447, kl=0.0381, beta=0.0002\n",
      "Batch 100, loss=0.0339, recon=0.0339, kl=0.0471, beta=0.0002\n",
      "Batch 120, loss=0.0272, recon=0.0272, kl=0.0859, beta=0.0002\n",
      "Batch 140, loss=0.0821, recon=0.0821, kl=0.0976, beta=0.0002\n",
      "Batch 160, loss=0.0390, recon=0.0390, kl=0.0674, beta=0.0002\n",
      "Batch 180, loss=0.0287, recon=0.0287, kl=0.0231, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0405, KL: 0.0731, Current Beta: 0.0002) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0198, recon=0.0198, kl=0.0062, beta=0.0004\n",
      "Batch 40, loss=0.0574, recon=0.0574, kl=0.0035, beta=0.0004\n",
      "Batch 60, loss=0.0289, recon=0.0289, kl=0.0099, beta=0.0004\n",
      "Batch 80, loss=0.0403, recon=0.0403, kl=0.0085, beta=0.0004\n",
      "Batch 100, loss=0.0239, recon=0.0239, kl=0.0055, beta=0.0004\n",
      "Batch 120, loss=0.0490, recon=0.0490, kl=0.0043, beta=0.0004\n",
      "Batch 140, loss=0.0244, recon=0.0244, kl=0.0033, beta=0.0004\n",
      "Batch 160, loss=0.0323, recon=0.0323, kl=0.0049, beta=0.0004\n",
      "Batch 180, loss=0.0328, recon=0.0328, kl=0.0042, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0395, KL: 0.0073, Current Beta: 0.0004) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=0.0025, beta=0.0006\n",
      "Batch 40, loss=0.0319, recon=0.0319, kl=0.0046, beta=0.0006\n",
      "Batch 60, loss=0.0558, recon=0.0558, kl=0.0033, beta=0.0006\n",
      "Batch 80, loss=0.0203, recon=0.0203, kl=0.0013, beta=0.0006\n",
      "Batch 100, loss=0.0427, recon=0.0427, kl=0.0012, beta=0.0006\n",
      "Batch 120, loss=0.0287, recon=0.0287, kl=0.0017, beta=0.0006\n",
      "Batch 140, loss=0.0247, recon=0.0247, kl=0.0017, beta=0.0006\n",
      "Batch 160, loss=0.0175, recon=0.0175, kl=0.0027, beta=0.0006\n",
      "Batch 180, loss=0.0250, recon=0.0250, kl=0.0016, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0388, KL: 0.0022, Current Beta: 0.0006) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0744, recon=0.0744, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.0286, recon=0.0286, kl=0.0011, beta=0.0010\n",
      "Batch 60, loss=0.0205, recon=0.0205, kl=0.0012, beta=0.0010\n",
      "Batch 80, loss=0.0218, recon=0.0218, kl=0.0006, beta=0.0010\n",
      "Batch 100, loss=0.0447, recon=0.0447, kl=0.0006, beta=0.0010\n",
      "Batch 120, loss=0.0289, recon=0.0289, kl=0.0006, beta=0.0010\n",
      "Batch 140, loss=0.1178, recon=0.1178, kl=0.0011, beta=0.0010\n",
      "Batch 160, loss=0.0336, recon=0.0336, kl=0.0008, beta=0.0010\n",
      "Batch 180, loss=0.0311, recon=0.0311, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0378 (Recon: 0.0378, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0320 | Avg Valid recon Loss: 0.0320\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1321, recon=0.1321, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0251, recon=0.0251, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0215, recon=0.0215, kl=0.0006, beta=0.0010\n",
      "Batch 80, loss=0.0371, recon=0.0371, kl=0.0006, beta=0.0010\n",
      "Batch 100, loss=0.0224, recon=0.0224, kl=0.0004, beta=0.0010\n",
      "Batch 120, loss=0.0272, recon=0.0272, kl=0.0005, beta=0.0010\n",
      "Batch 140, loss=0.0380, recon=0.0380, kl=0.0005, beta=0.0010\n",
      "Batch 160, loss=0.0273, recon=0.0273, kl=0.0010, beta=0.0010\n",
      "Batch 180, loss=0.0269, recon=0.0269, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0370, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0316 | Avg Valid recon Loss: 0.0316\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0381, recon=0.0381, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0241, recon=0.0241, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0264, recon=0.0264, kl=0.0007, beta=0.0010\n",
      "Batch 100, loss=0.0230, recon=0.0230, kl=0.0008, beta=0.0010\n",
      "Batch 120, loss=0.0268, recon=0.0268, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0224, recon=0.0224, kl=0.0010, beta=0.0010\n",
      "Batch 160, loss=0.0478, recon=0.0478, kl=0.0009, beta=0.0010\n",
      "Batch 180, loss=0.0316, recon=0.0316, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0362, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0313 | Avg Valid recon Loss: 0.0313\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0233, recon=0.0233, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0239, recon=0.0239, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0481, recon=0.0481, kl=0.0026, beta=0.0010\n",
      "Batch 80, loss=0.0217, recon=0.0217, kl=0.0008, beta=0.0010\n",
      "Batch 100, loss=0.0404, recon=0.0404, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.2291, recon=0.2291, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0252, recon=0.0252, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0420, recon=0.0420, kl=0.0013, beta=0.0010\n",
      "Batch 180, loss=0.0298, recon=0.0298, kl=0.0010, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0358, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0305 | Avg Valid recon Loss: 0.0305\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0899, recon=0.0899, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0400, recon=0.0400, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0564, recon=0.0564, kl=0.0010, beta=0.0010\n",
      "Batch 80, loss=0.1408, recon=0.1408, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0420, recon=0.0420, kl=0.0022, beta=0.0010\n",
      "Batch 120, loss=0.0331, recon=0.0331, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0261, recon=0.0261, kl=0.0006, beta=0.0010\n",
      "Batch 160, loss=0.0406, recon=0.0406, kl=0.0005, beta=0.0010\n",
      "Batch 180, loss=0.0251, recon=0.0251, kl=0.0020, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0355 (Recon: 0.0355, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0299 | Avg Valid recon Loss: 0.0299\n",
      "\n",
      "[VRAE Run 54/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1189, recon=0.1189, kl=68.3368, beta=0.0000\n",
      "Batch 40, loss=0.0746, recon=0.0746, kl=94.9234, beta=0.0000\n",
      "Batch 60, loss=0.0822, recon=0.0822, kl=90.1075, beta=0.0000\n",
      "Batch 80, loss=0.0731, recon=0.0731, kl=102.1857, beta=0.0000\n",
      "Batch 100, loss=0.0406, recon=0.0406, kl=92.1889, beta=0.0000\n",
      "Batch 120, loss=0.0464, recon=0.0464, kl=98.9395, beta=0.0000\n",
      "Batch 140, loss=0.0477, recon=0.0477, kl=113.9799, beta=0.0000\n",
      "Batch 160, loss=0.0404, recon=0.0404, kl=116.0592, beta=0.0000\n",
      "Batch 180, loss=0.0900, recon=0.0900, kl=103.7504, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1111 (Recon: 0.1111, KL: 91.6304, Current Beta: 0.0000) | Avg Valid Loss: 0.0794 | Avg Valid recon Loss: 0.0794\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0485, recon=0.0485, kl=100.0168, beta=0.0000\n",
      "Batch 40, loss=0.0566, recon=0.0566, kl=123.9398, beta=0.0000\n",
      "Batch 60, loss=0.0477, recon=0.0477, kl=121.3239, beta=0.0000\n",
      "Batch 80, loss=0.0582, recon=0.0582, kl=116.7799, beta=0.0000\n",
      "Batch 100, loss=0.0474, recon=0.0474, kl=121.8318, beta=0.0000\n",
      "Batch 120, loss=0.0248, recon=0.0248, kl=108.6635, beta=0.0000\n",
      "Batch 140, loss=0.0396, recon=0.0396, kl=105.8540, beta=0.0000\n",
      "Batch 160, loss=0.0379, recon=0.0379, kl=115.3262, beta=0.0000\n",
      "Batch 180, loss=0.0278, recon=0.0278, kl=118.5507, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0601 (Recon: 0.0601, KL: 113.2932, Current Beta: 0.0000) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0510, recon=0.0510, kl=111.3712, beta=0.0000\n",
      "Batch 40, loss=0.0357, recon=0.0357, kl=118.2693, beta=0.0000\n",
      "Batch 60, loss=0.0243, recon=0.0243, kl=127.5438, beta=0.0000\n",
      "Batch 80, loss=0.0316, recon=0.0316, kl=130.9172, beta=0.0000\n",
      "Batch 100, loss=0.0377, recon=0.0377, kl=134.5043, beta=0.0000\n",
      "Batch 120, loss=0.0261, recon=0.0261, kl=137.7448, beta=0.0000\n",
      "Batch 140, loss=0.0497, recon=0.0497, kl=139.8925, beta=0.0000\n",
      "Batch 160, loss=0.0493, recon=0.0493, kl=121.9009, beta=0.0000\n",
      "Batch 180, loss=0.0284, recon=0.0284, kl=94.6687, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0488 (Recon: 0.0488, KL: 125.6228, Current Beta: 0.0000) | Avg Valid Loss: 0.0486 | Avg Valid recon Loss: 0.0486\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0444, recon=0.0444, kl=123.8707, beta=0.0000\n",
      "Batch 40, loss=0.0468, recon=0.0468, kl=140.6398, beta=0.0000\n",
      "Batch 60, loss=0.0369, recon=0.0369, kl=142.5796, beta=0.0000\n",
      "Batch 80, loss=0.0326, recon=0.0326, kl=126.2138, beta=0.0000\n",
      "Batch 100, loss=0.0440, recon=0.0440, kl=96.5640, beta=0.0000\n",
      "Batch 120, loss=18522719649792.0000, recon=18522700775424.0000, kl=682184822226944.0000, beta=0.0000\n",
      "Batch 140, loss=0.0316, recon=0.0316, kl=99.4217, beta=0.0000\n",
      "Batch 160, loss=0.0299, recon=0.0299, kl=115.9203, beta=0.0000\n",
      "Batch 180, loss=0.0618, recon=0.0618, kl=115.6445, beta=0.0000\n",
      "  â†’ Avg Train Loss: 102335467679.4267 (Recon: 102335363401.1505, KL: 3768976918503.7651, Current Beta: 0.0000) | Avg Valid Loss: 0.0601 | Avg Valid recon Loss: 0.0601\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=105.6187, beta=0.0000\n",
      "Batch 40, loss=0.0386, recon=0.0385, kl=116.9509, beta=0.0000\n",
      "Batch 60, loss=0.0302, recon=0.0302, kl=131.5222, beta=0.0000\n",
      "Batch 80, loss=0.0406, recon=0.0406, kl=118.2388, beta=0.0000\n",
      "Batch 100, loss=0.0671, recon=0.0671, kl=170.5272, beta=0.0000\n",
      "Batch 120, loss=0.0856, recon=0.0856, kl=165.2267, beta=0.0000\n",
      "Batch 140, loss=0.1487, recon=0.1487, kl=165.8953, beta=0.0000\n",
      "Batch 160, loss=0.0717, recon=0.0717, kl=156.3572, beta=0.0000\n",
      "Batch 180, loss=0.0547, recon=0.0547, kl=175.1128, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1084 (Recon: 0.1083, KL: 144.3217, Current Beta: 0.0000) | Avg Valid Loss: 0.0801 | Avg Valid recon Loss: 0.0801\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0654, recon=0.0654, kl=180.0167, beta=0.0000\n",
      "Batch 40, loss=0.0574, recon=0.0574, kl=179.4884, beta=0.0000\n",
      "Batch 60, loss=1866.7252, recon=1866.7246, kl=2892.3130, beta=0.0000\n",
      "Batch 80, loss=0.7494, recon=0.7493, kl=184.6860, beta=0.0000\n",
      "Batch 100, loss=0.0917, recon=0.0916, kl=199.8378, beta=0.0000\n",
      "Batch 120, loss=0.1063, recon=0.1063, kl=211.8326, beta=0.0000\n",
      "Batch 140, loss=0.0689, recon=0.0688, kl=217.8240, beta=0.0000\n",
      "Batch 160, loss=0.1144, recon=0.1143, kl=218.4511, beta=0.0000\n",
      "Batch 180, loss=0.0680, recon=0.0679, kl=229.6956, beta=0.0000\n",
      "  â†’ Avg Train Loss: 182459.9212 (Recon: 182459.8824, KL: 187931.6451, Current Beta: 0.0000) | Avg Valid Loss: 0.0789 | Avg Valid recon Loss: 0.0788\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0655, recon=0.0654, kl=222.2050, beta=0.0000\n",
      "Batch 40, loss=0.0644, recon=0.0643, kl=225.6991, beta=0.0000\n",
      "Batch 60, loss=0.0535, recon=0.0534, kl=220.4262, beta=0.0000\n",
      "Batch 80, loss=0.0530, recon=0.0529, kl=224.0353, beta=0.0000\n",
      "Batch 100, loss=0.0506, recon=0.0505, kl=227.9067, beta=0.0000\n",
      "Batch 120, loss=0.0610, recon=0.0609, kl=224.1384, beta=0.0000\n",
      "Batch 140, loss=0.0594, recon=0.0593, kl=223.8579, beta=0.0000\n",
      "Batch 160, loss=0.0427, recon=0.0426, kl=239.6783, beta=0.0000\n",
      "Batch 180, loss=0.0412, recon=0.0411, kl=229.8485, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0717 (Recon: 0.0716, KL: 223.9105, Current Beta: 0.0000) | Avg Valid Loss: 0.0604 | Avg Valid recon Loss: 0.0603\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0458, recon=0.0455, kl=221.2438, beta=0.0000\n",
      "Batch 40, loss=0.0404, recon=0.0401, kl=226.9116, beta=0.0000\n",
      "Batch 60, loss=0.0546, recon=0.0543, kl=234.1753, beta=0.0000\n",
      "Batch 80, loss=0.0593, recon=0.0590, kl=227.1197, beta=0.0000\n",
      "Batch 100, loss=0.0478, recon=0.0475, kl=223.3042, beta=0.0000\n",
      "Batch 120, loss=0.0386, recon=0.0383, kl=221.8074, beta=0.0000\n",
      "Batch 140, loss=0.2078, recon=0.2074, kl=231.4997, beta=0.0000\n",
      "Batch 160, loss=0.0493, recon=0.0490, kl=228.2539, beta=0.0000\n",
      "Batch 180, loss=0.0416, recon=0.0412, kl=217.1914, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0623 (Recon: 0.0620, KL: 225.7539, Current Beta: 0.0000) | Avg Valid Loss: 0.0511 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0476, recon=0.0467, kl=222.4681, beta=0.0000\n",
      "Batch 40, loss=0.0319, recon=0.0310, kl=224.9406, beta=0.0000\n",
      "Batch 60, loss=0.0414, recon=0.0405, kl=219.3174, beta=0.0000\n",
      "Batch 80, loss=0.0709, recon=0.0701, kl=211.8586, beta=0.0000\n",
      "Batch 100, loss=0.0463, recon=0.0455, kl=216.6211, beta=0.0000\n",
      "Batch 120, loss=0.0714, recon=0.0705, kl=212.7204, beta=0.0000\n",
      "Batch 140, loss=0.0746, recon=0.0738, kl=212.9890, beta=0.0000\n",
      "Batch 160, loss=0.0536, recon=0.0527, kl=217.8093, beta=0.0000\n",
      "Batch 180, loss=0.0673, recon=0.0664, kl=218.1411, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0735 (Recon: 0.0726, KL: 215.9716, Current Beta: 0.0000) | Avg Valid Loss: 0.0549 | Avg Valid recon Loss: 0.0540\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0452, recon=0.0430, kl=205.2638, beta=0.0000\n",
      "Batch 40, loss=0.0377, recon=0.0353, kl=216.0303, beta=0.0000\n",
      "Batch 60, loss=0.0460, recon=0.0436, kl=218.8722, beta=0.0000\n",
      "Batch 80, loss=0.0354, recon=0.0332, kl=199.1151, beta=0.0000\n",
      "Batch 100, loss=0.0400, recon=0.0379, kl=190.5519, beta=0.0000\n",
      "Batch 120, loss=0.0286, recon=0.0265, kl=194.9073, beta=0.0000\n",
      "Batch 140, loss=0.0559, recon=0.0538, kl=194.2939, beta=0.0000\n",
      "Batch 160, loss=0.0628, recon=0.0607, kl=188.8641, beta=0.0000\n",
      "Batch 180, loss=0.0465, recon=0.0444, kl=186.9805, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0582 (Recon: 0.0560, KL: 200.1819, Current Beta: 0.0000) | Avg Valid Loss: 0.0577 | Avg Valid recon Loss: 0.0556\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0602, recon=0.0547, kl=185.6652, beta=0.0000\n",
      "Batch 40, loss=0.0355, recon=0.0300, kl=188.2825, beta=0.0000\n",
      "Batch 60, loss=0.0453, recon=0.0396, kl=195.8698, beta=0.0000\n",
      "Batch 80, loss=0.0451, recon=0.0398, kl=181.9556, beta=0.0000\n",
      "Batch 100, loss=0.0506, recon=0.0455, kl=176.7683, beta=0.0000\n",
      "Batch 120, loss=0.0504, recon=0.0454, kl=171.8504, beta=0.0000\n",
      "Batch 140, loss=0.0353, recon=0.0304, kl=166.4888, beta=0.0000\n",
      "Batch 160, loss=0.0348, recon=0.0300, kl=164.3489, beta=0.0000\n",
      "Batch 180, loss=0.0378, recon=0.0329, kl=166.7885, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0573 (Recon: 0.0520, KL: 180.7439, Current Beta: 0.0000) | Avg Valid Loss: 0.0512 | Avg Valid recon Loss: 0.0465\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0363, recon=0.0249, kl=150.5121, beta=0.0001\n",
      "Batch 40, loss=0.0445, recon=0.0333, kl=146.6426, beta=0.0001\n",
      "Batch 60, loss=0.0693, recon=0.0588, kl=138.0834, beta=0.0001\n",
      "Batch 80, loss=0.0388, recon=0.0294, kl=123.5533, beta=0.0001\n",
      "Batch 100, loss=0.0343, recon=0.0247, kl=126.9719, beta=0.0001\n",
      "Batch 120, loss=0.0386, recon=0.0302, kl=110.3732, beta=0.0001\n",
      "Batch 140, loss=0.0499, recon=0.0423, kl=100.5996, beta=0.0001\n",
      "Batch 160, loss=0.1437, recon=0.1367, kl=92.1212, beta=0.0001\n",
      "Batch 180, loss=0.0540, recon=0.0473, kl=88.2202, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0558 (Recon: 0.0465, KL: 122.2727, Current Beta: 0.0001) | Avg Valid Loss: 0.0631 | Avg Valid recon Loss: 0.0564\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0662, recon=0.0498, kl=90.2736, beta=0.0002\n",
      "Batch 40, loss=0.0604, recon=0.0489, kl=63.0653, beta=0.0002\n",
      "Batch 60, loss=0.0396, recon=0.0304, kl=50.5322, beta=0.0002\n",
      "Batch 80, loss=0.0728, recon=0.0652, kl=41.9078, beta=0.0002\n",
      "Batch 100, loss=0.0355, recon=0.0294, kl=33.4533, beta=0.0002\n",
      "Batch 120, loss=0.0581, recon=0.0518, kl=34.1867, beta=0.0002\n",
      "Batch 140, loss=0.0405, recon=0.0352, kl=28.9739, beta=0.0002\n",
      "Batch 160, loss=0.0328, recon=0.0286, kl=23.3320, beta=0.0002\n",
      "Batch 180, loss=0.0506, recon=0.0456, kl=27.4135, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0604 (Recon: 0.0516, KL: 48.1639, Current Beta: 0.0002) | Avg Valid Loss: 0.0521 | Avg Valid recon Loss: 0.0463\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0467, recon=0.0404, kl=16.6649, beta=0.0004\n",
      "Batch 40, loss=0.0566, recon=0.0516, kl=13.3062, beta=0.0004\n",
      "Batch 60, loss=0.0455, recon=0.0391, kl=16.8766, beta=0.0004\n",
      "Batch 80, loss=0.0447, recon=0.0380, kl=17.9190, beta=0.0004\n",
      "Batch 100, loss=0.0499, recon=0.0432, kl=17.7885, beta=0.0004\n",
      "Batch 120, loss=0.0821, recon=0.0775, kl=12.1006, beta=0.0004\n",
      "Batch 140, loss=0.0446, recon=0.0371, kl=19.8644, beta=0.0004\n",
      "Batch 160, loss=0.0424, recon=0.0365, kl=15.6310, beta=0.0004\n",
      "Batch 180, loss=0.0466, recon=0.0415, kl=13.5120, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0589 (Recon: 0.0523, KL: 17.2994, Current Beta: 0.0004) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0657, recon=0.0563, kl=15.1892, beta=0.0006\n",
      "Batch 40, loss=0.0368, recon=0.0303, kl=10.5010, beta=0.0006\n",
      "Batch 60, loss=0.0599, recon=0.0553, kl=7.3146, beta=0.0006\n",
      "Batch 80, loss=0.1438, recon=0.1398, kl=6.2829, beta=0.0006\n",
      "Batch 100, loss=0.1130, recon=0.0718, kl=66.1118, beta=0.0006\n",
      "Batch 120, loss=0.1537, recon=0.1097, kl=70.7727, beta=0.0006\n",
      "Batch 140, loss=0.1375, recon=0.0965, kl=65.7905, beta=0.0006\n",
      "Batch 160, loss=0.1006, recon=0.0665, kl=54.8388, beta=0.0006\n",
      "Batch 180, loss=0.0837, recon=0.0471, kl=58.7044, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.1373 (Recon: 0.1129, KL: 39.2175, Current Beta: 0.0006) | Avg Valid Loss: 0.0916 | Avg Valid recon Loss: 0.0602\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1124, recon=0.0619, kl=50.4455, beta=0.0010\n",
      "Batch 40, loss=0.0626, recon=0.0294, kl=33.1842, beta=0.0010\n",
      "Batch 60, loss=0.0647, recon=0.0342, kl=30.4078, beta=0.0010\n",
      "Batch 80, loss=0.0873, recon=0.0605, kl=26.8215, beta=0.0010\n",
      "Batch 100, loss=5.3944, recon=5.3536, kl=40.7935, beta=0.0010\n",
      "Batch 120, loss=2.8545, recon=2.7968, kl=57.6532, beta=0.0010\n",
      "Batch 140, loss=3.2221, recon=3.1224, kl=99.6983, beta=0.0010\n",
      "Batch 160, loss=0.6292, recon=0.5500, kl=79.1948, beta=0.0010\n",
      "Batch 180, loss=0.4981, recon=0.4324, kl=65.6425, beta=0.0010\n",
      "  â†’ Avg Train Loss: 1.8184 (Recon: 1.7647, KL: 53.7626, Current Beta: 0.0010) | Avg Valid Loss: 0.6100 | Avg Valid recon Loss: 0.5347\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.5096, recon=0.4499, kl=59.7093, beta=0.0010\n",
      "Batch 40, loss=0.2700, recon=0.2162, kl=53.7769, beta=0.0010\n",
      "Batch 60, loss=0.7080, recon=0.6508, kl=57.1218, beta=0.0010\n",
      "Batch 80, loss=0.3465, recon=0.2982, kl=48.3237, beta=0.0010\n",
      "Batch 100, loss=0.2747, recon=0.2296, kl=45.0909, beta=0.0010\n",
      "Batch 120, loss=0.2183, recon=0.1642, kl=54.1338, beta=0.0010\n",
      "Batch 140, loss=0.3196, recon=0.2786, kl=41.0213, beta=0.0010\n",
      "Batch 160, loss=0.2124, recon=0.1711, kl=41.3127, beta=0.0010\n",
      "Batch 180, loss=0.3596, recon=0.3158, kl=43.7687, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.4116 (Recon: 0.3583, KL: 53.2926, Current Beta: 0.0010) | Avg Valid Loss: 0.2031 | Avg Valid recon Loss: 0.1633\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1726, recon=0.1341, kl=38.4932, beta=0.0010\n",
      "Batch 40, loss=0.1940, recon=0.1576, kl=36.4302, beta=0.0010\n",
      "Batch 60, loss=0.1776, recon=0.1427, kl=34.8931, beta=0.0010\n",
      "Batch 80, loss=0.2125, recon=0.1816, kl=30.9012, beta=0.0010\n",
      "Batch 100, loss=0.1977, recon=0.1650, kl=32.7042, beta=0.0010\n",
      "Batch 120, loss=0.3583, recon=0.3302, kl=28.1439, beta=0.0010\n",
      "Batch 140, loss=0.1696, recon=0.1407, kl=28.9580, beta=0.0010\n",
      "Batch 160, loss=0.1985, recon=0.1716, kl=26.8684, beta=0.0010\n",
      "Batch 180, loss=0.1483, recon=0.1222, kl=26.0927, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.2209 (Recon: 0.1884, KL: 32.5109, Current Beta: 0.0010) | Avg Valid Loss: 0.1627 | Avg Valid recon Loss: 0.1349\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1684, recon=0.1380, kl=30.4806, beta=0.0010\n",
      "Batch 40, loss=0.1427, recon=0.1165, kl=26.1789, beta=0.0010\n",
      "Batch 60, loss=0.2066, recon=0.1782, kl=28.4053, beta=0.0010\n",
      "Batch 80, loss=0.1722, recon=0.1471, kl=25.1585, beta=0.0010\n",
      "Batch 100, loss=0.2168, recon=0.1920, kl=24.8734, beta=0.0010\n",
      "Batch 120, loss=0.1296, recon=0.1052, kl=24.4218, beta=0.0010\n",
      "Batch 140, loss=0.1067, recon=0.0847, kl=21.9671, beta=0.0010\n",
      "Batch 160, loss=0.1384, recon=0.1156, kl=22.7958, beta=0.0010\n",
      "Batch 180, loss=0.1423, recon=0.1224, kl=19.8828, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1926 (Recon: 0.1671, KL: 25.5438, Current Beta: 0.0010) | Avg Valid Loss: 0.1245 | Avg Valid recon Loss: 0.1032\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1446, recon=0.1257, kl=18.8397, beta=0.0010\n",
      "Batch 40, loss=0.1152, recon=0.0961, kl=19.0370, beta=0.0010\n",
      "Batch 60, loss=0.1472, recon=0.1291, kl=18.0887, beta=0.0010\n",
      "Batch 80, loss=0.1130, recon=0.0979, kl=15.1667, beta=0.0010\n",
      "Batch 100, loss=0.1811, recon=0.1625, kl=18.6498, beta=0.0010\n",
      "Batch 120, loss=0.1196, recon=0.1028, kl=16.7735, beta=0.0010\n",
      "Batch 140, loss=0.0950, recon=0.0783, kl=16.6554, beta=0.0010\n",
      "Batch 160, loss=0.1336, recon=0.1191, kl=14.5495, beta=0.0010\n",
      "Batch 180, loss=0.1074, recon=0.0926, kl=14.7449, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1580 (Recon: 0.1404, KL: 17.5746, Current Beta: 0.0010) | Avg Valid Loss: 0.1066 | Avg Valid recon Loss: 0.0926\n",
      "\n",
      "[VRAE Run 55/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=1.0162, recon=1.0162, kl=0.4186, beta=0.0000\n",
      "Batch 40, loss=0.7126, recon=0.7126, kl=3.1324, beta=0.0000\n",
      "Batch 60, loss=0.7901, recon=0.7901, kl=8.1903, beta=0.0000\n",
      "Batch 80, loss=0.2908, recon=0.2908, kl=11.9584, beta=0.0000\n",
      "Batch 100, loss=0.4479, recon=0.4479, kl=14.3911, beta=0.0000\n",
      "Batch 120, loss=1.1318, recon=1.1318, kl=17.3428, beta=0.0000\n",
      "Batch 140, loss=0.2043, recon=0.2043, kl=20.3503, beta=0.0000\n",
      "Batch 160, loss=0.1885, recon=0.1885, kl=22.6768, beta=0.0000\n",
      "Batch 180, loss=0.1108, recon=0.1108, kl=24.4950, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4354 (Recon: 0.4354, KL: 12.4425, Current Beta: 0.0000) | Avg Valid Loss: 0.2142 | Avg Valid recon Loss: 0.2142\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1578, recon=0.1578, kl=26.2995, beta=0.0000\n",
      "Batch 40, loss=0.1593, recon=0.1593, kl=27.4843, beta=0.0000\n",
      "Batch 60, loss=0.1737, recon=0.1737, kl=28.7067, beta=0.0000\n",
      "Batch 80, loss=0.1577, recon=0.1577, kl=29.6454, beta=0.0000\n",
      "Batch 100, loss=0.1167, recon=0.1167, kl=31.1006, beta=0.0000\n",
      "Batch 120, loss=0.3135, recon=0.3135, kl=31.7291, beta=0.0000\n",
      "Batch 140, loss=0.1983, recon=0.1983, kl=32.8579, beta=0.0000\n",
      "Batch 160, loss=0.0854, recon=0.0854, kl=33.8265, beta=0.0000\n",
      "Batch 180, loss=0.1198, recon=0.1198, kl=34.6922, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1855 (Recon: 0.1855, KL: 30.1534, Current Beta: 0.0000) | Avg Valid Loss: 0.1325 | Avg Valid recon Loss: 0.1325\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1081, recon=0.1081, kl=35.2327, beta=0.0000\n",
      "Batch 40, loss=0.1215, recon=0.1215, kl=35.7035, beta=0.0000\n",
      "Batch 60, loss=0.0999, recon=0.0999, kl=36.3721, beta=0.0000\n",
      "Batch 80, loss=0.0886, recon=0.0886, kl=37.5608, beta=0.0000\n",
      "Batch 100, loss=0.2156, recon=0.2156, kl=38.2080, beta=0.0000\n",
      "Batch 120, loss=0.1000, recon=0.1000, kl=38.1255, beta=0.0000\n",
      "Batch 140, loss=0.1093, recon=0.1093, kl=38.6453, beta=0.0000\n",
      "Batch 160, loss=0.6058, recon=0.6058, kl=38.9877, beta=0.0000\n",
      "Batch 180, loss=0.0854, recon=0.0854, kl=39.7314, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1320 (Recon: 0.1320, KL: 37.3759, Current Beta: 0.0000) | Avg Valid Loss: 0.1070 | Avg Valid recon Loss: 0.1070\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0804, recon=0.0804, kl=40.0151, beta=0.0000\n",
      "Batch 40, loss=0.0910, recon=0.0910, kl=40.3586, beta=0.0000\n",
      "Batch 60, loss=0.1161, recon=0.1161, kl=40.6482, beta=0.0000\n",
      "Batch 80, loss=0.0619, recon=0.0619, kl=41.0795, beta=0.0000\n",
      "Batch 100, loss=0.0525, recon=0.0525, kl=41.4535, beta=0.0000\n",
      "Batch 120, loss=0.0652, recon=0.0652, kl=41.7733, beta=0.0000\n",
      "Batch 140, loss=0.0718, recon=0.0718, kl=42.0196, beta=0.0000\n",
      "Batch 160, loss=0.0637, recon=0.0637, kl=42.1397, beta=0.0000\n",
      "Batch 180, loss=0.0893, recon=0.0893, kl=42.3905, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1082 (Recon: 0.1082, KL: 41.1894, Current Beta: 0.0000) | Avg Valid Loss: 0.0913 | Avg Valid recon Loss: 0.0913\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0772, recon=0.0772, kl=42.5985, beta=0.0000\n",
      "Batch 40, loss=0.1040, recon=0.1040, kl=42.1432, beta=0.0000\n",
      "Batch 60, loss=0.0675, recon=0.0675, kl=42.3882, beta=0.0000\n",
      "Batch 80, loss=0.0589, recon=0.0589, kl=42.9583, beta=0.0000\n",
      "Batch 100, loss=0.0430, recon=0.0430, kl=43.1760, beta=0.0000\n",
      "Batch 120, loss=0.0947, recon=0.0947, kl=43.6323, beta=0.0000\n",
      "Batch 140, loss=0.0691, recon=0.0691, kl=43.5539, beta=0.0000\n",
      "Batch 160, loss=0.0652, recon=0.0652, kl=42.9112, beta=0.0000\n",
      "Batch 180, loss=0.0543, recon=0.0543, kl=43.2059, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0950 (Recon: 0.0950, KL: 42.8878, Current Beta: 0.0000) | Avg Valid Loss: 0.0820 | Avg Valid recon Loss: 0.0820\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0507, recon=0.0507, kl=42.6898, beta=0.0000\n",
      "Batch 40, loss=0.0675, recon=0.0675, kl=42.2065, beta=0.0000\n",
      "Batch 60, loss=0.1060, recon=0.1060, kl=41.3991, beta=0.0000\n",
      "Batch 80, loss=0.0782, recon=0.0782, kl=41.6240, beta=0.0000\n",
      "Batch 100, loss=0.0515, recon=0.0515, kl=41.0981, beta=0.0000\n",
      "Batch 120, loss=0.4462, recon=0.4462, kl=40.3689, beta=0.0000\n",
      "Batch 140, loss=0.0638, recon=0.0638, kl=39.9398, beta=0.0000\n",
      "Batch 160, loss=0.0577, recon=0.0577, kl=39.4062, beta=0.0000\n",
      "Batch 180, loss=0.0491, recon=0.0491, kl=39.5988, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0870 (Recon: 0.0870, KL: 41.1118, Current Beta: 0.0000) | Avg Valid Loss: 0.0767 | Avg Valid recon Loss: 0.0767\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0412, recon=0.0412, kl=38.6267, beta=0.0000\n",
      "Batch 40, loss=0.0489, recon=0.0489, kl=37.5176, beta=0.0000\n",
      "Batch 60, loss=0.1033, recon=0.1033, kl=36.2031, beta=0.0000\n",
      "Batch 80, loss=0.0839, recon=0.0838, kl=34.9985, beta=0.0000\n",
      "Batch 100, loss=0.0459, recon=0.0458, kl=34.0123, beta=0.0000\n",
      "Batch 120, loss=0.0895, recon=0.0895, kl=32.6904, beta=0.0000\n",
      "Batch 140, loss=0.0575, recon=0.0575, kl=32.3672, beta=0.0000\n",
      "Batch 160, loss=0.0627, recon=0.0627, kl=31.4779, beta=0.0000\n",
      "Batch 180, loss=0.0569, recon=0.0569, kl=31.4883, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0805 (Recon: 0.0804, KL: 34.7892, Current Beta: 0.0000) | Avg Valid Loss: 0.0724 | Avg Valid recon Loss: 0.0724\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0730, recon=0.0730, kl=28.7020, beta=0.0000\n",
      "Batch 40, loss=0.0424, recon=0.0424, kl=25.9404, beta=0.0000\n",
      "Batch 60, loss=0.0424, recon=0.0423, kl=23.8188, beta=0.0000\n",
      "Batch 80, loss=0.1033, recon=0.1033, kl=21.9849, beta=0.0000\n",
      "Batch 100, loss=0.0748, recon=0.0747, kl=20.9325, beta=0.0000\n",
      "Batch 120, loss=0.0450, recon=0.0449, kl=20.2349, beta=0.0000\n",
      "Batch 140, loss=0.0460, recon=0.0460, kl=19.7821, beta=0.0000\n",
      "Batch 160, loss=0.0629, recon=0.0629, kl=19.4027, beta=0.0000\n",
      "Batch 180, loss=0.0568, recon=0.0568, kl=19.5035, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0759 (Recon: 0.0759, KL: 22.8106, Current Beta: 0.0000) | Avg Valid Loss: 0.0681 | Avg Valid recon Loss: 0.0681\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0758, recon=0.0758, kl=16.2849, beta=0.0000\n",
      "Batch 40, loss=0.0450, recon=0.0449, kl=12.6984, beta=0.0000\n",
      "Batch 60, loss=0.0728, recon=0.0728, kl=12.0610, beta=0.0000\n",
      "Batch 80, loss=0.0366, recon=0.0366, kl=11.8758, beta=0.0000\n",
      "Batch 100, loss=0.0515, recon=0.0515, kl=10.8852, beta=0.0000\n",
      "Batch 120, loss=0.0398, recon=0.0398, kl=11.1416, beta=0.0000\n",
      "Batch 140, loss=0.0935, recon=0.0935, kl=10.6204, beta=0.0000\n",
      "Batch 160, loss=0.0497, recon=0.0497, kl=10.5772, beta=0.0000\n",
      "Batch 180, loss=0.0420, recon=0.0420, kl=10.1442, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0720 (Recon: 0.0720, KL: 12.2844, Current Beta: 0.0000) | Avg Valid Loss: 0.0645 | Avg Valid recon Loss: 0.0645\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0586, recon=0.0585, kl=6.4743, beta=0.0000\n",
      "Batch 40, loss=0.0601, recon=0.0600, kl=5.3040, beta=0.0000\n",
      "Batch 60, loss=0.1071, recon=0.1070, kl=5.3505, beta=0.0000\n",
      "Batch 80, loss=0.0422, recon=0.0422, kl=5.1875, beta=0.0000\n",
      "Batch 100, loss=0.0511, recon=0.0510, kl=4.5594, beta=0.0000\n",
      "Batch 120, loss=0.0621, recon=0.0621, kl=4.6942, beta=0.0000\n",
      "Batch 140, loss=0.0405, recon=0.0404, kl=4.4287, beta=0.0000\n",
      "Batch 160, loss=0.0409, recon=0.0408, kl=4.7385, beta=0.0000\n",
      "Batch 180, loss=0.0514, recon=0.0513, kl=4.5485, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0688 (Recon: 0.0687, KL: 5.2783, Current Beta: 0.0000) | Avg Valid Loss: 0.0620 | Avg Valid recon Loss: 0.0620\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0633, recon=0.0632, kl=1.9341, beta=0.0000\n",
      "Batch 40, loss=0.3498, recon=0.3497, kl=2.0801, beta=0.0000\n",
      "Batch 60, loss=0.0327, recon=0.0326, kl=1.9656, beta=0.0000\n",
      "Batch 80, loss=0.0454, recon=0.0454, kl=1.6082, beta=0.0000\n",
      "Batch 100, loss=0.0600, recon=0.0599, kl=1.9977, beta=0.0000\n",
      "Batch 120, loss=0.0833, recon=0.0833, kl=1.4090, beta=0.0000\n",
      "Batch 140, loss=0.0327, recon=0.0327, kl=1.4680, beta=0.0000\n",
      "Batch 160, loss=0.0465, recon=0.0464, kl=1.4541, beta=0.0000\n",
      "Batch 180, loss=0.0463, recon=0.0462, kl=1.2568, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0658 (Recon: 0.0658, KL: 1.8483, Current Beta: 0.0000) | Avg Valid Loss: 0.0592 | Avg Valid recon Loss: 0.0591\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0396, recon=0.0396, kl=0.4582, beta=0.0001\n",
      "Batch 40, loss=0.0450, recon=0.0449, kl=0.4472, beta=0.0001\n",
      "Batch 60, loss=0.0299, recon=0.0299, kl=0.4351, beta=0.0001\n",
      "Batch 80, loss=0.0490, recon=0.0489, kl=0.3237, beta=0.0001\n",
      "Batch 100, loss=0.1050, recon=0.1050, kl=0.3107, beta=0.0001\n",
      "Batch 120, loss=0.0700, recon=0.0700, kl=0.2536, beta=0.0001\n",
      "Batch 140, loss=0.0435, recon=0.0435, kl=0.3569, beta=0.0001\n",
      "Batch 160, loss=0.0406, recon=0.0406, kl=0.2103, beta=0.0001\n",
      "Batch 180, loss=0.0580, recon=0.0580, kl=0.4547, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0635 (Recon: 0.0635, KL: 0.3971, Current Beta: 0.0001) | Avg Valid Loss: 0.0568 | Avg Valid recon Loss: 0.0568\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=0.0810, beta=0.0002\n",
      "Batch 40, loss=0.0371, recon=0.0371, kl=0.0438, beta=0.0002\n",
      "Batch 60, loss=0.0652, recon=0.0652, kl=0.0287, beta=0.0002\n",
      "Batch 80, loss=0.0753, recon=0.0753, kl=0.0248, beta=0.0002\n",
      "Batch 100, loss=0.0331, recon=0.0331, kl=0.0208, beta=0.0002\n",
      "Batch 120, loss=0.0372, recon=0.0372, kl=0.0198, beta=0.0002\n",
      "Batch 140, loss=0.1480, recon=0.1480, kl=0.0368, beta=0.0002\n",
      "Batch 160, loss=0.0591, recon=0.0591, kl=0.0073, beta=0.0002\n",
      "Batch 180, loss=0.0493, recon=0.0493, kl=0.0350, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0614 (Recon: 0.0614, KL: 0.0461, Current Beta: 0.0002) | Avg Valid Loss: 0.0554 | Avg Valid recon Loss: 0.0554\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0421, recon=0.0421, kl=0.0057, beta=0.0004\n",
      "Batch 40, loss=0.0361, recon=0.0361, kl=0.0048, beta=0.0004\n",
      "Batch 60, loss=0.0407, recon=0.0407, kl=0.0020, beta=0.0004\n",
      "Batch 80, loss=0.0289, recon=0.0289, kl=0.0035, beta=0.0004\n",
      "Batch 100, loss=0.0635, recon=0.0635, kl=0.0020, beta=0.0004\n",
      "Batch 120, loss=0.0429, recon=0.0429, kl=0.0039, beta=0.0004\n",
      "Batch 140, loss=0.0399, recon=0.0399, kl=0.0024, beta=0.0004\n",
      "Batch 160, loss=0.0684, recon=0.0684, kl=0.0016, beta=0.0004\n",
      "Batch 180, loss=0.0573, recon=0.0573, kl=0.0016, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0594 (Recon: 0.0594, KL: 0.0053, Current Beta: 0.0004) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0541\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0489, recon=0.0489, kl=0.0013, beta=0.0006\n",
      "Batch 40, loss=0.0392, recon=0.0392, kl=0.0015, beta=0.0006\n",
      "Batch 60, loss=0.0570, recon=0.0570, kl=0.0008, beta=0.0006\n",
      "Batch 80, loss=0.0334, recon=0.0334, kl=0.0004, beta=0.0006\n",
      "Batch 100, loss=0.0342, recon=0.0342, kl=0.0013, beta=0.0006\n",
      "Batch 120, loss=0.0433, recon=0.0433, kl=0.0006, beta=0.0006\n",
      "Batch 140, loss=0.0373, recon=0.0373, kl=0.0005, beta=0.0006\n",
      "Batch 160, loss=0.0363, recon=0.0363, kl=0.0009, beta=0.0006\n",
      "Batch 180, loss=0.0394, recon=0.0394, kl=0.0029, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 0.0012, Current Beta: 0.0006) | Avg Valid Loss: 0.0519 | Avg Valid recon Loss: 0.0519\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0480, recon=0.0480, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.1316, recon=0.1316, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0383, recon=0.0383, kl=0.0012, beta=0.0010\n",
      "Batch 80, loss=0.0549, recon=0.0549, kl=0.0010, beta=0.0010\n",
      "Batch 100, loss=0.0331, recon=0.0331, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0703, recon=0.0703, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0406, recon=0.0406, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0411, recon=0.0411, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0343, recon=0.0343, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0565 (Recon: 0.0565, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0728, recon=0.0728, kl=0.0005, beta=0.0010\n",
      "Batch 40, loss=0.0337, recon=0.0337, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0661, recon=0.0661, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0779, recon=0.0779, kl=0.0013, beta=0.0010\n",
      "Batch 100, loss=0.0274, recon=0.0274, kl=0.0005, beta=0.0010\n",
      "Batch 120, loss=0.0371, recon=0.0371, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0560, recon=0.0560, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0454, recon=0.0454, kl=0.0015, beta=0.0010\n",
      "Batch 180, loss=0.0349, recon=0.0348, kl=0.0009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0550 (Recon: 0.0550, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0497 | Avg Valid recon Loss: 0.0497\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.9482, recon=0.9482, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.0444, recon=0.0444, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0421, recon=0.0421, kl=0.0014, beta=0.0010\n",
      "Batch 80, loss=0.0286, recon=0.0286, kl=0.0016, beta=0.0010\n",
      "Batch 100, loss=0.1309, recon=0.1309, kl=0.0004, beta=0.0010\n",
      "Batch 120, loss=0.0387, recon=0.0387, kl=0.0005, beta=0.0010\n",
      "Batch 140, loss=0.0336, recon=0.0336, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0644, recon=0.0644, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0423, recon=0.0423, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0542 (Recon: 0.0542, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0376, recon=0.0376, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0389, recon=0.0389, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0421, recon=0.0421, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0452, recon=0.0452, kl=0.0003, beta=0.0010\n",
      "Batch 100, loss=0.0277, recon=0.0277, kl=0.0001, beta=0.0010\n",
      "Batch 120, loss=0.0319, recon=0.0319, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0275, recon=0.0275, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0368, recon=0.0368, kl=0.0034, beta=0.0010\n",
      "Batch 180, loss=0.0495, recon=0.0495, kl=0.0009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0529, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0478\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0288, recon=0.0288, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0535, recon=0.0535, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0553, recon=0.0553, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0265, recon=0.0265, kl=0.0004, beta=0.0010\n",
      "Batch 100, loss=0.0388, recon=0.0388, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.2323, recon=0.2323, kl=0.0008, beta=0.0010\n",
      "Batch 140, loss=0.1844, recon=0.1844, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0315, recon=0.0315, kl=0.0004, beta=0.0010\n",
      "Batch 180, loss=0.0378, recon=0.0378, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0519 (Recon: 0.0519, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0463 | Avg Valid recon Loss: 0.0463\n",
      "\n",
      "[VRAE Run 56/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2783, recon=0.2783, kl=12.7711, beta=0.0000\n",
      "Batch 40, loss=0.1460, recon=0.1460, kl=24.2225, beta=0.0000\n",
      "Batch 60, loss=0.1264, recon=0.1264, kl=29.2844, beta=0.0000\n",
      "Batch 80, loss=0.0923, recon=0.0923, kl=28.8566, beta=0.0000\n",
      "Batch 100, loss=0.0781, recon=0.0781, kl=31.1996, beta=0.0000\n",
      "Batch 120, loss=0.0629, recon=0.0629, kl=29.9678, beta=0.0000\n",
      "Batch 140, loss=0.0773, recon=0.0773, kl=27.6219, beta=0.0000\n",
      "Batch 160, loss=0.1060, recon=0.1060, kl=31.9226, beta=0.0000\n",
      "Batch 180, loss=0.0719, recon=0.0719, kl=33.0946, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1778 (Recon: 0.1778, KL: 26.0355, Current Beta: 0.0000) | Avg Valid Loss: 0.0815 | Avg Valid recon Loss: 0.0815\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0574, recon=0.0574, kl=34.5134, beta=0.0000\n",
      "Batch 40, loss=0.0608, recon=0.0608, kl=34.6210, beta=0.0000\n",
      "Batch 60, loss=0.0497, recon=0.0497, kl=34.9058, beta=0.0000\n",
      "Batch 80, loss=0.0566, recon=0.0566, kl=35.6728, beta=0.0000\n",
      "Batch 100, loss=0.0497, recon=0.0497, kl=35.9824, beta=0.0000\n",
      "Batch 120, loss=0.0540, recon=0.0540, kl=37.6747, beta=0.0000\n",
      "Batch 140, loss=0.0570, recon=0.0570, kl=33.6737, beta=0.0000\n",
      "Batch 160, loss=0.0774, recon=0.0774, kl=32.1508, beta=0.0000\n",
      "Batch 180, loss=0.0488, recon=0.0488, kl=35.3757, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0769 (Recon: 0.0769, KL: 34.8131, Current Beta: 0.0000) | Avg Valid Loss: 0.0595 | Avg Valid recon Loss: 0.0595\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0923, recon=0.0923, kl=37.6120, beta=0.0000\n",
      "Batch 40, loss=0.0355, recon=0.0355, kl=40.9823, beta=0.0000\n",
      "Batch 60, loss=0.0569, recon=0.0569, kl=39.2884, beta=0.0000\n",
      "Batch 80, loss=0.0386, recon=0.0386, kl=38.5061, beta=0.0000\n",
      "Batch 100, loss=0.0564, recon=0.0564, kl=38.5369, beta=0.0000\n",
      "Batch 120, loss=0.0808, recon=0.0808, kl=32.1951, beta=0.0000\n",
      "Batch 140, loss=0.0359, recon=0.0359, kl=35.1672, beta=0.0000\n",
      "Batch 160, loss=0.0521, recon=0.0521, kl=36.1920, beta=0.0000\n",
      "Batch 180, loss=0.0433, recon=0.0433, kl=37.4647, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0637 (Recon: 0.0637, KL: 37.0640, Current Beta: 0.0000) | Avg Valid Loss: 0.0516 | Avg Valid recon Loss: 0.0516\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0483, recon=0.0483, kl=36.5337, beta=0.0000\n",
      "Batch 40, loss=0.0328, recon=0.0328, kl=36.6994, beta=0.0000\n",
      "Batch 60, loss=0.0335, recon=0.0335, kl=38.3749, beta=0.0000\n",
      "Batch 80, loss=0.0429, recon=0.0429, kl=37.6311, beta=0.0000\n",
      "Batch 100, loss=0.0760, recon=0.0760, kl=37.5113, beta=0.0000\n",
      "Batch 120, loss=0.0335, recon=0.0335, kl=37.1000, beta=0.0000\n",
      "Batch 140, loss=0.0606, recon=0.0606, kl=36.7223, beta=0.0000\n",
      "Batch 160, loss=0.0551, recon=0.0551, kl=37.5557, beta=0.0000\n",
      "Batch 180, loss=0.0334, recon=0.0334, kl=39.9074, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0547, KL: 37.4742, Current Beta: 0.0000) | Avg Valid Loss: 0.0459 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0588, recon=0.0588, kl=40.4963, beta=0.0000\n",
      "Batch 40, loss=0.0412, recon=0.0412, kl=39.0900, beta=0.0000\n",
      "Batch 60, loss=0.0350, recon=0.0350, kl=39.2599, beta=0.0000\n",
      "Batch 80, loss=0.0631, recon=0.0631, kl=39.2598, beta=0.0000\n",
      "Batch 100, loss=0.0428, recon=0.0428, kl=35.2273, beta=0.0000\n",
      "Batch 120, loss=0.0371, recon=0.0371, kl=34.9336, beta=0.0000\n",
      "Batch 140, loss=0.0450, recon=0.0450, kl=36.7443, beta=0.0000\n",
      "Batch 160, loss=0.0387, recon=0.0387, kl=37.8861, beta=0.0000\n",
      "Batch 180, loss=0.0433, recon=0.0433, kl=36.3888, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0519 (Recon: 0.0519, KL: 38.0185, Current Beta: 0.0000) | Avg Valid Loss: 0.0533 | Avg Valid recon Loss: 0.0533\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0510, recon=0.0510, kl=34.9581, beta=0.0000\n",
      "Batch 40, loss=0.2030, recon=0.2030, kl=28.0342, beta=0.0000\n",
      "Batch 60, loss=0.0405, recon=0.0405, kl=30.0315, beta=0.0000\n",
      "Batch 80, loss=0.0255, recon=0.0255, kl=31.9196, beta=0.0000\n",
      "Batch 100, loss=0.1471, recon=0.1470, kl=31.8210, beta=0.0000\n",
      "Batch 120, loss=0.0291, recon=0.0291, kl=31.8278, beta=0.0000\n",
      "Batch 140, loss=0.0300, recon=0.0300, kl=31.9680, beta=0.0000\n",
      "Batch 160, loss=0.0876, recon=0.0876, kl=31.7916, beta=0.0000\n",
      "Batch 180, loss=0.0365, recon=0.0365, kl=33.3579, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0523, KL: 31.7779, Current Beta: 0.0000) | Avg Valid Loss: 0.0502 | Avg Valid recon Loss: 0.0501\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0308, recon=0.0307, kl=30.7448, beta=0.0000\n",
      "Batch 40, loss=0.0252, recon=0.0251, kl=27.9874, beta=0.0000\n",
      "Batch 60, loss=0.0293, recon=0.0293, kl=26.7820, beta=0.0000\n",
      "Batch 80, loss=0.0549, recon=0.0549, kl=26.5312, beta=0.0000\n",
      "Batch 100, loss=0.0414, recon=0.0414, kl=26.7479, beta=0.0000\n",
      "Batch 120, loss=0.0238, recon=0.0238, kl=26.9862, beta=0.0000\n",
      "Batch 140, loss=0.0296, recon=0.0296, kl=27.3873, beta=0.0000\n",
      "Batch 160, loss=0.0281, recon=0.0281, kl=26.8434, beta=0.0000\n",
      "Batch 180, loss=0.0348, recon=0.0348, kl=26.8925, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0496, KL: 27.7856, Current Beta: 0.0000) | Avg Valid Loss: 0.0502 | Avg Valid recon Loss: 0.0502\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0740, recon=0.0740, kl=22.3009, beta=0.0000\n",
      "Batch 40, loss=0.0331, recon=0.0331, kl=15.6270, beta=0.0000\n",
      "Batch 60, loss=0.0276, recon=0.0275, kl=21.5151, beta=0.0000\n",
      "Batch 80, loss=0.0351, recon=0.0350, kl=23.9549, beta=0.0000\n",
      "Batch 100, loss=0.0323, recon=0.0323, kl=22.7325, beta=0.0000\n",
      "Batch 120, loss=0.0476, recon=0.0476, kl=21.4980, beta=0.0000\n",
      "Batch 140, loss=0.0338, recon=0.0338, kl=21.9273, beta=0.0000\n",
      "Batch 160, loss=0.0341, recon=0.0340, kl=20.8527, beta=0.0000\n",
      "Batch 180, loss=0.0326, recon=0.0325, kl=19.8974, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0521 (Recon: 0.0521, KL: 21.3985, Current Beta: 0.0000) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0581, recon=0.0581, kl=14.0259, beta=0.0000\n",
      "Batch 40, loss=0.0451, recon=0.0451, kl=12.9584, beta=0.0000\n",
      "Batch 60, loss=0.0458, recon=0.0457, kl=16.8165, beta=0.0000\n",
      "Batch 80, loss=0.0356, recon=0.0356, kl=14.5301, beta=0.0000\n",
      "Batch 100, loss=0.0388, recon=0.0387, kl=14.7742, beta=0.0000\n",
      "Batch 120, loss=0.0273, recon=0.0272, kl=15.4516, beta=0.0000\n",
      "Batch 140, loss=0.0232, recon=0.0232, kl=13.1631, beta=0.0000\n",
      "Batch 160, loss=0.0362, recon=0.0361, kl=12.7346, beta=0.0000\n",
      "Batch 180, loss=0.0593, recon=0.0593, kl=12.1617, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0532, KL: 14.5794, Current Beta: 0.0000) | Avg Valid Loss: 0.0597 | Avg Valid recon Loss: 0.0596\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0453, recon=0.0452, kl=4.6741, beta=0.0000\n",
      "Batch 40, loss=0.0686, recon=0.0686, kl=5.8140, beta=0.0000\n",
      "Batch 60, loss=0.0713, recon=0.0712, kl=4.8769, beta=0.0000\n",
      "Batch 80, loss=0.0683, recon=0.0682, kl=8.0389, beta=0.0000\n",
      "Batch 100, loss=0.0349, recon=0.0348, kl=7.9982, beta=0.0000\n",
      "Batch 120, loss=0.0409, recon=0.0409, kl=4.6521, beta=0.0000\n",
      "Batch 140, loss=0.0337, recon=0.0336, kl=3.1210, beta=0.0000\n",
      "Batch 160, loss=0.0241, recon=0.0240, kl=4.8339, beta=0.0000\n",
      "Batch 180, loss=0.0257, recon=0.0256, kl=4.9732, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0541 (Recon: 0.0540, KL: 5.8644, Current Beta: 0.0000) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1075, recon=0.1075, kl=1.4273, beta=0.0000\n",
      "Batch 40, loss=0.0480, recon=0.0480, kl=0.8206, beta=0.0000\n",
      "Batch 60, loss=0.0465, recon=0.0465, kl=0.7288, beta=0.0000\n",
      "Batch 80, loss=0.0251, recon=0.0250, kl=0.6517, beta=0.0000\n",
      "Batch 100, loss=0.0434, recon=0.0434, kl=0.6638, beta=0.0000\n",
      "Batch 120, loss=0.0233, recon=0.0233, kl=0.8038, beta=0.0000\n",
      "Batch 140, loss=0.0543, recon=0.0542, kl=1.0307, beta=0.0000\n",
      "Batch 160, loss=0.0408, recon=0.0408, kl=0.8153, beta=0.0000\n",
      "Batch 180, loss=0.0320, recon=0.0319, kl=0.5068, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0453 (Recon: 0.0452, KL: 1.0383, Current Beta: 0.0000) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0393, recon=0.0393, kl=0.1402, beta=0.0001\n",
      "Batch 40, loss=0.0215, recon=0.0215, kl=0.0950, beta=0.0001\n",
      "Batch 60, loss=0.0289, recon=0.0288, kl=0.0743, beta=0.0001\n",
      "Batch 80, loss=0.0336, recon=0.0336, kl=0.0517, beta=0.0001\n",
      "Batch 100, loss=0.0194, recon=0.0193, kl=0.0387, beta=0.0001\n",
      "Batch 120, loss=0.0247, recon=0.0247, kl=0.0321, beta=0.0001\n",
      "Batch 140, loss=0.1159, recon=0.1159, kl=0.1058, beta=0.0001\n",
      "Batch 160, loss=0.0237, recon=0.0237, kl=0.1499, beta=0.0001\n",
      "Batch 180, loss=0.0435, recon=0.0435, kl=0.1616, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0410, KL: 0.1109, Current Beta: 0.0001) | Avg Valid Loss: 0.0362 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0495, recon=0.0495, kl=0.0147, beta=0.0002\n",
      "Batch 40, loss=0.0292, recon=0.0292, kl=0.0593, beta=0.0002\n",
      "Batch 60, loss=0.0519, recon=0.0518, kl=0.0933, beta=0.0002\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=0.0147, beta=0.0002\n",
      "Batch 100, loss=0.0221, recon=0.0221, kl=0.0307, beta=0.0002\n",
      "Batch 120, loss=0.0301, recon=0.0301, kl=0.0179, beta=0.0002\n",
      "Batch 140, loss=0.0216, recon=0.0216, kl=0.0253, beta=0.0002\n",
      "Batch 160, loss=0.0372, recon=0.0372, kl=0.0206, beta=0.0002\n",
      "Batch 180, loss=0.0887, recon=0.0887, kl=0.1147, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0405, KL: 0.0418, Current Beta: 0.0002) | Avg Valid Loss: 0.0550 | Avg Valid recon Loss: 0.0549\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0810, recon=0.0810, kl=0.0043, beta=0.0004\n",
      "Batch 40, loss=0.0364, recon=0.0364, kl=0.0075, beta=0.0004\n",
      "Batch 60, loss=0.0384, recon=0.0384, kl=0.0158, beta=0.0004\n",
      "Batch 80, loss=0.0481, recon=0.0481, kl=0.0046, beta=0.0004\n",
      "Batch 100, loss=0.0242, recon=0.0242, kl=0.0037, beta=0.0004\n",
      "Batch 120, loss=0.0483, recon=0.0483, kl=0.0037, beta=0.0004\n",
      "Batch 140, loss=0.0500, recon=0.0499, kl=0.0028, beta=0.0004\n",
      "Batch 160, loss=0.0367, recon=0.0367, kl=0.0049, beta=0.0004\n",
      "Batch 180, loss=0.0522, recon=0.0522, kl=0.0019, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0446, KL: 0.0083, Current Beta: 0.0004) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0242, recon=0.0242, kl=0.0019, beta=0.0006\n",
      "Batch 40, loss=0.0719, recon=0.0719, kl=0.0159, beta=0.0006\n",
      "Batch 60, loss=0.0422, recon=0.0422, kl=0.0031, beta=0.0006\n",
      "Batch 80, loss=0.0339, recon=0.0339, kl=0.0013, beta=0.0006\n",
      "Batch 100, loss=0.0412, recon=0.0412, kl=0.0013, beta=0.0006\n",
      "Batch 120, loss=0.0325, recon=0.0325, kl=0.0010, beta=0.0006\n",
      "Batch 140, loss=0.0350, recon=0.0350, kl=0.0009, beta=0.0006\n",
      "Batch 160, loss=0.0264, recon=0.0264, kl=0.0009, beta=0.0006\n",
      "Batch 180, loss=0.0295, recon=0.0295, kl=0.0012, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0430, KL: 0.0034, Current Beta: 0.0006) | Avg Valid Loss: 0.0359 | Avg Valid recon Loss: 0.0359\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0286, recon=0.0286, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0232, recon=0.0232, kl=0.0040, beta=0.0010\n",
      "Batch 60, loss=0.0463, recon=0.0463, kl=0.0011, beta=0.0010\n",
      "Batch 80, loss=0.0453, recon=0.0452, kl=0.0007, beta=0.0010\n",
      "Batch 100, loss=0.0247, recon=0.0247, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0261, recon=0.0261, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0480, recon=0.0480, kl=0.0035, beta=0.0010\n",
      "Batch 160, loss=0.4453, recon=0.4453, kl=0.0026, beta=0.0010\n",
      "Batch 180, loss=0.0431, recon=0.0431, kl=0.0021, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0400, KL: 0.0018, Current Beta: 0.0010) | Avg Valid Loss: 0.0528 | Avg Valid recon Loss: 0.0528\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1211, recon=0.1211, kl=0.0009, beta=0.0010\n",
      "Batch 40, loss=0.0473, recon=0.0473, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0402, recon=0.0402, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0618, recon=0.0618, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.1021, recon=0.1021, kl=0.0152, beta=0.0010\n",
      "Batch 120, loss=0.0323, recon=0.0323, kl=0.0037, beta=0.0010\n",
      "Batch 140, loss=0.0412, recon=0.0412, kl=0.0021, beta=0.0010\n",
      "Batch 160, loss=0.1328, recon=0.1328, kl=0.0068, beta=0.0010\n",
      "Batch 180, loss=0.0245, recon=0.0245, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0502, KL: 0.0030, Current Beta: 0.0010) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0355\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0344, recon=0.0344, kl=0.0011, beta=0.0010\n",
      "Batch 40, loss=0.0317, recon=0.0317, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0604, recon=0.0604, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0266, recon=0.0266, kl=0.0010, beta=0.0010\n",
      "Batch 100, loss=0.1258, recon=0.1258, kl=0.0017, beta=0.0010\n",
      "Batch 120, loss=0.0602, recon=0.0602, kl=0.0011, beta=0.0010\n",
      "Batch 140, loss=0.0321, recon=0.0321, kl=0.0011, beta=0.0010\n",
      "Batch 160, loss=0.0656, recon=0.0656, kl=0.0006, beta=0.0010\n",
      "Batch 180, loss=0.0396, recon=0.0396, kl=0.0208, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0425, KL: 0.0019, Current Beta: 0.0010) | Avg Valid Loss: 0.0344 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0405, recon=0.0405, kl=0.0028, beta=0.0010\n",
      "Batch 40, loss=0.0280, recon=0.0280, kl=0.0011, beta=0.0010\n",
      "Batch 60, loss=0.0353, recon=0.0353, kl=0.0008, beta=0.0010\n",
      "Batch 80, loss=0.0466, recon=0.0466, kl=0.0004, beta=0.0010\n",
      "Batch 100, loss=0.0308, recon=0.0308, kl=0.0002, beta=0.0010\n",
      "Batch 120, loss=0.0386, recon=0.0386, kl=0.0006, beta=0.0010\n",
      "Batch 140, loss=0.0233, recon=0.0232, kl=0.0713, beta=0.0010\n",
      "Batch 160, loss=0.0313, recon=0.0313, kl=0.0164, beta=0.0010\n",
      "Batch 180, loss=0.0273, recon=0.0273, kl=0.0235, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 0.0121, Current Beta: 0.0010) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0354, recon=0.0354, kl=0.0015, beta=0.0010\n",
      "Batch 40, loss=0.0297, recon=0.0297, kl=0.0024, beta=0.0010\n",
      "Batch 60, loss=0.4190, recon=0.4190, kl=0.0009, beta=0.0010\n",
      "Batch 80, loss=0.0332, recon=0.0332, kl=0.0013, beta=0.0010\n",
      "Batch 100, loss=0.0282, recon=0.0282, kl=0.0007, beta=0.0010\n",
      "Batch 120, loss=0.0275, recon=0.0275, kl=0.0013, beta=0.0010\n",
      "Batch 140, loss=0.0287, recon=0.0287, kl=0.0023, beta=0.0010\n",
      "Batch 160, loss=0.0622, recon=0.0622, kl=0.0007, beta=0.0010\n",
      "Batch 180, loss=0.0309, recon=0.0309, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0401 (Recon: 0.0401, KL: 0.0020, Current Beta: 0.0010) | Avg Valid Loss: 0.0337 | Avg Valid recon Loss: 0.0337\n",
      "\n",
      "[VRAE Run 57/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6358, recon=0.6358, kl=0.5078, beta=0.0000\n",
      "Batch 40, loss=0.4982, recon=0.4982, kl=3.0840, beta=0.0000\n",
      "Batch 60, loss=0.3236, recon=0.3236, kl=13.3319, beta=0.0000\n",
      "Batch 80, loss=0.3860, recon=0.3860, kl=23.2513, beta=0.0000\n",
      "Batch 100, loss=0.2485, recon=0.2485, kl=30.5042, beta=0.0000\n",
      "Batch 120, loss=0.4402, recon=0.4402, kl=35.9411, beta=0.0000\n",
      "Batch 140, loss=0.3048, recon=0.3048, kl=41.5043, beta=0.0000\n",
      "Batch 160, loss=0.2062, recon=0.2062, kl=47.2901, beta=0.0000\n",
      "Batch 180, loss=0.1667, recon=0.1667, kl=50.8222, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4441 (Recon: 0.4441, KL: 24.8004, Current Beta: 0.0000) | Avg Valid Loss: 0.2237 | Avg Valid recon Loss: 0.2237\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2010, recon=0.2010, kl=53.8990, beta=0.0000\n",
      "Batch 40, loss=0.2145, recon=0.2145, kl=56.5928, beta=0.0000\n",
      "Batch 60, loss=0.1941, recon=0.1941, kl=59.1229, beta=0.0000\n",
      "Batch 80, loss=0.1228, recon=0.1228, kl=61.3242, beta=0.0000\n",
      "Batch 100, loss=0.1250, recon=0.1250, kl=63.0954, beta=0.0000\n",
      "Batch 120, loss=0.1876, recon=0.1876, kl=64.3559, beta=0.0000\n",
      "Batch 140, loss=0.1576, recon=0.1576, kl=66.4503, beta=0.0000\n",
      "Batch 160, loss=0.2024, recon=0.2024, kl=68.3013, beta=0.0000\n",
      "Batch 180, loss=0.1876, recon=0.1876, kl=69.5752, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1919 (Recon: 0.1919, KL: 61.6155, Current Beta: 0.0000) | Avg Valid Loss: 0.1401 | Avg Valid recon Loss: 0.1401\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.4251, recon=0.4251, kl=71.4937, beta=0.0000\n",
      "Batch 40, loss=0.1278, recon=0.1278, kl=72.9764, beta=0.0000\n",
      "Batch 60, loss=0.2611, recon=0.2611, kl=73.7851, beta=0.0000\n",
      "Batch 80, loss=0.1330, recon=0.1330, kl=74.6876, beta=0.0000\n",
      "Batch 100, loss=0.1856, recon=0.1856, kl=75.8512, beta=0.0000\n",
      "Batch 120, loss=0.1193, recon=0.1193, kl=77.4934, beta=0.0000\n",
      "Batch 140, loss=0.0795, recon=0.0795, kl=78.9491, beta=0.0000\n",
      "Batch 160, loss=0.1154, recon=0.1154, kl=80.2218, beta=0.0000\n",
      "Batch 180, loss=0.1947, recon=0.1947, kl=81.3331, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1378 (Recon: 0.1378, KL: 75.6912, Current Beta: 0.0000) | Avg Valid Loss: 0.1093 | Avg Valid recon Loss: 0.1093\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0799, recon=0.0799, kl=82.7265, beta=0.0000\n",
      "Batch 40, loss=0.0938, recon=0.0938, kl=83.9550, beta=0.0000\n",
      "Batch 60, loss=0.0888, recon=0.0887, kl=85.2711, beta=0.0000\n",
      "Batch 80, loss=0.0527, recon=0.0527, kl=85.3959, beta=0.0000\n",
      "Batch 100, loss=0.1053, recon=0.1053, kl=86.2008, beta=0.0000\n",
      "Batch 120, loss=0.0920, recon=0.0920, kl=87.9472, beta=0.0000\n",
      "Batch 140, loss=0.0932, recon=0.0932, kl=88.2698, beta=0.0000\n",
      "Batch 160, loss=0.0859, recon=0.0859, kl=88.0412, beta=0.0000\n",
      "Batch 180, loss=0.0671, recon=0.0671, kl=87.7790, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1128 (Recon: 0.1128, KL: 85.8463, Current Beta: 0.0000) | Avg Valid Loss: 0.0951 | Avg Valid recon Loss: 0.0951\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0866, recon=0.0866, kl=88.2626, beta=0.0000\n",
      "Batch 40, loss=0.0822, recon=0.0822, kl=88.3305, beta=0.0000\n",
      "Batch 60, loss=0.0675, recon=0.0675, kl=89.0854, beta=0.0000\n",
      "Batch 80, loss=0.0899, recon=0.0899, kl=89.4129, beta=0.0000\n",
      "Batch 100, loss=0.0608, recon=0.0608, kl=89.3580, beta=0.0000\n",
      "Batch 120, loss=0.5732, recon=0.5732, kl=89.4085, beta=0.0000\n",
      "Batch 140, loss=0.0675, recon=0.0675, kl=89.6179, beta=0.0000\n",
      "Batch 160, loss=0.0514, recon=0.0514, kl=90.1776, beta=0.0000\n",
      "Batch 180, loss=0.0626, recon=0.0626, kl=90.6588, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0989 (Recon: 0.0989, KL: 89.2196, Current Beta: 0.0000) | Avg Valid Loss: 0.0862 | Avg Valid recon Loss: 0.0862\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0815, recon=0.0815, kl=91.9468, beta=0.0000\n",
      "Batch 40, loss=0.0511, recon=0.0511, kl=91.1492, beta=0.0000\n",
      "Batch 60, loss=0.0579, recon=0.0579, kl=90.4302, beta=0.0000\n",
      "Batch 80, loss=0.0915, recon=0.0915, kl=90.5179, beta=0.0000\n",
      "Batch 100, loss=0.0682, recon=0.0682, kl=90.1755, beta=0.0000\n",
      "Batch 120, loss=0.0646, recon=0.0646, kl=89.0354, beta=0.0000\n",
      "Batch 140, loss=0.0876, recon=0.0876, kl=87.6958, beta=0.0000\n",
      "Batch 160, loss=0.0669, recon=0.0668, kl=86.4725, beta=0.0000\n",
      "Batch 180, loss=1.4751, recon=1.4751, kl=86.0542, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0900 (Recon: 0.0899, KL: 89.5006, Current Beta: 0.0000) | Avg Valid Loss: 0.0793 | Avg Valid recon Loss: 0.0793\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0674, recon=0.0674, kl=83.8927, beta=0.0000\n",
      "Batch 40, loss=0.0609, recon=0.0608, kl=81.6572, beta=0.0000\n",
      "Batch 60, loss=0.0558, recon=0.0557, kl=78.1486, beta=0.0000\n",
      "Batch 80, loss=0.0573, recon=0.0572, kl=74.7984, beta=0.0000\n",
      "Batch 100, loss=0.0847, recon=0.0847, kl=73.2019, beta=0.0000\n",
      "Batch 120, loss=0.0800, recon=0.0800, kl=70.8011, beta=0.0000\n",
      "Batch 140, loss=0.0366, recon=0.0366, kl=69.2933, beta=0.0000\n",
      "Batch 160, loss=0.0977, recon=0.0976, kl=65.6100, beta=0.0000\n",
      "Batch 180, loss=0.0928, recon=0.0928, kl=64.2261, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0832 (Recon: 0.0832, KL: 74.6148, Current Beta: 0.0000) | Avg Valid Loss: 0.0733 | Avg Valid recon Loss: 0.0733\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0662, recon=0.0661, kl=52.2274, beta=0.0000\n",
      "Batch 40, loss=0.0747, recon=0.0746, kl=52.6707, beta=0.0000\n",
      "Batch 60, loss=0.0637, recon=0.0636, kl=47.4927, beta=0.0000\n",
      "Batch 80, loss=0.0596, recon=0.0596, kl=43.6570, beta=0.0000\n",
      "Batch 100, loss=0.0584, recon=0.0584, kl=40.4663, beta=0.0000\n",
      "Batch 120, loss=0.0562, recon=0.0561, kl=41.3071, beta=0.0000\n",
      "Batch 140, loss=0.1147, recon=0.1147, kl=41.0664, beta=0.0000\n",
      "Batch 160, loss=0.1393, recon=0.1393, kl=39.9220, beta=0.0000\n",
      "Batch 180, loss=0.0454, recon=0.0454, kl=38.3307, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0785 (Recon: 0.0784, KL: 45.5707, Current Beta: 0.0000) | Avg Valid Loss: 0.0690 | Avg Valid recon Loss: 0.0690\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0764, recon=0.0763, kl=28.6919, beta=0.0000\n",
      "Batch 40, loss=0.0895, recon=0.0894, kl=25.2959, beta=0.0000\n",
      "Batch 60, loss=0.0413, recon=0.0412, kl=24.4172, beta=0.0000\n",
      "Batch 80, loss=0.0430, recon=0.0429, kl=23.6457, beta=0.0000\n",
      "Batch 100, loss=0.1290, recon=0.1289, kl=20.8825, beta=0.0000\n",
      "Batch 120, loss=0.0498, recon=0.0497, kl=22.0018, beta=0.0000\n",
      "Batch 140, loss=0.0769, recon=0.0769, kl=21.9075, beta=0.0000\n",
      "Batch 160, loss=0.0433, recon=0.0432, kl=19.5443, beta=0.0000\n",
      "Batch 180, loss=0.0545, recon=0.0544, kl=20.0033, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0748 (Recon: 0.0747, KL: 23.8337, Current Beta: 0.0000) | Avg Valid Loss: 0.0648 | Avg Valid recon Loss: 0.0648\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0677, recon=0.0675, kl=11.0100, beta=0.0000\n",
      "Batch 40, loss=0.0590, recon=0.0589, kl=10.6865, beta=0.0000\n",
      "Batch 60, loss=0.0440, recon=0.0439, kl=10.3344, beta=0.0000\n",
      "Batch 80, loss=0.0500, recon=0.0499, kl=9.3617, beta=0.0000\n",
      "Batch 100, loss=0.0466, recon=0.0465, kl=8.2964, beta=0.0000\n",
      "Batch 120, loss=0.0951, recon=0.0950, kl=8.6689, beta=0.0000\n",
      "Batch 140, loss=0.3386, recon=0.3385, kl=7.5920, beta=0.0000\n",
      "Batch 160, loss=0.0384, recon=0.0383, kl=8.4290, beta=0.0000\n",
      "Batch 180, loss=0.0427, recon=0.0426, kl=7.1061, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0713 (Recon: 0.0712, KL: 9.6896, Current Beta: 0.0000) | Avg Valid Loss: 0.0631 | Avg Valid recon Loss: 0.0630\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0417, recon=0.0416, kl=3.7095, beta=0.0000\n",
      "Batch 40, loss=0.0448, recon=0.0447, kl=3.0246, beta=0.0000\n",
      "Batch 60, loss=0.0524, recon=0.0524, kl=2.8185, beta=0.0000\n",
      "Batch 80, loss=0.0609, recon=0.0608, kl=2.5517, beta=0.0000\n",
      "Batch 100, loss=0.0480, recon=0.0479, kl=2.3650, beta=0.0000\n",
      "Batch 120, loss=0.0430, recon=0.0429, kl=2.6602, beta=0.0000\n",
      "Batch 140, loss=0.0383, recon=0.0382, kl=2.2535, beta=0.0000\n",
      "Batch 160, loss=0.0671, recon=0.0671, kl=2.6425, beta=0.0000\n",
      "Batch 180, loss=0.0471, recon=0.0471, kl=1.8641, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0689 (Recon: 0.0689, KL: 2.8633, Current Beta: 0.0000) | Avg Valid Loss: 0.0600 | Avg Valid recon Loss: 0.0600\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0548, recon=0.0547, kl=0.9362, beta=0.0001\n",
      "Batch 40, loss=0.0586, recon=0.0586, kl=0.6876, beta=0.0001\n",
      "Batch 60, loss=0.0467, recon=0.0467, kl=0.7282, beta=0.0001\n",
      "Batch 80, loss=0.0375, recon=0.0374, kl=0.4817, beta=0.0001\n",
      "Batch 100, loss=0.0337, recon=0.0336, kl=0.5009, beta=0.0001\n",
      "Batch 120, loss=0.0529, recon=0.0529, kl=0.5211, beta=0.0001\n",
      "Batch 140, loss=0.0429, recon=0.0429, kl=0.4464, beta=0.0001\n",
      "Batch 160, loss=0.0712, recon=0.0712, kl=0.3459, beta=0.0001\n",
      "Batch 180, loss=0.0425, recon=0.0425, kl=0.3663, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0663 (Recon: 0.0662, KL: 0.5988, Current Beta: 0.0001) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0574\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0453, recon=0.0453, kl=0.1588, beta=0.0002\n",
      "Batch 40, loss=0.1234, recon=0.1233, kl=0.1223, beta=0.0002\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=0.1031, beta=0.0002\n",
      "Batch 80, loss=0.0342, recon=0.0342, kl=0.0634, beta=0.0002\n",
      "Batch 100, loss=0.0559, recon=0.0559, kl=0.0379, beta=0.0002\n",
      "Batch 120, loss=0.0371, recon=0.0371, kl=0.0447, beta=0.0002\n",
      "Batch 140, loss=0.0447, recon=0.0447, kl=0.0494, beta=0.0002\n",
      "Batch 160, loss=0.0515, recon=0.0515, kl=0.0377, beta=0.0002\n",
      "Batch 180, loss=0.0514, recon=0.0514, kl=0.0313, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0644 (Recon: 0.0644, KL: 0.0824, Current Beta: 0.0002) | Avg Valid Loss: 0.0567 | Avg Valid recon Loss: 0.0567\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0629, recon=0.0629, kl=0.0274, beta=0.0004\n",
      "Batch 40, loss=0.0604, recon=0.0604, kl=0.0092, beta=0.0004\n",
      "Batch 60, loss=0.0523, recon=0.0523, kl=0.0050, beta=0.0004\n",
      "Batch 80, loss=0.1498, recon=0.1498, kl=0.0043, beta=0.0004\n",
      "Batch 100, loss=0.0446, recon=0.0446, kl=0.0045, beta=0.0004\n",
      "Batch 120, loss=0.0599, recon=0.0599, kl=0.0049, beta=0.0004\n",
      "Batch 140, loss=0.0517, recon=0.0517, kl=0.0031, beta=0.0004\n",
      "Batch 160, loss=0.0546, recon=0.0546, kl=0.0041, beta=0.0004\n",
      "Batch 180, loss=0.0490, recon=0.0490, kl=0.0027, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0625 (Recon: 0.0625, KL: 0.0069, Current Beta: 0.0004) | Avg Valid Loss: 0.0546 | Avg Valid recon Loss: 0.0546\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0954, recon=0.0954, kl=0.0041, beta=0.0006\n",
      "Batch 40, loss=0.0479, recon=0.0479, kl=0.0020, beta=0.0006\n",
      "Batch 60, loss=1.1143, recon=1.1143, kl=0.0004, beta=0.0006\n",
      "Batch 80, loss=0.0501, recon=0.0501, kl=0.0012, beta=0.0006\n",
      "Batch 100, loss=0.0395, recon=0.0395, kl=0.0017, beta=0.0006\n",
      "Batch 120, loss=0.0330, recon=0.0330, kl=0.0006, beta=0.0006\n",
      "Batch 140, loss=0.0582, recon=0.0582, kl=0.0005, beta=0.0006\n",
      "Batch 160, loss=0.0501, recon=0.0501, kl=0.0004, beta=0.0006\n",
      "Batch 180, loss=0.0380, recon=0.0380, kl=0.0010, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0609 (Recon: 0.0609, KL: 0.0015, Current Beta: 0.0006) | Avg Valid Loss: 0.0536 | Avg Valid recon Loss: 0.0536\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0449, recon=0.0449, kl=0.0005, beta=0.0010\n",
      "Batch 40, loss=0.1582, recon=0.1582, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0704, recon=0.0704, kl=0.0006, beta=0.0010\n",
      "Batch 80, loss=0.0501, recon=0.0501, kl=0.0016, beta=0.0010\n",
      "Batch 100, loss=0.0470, recon=0.0470, kl=0.0007, beta=0.0010\n",
      "Batch 120, loss=0.0777, recon=0.0777, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0557, recon=0.0557, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0400, recon=0.0400, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0308, recon=0.0308, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0595 (Recon: 0.0595, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0519 | Avg Valid recon Loss: 0.0519\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0438, recon=0.0438, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.1263, recon=0.1263, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0390, recon=0.0390, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0457, recon=0.0457, kl=0.0003, beta=0.0010\n",
      "Batch 100, loss=0.0472, recon=0.0472, kl=0.0002, beta=0.0010\n",
      "Batch 120, loss=0.0655, recon=0.0655, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0481, recon=0.0481, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.1011, recon=0.1011, kl=0.0001, beta=0.0010\n",
      "Batch 180, loss=0.0400, recon=0.0400, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0581, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0309, recon=0.0309, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0527, recon=0.0527, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.1265, recon=0.1265, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0344, recon=0.0344, kl=0.0001, beta=0.0010\n",
      "Batch 100, loss=0.0652, recon=0.0652, kl=0.0024, beta=0.0010\n",
      "Batch 120, loss=0.0515, recon=0.0515, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0416, recon=0.0416, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0417, recon=0.0417, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0416, recon=0.0416, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0498 | Avg Valid recon Loss: 0.0498\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0759, recon=0.0759, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0381, recon=0.0381, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0296, recon=0.0296, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0360, recon=0.0360, kl=0.0001, beta=0.0010\n",
      "Batch 100, loss=0.0889, recon=0.0889, kl=0.0005, beta=0.0010\n",
      "Batch 120, loss=0.0633, recon=0.0633, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0393, recon=0.0393, kl=0.0001, beta=0.0010\n",
      "Batch 160, loss=0.0304, recon=0.0304, kl=0.0001, beta=0.0010\n",
      "Batch 180, loss=0.0407, recon=0.0407, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0487 | Avg Valid recon Loss: 0.0487\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0267, recon=0.0267, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0268, recon=0.0268, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0350, recon=0.0350, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0484, recon=0.0484, kl=0.0001, beta=0.0010\n",
      "Batch 100, loss=0.0421, recon=0.0421, kl=0.0002, beta=0.0010\n",
      "Batch 120, loss=0.0399, recon=0.0399, kl=0.0001, beta=0.0010\n",
      "Batch 140, loss=0.0350, recon=0.0350, kl=0.0001, beta=0.0010\n",
      "Batch 160, loss=0.0337, recon=0.0337, kl=0.0001, beta=0.0010\n",
      "Batch 180, loss=0.0584, recon=0.0584, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0543 (Recon: 0.0543, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.0475 | Avg Valid recon Loss: 0.0475\n",
      "\n",
      "[VRAE Run 58/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3770, recon=0.3770, kl=28.6152, beta=0.0000\n",
      "Batch 40, loss=0.1570, recon=0.1570, kl=56.1862, beta=0.0000\n",
      "Batch 60, loss=0.1304, recon=0.1304, kl=62.1218, beta=0.0000\n",
      "Batch 80, loss=0.0921, recon=0.0921, kl=60.8803, beta=0.0000\n",
      "Batch 100, loss=0.0817, recon=0.0817, kl=59.2016, beta=0.0000\n",
      "Batch 120, loss=0.0768, recon=0.0768, kl=58.9098, beta=0.0000\n",
      "Batch 140, loss=0.1103, recon=0.1103, kl=58.6215, beta=0.0000\n",
      "Batch 160, loss=0.0527, recon=0.0527, kl=64.0357, beta=0.0000\n",
      "Batch 180, loss=0.4386, recon=0.4386, kl=66.8727, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1704 (Recon: 0.1704, KL: 54.0423, Current Beta: 0.0000) | Avg Valid Loss: 0.0745 | Avg Valid recon Loss: 0.0745\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0461, recon=0.0461, kl=71.0130, beta=0.0000\n",
      "Batch 40, loss=0.0578, recon=0.0578, kl=72.5062, beta=0.0000\n",
      "Batch 60, loss=0.0409, recon=0.0409, kl=72.5775, beta=0.0000\n",
      "Batch 80, loss=0.0776, recon=0.0776, kl=73.7898, beta=0.0000\n",
      "Batch 100, loss=0.1089, recon=0.1089, kl=66.8552, beta=0.0000\n",
      "Batch 120, loss=0.0525, recon=0.0525, kl=60.5208, beta=0.0000\n",
      "Batch 140, loss=0.0773, recon=0.0773, kl=60.4662, beta=0.0000\n",
      "Batch 160, loss=0.0643, recon=0.0643, kl=64.8009, beta=0.0000\n",
      "Batch 180, loss=0.0474, recon=0.0474, kl=72.7591, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0721 (Recon: 0.0721, KL: 67.9350, Current Beta: 0.0000) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0574\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0304, recon=0.0304, kl=69.6975, beta=0.0000\n",
      "Batch 40, loss=0.0495, recon=0.0495, kl=70.7996, beta=0.0000\n",
      "Batch 60, loss=0.0354, recon=0.0354, kl=76.4306, beta=0.0000\n",
      "Batch 80, loss=0.0306, recon=0.0306, kl=78.3713, beta=0.0000\n",
      "Batch 100, loss=0.0457, recon=0.0457, kl=55.8620, beta=0.0000\n",
      "Batch 120, loss=0.0510, recon=0.0510, kl=54.9585, beta=0.0000\n",
      "Batch 140, loss=0.0854, recon=0.0854, kl=66.2440, beta=0.0000\n",
      "Batch 160, loss=0.1169, recon=0.1169, kl=70.9684, beta=0.0000\n",
      "Batch 180, loss=0.0296, recon=0.0296, kl=74.0295, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0616 (Recon: 0.0616, KL: 68.5726, Current Beta: 0.0000) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0461, recon=0.0461, kl=73.7878, beta=0.0000\n",
      "Batch 40, loss=0.0437, recon=0.0437, kl=75.2501, beta=0.0000\n",
      "Batch 60, loss=0.0414, recon=0.0414, kl=77.0048, beta=0.0000\n",
      "Batch 80, loss=0.0680, recon=0.0680, kl=75.0026, beta=0.0000\n",
      "Batch 100, loss=0.0392, recon=0.0392, kl=70.7507, beta=0.0000\n",
      "Batch 120, loss=0.1921, recon=0.1921, kl=70.9730, beta=0.0000\n",
      "Batch 140, loss=0.0463, recon=0.0463, kl=71.6763, beta=0.0000\n",
      "Batch 160, loss=0.0385, recon=0.0385, kl=63.1997, beta=0.0000\n",
      "Batch 180, loss=0.0390, recon=0.0390, kl=61.1257, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0544 (Recon: 0.0544, KL: 71.7263, Current Beta: 0.0000) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0465\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0349, recon=0.0349, kl=65.4012, beta=0.0000\n",
      "Batch 40, loss=0.0371, recon=0.0371, kl=68.0928, beta=0.0000\n",
      "Batch 60, loss=0.0359, recon=0.0359, kl=67.3307, beta=0.0000\n",
      "Batch 80, loss=0.0280, recon=0.0280, kl=68.8330, beta=0.0000\n",
      "Batch 100, loss=0.0466, recon=0.0466, kl=67.8538, beta=0.0000\n",
      "Batch 120, loss=0.0506, recon=0.0506, kl=69.7318, beta=0.0000\n",
      "Batch 140, loss=0.0342, recon=0.0341, kl=61.1263, beta=0.0000\n",
      "Batch 160, loss=0.0707, recon=0.0707, kl=56.7576, beta=0.0000\n",
      "Batch 180, loss=0.0438, recon=0.0438, kl=64.7965, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0490 (Recon: 0.0490, KL: 65.0963, Current Beta: 0.0000) | Avg Valid Loss: 0.0523 | Avg Valid recon Loss: 0.0523\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0587, recon=0.0587, kl=68.9951, beta=0.0000\n",
      "Batch 40, loss=0.0556, recon=0.0556, kl=65.9294, beta=0.0000\n",
      "Batch 60, loss=0.0610, recon=0.0610, kl=59.8772, beta=0.0000\n",
      "Batch 80, loss=0.0293, recon=0.0292, kl=61.4928, beta=0.0000\n",
      "Batch 100, loss=0.0362, recon=0.0362, kl=59.5887, beta=0.0000\n",
      "Batch 120, loss=0.7804, recon=0.7804, kl=57.7161, beta=0.0000\n",
      "Batch 140, loss=0.1441, recon=0.1440, kl=57.4241, beta=0.0000\n",
      "Batch 160, loss=0.0515, recon=0.0515, kl=62.8438, beta=0.0000\n",
      "Batch 180, loss=0.0417, recon=0.0417, kl=59.4031, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0571 (Recon: 0.0571, KL: 61.7248, Current Beta: 0.0000) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0536\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=56.3159, beta=0.0000\n",
      "Batch 40, loss=0.1064, recon=0.1064, kl=52.0449, beta=0.0000\n",
      "Batch 60, loss=0.0359, recon=0.0358, kl=49.9107, beta=0.0000\n",
      "Batch 80, loss=0.0493, recon=0.0492, kl=53.0330, beta=0.0000\n",
      "Batch 100, loss=0.0304, recon=0.0304, kl=58.3142, beta=0.0000\n",
      "Batch 120, loss=0.0328, recon=0.0327, kl=51.3595, beta=0.0000\n",
      "Batch 140, loss=0.0435, recon=0.0435, kl=47.9155, beta=0.0000\n",
      "Batch 160, loss=0.0436, recon=0.0436, kl=49.0705, beta=0.0000\n",
      "Batch 180, loss=0.0284, recon=0.0284, kl=45.6594, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0520 (Recon: 0.0520, KL: 51.9921, Current Beta: 0.0000) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0379, recon=0.0379, kl=34.5033, beta=0.0000\n",
      "Batch 40, loss=0.0545, recon=0.0544, kl=31.4865, beta=0.0000\n",
      "Batch 60, loss=0.0238, recon=0.0237, kl=44.6070, beta=0.0000\n",
      "Batch 80, loss=0.0409, recon=0.0408, kl=41.0818, beta=0.0000\n",
      "Batch 100, loss=0.0342, recon=0.0341, kl=57.0429, beta=0.0000\n",
      "Batch 120, loss=0.0479, recon=0.0478, kl=51.6777, beta=0.0000\n",
      "Batch 140, loss=0.0284, recon=0.0283, kl=49.2478, beta=0.0000\n",
      "Batch 160, loss=0.0723, recon=0.0723, kl=46.8770, beta=0.0000\n",
      "Batch 180, loss=0.0323, recon=0.0323, kl=45.4201, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0474 (Recon: 0.0474, KL: 44.0977, Current Beta: 0.0000) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0384\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0388, recon=0.0387, kl=31.5246, beta=0.0000\n",
      "Batch 40, loss=0.0260, recon=0.0259, kl=27.4414, beta=0.0000\n",
      "Batch 60, loss=0.0275, recon=0.0274, kl=29.7723, beta=0.0000\n",
      "Batch 80, loss=0.0445, recon=0.0443, kl=39.7885, beta=0.0000\n",
      "Batch 100, loss=0.0279, recon=0.0277, kl=33.9350, beta=0.0000\n",
      "Batch 120, loss=0.0380, recon=0.0378, kl=31.0739, beta=0.0000\n",
      "Batch 140, loss=0.0281, recon=0.0280, kl=27.0342, beta=0.0000\n",
      "Batch 160, loss=0.0429, recon=0.0428, kl=26.5051, beta=0.0000\n",
      "Batch 180, loss=0.0280, recon=0.0279, kl=22.6595, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0422, KL: 31.0018, Current Beta: 0.0000) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0414, recon=0.0412, kl=16.5920, beta=0.0000\n",
      "Batch 40, loss=0.0527, recon=0.0525, kl=17.5787, beta=0.0000\n",
      "Batch 60, loss=0.0766, recon=0.0765, kl=13.6710, beta=0.0000\n",
      "Batch 80, loss=0.0496, recon=0.0495, kl=11.4900, beta=0.0000\n",
      "Batch 100, loss=0.0346, recon=0.0344, kl=24.6425, beta=0.0000\n",
      "Batch 120, loss=0.0696, recon=0.0694, kl=19.3409, beta=0.0000\n",
      "Batch 140, loss=0.0388, recon=0.0386, kl=14.7523, beta=0.0000\n",
      "Batch 160, loss=0.0520, recon=0.0519, kl=12.4330, beta=0.0000\n",
      "Batch 180, loss=0.0480, recon=0.0478, kl=12.8771, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0559 (Recon: 0.0557, KL: 16.3895, Current Beta: 0.0000) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0388, recon=0.0386, kl=8.9045, beta=0.0000\n",
      "Batch 40, loss=0.0366, recon=0.0364, kl=6.4892, beta=0.0000\n",
      "Batch 60, loss=0.1495, recon=0.1493, kl=5.2076, beta=0.0000\n",
      "Batch 80, loss=0.0389, recon=0.0388, kl=4.4006, beta=0.0000\n",
      "Batch 100, loss=0.0304, recon=0.0303, kl=3.7774, beta=0.0000\n",
      "Batch 120, loss=0.0324, recon=0.0323, kl=3.1950, beta=0.0000\n",
      "Batch 140, loss=0.0285, recon=0.0284, kl=4.3938, beta=0.0000\n",
      "Batch 160, loss=0.0433, recon=0.0432, kl=4.6694, beta=0.0000\n",
      "Batch 180, loss=0.0301, recon=0.0300, kl=4.0879, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0457, KL: 5.4986, Current Beta: 0.0000) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0349, recon=0.0348, kl=2.0946, beta=0.0001\n",
      "Batch 40, loss=0.0533, recon=0.0532, kl=0.8119, beta=0.0001\n",
      "Batch 60, loss=0.0293, recon=0.0292, kl=0.7226, beta=0.0001\n",
      "Batch 80, loss=0.0703, recon=0.0702, kl=0.9541, beta=0.0001\n",
      "Batch 100, loss=0.0388, recon=0.0388, kl=0.9284, beta=0.0001\n",
      "Batch 120, loss=0.0273, recon=0.0272, kl=0.6599, beta=0.0001\n",
      "Batch 140, loss=0.0566, recon=0.0566, kl=0.4204, beta=0.0001\n",
      "Batch 160, loss=0.0337, recon=0.0337, kl=0.2358, beta=0.0001\n",
      "Batch 180, loss=0.0371, recon=0.0371, kl=0.3514, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0496, KL: 0.9755, Current Beta: 0.0001) | Avg Valid Loss: 0.0362 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1269, recon=0.1268, kl=0.5872, beta=0.0002\n",
      "Batch 40, loss=0.0235, recon=0.0235, kl=0.3050, beta=0.0002\n",
      "Batch 60, loss=0.0238, recon=0.0238, kl=0.0735, beta=0.0002\n",
      "Batch 80, loss=0.0718, recon=0.0718, kl=0.0597, beta=0.0002\n",
      "Batch 100, loss=0.0579, recon=0.0579, kl=0.0935, beta=0.0002\n",
      "Batch 120, loss=0.0251, recon=0.0251, kl=0.0427, beta=0.0002\n",
      "Batch 140, loss=0.0379, recon=0.0379, kl=0.0355, beta=0.0002\n",
      "Batch 160, loss=0.0380, recon=0.0380, kl=0.0365, beta=0.0002\n",
      "Batch 180, loss=0.0302, recon=0.0302, kl=0.0222, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0443 (Recon: 0.0443, KL: 0.1631, Current Beta: 0.0002) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0381, recon=0.0381, kl=0.0032, beta=0.0004\n",
      "Batch 40, loss=0.0408, recon=0.0408, kl=0.0045, beta=0.0004\n",
      "Batch 60, loss=0.0366, recon=0.0366, kl=0.0068, beta=0.0004\n",
      "Batch 80, loss=0.0255, recon=0.0255, kl=0.0399, beta=0.0004\n",
      "Batch 100, loss=0.1182, recon=0.1182, kl=0.0480, beta=0.0004\n",
      "Batch 120, loss=0.0235, recon=0.0235, kl=0.0101, beta=0.0004\n",
      "Batch 140, loss=0.0262, recon=0.0262, kl=0.0107, beta=0.0004\n",
      "Batch 160, loss=0.0440, recon=0.0440, kl=0.0058, beta=0.0004\n",
      "Batch 180, loss=0.0332, recon=0.0332, kl=0.0033, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0413, KL: 0.0154, Current Beta: 0.0004) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0390, recon=0.0389, kl=0.0415, beta=0.0006\n",
      "Batch 40, loss=0.0200, recon=0.0199, kl=0.0130, beta=0.0006\n",
      "Batch 60, loss=0.0980, recon=0.0980, kl=0.0165, beta=0.0006\n",
      "Batch 80, loss=0.0383, recon=0.0383, kl=0.0039, beta=0.0006\n",
      "Batch 100, loss=0.0202, recon=0.0202, kl=0.0019, beta=0.0006\n",
      "Batch 120, loss=0.0293, recon=0.0293, kl=0.0009, beta=0.0006\n",
      "Batch 140, loss=0.0273, recon=0.0273, kl=0.0018, beta=0.0006\n",
      "Batch 160, loss=0.0277, recon=0.0277, kl=0.0032, beta=0.0006\n",
      "Batch 180, loss=0.0285, recon=0.0285, kl=0.0031, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 0.0090, Current Beta: 0.0006) | Avg Valid Loss: 0.0323 | Avg Valid recon Loss: 0.0323\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0165, recon=0.0165, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0415, recon=0.0415, kl=0.0037, beta=0.0010\n",
      "Batch 60, loss=0.0588, recon=0.0588, kl=0.0080, beta=0.0010\n",
      "Batch 80, loss=0.0291, recon=0.0291, kl=0.0048, beta=0.0010\n",
      "Batch 100, loss=0.0405, recon=0.0405, kl=0.0007, beta=0.0010\n",
      "Batch 120, loss=0.0214, recon=0.0214, kl=0.0007, beta=0.0010\n",
      "Batch 140, loss=0.0238, recon=0.0238, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0338, recon=0.0338, kl=0.0007, beta=0.0010\n",
      "Batch 180, loss=0.0309, recon=0.0309, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 0.0019, Current Beta: 0.0010) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0262, recon=0.0262, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0302, recon=0.0302, kl=0.0010, beta=0.0010\n",
      "Batch 60, loss=0.0333, recon=0.0333, kl=0.0035, beta=0.0010\n",
      "Batch 80, loss=0.0423, recon=0.0423, kl=0.0011, beta=0.0010\n",
      "Batch 100, loss=0.0398, recon=0.0398, kl=0.0007, beta=0.0010\n",
      "Batch 120, loss=0.0446, recon=0.0446, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0253, recon=0.0253, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0251, recon=0.0251, kl=0.0007, beta=0.0010\n",
      "Batch 180, loss=0.0252, recon=0.0252, kl=0.0020, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 0.0013, Current Beta: 0.0010) | Avg Valid Loss: 0.0310 | Avg Valid recon Loss: 0.0310\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0235, recon=0.0235, kl=0.0008, beta=0.0010\n",
      "Batch 40, loss=0.0285, recon=0.0285, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0420, recon=0.0420, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.0678, recon=0.0678, kl=0.0016, beta=0.0010\n",
      "Batch 100, loss=0.0464, recon=0.0464, kl=0.0071, beta=0.0010\n",
      "Batch 120, loss=0.0337, recon=0.0337, kl=0.0030, beta=0.0010\n",
      "Batch 140, loss=0.0445, recon=0.0445, kl=0.0177, beta=0.0010\n",
      "Batch 160, loss=0.0306, recon=0.0306, kl=0.0074, beta=0.0010\n",
      "Batch 180, loss=0.0326, recon=0.0326, kl=0.0014, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0383 (Recon: 0.0383, KL: 0.0056, Current Beta: 0.0010) | Avg Valid Loss: 0.0306 | Avg Valid recon Loss: 0.0306\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0448, recon=0.0448, kl=0.0080, beta=0.0010\n",
      "Batch 40, loss=0.0324, recon=0.0324, kl=0.0009, beta=0.0010\n",
      "Batch 60, loss=0.0211, recon=0.0211, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0651, recon=0.0651, kl=0.0004, beta=0.0010\n",
      "Batch 100, loss=0.0306, recon=0.0306, kl=0.0007, beta=0.0010\n",
      "Batch 120, loss=0.0372, recon=0.0372, kl=0.0008, beta=0.0010\n",
      "Batch 140, loss=0.0500, recon=0.0500, kl=0.0007, beta=0.0010\n",
      "Batch 160, loss=0.0365, recon=0.0365, kl=0.0202, beta=0.0010\n",
      "Batch 180, loss=0.0507, recon=0.0507, kl=0.0039, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0425, KL: 0.0034, Current Beta: 0.0010) | Avg Valid Loss: 0.0611 | Avg Valid recon Loss: 0.0611\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0460, recon=0.0460, kl=0.0166, beta=0.0010\n",
      "Batch 40, loss=0.0557, recon=0.0557, kl=0.0136, beta=0.0010\n",
      "Batch 60, loss=0.0450, recon=0.0450, kl=0.0033, beta=0.0010\n",
      "Batch 80, loss=0.0644, recon=0.0644, kl=0.0040, beta=0.0010\n",
      "Batch 100, loss=0.0391, recon=0.0391, kl=0.0089, beta=0.0010\n",
      "Batch 120, loss=0.0560, recon=0.0560, kl=0.0043, beta=0.0010\n",
      "Batch 140, loss=0.0540, recon=0.0540, kl=0.0079, beta=0.0010\n",
      "Batch 160, loss=0.0328, recon=0.0328, kl=0.0027, beta=0.0010\n",
      "Batch 180, loss=0.0301, recon=0.0301, kl=0.0051, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0567 (Recon: 0.0567, KL: 0.0069, Current Beta: 0.0010) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "\n",
      "[VRAE Run 59/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7366, recon=0.7366, kl=0.8307, beta=0.0000\n",
      "Batch 40, loss=0.4896, recon=0.4896, kl=2.3685, beta=0.0000\n",
      "Batch 60, loss=0.4140, recon=0.4140, kl=17.4022, beta=0.0000\n",
      "Batch 80, loss=0.6153, recon=0.6153, kl=36.4195, beta=0.0000\n",
      "Batch 100, loss=0.2649, recon=0.2649, kl=50.9827, beta=0.0000\n",
      "Batch 120, loss=0.1902, recon=0.1902, kl=61.6096, beta=0.0000\n",
      "Batch 140, loss=0.2092, recon=0.2092, kl=69.9449, beta=0.0000\n",
      "Batch 160, loss=0.2084, recon=0.2084, kl=77.5143, beta=0.0000\n",
      "Batch 180, loss=0.3381, recon=0.3381, kl=82.7162, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4215 (Recon: 0.4215, KL: 40.2892, Current Beta: 0.0000) | Avg Valid Loss: 0.2112 | Avg Valid recon Loss: 0.2112\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2507, recon=0.2507, kl=90.6169, beta=0.0000\n",
      "Batch 40, loss=0.1675, recon=0.1675, kl=93.9505, beta=0.0000\n",
      "Batch 60, loss=0.1728, recon=0.1728, kl=97.8013, beta=0.0000\n",
      "Batch 80, loss=0.1517, recon=0.1517, kl=101.8579, beta=0.0000\n",
      "Batch 100, loss=0.1265, recon=0.1265, kl=105.3897, beta=0.0000\n",
      "Batch 120, loss=0.1333, recon=0.1333, kl=108.8543, beta=0.0000\n",
      "Batch 140, loss=0.1655, recon=0.1655, kl=112.2310, beta=0.0000\n",
      "Batch 160, loss=0.1950, recon=0.1950, kl=115.7369, beta=0.0000\n",
      "Batch 180, loss=0.1460, recon=0.1460, kl=119.6790, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1862 (Recon: 0.1862, KL: 103.3776, Current Beta: 0.0000) | Avg Valid Loss: 0.1371 | Avg Valid recon Loss: 0.1371\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1027, recon=0.1027, kl=123.7536, beta=0.0000\n",
      "Batch 40, loss=0.1596, recon=0.1596, kl=125.4181, beta=0.0000\n",
      "Batch 60, loss=0.2514, recon=0.2514, kl=126.6169, beta=0.0000\n",
      "Batch 80, loss=0.1059, recon=0.1059, kl=128.5796, beta=0.0000\n",
      "Batch 100, loss=0.1070, recon=0.1070, kl=131.6860, beta=0.0000\n",
      "Batch 120, loss=0.1198, recon=0.1198, kl=133.7312, beta=0.0000\n",
      "Batch 140, loss=0.0891, recon=0.0891, kl=135.4574, beta=0.0000\n",
      "Batch 160, loss=0.1084, recon=0.1084, kl=138.0524, beta=0.0000\n",
      "Batch 180, loss=0.0630, recon=0.0630, kl=140.6863, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1363 (Recon: 0.1363, KL: 130.5794, Current Beta: 0.0000) | Avg Valid Loss: 0.1093 | Avg Valid recon Loss: 0.1093\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0535, recon=0.0535, kl=142.5638, beta=0.0000\n",
      "Batch 40, loss=0.0906, recon=0.0906, kl=144.9434, beta=0.0000\n",
      "Batch 60, loss=0.0660, recon=0.0660, kl=146.6088, beta=0.0000\n",
      "Batch 80, loss=0.0660, recon=0.0660, kl=148.5654, beta=0.0000\n",
      "Batch 100, loss=0.1214, recon=0.1214, kl=150.7571, beta=0.0000\n",
      "Batch 120, loss=0.0852, recon=0.0852, kl=152.5661, beta=0.0000\n",
      "Batch 140, loss=0.0991, recon=0.0991, kl=154.3442, beta=0.0000\n",
      "Batch 160, loss=0.0511, recon=0.0511, kl=155.1514, beta=0.0000\n",
      "Batch 180, loss=0.0536, recon=0.0536, kl=156.3017, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1117 (Recon: 0.1117, KL: 149.4547, Current Beta: 0.0000) | Avg Valid Loss: 0.0926 | Avg Valid recon Loss: 0.0926\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0871, recon=0.0870, kl=157.9262, beta=0.0000\n",
      "Batch 40, loss=0.1621, recon=0.1621, kl=158.3659, beta=0.0000\n",
      "Batch 60, loss=0.1009, recon=0.1009, kl=157.8620, beta=0.0000\n",
      "Batch 80, loss=0.0577, recon=0.0577, kl=157.5934, beta=0.0000\n",
      "Batch 100, loss=0.1049, recon=0.1049, kl=158.3823, beta=0.0000\n",
      "Batch 120, loss=0.0972, recon=0.0972, kl=158.4540, beta=0.0000\n",
      "Batch 140, loss=0.0795, recon=0.0795, kl=158.7115, beta=0.0000\n",
      "Batch 160, loss=0.0886, recon=0.0886, kl=158.0754, beta=0.0000\n",
      "Batch 180, loss=0.0812, recon=0.0812, kl=157.9235, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0974 (Recon: 0.0974, KL: 157.9508, Current Beta: 0.0000) | Avg Valid Loss: 0.0832 | Avg Valid recon Loss: 0.0832\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0838, recon=0.0838, kl=156.2486, beta=0.0000\n",
      "Batch 40, loss=0.0845, recon=0.0844, kl=154.0601, beta=0.0000\n",
      "Batch 60, loss=0.1535, recon=0.1535, kl=150.1259, beta=0.0000\n",
      "Batch 80, loss=0.0944, recon=0.0943, kl=148.8823, beta=0.0000\n",
      "Batch 100, loss=0.0539, recon=0.0539, kl=146.1586, beta=0.0000\n",
      "Batch 120, loss=0.0971, recon=0.0970, kl=144.8239, beta=0.0000\n",
      "Batch 140, loss=0.0396, recon=0.0396, kl=143.9851, beta=0.0000\n",
      "Batch 160, loss=0.0464, recon=0.0464, kl=142.1219, beta=0.0000\n",
      "Batch 180, loss=0.0639, recon=0.0639, kl=141.3321, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0883 (Recon: 0.0882, KL: 148.4847, Current Beta: 0.0000) | Avg Valid Loss: 0.0756 | Avg Valid recon Loss: 0.0755\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0818, recon=0.0817, kl=134.4336, beta=0.0000\n",
      "Batch 40, loss=0.0610, recon=0.0610, kl=125.7586, beta=0.0000\n",
      "Batch 60, loss=0.0622, recon=0.0621, kl=115.3852, beta=0.0000\n",
      "Batch 80, loss=0.0346, recon=0.0345, kl=109.7978, beta=0.0000\n",
      "Batch 100, loss=0.0384, recon=0.0384, kl=104.3353, beta=0.0000\n",
      "Batch 120, loss=0.1117, recon=0.1117, kl=101.9771, beta=0.0000\n",
      "Batch 140, loss=0.0524, recon=0.0524, kl=98.4488, beta=0.0000\n",
      "Batch 160, loss=0.0487, recon=0.0487, kl=94.6470, beta=0.0000\n",
      "Batch 180, loss=0.0583, recon=0.0582, kl=94.6322, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0814 (Recon: 0.0814, KL: 111.3517, Current Beta: 0.0000) | Avg Valid Loss: 0.0715 | Avg Valid recon Loss: 0.0714\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0648, recon=0.0647, kl=75.8309, beta=0.0000\n",
      "Batch 40, loss=0.0530, recon=0.0529, kl=59.5977, beta=0.0000\n",
      "Batch 60, loss=0.0633, recon=0.0632, kl=56.3236, beta=0.0000\n",
      "Batch 80, loss=0.0551, recon=0.0550, kl=64.8073, beta=0.0000\n",
      "Batch 100, loss=0.0807, recon=0.0806, kl=63.1729, beta=0.0000\n",
      "Batch 120, loss=0.0647, recon=0.0646, kl=62.0618, beta=0.0000\n",
      "Batch 140, loss=0.0651, recon=0.0650, kl=58.1192, beta=0.0000\n",
      "Batch 160, loss=0.0389, recon=0.0389, kl=56.7488, beta=0.0000\n",
      "Batch 180, loss=0.0614, recon=0.0613, kl=54.4845, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0766 (Recon: 0.0765, KL: 63.1865, Current Beta: 0.0000) | Avg Valid Loss: 0.0684 | Avg Valid recon Loss: 0.0683\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0603, recon=0.0602, kl=32.5852, beta=0.0000\n",
      "Batch 40, loss=0.0528, recon=0.0527, kl=30.2905, beta=0.0000\n",
      "Batch 60, loss=0.3353, recon=0.3351, kl=31.1961, beta=0.0000\n",
      "Batch 80, loss=0.0748, recon=0.0747, kl=27.3810, beta=0.0000\n",
      "Batch 100, loss=0.0546, recon=0.0545, kl=27.1865, beta=0.0000\n",
      "Batch 120, loss=0.0416, recon=0.0415, kl=24.7880, beta=0.0000\n",
      "Batch 140, loss=1.2219, recon=1.2218, kl=24.8218, beta=0.0000\n",
      "Batch 160, loss=0.0432, recon=0.0431, kl=24.2000, beta=0.0000\n",
      "Batch 180, loss=0.0658, recon=0.0657, kl=27.4091, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0725 (Recon: 0.0724, KL: 29.4078, Current Beta: 0.0000) | Avg Valid Loss: 0.0641 | Avg Valid recon Loss: 0.0640\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0440, recon=0.0438, kl=12.3192, beta=0.0000\n",
      "Batch 40, loss=0.0500, recon=0.0499, kl=11.9306, beta=0.0000\n",
      "Batch 60, loss=0.0417, recon=0.0416, kl=10.2658, beta=0.0000\n",
      "Batch 80, loss=0.0645, recon=0.0644, kl=9.1486, beta=0.0000\n",
      "Batch 100, loss=0.0578, recon=0.0577, kl=8.9043, beta=0.0000\n",
      "Batch 120, loss=0.0434, recon=0.0433, kl=8.7358, beta=0.0000\n",
      "Batch 140, loss=0.0530, recon=0.0529, kl=8.4651, beta=0.0000\n",
      "Batch 160, loss=0.0495, recon=0.0494, kl=9.3494, beta=0.0000\n",
      "Batch 180, loss=0.0381, recon=0.0380, kl=7.3046, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0696 (Recon: 0.0695, KL: 10.5288, Current Beta: 0.0000) | Avg Valid Loss: 0.0618 | Avg Valid recon Loss: 0.0618\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0387, recon=0.0386, kl=3.2548, beta=0.0000\n",
      "Batch 40, loss=0.0342, recon=0.0341, kl=4.2520, beta=0.0000\n",
      "Batch 60, loss=0.0522, recon=0.0521, kl=2.8473, beta=0.0000\n",
      "Batch 80, loss=0.0485, recon=0.0484, kl=3.3565, beta=0.0000\n",
      "Batch 100, loss=0.0318, recon=0.0317, kl=2.6790, beta=0.0000\n",
      "Batch 120, loss=0.0517, recon=0.0516, kl=2.4598, beta=0.0000\n",
      "Batch 140, loss=0.0700, recon=0.0699, kl=3.1122, beta=0.0000\n",
      "Batch 160, loss=0.0572, recon=0.0571, kl=3.1013, beta=0.0000\n",
      "Batch 180, loss=0.0790, recon=0.0790, kl=2.1609, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0670 (Recon: 0.0669, KL: 3.3106, Current Beta: 0.0000) | Avg Valid Loss: 0.0595 | Avg Valid recon Loss: 0.0594\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0464, recon=0.0463, kl=0.9346, beta=0.0001\n",
      "Batch 40, loss=0.0523, recon=0.0522, kl=1.2079, beta=0.0001\n",
      "Batch 60, loss=0.0359, recon=0.0358, kl=0.9542, beta=0.0001\n",
      "Batch 80, loss=0.0480, recon=0.0480, kl=0.8480, beta=0.0001\n",
      "Batch 100, loss=0.0919, recon=0.0918, kl=0.5949, beta=0.0001\n",
      "Batch 120, loss=0.0507, recon=0.0506, kl=0.5462, beta=0.0001\n",
      "Batch 140, loss=0.0497, recon=0.0496, kl=0.4749, beta=0.0001\n",
      "Batch 160, loss=0.0698, recon=0.0698, kl=0.5444, beta=0.0001\n",
      "Batch 180, loss=0.0427, recon=0.0426, kl=0.4207, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0646 (Recon: 0.0645, KL: 0.8143, Current Beta: 0.0001) | Avg Valid Loss: 0.0577 | Avg Valid recon Loss: 0.0577\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0608, recon=0.0608, kl=0.2419, beta=0.0002\n",
      "Batch 40, loss=0.1926, recon=0.1926, kl=0.1220, beta=0.0002\n",
      "Batch 60, loss=0.0553, recon=0.0552, kl=0.1301, beta=0.0002\n",
      "Batch 80, loss=0.0450, recon=0.0450, kl=0.0775, beta=0.0002\n",
      "Batch 100, loss=0.0800, recon=0.0800, kl=0.0729, beta=0.0002\n",
      "Batch 120, loss=0.0373, recon=0.0373, kl=0.0624, beta=0.0002\n",
      "Batch 140, loss=0.0383, recon=0.0383, kl=0.0498, beta=0.0002\n",
      "Batch 160, loss=0.0487, recon=0.0487, kl=0.0471, beta=0.0002\n",
      "Batch 180, loss=0.0367, recon=0.0367, kl=0.0278, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0627 (Recon: 0.0627, KL: 0.1199, Current Beta: 0.0002) | Avg Valid Loss: 0.0552 | Avg Valid recon Loss: 0.0552\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0450, recon=0.0450, kl=0.0246, beta=0.0004\n",
      "Batch 40, loss=0.0427, recon=0.0427, kl=0.0073, beta=0.0004\n",
      "Batch 60, loss=0.0447, recon=0.0447, kl=0.0060, beta=0.0004\n",
      "Batch 80, loss=0.0446, recon=0.0446, kl=0.0041, beta=0.0004\n",
      "Batch 100, loss=0.0431, recon=0.0431, kl=0.0038, beta=0.0004\n",
      "Batch 120, loss=0.1039, recon=0.1039, kl=0.0039, beta=0.0004\n",
      "Batch 140, loss=0.0475, recon=0.0475, kl=0.0045, beta=0.0004\n",
      "Batch 160, loss=0.0487, recon=0.0487, kl=0.0025, beta=0.0004\n",
      "Batch 180, loss=0.0534, recon=0.0534, kl=0.0027, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0608 (Recon: 0.0608, KL: 0.0087, Current Beta: 0.0004) | Avg Valid Loss: 0.0547 | Avg Valid recon Loss: 0.0547\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1607, recon=0.1606, kl=0.0175, beta=0.0006\n",
      "Batch 40, loss=0.0439, recon=0.0439, kl=0.0026, beta=0.0006\n",
      "Batch 60, loss=0.0786, recon=0.0786, kl=0.0018, beta=0.0006\n",
      "Batch 80, loss=0.0390, recon=0.0390, kl=0.0038, beta=0.0006\n",
      "Batch 100, loss=0.0302, recon=0.0302, kl=0.0010, beta=0.0006\n",
      "Batch 120, loss=0.0540, recon=0.0540, kl=0.0010, beta=0.0006\n",
      "Batch 140, loss=0.0352, recon=0.0352, kl=0.0009, beta=0.0006\n",
      "Batch 160, loss=0.0456, recon=0.0456, kl=0.0010, beta=0.0006\n",
      "Batch 180, loss=0.0463, recon=0.0463, kl=0.0007, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0593 (Recon: 0.0593, KL: 0.0028, Current Beta: 0.0006) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1242, recon=0.1242, kl=0.0059, beta=0.0010\n",
      "Batch 40, loss=0.0435, recon=0.0435, kl=0.0010, beta=0.0010\n",
      "Batch 60, loss=0.0485, recon=0.0485, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.0510, recon=0.0510, kl=0.0005, beta=0.0010\n",
      "Batch 100, loss=0.0293, recon=0.0293, kl=0.0005, beta=0.0010\n",
      "Batch 120, loss=0.0308, recon=0.0308, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0604, recon=0.0604, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0924, recon=0.0924, kl=0.0016, beta=0.0010\n",
      "Batch 180, loss=0.0447, recon=0.0447, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0577 (Recon: 0.0577, KL: 0.0016, Current Beta: 0.0010) | Avg Valid Loss: 0.0514 | Avg Valid recon Loss: 0.0514\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0362, recon=0.0362, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0375, recon=0.0375, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0622, recon=0.0622, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0375, recon=0.0375, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0411, recon=0.0411, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0373, recon=0.0373, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.1295, recon=0.1295, kl=0.0005, beta=0.0010\n",
      "Batch 160, loss=0.0579, recon=0.0579, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0552, recon=0.0552, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0564 (Recon: 0.0564, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0499\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0339, recon=0.0339, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0380, recon=0.0380, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0434, recon=0.0434, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0294, recon=0.0294, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0439, recon=0.0439, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0545, recon=0.0545, kl=0.0032, beta=0.0010\n",
      "Batch 140, loss=0.0328, recon=0.0328, kl=0.0011, beta=0.0010\n",
      "Batch 160, loss=0.0404, recon=0.0404, kl=0.0005, beta=0.0010\n",
      "Batch 180, loss=0.0554, recon=0.0554, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0494 | Avg Valid recon Loss: 0.0494\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0364, recon=0.0364, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0350, recon=0.0350, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0336, recon=0.0336, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0352, recon=0.0352, kl=0.0027, beta=0.0010\n",
      "Batch 100, loss=0.0636, recon=0.0636, kl=0.0007, beta=0.0010\n",
      "Batch 120, loss=0.0399, recon=0.0399, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0294, recon=0.0294, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0263, recon=0.0263, kl=0.0001, beta=0.0010\n",
      "Batch 180, loss=0.0416, recon=0.0416, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0541 (Recon: 0.0541, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0548, recon=0.0548, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0374, recon=0.0374, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0274, recon=0.0274, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0370, recon=0.0370, kl=0.0003, beta=0.0010\n",
      "Batch 100, loss=0.0305, recon=0.0305, kl=0.0001, beta=0.0010\n",
      "Batch 120, loss=0.0364, recon=0.0364, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0338, recon=0.0338, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0348, recon=0.0348, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0362, recon=0.0362, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0528 (Recon: 0.0528, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0473 | Avg Valid recon Loss: 0.0473\n",
      "\n",
      "[VRAE Run 60/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2560, recon=0.2560, kl=57.7959, beta=0.0000\n",
      "Batch 40, loss=2.3253, recon=2.3253, kl=86.5091, beta=0.0000\n",
      "Batch 60, loss=0.7559, recon=0.7559, kl=89.8482, beta=0.0000\n",
      "Batch 80, loss=0.1322, recon=0.1322, kl=110.1107, beta=0.0000\n",
      "Batch 100, loss=0.1310, recon=0.1310, kl=113.5200, beta=0.0000\n",
      "Batch 120, loss=0.1045, recon=0.1045, kl=123.6073, beta=0.0000\n",
      "Batch 140, loss=0.0532, recon=0.0532, kl=126.1058, beta=0.0000\n",
      "Batch 160, loss=0.0634, recon=0.0634, kl=97.7687, beta=0.0000\n",
      "Batch 180, loss=0.0431, recon=0.0431, kl=116.3064, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1723 (Recon: 0.1723, KL: 95.8484, Current Beta: 0.0000) | Avg Valid Loss: 0.0757 | Avg Valid recon Loss: 0.0757\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1007, recon=0.1007, kl=122.3202, beta=0.0000\n",
      "Batch 40, loss=0.0399, recon=0.0399, kl=117.9806, beta=0.0000\n",
      "Batch 60, loss=0.0390, recon=0.0390, kl=117.6543, beta=0.0000\n",
      "Batch 80, loss=0.0498, recon=0.0498, kl=121.3955, beta=0.0000\n",
      "Batch 100, loss=0.0467, recon=0.0467, kl=131.4727, beta=0.0000\n",
      "Batch 120, loss=0.0549, recon=0.0549, kl=138.2559, beta=0.0000\n",
      "Batch 140, loss=0.0845, recon=0.0845, kl=140.0199, beta=0.0000\n",
      "Batch 160, loss=0.0468, recon=0.0468, kl=109.2423, beta=0.0000\n",
      "Batch 180, loss=0.0561, recon=0.0561, kl=124.3281, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0783 (Recon: 0.0783, KL: 124.4534, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0533, recon=0.0533, kl=132.1023, beta=0.0000\n",
      "Batch 40, loss=0.0452, recon=0.0452, kl=141.0843, beta=0.0000\n",
      "Batch 60, loss=0.0420, recon=0.0420, kl=149.2360, beta=0.0000\n",
      "Batch 80, loss=1.2822, recon=1.2822, kl=149.0379, beta=0.0000\n",
      "Batch 100, loss=0.0717, recon=0.0717, kl=121.8539, beta=0.0000\n",
      "Batch 120, loss=0.0689, recon=0.0689, kl=118.7699, beta=0.0000\n",
      "Batch 140, loss=0.0357, recon=0.0357, kl=130.2304, beta=0.0000\n",
      "Batch 160, loss=0.0307, recon=0.0307, kl=121.3686, beta=0.0000\n",
      "Batch 180, loss=0.0664, recon=0.0664, kl=132.3530, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0660 (Recon: 0.0660, KL: 132.2585, Current Beta: 0.0000) | Avg Valid Loss: 0.0722 | Avg Valid recon Loss: 0.0722\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0376, recon=0.0376, kl=129.2701, beta=0.0000\n",
      "Batch 40, loss=0.0473, recon=0.0473, kl=125.9014, beta=0.0000\n",
      "Batch 60, loss=0.0492, recon=0.0492, kl=134.9398, beta=0.0000\n",
      "Batch 80, loss=0.0611, recon=0.0610, kl=134.7939, beta=0.0000\n",
      "Batch 100, loss=0.0455, recon=0.0455, kl=141.0619, beta=0.0000\n",
      "Batch 120, loss=0.0304, recon=0.0304, kl=111.2741, beta=0.0000\n",
      "Batch 140, loss=0.0417, recon=0.0417, kl=106.8540, beta=0.0000\n",
      "Batch 160, loss=0.0570, recon=0.0570, kl=122.5817, beta=0.0000\n",
      "Batch 180, loss=0.0432, recon=0.0432, kl=134.8232, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0603 (Recon: 0.0603, KL: 126.2035, Current Beta: 0.0000) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0330, recon=0.0330, kl=134.0304, beta=0.0000\n",
      "Batch 40, loss=0.0514, recon=0.0514, kl=132.3169, beta=0.0000\n",
      "Batch 60, loss=0.0554, recon=0.0554, kl=131.4611, beta=0.0000\n",
      "Batch 80, loss=0.0306, recon=0.0306, kl=130.3600, beta=0.0000\n",
      "Batch 100, loss=0.0397, recon=0.0397, kl=91.2866, beta=0.0000\n",
      "Batch 120, loss=0.0362, recon=0.0362, kl=103.8122, beta=0.0000\n",
      "Batch 140, loss=0.0479, recon=0.0479, kl=118.6689, beta=0.0000\n",
      "Batch 160, loss=0.0487, recon=0.0487, kl=122.8292, beta=0.0000\n",
      "Batch 180, loss=0.0295, recon=0.0295, kl=130.6932, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0525 (Recon: 0.0525, KL: 121.6490, Current Beta: 0.0000) | Avg Valid Loss: 0.0428 | Avg Valid recon Loss: 0.0428\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0432, recon=0.0431, kl=127.3386, beta=0.0000\n",
      "Batch 40, loss=0.0273, recon=0.0272, kl=98.0034, beta=0.0000\n",
      "Batch 60, loss=0.0293, recon=0.0293, kl=105.2041, beta=0.0000\n",
      "Batch 80, loss=0.0362, recon=0.0361, kl=110.8589, beta=0.0000\n",
      "Batch 100, loss=0.0257, recon=0.0257, kl=118.4881, beta=0.0000\n",
      "Batch 120, loss=0.0565, recon=0.0565, kl=118.8025, beta=0.0000\n",
      "Batch 140, loss=0.0404, recon=0.0403, kl=113.3525, beta=0.0000\n",
      "Batch 160, loss=0.0360, recon=0.0360, kl=111.7761, beta=0.0000\n",
      "Batch 180, loss=0.0607, recon=0.0606, kl=113.3256, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0489 (Recon: 0.0489, KL: 114.1342, Current Beta: 0.0000) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0521, recon=0.0520, kl=103.3086, beta=0.0000\n",
      "Batch 40, loss=0.1040, recon=0.1040, kl=93.9038, beta=0.0000\n",
      "Batch 60, loss=0.0357, recon=0.0356, kl=93.8707, beta=0.0000\n",
      "Batch 80, loss=0.0382, recon=0.0381, kl=101.1228, beta=0.0000\n",
      "Batch 100, loss=0.0736, recon=0.0736, kl=102.8500, beta=0.0000\n",
      "Batch 120, loss=0.0342, recon=0.0341, kl=100.0082, beta=0.0000\n",
      "Batch 140, loss=0.0353, recon=0.0353, kl=110.0626, beta=0.0000\n",
      "Batch 160, loss=0.0363, recon=0.0363, kl=115.1354, beta=0.0000\n",
      "Batch 180, loss=0.0276, recon=0.0276, kl=109.2559, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0586 (Recon: 0.0585, KL: 103.1718, Current Beta: 0.0000) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0473\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0308, recon=0.0307, kl=78.4401, beta=0.0000\n",
      "Batch 40, loss=0.0311, recon=0.0310, kl=74.7278, beta=0.0000\n",
      "Batch 60, loss=0.0294, recon=0.0293, kl=81.5189, beta=0.0000\n",
      "Batch 80, loss=0.0612, recon=0.0610, kl=80.2189, beta=0.0000\n",
      "Batch 100, loss=0.0437, recon=0.0435, kl=91.2589, beta=0.0000\n",
      "Batch 120, loss=0.0443, recon=0.0442, kl=89.5539, beta=0.0000\n",
      "Batch 140, loss=0.0311, recon=0.0310, kl=78.6215, beta=0.0000\n",
      "Batch 160, loss=0.0768, recon=0.0767, kl=70.2933, beta=0.0000\n",
      "Batch 180, loss=0.0389, recon=0.0388, kl=69.9151, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0479, KL: 81.8172, Current Beta: 0.0000) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0432, recon=0.0430, kl=52.6859, beta=0.0000\n",
      "Batch 40, loss=0.0330, recon=0.0328, kl=54.5852, beta=0.0000\n",
      "Batch 60, loss=0.0307, recon=0.0304, kl=60.0091, beta=0.0000\n",
      "Batch 80, loss=0.0378, recon=0.0376, kl=53.6901, beta=0.0000\n",
      "Batch 100, loss=0.0276, recon=0.0275, kl=45.5387, beta=0.0000\n",
      "Batch 120, loss=0.0269, recon=0.0267, kl=44.4471, beta=0.0000\n",
      "Batch 140, loss=0.0315, recon=0.0313, kl=40.0317, beta=0.0000\n",
      "Batch 160, loss=0.0367, recon=0.0366, kl=39.2176, beta=0.0000\n",
      "Batch 180, loss=0.0269, recon=0.0267, kl=39.7739, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0435 (Recon: 0.0433, KL: 49.0661, Current Beta: 0.0000) | Avg Valid Loss: 0.0356 | Avg Valid recon Loss: 0.0355\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0335, recon=0.0333, kl=18.1701, beta=0.0000\n",
      "Batch 40, loss=0.0614, recon=0.0610, kl=29.9482, beta=0.0000\n",
      "Batch 60, loss=0.0320, recon=0.0316, kl=39.0025, beta=0.0000\n",
      "Batch 80, loss=0.0263, recon=0.0259, kl=32.7374, beta=0.0000\n",
      "Batch 100, loss=0.0302, recon=0.0299, kl=26.9504, beta=0.0000\n",
      "Batch 120, loss=0.0267, recon=0.0264, kl=22.8145, beta=0.0000\n",
      "Batch 140, loss=0.0439, recon=0.0435, kl=30.8886, beta=0.0000\n",
      "Batch 160, loss=0.0553, recon=0.0549, kl=31.7984, beta=0.0000\n",
      "Batch 180, loss=0.0342, recon=0.0339, kl=22.2067, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0439 (Recon: 0.0436, KL: 29.4282, Current Beta: 0.0000) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0313, recon=0.0310, kl=9.6729, beta=0.0000\n",
      "Batch 40, loss=0.0471, recon=0.0469, kl=8.3334, beta=0.0000\n",
      "Batch 60, loss=0.0339, recon=0.0336, kl=10.1665, beta=0.0000\n",
      "Batch 80, loss=0.0292, recon=0.0288, kl=13.1580, beta=0.0000\n",
      "Batch 100, loss=0.0359, recon=0.0355, kl=13.0860, beta=0.0000\n",
      "Batch 120, loss=0.1907, recon=0.1903, kl=11.0780, beta=0.0000\n",
      "Batch 140, loss=0.0246, recon=0.0243, kl=10.4653, beta=0.0000\n",
      "Batch 160, loss=0.0227, recon=0.0224, kl=9.8541, beta=0.0000\n",
      "Batch 180, loss=0.0267, recon=0.0264, kl=8.2527, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0444 (Recon: 0.0441, KL: 11.0775, Current Beta: 0.0000) | Avg Valid Loss: 0.0344 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0292, recon=0.0289, kl=3.8534, beta=0.0001\n",
      "Batch 40, loss=0.0381, recon=0.0380, kl=1.0981, beta=0.0001\n",
      "Batch 60, loss=0.0303, recon=0.0302, kl=0.8725, beta=0.0001\n",
      "Batch 80, loss=0.0340, recon=0.0338, kl=1.7669, beta=0.0001\n",
      "Batch 100, loss=0.0202, recon=0.0200, kl=2.7683, beta=0.0001\n",
      "Batch 120, loss=0.0425, recon=0.0419, kl=8.2409, beta=0.0001\n",
      "Batch 140, loss=0.0310, recon=0.0302, kl=10.2365, beta=0.0001\n",
      "Batch 160, loss=0.0304, recon=0.0298, kl=7.9485, beta=0.0001\n",
      "Batch 180, loss=0.0586, recon=0.0583, kl=3.9941, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0416, KL: 4.8156, Current Beta: 0.0001) | Avg Valid Loss: 0.0442 | Avg Valid recon Loss: 0.0440\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1997, recon=0.1988, kl=4.8772, beta=0.0002\n",
      "Batch 40, loss=0.0382, recon=0.0378, kl=2.2387, beta=0.0002\n",
      "Batch 60, loss=0.0569, recon=0.0565, kl=2.3034, beta=0.0002\n",
      "Batch 80, loss=0.0372, recon=0.0359, kl=7.3255, beta=0.0002\n",
      "Batch 100, loss=0.0389, recon=0.0375, kl=7.7945, beta=0.0002\n",
      "Batch 120, loss=0.0289, recon=0.0278, kl=5.9538, beta=0.0002\n",
      "Batch 140, loss=0.0398, recon=0.0390, kl=4.3058, beta=0.0002\n",
      "Batch 160, loss=0.0358, recon=0.0350, kl=4.4294, beta=0.0002\n",
      "Batch 180, loss=0.0567, recon=0.0558, kl=4.9049, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0515 (Recon: 0.0506, KL: 4.8488, Current Beta: 0.0002) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0605, recon=0.0592, kl=3.6514, beta=0.0004\n",
      "Batch 40, loss=0.0649, recon=0.0640, kl=2.4655, beta=0.0004\n",
      "Batch 60, loss=0.0462, recon=0.0444, kl=4.7150, beta=0.0004\n",
      "Batch 80, loss=0.1426, recon=0.1412, kl=3.7753, beta=0.0004\n",
      "Batch 100, loss=0.0454, recon=0.0443, kl=2.8927, beta=0.0004\n",
      "Batch 120, loss=0.0465, recon=0.0457, kl=2.1308, beta=0.0004\n",
      "Batch 140, loss=0.0605, recon=0.0599, kl=1.6804, beta=0.0004\n",
      "Batch 160, loss=0.0331, recon=0.0322, kl=2.4920, beta=0.0004\n",
      "Batch 180, loss=0.0428, recon=0.0418, kl=2.4755, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0457, KL: 3.0927, Current Beta: 0.0004) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0386, recon=0.0376, kl=1.7150, beta=0.0006\n",
      "Batch 40, loss=0.0576, recon=0.0552, kl=3.8822, beta=0.0006\n",
      "Batch 60, loss=0.0394, recon=0.0372, kl=3.5675, beta=0.0006\n",
      "Batch 80, loss=0.0319, recon=0.0302, kl=2.6210, beta=0.0006\n",
      "Batch 100, loss=0.1553, recon=0.1534, kl=3.0065, beta=0.0006\n",
      "Batch 120, loss=0.0431, recon=0.0415, kl=2.5253, beta=0.0006\n",
      "Batch 140, loss=0.0235, recon=0.0223, kl=1.9146, beta=0.0006\n",
      "Batch 160, loss=0.0344, recon=0.0335, kl=1.4758, beta=0.0006\n",
      "Batch 180, loss=0.0221, recon=0.0213, kl=1.3997, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0463, KL: 2.4940, Current Beta: 0.0006) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0294, recon=0.0283, kl=1.1462, beta=0.0010\n",
      "Batch 40, loss=0.0236, recon=0.0228, kl=0.8244, beta=0.0010\n",
      "Batch 60, loss=0.0492, recon=0.0486, kl=0.6171, beta=0.0010\n",
      "Batch 80, loss=0.1303, recon=0.1293, kl=1.0583, beta=0.0010\n",
      "Batch 100, loss=0.0262, recon=0.0255, kl=0.7452, beta=0.0010\n",
      "Batch 120, loss=0.0281, recon=0.0276, kl=0.4685, beta=0.0010\n",
      "Batch 140, loss=0.0336, recon=0.0329, kl=0.7373, beta=0.0010\n",
      "Batch 160, loss=0.0334, recon=0.0308, kl=2.6297, beta=0.0010\n",
      "Batch 180, loss=0.0346, recon=0.0311, kl=3.4558, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0406, KL: 1.2243, Current Beta: 0.0010) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0349\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0687, recon=0.0656, kl=3.1093, beta=0.0010\n",
      "Batch 40, loss=0.0348, recon=0.0324, kl=2.3990, beta=0.0010\n",
      "Batch 60, loss=0.0327, recon=0.0306, kl=2.0155, beta=0.0010\n",
      "Batch 80, loss=0.0344, recon=0.0328, kl=1.5989, beta=0.0010\n",
      "Batch 100, loss=0.0354, recon=0.0341, kl=1.2758, beta=0.0010\n",
      "Batch 120, loss=0.0866, recon=0.0849, kl=1.6995, beta=0.0010\n",
      "Batch 140, loss=0.0440, recon=0.0425, kl=1.4812, beta=0.0010\n",
      "Batch 160, loss=0.0350, recon=0.0338, kl=1.1907, beta=0.0010\n",
      "Batch 180, loss=0.0670, recon=0.0658, kl=1.1792, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0477, KL: 1.8881, Current Beta: 0.0010) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0474, recon=0.0462, kl=1.2048, beta=0.0010\n",
      "Batch 40, loss=0.1045, recon=0.1034, kl=1.0297, beta=0.0010\n",
      "Batch 60, loss=0.0396, recon=0.0380, kl=1.6184, beta=0.0010\n",
      "Batch 80, loss=0.0676, recon=0.0654, kl=2.1971, beta=0.0010\n",
      "Batch 100, loss=0.0462, recon=0.0441, kl=2.0876, beta=0.0010\n",
      "Batch 120, loss=0.0241, recon=0.0222, kl=1.9564, beta=0.0010\n",
      "Batch 140, loss=0.0351, recon=0.0335, kl=1.5778, beta=0.0010\n",
      "Batch 160, loss=0.0616, recon=0.0603, kl=1.2684, beta=0.0010\n",
      "Batch 180, loss=0.0390, recon=0.0379, kl=1.0657, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0508, KL: 1.5518, Current Beta: 0.0010) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0340, recon=0.0331, kl=0.9085, beta=0.0010\n",
      "Batch 40, loss=0.0381, recon=0.0372, kl=0.9756, beta=0.0010\n",
      "Batch 60, loss=0.0313, recon=0.0303, kl=0.9773, beta=0.0010\n",
      "Batch 80, loss=0.0403, recon=0.0394, kl=0.9142, beta=0.0010\n",
      "Batch 100, loss=0.0257, recon=0.0249, kl=0.7925, beta=0.0010\n",
      "Batch 120, loss=0.0410, recon=0.0402, kl=0.7783, beta=0.0010\n",
      "Batch 140, loss=0.0279, recon=0.0271, kl=0.7799, beta=0.0010\n",
      "Batch 160, loss=0.0437, recon=0.0430, kl=0.6466, beta=0.0010\n",
      "Batch 180, loss=0.1339, recon=0.1334, kl=0.5289, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0436 (Recon: 0.0428, KL: 0.8323, Current Beta: 0.0010) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0317, recon=0.0311, kl=0.5557, beta=0.0010\n",
      "Batch 40, loss=0.0327, recon=0.0321, kl=0.5473, beta=0.0010\n",
      "Batch 60, loss=0.0287, recon=0.0282, kl=0.4541, beta=0.0010\n",
      "Batch 80, loss=0.0381, recon=0.0378, kl=0.3648, beta=0.0010\n",
      "Batch 100, loss=0.0538, recon=0.0535, kl=0.3076, beta=0.0010\n",
      "Batch 120, loss=0.0316, recon=0.0311, kl=0.5470, beta=0.0010\n",
      "Batch 140, loss=0.1384, recon=0.1378, kl=0.6024, beta=0.0010\n",
      "Batch 160, loss=0.0353, recon=0.0348, kl=0.5145, beta=0.0010\n",
      "Batch 180, loss=0.0408, recon=0.0403, kl=0.5448, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0408 (Recon: 0.0403, KL: 0.4911, Current Beta: 0.0010) | Avg Valid Loss: 0.0340 | Avg Valid recon Loss: 0.0335\n",
      "\n",
      "[VRAE Run 61/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4147, recon=0.4147, kl=0.9019, beta=0.0000\n",
      "Batch 40, loss=0.3198, recon=0.3198, kl=12.5781, beta=0.0000\n",
      "Batch 60, loss=0.1961, recon=0.1961, kl=19.1484, beta=0.0000\n",
      "Batch 80, loss=0.1704, recon=0.1704, kl=24.7514, beta=0.0000\n",
      "Batch 100, loss=0.2207, recon=0.2207, kl=27.1213, beta=0.0000\n",
      "Batch 120, loss=0.1893, recon=0.1893, kl=30.8147, beta=0.0000\n",
      "Batch 140, loss=0.1384, recon=0.1384, kl=34.5753, beta=0.0000\n",
      "Batch 160, loss=0.1179, recon=0.1179, kl=39.3602, beta=0.0000\n",
      "Batch 180, loss=0.1338, recon=0.1338, kl=39.3688, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2968 (Recon: 0.2968, KL: 23.3568, Current Beta: 0.0000) | Avg Valid Loss: 0.1248 | Avg Valid recon Loss: 0.1248\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1349, recon=0.1349, kl=39.2782, beta=0.0000\n",
      "Batch 40, loss=0.1705, recon=0.1705, kl=39.3591, beta=0.0000\n",
      "Batch 60, loss=0.1595, recon=0.1595, kl=39.9189, beta=0.0000\n",
      "Batch 80, loss=0.1208, recon=0.1208, kl=40.9130, beta=0.0000\n",
      "Batch 100, loss=0.0895, recon=0.0895, kl=42.0303, beta=0.0000\n",
      "Batch 120, loss=0.0941, recon=0.0941, kl=42.2814, beta=0.0000\n",
      "Batch 140, loss=0.1101, recon=0.1101, kl=42.8978, beta=0.0000\n",
      "Batch 160, loss=0.0860, recon=0.0860, kl=44.1944, beta=0.0000\n",
      "Batch 180, loss=0.0719, recon=0.0719, kl=44.8008, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1220 (Recon: 0.1220, KL: 41.3811, Current Beta: 0.0000) | Avg Valid Loss: 0.0893 | Avg Valid recon Loss: 0.0893\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0977, recon=0.0977, kl=46.0538, beta=0.0000\n",
      "Batch 40, loss=0.1369, recon=0.1369, kl=47.7071, beta=0.0000\n",
      "Batch 60, loss=0.0730, recon=0.0730, kl=48.1410, beta=0.0000\n",
      "Batch 80, loss=0.0579, recon=0.0579, kl=48.9531, beta=0.0000\n",
      "Batch 100, loss=0.0695, recon=0.0695, kl=48.4280, beta=0.0000\n",
      "Batch 120, loss=0.0614, recon=0.0614, kl=49.1597, beta=0.0000\n",
      "Batch 140, loss=0.0585, recon=0.0585, kl=49.5740, beta=0.0000\n",
      "Batch 160, loss=0.0463, recon=0.0463, kl=50.3932, beta=0.0000\n",
      "Batch 180, loss=0.0883, recon=0.0883, kl=50.1441, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0941 (Recon: 0.0941, KL: 48.3981, Current Beta: 0.0000) | Avg Valid Loss: 0.0760 | Avg Valid recon Loss: 0.0760\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0461, recon=0.0461, kl=50.8171, beta=0.0000\n",
      "Batch 40, loss=0.0507, recon=0.0507, kl=51.5430, beta=0.0000\n",
      "Batch 60, loss=0.0527, recon=0.0527, kl=50.8654, beta=0.0000\n",
      "Batch 80, loss=0.0569, recon=0.0569, kl=52.3492, beta=0.0000\n",
      "Batch 100, loss=1.3064, recon=1.3064, kl=52.4991, beta=0.0000\n",
      "Batch 120, loss=0.0541, recon=0.0541, kl=52.8256, beta=0.0000\n",
      "Batch 140, loss=0.0604, recon=0.0604, kl=52.8931, beta=0.0000\n",
      "Batch 160, loss=0.0534, recon=0.0534, kl=52.7851, beta=0.0000\n",
      "Batch 180, loss=0.0890, recon=0.0890, kl=53.3802, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0813 (Recon: 0.0813, KL: 52.0773, Current Beta: 0.0000) | Avg Valid Loss: 0.0668 | Avg Valid recon Loss: 0.0668\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0529, recon=0.0529, kl=52.8143, beta=0.0000\n",
      "Batch 40, loss=0.0431, recon=0.0431, kl=52.8623, beta=0.0000\n",
      "Batch 60, loss=0.0465, recon=0.0464, kl=53.3564, beta=0.0000\n",
      "Batch 80, loss=0.0523, recon=0.0523, kl=52.5542, beta=0.0000\n",
      "Batch 100, loss=0.0413, recon=0.0413, kl=54.1398, beta=0.0000\n",
      "Batch 120, loss=0.0489, recon=0.0489, kl=52.9276, beta=0.0000\n",
      "Batch 140, loss=0.0510, recon=0.0510, kl=51.6475, beta=0.0000\n",
      "Batch 160, loss=0.0505, recon=0.0505, kl=50.5706, beta=0.0000\n",
      "Batch 180, loss=0.0417, recon=0.0417, kl=49.9727, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0724 (Recon: 0.0724, KL: 52.4528, Current Beta: 0.0000) | Avg Valid Loss: 0.0612 | Avg Valid recon Loss: 0.0612\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0414, recon=0.0414, kl=49.8639, beta=0.0000\n",
      "Batch 40, loss=0.0644, recon=0.0644, kl=49.1706, beta=0.0000\n",
      "Batch 60, loss=0.0564, recon=0.0564, kl=48.0777, beta=0.0000\n",
      "Batch 80, loss=0.0415, recon=0.0415, kl=46.7271, beta=0.0000\n",
      "Batch 100, loss=0.0540, recon=0.0540, kl=45.1356, beta=0.0000\n",
      "Batch 120, loss=0.0425, recon=0.0425, kl=44.4063, beta=0.0000\n",
      "Batch 140, loss=0.0518, recon=0.0518, kl=41.7622, beta=0.0000\n",
      "Batch 160, loss=0.0397, recon=0.0397, kl=41.7403, beta=0.0000\n",
      "Batch 180, loss=0.0508, recon=0.0508, kl=40.7366, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0663 (Recon: 0.0663, KL: 45.7001, Current Beta: 0.0000) | Avg Valid Loss: 0.0569 | Avg Valid recon Loss: 0.0569\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0901, recon=0.0901, kl=37.6140, beta=0.0000\n",
      "Batch 40, loss=0.0326, recon=0.0326, kl=34.4850, beta=0.0000\n",
      "Batch 60, loss=0.0424, recon=0.0424, kl=33.0468, beta=0.0000\n",
      "Batch 80, loss=0.0546, recon=0.0545, kl=32.0719, beta=0.0000\n",
      "Batch 100, loss=0.0413, recon=0.0413, kl=30.9780, beta=0.0000\n",
      "Batch 120, loss=0.0381, recon=0.0381, kl=31.7855, beta=0.0000\n",
      "Batch 140, loss=0.1531, recon=0.1531, kl=31.5161, beta=0.0000\n",
      "Batch 160, loss=0.0378, recon=0.0377, kl=31.1026, beta=0.0000\n",
      "Batch 180, loss=0.0514, recon=0.0514, kl=30.1451, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0617 (Recon: 0.0617, KL: 33.0622, Current Beta: 0.0000) | Avg Valid Loss: 0.0526 | Avg Valid recon Loss: 0.0526\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0301, recon=0.0300, kl=25.4334, beta=0.0000\n",
      "Batch 40, loss=0.0553, recon=0.0553, kl=23.0786, beta=0.0000\n",
      "Batch 60, loss=0.0485, recon=0.0485, kl=20.4173, beta=0.0000\n",
      "Batch 80, loss=0.0403, recon=0.0403, kl=20.0147, beta=0.0000\n",
      "Batch 100, loss=0.0468, recon=0.0468, kl=20.5878, beta=0.0000\n",
      "Batch 120, loss=0.0382, recon=0.0381, kl=20.0651, beta=0.0000\n",
      "Batch 140, loss=0.0390, recon=0.0389, kl=19.0829, beta=0.0000\n",
      "Batch 160, loss=0.0325, recon=0.0325, kl=19.7278, beta=0.0000\n",
      "Batch 180, loss=0.0618, recon=0.0618, kl=19.2413, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 21.3858, Current Beta: 0.0000) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0496\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.2142, recon=0.2141, kl=14.7606, beta=0.0000\n",
      "Batch 40, loss=0.0519, recon=0.0518, kl=11.8855, beta=0.0000\n",
      "Batch 60, loss=0.0333, recon=0.0332, kl=11.4639, beta=0.0000\n",
      "Batch 80, loss=0.1447, recon=0.1446, kl=11.7203, beta=0.0000\n",
      "Batch 100, loss=0.0527, recon=0.0526, kl=12.2889, beta=0.0000\n",
      "Batch 120, loss=0.0346, recon=0.0346, kl=11.1811, beta=0.0000\n",
      "Batch 140, loss=0.0416, recon=0.0416, kl=10.5298, beta=0.0000\n",
      "Batch 160, loss=0.0306, recon=0.0306, kl=10.4603, beta=0.0000\n",
      "Batch 180, loss=0.1177, recon=0.1176, kl=10.8990, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0551, KL: 12.2184, Current Beta: 0.0000) | Avg Valid Loss: 0.0475 | Avg Valid recon Loss: 0.0474\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0357, recon=0.0357, kl=5.5820, beta=0.0000\n",
      "Batch 40, loss=0.0290, recon=0.0290, kl=5.9930, beta=0.0000\n",
      "Batch 60, loss=0.0301, recon=0.0301, kl=5.5042, beta=0.0000\n",
      "Batch 80, loss=0.0364, recon=0.0364, kl=5.5862, beta=0.0000\n",
      "Batch 100, loss=0.0495, recon=0.0494, kl=5.1997, beta=0.0000\n",
      "Batch 120, loss=0.0407, recon=0.0407, kl=4.4289, beta=0.0000\n",
      "Batch 140, loss=0.0423, recon=0.0423, kl=4.8400, beta=0.0000\n",
      "Batch 160, loss=0.0523, recon=0.0522, kl=4.6093, beta=0.0000\n",
      "Batch 180, loss=0.0416, recon=0.0416, kl=4.1773, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0528 (Recon: 0.0528, KL: 5.4235, Current Beta: 0.0000) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0312, recon=0.0311, kl=2.1851, beta=0.0000\n",
      "Batch 40, loss=0.0307, recon=0.0306, kl=2.2296, beta=0.0000\n",
      "Batch 60, loss=0.0415, recon=0.0415, kl=2.2551, beta=0.0000\n",
      "Batch 80, loss=0.0259, recon=0.0259, kl=1.7876, beta=0.0000\n",
      "Batch 100, loss=0.0372, recon=0.0372, kl=1.9631, beta=0.0000\n",
      "Batch 120, loss=0.0631, recon=0.0630, kl=2.1213, beta=0.0000\n",
      "Batch 140, loss=0.0471, recon=0.0470, kl=1.6676, beta=0.0000\n",
      "Batch 160, loss=0.0623, recon=0.0622, kl=1.4867, beta=0.0000\n",
      "Batch 180, loss=0.0297, recon=0.0297, kl=1.7295, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0511 (Recon: 0.0511, KL: 2.0664, Current Beta: 0.0000) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0440\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0296, recon=0.0295, kl=1.1281, beta=0.0001\n",
      "Batch 40, loss=0.0307, recon=0.0307, kl=0.4861, beta=0.0001\n",
      "Batch 60, loss=0.0668, recon=0.0668, kl=0.8222, beta=0.0001\n",
      "Batch 80, loss=0.0517, recon=0.0517, kl=0.4445, beta=0.0001\n",
      "Batch 100, loss=0.0365, recon=0.0364, kl=0.3582, beta=0.0001\n",
      "Batch 120, loss=0.0389, recon=0.0389, kl=0.2686, beta=0.0001\n",
      "Batch 140, loss=0.0418, recon=0.0418, kl=0.2768, beta=0.0001\n",
      "Batch 160, loss=0.0406, recon=0.0406, kl=0.2002, beta=0.0001\n",
      "Batch 180, loss=0.0227, recon=0.0227, kl=0.2343, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0494, KL: 0.4826, Current Beta: 0.0001) | Avg Valid Loss: 0.0429 | Avg Valid recon Loss: 0.0428\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0418, recon=0.0418, kl=0.0330, beta=0.0002\n",
      "Batch 40, loss=0.0339, recon=0.0339, kl=0.0496, beta=0.0002\n",
      "Batch 60, loss=0.0326, recon=0.0326, kl=0.0304, beta=0.0002\n",
      "Batch 80, loss=0.0610, recon=0.0610, kl=0.0133, beta=0.0002\n",
      "Batch 100, loss=0.0527, recon=0.0527, kl=0.0231, beta=0.0002\n",
      "Batch 120, loss=0.0306, recon=0.0306, kl=0.0239, beta=0.0002\n",
      "Batch 140, loss=0.0347, recon=0.0347, kl=0.0098, beta=0.0002\n",
      "Batch 160, loss=0.0266, recon=0.0266, kl=0.0089, beta=0.0002\n",
      "Batch 180, loss=0.0484, recon=0.0484, kl=0.0266, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0477 (Recon: 0.0477, KL: 0.0347, Current Beta: 0.0002) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0523, recon=0.0523, kl=0.0122, beta=0.0004\n",
      "Batch 40, loss=0.0386, recon=0.0386, kl=0.0094, beta=0.0004\n",
      "Batch 60, loss=0.0424, recon=0.0424, kl=0.0047, beta=0.0004\n",
      "Batch 80, loss=0.7052, recon=0.7052, kl=0.0025, beta=0.0004\n",
      "Batch 100, loss=0.0487, recon=0.0487, kl=0.0031, beta=0.0004\n",
      "Batch 120, loss=0.0512, recon=0.0512, kl=0.0090, beta=0.0004\n",
      "Batch 140, loss=0.0457, recon=0.0457, kl=0.0042, beta=0.0004\n",
      "Batch 160, loss=0.0284, recon=0.0284, kl=0.0032, beta=0.0004\n",
      "Batch 180, loss=0.0412, recon=0.0412, kl=0.0042, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0464 (Recon: 0.0464, KL: 0.0063, Current Beta: 0.0004) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0298, recon=0.0298, kl=0.0012, beta=0.0006\n",
      "Batch 40, loss=0.0593, recon=0.0593, kl=0.0016, beta=0.0006\n",
      "Batch 60, loss=0.0227, recon=0.0227, kl=0.0106, beta=0.0006\n",
      "Batch 80, loss=0.0301, recon=0.0301, kl=0.0020, beta=0.0006\n",
      "Batch 100, loss=0.0604, recon=0.0604, kl=0.0014, beta=0.0006\n",
      "Batch 120, loss=0.0241, recon=0.0241, kl=0.0016, beta=0.0006\n",
      "Batch 140, loss=0.0319, recon=0.0319, kl=0.0011, beta=0.0006\n",
      "Batch 160, loss=0.0576, recon=0.0576, kl=0.0014, beta=0.0006\n",
      "Batch 180, loss=0.0426, recon=0.0426, kl=0.0007, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0454 (Recon: 0.0454, KL: 0.0027, Current Beta: 0.0006) | Avg Valid Loss: 0.0397 | Avg Valid recon Loss: 0.0397\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0255, recon=0.0255, kl=0.0060, beta=0.0010\n",
      "Batch 40, loss=0.0269, recon=0.0269, kl=0.0009, beta=0.0010\n",
      "Batch 60, loss=0.0238, recon=0.0238, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0244, recon=0.0244, kl=0.0008, beta=0.0010\n",
      "Batch 100, loss=0.0648, recon=0.0648, kl=0.0010, beta=0.0010\n",
      "Batch 120, loss=0.0228, recon=0.0228, kl=0.0017, beta=0.0010\n",
      "Batch 140, loss=0.0334, recon=0.0334, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0324, recon=0.0324, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0318, recon=0.0318, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 0.0017, Current Beta: 0.0010) | Avg Valid Loss: 0.0378 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0366, recon=0.0366, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0633, recon=0.0633, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.1273, recon=0.1273, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0527, recon=0.0527, kl=0.0036, beta=0.0010\n",
      "Batch 100, loss=0.0341, recon=0.0341, kl=0.0008, beta=0.0010\n",
      "Batch 120, loss=0.0900, recon=0.0900, kl=0.0007, beta=0.0010\n",
      "Batch 140, loss=0.0283, recon=0.0283, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0310, recon=0.0310, kl=0.0005, beta=0.0010\n",
      "Batch 180, loss=0.1728, recon=0.1728, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0431, KL: 0.0011, Current Beta: 0.0010) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0248, recon=0.0248, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0282, recon=0.0282, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0265, recon=0.0265, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0476, recon=0.0476, kl=0.0006, beta=0.0010\n",
      "Batch 100, loss=0.0203, recon=0.0203, kl=0.0006, beta=0.0010\n",
      "Batch 120, loss=0.0245, recon=0.0245, kl=0.0008, beta=0.0010\n",
      "Batch 140, loss=0.0289, recon=0.0289, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0300, recon=0.0300, kl=0.0004, beta=0.0010\n",
      "Batch 180, loss=0.0233, recon=0.0233, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0426 (Recon: 0.0426, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0394, recon=0.0394, kl=0.0010, beta=0.0010\n",
      "Batch 40, loss=0.0367, recon=0.0367, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0321, recon=0.0321, kl=0.0010, beta=0.0010\n",
      "Batch 80, loss=0.0249, recon=0.0249, kl=0.0003, beta=0.0010\n",
      "Batch 100, loss=0.0346, recon=0.0346, kl=0.0005, beta=0.0010\n",
      "Batch 120, loss=0.5583, recon=0.5583, kl=0.0045, beta=0.0010\n",
      "Batch 140, loss=0.0490, recon=0.0490, kl=0.0011, beta=0.0010\n",
      "Batch 160, loss=0.0337, recon=0.0337, kl=0.0008, beta=0.0010\n",
      "Batch 180, loss=0.0325, recon=0.0325, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0414, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0355\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0216, recon=0.0216, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0383, recon=0.0383, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0409, recon=0.0409, kl=0.0006, beta=0.0010\n",
      "Batch 80, loss=0.0242, recon=0.0242, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0497, recon=0.0497, kl=0.0009, beta=0.0010\n",
      "Batch 120, loss=0.0223, recon=0.0223, kl=0.0008, beta=0.0010\n",
      "Batch 140, loss=0.0314, recon=0.0314, kl=0.0006, beta=0.0010\n",
      "Batch 160, loss=0.0214, recon=0.0214, kl=0.0005, beta=0.0010\n",
      "Batch 180, loss=0.0247, recon=0.0247, kl=0.0014, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0412 (Recon: 0.0412, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0352\n",
      "\n",
      "[VRAE Run 62/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1999, recon=0.1999, kl=19.4317, beta=0.0000\n",
      "Batch 40, loss=0.1441, recon=0.1441, kl=28.7637, beta=0.0000\n",
      "Batch 60, loss=0.1073, recon=0.1073, kl=30.1598, beta=0.0000\n",
      "Batch 80, loss=0.0720, recon=0.0720, kl=29.6713, beta=0.0000\n",
      "Batch 100, loss=0.1098, recon=0.1098, kl=29.7124, beta=0.0000\n",
      "Batch 120, loss=0.1556, recon=0.1556, kl=33.5200, beta=0.0000\n",
      "Batch 140, loss=0.0512, recon=0.0512, kl=33.9722, beta=0.0000\n",
      "Batch 160, loss=0.0539, recon=0.0539, kl=34.3657, beta=0.0000\n",
      "Batch 180, loss=0.0496, recon=0.0496, kl=31.1264, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1333 (Recon: 0.1333, KL: 28.6479, Current Beta: 0.0000) | Avg Valid Loss: 0.0600 | Avg Valid recon Loss: 0.0600\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0388, recon=0.0388, kl=33.8279, beta=0.0000\n",
      "Batch 40, loss=0.0429, recon=0.0429, kl=32.6276, beta=0.0000\n",
      "Batch 60, loss=0.0448, recon=0.0448, kl=33.7974, beta=0.0000\n",
      "Batch 80, loss=0.0400, recon=0.0400, kl=35.2347, beta=0.0000\n",
      "Batch 100, loss=0.0382, recon=0.0382, kl=35.4333, beta=0.0000\n",
      "Batch 120, loss=0.0342, recon=0.0342, kl=33.3442, beta=0.0000\n",
      "Batch 140, loss=0.0752, recon=0.0752, kl=34.0122, beta=0.0000\n",
      "Batch 160, loss=0.0648, recon=0.0648, kl=35.1342, beta=0.0000\n",
      "Batch 180, loss=0.0487, recon=0.0487, kl=37.7820, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0621 (Recon: 0.0621, KL: 34.3113, Current Beta: 0.0000) | Avg Valid Loss: 0.0585 | Avg Valid recon Loss: 0.0585\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0289, recon=0.0289, kl=39.3041, beta=0.0000\n",
      "Batch 40, loss=0.0570, recon=0.0570, kl=39.0393, beta=0.0000\n",
      "Batch 60, loss=0.0667, recon=0.0667, kl=39.8286, beta=0.0000\n",
      "Batch 80, loss=0.0410, recon=0.0410, kl=40.0033, beta=0.0000\n",
      "Batch 100, loss=0.0415, recon=0.0415, kl=32.3687, beta=0.0000\n",
      "Batch 120, loss=0.0436, recon=0.0436, kl=36.2478, beta=0.0000\n",
      "Batch 140, loss=0.0283, recon=0.0283, kl=39.0308, beta=0.0000\n",
      "Batch 160, loss=0.0399, recon=0.0399, kl=39.0439, beta=0.0000\n",
      "Batch 180, loss=0.0523, recon=0.0523, kl=38.1388, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0578 (Recon: 0.0578, KL: 38.2250, Current Beta: 0.0000) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0271, recon=0.0271, kl=39.2899, beta=0.0000\n",
      "Batch 40, loss=0.0513, recon=0.0513, kl=38.8528, beta=0.0000\n",
      "Batch 60, loss=0.0407, recon=0.0407, kl=41.4772, beta=0.0000\n",
      "Batch 80, loss=0.0823, recon=0.0823, kl=41.2019, beta=0.0000\n",
      "Batch 100, loss=0.0695, recon=0.0695, kl=40.4987, beta=0.0000\n",
      "Batch 120, loss=0.0439, recon=0.0439, kl=42.2336, beta=0.0000\n",
      "Batch 140, loss=0.0331, recon=0.0331, kl=43.0793, beta=0.0000\n",
      "Batch 160, loss=0.0253, recon=0.0253, kl=44.3702, beta=0.0000\n",
      "Batch 180, loss=0.0436, recon=0.0436, kl=41.7210, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0472, KL: 41.4533, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0498, recon=0.0498, kl=39.4397, beta=0.0000\n",
      "Batch 40, loss=0.0527, recon=0.0527, kl=32.2221, beta=0.0000\n",
      "Batch 60, loss=0.0503, recon=0.0503, kl=32.7695, beta=0.0000\n",
      "Batch 80, loss=0.0317, recon=0.0317, kl=25.7031, beta=0.0000\n",
      "Batch 100, loss=0.0296, recon=0.0296, kl=34.8966, beta=0.0000\n",
      "Batch 120, loss=0.0285, recon=0.0285, kl=39.7386, beta=0.0000\n",
      "Batch 140, loss=0.0310, recon=0.0310, kl=40.4303, beta=0.0000\n",
      "Batch 160, loss=0.0284, recon=0.0284, kl=38.1364, beta=0.0000\n",
      "Batch 180, loss=0.0262, recon=0.0262, kl=38.5755, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0508, KL: 35.9183, Current Beta: 0.0000) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0274, recon=0.0274, kl=31.9457, beta=0.0000\n",
      "Batch 40, loss=0.0297, recon=0.0297, kl=36.3756, beta=0.0000\n",
      "Batch 60, loss=0.0210, recon=0.0209, kl=36.9282, beta=0.0000\n",
      "Batch 80, loss=0.0528, recon=0.0527, kl=36.8090, beta=0.0000\n",
      "Batch 100, loss=0.0321, recon=0.0321, kl=32.3314, beta=0.0000\n",
      "Batch 120, loss=0.0313, recon=0.0313, kl=36.7259, beta=0.0000\n",
      "Batch 140, loss=0.0398, recon=0.0398, kl=36.7568, beta=0.0000\n",
      "Batch 160, loss=0.0282, recon=0.0282, kl=36.6399, beta=0.0000\n",
      "Batch 180, loss=0.0478, recon=0.0478, kl=37.7791, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 35.9837, Current Beta: 0.0000) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0432, recon=0.0431, kl=36.0329, beta=0.0000\n",
      "Batch 40, loss=0.1230, recon=0.1229, kl=33.5109, beta=0.0000\n",
      "Batch 60, loss=0.0237, recon=0.0237, kl=31.8773, beta=0.0000\n",
      "Batch 80, loss=0.0544, recon=0.0544, kl=38.8854, beta=0.0000\n",
      "Batch 100, loss=0.0308, recon=0.0308, kl=38.9558, beta=0.0000\n",
      "Batch 120, loss=0.0262, recon=0.0262, kl=36.8879, beta=0.0000\n",
      "Batch 140, loss=0.0248, recon=0.0248, kl=37.5795, beta=0.0000\n",
      "Batch 160, loss=0.1190, recon=0.1189, kl=36.0848, beta=0.0000\n",
      "Batch 180, loss=0.0410, recon=0.0409, kl=34.2084, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0397 (Recon: 0.0397, KL: 35.9637, Current Beta: 0.0000) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0348, recon=0.0348, kl=30.7582, beta=0.0000\n",
      "Batch 40, loss=0.0243, recon=0.0242, kl=26.3628, beta=0.0000\n",
      "Batch 60, loss=0.0297, recon=0.0296, kl=24.3208, beta=0.0000\n",
      "Batch 80, loss=0.1019, recon=0.1018, kl=28.8284, beta=0.0000\n",
      "Batch 100, loss=0.0307, recon=0.0307, kl=27.2313, beta=0.0000\n",
      "Batch 120, loss=0.0414, recon=0.0413, kl=26.7823, beta=0.0000\n",
      "Batch 140, loss=0.0304, recon=0.0304, kl=27.8294, beta=0.0000\n",
      "Batch 160, loss=0.0378, recon=0.0378, kl=25.2176, beta=0.0000\n",
      "Batch 180, loss=0.0234, recon=0.0233, kl=25.6640, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0399 (Recon: 0.0399, KL: 27.2940, Current Beta: 0.0000) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0326\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0650, recon=0.0650, kl=18.4401, beta=0.0000\n",
      "Batch 40, loss=0.0328, recon=0.0327, kl=20.2437, beta=0.0000\n",
      "Batch 60, loss=0.0347, recon=0.0347, kl=17.7429, beta=0.0000\n",
      "Batch 80, loss=0.0253, recon=0.0252, kl=16.8272, beta=0.0000\n",
      "Batch 100, loss=0.0388, recon=0.0388, kl=21.4852, beta=0.0000\n",
      "Batch 120, loss=0.0232, recon=0.0231, kl=20.2876, beta=0.0000\n",
      "Batch 140, loss=0.0448, recon=0.0447, kl=22.1462, beta=0.0000\n",
      "Batch 160, loss=0.0244, recon=0.0243, kl=22.5863, beta=0.0000\n",
      "Batch 180, loss=0.0247, recon=0.0246, kl=18.9060, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0387 (Recon: 0.0386, KL: 20.2084, Current Beta: 0.0000) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0257, recon=0.0255, kl=12.3329, beta=0.0000\n",
      "Batch 40, loss=0.0318, recon=0.0317, kl=11.5654, beta=0.0000\n",
      "Batch 60, loss=0.0217, recon=0.0216, kl=11.7567, beta=0.0000\n",
      "Batch 80, loss=0.0227, recon=0.0225, kl=12.1571, beta=0.0000\n",
      "Batch 100, loss=0.0471, recon=0.0470, kl=13.2890, beta=0.0000\n",
      "Batch 120, loss=0.1171, recon=0.1169, kl=15.4496, beta=0.0000\n",
      "Batch 140, loss=0.0585, recon=0.0583, kl=22.0686, beta=0.0000\n",
      "Batch 160, loss=0.0534, recon=0.0532, kl=16.9108, beta=0.0000\n",
      "Batch 180, loss=0.0359, recon=0.0358, kl=14.2841, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0553, KL: 14.5470, Current Beta: 0.0000) | Avg Valid Loss: 0.0459 | Avg Valid recon Loss: 0.0457\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0567, recon=0.0564, kl=7.1442, beta=0.0000\n",
      "Batch 40, loss=0.0383, recon=0.0381, kl=7.5742, beta=0.0000\n",
      "Batch 60, loss=0.0621, recon=0.0618, kl=7.5771, beta=0.0000\n",
      "Batch 80, loss=0.0234, recon=0.0232, kl=6.3538, beta=0.0000\n",
      "Batch 100, loss=0.0439, recon=0.0438, kl=6.0791, beta=0.0000\n",
      "Batch 120, loss=0.0282, recon=0.0280, kl=5.9438, beta=0.0000\n",
      "Batch 140, loss=0.0421, recon=0.0419, kl=6.2049, beta=0.0000\n",
      "Batch 160, loss=0.0303, recon=0.0301, kl=8.2899, beta=0.0000\n",
      "Batch 180, loss=0.0312, recon=0.0309, kl=7.7494, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0506 (Recon: 0.0503, KL: 7.3398, Current Beta: 0.0000) | Avg Valid Loss: 0.0440 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0354, recon=0.0351, kl=4.4597, beta=0.0001\n",
      "Batch 40, loss=0.0277, recon=0.0275, kl=2.7153, beta=0.0001\n",
      "Batch 60, loss=0.0277, recon=0.0276, kl=1.9200, beta=0.0001\n",
      "Batch 80, loss=0.0388, recon=0.0387, kl=1.9394, beta=0.0001\n",
      "Batch 100, loss=0.0467, recon=0.0465, kl=2.4275, beta=0.0001\n",
      "Batch 120, loss=0.0374, recon=0.0372, kl=2.3577, beta=0.0001\n",
      "Batch 140, loss=0.0299, recon=0.0297, kl=2.1786, beta=0.0001\n",
      "Batch 160, loss=0.0370, recon=0.0369, kl=1.9803, beta=0.0001\n",
      "Batch 180, loss=0.0279, recon=0.0278, kl=1.4953, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0403 (Recon: 0.0401, KL: 2.6557, Current Beta: 0.0001) | Avg Valid Loss: 0.0322 | Avg Valid recon Loss: 0.0321\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0173, recon=0.0172, kl=0.4870, beta=0.0002\n",
      "Batch 40, loss=0.0209, recon=0.0209, kl=0.1851, beta=0.0002\n",
      "Batch 60, loss=0.0248, recon=0.0247, kl=0.3246, beta=0.0002\n",
      "Batch 80, loss=0.0748, recon=0.0747, kl=0.5655, beta=0.0002\n",
      "Batch 100, loss=0.0765, recon=0.0764, kl=0.4479, beta=0.0002\n",
      "Batch 120, loss=0.0237, recon=0.0237, kl=0.2801, beta=0.0002\n",
      "Batch 140, loss=0.0263, recon=0.0262, kl=0.1091, beta=0.0002\n",
      "Batch 160, loss=0.0284, recon=0.0284, kl=0.1488, beta=0.0002\n",
      "Batch 180, loss=0.0258, recon=0.0258, kl=0.1598, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0371 (Recon: 0.0370, KL: 0.3518, Current Beta: 0.0002) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0326\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0413, recon=0.0413, kl=0.0439, beta=0.0004\n",
      "Batch 40, loss=0.0227, recon=0.0227, kl=0.0143, beta=0.0004\n",
      "Batch 60, loss=0.0263, recon=0.0262, kl=0.0565, beta=0.0004\n",
      "Batch 80, loss=0.0312, recon=0.0311, kl=0.1879, beta=0.0004\n",
      "Batch 100, loss=0.0400, recon=0.0399, kl=0.3555, beta=0.0004\n",
      "Batch 120, loss=0.0471, recon=0.0471, kl=0.1436, beta=0.0004\n",
      "Batch 140, loss=0.0356, recon=0.0355, kl=0.0926, beta=0.0004\n",
      "Batch 160, loss=0.0222, recon=0.0221, kl=0.0396, beta=0.0004\n",
      "Batch 180, loss=0.0332, recon=0.0332, kl=0.0412, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0412 (Recon: 0.0412, KL: 0.1083, Current Beta: 0.0004) | Avg Valid Loss: 0.0366 | Avg Valid recon Loss: 0.0366\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1243, recon=0.1243, kl=0.0099, beta=0.0006\n",
      "Batch 40, loss=0.0355, recon=0.0355, kl=0.0162, beta=0.0006\n",
      "Batch 60, loss=0.0449, recon=0.0448, kl=0.1102, beta=0.0006\n",
      "Batch 80, loss=0.0381, recon=0.0377, kl=0.6393, beta=0.0006\n",
      "Batch 100, loss=0.0270, recon=0.0268, kl=0.2473, beta=0.0006\n",
      "Batch 120, loss=0.0284, recon=0.0284, kl=0.0693, beta=0.0006\n",
      "Batch 140, loss=0.0367, recon=0.0367, kl=0.0369, beta=0.0006\n",
      "Batch 160, loss=0.0428, recon=0.0428, kl=0.0188, beta=0.0006\n",
      "Batch 180, loss=0.0300, recon=0.0300, kl=0.0187, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0496, KL: 0.1302, Current Beta: 0.0006) | Avg Valid Loss: 0.0367 | Avg Valid recon Loss: 0.0367\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0364, recon=0.0364, kl=0.0046, beta=0.0010\n",
      "Batch 40, loss=0.0479, recon=0.0479, kl=0.0041, beta=0.0010\n",
      "Batch 60, loss=0.0242, recon=0.0242, kl=0.0031, beta=0.0010\n",
      "Batch 80, loss=0.0214, recon=0.0214, kl=0.0037, beta=0.0010\n",
      "Batch 100, loss=0.0360, recon=0.0360, kl=0.0031, beta=0.0010\n",
      "Batch 120, loss=0.0221, recon=0.0221, kl=0.0026, beta=0.0010\n",
      "Batch 140, loss=0.0254, recon=0.0254, kl=0.0021, beta=0.0010\n",
      "Batch 160, loss=0.0275, recon=0.0275, kl=0.0032, beta=0.0010\n",
      "Batch 180, loss=0.0388, recon=0.0388, kl=0.0046, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0353 (Recon: 0.0353, KL: 0.0043, Current Beta: 0.0010) | Avg Valid Loss: 0.0459 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0505, recon=0.0504, kl=0.0144, beta=0.0010\n",
      "Batch 40, loss=0.0296, recon=0.0296, kl=0.0219, beta=0.0010\n",
      "Batch 60, loss=0.0379, recon=0.0379, kl=0.0037, beta=0.0010\n",
      "Batch 80, loss=0.0356, recon=0.0356, kl=0.0119, beta=0.0010\n",
      "Batch 100, loss=0.0788, recon=0.0787, kl=0.0218, beta=0.0010\n",
      "Batch 120, loss=0.0452, recon=0.0450, kl=0.1031, beta=0.0010\n",
      "Batch 140, loss=0.0413, recon=0.0413, kl=0.0772, beta=0.0010\n",
      "Batch 160, loss=0.0401, recon=0.0401, kl=0.0141, beta=0.0010\n",
      "Batch 180, loss=0.0225, recon=0.0225, kl=0.0333, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0474 (Recon: 0.0473, KL: 0.0338, Current Beta: 0.0010) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0977, recon=0.0977, kl=0.0098, beta=0.0010\n",
      "Batch 40, loss=0.1216, recon=0.1213, kl=0.2521, beta=0.0010\n",
      "Batch 60, loss=0.0777, recon=0.0770, kl=0.6833, beta=0.0010\n",
      "Batch 80, loss=0.0516, recon=0.0513, kl=0.2625, beta=0.0010\n",
      "Batch 100, loss=0.0400, recon=0.0399, kl=0.0601, beta=0.0010\n",
      "Batch 120, loss=0.0440, recon=0.0440, kl=0.0212, beta=0.0010\n",
      "Batch 140, loss=0.0417, recon=0.0417, kl=0.0101, beta=0.0010\n",
      "Batch 160, loss=0.0462, recon=0.0462, kl=0.0082, beta=0.0010\n",
      "Batch 180, loss=0.1166, recon=0.1166, kl=0.0069, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0658 (Recon: 0.0657, KL: 0.1481, Current Beta: 0.0010) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0622, recon=0.0622, kl=0.0045, beta=0.0010\n",
      "Batch 40, loss=0.0563, recon=0.0563, kl=0.0024, beta=0.0010\n",
      "Batch 60, loss=0.0340, recon=0.0340, kl=0.0024, beta=0.0010\n",
      "Batch 80, loss=0.0251, recon=0.0251, kl=0.0053, beta=0.0010\n",
      "Batch 100, loss=0.0336, recon=0.0336, kl=0.0615, beta=0.0010\n",
      "Batch 120, loss=0.0412, recon=0.0412, kl=0.0450, beta=0.0010\n",
      "Batch 140, loss=0.0420, recon=0.0420, kl=0.0185, beta=0.0010\n",
      "Batch 160, loss=0.1609, recon=0.1609, kl=0.0109, beta=0.0010\n",
      "Batch 180, loss=0.0679, recon=0.0679, kl=0.0567, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0553 (Recon: 0.0553, KL: 0.0185, Current Beta: 0.0010) | Avg Valid Loss: 0.0864 | Avg Valid recon Loss: 0.0864\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0323, recon=0.0320, kl=0.2655, beta=0.0010\n",
      "Batch 40, loss=0.0706, recon=0.0702, kl=0.3860, beta=0.0010\n",
      "Batch 60, loss=0.0310, recon=0.0308, kl=0.2483, beta=0.0010\n",
      "Batch 80, loss=0.0311, recon=0.0310, kl=0.1136, beta=0.0010\n",
      "Batch 100, loss=0.0315, recon=0.0315, kl=0.0478, beta=0.0010\n",
      "Batch 120, loss=0.0634, recon=0.0633, kl=0.0224, beta=0.0010\n",
      "Batch 140, loss=0.0703, recon=0.0703, kl=0.0404, beta=0.0010\n",
      "Batch 160, loss=1.9637, recon=1.9628, kl=0.8604, beta=0.0010\n",
      "Batch 180, loss=43.0475, recon=43.0382, kl=9.2775, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 63/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3901, recon=0.3901, kl=0.7916, beta=0.0000\n",
      "Batch 40, loss=0.3744, recon=0.3744, kl=13.6528, beta=0.0000\n",
      "Batch 60, loss=0.4180, recon=0.4180, kl=31.6435, beta=0.0000\n",
      "Batch 80, loss=0.2602, recon=0.2602, kl=40.8778, beta=0.0000\n",
      "Batch 100, loss=0.1736, recon=0.1736, kl=48.1432, beta=0.0000\n",
      "Batch 120, loss=0.1603, recon=0.1603, kl=54.2370, beta=0.0000\n",
      "Batch 140, loss=0.2668, recon=0.2668, kl=62.0181, beta=0.0000\n",
      "Batch 160, loss=0.2125, recon=0.2125, kl=67.7058, beta=0.0000\n",
      "Batch 180, loss=0.0800, recon=0.0800, kl=70.6871, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3063 (Recon: 0.3063, KL: 39.6235, Current Beta: 0.0000) | Avg Valid Loss: 0.1356 | Avg Valid recon Loss: 0.1356\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1304, recon=0.1304, kl=74.0893, beta=0.0000\n",
      "Batch 40, loss=0.1409, recon=0.1409, kl=74.6974, beta=0.0000\n",
      "Batch 60, loss=0.0998, recon=0.0998, kl=72.2350, beta=0.0000\n",
      "Batch 80, loss=0.1766, recon=0.1766, kl=71.5898, beta=0.0000\n",
      "Batch 100, loss=0.1395, recon=0.1395, kl=71.8757, beta=0.0000\n",
      "Batch 120, loss=0.0935, recon=0.0935, kl=73.4649, beta=0.0000\n",
      "Batch 140, loss=0.1577, recon=0.1577, kl=76.9475, beta=0.0000\n",
      "Batch 160, loss=0.1059, recon=0.1059, kl=78.0510, beta=0.0000\n",
      "Batch 180, loss=0.0949, recon=0.0949, kl=77.6132, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1313 (Recon: 0.1313, KL: 74.0955, Current Beta: 0.0000) | Avg Valid Loss: 0.0944 | Avg Valid recon Loss: 0.0944\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0725, recon=0.0725, kl=79.1621, beta=0.0000\n",
      "Batch 40, loss=0.0687, recon=0.0687, kl=80.0087, beta=0.0000\n",
      "Batch 60, loss=0.0851, recon=0.0851, kl=83.9861, beta=0.0000\n",
      "Batch 80, loss=0.0624, recon=0.0624, kl=83.1771, beta=0.0000\n",
      "Batch 100, loss=0.0631, recon=0.0631, kl=85.2333, beta=0.0000\n",
      "Batch 120, loss=0.1240, recon=0.1240, kl=89.1410, beta=0.0000\n",
      "Batch 140, loss=0.0828, recon=0.0828, kl=88.1685, beta=0.0000\n",
      "Batch 160, loss=0.0572, recon=0.0572, kl=87.6176, beta=0.0000\n",
      "Batch 180, loss=0.0571, recon=0.0571, kl=88.4535, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0961 (Recon: 0.0961, KL: 84.4521, Current Beta: 0.0000) | Avg Valid Loss: 0.0746 | Avg Valid recon Loss: 0.0746\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0975, recon=0.0974, kl=89.7571, beta=0.0000\n",
      "Batch 40, loss=0.0721, recon=0.0721, kl=89.7244, beta=0.0000\n",
      "Batch 60, loss=0.0570, recon=0.0570, kl=89.5999, beta=0.0000\n",
      "Batch 80, loss=0.3894, recon=0.3894, kl=89.3933, beta=0.0000\n",
      "Batch 100, loss=0.0569, recon=0.0569, kl=89.3610, beta=0.0000\n",
      "Batch 120, loss=0.0565, recon=0.0565, kl=89.5112, beta=0.0000\n",
      "Batch 140, loss=0.0658, recon=0.0658, kl=87.7642, beta=0.0000\n",
      "Batch 160, loss=0.0606, recon=0.0606, kl=88.1867, beta=0.0000\n",
      "Batch 180, loss=0.0607, recon=0.0607, kl=87.8474, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0795 (Recon: 0.0795, KL: 89.1205, Current Beta: 0.0000) | Avg Valid Loss: 0.0652 | Avg Valid recon Loss: 0.0652\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0494, recon=0.0494, kl=88.0257, beta=0.0000\n",
      "Batch 40, loss=0.0730, recon=0.0730, kl=86.1379, beta=0.0000\n",
      "Batch 60, loss=0.0499, recon=0.0499, kl=85.6264, beta=0.0000\n",
      "Batch 80, loss=0.0656, recon=0.0656, kl=85.3954, beta=0.0000\n",
      "Batch 100, loss=0.0664, recon=0.0664, kl=84.4081, beta=0.0000\n",
      "Batch 120, loss=0.0503, recon=0.0503, kl=83.5254, beta=0.0000\n",
      "Batch 140, loss=0.0415, recon=0.0415, kl=81.9553, beta=0.0000\n",
      "Batch 160, loss=0.0687, recon=0.0687, kl=81.0775, beta=0.0000\n",
      "Batch 180, loss=0.1225, recon=0.1225, kl=81.5575, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0704 (Recon: 0.0704, KL: 84.3050, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0438, recon=0.0438, kl=77.1598, beta=0.0000\n",
      "Batch 40, loss=0.0432, recon=0.0432, kl=74.3669, beta=0.0000\n",
      "Batch 60, loss=0.0314, recon=0.0314, kl=71.9543, beta=0.0000\n",
      "Batch 80, loss=0.0727, recon=0.0727, kl=68.4965, beta=0.0000\n",
      "Batch 100, loss=0.0329, recon=0.0329, kl=66.6465, beta=0.0000\n",
      "Batch 120, loss=0.0828, recon=0.0828, kl=65.5057, beta=0.0000\n",
      "Batch 140, loss=0.0582, recon=0.0582, kl=61.0688, beta=0.0000\n",
      "Batch 160, loss=0.0572, recon=0.0572, kl=62.1039, beta=0.0000\n",
      "Batch 180, loss=0.0409, recon=0.0409, kl=66.6598, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0645 (Recon: 0.0645, KL: 68.9638, Current Beta: 0.0000) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0559\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0380, recon=0.0379, kl=59.7346, beta=0.0000\n",
      "Batch 40, loss=0.0407, recon=0.0406, kl=54.1927, beta=0.0000\n",
      "Batch 60, loss=0.0367, recon=0.0367, kl=47.8760, beta=0.0000\n",
      "Batch 80, loss=0.0318, recon=0.0318, kl=44.2420, beta=0.0000\n",
      "Batch 100, loss=0.0429, recon=0.0429, kl=41.0234, beta=0.0000\n",
      "Batch 120, loss=0.0448, recon=0.0447, kl=40.7317, beta=0.0000\n",
      "Batch 140, loss=0.0343, recon=0.0342, kl=41.2289, beta=0.0000\n",
      "Batch 160, loss=0.0267, recon=0.0267, kl=39.9479, beta=0.0000\n",
      "Batch 180, loss=0.0319, recon=0.0319, kl=39.1259, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0603 (Recon: 0.0603, KL: 46.7397, Current Beta: 0.0000) | Avg Valid Loss: 0.0523 | Avg Valid recon Loss: 0.0522\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0710, recon=0.0710, kl=30.8959, beta=0.0000\n",
      "Batch 40, loss=0.0435, recon=0.0435, kl=24.3661, beta=0.0000\n",
      "Batch 60, loss=0.0558, recon=0.0557, kl=25.5022, beta=0.0000\n",
      "Batch 80, loss=0.0336, recon=0.0336, kl=24.8219, beta=0.0000\n",
      "Batch 100, loss=0.0383, recon=0.0383, kl=25.8896, beta=0.0000\n",
      "Batch 120, loss=0.0423, recon=0.0423, kl=23.4135, beta=0.0000\n",
      "Batch 140, loss=0.0395, recon=0.0395, kl=22.5226, beta=0.0000\n",
      "Batch 160, loss=0.0451, recon=0.0451, kl=22.5047, beta=0.0000\n",
      "Batch 180, loss=0.0348, recon=0.0348, kl=21.9278, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 25.3919, Current Beta: 0.0000) | Avg Valid Loss: 0.0503 | Avg Valid recon Loss: 0.0502\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0941, recon=0.0940, kl=13.2342, beta=0.0000\n",
      "Batch 40, loss=0.0371, recon=0.0371, kl=12.6095, beta=0.0000\n",
      "Batch 60, loss=0.0383, recon=0.0383, kl=13.7540, beta=0.0000\n",
      "Batch 80, loss=0.2385, recon=0.2384, kl=11.7389, beta=0.0000\n",
      "Batch 100, loss=0.0370, recon=0.0369, kl=10.3043, beta=0.0000\n",
      "Batch 120, loss=0.0338, recon=0.0337, kl=10.4730, beta=0.0000\n",
      "Batch 140, loss=0.0367, recon=0.0367, kl=10.2170, beta=0.0000\n",
      "Batch 160, loss=0.0620, recon=0.0620, kl=10.7842, beta=0.0000\n",
      "Batch 180, loss=0.0391, recon=0.0390, kl=8.9475, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0545, KL: 12.0311, Current Beta: 0.0000) | Avg Valid Loss: 0.0483 | Avg Valid recon Loss: 0.0483\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0408, recon=0.0408, kl=4.6585, beta=0.0000\n",
      "Batch 40, loss=0.0314, recon=0.0313, kl=5.3264, beta=0.0000\n",
      "Batch 60, loss=0.0339, recon=0.0338, kl=5.0667, beta=0.0000\n",
      "Batch 80, loss=0.0346, recon=0.0346, kl=4.9908, beta=0.0000\n",
      "Batch 100, loss=0.0663, recon=0.0662, kl=5.2548, beta=0.0000\n",
      "Batch 120, loss=0.0385, recon=0.0385, kl=4.3193, beta=0.0000\n",
      "Batch 140, loss=0.0601, recon=0.0600, kl=3.8131, beta=0.0000\n",
      "Batch 160, loss=0.0402, recon=0.0402, kl=3.7121, beta=0.0000\n",
      "Batch 180, loss=0.0231, recon=0.0231, kl=4.1000, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0525 (Recon: 0.0524, KL: 4.8040, Current Beta: 0.0000) | Avg Valid Loss: 0.0462 | Avg Valid recon Loss: 0.0462\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0269, recon=0.0269, kl=2.4997, beta=0.0000\n",
      "Batch 40, loss=0.0382, recon=0.0381, kl=1.8911, beta=0.0000\n",
      "Batch 60, loss=0.0283, recon=0.0283, kl=1.2571, beta=0.0000\n",
      "Batch 80, loss=0.0373, recon=0.0372, kl=1.5978, beta=0.0000\n",
      "Batch 100, loss=0.0332, recon=0.0331, kl=1.7799, beta=0.0000\n",
      "Batch 120, loss=0.0444, recon=0.0444, kl=1.5873, beta=0.0000\n",
      "Batch 140, loss=0.0317, recon=0.0317, kl=1.4285, beta=0.0000\n",
      "Batch 160, loss=0.0509, recon=0.0508, kl=1.6640, beta=0.0000\n",
      "Batch 180, loss=0.0480, recon=0.0480, kl=1.1537, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0507 (Recon: 0.0507, KL: 1.7751, Current Beta: 0.0000) | Avg Valid Loss: 0.0454 | Avg Valid recon Loss: 0.0454\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0362, recon=0.0362, kl=0.4738, beta=0.0001\n",
      "Batch 40, loss=0.0385, recon=0.0385, kl=0.4859, beta=0.0001\n",
      "Batch 60, loss=0.0429, recon=0.0429, kl=0.5608, beta=0.0001\n",
      "Batch 80, loss=0.0442, recon=0.0441, kl=0.5300, beta=0.0001\n",
      "Batch 100, loss=0.0380, recon=0.0379, kl=0.3581, beta=0.0001\n",
      "Batch 120, loss=0.0403, recon=0.0402, kl=0.2738, beta=0.0001\n",
      "Batch 140, loss=0.0773, recon=0.0773, kl=0.3980, beta=0.0001\n",
      "Batch 160, loss=0.0679, recon=0.0679, kl=0.3088, beta=0.0001\n",
      "Batch 180, loss=0.0381, recon=0.0381, kl=0.2291, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0493 (Recon: 0.0493, KL: 0.4658, Current Beta: 0.0001) | Avg Valid Loss: 0.0439 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0389, recon=0.0389, kl=0.0411, beta=0.0002\n",
      "Batch 40, loss=0.0321, recon=0.0321, kl=0.0591, beta=0.0002\n",
      "Batch 60, loss=0.0304, recon=0.0304, kl=0.0699, beta=0.0002\n",
      "Batch 80, loss=0.0240, recon=0.0240, kl=0.0661, beta=0.0002\n",
      "Batch 100, loss=0.0238, recon=0.0238, kl=0.0418, beta=0.0002\n",
      "Batch 120, loss=0.0345, recon=0.0345, kl=0.0220, beta=0.0002\n",
      "Batch 140, loss=0.0312, recon=0.0312, kl=0.0208, beta=0.0002\n",
      "Batch 160, loss=0.0309, recon=0.0309, kl=0.0298, beta=0.0002\n",
      "Batch 180, loss=0.0248, recon=0.0248, kl=0.0139, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0481 (Recon: 0.0481, KL: 0.0433, Current Beta: 0.0002) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0280, recon=0.0280, kl=0.0034, beta=0.0004\n",
      "Batch 40, loss=0.0532, recon=0.0532, kl=0.0030, beta=0.0004\n",
      "Batch 60, loss=0.0772, recon=0.0772, kl=0.0096, beta=0.0004\n",
      "Batch 80, loss=0.0302, recon=0.0302, kl=0.0066, beta=0.0004\n",
      "Batch 100, loss=0.0396, recon=0.0396, kl=0.0031, beta=0.0004\n",
      "Batch 120, loss=0.0273, recon=0.0273, kl=0.0047, beta=0.0004\n",
      "Batch 140, loss=0.0411, recon=0.0411, kl=0.0021, beta=0.0004\n",
      "Batch 160, loss=0.0370, recon=0.0370, kl=0.0050, beta=0.0004\n",
      "Batch 180, loss=0.0318, recon=0.0318, kl=0.0022, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0468 (Recon: 0.0468, KL: 0.0051, Current Beta: 0.0004) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0265, recon=0.0265, kl=0.0035, beta=0.0006\n",
      "Batch 40, loss=0.0396, recon=0.0396, kl=0.0012, beta=0.0006\n",
      "Batch 60, loss=0.0230, recon=0.0230, kl=0.0007, beta=0.0006\n",
      "Batch 80, loss=0.0882, recon=0.0882, kl=0.0014, beta=0.0006\n",
      "Batch 100, loss=0.0529, recon=0.0529, kl=0.0010, beta=0.0006\n",
      "Batch 120, loss=0.0292, recon=0.0292, kl=0.0043, beta=0.0006\n",
      "Batch 140, loss=0.0281, recon=0.0281, kl=0.0014, beta=0.0006\n",
      "Batch 160, loss=0.0401, recon=0.0401, kl=0.0020, beta=0.0006\n",
      "Batch 180, loss=0.0422, recon=0.0422, kl=0.0015, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 0.0021, Current Beta: 0.0006) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0858, recon=0.0858, kl=0.0014, beta=0.0010\n",
      "Batch 40, loss=0.0329, recon=0.0329, kl=0.0007, beta=0.0010\n",
      "Batch 60, loss=0.1797, recon=0.1797, kl=0.0010, beta=0.0010\n",
      "Batch 80, loss=0.0461, recon=0.0461, kl=0.0005, beta=0.0010\n",
      "Batch 100, loss=0.0432, recon=0.0432, kl=0.0007, beta=0.0010\n",
      "Batch 120, loss=0.1745, recon=0.1745, kl=0.0016, beta=0.0010\n",
      "Batch 140, loss=0.1420, recon=0.1420, kl=0.0007, beta=0.0010\n",
      "Batch 160, loss=0.0372, recon=0.0372, kl=0.0007, beta=0.0010\n",
      "Batch 180, loss=0.0444, recon=0.0444, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0446, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0347, recon=0.0347, kl=0.0014, beta=0.0010\n",
      "Batch 40, loss=0.0251, recon=0.0251, kl=0.0009, beta=0.0010\n",
      "Batch 60, loss=0.0569, recon=0.0569, kl=0.0008, beta=0.0010\n",
      "Batch 80, loss=0.0272, recon=0.0272, kl=0.0006, beta=0.0010\n",
      "Batch 100, loss=0.0327, recon=0.0327, kl=0.0011, beta=0.0010\n",
      "Batch 120, loss=0.0664, recon=0.0664, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0439, recon=0.0439, kl=0.0015, beta=0.0010\n",
      "Batch 160, loss=0.0269, recon=0.0269, kl=0.0006, beta=0.0010\n",
      "Batch 180, loss=0.0258, recon=0.0258, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0440, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0384\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0356, recon=0.0356, kl=0.0036, beta=0.0010\n",
      "Batch 40, loss=0.0329, recon=0.0329, kl=0.0008, beta=0.0010\n",
      "Batch 60, loss=0.0279, recon=0.0279, kl=0.0016, beta=0.0010\n",
      "Batch 80, loss=0.0251, recon=0.0251, kl=0.0006, beta=0.0010\n",
      "Batch 100, loss=0.0285, recon=0.0285, kl=0.0009, beta=0.0010\n",
      "Batch 120, loss=0.0288, recon=0.0288, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0266, recon=0.0266, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0330, recon=0.0330, kl=0.0004, beta=0.0010\n",
      "Batch 180, loss=0.0633, recon=0.0633, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0431, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0349, recon=0.0349, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0299, recon=0.0299, kl=0.0007, beta=0.0010\n",
      "Batch 60, loss=0.0260, recon=0.0260, kl=0.0019, beta=0.0010\n",
      "Batch 80, loss=0.0386, recon=0.0386, kl=0.0006, beta=0.0010\n",
      "Batch 100, loss=0.0357, recon=0.0357, kl=0.0025, beta=0.0010\n",
      "Batch 120, loss=0.0557, recon=0.0557, kl=0.0006, beta=0.0010\n",
      "Batch 140, loss=0.0310, recon=0.0310, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0246, recon=0.0246, kl=0.0007, beta=0.0010\n",
      "Batch 180, loss=0.0411, recon=0.0411, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0250, recon=0.0250, kl=0.0005, beta=0.0010\n",
      "Batch 40, loss=0.0395, recon=0.0395, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.1117, recon=0.1117, kl=0.0012, beta=0.0010\n",
      "Batch 80, loss=0.0241, recon=0.0241, kl=0.0007, beta=0.0010\n",
      "Batch 100, loss=0.0413, recon=0.0413, kl=0.0013, beta=0.0010\n",
      "Batch 120, loss=0.0207, recon=0.0207, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0274, recon=0.0274, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0268, recon=0.0268, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0383, recon=0.0383, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0416, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0360 | Avg Valid recon Loss: 0.0360\n",
      "\n",
      "[VRAE Run 64/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1403, recon=0.1403, kl=37.8350, beta=0.0000\n",
      "Batch 40, loss=0.0745, recon=0.0745, kl=52.5162, beta=0.0000\n",
      "Batch 60, loss=0.0820, recon=0.0820, kl=57.2058, beta=0.0000\n",
      "Batch 80, loss=0.0823, recon=0.0823, kl=57.0398, beta=0.0000\n",
      "Batch 100, loss=0.1018, recon=0.1018, kl=62.6867, beta=0.0000\n",
      "Batch 120, loss=0.0555, recon=0.0555, kl=64.3465, beta=0.0000\n",
      "Batch 140, loss=0.0618, recon=0.0618, kl=63.6693, beta=0.0000\n",
      "Batch 160, loss=0.0517, recon=0.0517, kl=65.4791, beta=0.0000\n",
      "Batch 180, loss=0.0371, recon=0.0371, kl=60.7334, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1256 (Recon: 0.1256, KL: 55.5614, Current Beta: 0.0000) | Avg Valid Loss: 0.0567 | Avg Valid recon Loss: 0.0567\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0600, recon=0.0600, kl=52.4359, beta=0.0000\n",
      "Batch 40, loss=0.0406, recon=0.0406, kl=60.4948, beta=0.0000\n",
      "Batch 60, loss=0.0604, recon=0.0604, kl=68.4582, beta=0.0000\n",
      "Batch 80, loss=0.0500, recon=0.0500, kl=66.4087, beta=0.0000\n",
      "Batch 100, loss=0.0679, recon=0.0679, kl=68.9091, beta=0.0000\n",
      "Batch 120, loss=0.0341, recon=0.0341, kl=69.8482, beta=0.0000\n",
      "Batch 140, loss=0.0387, recon=0.0387, kl=44.0102, beta=0.0000\n",
      "Batch 160, loss=0.0297, recon=0.0297, kl=56.5823, beta=0.0000\n",
      "Batch 180, loss=0.0330, recon=0.0330, kl=69.8300, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0609 (Recon: 0.0609, KL: 61.4012, Current Beta: 0.0000) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0775, recon=0.0775, kl=70.1231, beta=0.0000\n",
      "Batch 40, loss=0.0587, recon=0.0587, kl=70.3013, beta=0.0000\n",
      "Batch 60, loss=0.0293, recon=0.0293, kl=69.4025, beta=0.0000\n",
      "Batch 80, loss=0.0329, recon=0.0329, kl=71.7071, beta=0.0000\n",
      "Batch 100, loss=0.0366, recon=0.0366, kl=71.4068, beta=0.0000\n",
      "Batch 120, loss=0.0328, recon=0.0328, kl=64.3499, beta=0.0000\n",
      "Batch 140, loss=0.0254, recon=0.0254, kl=62.6934, beta=0.0000\n",
      "Batch 160, loss=0.0659, recon=0.0658, kl=66.3912, beta=0.0000\n",
      "Batch 180, loss=0.0450, recon=0.0450, kl=70.5552, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0535 (Recon: 0.0535, KL: 68.5550, Current Beta: 0.0000) | Avg Valid Loss: 0.0762 | Avg Valid recon Loss: 0.0762\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0397, recon=0.0397, kl=58.7672, beta=0.0000\n",
      "Batch 40, loss=0.0615, recon=0.0615, kl=62.9282, beta=0.0000\n",
      "Batch 60, loss=0.0915, recon=0.0915, kl=70.8571, beta=0.0000\n",
      "Batch 80, loss=0.0486, recon=0.0486, kl=73.0203, beta=0.0000\n",
      "Batch 100, loss=0.2053, recon=0.2053, kl=50.9393, beta=0.0000\n",
      "Batch 120, loss=0.0342, recon=0.0342, kl=58.9543, beta=0.0000\n",
      "Batch 140, loss=0.0466, recon=0.0466, kl=77.6096, beta=0.0000\n",
      "Batch 160, loss=0.0331, recon=0.0331, kl=84.7184, beta=0.0000\n",
      "Batch 180, loss=0.0403, recon=0.0403, kl=70.0074, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0516, KL: 68.1692, Current Beta: 0.0000) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0327, recon=0.0327, kl=69.2712, beta=0.0000\n",
      "Batch 40, loss=0.0395, recon=0.0394, kl=84.4446, beta=0.0000\n",
      "Batch 60, loss=0.0460, recon=0.0460, kl=83.7844, beta=0.0000\n",
      "Batch 80, loss=0.0655, recon=0.0655, kl=85.9860, beta=0.0000\n",
      "Batch 100, loss=0.0226, recon=0.0226, kl=84.3037, beta=0.0000\n",
      "Batch 120, loss=0.0493, recon=0.0493, kl=82.9723, beta=0.0000\n",
      "Batch 140, loss=0.0494, recon=0.0494, kl=88.4567, beta=0.0000\n",
      "Batch 160, loss=0.0240, recon=0.0240, kl=73.1857, beta=0.0000\n",
      "Batch 180, loss=0.0333, recon=0.0333, kl=59.2317, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 79.4694, Current Beta: 0.0000) | Avg Valid Loss: 0.0532 | Avg Valid recon Loss: 0.0532\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0703, recon=0.0702, kl=75.4024, beta=0.0000\n",
      "Batch 40, loss=0.0579, recon=0.0579, kl=78.7420, beta=0.0000\n",
      "Batch 60, loss=0.0448, recon=0.0447, kl=78.8162, beta=0.0000\n",
      "Batch 80, loss=0.0411, recon=0.0411, kl=58.0254, beta=0.0000\n",
      "Batch 100, loss=0.0285, recon=0.0285, kl=61.2022, beta=0.0000\n",
      "Batch 120, loss=0.0395, recon=0.0395, kl=71.2421, beta=0.0000\n",
      "Batch 140, loss=0.0343, recon=0.0343, kl=75.1412, beta=0.0000\n",
      "Batch 160, loss=0.0211, recon=0.0210, kl=82.1379, beta=0.0000\n",
      "Batch 180, loss=0.0335, recon=0.0335, kl=80.0337, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0563 (Recon: 0.0562, KL: 72.6245, Current Beta: 0.0000) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0285, recon=0.0285, kl=71.0335, beta=0.0000\n",
      "Batch 40, loss=0.0284, recon=0.0284, kl=65.1131, beta=0.0000\n",
      "Batch 60, loss=0.0268, recon=0.0267, kl=68.8537, beta=0.0000\n",
      "Batch 80, loss=0.0347, recon=0.0347, kl=73.8246, beta=0.0000\n",
      "Batch 100, loss=0.0257, recon=0.0256, kl=71.4295, beta=0.0000\n",
      "Batch 120, loss=0.0359, recon=0.0358, kl=69.4555, beta=0.0000\n",
      "Batch 140, loss=0.0385, recon=0.0385, kl=71.0242, beta=0.0000\n",
      "Batch 160, loss=0.0718, recon=0.0717, kl=70.6133, beta=0.0000\n",
      "Batch 180, loss=0.0355, recon=0.0355, kl=67.6938, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0431, KL: 70.5304, Current Beta: 0.0000) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0478\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0385, recon=0.0384, kl=62.9266, beta=0.0000\n",
      "Batch 40, loss=0.0351, recon=0.0350, kl=55.0891, beta=0.0000\n",
      "Batch 60, loss=0.0325, recon=0.0324, kl=64.4019, beta=0.0000\n",
      "Batch 80, loss=0.0264, recon=0.0263, kl=60.9426, beta=0.0000\n",
      "Batch 100, loss=0.0590, recon=0.0589, kl=59.1692, beta=0.0000\n",
      "Batch 120, loss=0.0502, recon=0.0501, kl=61.4273, beta=0.0000\n",
      "Batch 140, loss=0.0482, recon=0.0481, kl=63.2430, beta=0.0000\n",
      "Batch 160, loss=0.1113, recon=0.1112, kl=66.4012, beta=0.0000\n",
      "Batch 180, loss=0.0182, recon=0.0181, kl=62.6388, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0453 (Recon: 0.0452, KL: 62.0487, Current Beta: 0.0000) | Avg Valid Loss: 0.0323 | Avg Valid recon Loss: 0.0322\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0309, recon=0.0307, kl=46.8965, beta=0.0000\n",
      "Batch 40, loss=0.0236, recon=0.0235, kl=44.1076, beta=0.0000\n",
      "Batch 60, loss=0.0253, recon=0.0251, kl=45.3278, beta=0.0000\n",
      "Batch 80, loss=0.0498, recon=0.0496, kl=42.6747, beta=0.0000\n",
      "Batch 100, loss=0.0513, recon=0.0512, kl=37.5506, beta=0.0000\n",
      "Batch 120, loss=0.0349, recon=0.0347, kl=50.2778, beta=0.0000\n",
      "Batch 140, loss=0.0316, recon=0.0314, kl=51.3313, beta=0.0000\n",
      "Batch 160, loss=0.0478, recon=0.0476, kl=43.7412, beta=0.0000\n",
      "Batch 180, loss=0.0251, recon=0.0249, kl=46.0406, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0412, KL: 45.8119, Current Beta: 0.0000) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0458\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0398, recon=0.0395, kl=29.8458, beta=0.0000\n",
      "Batch 40, loss=0.0437, recon=0.0433, kl=34.5699, beta=0.0000\n",
      "Batch 60, loss=0.0498, recon=0.0494, kl=33.0353, beta=0.0000\n",
      "Batch 80, loss=0.0301, recon=0.0298, kl=33.3088, beta=0.0000\n",
      "Batch 100, loss=0.0356, recon=0.0353, kl=31.8034, beta=0.0000\n",
      "Batch 120, loss=0.0213, recon=0.0209, kl=29.2412, beta=0.0000\n",
      "Batch 140, loss=0.0317, recon=0.0314, kl=26.7411, beta=0.0000\n",
      "Batch 160, loss=0.0242, recon=0.0239, kl=25.5440, beta=0.0000\n",
      "Batch 180, loss=0.0242, recon=0.0239, kl=26.1843, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0482, KL: 31.3187, Current Beta: 0.0000) | Avg Valid Loss: 0.0397 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0193, recon=0.0188, kl=15.5849, beta=0.0000\n",
      "Batch 40, loss=0.0370, recon=0.0366, kl=13.5278, beta=0.0000\n",
      "Batch 60, loss=0.0453, recon=0.0449, kl=11.9504, beta=0.0000\n",
      "Batch 80, loss=0.0346, recon=0.0343, kl=10.3573, beta=0.0000\n",
      "Batch 100, loss=0.0351, recon=0.0347, kl=15.3287, beta=0.0000\n",
      "Batch 120, loss=0.0215, recon=0.0212, kl=11.7329, beta=0.0000\n",
      "Batch 140, loss=0.0316, recon=0.0313, kl=10.7823, beta=0.0000\n",
      "Batch 160, loss=0.0243, recon=0.0240, kl=7.4568, beta=0.0000\n",
      "Batch 180, loss=0.0168, recon=0.0166, kl=7.5532, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0373, KL: 12.3235, Current Beta: 0.0000) | Avg Valid Loss: 0.0311 | Avg Valid recon Loss: 0.0309\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0187, recon=0.0184, kl=3.7757, beta=0.0001\n",
      "Batch 40, loss=0.0575, recon=0.0572, kl=3.2945, beta=0.0001\n",
      "Batch 60, loss=0.0380, recon=0.0376, kl=4.8834, beta=0.0001\n",
      "Batch 80, loss=0.0336, recon=0.0332, kl=5.6762, beta=0.0001\n",
      "Batch 100, loss=0.0571, recon=0.0567, kl=4.7524, beta=0.0001\n",
      "Batch 120, loss=0.0289, recon=0.0287, kl=3.4064, beta=0.0001\n",
      "Batch 140, loss=0.0878, recon=0.0875, kl=2.8020, beta=0.0001\n",
      "Batch 160, loss=0.0718, recon=0.0715, kl=3.3268, beta=0.0001\n",
      "Batch 180, loss=0.0312, recon=0.0308, kl=5.6639, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0489 (Recon: 0.0486, KL: 4.2273, Current Beta: 0.0001) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0321, recon=0.0310, kl=5.9807, beta=0.0002\n",
      "Batch 40, loss=0.0274, recon=0.0266, kl=4.3456, beta=0.0002\n",
      "Batch 60, loss=0.0563, recon=0.0557, kl=2.8376, beta=0.0002\n",
      "Batch 80, loss=0.0316, recon=0.0313, kl=1.8117, beta=0.0002\n",
      "Batch 100, loss=0.0216, recon=0.0214, kl=1.2550, beta=0.0002\n",
      "Batch 120, loss=0.0288, recon=0.0286, kl=0.8898, beta=0.0002\n",
      "Batch 140, loss=0.0288, recon=0.0286, kl=0.6558, beta=0.0002\n",
      "Batch 160, loss=0.0456, recon=0.0455, kl=0.5557, beta=0.0002\n",
      "Batch 180, loss=0.0383, recon=0.0381, kl=1.2651, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0436, KL: 2.4318, Current Beta: 0.0002) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0721, recon=0.0714, kl=1.8688, beta=0.0004\n",
      "Batch 40, loss=0.0422, recon=0.0417, kl=1.3149, beta=0.0004\n",
      "Batch 60, loss=0.0377, recon=0.0374, kl=0.7788, beta=0.0004\n",
      "Batch 80, loss=0.0295, recon=0.0294, kl=0.4185, beta=0.0004\n",
      "Batch 100, loss=0.0555, recon=0.0554, kl=0.2140, beta=0.0004\n",
      "Batch 120, loss=0.0397, recon=0.0396, kl=0.1966, beta=0.0004\n",
      "Batch 140, loss=0.0402, recon=0.0402, kl=0.2247, beta=0.0004\n",
      "Batch 160, loss=0.0204, recon=0.0203, kl=0.1547, beta=0.0004\n",
      "Batch 180, loss=0.0413, recon=0.0413, kl=0.1338, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0448 (Recon: 0.0445, KL: 0.6640, Current Beta: 0.0004) | Avg Valid Loss: 0.0483 | Avg Valid recon Loss: 0.0483\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0443, recon=0.0443, kl=0.0374, beta=0.0006\n",
      "Batch 40, loss=0.9240, recon=0.9239, kl=0.0295, beta=0.0006\n",
      "Batch 60, loss=0.2022, recon=0.2021, kl=0.1040, beta=0.0006\n",
      "Batch 80, loss=0.0507, recon=0.0504, kl=0.4570, beta=0.0006\n",
      "Batch 100, loss=0.0326, recon=0.0322, kl=0.6570, beta=0.0006\n",
      "Batch 120, loss=0.0507, recon=0.0503, kl=0.6873, beta=0.0006\n",
      "Batch 140, loss=0.0379, recon=0.0377, kl=0.3157, beta=0.0006\n",
      "Batch 160, loss=0.0279, recon=0.0278, kl=0.1140, beta=0.0006\n",
      "Batch 180, loss=0.0239, recon=0.0239, kl=0.0352, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0515, KL: 0.2767, Current Beta: 0.0006) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0384\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0859, recon=0.0858, kl=0.0156, beta=0.0010\n",
      "Batch 40, loss=0.0610, recon=0.0609, kl=0.0775, beta=0.0010\n",
      "Batch 60, loss=0.0295, recon=0.0294, kl=0.0762, beta=0.0010\n",
      "Batch 80, loss=0.0536, recon=0.0535, kl=0.0258, beta=0.0010\n",
      "Batch 100, loss=0.0423, recon=0.0423, kl=0.0201, beta=0.0010\n",
      "Batch 120, loss=0.0604, recon=0.0600, kl=0.3685, beta=0.0010\n",
      "Batch 140, loss=0.0214, recon=0.0211, kl=0.3104, beta=0.0010\n",
      "Batch 160, loss=0.0225, recon=0.0224, kl=0.0627, beta=0.0010\n",
      "Batch 180, loss=0.0287, recon=0.0287, kl=0.0120, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0536 (Recon: 0.0535, KL: 0.1072, Current Beta: 0.0010) | Avg Valid Loss: 0.0335 | Avg Valid recon Loss: 0.0334\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1095, recon=0.1095, kl=0.0086, beta=0.0010\n",
      "Batch 40, loss=0.0265, recon=0.0265, kl=0.0106, beta=0.0010\n",
      "Batch 60, loss=0.0215, recon=0.0214, kl=0.0099, beta=0.0010\n",
      "Batch 80, loss=0.0256, recon=0.0256, kl=0.0045, beta=0.0010\n",
      "Batch 100, loss=0.0384, recon=0.0384, kl=0.0218, beta=0.0010\n",
      "Batch 120, loss=0.0254, recon=0.0254, kl=0.0486, beta=0.0010\n",
      "Batch 140, loss=0.0327, recon=0.0326, kl=0.0250, beta=0.0010\n",
      "Batch 160, loss=0.0175, recon=0.0175, kl=0.0227, beta=0.0010\n",
      "Batch 180, loss=0.0184, recon=0.0184, kl=0.0087, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0433, KL: 0.0180, Current Beta: 0.0010) | Avg Valid Loss: 0.0324 | Avg Valid recon Loss: 0.0323\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0309, recon=0.0309, kl=0.0050, beta=0.0010\n",
      "Batch 40, loss=0.0654, recon=0.0654, kl=0.0283, beta=0.0010\n",
      "Batch 60, loss=0.0601, recon=0.0599, kl=0.1830, beta=0.0010\n",
      "Batch 80, loss=0.0504, recon=0.0503, kl=0.0914, beta=0.0010\n",
      "Batch 100, loss=0.0618, recon=0.0617, kl=0.0337, beta=0.0010\n",
      "Batch 120, loss=0.0407, recon=0.0407, kl=0.0384, beta=0.0010\n",
      "Batch 140, loss=0.0291, recon=0.0291, kl=0.0212, beta=0.0010\n",
      "Batch 160, loss=0.0508, recon=0.0508, kl=0.0079, beta=0.0010\n",
      "Batch 180, loss=0.0207, recon=0.0207, kl=0.0077, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0477 (Recon: 0.0477, KL: 0.0454, Current Beta: 0.0010) | Avg Valid Loss: 0.0324 | Avg Valid recon Loss: 0.0324\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0334, recon=0.0334, kl=0.0055, beta=0.0010\n",
      "Batch 40, loss=0.0566, recon=0.0566, kl=0.0066, beta=0.0010\n",
      "Batch 60, loss=0.0503, recon=0.0503, kl=0.0347, beta=0.0010\n",
      "Batch 80, loss=0.0393, recon=0.0392, kl=0.1171, beta=0.0010\n",
      "Batch 100, loss=0.0249, recon=0.0249, kl=0.0321, beta=0.0010\n",
      "Batch 120, loss=0.0337, recon=0.0337, kl=0.0085, beta=0.0010\n",
      "Batch 140, loss=0.0259, recon=0.0259, kl=0.0039, beta=0.0010\n",
      "Batch 160, loss=0.0175, recon=0.0175, kl=0.0062, beta=0.0010\n",
      "Batch 180, loss=0.0280, recon=0.0280, kl=0.0038, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 0.0246, Current Beta: 0.0010) | Avg Valid Loss: 0.0315 | Avg Valid recon Loss: 0.0315\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.4039, recon=0.4039, kl=0.0030, beta=0.0010\n",
      "Batch 40, loss=0.0478, recon=0.0478, kl=0.0041, beta=0.0010\n",
      "Batch 60, loss=0.0244, recon=0.0244, kl=0.0068, beta=0.0010\n",
      "Batch 80, loss=0.0454, recon=0.0454, kl=0.0038, beta=0.0010\n",
      "Batch 100, loss=0.0227, recon=0.0227, kl=0.0019, beta=0.0010\n",
      "Batch 120, loss=0.0294, recon=0.0294, kl=0.0021, beta=0.0010\n",
      "Batch 140, loss=0.0279, recon=0.0279, kl=0.0018, beta=0.0010\n",
      "Batch 160, loss=0.0443, recon=0.0443, kl=0.0044, beta=0.0010\n",
      "Batch 180, loss=0.0326, recon=0.0326, kl=0.0121, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0357 (Recon: 0.0357, KL: 0.0038, Current Beta: 0.0010) | Avg Valid Loss: 0.0302 | Avg Valid recon Loss: 0.0302\n",
      "\n",
      "[VRAE Run 65/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4733, recon=0.4733, kl=1.3351, beta=0.0000\n",
      "Batch 40, loss=0.2637, recon=0.2637, kl=35.8030, beta=0.0000\n",
      "Batch 60, loss=0.2486, recon=0.2486, kl=75.1466, beta=0.0000\n",
      "Batch 80, loss=0.2451, recon=0.2451, kl=93.4398, beta=0.0000\n",
      "Batch 100, loss=0.1835, recon=0.1835, kl=102.1198, beta=0.0000\n",
      "Batch 120, loss=0.1262, recon=0.1262, kl=113.4131, beta=0.0000\n",
      "Batch 140, loss=0.1830, recon=0.1830, kl=121.3783, beta=0.0000\n",
      "Batch 160, loss=0.1371, recon=0.1371, kl=126.5014, beta=0.0000\n",
      "Batch 180, loss=0.1476, recon=0.1476, kl=131.5482, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2801 (Recon: 0.2801, KL: 82.0859, Current Beta: 0.0000) | Avg Valid Loss: 0.1210 | Avg Valid recon Loss: 0.1210\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1564, recon=0.1564, kl=136.4861, beta=0.0000\n",
      "Batch 40, loss=0.0850, recon=0.0850, kl=138.6569, beta=0.0000\n",
      "Batch 60, loss=0.0965, recon=0.0965, kl=141.7222, beta=0.0000\n",
      "Batch 80, loss=0.0717, recon=0.0717, kl=145.1632, beta=0.0000\n",
      "Batch 100, loss=0.0843, recon=0.0843, kl=146.5116, beta=0.0000\n",
      "Batch 120, loss=0.0729, recon=0.0729, kl=149.1898, beta=0.0000\n",
      "Batch 140, loss=0.1013, recon=0.1013, kl=152.8958, beta=0.0000\n",
      "Batch 160, loss=0.1103, recon=0.1103, kl=156.8408, beta=0.0000\n",
      "Batch 180, loss=0.1131, recon=0.1131, kl=158.0576, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1222 (Recon: 0.1222, KL: 146.0917, Current Beta: 0.0000) | Avg Valid Loss: 0.0895 | Avg Valid recon Loss: 0.0895\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1345, recon=0.1345, kl=159.7444, beta=0.0000\n",
      "Batch 40, loss=0.0836, recon=0.0836, kl=161.0925, beta=0.0000\n",
      "Batch 60, loss=0.2312, recon=0.2312, kl=162.4058, beta=0.0000\n",
      "Batch 80, loss=0.0557, recon=0.0557, kl=162.6253, beta=0.0000\n",
      "Batch 100, loss=0.0654, recon=0.0654, kl=163.6979, beta=0.0000\n",
      "Batch 120, loss=0.0622, recon=0.0622, kl=168.4942, beta=0.0000\n",
      "Batch 140, loss=0.0601, recon=0.0601, kl=170.8931, beta=0.0000\n",
      "Batch 160, loss=0.0701, recon=0.0701, kl=170.8956, beta=0.0000\n",
      "Batch 180, loss=0.0743, recon=0.0743, kl=170.7779, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0936 (Recon: 0.0936, KL: 164.9010, Current Beta: 0.0000) | Avg Valid Loss: 0.0745 | Avg Valid recon Loss: 0.0744\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0792, recon=0.0792, kl=170.6905, beta=0.0000\n",
      "Batch 40, loss=0.0599, recon=0.0599, kl=174.6326, beta=0.0000\n",
      "Batch 60, loss=0.0774, recon=0.0774, kl=173.2361, beta=0.0000\n",
      "Batch 80, loss=0.0532, recon=0.0532, kl=175.7034, beta=0.0000\n",
      "Batch 100, loss=0.0725, recon=0.0725, kl=177.2940, beta=0.0000\n",
      "Batch 120, loss=0.1440, recon=0.1440, kl=177.5447, beta=0.0000\n",
      "Batch 140, loss=0.0532, recon=0.0532, kl=176.2977, beta=0.0000\n",
      "Batch 160, loss=0.0581, recon=0.0581, kl=176.3492, beta=0.0000\n",
      "Batch 180, loss=0.0377, recon=0.0377, kl=175.8909, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0787 (Recon: 0.0787, KL: 174.9864, Current Beta: 0.0000) | Avg Valid Loss: 0.0647 | Avg Valid recon Loss: 0.0647\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0744, recon=0.0744, kl=175.2549, beta=0.0000\n",
      "Batch 40, loss=0.0478, recon=0.0478, kl=172.8561, beta=0.0000\n",
      "Batch 60, loss=0.0492, recon=0.0492, kl=167.7234, beta=0.0000\n",
      "Batch 80, loss=0.0379, recon=0.0378, kl=165.8224, beta=0.0000\n",
      "Batch 100, loss=0.0732, recon=0.0732, kl=163.0059, beta=0.0000\n",
      "Batch 120, loss=0.0701, recon=0.0701, kl=161.7881, beta=0.0000\n",
      "Batch 140, loss=0.0734, recon=0.0734, kl=159.8572, beta=0.0000\n",
      "Batch 160, loss=0.0555, recon=0.0554, kl=156.4155, beta=0.0000\n",
      "Batch 180, loss=0.0621, recon=0.0620, kl=153.8521, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0698 (Recon: 0.0698, KL: 165.2357, Current Beta: 0.0000) | Avg Valid Loss: 0.0596 | Avg Valid recon Loss: 0.0596\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0450, recon=0.0450, kl=148.5297, beta=0.0000\n",
      "Batch 40, loss=0.0446, recon=0.0446, kl=139.2227, beta=0.0000\n",
      "Batch 60, loss=0.0708, recon=0.0707, kl=134.0279, beta=0.0000\n",
      "Batch 80, loss=0.0427, recon=0.0427, kl=124.4845, beta=0.0000\n",
      "Batch 100, loss=0.0761, recon=0.0761, kl=116.9175, beta=0.0000\n",
      "Batch 120, loss=0.0509, recon=0.0509, kl=117.6813, beta=0.0000\n",
      "Batch 140, loss=0.0365, recon=0.0365, kl=117.3719, beta=0.0000\n",
      "Batch 160, loss=0.0323, recon=0.0323, kl=115.9981, beta=0.0000\n",
      "Batch 180, loss=0.0438, recon=0.0438, kl=108.4310, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0640 (Recon: 0.0640, KL: 126.8480, Current Beta: 0.0000) | Avg Valid Loss: 0.0544 | Avg Valid recon Loss: 0.0544\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0724, recon=0.0724, kl=98.6657, beta=0.0000\n",
      "Batch 40, loss=0.0340, recon=0.0339, kl=85.5953, beta=0.0000\n",
      "Batch 60, loss=0.0589, recon=0.0588, kl=77.9662, beta=0.0000\n",
      "Batch 80, loss=0.0408, recon=0.0407, kl=79.4866, beta=0.0000\n",
      "Batch 100, loss=0.0403, recon=0.0402, kl=74.5359, beta=0.0000\n",
      "Batch 120, loss=0.0674, recon=0.0673, kl=76.9246, beta=0.0000\n",
      "Batch 140, loss=0.0549, recon=0.0549, kl=72.0616, beta=0.0000\n",
      "Batch 160, loss=0.0573, recon=0.0573, kl=73.0367, beta=0.0000\n",
      "Batch 180, loss=0.0342, recon=0.0341, kl=73.1759, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0595 (Recon: 0.0595, KL: 80.7416, Current Beta: 0.0000) | Avg Valid Loss: 0.0515 | Avg Valid recon Loss: 0.0514\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0442, recon=0.0441, kl=50.2157, beta=0.0000\n",
      "Batch 40, loss=0.0620, recon=0.0619, kl=45.0344, beta=0.0000\n",
      "Batch 60, loss=0.0767, recon=0.0767, kl=43.5701, beta=0.0000\n",
      "Batch 80, loss=0.0367, recon=0.0367, kl=42.1458, beta=0.0000\n",
      "Batch 100, loss=0.0368, recon=0.0368, kl=40.1375, beta=0.0000\n",
      "Batch 120, loss=0.0370, recon=0.0369, kl=39.4639, beta=0.0000\n",
      "Batch 140, loss=0.0359, recon=0.0358, kl=36.9656, beta=0.0000\n",
      "Batch 160, loss=0.0309, recon=0.0308, kl=36.0612, beta=0.0000\n",
      "Batch 180, loss=0.0426, recon=0.0426, kl=38.8579, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0565 (Recon: 0.0564, KL: 42.8916, Current Beta: 0.0000) | Avg Valid Loss: 0.0487 | Avg Valid recon Loss: 0.0486\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.9167, recon=0.9166, kl=22.2433, beta=0.0000\n",
      "Batch 40, loss=0.0362, recon=0.0361, kl=19.9700, beta=0.0000\n",
      "Batch 60, loss=0.1461, recon=0.1460, kl=20.0116, beta=0.0000\n",
      "Batch 80, loss=0.0340, recon=0.0339, kl=17.9988, beta=0.0000\n",
      "Batch 100, loss=0.0401, recon=0.0400, kl=17.7620, beta=0.0000\n",
      "Batch 120, loss=0.0349, recon=0.0348, kl=16.9054, beta=0.0000\n",
      "Batch 140, loss=0.0500, recon=0.0500, kl=16.2840, beta=0.0000\n",
      "Batch 160, loss=0.0234, recon=0.0233, kl=19.4330, beta=0.0000\n",
      "Batch 180, loss=0.0632, recon=0.0631, kl=15.1999, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0541 (Recon: 0.0540, KL: 19.6551, Current Beta: 0.0000) | Avg Valid Loss: 0.0463 | Avg Valid recon Loss: 0.0463\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0417, recon=0.0416, kl=7.2492, beta=0.0000\n",
      "Batch 40, loss=0.0391, recon=0.0390, kl=8.3431, beta=0.0000\n",
      "Batch 60, loss=0.0317, recon=0.0316, kl=6.3252, beta=0.0000\n",
      "Batch 80, loss=0.0382, recon=0.0382, kl=6.4436, beta=0.0000\n",
      "Batch 100, loss=0.0311, recon=0.0311, kl=6.7916, beta=0.0000\n",
      "Batch 120, loss=0.0364, recon=0.0363, kl=6.3626, beta=0.0000\n",
      "Batch 140, loss=0.0275, recon=0.0274, kl=4.8349, beta=0.0000\n",
      "Batch 160, loss=0.0862, recon=0.0861, kl=5.2423, beta=0.0000\n",
      "Batch 180, loss=0.0347, recon=0.0347, kl=4.7525, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0522, KL: 6.7609, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0320, recon=0.0319, kl=2.7434, beta=0.0000\n",
      "Batch 40, loss=0.0312, recon=0.0311, kl=2.5821, beta=0.0000\n",
      "Batch 60, loss=0.0395, recon=0.0394, kl=2.8872, beta=0.0000\n",
      "Batch 80, loss=0.0312, recon=0.0311, kl=2.1431, beta=0.0000\n",
      "Batch 100, loss=0.0304, recon=0.0303, kl=2.1271, beta=0.0000\n",
      "Batch 120, loss=0.0278, recon=0.0278, kl=2.1084, beta=0.0000\n",
      "Batch 140, loss=0.0534, recon=0.0533, kl=2.1859, beta=0.0000\n",
      "Batch 160, loss=0.0587, recon=0.0587, kl=1.6919, beta=0.0000\n",
      "Batch 180, loss=0.0643, recon=0.0643, kl=1.7739, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0500 (Recon: 0.0499, KL: 2.2936, Current Beta: 0.0000) | Avg Valid Loss: 0.0432 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0309, recon=0.0308, kl=0.6292, beta=0.0001\n",
      "Batch 40, loss=0.0422, recon=0.0421, kl=1.0041, beta=0.0001\n",
      "Batch 60, loss=0.0720, recon=0.0719, kl=0.6994, beta=0.0001\n",
      "Batch 80, loss=0.0380, recon=0.0379, kl=0.8534, beta=0.0001\n",
      "Batch 100, loss=0.0232, recon=0.0231, kl=0.6795, beta=0.0001\n",
      "Batch 120, loss=0.0254, recon=0.0253, kl=0.5724, beta=0.0001\n",
      "Batch 140, loss=0.0337, recon=0.0337, kl=0.4940, beta=0.0001\n",
      "Batch 160, loss=0.0315, recon=0.0315, kl=0.4891, beta=0.0001\n",
      "Batch 180, loss=0.0303, recon=0.0302, kl=0.4350, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0485, KL: 0.7054, Current Beta: 0.0001) | Avg Valid Loss: 0.0414 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0269, recon=0.0268, kl=0.1091, beta=0.0002\n",
      "Batch 40, loss=0.0401, recon=0.0401, kl=0.1248, beta=0.0002\n",
      "Batch 60, loss=0.0360, recon=0.0360, kl=0.1031, beta=0.0002\n",
      "Batch 80, loss=0.0216, recon=0.0215, kl=0.0706, beta=0.0002\n",
      "Batch 100, loss=0.0409, recon=0.0409, kl=0.0578, beta=0.0002\n",
      "Batch 120, loss=0.0351, recon=0.0351, kl=0.0675, beta=0.0002\n",
      "Batch 140, loss=0.0351, recon=0.0351, kl=0.0438, beta=0.0002\n",
      "Batch 160, loss=0.0527, recon=0.0527, kl=0.0570, beta=0.0002\n",
      "Batch 180, loss=0.0409, recon=0.0409, kl=0.0503, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0472, KL: 0.0930, Current Beta: 0.0002) | Avg Valid Loss: 0.0405 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0415, recon=0.0415, kl=0.0063, beta=0.0004\n",
      "Batch 40, loss=0.0282, recon=0.0282, kl=0.0136, beta=0.0004\n",
      "Batch 60, loss=0.0306, recon=0.0306, kl=0.0075, beta=0.0004\n",
      "Batch 80, loss=0.0273, recon=0.0273, kl=0.0054, beta=0.0004\n",
      "Batch 100, loss=0.0285, recon=0.0285, kl=0.0046, beta=0.0004\n",
      "Batch 120, loss=0.0743, recon=0.0743, kl=0.0061, beta=0.0004\n",
      "Batch 140, loss=0.0292, recon=0.0292, kl=0.0043, beta=0.0004\n",
      "Batch 160, loss=0.0244, recon=0.0244, kl=0.0026, beta=0.0004\n",
      "Batch 180, loss=0.0339, recon=0.0339, kl=0.0041, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0460 (Recon: 0.0460, KL: 0.0079, Current Beta: 0.0004) | Avg Valid Loss: 0.0396 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.6886, recon=0.6886, kl=0.0015, beta=0.0006\n",
      "Batch 40, loss=0.0431, recon=0.0431, kl=0.0016, beta=0.0006\n",
      "Batch 60, loss=0.0267, recon=0.0267, kl=0.0017, beta=0.0006\n",
      "Batch 80, loss=0.0473, recon=0.0473, kl=0.0006, beta=0.0006\n",
      "Batch 100, loss=0.0225, recon=0.0225, kl=0.0008, beta=0.0006\n",
      "Batch 120, loss=0.0457, recon=0.0457, kl=0.0008, beta=0.0006\n",
      "Batch 140, loss=0.0327, recon=0.0327, kl=0.0010, beta=0.0006\n",
      "Batch 160, loss=0.1709, recon=0.1709, kl=0.0024, beta=0.0006\n",
      "Batch 180, loss=0.0281, recon=0.0281, kl=0.0013, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0449, KL: 0.0014, Current Beta: 0.0006) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0291, recon=0.0291, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0325, recon=0.0325, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0310, recon=0.0310, kl=0.0008, beta=0.0010\n",
      "Batch 100, loss=0.0379, recon=0.0379, kl=0.0004, beta=0.0010\n",
      "Batch 120, loss=0.0434, recon=0.0434, kl=0.0003, beta=0.0010\n",
      "Batch 140, loss=0.0429, recon=0.0429, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0347, recon=0.0347, kl=0.0007, beta=0.0010\n",
      "Batch 180, loss=0.0466, recon=0.0466, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0438, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0311, recon=0.0311, kl=0.0026, beta=0.0010\n",
      "Batch 40, loss=0.0222, recon=0.0222, kl=0.0007, beta=0.0010\n",
      "Batch 60, loss=0.0634, recon=0.0634, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0240, recon=0.0240, kl=0.0006, beta=0.0010\n",
      "Batch 100, loss=0.0631, recon=0.0631, kl=0.0002, beta=0.0010\n",
      "Batch 120, loss=0.0587, recon=0.0587, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0275, recon=0.0275, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0274, recon=0.0274, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0248, recon=0.0248, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0430, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0274, recon=0.0274, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0304, recon=0.0304, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0279, recon=0.0279, kl=0.0006, beta=0.0010\n",
      "Batch 80, loss=0.0293, recon=0.0293, kl=0.0003, beta=0.0010\n",
      "Batch 100, loss=0.0524, recon=0.0524, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0280, recon=0.0280, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0320, recon=0.0320, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0240, recon=0.0240, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0383, recon=0.0383, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0235, recon=0.0235, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0243, recon=0.0243, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0313, recon=0.0313, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0278, recon=0.0278, kl=0.0014, beta=0.0010\n",
      "Batch 100, loss=0.0252, recon=0.0252, kl=0.0004, beta=0.0010\n",
      "Batch 120, loss=0.0544, recon=0.0544, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0264, recon=0.0264, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0253, recon=0.0253, kl=0.0001, beta=0.0010\n",
      "Batch 180, loss=0.0379, recon=0.0379, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0414, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0223, recon=0.0223, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0387, recon=0.0387, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0200, recon=0.0200, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0333, recon=0.0333, kl=0.0001, beta=0.0010\n",
      "Batch 100, loss=0.0435, recon=0.0435, kl=0.0001, beta=0.0010\n",
      "Batch 120, loss=0.0266, recon=0.0266, kl=0.0010, beta=0.0010\n",
      "Batch 140, loss=0.0279, recon=0.0279, kl=0.0002, beta=0.0010\n",
      "Batch 160, loss=0.0236, recon=0.0236, kl=0.0001, beta=0.0010\n",
      "Batch 180, loss=0.0569, recon=0.0569, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0407 (Recon: 0.0407, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "\n",
      "[VRAE Run 66/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1653, recon=0.1653, kl=75.6262, beta=0.0000\n",
      "Batch 40, loss=0.0878, recon=0.0878, kl=93.6570, beta=0.0000\n",
      "Batch 60, loss=0.1260, recon=0.1260, kl=122.5406, beta=0.0000\n",
      "Batch 80, loss=0.4305, recon=0.4305, kl=109.6935, beta=0.0000\n",
      "Batch 100, loss=0.0735, recon=0.0735, kl=120.0919, beta=0.0000\n",
      "Batch 120, loss=0.0807, recon=0.0807, kl=110.2728, beta=0.0000\n",
      "Batch 140, loss=0.0640, recon=0.0640, kl=117.8797, beta=0.0000\n",
      "Batch 160, loss=0.0402, recon=0.0402, kl=130.5223, beta=0.0000\n",
      "Batch 180, loss=0.0357, recon=0.0357, kl=122.6424, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1292 (Recon: 0.1292, KL: 104.7457, Current Beta: 0.0000) | Avg Valid Loss: 0.0571 | Avg Valid recon Loss: 0.0571\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0459, recon=0.0459, kl=124.0498, beta=0.0000\n",
      "Batch 40, loss=0.0403, recon=0.0403, kl=103.8524, beta=0.0000\n",
      "Batch 60, loss=0.3734, recon=0.3734, kl=115.2881, beta=0.0000\n",
      "Batch 80, loss=0.0360, recon=0.0360, kl=110.9168, beta=0.0000\n",
      "Batch 100, loss=0.0305, recon=0.0305, kl=109.9189, beta=0.0000\n",
      "Batch 120, loss=0.0479, recon=0.0479, kl=92.9849, beta=0.0000\n",
      "Batch 140, loss=1.4172, recon=1.4172, kl=120.5781, beta=0.0000\n",
      "Batch 160, loss=0.0319, recon=0.0319, kl=127.3091, beta=0.0000\n",
      "Batch 180, loss=0.0514, recon=0.0514, kl=135.6034, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0616 (Recon: 0.0616, KL: 116.0601, Current Beta: 0.0000) | Avg Valid Loss: 0.0544 | Avg Valid recon Loss: 0.0544\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0504, recon=0.0504, kl=141.2621, beta=0.0000\n",
      "Batch 40, loss=0.0593, recon=0.0593, kl=145.6427, beta=0.0000\n",
      "Batch 60, loss=0.0322, recon=0.0322, kl=122.9223, beta=0.0000\n",
      "Batch 80, loss=0.0402, recon=0.0402, kl=110.4684, beta=0.0000\n",
      "Batch 100, loss=0.0506, recon=0.0506, kl=122.3691, beta=0.0000\n",
      "Batch 120, loss=0.0488, recon=0.0488, kl=136.6148, beta=0.0000\n",
      "Batch 140, loss=0.0522, recon=0.0522, kl=138.7393, beta=0.0000\n",
      "Batch 160, loss=0.0338, recon=0.0338, kl=156.4142, beta=0.0000\n",
      "Batch 180, loss=0.0458, recon=0.0458, kl=114.4393, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0584 (Recon: 0.0584, KL: 133.1574, Current Beta: 0.0000) | Avg Valid Loss: 0.0469 | Avg Valid recon Loss: 0.0469\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0442, recon=0.0442, kl=125.5940, beta=0.0000\n",
      "Batch 40, loss=0.0274, recon=0.0274, kl=130.2519, beta=0.0000\n",
      "Batch 60, loss=0.0510, recon=0.0510, kl=143.5898, beta=0.0000\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=144.5338, beta=0.0000\n",
      "Batch 100, loss=0.0472, recon=0.0472, kl=114.1940, beta=0.0000\n",
      "Batch 120, loss=0.0559, recon=0.0559, kl=127.6386, beta=0.0000\n",
      "Batch 140, loss=0.0698, recon=0.0698, kl=136.4362, beta=0.0000\n",
      "Batch 160, loss=0.0419, recon=0.0419, kl=132.1109, beta=0.0000\n",
      "Batch 180, loss=0.1258, recon=0.1258, kl=126.9005, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0549 (Recon: 0.0549, KL: 131.4526, Current Beta: 0.0000) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0356, recon=0.0356, kl=120.9843, beta=0.0000\n",
      "Batch 40, loss=0.0478, recon=0.0478, kl=110.7919, beta=0.0000\n",
      "Batch 60, loss=0.0320, recon=0.0320, kl=140.3643, beta=0.0000\n",
      "Batch 80, loss=0.0342, recon=0.0342, kl=143.1876, beta=0.0000\n",
      "Batch 100, loss=0.0398, recon=0.0398, kl=135.5945, beta=0.0000\n",
      "Batch 120, loss=0.0307, recon=0.0307, kl=129.1743, beta=0.0000\n",
      "Batch 140, loss=0.0291, recon=0.0291, kl=135.5886, beta=0.0000\n",
      "Batch 160, loss=0.0325, recon=0.0325, kl=139.1452, beta=0.0000\n",
      "Batch 180, loss=0.0587, recon=0.0587, kl=139.8696, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0469, KL: 132.5196, Current Beta: 0.0000) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0392\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0458, recon=0.0458, kl=133.3082, beta=0.0000\n",
      "Batch 40, loss=0.1399, recon=0.1398, kl=120.1437, beta=0.0000\n",
      "Batch 60, loss=0.0458, recon=0.0458, kl=117.2978, beta=0.0000\n",
      "Batch 80, loss=0.0302, recon=0.0302, kl=120.7603, beta=0.0000\n",
      "Batch 100, loss=0.0234, recon=0.0234, kl=118.9978, beta=0.0000\n",
      "Batch 120, loss=0.0433, recon=0.0433, kl=106.0294, beta=0.0000\n",
      "Batch 140, loss=0.0541, recon=0.0541, kl=123.6570, beta=0.0000\n",
      "Batch 160, loss=0.0447, recon=0.0446, kl=139.9467, beta=0.0000\n",
      "Batch 180, loss=0.0286, recon=0.0285, kl=116.9088, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0455, KL: 123.6701, Current Beta: 0.0000) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0277, recon=0.0276, kl=108.9258, beta=0.0000\n",
      "Batch 40, loss=0.0281, recon=0.0280, kl=111.4460, beta=0.0000\n",
      "Batch 60, loss=0.0477, recon=0.0477, kl=115.2242, beta=0.0000\n",
      "Batch 80, loss=0.0269, recon=0.0268, kl=109.5805, beta=0.0000\n",
      "Batch 100, loss=0.0215, recon=0.0214, kl=111.3632, beta=0.0000\n",
      "Batch 120, loss=0.0245, recon=0.0245, kl=115.1203, beta=0.0000\n",
      "Batch 140, loss=0.0192, recon=0.0191, kl=109.8259, beta=0.0000\n",
      "Batch 160, loss=0.0339, recon=0.0338, kl=111.3467, beta=0.0000\n",
      "Batch 180, loss=0.1046, recon=0.1046, kl=97.8412, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0438, KL: 111.9781, Current Beta: 0.0000) | Avg Valid Loss: 0.0809 | Avg Valid recon Loss: 0.0809\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0738, recon=0.0737, kl=82.9143, beta=0.0000\n",
      "Batch 40, loss=0.0488, recon=0.0486, kl=86.7368, beta=0.0000\n",
      "Batch 60, loss=0.0584, recon=0.0583, kl=105.6508, beta=0.0000\n",
      "Batch 80, loss=0.0290, recon=0.0288, kl=111.7446, beta=0.0000\n",
      "Batch 100, loss=0.0620, recon=0.0618, kl=108.1685, beta=0.0000\n",
      "Batch 120, loss=0.0397, recon=0.0396, kl=96.0659, beta=0.0000\n",
      "Batch 140, loss=0.0279, recon=0.0277, kl=100.0591, beta=0.0000\n",
      "Batch 160, loss=0.0342, recon=0.0341, kl=90.7114, beta=0.0000\n",
      "Batch 180, loss=0.0498, recon=0.0497, kl=102.0254, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0538 (Recon: 0.0537, KL: 96.6709, Current Beta: 0.0000) | Avg Valid Loss: 0.0502 | Avg Valid recon Loss: 0.0501\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0243, recon=0.0240, kl=78.0598, beta=0.0000\n",
      "Batch 40, loss=0.0343, recon=0.0340, kl=73.9982, beta=0.0000\n",
      "Batch 60, loss=0.0173, recon=0.0170, kl=74.0633, beta=0.0000\n",
      "Batch 80, loss=0.0297, recon=0.0294, kl=73.3307, beta=0.0000\n",
      "Batch 100, loss=0.0294, recon=0.0291, kl=71.9814, beta=0.0000\n",
      "Batch 120, loss=0.1452, recon=0.1449, kl=71.8760, beta=0.0000\n",
      "Batch 140, loss=0.0383, recon=0.0380, kl=82.7986, beta=0.0000\n",
      "Batch 160, loss=0.1038, recon=0.1035, kl=76.4423, beta=0.0000\n",
      "Batch 180, loss=0.0689, recon=0.0686, kl=68.8237, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0426, KL: 76.1381, Current Beta: 0.0000) | Avg Valid Loss: 0.0337 | Avg Valid recon Loss: 0.0335\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0277, recon=0.0273, kl=42.6969, beta=0.0000\n",
      "Batch 40, loss=0.0355, recon=0.0351, kl=40.1414, beta=0.0000\n",
      "Batch 60, loss=0.0437, recon=0.0432, kl=41.9266, beta=0.0000\n",
      "Batch 80, loss=0.0345, recon=0.0340, kl=41.2494, beta=0.0000\n",
      "Batch 100, loss=0.0299, recon=0.0294, kl=44.9433, beta=0.0000\n",
      "Batch 120, loss=0.0349, recon=0.0344, kl=47.3392, beta=0.0000\n",
      "Batch 140, loss=0.0428, recon=0.0423, kl=37.4805, beta=0.0000\n",
      "Batch 160, loss=0.0252, recon=0.0248, kl=35.0796, beta=0.0000\n",
      "Batch 180, loss=0.0562, recon=0.0558, kl=40.0844, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0387, KL: 42.3864, Current Beta: 0.0000) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0299, recon=0.0291, kl=26.5215, beta=0.0000\n",
      "Batch 40, loss=0.0240, recon=0.0233, kl=23.6378, beta=0.0000\n",
      "Batch 60, loss=0.0256, recon=0.0248, kl=26.5317, beta=0.0000\n",
      "Batch 80, loss=0.0287, recon=0.0277, kl=33.5198, beta=0.0000\n",
      "Batch 100, loss=0.0268, recon=0.0258, kl=35.6586, beta=0.0000\n",
      "Batch 120, loss=0.0204, recon=0.0194, kl=34.4981, beta=0.0000\n",
      "Batch 140, loss=0.0414, recon=0.0405, kl=31.7727, beta=0.0000\n",
      "Batch 160, loss=0.0359, recon=0.0351, kl=29.5538, beta=0.0000\n",
      "Batch 180, loss=0.0270, recon=0.0262, kl=27.5499, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0383, KL: 30.2813, Current Beta: 0.0000) | Avg Valid Loss: 0.0311 | Avg Valid recon Loss: 0.0302\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0241, recon=0.0226, kl=20.7110, beta=0.0001\n",
      "Batch 40, loss=0.0264, recon=0.0253, kl=14.3547, beta=0.0001\n",
      "Batch 60, loss=0.0264, recon=0.0256, kl=10.5861, beta=0.0001\n",
      "Batch 80, loss=0.0324, recon=0.0318, kl=7.9248, beta=0.0001\n",
      "Batch 100, loss=0.0243, recon=0.0237, kl=7.8884, beta=0.0001\n",
      "Batch 120, loss=0.0515, recon=0.0512, kl=4.2541, beta=0.0001\n",
      "Batch 140, loss=0.0156, recon=0.0152, kl=6.2346, beta=0.0001\n",
      "Batch 160, loss=0.0388, recon=0.0383, kl=5.7883, beta=0.0001\n",
      "Batch 180, loss=0.0305, recon=0.0300, kl=5.9008, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0364 (Recon: 0.0356, KL: 10.5863, Current Beta: 0.0001) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0209, recon=0.0203, kl=3.6284, beta=0.0002\n",
      "Batch 40, loss=0.0563, recon=0.0559, kl=1.9305, beta=0.0002\n",
      "Batch 60, loss=0.0259, recon=0.0257, kl=1.2852, beta=0.0002\n",
      "Batch 80, loss=0.0454, recon=0.0453, kl=0.8326, beta=0.0002\n",
      "Batch 100, loss=0.0231, recon=0.0228, kl=1.8031, beta=0.0002\n",
      "Batch 120, loss=0.0491, recon=0.0485, kl=3.4885, beta=0.0002\n",
      "Batch 140, loss=0.0489, recon=0.0482, kl=3.9482, beta=0.0002\n",
      "Batch 160, loss=0.0313, recon=0.0309, kl=2.6571, beta=0.0002\n",
      "Batch 180, loss=0.1432, recon=0.1429, kl=1.5146, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0414, KL: 2.5976, Current Beta: 0.0002) | Avg Valid Loss: 0.0378 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0312, recon=0.0311, kl=0.2915, beta=0.0004\n",
      "Batch 40, loss=0.0447, recon=0.0447, kl=0.0780, beta=0.0004\n",
      "Batch 60, loss=0.0199, recon=0.0198, kl=0.0644, beta=0.0004\n",
      "Batch 80, loss=0.0312, recon=0.0312, kl=0.0632, beta=0.0004\n",
      "Batch 100, loss=0.0319, recon=0.0319, kl=0.0530, beta=0.0004\n",
      "Batch 120, loss=0.0301, recon=0.0301, kl=0.0635, beta=0.0004\n",
      "Batch 140, loss=0.0828, recon=0.0828, kl=0.0513, beta=0.0004\n",
      "Batch 160, loss=0.0272, recon=0.0272, kl=0.0540, beta=0.0004\n",
      "Batch 180, loss=0.0408, recon=0.0407, kl=0.1269, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 0.1514, Current Beta: 0.0004) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0540\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0753, recon=0.0751, kl=0.3071, beta=0.0006\n",
      "Batch 40, loss=0.0282, recon=0.0281, kl=0.1729, beta=0.0006\n",
      "Batch 60, loss=0.0289, recon=0.0289, kl=0.0474, beta=0.0006\n",
      "Batch 80, loss=0.0725, recon=0.0724, kl=0.0452, beta=0.0006\n",
      "Batch 100, loss=0.0681, recon=0.0681, kl=0.0772, beta=0.0006\n",
      "Batch 120, loss=0.0536, recon=0.0535, kl=0.2430, beta=0.0006\n",
      "Batch 140, loss=0.0372, recon=0.0370, kl=0.2158, beta=0.0006\n",
      "Batch 160, loss=0.0639, recon=0.0639, kl=0.0952, beta=0.0006\n",
      "Batch 180, loss=0.0227, recon=0.0226, kl=0.0877, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0517, KL: 0.1503, Current Beta: 0.0006) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0891, recon=0.0891, kl=0.0132, beta=0.0010\n",
      "Batch 40, loss=0.0493, recon=0.0493, kl=0.0181, beta=0.0010\n",
      "Batch 60, loss=0.0350, recon=0.0350, kl=0.0503, beta=0.0010\n",
      "Batch 80, loss=0.0222, recon=0.0222, kl=0.0102, beta=0.0010\n",
      "Batch 100, loss=0.0419, recon=0.0419, kl=0.0088, beta=0.0010\n",
      "Batch 120, loss=0.0168, recon=0.0168, kl=0.0047, beta=0.0010\n",
      "Batch 140, loss=0.0249, recon=0.0249, kl=0.0042, beta=0.0010\n",
      "Batch 160, loss=0.4897, recon=0.4897, kl=0.0035, beta=0.0010\n",
      "Batch 180, loss=0.0520, recon=0.0520, kl=0.0082, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 0.0164, Current Beta: 0.0010) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0313, recon=0.0313, kl=0.0185, beta=0.0010\n",
      "Batch 40, loss=0.0423, recon=0.0422, kl=0.0385, beta=0.0010\n",
      "Batch 60, loss=0.0577, recon=0.0577, kl=0.0704, beta=0.0010\n",
      "Batch 80, loss=0.0276, recon=0.0275, kl=0.0378, beta=0.0010\n",
      "Batch 100, loss=0.0269, recon=0.0269, kl=0.0106, beta=0.0010\n",
      "Batch 120, loss=0.0281, recon=0.0281, kl=0.0076, beta=0.0010\n",
      "Batch 140, loss=0.0263, recon=0.0263, kl=0.0040, beta=0.0010\n",
      "Batch 160, loss=0.0513, recon=0.0513, kl=0.0102, beta=0.0010\n",
      "Batch 180, loss=0.0271, recon=0.0270, kl=0.0291, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 0.0258, Current Beta: 0.0010) | Avg Valid Loss: 0.0385 | Avg Valid recon Loss: 0.0384\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0263, recon=0.0263, kl=0.0250, beta=0.0010\n",
      "Batch 40, loss=0.0278, recon=0.0277, kl=0.0075, beta=0.0010\n",
      "Batch 60, loss=0.0694, recon=0.0694, kl=0.0033, beta=0.0010\n",
      "Batch 80, loss=0.0543, recon=0.0542, kl=0.0278, beta=0.0010\n",
      "Batch 100, loss=0.0483, recon=0.0482, kl=0.1019, beta=0.0010\n",
      "Batch 120, loss=0.0260, recon=0.0255, kl=0.4915, beta=0.0010\n",
      "Batch 140, loss=0.0231, recon=0.0230, kl=0.1693, beta=0.0010\n",
      "Batch 160, loss=0.0214, recon=0.0213, kl=0.1011, beta=0.0010\n",
      "Batch 180, loss=0.0420, recon=0.0420, kl=0.0162, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0452 (Recon: 0.0450, KL: 0.1150, Current Beta: 0.0010) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0624, recon=0.0623, kl=0.0473, beta=0.0010\n",
      "Batch 40, loss=0.0339, recon=0.0338, kl=0.0311, beta=0.0010\n",
      "Batch 60, loss=0.0374, recon=0.0374, kl=0.0165, beta=0.0010\n",
      "Batch 80, loss=0.0450, recon=0.0450, kl=0.0043, beta=0.0010\n",
      "Batch 100, loss=0.0354, recon=0.0354, kl=0.0123, beta=0.0010\n",
      "Batch 120, loss=0.0212, recon=0.0212, kl=0.0076, beta=0.0010\n",
      "Batch 140, loss=0.0207, recon=0.0206, kl=0.0118, beta=0.0010\n",
      "Batch 160, loss=0.0236, recon=0.0236, kl=0.0081, beta=0.0010\n",
      "Batch 180, loss=0.0330, recon=0.0330, kl=0.0027, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0425, KL: 0.0171, Current Beta: 0.0010) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0394\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0293, recon=0.0293, kl=0.0031, beta=0.0010\n",
      "Batch 40, loss=0.0236, recon=0.0236, kl=0.0016, beta=0.0010\n",
      "Batch 60, loss=0.0244, recon=0.0244, kl=0.0046, beta=0.0010\n",
      "Batch 80, loss=0.0369, recon=0.0369, kl=0.0040, beta=0.0010\n",
      "Batch 100, loss=0.0294, recon=0.0294, kl=0.0090, beta=0.0010\n",
      "Batch 120, loss=0.0259, recon=0.0258, kl=0.0060, beta=0.0010\n",
      "Batch 140, loss=0.0420, recon=0.0420, kl=0.0134, beta=0.0010\n",
      "Batch 160, loss=0.0276, recon=0.0276, kl=0.0047, beta=0.0010\n",
      "Batch 180, loss=0.0715, recon=0.0715, kl=0.0025, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0414, KL: 0.0056, Current Beta: 0.0010) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0317\n",
      "\n",
      "[VRAE Run 67/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2865, recon=0.2865, kl=4.1095, beta=0.0000\n",
      "Batch 40, loss=0.2598, recon=0.2598, kl=15.8158, beta=0.0000\n",
      "Batch 60, loss=0.1337, recon=0.1337, kl=22.5197, beta=0.0000\n",
      "Batch 80, loss=0.1418, recon=0.1418, kl=28.0027, beta=0.0000\n",
      "Batch 100, loss=0.1092, recon=0.1092, kl=31.7192, beta=0.0000\n",
      "Batch 120, loss=0.0870, recon=0.0870, kl=40.2435, beta=0.0000\n",
      "Batch 140, loss=0.0716, recon=0.0716, kl=40.2102, beta=0.0000\n",
      "Batch 160, loss=0.0852, recon=0.0852, kl=43.0946, beta=0.0000\n",
      "Batch 180, loss=0.0802, recon=0.0802, kl=37.8747, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1955 (Recon: 0.1955, KL: 27.4225, Current Beta: 0.0000) | Avg Valid Loss: 0.0826 | Avg Valid recon Loss: 0.0826\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0758, recon=0.0758, kl=41.1442, beta=0.0000\n",
      "Batch 40, loss=0.0769, recon=0.0769, kl=44.1152, beta=0.0000\n",
      "Batch 60, loss=0.0826, recon=0.0826, kl=45.7603, beta=0.0000\n",
      "Batch 80, loss=0.0858, recon=0.0858, kl=46.3361, beta=0.0000\n",
      "Batch 100, loss=0.3743, recon=0.3743, kl=50.4635, beta=0.0000\n",
      "Batch 120, loss=0.0625, recon=0.0625, kl=50.5064, beta=0.0000\n",
      "Batch 140, loss=0.0827, recon=0.0827, kl=53.0804, beta=0.0000\n",
      "Batch 160, loss=0.0634, recon=0.0634, kl=54.8015, beta=0.0000\n",
      "Batch 180, loss=0.0585, recon=0.0585, kl=57.2339, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0895 (Recon: 0.0895, KL: 48.3007, Current Beta: 0.0000) | Avg Valid Loss: 0.0636 | Avg Valid recon Loss: 0.0636\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0554, recon=0.0554, kl=52.9027, beta=0.0000\n",
      "Batch 40, loss=0.0601, recon=0.0601, kl=56.2997, beta=0.0000\n",
      "Batch 60, loss=0.0517, recon=0.0517, kl=57.5463, beta=0.0000\n",
      "Batch 80, loss=0.0472, recon=0.0472, kl=55.2681, beta=0.0000\n",
      "Batch 100, loss=0.0726, recon=0.0726, kl=54.2031, beta=0.0000\n",
      "Batch 120, loss=0.0498, recon=0.0498, kl=52.9044, beta=0.0000\n",
      "Batch 140, loss=0.0593, recon=0.0593, kl=51.2712, beta=0.0000\n",
      "Batch 160, loss=0.0517, recon=0.0517, kl=50.8910, beta=0.0000\n",
      "Batch 180, loss=0.0450, recon=0.0450, kl=50.9519, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0697 (Recon: 0.0697, KL: 54.1510, Current Beta: 0.0000) | Avg Valid Loss: 0.0531 | Avg Valid recon Loss: 0.0531\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0400, recon=0.0400, kl=52.9620, beta=0.0000\n",
      "Batch 40, loss=0.0335, recon=0.0335, kl=56.5216, beta=0.0000\n",
      "Batch 60, loss=0.0288, recon=0.0288, kl=50.7402, beta=0.0000\n",
      "Batch 80, loss=0.0749, recon=0.0749, kl=52.4743, beta=0.0000\n",
      "Batch 100, loss=0.0687, recon=0.0687, kl=51.4122, beta=0.0000\n",
      "Batch 120, loss=0.0416, recon=0.0416, kl=53.8846, beta=0.0000\n",
      "Batch 140, loss=0.0401, recon=0.0401, kl=54.5403, beta=0.0000\n",
      "Batch 160, loss=0.0378, recon=0.0378, kl=49.8503, beta=0.0000\n",
      "Batch 180, loss=0.0416, recon=0.0416, kl=51.9138, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0587 (Recon: 0.0587, KL: 52.3534, Current Beta: 0.0000) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0480\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0779, recon=0.0779, kl=51.1204, beta=0.0000\n",
      "Batch 40, loss=0.0313, recon=0.0313, kl=46.2471, beta=0.0000\n",
      "Batch 60, loss=0.0517, recon=0.0517, kl=47.4519, beta=0.0000\n",
      "Batch 80, loss=0.0407, recon=0.0407, kl=45.6873, beta=0.0000\n",
      "Batch 100, loss=0.0386, recon=0.0386, kl=45.0591, beta=0.0000\n",
      "Batch 120, loss=0.0304, recon=0.0304, kl=45.5327, beta=0.0000\n",
      "Batch 140, loss=0.0253, recon=0.0253, kl=45.2848, beta=0.0000\n",
      "Batch 160, loss=0.0330, recon=0.0329, kl=43.8146, beta=0.0000\n",
      "Batch 180, loss=0.0173, recon=0.0173, kl=44.6743, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0522 (Recon: 0.0522, KL: 46.6384, Current Beta: 0.0000) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0276, recon=0.0276, kl=41.3896, beta=0.0000\n",
      "Batch 40, loss=0.0449, recon=0.0449, kl=40.5226, beta=0.0000\n",
      "Batch 60, loss=0.0320, recon=0.0320, kl=38.0537, beta=0.0000\n",
      "Batch 80, loss=0.0306, recon=0.0306, kl=37.9143, beta=0.0000\n",
      "Batch 100, loss=0.0276, recon=0.0276, kl=36.4051, beta=0.0000\n",
      "Batch 120, loss=0.0314, recon=0.0314, kl=37.3884, beta=0.0000\n",
      "Batch 140, loss=0.0844, recon=0.0844, kl=35.5088, beta=0.0000\n",
      "Batch 160, loss=0.0215, recon=0.0215, kl=36.1113, beta=0.0000\n",
      "Batch 180, loss=0.0287, recon=0.0287, kl=35.7809, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0471 (Recon: 0.0471, KL: 38.2118, Current Beta: 0.0000) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0227, recon=0.0227, kl=33.4022, beta=0.0000\n",
      "Batch 40, loss=0.0226, recon=0.0226, kl=30.5993, beta=0.0000\n",
      "Batch 60, loss=0.1739, recon=0.1739, kl=29.6159, beta=0.0000\n",
      "Batch 80, loss=0.0610, recon=0.0609, kl=28.2494, beta=0.0000\n",
      "Batch 100, loss=0.0341, recon=0.0341, kl=24.6007, beta=0.0000\n",
      "Batch 120, loss=0.1739, recon=0.1739, kl=24.6830, beta=0.0000\n",
      "Batch 140, loss=0.0344, recon=0.0344, kl=26.5900, beta=0.0000\n",
      "Batch 160, loss=0.0259, recon=0.0259, kl=25.8923, beta=0.0000\n",
      "Batch 180, loss=0.0299, recon=0.0299, kl=26.7146, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0439 (Recon: 0.0439, KL: 28.2041, Current Beta: 0.0000) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=20.0285, beta=0.0000\n",
      "Batch 40, loss=0.0186, recon=0.0186, kl=16.6786, beta=0.0000\n",
      "Batch 60, loss=0.0293, recon=0.0293, kl=15.1740, beta=0.0000\n",
      "Batch 80, loss=0.0277, recon=0.0277, kl=15.1543, beta=0.0000\n",
      "Batch 100, loss=0.0221, recon=0.0221, kl=15.2907, beta=0.0000\n",
      "Batch 120, loss=0.0278, recon=0.0278, kl=15.5406, beta=0.0000\n",
      "Batch 140, loss=0.0542, recon=0.0542, kl=15.8930, beta=0.0000\n",
      "Batch 160, loss=0.0357, recon=0.0357, kl=14.9910, beta=0.0000\n",
      "Batch 180, loss=0.0256, recon=0.0255, kl=14.7826, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0410, KL: 16.5973, Current Beta: 0.0000) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0285, recon=0.0285, kl=9.5742, beta=0.0000\n",
      "Batch 40, loss=0.0340, recon=0.0340, kl=9.9296, beta=0.0000\n",
      "Batch 60, loss=0.0230, recon=0.0230, kl=8.9999, beta=0.0000\n",
      "Batch 80, loss=0.0349, recon=0.0349, kl=7.8821, beta=0.0000\n",
      "Batch 100, loss=0.0290, recon=0.0290, kl=7.7624, beta=0.0000\n",
      "Batch 120, loss=0.0664, recon=0.0663, kl=7.1785, beta=0.0000\n",
      "Batch 140, loss=0.0325, recon=0.0324, kl=7.1520, beta=0.0000\n",
      "Batch 160, loss=0.0263, recon=0.0263, kl=7.0899, beta=0.0000\n",
      "Batch 180, loss=0.0285, recon=0.0285, kl=7.2868, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0390, KL: 8.4082, Current Beta: 0.0000) | Avg Valid Loss: 0.0336 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0275, recon=0.0275, kl=3.6118, beta=0.0000\n",
      "Batch 40, loss=0.0336, recon=0.0336, kl=3.6924, beta=0.0000\n",
      "Batch 60, loss=0.0262, recon=0.0262, kl=6.1701, beta=0.0000\n",
      "Batch 80, loss=0.0223, recon=0.0223, kl=3.6545, beta=0.0000\n",
      "Batch 100, loss=0.0259, recon=0.0258, kl=3.9941, beta=0.0000\n",
      "Batch 120, loss=0.0260, recon=0.0260, kl=2.9442, beta=0.0000\n",
      "Batch 140, loss=0.0202, recon=0.0201, kl=3.3048, beta=0.0000\n",
      "Batch 160, loss=0.0340, recon=0.0340, kl=2.6262, beta=0.0000\n",
      "Batch 180, loss=0.0398, recon=0.0398, kl=3.2740, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0370, KL: 3.8991, Current Beta: 0.0000) | Avg Valid Loss: 0.0326 | Avg Valid recon Loss: 0.0325\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0554, recon=0.0553, kl=1.3007, beta=0.0000\n",
      "Batch 40, loss=0.1047, recon=0.1046, kl=2.2365, beta=0.0000\n",
      "Batch 60, loss=0.0182, recon=0.0182, kl=1.6172, beta=0.0000\n",
      "Batch 80, loss=0.0187, recon=0.0186, kl=1.2425, beta=0.0000\n",
      "Batch 100, loss=0.0222, recon=0.0221, kl=1.3767, beta=0.0000\n",
      "Batch 120, loss=0.0349, recon=0.0349, kl=1.7494, beta=0.0000\n",
      "Batch 140, loss=0.0226, recon=0.0225, kl=1.2252, beta=0.0000\n",
      "Batch 160, loss=0.0219, recon=0.0219, kl=1.4185, beta=0.0000\n",
      "Batch 180, loss=0.0398, recon=0.0397, kl=1.0981, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0359 (Recon: 0.0359, KL: 1.5829, Current Beta: 0.0000) | Avg Valid Loss: 0.0313 | Avg Valid recon Loss: 0.0313\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0608, recon=0.0608, kl=0.3253, beta=0.0001\n",
      "Batch 40, loss=0.0484, recon=0.0484, kl=0.6516, beta=0.0001\n",
      "Batch 60, loss=0.0412, recon=0.0412, kl=0.3738, beta=0.0001\n",
      "Batch 80, loss=0.0278, recon=0.0278, kl=0.3188, beta=0.0001\n",
      "Batch 100, loss=0.0263, recon=0.0262, kl=0.4241, beta=0.0001\n",
      "Batch 120, loss=0.0304, recon=0.0304, kl=0.1846, beta=0.0001\n",
      "Batch 140, loss=0.4631, recon=0.4631, kl=0.2092, beta=0.0001\n",
      "Batch 160, loss=0.0710, recon=0.0709, kl=0.1922, beta=0.0001\n",
      "Batch 180, loss=0.0514, recon=0.0514, kl=0.1769, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0348 (Recon: 0.0348, KL: 0.3576, Current Beta: 0.0001) | Avg Valid Loss: 0.0319 | Avg Valid recon Loss: 0.0318\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0217, recon=0.0217, kl=0.0099, beta=0.0002\n",
      "Batch 40, loss=0.0444, recon=0.0444, kl=0.1046, beta=0.0002\n",
      "Batch 60, loss=0.0365, recon=0.0365, kl=0.0173, beta=0.0002\n",
      "Batch 80, loss=0.0363, recon=0.0363, kl=0.0272, beta=0.0002\n",
      "Batch 100, loss=0.0336, recon=0.0335, kl=0.0340, beta=0.0002\n",
      "Batch 120, loss=0.0153, recon=0.0153, kl=0.0096, beta=0.0002\n",
      "Batch 140, loss=0.0253, recon=0.0253, kl=0.0226, beta=0.0002\n",
      "Batch 160, loss=0.0206, recon=0.0206, kl=0.0147, beta=0.0002\n",
      "Batch 180, loss=0.0167, recon=0.0166, kl=0.0606, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0342 (Recon: 0.0342, KL: 0.0371, Current Beta: 0.0002) | Avg Valid Loss: 0.0299 | Avg Valid recon Loss: 0.0299\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0185, recon=0.0185, kl=0.0062, beta=0.0004\n",
      "Batch 40, loss=0.0244, recon=0.0244, kl=0.0027, beta=0.0004\n",
      "Batch 60, loss=0.0208, recon=0.0208, kl=0.0013, beta=0.0004\n",
      "Batch 80, loss=0.0283, recon=0.0283, kl=0.0030, beta=0.0004\n",
      "Batch 100, loss=0.0260, recon=0.0260, kl=0.0035, beta=0.0004\n",
      "Batch 120, loss=0.0268, recon=0.0268, kl=0.0115, beta=0.0004\n",
      "Batch 140, loss=0.0283, recon=0.0283, kl=0.0139, beta=0.0004\n",
      "Batch 160, loss=0.1213, recon=0.1213, kl=0.0195, beta=0.0004\n",
      "Batch 180, loss=0.0376, recon=0.0376, kl=0.0019, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0329 (Recon: 0.0329, KL: 0.0092, Current Beta: 0.0004) | Avg Valid Loss: 0.0294 | Avg Valid recon Loss: 0.0294\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0422, recon=0.0422, kl=0.0010, beta=0.0006\n",
      "Batch 40, loss=0.0240, recon=0.0240, kl=0.0013, beta=0.0006\n",
      "Batch 60, loss=0.0180, recon=0.0180, kl=0.0013, beta=0.0006\n",
      "Batch 80, loss=0.0212, recon=0.0212, kl=0.0021, beta=0.0006\n",
      "Batch 100, loss=0.0229, recon=0.0229, kl=0.0010, beta=0.0006\n",
      "Batch 120, loss=0.0186, recon=0.0186, kl=0.0014, beta=0.0006\n",
      "Batch 140, loss=0.0178, recon=0.0178, kl=0.0059, beta=0.0006\n",
      "Batch 160, loss=0.0142, recon=0.0142, kl=0.0022, beta=0.0006\n",
      "Batch 180, loss=0.0264, recon=0.0264, kl=0.0029, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0322 (Recon: 0.0322, KL: 0.0023, Current Beta: 0.0006) | Avg Valid Loss: 0.0288 | Avg Valid recon Loss: 0.0288\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0182, recon=0.0182, kl=0.0011, beta=0.0010\n",
      "Batch 40, loss=0.0294, recon=0.0294, kl=0.0007, beta=0.0010\n",
      "Batch 60, loss=0.0213, recon=0.0213, kl=0.0006, beta=0.0010\n",
      "Batch 80, loss=0.0242, recon=0.0242, kl=0.0004, beta=0.0010\n",
      "Batch 100, loss=0.0211, recon=0.0211, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0175, recon=0.0175, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0195, recon=0.0195, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0200, recon=0.0200, kl=0.0006, beta=0.0010\n",
      "Batch 180, loss=0.0298, recon=0.0298, kl=0.0021, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0319 (Recon: 0.0319, KL: 0.0011, Current Beta: 0.0010) | Avg Valid Loss: 0.0289 | Avg Valid recon Loss: 0.0289\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0372, recon=0.0372, kl=0.0012, beta=0.0010\n",
      "Batch 40, loss=0.0328, recon=0.0328, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0274, recon=0.0274, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0266, recon=0.0266, kl=0.0005, beta=0.0010\n",
      "Batch 100, loss=0.0213, recon=0.0213, kl=0.0251, beta=0.0010\n",
      "Batch 120, loss=0.0166, recon=0.0166, kl=0.0019, beta=0.0010\n",
      "Batch 140, loss=0.0236, recon=0.0236, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0291, recon=0.0291, kl=0.0008, beta=0.0010\n",
      "Batch 180, loss=0.0203, recon=0.0203, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0313 (Recon: 0.0313, KL: 0.0017, Current Beta: 0.0010) | Avg Valid Loss: 0.0269 | Avg Valid recon Loss: 0.0269\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0347, recon=0.0347, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0199, recon=0.0199, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0193, recon=0.0193, kl=0.0038, beta=0.0010\n",
      "Batch 80, loss=0.1062, recon=0.1062, kl=0.0010, beta=0.0010\n",
      "Batch 100, loss=0.0205, recon=0.0205, kl=0.0004, beta=0.0010\n",
      "Batch 120, loss=0.0255, recon=0.0255, kl=0.0009, beta=0.0010\n",
      "Batch 140, loss=0.0218, recon=0.0218, kl=0.0005, beta=0.0010\n",
      "Batch 160, loss=0.0806, recon=0.0806, kl=0.0007, beta=0.0010\n",
      "Batch 180, loss=0.0240, recon=0.0240, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0306 (Recon: 0.0306, KL: 0.0019, Current Beta: 0.0010) | Avg Valid Loss: 0.0311 | Avg Valid recon Loss: 0.0311\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0378, recon=0.0378, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0165, recon=0.0165, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0321, recon=0.0321, kl=0.0019, beta=0.0010\n",
      "Batch 80, loss=0.0362, recon=0.0362, kl=0.0036, beta=0.0010\n",
      "Batch 100, loss=0.0282, recon=0.0282, kl=0.0012, beta=0.0010\n",
      "Batch 120, loss=0.0272, recon=0.0272, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0981, recon=0.0981, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0334, recon=0.0334, kl=0.0004, beta=0.0010\n",
      "Batch 180, loss=0.0568, recon=0.0568, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0325 (Recon: 0.0325, KL: 0.0016, Current Beta: 0.0010) | Avg Valid Loss: 0.0281 | Avg Valid recon Loss: 0.0281\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0231, recon=0.0231, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0366, recon=0.0366, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0326, recon=0.0326, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0223, recon=0.0223, kl=0.0006, beta=0.0010\n",
      "Batch 100, loss=0.0182, recon=0.0182, kl=0.0003, beta=0.0010\n",
      "Batch 120, loss=0.0296, recon=0.0296, kl=0.0095, beta=0.0010\n",
      "Batch 140, loss=0.0343, recon=0.0343, kl=0.0011, beta=0.0010\n",
      "Batch 160, loss=0.0168, recon=0.0168, kl=0.0006, beta=0.0010\n",
      "Batch 180, loss=0.0210, recon=0.0210, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0303 (Recon: 0.0303, KL: 0.0011, Current Beta: 0.0010) | Avg Valid Loss: 0.0263 | Avg Valid recon Loss: 0.0263\n",
      " New best VRAE model found with validation loss: 0.0263\n",
      "   Model saved to ./ecg_model_logs\\best_vrae_model.pth\n",
      "\n",
      "[VRAE Run 68/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1419, recon=0.1419, kl=30.8353, beta=0.0000\n",
      "Batch 40, loss=0.1059, recon=0.1059, kl=26.0436, beta=0.0000\n",
      "Batch 60, loss=0.0799, recon=0.0799, kl=23.8399, beta=0.0000\n",
      "Batch 80, loss=0.0467, recon=0.0467, kl=24.3945, beta=0.0000\n",
      "Batch 100, loss=0.0562, recon=0.0562, kl=31.5814, beta=0.0000\n",
      "Batch 120, loss=0.0546, recon=0.0546, kl=37.4161, beta=0.0000\n",
      "Batch 140, loss=0.0850, recon=0.0850, kl=37.4955, beta=0.0000\n",
      "Batch 160, loss=0.0575, recon=0.0575, kl=36.6498, beta=0.0000\n",
      "Batch 180, loss=0.0553, recon=0.0553, kl=35.0250, beta=0.0000\n",
      "  â†’ Avg Train Loss: 7.2092 (Recon: 7.2092, KL: 379.1405, Current Beta: 0.0000) | Avg Valid Loss: 0.0672 | Avg Valid recon Loss: 0.0672\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0794, recon=0.0794, kl=36.7750, beta=0.0000\n",
      "Batch 40, loss=0.0311, recon=0.0311, kl=37.4351, beta=0.0000\n",
      "Batch 60, loss=0.0603, recon=0.0603, kl=35.7946, beta=0.0000\n",
      "Batch 80, loss=0.0353, recon=0.0353, kl=37.2865, beta=0.0000\n",
      "Batch 100, loss=0.0559, recon=0.0559, kl=37.1319, beta=0.0000\n",
      "Batch 120, loss=0.0390, recon=0.0390, kl=36.5592, beta=0.0000\n",
      "Batch 140, loss=1.0878, recon=1.0878, kl=37.8460, beta=0.0000\n",
      "Batch 160, loss=0.0560, recon=0.0560, kl=36.6468, beta=0.0000\n",
      "Batch 180, loss=0.0408, recon=0.0408, kl=37.1022, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0582 (Recon: 0.0582, KL: 36.9369, Current Beta: 0.0000) | Avg Valid Loss: 0.0525 | Avg Valid recon Loss: 0.0525\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0444, recon=0.0444, kl=37.2346, beta=0.0000\n",
      "Batch 40, loss=0.0380, recon=0.0380, kl=37.2684, beta=0.0000\n",
      "Batch 60, loss=0.0356, recon=0.0356, kl=37.9325, beta=0.0000\n",
      "Batch 80, loss=0.0306, recon=0.0306, kl=38.9403, beta=0.0000\n",
      "Batch 100, loss=0.0282, recon=0.0281, kl=35.6740, beta=0.0000\n",
      "Batch 120, loss=0.0591, recon=0.0591, kl=36.4529, beta=0.0000\n",
      "Batch 140, loss=0.0513, recon=0.0513, kl=34.6117, beta=0.0000\n",
      "Batch 160, loss=0.0308, recon=0.0308, kl=33.6089, beta=0.0000\n",
      "Batch 180, loss=0.1936, recon=0.1936, kl=34.3037, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 36.1295, Current Beta: 0.0000) | Avg Valid Loss: 0.0506 | Avg Valid recon Loss: 0.0506\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0406, recon=0.0406, kl=35.3334, beta=0.0000\n",
      "Batch 40, loss=0.1436, recon=0.1436, kl=35.4436, beta=0.0000\n",
      "Batch 60, loss=0.0395, recon=0.0395, kl=35.9742, beta=0.0000\n",
      "Batch 80, loss=0.0476, recon=0.0476, kl=32.7350, beta=0.0000\n",
      "Batch 100, loss=0.0450, recon=0.0450, kl=29.7866, beta=0.0000\n",
      "Batch 120, loss=0.1355, recon=0.1355, kl=30.8690, beta=0.0000\n",
      "Batch 140, loss=0.0269, recon=0.0269, kl=31.2839, beta=0.0000\n",
      "Batch 160, loss=0.0245, recon=0.0245, kl=32.9690, beta=0.0000\n",
      "Batch 180, loss=0.0245, recon=0.0245, kl=31.8754, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0521 (Recon: 0.0521, KL: 32.9192, Current Beta: 0.0000) | Avg Valid Loss: 0.0360 | Avg Valid recon Loss: 0.0360\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0274, recon=0.0274, kl=32.5434, beta=0.0000\n",
      "Batch 40, loss=0.0420, recon=0.0420, kl=34.3538, beta=0.0000\n",
      "Batch 60, loss=0.0305, recon=0.0305, kl=29.6456, beta=0.0000\n",
      "Batch 80, loss=0.0517, recon=0.0517, kl=29.9856, beta=0.0000\n",
      "Batch 100, loss=0.0495, recon=0.0495, kl=29.7657, beta=0.0000\n",
      "Batch 120, loss=0.0483, recon=0.0483, kl=30.9209, beta=0.0000\n",
      "Batch 140, loss=0.0519, recon=0.0518, kl=31.8075, beta=0.0000\n",
      "Batch 160, loss=0.0286, recon=0.0286, kl=31.7808, beta=0.0000\n",
      "Batch 180, loss=0.0303, recon=0.0303, kl=33.2211, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0474 (Recon: 0.0474, KL: 31.4342, Current Beta: 0.0000) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0355\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0566, recon=0.0566, kl=31.2095, beta=0.0000\n",
      "Batch 40, loss=0.0758, recon=0.0758, kl=27.7745, beta=0.0000\n",
      "Batch 60, loss=0.0205, recon=0.0205, kl=30.0737, beta=0.0000\n",
      "Batch 80, loss=0.0275, recon=0.0275, kl=31.0783, beta=0.0000\n",
      "Batch 100, loss=0.0279, recon=0.0279, kl=31.6304, beta=0.0000\n",
      "Batch 120, loss=0.0261, recon=0.0261, kl=32.7950, beta=0.0000\n",
      "Batch 140, loss=0.0212, recon=0.0212, kl=33.4255, beta=0.0000\n",
      "Batch 160, loss=0.0308, recon=0.0308, kl=34.8130, beta=0.0000\n",
      "Batch 180, loss=0.0360, recon=0.0360, kl=33.2265, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 31.6982, Current Beta: 0.0000) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0253, recon=0.0253, kl=33.2440, beta=0.0000\n",
      "Batch 40, loss=0.0260, recon=0.0260, kl=33.8680, beta=0.0000\n",
      "Batch 60, loss=0.0624, recon=0.0624, kl=31.5845, beta=0.0000\n",
      "Batch 80, loss=0.0327, recon=0.0327, kl=26.7421, beta=0.0000\n",
      "Batch 100, loss=0.0418, recon=0.0417, kl=29.6549, beta=0.0000\n",
      "Batch 120, loss=0.0266, recon=0.0266, kl=32.7017, beta=0.0000\n",
      "Batch 140, loss=0.0257, recon=0.0257, kl=33.5108, beta=0.0000\n",
      "Batch 160, loss=0.0255, recon=0.0255, kl=34.5917, beta=0.0000\n",
      "Batch 180, loss=0.0196, recon=0.0196, kl=34.8021, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0462, KL: 32.1999, Current Beta: 0.0000) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0334, recon=0.0334, kl=33.7835, beta=0.0000\n",
      "Batch 40, loss=0.0288, recon=0.0288, kl=33.1200, beta=0.0000\n",
      "Batch 60, loss=0.0316, recon=0.0315, kl=31.3590, beta=0.0000\n",
      "Batch 80, loss=0.0246, recon=0.0246, kl=32.1355, beta=0.0000\n",
      "Batch 100, loss=0.1001, recon=0.1001, kl=32.9126, beta=0.0000\n",
      "Batch 120, loss=0.0348, recon=0.0348, kl=28.2722, beta=0.0000\n",
      "Batch 140, loss=0.0428, recon=0.0428, kl=27.5945, beta=0.0000\n",
      "Batch 160, loss=0.0279, recon=0.0278, kl=28.8843, beta=0.0000\n",
      "Batch 180, loss=0.0319, recon=0.0318, kl=30.1123, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0454 (Recon: 0.0454, KL: 31.1289, Current Beta: 0.0000) | Avg Valid Loss: 0.0343 | Avg Valid recon Loss: 0.0343\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0304, recon=0.0303, kl=27.7281, beta=0.0000\n",
      "Batch 40, loss=0.0276, recon=0.0275, kl=25.7820, beta=0.0000\n",
      "Batch 60, loss=0.0295, recon=0.0294, kl=25.4919, beta=0.0000\n",
      "Batch 80, loss=0.0241, recon=0.0239, kl=26.9439, beta=0.0000\n",
      "Batch 100, loss=0.0306, recon=0.0304, kl=26.6869, beta=0.0000\n",
      "Batch 120, loss=0.0371, recon=0.0370, kl=25.1808, beta=0.0000\n",
      "Batch 140, loss=0.0613, recon=0.0612, kl=25.9668, beta=0.0000\n",
      "Batch 160, loss=0.0202, recon=0.0201, kl=25.0376, beta=0.0000\n",
      "Batch 180, loss=2.8470, recon=2.8470, kl=16.7040, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0796 (Recon: 0.0795, KL: 26.1804, Current Beta: 0.0000) | Avg Valid Loss: 1.2580 | Avg Valid recon Loss: 1.2579\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.2038, recon=0.2037, kl=15.9649, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 11/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 12/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 13/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0002) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 14/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0004) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0006) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 69/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4904, recon=0.4904, kl=8.2262, beta=0.0000\n",
      "Batch 40, loss=1.0649, recon=1.0649, kl=36.8940, beta=0.0000\n",
      "Batch 60, loss=0.1704, recon=0.1704, kl=47.6025, beta=0.0000\n",
      "Batch 80, loss=0.1135, recon=0.1135, kl=56.9694, beta=0.0000\n",
      "Batch 100, loss=0.1488, recon=0.1488, kl=66.4771, beta=0.0000\n",
      "Batch 120, loss=0.1292, recon=0.1292, kl=73.9709, beta=0.0000\n",
      "Batch 140, loss=0.1315, recon=0.1315, kl=82.1010, beta=0.0000\n",
      "Batch 160, loss=0.0960, recon=0.0960, kl=82.1612, beta=0.0000\n",
      "Batch 180, loss=0.0819, recon=0.0819, kl=84.5188, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2074 (Recon: 0.2074, KL: 55.6277, Current Beta: 0.0000) | Avg Valid Loss: 0.0908 | Avg Valid recon Loss: 0.0908\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1547, recon=0.1547, kl=83.0300, beta=0.0000\n",
      "Batch 40, loss=0.0912, recon=0.0912, kl=83.6796, beta=0.0000\n",
      "Batch 60, loss=0.0958, recon=0.0958, kl=86.9573, beta=0.0000\n",
      "Batch 80, loss=0.1087, recon=0.1087, kl=87.5631, beta=0.0000\n",
      "Batch 100, loss=0.0733, recon=0.0733, kl=84.2330, beta=0.0000\n",
      "Batch 120, loss=0.0790, recon=0.0790, kl=89.7504, beta=0.0000\n",
      "Batch 140, loss=0.0853, recon=0.0853, kl=94.8909, beta=0.0000\n",
      "Batch 160, loss=0.0688, recon=0.0688, kl=96.3609, beta=0.0000\n",
      "Batch 180, loss=0.0526, recon=0.0526, kl=100.2064, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0936 (Recon: 0.0936, KL: 88.8132, Current Beta: 0.0000) | Avg Valid Loss: 0.0648 | Avg Valid recon Loss: 0.0648\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0662, recon=0.0662, kl=97.0029, beta=0.0000\n",
      "Batch 40, loss=0.0545, recon=0.0545, kl=89.8475, beta=0.0000\n",
      "Batch 60, loss=0.0516, recon=0.0516, kl=91.7321, beta=0.0000\n",
      "Batch 80, loss=0.0417, recon=0.0417, kl=96.5128, beta=0.0000\n",
      "Batch 100, loss=0.0487, recon=0.0487, kl=97.8969, beta=0.0000\n",
      "Batch 120, loss=0.0404, recon=0.0404, kl=96.5852, beta=0.0000\n",
      "Batch 140, loss=0.0545, recon=0.0545, kl=96.9499, beta=0.0000\n",
      "Batch 160, loss=0.0503, recon=0.0503, kl=91.0575, beta=0.0000\n",
      "Batch 180, loss=0.0442, recon=0.0442, kl=96.3969, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0704 (Recon: 0.0704, KL: 95.3159, Current Beta: 0.0000) | Avg Valid Loss: 0.0540 | Avg Valid recon Loss: 0.0540\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0542, recon=0.0542, kl=96.0080, beta=0.0000\n",
      "Batch 40, loss=0.2791, recon=0.2791, kl=94.1433, beta=0.0000\n",
      "Batch 60, loss=0.0483, recon=0.0483, kl=94.4712, beta=0.0000\n",
      "Batch 80, loss=0.0435, recon=0.0435, kl=91.2084, beta=0.0000\n",
      "Batch 100, loss=0.0410, recon=0.0410, kl=90.9991, beta=0.0000\n",
      "Batch 120, loss=0.3494, recon=0.3494, kl=95.5961, beta=0.0000\n",
      "Batch 140, loss=0.0389, recon=0.0389, kl=92.3307, beta=0.0000\n",
      "Batch 160, loss=0.0422, recon=0.0422, kl=94.2756, beta=0.0000\n",
      "Batch 180, loss=0.0468, recon=0.0468, kl=92.8983, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0592 (Recon: 0.0592, KL: 93.9588, Current Beta: 0.0000) | Avg Valid Loss: 0.0462 | Avg Valid recon Loss: 0.0462\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0340, recon=0.0340, kl=88.9575, beta=0.0000\n",
      "Batch 40, loss=0.0394, recon=0.0394, kl=87.6111, beta=0.0000\n",
      "Batch 60, loss=0.0375, recon=0.0375, kl=86.2703, beta=0.0000\n",
      "Batch 80, loss=0.0348, recon=0.0348, kl=84.7164, beta=0.0000\n",
      "Batch 100, loss=0.0468, recon=0.0468, kl=81.3733, beta=0.0000\n",
      "Batch 120, loss=0.0423, recon=0.0423, kl=82.3645, beta=0.0000\n",
      "Batch 140, loss=0.0284, recon=0.0284, kl=82.7346, beta=0.0000\n",
      "Batch 160, loss=0.0336, recon=0.0336, kl=83.6727, beta=0.0000\n",
      "Batch 180, loss=0.0808, recon=0.0808, kl=83.6149, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0519 (Recon: 0.0519, KL: 85.7404, Current Beta: 0.0000) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0773, recon=0.0773, kl=76.1669, beta=0.0000\n",
      "Batch 40, loss=0.0293, recon=0.0293, kl=74.2942, beta=0.0000\n",
      "Batch 60, loss=0.0595, recon=0.0595, kl=70.7436, beta=0.0000\n",
      "Batch 80, loss=0.0357, recon=0.0357, kl=72.1236, beta=0.0000\n",
      "Batch 100, loss=0.1980, recon=0.1980, kl=68.8223, beta=0.0000\n",
      "Batch 120, loss=0.0257, recon=0.0256, kl=65.6864, beta=0.0000\n",
      "Batch 140, loss=0.0323, recon=0.0323, kl=65.6750, beta=0.0000\n",
      "Batch 160, loss=0.0251, recon=0.0251, kl=63.6364, beta=0.0000\n",
      "Batch 180, loss=0.0281, recon=0.0281, kl=61.8529, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0471 (Recon: 0.0471, KL: 70.0557, Current Beta: 0.0000) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0241, recon=0.0241, kl=57.5431, beta=0.0000\n",
      "Batch 40, loss=0.0254, recon=0.0254, kl=50.4277, beta=0.0000\n",
      "Batch 60, loss=0.0232, recon=0.0232, kl=48.1602, beta=0.0000\n",
      "Batch 80, loss=0.0245, recon=0.0245, kl=47.9218, beta=0.0000\n",
      "Batch 100, loss=0.0397, recon=0.0397, kl=45.1841, beta=0.0000\n",
      "Batch 120, loss=0.0496, recon=0.0495, kl=45.8601, beta=0.0000\n",
      "Batch 140, loss=0.0290, recon=0.0290, kl=44.4661, beta=0.0000\n",
      "Batch 160, loss=0.0793, recon=0.0792, kl=44.8931, beta=0.0000\n",
      "Batch 180, loss=0.0285, recon=0.0285, kl=43.7086, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0431, KL: 48.4327, Current Beta: 0.0000) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0259, recon=0.0259, kl=38.8497, beta=0.0000\n",
      "Batch 40, loss=0.0446, recon=0.0445, kl=30.7143, beta=0.0000\n",
      "Batch 60, loss=0.0284, recon=0.0284, kl=27.4204, beta=0.0000\n",
      "Batch 80, loss=0.0244, recon=0.0244, kl=26.7508, beta=0.0000\n",
      "Batch 100, loss=0.0433, recon=0.0433, kl=25.4656, beta=0.0000\n",
      "Batch 120, loss=0.0274, recon=0.0273, kl=23.3130, beta=0.0000\n",
      "Batch 140, loss=0.0236, recon=0.0236, kl=26.7364, beta=0.0000\n",
      "Batch 160, loss=0.0239, recon=0.0239, kl=24.8920, beta=0.0000\n",
      "Batch 180, loss=0.0227, recon=0.0227, kl=25.4781, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0409, KL: 28.9737, Current Beta: 0.0000) | Avg Valid Loss: 0.0348 | Avg Valid recon Loss: 0.0348\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0243, recon=0.0242, kl=16.3484, beta=0.0000\n",
      "Batch 40, loss=0.0257, recon=0.0257, kl=12.7432, beta=0.0000\n",
      "Batch 60, loss=0.0339, recon=0.0339, kl=12.3124, beta=0.0000\n",
      "Batch 80, loss=0.0314, recon=0.0313, kl=11.7180, beta=0.0000\n",
      "Batch 100, loss=0.0286, recon=0.0285, kl=11.5328, beta=0.0000\n",
      "Batch 120, loss=0.0373, recon=0.0373, kl=11.4684, beta=0.0000\n",
      "Batch 140, loss=0.0260, recon=0.0260, kl=9.9018, beta=0.0000\n",
      "Batch 160, loss=0.0243, recon=0.0242, kl=10.3205, beta=0.0000\n",
      "Batch 180, loss=0.0305, recon=0.0304, kl=11.2612, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0387 (Recon: 0.0386, KL: 12.8231, Current Beta: 0.0000) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0345\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0275, recon=0.0274, kl=5.6264, beta=0.0000\n",
      "Batch 40, loss=0.0241, recon=0.0241, kl=5.1137, beta=0.0000\n",
      "Batch 60, loss=0.0292, recon=0.0292, kl=5.3061, beta=0.0000\n",
      "Batch 80, loss=0.0257, recon=0.0256, kl=4.3081, beta=0.0000\n",
      "Batch 100, loss=0.0191, recon=0.0190, kl=4.8755, beta=0.0000\n",
      "Batch 120, loss=0.0276, recon=0.0275, kl=3.9340, beta=0.0000\n",
      "Batch 140, loss=0.0291, recon=0.0291, kl=4.6038, beta=0.0000\n",
      "Batch 160, loss=0.1572, recon=0.1572, kl=3.6883, beta=0.0000\n",
      "Batch 180, loss=0.0256, recon=0.0255, kl=4.2400, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0372 (Recon: 0.0372, KL: 4.9099, Current Beta: 0.0000) | Avg Valid Loss: 0.0322 | Avg Valid recon Loss: 0.0322\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0204, recon=0.0203, kl=1.4841, beta=0.0000\n",
      "Batch 40, loss=0.0207, recon=0.0206, kl=2.3254, beta=0.0000\n",
      "Batch 60, loss=0.0257, recon=0.0256, kl=1.3999, beta=0.0000\n",
      "Batch 80, loss=0.0310, recon=0.0309, kl=1.8507, beta=0.0000\n",
      "Batch 100, loss=0.0206, recon=0.0206, kl=1.5151, beta=0.0000\n",
      "Batch 120, loss=0.0225, recon=0.0224, kl=1.3771, beta=0.0000\n",
      "Batch 140, loss=0.0230, recon=0.0229, kl=1.3452, beta=0.0000\n",
      "Batch 160, loss=0.0294, recon=0.0293, kl=1.6037, beta=0.0000\n",
      "Batch 180, loss=0.0316, recon=0.0316, kl=1.1300, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0359 (Recon: 0.0359, KL: 1.7344, Current Beta: 0.0000) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0306\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0179, recon=0.0179, kl=0.2898, beta=0.0001\n",
      "Batch 40, loss=0.0247, recon=0.0246, kl=0.3789, beta=0.0001\n",
      "Batch 60, loss=0.0345, recon=0.0345, kl=0.4582, beta=0.0001\n",
      "Batch 80, loss=0.0242, recon=0.0241, kl=0.4493, beta=0.0001\n",
      "Batch 100, loss=0.0292, recon=0.0292, kl=0.2102, beta=0.0001\n",
      "Batch 120, loss=0.0255, recon=0.0255, kl=0.4503, beta=0.0001\n",
      "Batch 140, loss=0.0261, recon=0.0260, kl=0.2195, beta=0.0001\n",
      "Batch 160, loss=0.0267, recon=0.0266, kl=0.2612, beta=0.0001\n",
      "Batch 180, loss=0.0353, recon=0.0352, kl=0.2924, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0348 (Recon: 0.0347, KL: 0.3961, Current Beta: 0.0001) | Avg Valid Loss: 0.0299 | Avg Valid recon Loss: 0.0299\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0254, recon=0.0254, kl=0.0260, beta=0.0002\n",
      "Batch 40, loss=0.4500, recon=0.4500, kl=0.0599, beta=0.0002\n",
      "Batch 60, loss=0.0179, recon=0.0179, kl=0.0225, beta=0.0002\n",
      "Batch 80, loss=0.0298, recon=0.0298, kl=0.0792, beta=0.0002\n",
      "Batch 100, loss=0.1404, recon=0.1404, kl=0.0320, beta=0.0002\n",
      "Batch 120, loss=0.0253, recon=0.0253, kl=0.0442, beta=0.0002\n",
      "Batch 140, loss=0.0311, recon=0.0311, kl=0.0309, beta=0.0002\n",
      "Batch 160, loss=0.0258, recon=0.0258, kl=0.0157, beta=0.0002\n",
      "Batch 180, loss=0.0504, recon=0.0504, kl=0.0462, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0339 (Recon: 0.0339, KL: 0.0602, Current Beta: 0.0002) | Avg Valid Loss: 0.0295 | Avg Valid recon Loss: 0.0295\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0207, recon=0.0207, kl=0.0090, beta=0.0004\n",
      "Batch 40, loss=0.0217, recon=0.0217, kl=0.0045, beta=0.0004\n",
      "Batch 60, loss=0.0202, recon=0.0202, kl=0.0066, beta=0.0004\n",
      "Batch 80, loss=0.0226, recon=0.0226, kl=0.0032, beta=0.0004\n",
      "Batch 100, loss=0.0792, recon=0.0792, kl=0.0062, beta=0.0004\n",
      "Batch 120, loss=0.0672, recon=0.0672, kl=0.0059, beta=0.0004\n",
      "Batch 140, loss=0.0215, recon=0.0215, kl=0.0103, beta=0.0004\n",
      "Batch 160, loss=0.0183, recon=0.0183, kl=0.0022, beta=0.0004\n",
      "Batch 180, loss=0.0234, recon=0.0234, kl=0.0026, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0332 (Recon: 0.0332, KL: 0.0076, Current Beta: 0.0004) | Avg Valid Loss: 0.0285 | Avg Valid recon Loss: 0.0285\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0260, recon=0.0260, kl=0.0027, beta=0.0006\n",
      "Batch 40, loss=0.0135, recon=0.0135, kl=0.0005, beta=0.0006\n",
      "Batch 60, loss=0.0203, recon=0.0203, kl=0.0072, beta=0.0006\n",
      "Batch 80, loss=0.0497, recon=0.0497, kl=0.0023, beta=0.0006\n",
      "Batch 100, loss=0.0225, recon=0.0225, kl=0.0016, beta=0.0006\n",
      "Batch 120, loss=0.0325, recon=0.0325, kl=0.0018, beta=0.0006\n",
      "Batch 140, loss=0.0148, recon=0.0148, kl=0.0007, beta=0.0006\n",
      "Batch 160, loss=0.0190, recon=0.0190, kl=0.0011, beta=0.0006\n",
      "Batch 180, loss=0.0228, recon=0.0228, kl=0.0009, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0326 (Recon: 0.0326, KL: 0.0022, Current Beta: 0.0006) | Avg Valid Loss: 0.0280 | Avg Valid recon Loss: 0.0279\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0448, recon=0.0448, kl=0.0005, beta=0.0010\n",
      "Batch 40, loss=0.0243, recon=0.0243, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0538, recon=0.0538, kl=0.0011, beta=0.0010\n",
      "Batch 80, loss=0.0318, recon=0.0318, kl=0.0003, beta=0.0010\n",
      "Batch 100, loss=0.0217, recon=0.0217, kl=0.0006, beta=0.0010\n",
      "Batch 120, loss=0.0411, recon=0.0411, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0235, recon=0.0235, kl=0.0009, beta=0.0010\n",
      "Batch 160, loss=0.0241, recon=0.0241, kl=0.0005, beta=0.0010\n",
      "Batch 180, loss=0.0307, recon=0.0307, kl=0.0019, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0317 (Recon: 0.0317, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0275 | Avg Valid recon Loss: 0.0275\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0631, recon=0.0631, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0183, recon=0.0183, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0235, recon=0.0235, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.0209, recon=0.0209, kl=0.0001, beta=0.0010\n",
      "Batch 100, loss=0.0488, recon=0.0488, kl=0.0002, beta=0.0010\n",
      "Batch 120, loss=0.0205, recon=0.0205, kl=0.0001, beta=0.0010\n",
      "Batch 140, loss=0.0385, recon=0.0385, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0263, recon=0.0263, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0155, recon=0.0155, kl=0.0016, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0312 (Recon: 0.0312, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0274 | Avg Valid recon Loss: 0.0274\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0221, recon=0.0221, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0180, recon=0.0180, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0183, recon=0.0183, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0254, recon=0.0254, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0296, recon=0.0296, kl=0.0010, beta=0.0010\n",
      "Batch 120, loss=0.0154, recon=0.0154, kl=0.0002, beta=0.0010\n",
      "Batch 140, loss=0.0181, recon=0.0181, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0368, recon=0.0368, kl=0.0002, beta=0.0010\n",
      "Batch 180, loss=0.0177, recon=0.0177, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0311 (Recon: 0.0311, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0271 | Avg Valid recon Loss: 0.0271\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0221, recon=0.0221, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0240, recon=0.0240, kl=0.0010, beta=0.0010\n",
      "Batch 60, loss=0.0292, recon=0.0292, kl=0.0008, beta=0.0010\n",
      "Batch 80, loss=0.0248, recon=0.0248, kl=0.0003, beta=0.0010\n",
      "Batch 100, loss=0.0606, recon=0.0606, kl=0.0002, beta=0.0010\n",
      "Batch 120, loss=0.0346, recon=0.0346, kl=0.0014, beta=0.0010\n",
      "Batch 140, loss=0.0227, recon=0.0227, kl=0.0006, beta=0.0010\n",
      "Batch 160, loss=0.0301, recon=0.0301, kl=0.0003, beta=0.0010\n",
      "Batch 180, loss=0.0193, recon=0.0193, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0305 (Recon: 0.0305, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0267 | Avg Valid recon Loss: 0.0267\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0248, recon=0.0248, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0408, recon=0.0408, kl=0.0007, beta=0.0010\n",
      "Batch 60, loss=0.0297, recon=0.0297, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0413, recon=0.0413, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0307, recon=0.0307, kl=0.0001, beta=0.0010\n",
      "Batch 120, loss=0.0179, recon=0.0179, kl=0.0001, beta=0.0010\n",
      "Batch 140, loss=0.0186, recon=0.0186, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0283, recon=0.0283, kl=0.0019, beta=0.0010\n",
      "Batch 180, loss=0.0275, recon=0.0275, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0300 (Recon: 0.0300, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0260 | Avg Valid recon Loss: 0.0260\n",
      " New best VRAE model found with validation loss: 0.0260\n",
      "   Model saved to ./ecg_model_logs\\best_vrae_model.pth\n",
      "\n",
      "[VRAE Run 70/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1200, recon=0.1200, kl=28.0929, beta=0.0000\n",
      "Batch 40, loss=0.0811, recon=0.0811, kl=44.5772, beta=0.0000\n",
      "Batch 60, loss=0.5599, recon=0.5599, kl=47.8651, beta=0.0000\n",
      "Batch 80, loss=0.0760, recon=0.0760, kl=61.1085, beta=0.0000\n",
      "Batch 100, loss=0.0875, recon=0.0875, kl=52.6318, beta=0.0000\n",
      "Batch 120, loss=0.0595, recon=0.0595, kl=52.1431, beta=0.0000\n",
      "Batch 140, loss=0.0533, recon=0.0533, kl=49.2415, beta=0.0000\n",
      "Batch 160, loss=0.0588, recon=0.0588, kl=50.1840, beta=0.0000\n",
      "Batch 180, loss=0.1410, recon=0.1410, kl=56.6499, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1139 (Recon: 0.1139, KL: 46.2227, Current Beta: 0.0000) | Avg Valid Loss: 0.0935 | Avg Valid recon Loss: 0.0935\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2328, recon=0.2328, kl=37.8699, beta=0.0000\n",
      "Batch 40, loss=0.0437, recon=0.0437, kl=74.1822, beta=0.0000\n",
      "Batch 60, loss=0.0427, recon=0.0427, kl=66.2024, beta=0.0000\n",
      "Batch 80, loss=0.0326, recon=0.0326, kl=68.4631, beta=0.0000\n",
      "Batch 100, loss=0.0447, recon=0.0447, kl=82.5606, beta=0.0000\n",
      "Batch 120, loss=0.0340, recon=0.0340, kl=62.9077, beta=0.0000\n",
      "Batch 140, loss=0.0272, recon=0.0272, kl=66.3633, beta=0.0000\n",
      "Batch 160, loss=0.0273, recon=0.0273, kl=72.8563, beta=0.0000\n",
      "Batch 180, loss=0.0640, recon=0.0640, kl=75.8061, beta=0.0000\n",
      "  â†’ Avg Train Loss: 223.5498 (Recon: 223.5498, KL: 7411.0304, Current Beta: 0.0000) | Avg Valid Loss: 0.0643 | Avg Valid recon Loss: 0.0643\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0425, recon=0.0425, kl=80.3398, beta=0.0000\n",
      "Batch 40, loss=0.0277, recon=0.0277, kl=80.7056, beta=0.0000\n",
      "Batch 60, loss=0.0642, recon=0.0642, kl=75.3870, beta=0.0000\n",
      "Batch 80, loss=0.1489, recon=0.1489, kl=66.1554, beta=0.0000\n",
      "Batch 100, loss=0.0450, recon=0.0450, kl=70.2595, beta=0.0000\n",
      "Batch 120, loss=0.0322, recon=0.0322, kl=57.8046, beta=0.0000\n",
      "Batch 140, loss=0.0335, recon=0.0335, kl=64.1891, beta=0.0000\n",
      "Batch 160, loss=0.0326, recon=0.0326, kl=70.6015, beta=0.0000\n",
      "Batch 180, loss=0.0355, recon=0.0355, kl=77.4923, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0647 (Recon: 0.0647, KL: 71.9959, Current Beta: 0.0000) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0321, recon=0.0321, kl=78.8778, beta=0.0000\n",
      "Batch 40, loss=0.0300, recon=0.0300, kl=81.7673, beta=0.0000\n",
      "Batch 60, loss=0.0200, recon=0.0200, kl=83.3844, beta=0.0000\n",
      "Batch 80, loss=0.0343, recon=0.0343, kl=84.6896, beta=0.0000\n",
      "Batch 100, loss=0.0718, recon=0.0718, kl=83.6183, beta=0.0000\n",
      "Batch 120, loss=0.0489, recon=0.0489, kl=80.0274, beta=0.0000\n",
      "Batch 140, loss=0.0507, recon=0.0507, kl=78.1957, beta=0.0000\n",
      "Batch 160, loss=0.0365, recon=0.0365, kl=77.1235, beta=0.0000\n",
      "Batch 180, loss=0.0260, recon=0.0260, kl=77.0166, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0480, KL: 80.5489, Current Beta: 0.0000) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0169, recon=0.0169, kl=78.8329, beta=0.0000\n",
      "Batch 40, loss=0.0359, recon=0.0359, kl=84.7452, beta=0.0000\n",
      "Batch 60, loss=0.0506, recon=0.0506, kl=75.3362, beta=0.0000\n",
      "Batch 80, loss=0.0579, recon=0.0579, kl=68.0905, beta=0.0000\n",
      "Batch 100, loss=0.0294, recon=0.0294, kl=76.2504, beta=0.0000\n",
      "Batch 120, loss=0.0238, recon=0.0238, kl=77.6189, beta=0.0000\n",
      "Batch 140, loss=0.0405, recon=0.0405, kl=87.3978, beta=0.0000\n",
      "Batch 160, loss=0.0205, recon=0.0205, kl=82.0974, beta=0.0000\n",
      "Batch 180, loss=0.0372, recon=0.0372, kl=76.9322, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0411 (Recon: 0.0411, KL: 78.8629, Current Beta: 0.0000) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0952, recon=0.0952, kl=75.5290, beta=0.0000\n",
      "Batch 40, loss=0.0355, recon=0.0355, kl=52.4818, beta=0.0000\n",
      "Batch 60, loss=0.0304, recon=0.0304, kl=58.9549, beta=0.0000\n",
      "Batch 80, loss=0.0480, recon=0.0480, kl=63.0432, beta=0.0000\n",
      "Batch 100, loss=0.0267, recon=0.0267, kl=64.8910, beta=0.0000\n",
      "Batch 120, loss=0.0444, recon=0.0443, kl=68.9636, beta=0.0000\n",
      "Batch 140, loss=0.0584, recon=0.0584, kl=72.6841, beta=0.0000\n",
      "Batch 160, loss=0.0362, recon=0.0362, kl=66.5729, beta=0.0000\n",
      "Batch 180, loss=0.0308, recon=0.0308, kl=69.3872, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0524, KL: 65.3222, Current Beta: 0.0000) | Avg Valid Loss: 0.0367 | Avg Valid recon Loss: 0.0367\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0272, recon=0.0271, kl=70.9468, beta=0.0000\n",
      "Batch 40, loss=0.0256, recon=0.0256, kl=70.8751, beta=0.0000\n",
      "Batch 60, loss=0.0261, recon=0.0261, kl=71.3048, beta=0.0000\n",
      "Batch 80, loss=0.0453, recon=0.0452, kl=71.4372, beta=0.0000\n",
      "Batch 100, loss=0.0289, recon=0.0288, kl=71.9359, beta=0.0000\n",
      "Batch 120, loss=0.0197, recon=0.0197, kl=72.0549, beta=0.0000\n",
      "Batch 140, loss=0.0259, recon=0.0259, kl=72.4004, beta=0.0000\n",
      "Batch 160, loss=0.0279, recon=0.0278, kl=73.0369, beta=0.0000\n",
      "Batch 180, loss=0.0819, recon=0.0819, kl=73.5046, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0408, KL: 71.7595, Current Beta: 0.0000) | Avg Valid Loss: 0.0523 | Avg Valid recon Loss: 0.0523\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0318, recon=0.0317, kl=73.6914, beta=0.0000\n",
      "Batch 40, loss=0.0323, recon=0.0322, kl=72.8331, beta=0.0000\n",
      "Batch 60, loss=0.0404, recon=0.0403, kl=71.2963, beta=0.0000\n",
      "Batch 80, loss=0.0373, recon=0.0372, kl=70.5540, beta=0.0000\n",
      "Batch 100, loss=0.0278, recon=0.0277, kl=70.3844, beta=0.0000\n",
      "Batch 120, loss=0.0300, recon=0.0299, kl=70.8025, beta=0.0000\n",
      "Batch 140, loss=0.0246, recon=0.0245, kl=70.5987, beta=0.0000\n",
      "Batch 160, loss=0.0254, recon=0.0253, kl=69.6130, beta=0.0000\n",
      "Batch 180, loss=0.0421, recon=0.0420, kl=69.3549, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0419, KL: 71.2782, Current Beta: 0.0000) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0471\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0348, recon=0.0345, kl=67.4241, beta=0.0000\n",
      "Batch 40, loss=0.0340, recon=0.0338, kl=55.5448, beta=0.0000\n",
      "Batch 60, loss=0.0457, recon=0.0455, kl=52.0309, beta=0.0000\n",
      "Batch 80, loss=0.0476, recon=0.0473, kl=58.7301, beta=0.0000\n",
      "Batch 100, loss=0.0455, recon=0.0452, kl=63.0918, beta=0.0000\n",
      "Batch 120, loss=0.0287, recon=0.0285, kl=55.4794, beta=0.0000\n",
      "Batch 140, loss=0.0202, recon=0.0200, kl=52.6580, beta=0.0000\n",
      "Batch 160, loss=0.0282, recon=0.0280, kl=51.3715, beta=0.0000\n",
      "Batch 180, loss=0.0344, recon=0.0341, kl=55.8769, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0464, KL: 58.9187, Current Beta: 0.0000) | Avg Valid Loss: 0.0328 | Avg Valid recon Loss: 0.0326\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0227, recon=0.0222, kl=41.1050, beta=0.0000\n",
      "Batch 40, loss=0.0198, recon=0.0194, kl=36.7558, beta=0.0000\n",
      "Batch 60, loss=0.0184, recon=0.0180, kl=38.1035, beta=0.0000\n",
      "Batch 80, loss=0.0289, recon=0.0285, kl=39.0592, beta=0.0000\n",
      "Batch 100, loss=0.0244, recon=0.0240, kl=33.6962, beta=0.0000\n",
      "Batch 120, loss=0.0237, recon=0.0233, kl=38.0012, beta=0.0000\n",
      "Batch 140, loss=0.0935, recon=0.0931, kl=34.0759, beta=0.0000\n",
      "Batch 160, loss=0.0464, recon=0.0459, kl=45.4079, beta=0.0000\n",
      "Batch 180, loss=0.0457, recon=0.0452, kl=46.8068, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0430, KL: 38.9100, Current Beta: 0.0000) | Avg Valid Loss: 0.0567 | Avg Valid recon Loss: 0.0562\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0707, recon=0.0696, kl=37.9416, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 12/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 13/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0002) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 14/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0004) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0006) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 71/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3009, recon=0.3009, kl=8.3670, beta=0.0000\n",
      "Batch 40, loss=0.1882, recon=0.1882, kl=67.2595, beta=0.0000\n",
      "Batch 60, loss=0.1711, recon=0.1711, kl=97.0451, beta=0.0000\n",
      "Batch 80, loss=0.1321, recon=0.1321, kl=111.2961, beta=0.0000\n",
      "Batch 100, loss=0.1178, recon=0.1178, kl=127.4591, beta=0.0000\n",
      "Batch 120, loss=0.1176, recon=0.1176, kl=139.0751, beta=0.0000\n",
      "Batch 140, loss=0.0778, recon=0.0778, kl=137.7700, beta=0.0000\n",
      "Batch 160, loss=0.0935, recon=0.0935, kl=145.3949, beta=0.0000\n",
      "Batch 180, loss=0.0712, recon=0.0712, kl=147.2357, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2054 (Recon: 0.2054, KL: 101.5359, Current Beta: 0.0000) | Avg Valid Loss: 0.0846 | Avg Valid recon Loss: 0.0846\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1194, recon=0.1194, kl=152.2656, beta=0.0000\n",
      "Batch 40, loss=0.0680, recon=0.0680, kl=156.5185, beta=0.0000\n",
      "Batch 60, loss=0.0754, recon=0.0754, kl=166.4640, beta=0.0000\n",
      "Batch 80, loss=0.0741, recon=0.0741, kl=175.4030, beta=0.0000\n",
      "Batch 100, loss=0.0483, recon=0.0483, kl=173.2324, beta=0.0000\n",
      "Batch 120, loss=0.0573, recon=0.0573, kl=171.9273, beta=0.0000\n",
      "Batch 140, loss=0.0720, recon=0.0720, kl=174.8489, beta=0.0000\n",
      "Batch 160, loss=0.0606, recon=0.0606, kl=177.1990, beta=0.0000\n",
      "Batch 180, loss=0.0712, recon=0.0712, kl=175.7560, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0915 (Recon: 0.0915, KL: 167.6428, Current Beta: 0.0000) | Avg Valid Loss: 0.0649 | Avg Valid recon Loss: 0.0649\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0647, recon=0.0647, kl=178.7151, beta=0.0000\n",
      "Batch 40, loss=0.0620, recon=0.0620, kl=175.8567, beta=0.0000\n",
      "Batch 60, loss=0.0690, recon=0.0690, kl=177.7872, beta=0.0000\n",
      "Batch 80, loss=0.0509, recon=0.0509, kl=175.1071, beta=0.0000\n",
      "Batch 100, loss=0.0660, recon=0.0660, kl=174.8375, beta=0.0000\n",
      "Batch 120, loss=0.0341, recon=0.0341, kl=177.1672, beta=0.0000\n",
      "Batch 140, loss=0.0397, recon=0.0397, kl=176.9224, beta=0.0000\n",
      "Batch 160, loss=0.0596, recon=0.0596, kl=175.1807, beta=0.0000\n",
      "Batch 180, loss=0.0740, recon=0.0740, kl=184.2815, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0699 (Recon: 0.0699, KL: 177.0247, Current Beta: 0.0000) | Avg Valid Loss: 0.0533 | Avg Valid recon Loss: 0.0533\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0472, recon=0.0472, kl=179.4706, beta=0.0000\n",
      "Batch 40, loss=0.0333, recon=0.0333, kl=176.2926, beta=0.0000\n",
      "Batch 60, loss=0.0370, recon=0.0370, kl=178.2873, beta=0.0000\n",
      "Batch 80, loss=0.0558, recon=0.0558, kl=176.9118, beta=0.0000\n",
      "Batch 100, loss=0.1148, recon=0.1148, kl=174.0770, beta=0.0000\n",
      "Batch 120, loss=0.0345, recon=0.0345, kl=171.3553, beta=0.0000\n",
      "Batch 140, loss=0.1766, recon=0.1766, kl=170.4450, beta=0.0000\n",
      "Batch 160, loss=0.0276, recon=0.0276, kl=165.0227, beta=0.0000\n",
      "Batch 180, loss=0.1150, recon=0.1150, kl=161.2134, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0595 (Recon: 0.0595, KL: 173.5817, Current Beta: 0.0000) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0370, recon=0.0370, kl=152.3634, beta=0.0000\n",
      "Batch 40, loss=0.0384, recon=0.0384, kl=157.4019, beta=0.0000\n",
      "Batch 60, loss=0.0321, recon=0.0321, kl=149.5619, beta=0.0000\n",
      "Batch 80, loss=0.0755, recon=0.0755, kl=142.3652, beta=0.0000\n",
      "Batch 100, loss=0.0364, recon=0.0364, kl=139.9893, beta=0.0000\n",
      "Batch 120, loss=0.0333, recon=0.0333, kl=146.1270, beta=0.0000\n",
      "Batch 140, loss=0.8247, recon=0.8247, kl=140.2784, beta=0.0000\n",
      "Batch 160, loss=0.0356, recon=0.0356, kl=136.6617, beta=0.0000\n",
      "Batch 180, loss=0.0370, recon=0.0370, kl=130.0353, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0522, KL: 145.1762, Current Beta: 0.0000) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0368, recon=0.0368, kl=127.2059, beta=0.0000\n",
      "Batch 40, loss=0.0616, recon=0.0616, kl=117.7001, beta=0.0000\n",
      "Batch 60, loss=0.0268, recon=0.0268, kl=107.0119, beta=0.0000\n",
      "Batch 80, loss=0.0395, recon=0.0395, kl=103.1898, beta=0.0000\n",
      "Batch 100, loss=0.0620, recon=0.0620, kl=105.8197, beta=0.0000\n",
      "Batch 120, loss=0.0361, recon=0.0361, kl=110.2804, beta=0.0000\n",
      "Batch 140, loss=0.0353, recon=0.0353, kl=105.5683, beta=0.0000\n",
      "Batch 160, loss=0.0221, recon=0.0221, kl=102.3094, beta=0.0000\n",
      "Batch 180, loss=0.0332, recon=0.0332, kl=107.8207, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0466, KL: 111.2294, Current Beta: 0.0000) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0304, recon=0.0304, kl=93.8406, beta=0.0000\n",
      "Batch 40, loss=0.0304, recon=0.0303, kl=77.1298, beta=0.0000\n",
      "Batch 60, loss=0.0312, recon=0.0312, kl=70.4222, beta=0.0000\n",
      "Batch 80, loss=0.0286, recon=0.0286, kl=71.5758, beta=0.0000\n",
      "Batch 100, loss=0.1798, recon=0.1797, kl=69.9018, beta=0.0000\n",
      "Batch 120, loss=0.0392, recon=0.0392, kl=70.3197, beta=0.0000\n",
      "Batch 140, loss=0.0286, recon=0.0285, kl=74.2893, beta=0.0000\n",
      "Batch 160, loss=0.0322, recon=0.0322, kl=68.4841, beta=0.0000\n",
      "Batch 180, loss=0.0349, recon=0.0349, kl=68.3846, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0430, KL: 75.9189, Current Beta: 0.0000) | Avg Valid Loss: 0.0360 | Avg Valid recon Loss: 0.0360\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0419, recon=0.0418, kl=48.2623, beta=0.0000\n",
      "Batch 40, loss=0.0238, recon=0.0237, kl=36.5648, beta=0.0000\n",
      "Batch 60, loss=0.1457, recon=0.1456, kl=35.6531, beta=0.0000\n",
      "Batch 80, loss=0.0420, recon=0.0420, kl=37.6684, beta=0.0000\n",
      "Batch 100, loss=0.0316, recon=0.0315, kl=32.4665, beta=0.0000\n",
      "Batch 120, loss=0.0246, recon=0.0245, kl=35.2830, beta=0.0000\n",
      "Batch 140, loss=0.1028, recon=0.1028, kl=33.2312, beta=0.0000\n",
      "Batch 160, loss=0.0270, recon=0.0270, kl=37.3376, beta=0.0000\n",
      "Batch 180, loss=0.0351, recon=0.0350, kl=37.0288, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0404, KL: 38.3405, Current Beta: 0.0000) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0345\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0367, recon=0.0366, kl=19.8271, beta=0.0000\n",
      "Batch 40, loss=0.0291, recon=0.0291, kl=15.6622, beta=0.0000\n",
      "Batch 60, loss=0.0307, recon=0.0307, kl=15.2869, beta=0.0000\n",
      "Batch 80, loss=0.0248, recon=0.0248, kl=15.4808, beta=0.0000\n",
      "Batch 100, loss=0.0488, recon=0.0488, kl=17.4363, beta=0.0000\n",
      "Batch 120, loss=0.0290, recon=0.0290, kl=14.1304, beta=0.0000\n",
      "Batch 140, loss=0.0319, recon=0.0318, kl=14.4258, beta=0.0000\n",
      "Batch 160, loss=0.0218, recon=0.0217, kl=14.6615, beta=0.0000\n",
      "Batch 180, loss=0.1556, recon=0.1556, kl=12.2108, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0383 (Recon: 0.0382, KL: 16.5955, Current Beta: 0.0000) | Avg Valid Loss: 0.0328 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0467, recon=0.0466, kl=5.7317, beta=0.0000\n",
      "Batch 40, loss=0.0392, recon=0.0391, kl=6.2451, beta=0.0000\n",
      "Batch 60, loss=0.0330, recon=0.0329, kl=7.3696, beta=0.0000\n",
      "Batch 80, loss=0.0230, recon=0.0230, kl=5.6774, beta=0.0000\n",
      "Batch 100, loss=0.0288, recon=0.0288, kl=5.5403, beta=0.0000\n",
      "Batch 120, loss=0.0203, recon=0.0202, kl=5.0855, beta=0.0000\n",
      "Batch 140, loss=0.0304, recon=0.0303, kl=5.2284, beta=0.0000\n",
      "Batch 160, loss=0.0244, recon=0.0244, kl=5.7656, beta=0.0000\n",
      "Batch 180, loss=0.0237, recon=0.0236, kl=5.0650, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0371 (Recon: 0.0370, KL: 6.2533, Current Beta: 0.0000) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0318\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0324, recon=0.0323, kl=2.1461, beta=0.0000\n",
      "Batch 40, loss=0.0182, recon=0.0181, kl=2.2861, beta=0.0000\n",
      "Batch 60, loss=0.0336, recon=0.0335, kl=1.9968, beta=0.0000\n",
      "Batch 80, loss=0.0264, recon=0.0263, kl=2.9234, beta=0.0000\n",
      "Batch 100, loss=0.0465, recon=0.0464, kl=1.4210, beta=0.0000\n",
      "Batch 120, loss=0.0501, recon=0.0500, kl=2.1126, beta=0.0000\n",
      "Batch 140, loss=0.0299, recon=0.0298, kl=3.6722, beta=0.0000\n",
      "Batch 160, loss=0.0549, recon=0.0549, kl=2.3916, beta=0.0000\n",
      "Batch 180, loss=0.0252, recon=0.0252, kl=1.6828, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0356 (Recon: 0.0355, KL: 2.3405, Current Beta: 0.0000) | Avg Valid Loss: 0.0315 | Avg Valid recon Loss: 0.0314\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0233, recon=0.0232, kl=0.6706, beta=0.0001\n",
      "Batch 40, loss=0.0264, recon=0.0264, kl=0.9638, beta=0.0001\n",
      "Batch 60, loss=0.0242, recon=0.0242, kl=0.5726, beta=0.0001\n",
      "Batch 80, loss=0.0343, recon=0.0342, kl=0.6316, beta=0.0001\n",
      "Batch 100, loss=0.0933, recon=0.0933, kl=0.5252, beta=0.0001\n",
      "Batch 120, loss=0.0182, recon=0.0181, kl=0.8697, beta=0.0001\n",
      "Batch 140, loss=0.0335, recon=0.0335, kl=0.5876, beta=0.0001\n",
      "Batch 160, loss=0.0161, recon=0.0161, kl=0.4367, beta=0.0001\n",
      "Batch 180, loss=0.4439, recon=0.4439, kl=0.4101, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0345 (Recon: 0.0344, KL: 0.6900, Current Beta: 0.0001) | Avg Valid Loss: 0.0314 | Avg Valid recon Loss: 0.0314\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0279, recon=0.0279, kl=0.2769, beta=0.0002\n",
      "Batch 40, loss=0.0247, recon=0.0247, kl=0.2367, beta=0.0002\n",
      "Batch 60, loss=0.0458, recon=0.0458, kl=0.0618, beta=0.0002\n",
      "Batch 80, loss=0.0296, recon=0.0296, kl=0.1506, beta=0.0002\n",
      "Batch 100, loss=0.0553, recon=0.0553, kl=0.0988, beta=0.0002\n",
      "Batch 120, loss=0.0419, recon=0.0419, kl=0.0703, beta=0.0002\n",
      "Batch 140, loss=0.0180, recon=0.0180, kl=0.0876, beta=0.0002\n",
      "Batch 160, loss=0.0328, recon=0.0327, kl=0.1912, beta=0.0002\n",
      "Batch 180, loss=0.0289, recon=0.0289, kl=0.0850, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0338 (Recon: 0.0338, KL: 0.1497, Current Beta: 0.0002) | Avg Valid Loss: 0.0302 | Avg Valid recon Loss: 0.0301\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1458, recon=0.1458, kl=0.0188, beta=0.0004\n",
      "Batch 40, loss=0.0219, recon=0.0219, kl=0.0189, beta=0.0004\n",
      "Batch 60, loss=0.0280, recon=0.0280, kl=0.0123, beta=0.0004\n",
      "Batch 80, loss=0.0244, recon=0.0244, kl=0.0228, beta=0.0004\n",
      "Batch 100, loss=0.0315, recon=0.0315, kl=0.0186, beta=0.0004\n",
      "Batch 120, loss=0.0250, recon=0.0250, kl=0.0125, beta=0.0004\n",
      "Batch 140, loss=0.0174, recon=0.0174, kl=0.0100, beta=0.0004\n",
      "Batch 160, loss=0.0251, recon=0.0251, kl=0.0124, beta=0.0004\n",
      "Batch 180, loss=0.0481, recon=0.0481, kl=0.0076, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0338 (Recon: 0.0338, KL: 0.0202, Current Beta: 0.0004) | Avg Valid Loss: 0.0310 | Avg Valid recon Loss: 0.0310\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0276, recon=0.0276, kl=0.0016, beta=0.0006\n",
      "Batch 40, loss=0.0202, recon=0.0202, kl=0.0075, beta=0.0006\n",
      "Batch 60, loss=0.0215, recon=0.0215, kl=0.0022, beta=0.0006\n",
      "Batch 80, loss=0.0184, recon=0.0184, kl=0.0019, beta=0.0006\n",
      "Batch 100, loss=0.0255, recon=0.0255, kl=0.0043, beta=0.0006\n",
      "Batch 120, loss=0.0386, recon=0.0386, kl=0.0055, beta=0.0006\n",
      "Batch 140, loss=0.0247, recon=0.0247, kl=0.0020, beta=0.0006\n",
      "Batch 160, loss=0.0180, recon=0.0180, kl=0.0017, beta=0.0006\n",
      "Batch 180, loss=0.0279, recon=0.0278, kl=0.0067, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0326 (Recon: 0.0326, KL: 0.0041, Current Beta: 0.0006) | Avg Valid Loss: 0.0282 | Avg Valid recon Loss: 0.0282\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0250, recon=0.0250, kl=0.0027, beta=0.0010\n",
      "Batch 40, loss=0.0383, recon=0.0383, kl=0.0034, beta=0.0010\n",
      "Batch 60, loss=0.0195, recon=0.0195, kl=0.0019, beta=0.0010\n",
      "Batch 80, loss=0.0404, recon=0.0404, kl=0.0014, beta=0.0010\n",
      "Batch 100, loss=0.0218, recon=0.0218, kl=0.0007, beta=0.0010\n",
      "Batch 120, loss=0.0315, recon=0.0315, kl=0.0012, beta=0.0010\n",
      "Batch 140, loss=0.0208, recon=0.0208, kl=0.0005, beta=0.0010\n",
      "Batch 160, loss=0.0238, recon=0.0238, kl=0.0005, beta=0.0010\n",
      "Batch 180, loss=0.0238, recon=0.0238, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0316 (Recon: 0.0316, KL: 0.0019, Current Beta: 0.0010) | Avg Valid Loss: 0.0270 | Avg Valid recon Loss: 0.0270\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0158, recon=0.0158, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0247, recon=0.0247, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0276, recon=0.0276, kl=0.0008, beta=0.0010\n",
      "Batch 80, loss=0.0282, recon=0.0282, kl=0.0008, beta=0.0010\n",
      "Batch 100, loss=0.0238, recon=0.0238, kl=0.0030, beta=0.0010\n",
      "Batch 120, loss=0.0211, recon=0.0211, kl=0.0007, beta=0.0010\n",
      "Batch 140, loss=0.1236, recon=0.1236, kl=0.0004, beta=0.0010\n",
      "Batch 160, loss=0.0209, recon=0.0209, kl=0.0006, beta=0.0010\n",
      "Batch 180, loss=0.0230, recon=0.0230, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0308 (Recon: 0.0308, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0263 | Avg Valid recon Loss: 0.0263\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0614, recon=0.0614, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.0233, recon=0.0233, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0165, recon=0.0165, kl=0.0006, beta=0.0010\n",
      "Batch 80, loss=0.0276, recon=0.0276, kl=0.0005, beta=0.0010\n",
      "Batch 100, loss=0.0239, recon=0.0239, kl=0.0028, beta=0.0010\n",
      "Batch 120, loss=0.0295, recon=0.0295, kl=0.0009, beta=0.0010\n",
      "Batch 140, loss=0.0187, recon=0.0187, kl=0.0006, beta=0.0010\n",
      "Batch 160, loss=0.0193, recon=0.0193, kl=0.0011, beta=0.0010\n",
      "Batch 180, loss=0.0301, recon=0.0301, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0304 (Recon: 0.0304, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0258 | Avg Valid recon Loss: 0.0258\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0187, recon=0.0187, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0323, recon=0.0323, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0241, recon=0.0241, kl=0.0006, beta=0.0010\n",
      "Batch 80, loss=0.0379, recon=0.0379, kl=0.0018, beta=0.0010\n",
      "Batch 100, loss=0.0335, recon=0.0335, kl=0.0004, beta=0.0010\n",
      "Batch 120, loss=0.0329, recon=0.0329, kl=0.0004, beta=0.0010\n",
      "Batch 140, loss=0.0191, recon=0.0191, kl=0.0006, beta=0.0010\n",
      "Batch 160, loss=0.0199, recon=0.0199, kl=0.0004, beta=0.0010\n",
      "Batch 180, loss=0.0257, recon=0.0257, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0298 (Recon: 0.0298, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0266 | Avg Valid recon Loss: 0.0266\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0182, recon=0.0182, kl=0.0008, beta=0.0010\n",
      "Batch 40, loss=0.0269, recon=0.0269, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0198, recon=0.0198, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0300, recon=0.0300, kl=0.0002, beta=0.0010\n",
      "Batch 100, loss=0.0508, recon=0.0508, kl=0.0039, beta=0.0010\n",
      "Batch 120, loss=0.0225, recon=0.0225, kl=0.0009, beta=0.0010\n",
      "Batch 140, loss=0.0234, recon=0.0234, kl=0.0003, beta=0.0010\n",
      "Batch 160, loss=0.0308, recon=0.0308, kl=0.0005, beta=0.0010\n",
      "Batch 180, loss=0.0130, recon=0.0130, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0296 (Recon: 0.0296, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0257 | Avg Valid recon Loss: 0.0257\n",
      " New best VRAE model found with validation loss: 0.0257\n",
      "   Model saved to ./ecg_model_logs\\best_vrae_model.pth\n",
      "\n",
      "[VRAE Run 72/324] Training with params: {'batch_size': 32, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1313, recon=0.1313, kl=46.7592, beta=0.0000\n",
      "Batch 40, loss=0.0970, recon=0.0970, kl=82.3285, beta=0.0000\n",
      "Batch 60, loss=0.0663, recon=0.0663, kl=91.0536, beta=0.0000\n",
      "Batch 80, loss=0.0592, recon=0.0592, kl=114.5577, beta=0.0000\n",
      "Batch 100, loss=0.0835, recon=0.0835, kl=83.8480, beta=0.0000\n",
      "Batch 120, loss=0.0415, recon=0.0415, kl=124.0807, beta=0.0000\n",
      "Batch 140, loss=0.0525, recon=0.0525, kl=103.9077, beta=0.0000\n",
      "Batch 160, loss=0.0672, recon=0.0672, kl=125.3257, beta=0.0000\n",
      "Batch 180, loss=0.0690, recon=0.0690, kl=103.3442, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1163 (Recon: 0.1163, KL: 92.3529, Current Beta: 0.0000) | Avg Valid Loss: 0.0698 | Avg Valid recon Loss: 0.0698\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0406, recon=0.0406, kl=104.1220, beta=0.0000\n",
      "Batch 40, loss=0.0690, recon=0.0690, kl=123.5531, beta=0.0000\n",
      "Batch 60, loss=0.0418, recon=0.0418, kl=127.9667, beta=0.0000\n",
      "Batch 80, loss=0.0430, recon=0.0430, kl=142.2146, beta=0.0000\n",
      "Batch 100, loss=0.0472, recon=0.0472, kl=138.9764, beta=0.0000\n",
      "Batch 120, loss=0.0448, recon=0.0448, kl=143.0800, beta=0.0000\n",
      "Batch 140, loss=0.0951, recon=0.0951, kl=139.9776, beta=0.0000\n",
      "Batch 160, loss=0.0445, recon=0.0445, kl=114.1236, beta=0.0000\n",
      "Batch 180, loss=0.0901, recon=0.0901, kl=127.0449, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0607 (Recon: 0.0607, KL: 126.5342, Current Beta: 0.0000) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0474\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0270, recon=0.0270, kl=127.8695, beta=0.0000\n",
      "Batch 40, loss=0.0328, recon=0.0328, kl=141.1641, beta=0.0000\n",
      "Batch 60, loss=0.0251, recon=0.0251, kl=135.2510, beta=0.0000\n",
      "Batch 80, loss=0.2266, recon=0.2266, kl=136.9584, beta=0.0000\n",
      "Batch 100, loss=0.0322, recon=0.0322, kl=134.2888, beta=0.0000\n",
      "Batch 120, loss=0.0553, recon=0.0553, kl=127.0029, beta=0.0000\n",
      "Batch 140, loss=0.0579, recon=0.0579, kl=137.2839, beta=0.0000\n",
      "Batch 160, loss=0.0405, recon=0.0405, kl=143.6481, beta=0.0000\n",
      "Batch 180, loss=0.0409, recon=0.0409, kl=143.9700, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0515 (Recon: 0.0515, KL: 135.8050, Current Beta: 0.0000) | Avg Valid Loss: 0.0512 | Avg Valid recon Loss: 0.0512\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0485, recon=0.0485, kl=139.9688, beta=0.0000\n",
      "Batch 40, loss=0.0563, recon=0.0563, kl=146.9410, beta=0.0000\n",
      "Batch 60, loss=0.0405, recon=0.0405, kl=152.8568, beta=0.0000\n",
      "Batch 80, loss=0.0727, recon=0.0727, kl=153.7108, beta=0.0000\n",
      "Batch 100, loss=0.0776, recon=0.0776, kl=155.7534, beta=0.0000\n",
      "Batch 120, loss=0.0240, recon=0.0240, kl=158.5128, beta=0.0000\n",
      "Batch 140, loss=0.0308, recon=0.0308, kl=132.3108, beta=0.0000\n",
      "Batch 160, loss=0.0441, recon=0.0441, kl=157.5339, beta=0.0000\n",
      "Batch 180, loss=0.0378, recon=0.0378, kl=167.5891, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0507 (Recon: 0.0507, KL: 150.5479, Current Beta: 0.0000) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0254, recon=0.0253, kl=154.8578, beta=0.0000\n",
      "Batch 40, loss=0.0331, recon=0.0331, kl=138.0954, beta=0.0000\n",
      "Batch 60, loss=0.0248, recon=0.0248, kl=158.8142, beta=0.0000\n",
      "Batch 80, loss=0.0508, recon=0.0508, kl=161.7127, beta=0.0000\n",
      "Batch 100, loss=0.0394, recon=0.0393, kl=162.5987, beta=0.0000\n",
      "Batch 120, loss=0.0342, recon=0.0342, kl=159.8435, beta=0.0000\n",
      "Batch 140, loss=0.0400, recon=0.0400, kl=161.9406, beta=0.0000\n",
      "Batch 160, loss=0.0249, recon=0.0249, kl=152.4200, beta=0.0000\n",
      "Batch 180, loss=0.0398, recon=0.0398, kl=158.5819, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0405, KL: 157.0632, Current Beta: 0.0000) | Avg Valid Loss: 0.0546 | Avg Valid recon Loss: 0.0546\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0307, recon=0.0306, kl=94.8308, beta=0.0000\n",
      "Batch 40, loss=0.0466, recon=0.0466, kl=130.9129, beta=0.0000\n",
      "Batch 60, loss=0.0893, recon=0.0893, kl=153.3089, beta=0.0000\n",
      "Batch 80, loss=0.0422, recon=0.0422, kl=160.2103, beta=0.0000\n",
      "Batch 100, loss=0.0515, recon=0.0514, kl=175.5194, beta=0.0000\n",
      "Batch 120, loss=0.0333, recon=0.0332, kl=177.4158, beta=0.0000\n",
      "Batch 140, loss=0.0266, recon=0.0266, kl=196.7750, beta=0.0000\n",
      "Batch 160, loss=0.0421, recon=0.0421, kl=200.2392, beta=0.0000\n",
      "Batch 180, loss=0.0465, recon=0.0465, kl=204.8601, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0588 (Recon: 0.0588, KL: 161.8014, Current Beta: 0.0000) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0338, recon=0.0337, kl=198.8059, beta=0.0000\n",
      "Batch 40, loss=0.0310, recon=0.0309, kl=202.3551, beta=0.0000\n",
      "Batch 60, loss=0.0462, recon=0.0461, kl=199.2310, beta=0.0000\n",
      "Batch 80, loss=0.0308, recon=0.0307, kl=197.5051, beta=0.0000\n",
      "Batch 100, loss=0.0344, recon=0.0343, kl=186.5409, beta=0.0000\n",
      "Batch 120, loss=0.0245, recon=0.0244, kl=192.8866, beta=0.0000\n",
      "Batch 140, loss=0.0235, recon=0.0234, kl=181.0753, beta=0.0000\n",
      "Batch 160, loss=0.0268, recon=0.0267, kl=184.7608, beta=0.0000\n",
      "Batch 180, loss=0.0418, recon=0.0417, kl=182.5811, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0428, KL: 191.8156, Current Beta: 0.0000) | Avg Valid Loss: 0.0586 | Avg Valid recon Loss: 0.0585\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0336, recon=0.0333, kl=180.1415, beta=0.0000\n",
      "Batch 40, loss=0.1632, recon=0.1629, kl=183.2571, beta=0.0000\n",
      "Batch 60, loss=0.0674, recon=0.0672, kl=151.9942, beta=0.0000\n",
      "Batch 80, loss=0.0473, recon=0.0470, kl=167.5668, beta=0.0000\n",
      "Batch 100, loss=0.0496, recon=0.0494, kl=161.4143, beta=0.0000\n",
      "Batch 120, loss=0.0489, recon=0.0486, kl=157.4272, beta=0.0000\n",
      "Batch 140, loss=0.0387, recon=0.0385, kl=154.1022, beta=0.0000\n",
      "Batch 160, loss=0.0408, recon=0.0406, kl=151.5272, beta=0.0000\n",
      "Batch 180, loss=0.0373, recon=0.0371, kl=152.2466, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0590 (Recon: 0.0588, KL: 163.5971, Current Beta: 0.0000) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0472\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0566, recon=0.0560, kl=152.1547, beta=0.0000\n",
      "Batch 40, loss=0.0222, recon=0.0216, kl=144.1620, beta=0.0000\n",
      "Batch 60, loss=0.0363, recon=0.0357, kl=147.5520, beta=0.0000\n",
      "Batch 80, loss=0.0307, recon=0.0301, kl=151.2269, beta=0.0000\n",
      "Batch 100, loss=0.0435, recon=0.0429, kl=139.3918, beta=0.0000\n",
      "Batch 120, loss=0.0573, recon=0.0567, kl=135.7926, beta=0.0000\n",
      "Batch 140, loss=0.0626, recon=0.0621, kl=133.0912, beta=0.0000\n",
      "Batch 160, loss=0.0467, recon=0.0462, kl=129.5932, beta=0.0000\n",
      "Batch 180, loss=0.0373, recon=0.0367, kl=136.6931, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0536 (Recon: 0.0530, KL: 142.1331, Current Beta: 0.0000) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0432\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0572, recon=0.0558, kl=126.9774, beta=0.0000\n",
      "Batch 40, loss=0.0271, recon=0.0258, kl=112.3283, beta=0.0000\n",
      "Batch 60, loss=0.0860, recon=0.0848, kl=110.0836, beta=0.0000\n",
      "Batch 80, loss=0.0452, recon=0.0439, kl=113.9930, beta=0.0000\n",
      "Batch 100, loss=0.0405, recon=0.0393, kl=111.4312, beta=0.0000\n",
      "Batch 120, loss=0.0498, recon=0.0487, kl=99.0277, beta=0.0000\n",
      "Batch 140, loss=0.0337, recon=0.0325, kl=105.0726, beta=0.0000\n",
      "Batch 160, loss=0.0334, recon=0.0323, kl=94.0498, beta=0.0000\n",
      "Batch 180, loss=0.0723, recon=0.0713, kl=96.0336, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0542 (Recon: 0.0530, KL: 109.4037, Current Beta: 0.0000) | Avg Valid Loss: 0.0529 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0337, recon=0.0309, kl=95.2043, beta=0.0000\n",
      "Batch 40, loss=0.0396, recon=0.0376, kl=71.2341, beta=0.0000\n",
      "Batch 60, loss=0.0359, recon=0.0335, kl=83.1646, beta=0.0000\n",
      "Batch 80, loss=0.0387, recon=0.0364, kl=76.6636, beta=0.0000\n",
      "Batch 100, loss=0.0431, recon=0.0404, kl=91.8472, beta=0.0000\n",
      "Batch 120, loss=0.0554, recon=0.0528, kl=89.0894, beta=0.0000\n",
      "Batch 140, loss=0.0620, recon=0.0595, kl=84.8629, beta=0.0000\n",
      "Batch 160, loss=0.0339, recon=0.0308, kl=107.4207, beta=0.0000\n",
      "Batch 180, loss=0.0400, recon=0.0377, kl=80.9622, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0542 (Recon: 0.0517, KL: 86.6549, Current Beta: 0.0000) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0443\n",
      "Epoch 12/20\n",
      "Batch 20, loss=162.4809, recon=162.4689, kl=157.8840, beta=0.0001\n",
      "Batch 40, loss=202.7888, recon=202.7712, kl=231.9183, beta=0.0001\n",
      "Batch 60, loss=80.0088, recon=79.9987, kl=133.3160, beta=0.0001\n",
      "Batch 80, loss=99.4238, recon=99.4167, kl=93.3123, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 13/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0002\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0002) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 14/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0004\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0004) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0006\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0006) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 73/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5611, recon=0.5611, kl=0.2135, beta=0.0000\n",
      "Batch 40, loss=0.6241, recon=0.6241, kl=0.5856, beta=0.0000\n",
      "Batch 60, loss=0.4041, recon=0.4041, kl=3.4710, beta=0.0000\n",
      "Batch 80, loss=0.3816, recon=0.3816, kl=8.6788, beta=0.0000\n",
      "Batch 100, loss=0.3493, recon=0.3493, kl=11.9586, beta=0.0000\n",
      "Batch 120, loss=0.4062, recon=0.4062, kl=15.5630, beta=0.0000\n",
      "Batch 140, loss=0.2683, recon=0.2683, kl=18.5671, beta=0.0000\n",
      "Batch 160, loss=0.2542, recon=0.2542, kl=20.3574, beta=0.0000\n",
      "Batch 180, loss=0.3321, recon=0.3321, kl=22.6709, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4420 (Recon: 0.4420, KL: 10.2466, Current Beta: 0.0000) | Avg Valid Loss: 0.2425 | Avg Valid recon Loss: 0.2425\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1665, recon=0.1665, kl=23.5709, beta=0.0000\n",
      "Batch 40, loss=0.3347, recon=0.3347, kl=24.8176, beta=0.0000\n",
      "Batch 60, loss=0.1636, recon=0.1636, kl=25.7529, beta=0.0000\n",
      "Batch 80, loss=0.1382, recon=0.1382, kl=26.1777, beta=0.0000\n",
      "Batch 100, loss=0.2937, recon=0.2937, kl=27.1109, beta=0.0000\n",
      "Batch 120, loss=0.1315, recon=0.1315, kl=28.3250, beta=0.0000\n",
      "Batch 140, loss=0.1508, recon=0.1508, kl=28.3449, beta=0.0000\n",
      "Batch 160, loss=0.2519, recon=0.2519, kl=28.7122, beta=0.0000\n",
      "Batch 180, loss=0.1801, recon=0.1801, kl=29.5913, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2189 (Recon: 0.2189, KL: 26.5900, Current Beta: 0.0000) | Avg Valid Loss: 0.1542 | Avg Valid recon Loss: 0.1542\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1786, recon=0.1786, kl=30.0498, beta=0.0000\n",
      "Batch 40, loss=0.0935, recon=0.0935, kl=29.7992, beta=0.0000\n",
      "Batch 60, loss=0.1625, recon=0.1625, kl=30.0390, beta=0.0000\n",
      "Batch 80, loss=0.1427, recon=0.1427, kl=30.1947, beta=0.0000\n",
      "Batch 100, loss=0.1141, recon=0.1141, kl=30.4053, beta=0.0000\n",
      "Batch 120, loss=0.1517, recon=0.1517, kl=29.6666, beta=0.0000\n",
      "Batch 140, loss=0.1850, recon=0.1850, kl=29.6114, beta=0.0000\n",
      "Batch 160, loss=0.0915, recon=0.0915, kl=29.9556, beta=0.0000\n",
      "Batch 180, loss=0.0789, recon=0.0789, kl=30.7765, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1607 (Recon: 0.1607, KL: 29.9955, Current Beta: 0.0000) | Avg Valid Loss: 0.1184 | Avg Valid recon Loss: 0.1184\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1150, recon=0.1150, kl=29.6910, beta=0.0000\n",
      "Batch 40, loss=0.0747, recon=0.0747, kl=28.6414, beta=0.0000\n",
      "Batch 60, loss=0.1686, recon=0.1686, kl=27.9134, beta=0.0000\n",
      "Batch 80, loss=0.0852, recon=0.0852, kl=27.6560, beta=0.0000\n",
      "Batch 100, loss=0.0936, recon=0.0936, kl=27.1713, beta=0.0000\n",
      "Batch 120, loss=0.0988, recon=0.0988, kl=26.7925, beta=0.0000\n",
      "Batch 140, loss=0.1324, recon=0.1324, kl=26.2536, beta=0.0000\n",
      "Batch 160, loss=0.0693, recon=0.0693, kl=26.9448, beta=0.0000\n",
      "Batch 180, loss=0.0864, recon=0.0864, kl=26.5284, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1291 (Recon: 0.1291, KL: 27.7631, Current Beta: 0.0000) | Avg Valid Loss: 0.1010 | Avg Valid recon Loss: 0.1009\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0942, recon=0.0942, kl=24.9530, beta=0.0000\n",
      "Batch 40, loss=0.0876, recon=0.0876, kl=22.9123, beta=0.0000\n",
      "Batch 60, loss=0.0813, recon=0.0813, kl=20.7798, beta=0.0000\n",
      "Batch 80, loss=0.0740, recon=0.0740, kl=21.1555, beta=0.0000\n",
      "Batch 100, loss=0.0669, recon=0.0669, kl=20.6749, beta=0.0000\n",
      "Batch 120, loss=0.0695, recon=0.0695, kl=18.8502, beta=0.0000\n",
      "Batch 140, loss=0.1538, recon=0.1538, kl=18.2181, beta=0.0000\n",
      "Batch 160, loss=0.0742, recon=0.0742, kl=17.6412, beta=0.0000\n",
      "Batch 180, loss=0.1227, recon=0.1227, kl=17.9981, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1092 (Recon: 0.1092, KL: 20.7671, Current Beta: 0.0000) | Avg Valid Loss: 0.0871 | Avg Valid recon Loss: 0.0870\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0638, recon=0.0638, kl=15.6943, beta=0.0000\n",
      "Batch 40, loss=0.3396, recon=0.3396, kl=13.5524, beta=0.0000\n",
      "Batch 60, loss=0.0531, recon=0.0531, kl=12.8875, beta=0.0000\n",
      "Batch 80, loss=0.0556, recon=0.0556, kl=12.0867, beta=0.0000\n",
      "Batch 100, loss=0.0783, recon=0.0783, kl=11.1715, beta=0.0000\n",
      "Batch 120, loss=0.0494, recon=0.0494, kl=10.9451, beta=0.0000\n",
      "Batch 140, loss=0.1047, recon=0.1047, kl=10.2861, beta=0.0000\n",
      "Batch 160, loss=0.1107, recon=0.1107, kl=10.6703, beta=0.0000\n",
      "Batch 180, loss=0.0625, recon=0.0625, kl=10.2404, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0963 (Recon: 0.0963, KL: 12.3311, Current Beta: 0.0000) | Avg Valid Loss: 0.0792 | Avg Valid recon Loss: 0.0791\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0761, recon=0.0760, kl=6.6034, beta=0.0000\n",
      "Batch 40, loss=0.0557, recon=0.0557, kl=5.3599, beta=0.0000\n",
      "Batch 60, loss=0.0693, recon=0.0693, kl=4.8169, beta=0.0000\n",
      "Batch 80, loss=0.0561, recon=0.0561, kl=4.4529, beta=0.0000\n",
      "Batch 100, loss=0.0919, recon=0.0919, kl=4.1202, beta=0.0000\n",
      "Batch 120, loss=0.0932, recon=0.0932, kl=4.3958, beta=0.0000\n",
      "Batch 140, loss=0.1077, recon=0.1076, kl=3.9752, beta=0.0000\n",
      "Batch 160, loss=0.0651, recon=0.0651, kl=4.1438, beta=0.0000\n",
      "Batch 180, loss=0.0686, recon=0.0686, kl=4.0149, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0871 (Recon: 0.0871, KL: 4.9532, Current Beta: 0.0000) | Avg Valid Loss: 0.0735 | Avg Valid recon Loss: 0.0735\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0516, recon=0.0516, kl=2.0483, beta=0.0000\n",
      "Batch 40, loss=0.0569, recon=0.0569, kl=2.3763, beta=0.0000\n",
      "Batch 60, loss=0.0744, recon=0.0744, kl=1.6547, beta=0.0000\n",
      "Batch 80, loss=0.0609, recon=0.0609, kl=1.8300, beta=0.0000\n",
      "Batch 100, loss=0.0528, recon=0.0528, kl=1.4726, beta=0.0000\n",
      "Batch 120, loss=0.0551, recon=0.0550, kl=1.6413, beta=0.0000\n",
      "Batch 140, loss=0.0516, recon=0.0516, kl=1.4666, beta=0.0000\n",
      "Batch 160, loss=0.0411, recon=0.0411, kl=1.6376, beta=0.0000\n",
      "Batch 180, loss=0.0797, recon=0.0797, kl=1.2177, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0809 (Recon: 0.0809, KL: 1.8115, Current Beta: 0.0000) | Avg Valid Loss: 0.0693 | Avg Valid recon Loss: 0.0693\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0491, recon=0.0490, kl=0.5484, beta=0.0000\n",
      "Batch 40, loss=0.0398, recon=0.0398, kl=0.5475, beta=0.0000\n",
      "Batch 60, loss=0.1592, recon=0.1591, kl=0.7326, beta=0.0000\n",
      "Batch 80, loss=0.0636, recon=0.0636, kl=0.5226, beta=0.0000\n",
      "Batch 100, loss=0.0828, recon=0.0828, kl=0.4311, beta=0.0000\n",
      "Batch 120, loss=0.0616, recon=0.0616, kl=0.3141, beta=0.0000\n",
      "Batch 140, loss=0.0429, recon=0.0429, kl=0.4039, beta=0.0000\n",
      "Batch 160, loss=0.0405, recon=0.0405, kl=0.2501, beta=0.0000\n",
      "Batch 180, loss=0.0990, recon=0.0990, kl=0.2973, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0757 (Recon: 0.0757, KL: 0.4904, Current Beta: 0.0000) | Avg Valid Loss: 0.0659 | Avg Valid recon Loss: 0.0659\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0403, recon=0.0403, kl=0.0472, beta=0.0001\n",
      "Batch 40, loss=0.0510, recon=0.0510, kl=0.0770, beta=0.0001\n",
      "Batch 60, loss=0.0941, recon=0.0941, kl=0.0395, beta=0.0001\n",
      "Batch 80, loss=0.0487, recon=0.0487, kl=0.0441, beta=0.0001\n",
      "Batch 100, loss=0.0663, recon=0.0663, kl=0.0361, beta=0.0001\n",
      "Batch 120, loss=0.0516, recon=0.0516, kl=0.0176, beta=0.0001\n",
      "Batch 140, loss=0.0330, recon=0.0330, kl=0.0331, beta=0.0001\n",
      "Batch 160, loss=0.0438, recon=0.0438, kl=0.0155, beta=0.0001\n",
      "Batch 180, loss=0.0552, recon=0.0552, kl=0.0314, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0719 (Recon: 0.0719, KL: 0.0465, Current Beta: 0.0001) | Avg Valid Loss: 0.0628 | Avg Valid recon Loss: 0.0628\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0640, recon=0.0640, kl=0.0227, beta=0.0003\n",
      "Batch 40, loss=0.0430, recon=0.0430, kl=0.0040, beta=0.0003\n",
      "Batch 60, loss=0.0803, recon=0.0803, kl=0.0096, beta=0.0003\n",
      "Batch 80, loss=0.0517, recon=0.0517, kl=0.0021, beta=0.0003\n",
      "Batch 100, loss=0.0327, recon=0.0326, kl=0.0033, beta=0.0003\n",
      "Batch 120, loss=0.0349, recon=0.0349, kl=0.0019, beta=0.0003\n",
      "Batch 140, loss=0.0406, recon=0.0406, kl=0.0031, beta=0.0003\n",
      "Batch 160, loss=0.0633, recon=0.0633, kl=0.0016, beta=0.0003\n",
      "Batch 180, loss=0.0428, recon=0.0428, kl=0.0019, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0689 (Recon: 0.0689, KL: 0.0046, Current Beta: 0.0003) | Avg Valid Loss: 0.0602 | Avg Valid recon Loss: 0.0602\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0377, recon=0.0377, kl=0.0010, beta=0.0008\n",
      "Batch 40, loss=1.2026, recon=1.2026, kl=0.0009, beta=0.0008\n",
      "Batch 60, loss=0.0613, recon=0.0613, kl=0.0012, beta=0.0008\n",
      "Batch 80, loss=0.0417, recon=0.0417, kl=0.0004, beta=0.0008\n",
      "Batch 100, loss=0.0669, recon=0.0669, kl=0.0012, beta=0.0008\n",
      "Batch 120, loss=0.0520, recon=0.0520, kl=0.0006, beta=0.0008\n",
      "Batch 140, loss=0.0767, recon=0.0767, kl=0.0008, beta=0.0008\n",
      "Batch 160, loss=0.0703, recon=0.0703, kl=0.0007, beta=0.0008\n",
      "Batch 180, loss=0.0330, recon=0.0330, kl=0.0003, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0661 (Recon: 0.0661, KL: 0.0011, Current Beta: 0.0008) | Avg Valid Loss: 0.0580 | Avg Valid recon Loss: 0.0580\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0864, recon=0.0864, kl=0.0008, beta=0.0018\n",
      "Batch 40, loss=0.0453, recon=0.0453, kl=0.0002, beta=0.0018\n",
      "Batch 60, loss=0.0325, recon=0.0325, kl=0.0002, beta=0.0018\n",
      "Batch 80, loss=0.0463, recon=0.0463, kl=0.0007, beta=0.0018\n",
      "Batch 100, loss=0.0341, recon=0.0341, kl=0.0004, beta=0.0018\n",
      "Batch 120, loss=0.0469, recon=0.0469, kl=0.0003, beta=0.0018\n",
      "Batch 140, loss=0.1120, recon=0.1120, kl=0.0067, beta=0.0018\n",
      "Batch 160, loss=0.0288, recon=0.0288, kl=0.0004, beta=0.0018\n",
      "Batch 180, loss=0.3033, recon=0.3033, kl=0.0005, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0640 (Recon: 0.0640, KL: 0.0004, Current Beta: 0.0018) | Avg Valid Loss: 0.0573 | Avg Valid recon Loss: 0.0573\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0282, recon=0.0282, kl=0.0003, beta=0.0038\n",
      "Batch 40, loss=0.0526, recon=0.0526, kl=0.0003, beta=0.0038\n",
      "Batch 60, loss=0.0321, recon=0.0321, kl=0.0003, beta=0.0038\n",
      "Batch 80, loss=0.0437, recon=0.0437, kl=0.0002, beta=0.0038\n",
      "Batch 100, loss=0.0409, recon=0.0409, kl=0.0002, beta=0.0038\n",
      "Batch 120, loss=0.0762, recon=0.0762, kl=0.0001, beta=0.0038\n",
      "Batch 140, loss=0.0628, recon=0.0628, kl=0.0002, beta=0.0038\n",
      "Batch 160, loss=0.0495, recon=0.0495, kl=0.0000, beta=0.0038\n",
      "Batch 180, loss=0.0298, recon=0.0298, kl=0.0002, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0621 (Recon: 0.0621, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0549 | Avg Valid recon Loss: 0.0549\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0656, recon=0.0656, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0810, recon=0.0810, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0330, recon=0.0330, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0478, recon=0.0478, kl=0.0000, beta=0.0062\n",
      "Batch 100, loss=0.0485, recon=0.0485, kl=0.0002, beta=0.0062\n",
      "Batch 120, loss=0.0419, recon=0.0419, kl=0.0001, beta=0.0062\n",
      "Batch 140, loss=0.0344, recon=0.0344, kl=0.0001, beta=0.0062\n",
      "Batch 160, loss=0.0434, recon=0.0434, kl=0.0001, beta=0.0062\n",
      "Batch 180, loss=0.0498, recon=0.0498, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0602 (Recon: 0.0602, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0532 | Avg Valid recon Loss: 0.0532\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0447, recon=0.0447, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0661, recon=0.0661, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0548, recon=0.0548, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0444, recon=0.0444, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0532, recon=0.0532, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0457, recon=0.0457, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0488, recon=0.0488, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0477, recon=0.0477, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0416, recon=0.0416, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0587 (Recon: 0.0587, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0516 | Avg Valid recon Loss: 0.0516\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0333, recon=0.0333, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0527, recon=0.0527, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0886, recon=0.0886, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0560, recon=0.0560, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0618, recon=0.0618, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0357, recon=0.0357, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=1.0332, recon=1.0332, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0318, recon=0.0318, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0379, recon=0.0379, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0573 (Recon: 0.0573, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0505 | Avg Valid recon Loss: 0.0505\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0643, recon=0.0643, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0423, recon=0.0423, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0325, recon=0.0325, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0391, recon=0.0391, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0459, recon=0.0459, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0424, recon=0.0424, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0417, recon=0.0417, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0533, recon=0.0533, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0745, recon=0.0745, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0560 (Recon: 0.0560, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0333, recon=0.0333, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0440, recon=0.0440, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0254, recon=0.0254, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0315, recon=0.0315, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0434, recon=0.0434, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0350, recon=0.0350, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0362, recon=0.0362, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0428, recon=0.0428, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0538, recon=0.0538, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0547, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0483 | Avg Valid recon Loss: 0.0483\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0383, recon=0.0383, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0346, recon=0.0346, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0329, recon=0.0329, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0432, recon=0.0432, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0307, recon=0.0307, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0324, recon=0.0324, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0228, recon=0.0228, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0463, recon=0.0463, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0372, recon=0.0372, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0537 (Recon: 0.0537, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0469 | Avg Valid recon Loss: 0.0469\n",
      "\n",
      "[VRAE Run 74/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2595, recon=0.2595, kl=15.6640, beta=0.0000\n",
      "Batch 40, loss=0.3248, recon=0.3248, kl=24.9106, beta=0.0000\n",
      "Batch 60, loss=0.1150, recon=0.1150, kl=26.6037, beta=0.0000\n",
      "Batch 80, loss=0.0992, recon=0.0992, kl=28.2932, beta=0.0000\n",
      "Batch 100, loss=0.0564, recon=0.0564, kl=29.5609, beta=0.0000\n",
      "Batch 120, loss=0.1505, recon=0.1505, kl=29.6685, beta=0.0000\n",
      "Batch 140, loss=0.1651, recon=0.1651, kl=29.8929, beta=0.0000\n",
      "Batch 160, loss=0.0862, recon=0.0862, kl=33.2598, beta=0.0000\n",
      "Batch 180, loss=0.0767, recon=0.0767, kl=32.2914, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1660 (Recon: 0.1660, KL: 26.1848, Current Beta: 0.0000) | Avg Valid Loss: 0.0714 | Avg Valid recon Loss: 0.0714\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0744, recon=0.0744, kl=30.8069, beta=0.0000\n",
      "Batch 40, loss=0.0533, recon=0.0533, kl=32.0624, beta=0.0000\n",
      "Batch 60, loss=0.0578, recon=0.0578, kl=29.2377, beta=0.0000\n",
      "Batch 80, loss=0.0450, recon=0.0450, kl=28.6395, beta=0.0000\n",
      "Batch 100, loss=0.0561, recon=0.0561, kl=29.3270, beta=0.0000\n",
      "Batch 120, loss=0.0389, recon=0.0389, kl=31.9551, beta=0.0000\n",
      "Batch 140, loss=0.0397, recon=0.0397, kl=32.9376, beta=0.0000\n",
      "Batch 160, loss=0.0609, recon=0.0609, kl=33.6777, beta=0.0000\n",
      "Batch 180, loss=0.1172, recon=0.1172, kl=34.1657, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0727 (Recon: 0.0727, KL: 31.2294, Current Beta: 0.0000) | Avg Valid Loss: 0.0677 | Avg Valid recon Loss: 0.0677\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0439, recon=0.0439, kl=27.4520, beta=0.0000\n",
      "Batch 40, loss=0.0380, recon=0.0380, kl=31.3176, beta=0.0000\n",
      "Batch 60, loss=0.0455, recon=0.0455, kl=30.6865, beta=0.0000\n",
      "Batch 80, loss=0.0710, recon=0.0710, kl=32.8180, beta=0.0000\n",
      "Batch 100, loss=0.0494, recon=0.0494, kl=32.0620, beta=0.0000\n",
      "Batch 120, loss=0.0860, recon=0.0860, kl=30.8825, beta=0.0000\n",
      "Batch 140, loss=0.0427, recon=0.0427, kl=30.4897, beta=0.0000\n",
      "Batch 160, loss=1.3313, recon=1.3313, kl=33.9599, beta=0.0000\n",
      "Batch 180, loss=0.0696, recon=0.0696, kl=31.5905, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0683 (Recon: 0.0683, KL: 31.5342, Current Beta: 0.0000) | Avg Valid Loss: 0.0713 | Avg Valid recon Loss: 0.0713\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0734, recon=0.0734, kl=29.2656, beta=0.0000\n",
      "Batch 40, loss=0.0352, recon=0.0352, kl=26.7166, beta=0.0000\n",
      "Batch 60, loss=0.0513, recon=0.0513, kl=25.1666, beta=0.0000\n",
      "Batch 80, loss=0.0355, recon=0.0355, kl=26.5046, beta=0.0000\n",
      "Batch 100, loss=0.0457, recon=0.0457, kl=24.4554, beta=0.0000\n",
      "Batch 120, loss=0.0441, recon=0.0441, kl=24.4613, beta=0.0000\n",
      "Batch 140, loss=0.0400, recon=0.0399, kl=25.8630, beta=0.0000\n",
      "Batch 160, loss=0.0343, recon=0.0343, kl=24.2013, beta=0.0000\n",
      "Batch 180, loss=0.0422, recon=0.0421, kl=24.6998, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0635 (Recon: 0.0634, KL: 26.1317, Current Beta: 0.0000) | Avg Valid Loss: 0.0572 | Avg Valid recon Loss: 0.0571\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=21.5329, beta=0.0000\n",
      "Batch 40, loss=1.1765, recon=1.1765, kl=19.9208, beta=0.0000\n",
      "Batch 60, loss=0.1548, recon=0.1548, kl=17.0659, beta=0.0000\n",
      "Batch 80, loss=0.0370, recon=0.0370, kl=18.6843, beta=0.0000\n",
      "Batch 100, loss=0.0513, recon=0.0513, kl=18.1903, beta=0.0000\n",
      "Batch 120, loss=0.0310, recon=0.0309, kl=17.1586, beta=0.0000\n",
      "Batch 140, loss=0.0283, recon=0.0282, kl=17.5269, beta=0.0000\n",
      "Batch 160, loss=0.0516, recon=0.0515, kl=16.6489, beta=0.0000\n",
      "Batch 180, loss=0.0334, recon=0.0334, kl=15.3462, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0586 (Recon: 0.0586, KL: 18.4967, Current Beta: 0.0000) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0472\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0359, recon=0.0358, kl=12.9075, beta=0.0000\n",
      "Batch 40, loss=0.0668, recon=0.0668, kl=11.9695, beta=0.0000\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=12.5667, beta=0.0000\n",
      "Batch 80, loss=0.0320, recon=0.0320, kl=12.7319, beta=0.0000\n",
      "Batch 100, loss=0.1012, recon=0.1012, kl=13.2551, beta=0.0000\n",
      "Batch 120, loss=0.0372, recon=0.0372, kl=13.5521, beta=0.0000\n",
      "Batch 140, loss=0.0331, recon=0.0331, kl=12.7041, beta=0.0000\n",
      "Batch 160, loss=0.0512, recon=0.0512, kl=11.0102, beta=0.0000\n",
      "Batch 180, loss=0.0479, recon=0.0479, kl=11.0453, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0565 (Recon: 0.0565, KL: 12.7460, Current Beta: 0.0000) | Avg Valid Loss: 0.0558 | Avg Valid recon Loss: 0.0557\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0320, recon=0.0320, kl=5.5089, beta=0.0000\n",
      "Batch 40, loss=0.0367, recon=0.0367, kl=5.9338, beta=0.0000\n",
      "Batch 60, loss=0.0549, recon=0.0549, kl=6.6264, beta=0.0000\n",
      "Batch 80, loss=0.0386, recon=0.0385, kl=5.4068, beta=0.0000\n",
      "Batch 100, loss=0.0485, recon=0.0485, kl=6.4567, beta=0.0000\n",
      "Batch 120, loss=0.0344, recon=0.0344, kl=7.9884, beta=0.0000\n",
      "Batch 140, loss=0.0490, recon=0.0489, kl=7.3327, beta=0.0000\n",
      "Batch 160, loss=0.0284, recon=0.0283, kl=4.9319, beta=0.0000\n",
      "Batch 180, loss=0.0393, recon=0.0392, kl=4.8249, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 6.4569, Current Beta: 0.0000) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0288, recon=0.0288, kl=2.1182, beta=0.0000\n",
      "Batch 40, loss=0.0399, recon=0.0399, kl=1.6769, beta=0.0000\n",
      "Batch 60, loss=0.0454, recon=0.0454, kl=2.0635, beta=0.0000\n",
      "Batch 80, loss=0.0272, recon=0.0272, kl=1.5996, beta=0.0000\n",
      "Batch 100, loss=0.0326, recon=0.0326, kl=1.1938, beta=0.0000\n",
      "Batch 120, loss=0.0323, recon=0.0323, kl=0.9448, beta=0.0000\n",
      "Batch 140, loss=0.0519, recon=0.0519, kl=1.1530, beta=0.0000\n",
      "Batch 160, loss=0.0425, recon=0.0425, kl=1.1071, beta=0.0000\n",
      "Batch 180, loss=0.0294, recon=0.0294, kl=1.3462, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0523, KL: 1.6284, Current Beta: 0.0000) | Avg Valid Loss: 0.0453 | Avg Valid recon Loss: 0.0453\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0504, recon=0.0504, kl=0.1737, beta=0.0000\n",
      "Batch 40, loss=0.0409, recon=0.0409, kl=0.1993, beta=0.0000\n",
      "Batch 60, loss=0.0356, recon=0.0356, kl=0.1609, beta=0.0000\n",
      "Batch 80, loss=0.0339, recon=0.0339, kl=0.1750, beta=0.0000\n",
      "Batch 100, loss=0.0286, recon=0.0286, kl=0.2843, beta=0.0000\n",
      "Batch 120, loss=0.0295, recon=0.0295, kl=0.1000, beta=0.0000\n",
      "Batch 140, loss=0.0271, recon=0.0271, kl=0.0700, beta=0.0000\n",
      "Batch 160, loss=0.0242, recon=0.0241, kl=0.1389, beta=0.0000\n",
      "Batch 180, loss=0.0374, recon=0.0374, kl=0.1420, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0508, KL: 0.2244, Current Beta: 0.0000) | Avg Valid Loss: 0.0446 | Avg Valid recon Loss: 0.0446\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0425, recon=0.0425, kl=0.0097, beta=0.0001\n",
      "Batch 40, loss=0.0274, recon=0.0274, kl=0.1488, beta=0.0001\n",
      "Batch 60, loss=0.0290, recon=0.0290, kl=0.0872, beta=0.0001\n",
      "Batch 80, loss=0.0345, recon=0.0345, kl=0.0331, beta=0.0001\n",
      "Batch 100, loss=0.0194, recon=0.0194, kl=0.0129, beta=0.0001\n",
      "Batch 120, loss=0.0709, recon=0.0709, kl=0.0166, beta=0.0001\n",
      "Batch 140, loss=0.0453, recon=0.0453, kl=0.0491, beta=0.0001\n",
      "Batch 160, loss=0.0791, recon=0.0791, kl=0.0333, beta=0.0001\n",
      "Batch 180, loss=0.0460, recon=0.0460, kl=0.1580, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0540, KL: 0.0595, Current Beta: 0.0001) | Avg Valid Loss: 0.0570 | Avg Valid recon Loss: 0.0570\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1885, recon=0.1885, kl=0.0082, beta=0.0003\n",
      "Batch 40, loss=0.0317, recon=0.0317, kl=0.0101, beta=0.0003\n",
      "Batch 60, loss=0.0470, recon=0.0470, kl=0.0047, beta=0.0003\n",
      "Batch 80, loss=0.0362, recon=0.0362, kl=0.0046, beta=0.0003\n",
      "Batch 100, loss=0.0423, recon=0.0423, kl=0.0014, beta=0.0003\n",
      "Batch 120, loss=0.0267, recon=0.0267, kl=0.0013, beta=0.0003\n",
      "Batch 140, loss=0.0478, recon=0.0478, kl=0.0021, beta=0.0003\n",
      "Batch 160, loss=0.0443, recon=0.0443, kl=0.0103, beta=0.0003\n",
      "Batch 180, loss=0.1030, recon=0.1030, kl=0.0799, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0539 (Recon: 0.0539, KL: 0.0136, Current Beta: 0.0003) | Avg Valid Loss: 0.0704 | Avg Valid recon Loss: 0.0704\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0650, recon=0.0650, kl=0.0081, beta=0.0008\n",
      "Batch 40, loss=0.1039, recon=0.1039, kl=0.0039, beta=0.0008\n",
      "Batch 60, loss=0.0614, recon=0.0614, kl=0.0023, beta=0.0008\n",
      "Batch 80, loss=0.0386, recon=0.0386, kl=0.0014, beta=0.0008\n",
      "Batch 100, loss=0.0450, recon=0.0450, kl=0.0013, beta=0.0008\n",
      "Batch 120, loss=0.0482, recon=0.0482, kl=0.0008, beta=0.0008\n",
      "Batch 140, loss=0.0647, recon=0.0647, kl=0.0013, beta=0.0008\n",
      "Batch 160, loss=0.0632, recon=0.0632, kl=0.0020, beta=0.0008\n",
      "Batch 180, loss=0.0381, recon=0.0381, kl=0.0011, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0626 (Recon: 0.0626, KL: 0.0053, Current Beta: 0.0008) | Avg Valid Loss: 0.0489 | Avg Valid recon Loss: 0.0489\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0375, recon=0.0375, kl=0.0011, beta=0.0018\n",
      "Batch 40, loss=0.0428, recon=0.0428, kl=0.0008, beta=0.0018\n",
      "Batch 60, loss=0.0475, recon=0.0475, kl=0.0006, beta=0.0018\n",
      "Batch 80, loss=0.0410, recon=0.0410, kl=0.0005, beta=0.0018\n",
      "Batch 100, loss=0.0357, recon=0.0357, kl=0.0003, beta=0.0018\n",
      "Batch 120, loss=0.0507, recon=0.0507, kl=0.0004, beta=0.0018\n",
      "Batch 140, loss=0.0323, recon=0.0323, kl=0.0006, beta=0.0018\n",
      "Batch 160, loss=0.0538, recon=0.0538, kl=0.0004, beta=0.0018\n",
      "Batch 180, loss=0.9498, recon=0.9498, kl=0.0004, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0502, KL: 0.0008, Current Beta: 0.0018) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0559\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0350, recon=0.0350, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0465, recon=0.0465, kl=0.0006, beta=0.0038\n",
      "Batch 60, loss=0.0625, recon=0.0625, kl=0.0004, beta=0.0038\n",
      "Batch 80, loss=0.0404, recon=0.0404, kl=0.0001, beta=0.0038\n",
      "Batch 100, loss=0.0364, recon=0.0364, kl=0.0001, beta=0.0038\n",
      "Batch 120, loss=0.0338, recon=0.0338, kl=0.0001, beta=0.0038\n",
      "Batch 140, loss=0.0537, recon=0.0537, kl=0.0003, beta=0.0038\n",
      "Batch 160, loss=0.0435, recon=0.0435, kl=0.0002, beta=0.0038\n",
      "Batch 180, loss=0.0335, recon=0.0335, kl=0.0002, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0531 (Recon: 0.0531, KL: 0.0004, Current Beta: 0.0038) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0656, recon=0.0656, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0352, recon=0.0352, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0353, recon=0.0353, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0918, recon=0.0918, kl=0.0001, beta=0.0062\n",
      "Batch 100, loss=0.0306, recon=0.0306, kl=0.0015, beta=0.0062\n",
      "Batch 120, loss=0.0260, recon=0.0260, kl=0.0017, beta=0.0062\n",
      "Batch 140, loss=0.0588, recon=0.0588, kl=0.0017, beta=0.0062\n",
      "Batch 160, loss=0.0550, recon=0.0550, kl=0.0002, beta=0.0062\n",
      "Batch 180, loss=0.0653, recon=0.0653, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0462, KL: 0.0007, Current Beta: 0.0062) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0559, recon=0.0559, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0329, recon=0.0329, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0410, recon=0.0410, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0370, recon=0.0370, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0398, recon=0.0398, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0410, recon=0.0410, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0310, recon=0.0310, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0227, recon=0.0227, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0461, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0458, recon=0.0458, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0299, recon=0.0299, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0720, recon=0.0720, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0735, recon=0.0735, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0606, recon=0.0606, kl=0.0002, beta=0.0100\n",
      "Batch 120, loss=0.0384, recon=0.0384, kl=0.0005, beta=0.0100\n",
      "Batch 140, loss=0.0360, recon=0.0360, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0304, recon=0.0304, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0485, recon=0.0485, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0542 (Recon: 0.0542, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0454 | Avg Valid recon Loss: 0.0454\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0730, recon=0.0730, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0388, recon=0.0388, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0748, recon=0.0748, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0508, recon=0.0508, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.1102, recon=0.1102, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0493, recon=0.0493, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0303, recon=0.0303, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0514, recon=0.0514, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0367, recon=0.0367, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0307, recon=0.0307, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0420, recon=0.0420, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0363, recon=0.0363, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0566, recon=0.0564, kl=0.0225, beta=0.0100\n",
      "Batch 100, loss=0.0383, recon=0.0382, kl=0.0123, beta=0.0100\n",
      "Batch 120, loss=0.0688, recon=0.0688, kl=0.0026, beta=0.0100\n",
      "Batch 140, loss=0.0332, recon=0.0332, kl=0.0003, beta=0.0100\n",
      "Batch 160, loss=0.0485, recon=0.0485, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0293, recon=0.0293, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0522 (Recon: 0.0521, KL: 0.0108, Current Beta: 0.0100) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0440, recon=0.0440, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0487, recon=0.0487, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0504, recon=0.0504, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0546, recon=0.0546, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0331, recon=0.0331, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0420, recon=0.0420, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0294, recon=0.0294, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0486, recon=0.0486, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0426, recon=0.0426, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0481 (Recon: 0.0481, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0445 | Avg Valid recon Loss: 0.0445\n",
      "\n",
      "[VRAE Run 75/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5340, recon=0.5340, kl=0.4176, beta=0.0000\n",
      "Batch 40, loss=0.5689, recon=0.5689, kl=1.0415, beta=0.0000\n",
      "Batch 60, loss=0.5746, recon=0.5746, kl=5.2956, beta=0.0000\n",
      "Batch 80, loss=0.8060, recon=0.8060, kl=17.2916, beta=0.0000\n",
      "Batch 100, loss=0.2462, recon=0.2462, kl=28.9586, beta=0.0000\n",
      "Batch 120, loss=0.2426, recon=0.2426, kl=35.2532, beta=0.0000\n",
      "Batch 140, loss=0.1540, recon=0.1540, kl=39.7139, beta=0.0000\n",
      "Batch 160, loss=0.2749, recon=0.2749, kl=42.5365, beta=0.0000\n",
      "Batch 180, loss=0.2361, recon=0.2361, kl=44.7985, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4382 (Recon: 0.4382, KL: 21.7140, Current Beta: 0.0000) | Avg Valid Loss: 0.2457 | Avg Valid recon Loss: 0.2457\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1610, recon=0.1610, kl=46.5137, beta=0.0000\n",
      "Batch 40, loss=0.2573, recon=0.2573, kl=47.6066, beta=0.0000\n",
      "Batch 60, loss=0.2049, recon=0.2049, kl=49.3590, beta=0.0000\n",
      "Batch 80, loss=1.0503, recon=1.0503, kl=50.5982, beta=0.0000\n",
      "Batch 100, loss=0.2320, recon=0.2320, kl=52.7008, beta=0.0000\n",
      "Batch 120, loss=0.1514, recon=0.1514, kl=54.3163, beta=0.0000\n",
      "Batch 140, loss=0.1223, recon=0.1223, kl=54.9975, beta=0.0000\n",
      "Batch 160, loss=0.2378, recon=0.2378, kl=56.3004, beta=0.0000\n",
      "Batch 180, loss=0.1234, recon=0.1234, kl=57.1505, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2209 (Recon: 0.2209, KL: 51.5956, Current Beta: 0.0000) | Avg Valid Loss: 0.1553 | Avg Valid recon Loss: 0.1553\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1681, recon=0.1681, kl=57.7815, beta=0.0000\n",
      "Batch 40, loss=0.1252, recon=0.1252, kl=57.9197, beta=0.0000\n",
      "Batch 60, loss=0.1892, recon=0.1892, kl=57.6224, beta=0.0000\n",
      "Batch 80, loss=0.1864, recon=0.1864, kl=57.9736, beta=0.0000\n",
      "Batch 100, loss=0.1237, recon=0.1237, kl=58.3641, beta=0.0000\n",
      "Batch 120, loss=0.1106, recon=0.1105, kl=58.4681, beta=0.0000\n",
      "Batch 140, loss=0.1575, recon=0.1575, kl=58.5638, beta=0.0000\n",
      "Batch 160, loss=0.1226, recon=0.1226, kl=58.8959, beta=0.0000\n",
      "Batch 180, loss=0.8250, recon=0.8250, kl=59.3181, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1630 (Recon: 0.1630, KL: 58.2238, Current Beta: 0.0000) | Avg Valid Loss: 0.1213 | Avg Valid recon Loss: 0.1212\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0803, recon=0.0803, kl=58.5182, beta=0.0000\n",
      "Batch 40, loss=0.1562, recon=0.1561, kl=56.8367, beta=0.0000\n",
      "Batch 60, loss=0.1116, recon=0.1116, kl=54.8290, beta=0.0000\n",
      "Batch 80, loss=0.1301, recon=0.1301, kl=54.0687, beta=0.0000\n",
      "Batch 100, loss=0.0997, recon=0.0997, kl=53.1569, beta=0.0000\n",
      "Batch 120, loss=0.1101, recon=0.1101, kl=52.4940, beta=0.0000\n",
      "Batch 140, loss=0.1291, recon=0.1291, kl=51.8203, beta=0.0000\n",
      "Batch 160, loss=0.0861, recon=0.0861, kl=50.6980, beta=0.0000\n",
      "Batch 180, loss=0.0852, recon=0.0852, kl=50.2369, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1317 (Recon: 0.1317, KL: 54.1096, Current Beta: 0.0000) | Avg Valid Loss: 0.1021 | Avg Valid recon Loss: 0.1021\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0797, recon=0.0796, kl=47.6617, beta=0.0000\n",
      "Batch 40, loss=0.1761, recon=0.1760, kl=43.5595, beta=0.0000\n",
      "Batch 60, loss=0.0933, recon=0.0933, kl=39.9282, beta=0.0000\n",
      "Batch 80, loss=0.1764, recon=0.1764, kl=37.1346, beta=0.0000\n",
      "Batch 100, loss=0.0848, recon=0.0848, kl=35.6251, beta=0.0000\n",
      "Batch 120, loss=0.0974, recon=0.0974, kl=35.0856, beta=0.0000\n",
      "Batch 140, loss=0.0684, recon=0.0683, kl=33.6175, beta=0.0000\n",
      "Batch 160, loss=0.1507, recon=0.1507, kl=32.5112, beta=0.0000\n",
      "Batch 180, loss=0.0846, recon=0.0846, kl=32.6358, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1119 (Recon: 0.1119, KL: 38.4892, Current Beta: 0.0000) | Avg Valid Loss: 0.0890 | Avg Valid recon Loss: 0.0889\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0538, recon=0.0538, kl=28.5292, beta=0.0000\n",
      "Batch 40, loss=0.1072, recon=0.1072, kl=22.0447, beta=0.0000\n",
      "Batch 60, loss=0.1447, recon=0.1446, kl=18.8754, beta=0.0000\n",
      "Batch 80, loss=0.0568, recon=0.0568, kl=18.1903, beta=0.0000\n",
      "Batch 100, loss=0.1513, recon=0.1513, kl=17.5420, beta=0.0000\n",
      "Batch 120, loss=0.0826, recon=0.0825, kl=17.4187, beta=0.0000\n",
      "Batch 140, loss=0.0726, recon=0.0725, kl=15.9409, beta=0.0000\n",
      "Batch 160, loss=0.0721, recon=0.0721, kl=15.5083, beta=0.0000\n",
      "Batch 180, loss=0.0735, recon=0.0734, kl=15.1788, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0983 (Recon: 0.0983, KL: 19.7315, Current Beta: 0.0000) | Avg Valid Loss: 0.0809 | Avg Valid recon Loss: 0.0808\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0513, recon=0.0513, kl=9.0272, beta=0.0000\n",
      "Batch 40, loss=0.0752, recon=0.0751, kl=7.6185, beta=0.0000\n",
      "Batch 60, loss=0.0526, recon=0.0526, kl=6.6000, beta=0.0000\n",
      "Batch 80, loss=0.2149, recon=0.2149, kl=6.5555, beta=0.0000\n",
      "Batch 100, loss=0.0592, recon=0.0591, kl=6.8075, beta=0.0000\n",
      "Batch 120, loss=0.0572, recon=0.0572, kl=5.9522, beta=0.0000\n",
      "Batch 140, loss=0.0568, recon=0.0568, kl=5.4578, beta=0.0000\n",
      "Batch 160, loss=0.0541, recon=0.0541, kl=5.1033, beta=0.0000\n",
      "Batch 180, loss=0.0877, recon=0.0877, kl=4.7163, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0896 (Recon: 0.0895, KL: 6.9906, Current Beta: 0.0000) | Avg Valid Loss: 0.0755 | Avg Valid recon Loss: 0.0755\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0944, recon=0.0943, kl=2.0862, beta=0.0000\n",
      "Batch 40, loss=0.0576, recon=0.0576, kl=2.3484, beta=0.0000\n",
      "Batch 60, loss=0.0860, recon=0.0859, kl=1.8398, beta=0.0000\n",
      "Batch 80, loss=0.0547, recon=0.0546, kl=2.0120, beta=0.0000\n",
      "Batch 100, loss=0.0469, recon=0.0469, kl=1.9421, beta=0.0000\n",
      "Batch 120, loss=0.1394, recon=0.1394, kl=1.7671, beta=0.0000\n",
      "Batch 140, loss=0.0630, recon=0.0630, kl=1.6730, beta=0.0000\n",
      "Batch 160, loss=0.0815, recon=0.0815, kl=1.4171, beta=0.0000\n",
      "Batch 180, loss=0.0728, recon=0.0728, kl=1.2838, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0830 (Recon: 0.0830, KL: 1.9612, Current Beta: 0.0000) | Avg Valid Loss: 0.0714 | Avg Valid recon Loss: 0.0714\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0516, recon=0.0516, kl=0.4376, beta=0.0000\n",
      "Batch 40, loss=0.0567, recon=0.0567, kl=0.4314, beta=0.0000\n",
      "Batch 60, loss=0.0446, recon=0.0446, kl=0.4811, beta=0.0000\n",
      "Batch 80, loss=0.0493, recon=0.0493, kl=0.3732, beta=0.0000\n",
      "Batch 100, loss=0.1601, recon=0.1601, kl=0.4439, beta=0.0000\n",
      "Batch 120, loss=0.2286, recon=0.2286, kl=0.3463, beta=0.0000\n",
      "Batch 140, loss=0.0550, recon=0.0550, kl=0.3283, beta=0.0000\n",
      "Batch 160, loss=0.0602, recon=0.0602, kl=0.2367, beta=0.0000\n",
      "Batch 180, loss=0.0353, recon=0.0353, kl=0.5108, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0783 (Recon: 0.0782, KL: 0.4277, Current Beta: 0.0000) | Avg Valid Loss: 0.0676 | Avg Valid recon Loss: 0.0676\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0749, recon=0.0749, kl=0.0763, beta=0.0001\n",
      "Batch 40, loss=0.0853, recon=0.0853, kl=0.0539, beta=0.0001\n",
      "Batch 60, loss=0.0550, recon=0.0550, kl=0.0438, beta=0.0001\n",
      "Batch 80, loss=0.0590, recon=0.0590, kl=0.0290, beta=0.0001\n",
      "Batch 100, loss=0.0521, recon=0.0521, kl=0.0458, beta=0.0001\n",
      "Batch 120, loss=0.0569, recon=0.0569, kl=0.0265, beta=0.0001\n",
      "Batch 140, loss=0.0971, recon=0.0971, kl=0.0212, beta=0.0001\n",
      "Batch 160, loss=0.0412, recon=0.0412, kl=0.0220, beta=0.0001\n",
      "Batch 180, loss=0.0380, recon=0.0380, kl=0.0149, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0740 (Recon: 0.0740, KL: 0.0613, Current Beta: 0.0001) | Avg Valid Loss: 0.0640 | Avg Valid recon Loss: 0.0640\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1968, recon=0.1968, kl=0.0035, beta=0.0003\n",
      "Batch 40, loss=0.0330, recon=0.0330, kl=0.0019, beta=0.0003\n",
      "Batch 60, loss=0.0571, recon=0.0571, kl=0.0043, beta=0.0003\n",
      "Batch 80, loss=0.0590, recon=0.0590, kl=0.0039, beta=0.0003\n",
      "Batch 100, loss=0.0360, recon=0.0360, kl=0.0041, beta=0.0003\n",
      "Batch 120, loss=0.0537, recon=0.0537, kl=0.0023, beta=0.0003\n",
      "Batch 140, loss=0.0841, recon=0.0841, kl=0.0017, beta=0.0003\n",
      "Batch 160, loss=0.0912, recon=0.0912, kl=0.0015, beta=0.0003\n",
      "Batch 180, loss=0.0593, recon=0.0593, kl=0.0012, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0710 (Recon: 0.0710, KL: 0.0037, Current Beta: 0.0003) | Avg Valid Loss: 0.0615 | Avg Valid recon Loss: 0.0615\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0461, recon=0.0461, kl=0.0003, beta=0.0008\n",
      "Batch 40, loss=0.0517, recon=0.0517, kl=0.0005, beta=0.0008\n",
      "Batch 60, loss=0.0547, recon=0.0547, kl=0.0004, beta=0.0008\n",
      "Batch 80, loss=0.0371, recon=0.0371, kl=0.0005, beta=0.0008\n",
      "Batch 100, loss=0.0513, recon=0.0513, kl=0.0011, beta=0.0008\n",
      "Batch 120, loss=0.0461, recon=0.0461, kl=0.0007, beta=0.0008\n",
      "Batch 140, loss=0.0443, recon=0.0443, kl=0.0007, beta=0.0008\n",
      "Batch 160, loss=0.0455, recon=0.0455, kl=0.0007, beta=0.0008\n",
      "Batch 180, loss=0.0562, recon=0.0562, kl=0.0004, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0681 (Recon: 0.0681, KL: 0.0006, Current Beta: 0.0008) | Avg Valid Loss: 0.0599 | Avg Valid recon Loss: 0.0599\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0416, recon=0.0416, kl=0.0002, beta=0.0018\n",
      "Batch 40, loss=0.0359, recon=0.0359, kl=0.0002, beta=0.0018\n",
      "Batch 60, loss=0.0483, recon=0.0483, kl=0.0002, beta=0.0018\n",
      "Batch 80, loss=0.0496, recon=0.0496, kl=0.0001, beta=0.0018\n",
      "Batch 100, loss=0.0434, recon=0.0434, kl=0.0003, beta=0.0018\n",
      "Batch 120, loss=0.0705, recon=0.0705, kl=0.0002, beta=0.0018\n",
      "Batch 140, loss=0.0488, recon=0.0488, kl=0.0002, beta=0.0018\n",
      "Batch 160, loss=0.0350, recon=0.0350, kl=0.0001, beta=0.0018\n",
      "Batch 180, loss=0.0410, recon=0.0410, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0657 (Recon: 0.0657, KL: 0.0003, Current Beta: 0.0018) | Avg Valid Loss: 0.0577 | Avg Valid recon Loss: 0.0577\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0295, recon=0.0295, kl=0.0003, beta=0.0038\n",
      "Batch 40, loss=0.0531, recon=0.0531, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.0333, recon=0.0333, kl=0.0000, beta=0.0038\n",
      "Batch 80, loss=0.0560, recon=0.0560, kl=0.0000, beta=0.0038\n",
      "Batch 100, loss=0.0368, recon=0.0368, kl=0.0002, beta=0.0038\n",
      "Batch 120, loss=0.0458, recon=0.0458, kl=0.0002, beta=0.0038\n",
      "Batch 140, loss=0.0337, recon=0.0337, kl=0.0000, beta=0.0038\n",
      "Batch 160, loss=0.0446, recon=0.0446, kl=0.0000, beta=0.0038\n",
      "Batch 180, loss=0.0488, recon=0.0488, kl=0.0000, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0634 (Recon: 0.0634, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0556 | Avg Valid recon Loss: 0.0556\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0506, recon=0.0506, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0423, recon=0.0423, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0546, recon=0.0546, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0444, recon=0.0444, kl=0.0000, beta=0.0062\n",
      "Batch 100, loss=0.0533, recon=0.0533, kl=0.0001, beta=0.0062\n",
      "Batch 120, loss=0.0540, recon=0.0540, kl=0.0000, beta=0.0062\n",
      "Batch 140, loss=0.0420, recon=0.0420, kl=0.0000, beta=0.0062\n",
      "Batch 160, loss=0.0347, recon=0.0347, kl=0.0000, beta=0.0062\n",
      "Batch 180, loss=0.0695, recon=0.0695, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0615 (Recon: 0.0615, KL: 0.0000, Current Beta: 0.0062) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0537\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0246, recon=0.0246, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0311, recon=0.0311, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0530, recon=0.0530, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.1805, recon=0.1805, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0437, recon=0.0437, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0360, recon=0.0360, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.1352, recon=0.1352, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0383, recon=0.0383, kl=0.0004, beta=0.0100\n",
      "Batch 180, loss=0.0337, recon=0.0337, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0597 (Recon: 0.0597, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0525 | Avg Valid recon Loss: 0.0525\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0578, recon=0.0578, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0542, recon=0.0542, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0408, recon=0.0408, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0330, recon=0.0330, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0463, recon=0.0463, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0451, recon=0.0451, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0381, recon=0.0381, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0343, recon=0.0343, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0528, recon=0.0528, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0581, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0514 | Avg Valid recon Loss: 0.0514\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0737, recon=0.0737, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0401, recon=0.0401, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0548, recon=0.0548, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0291, recon=0.0291, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=1.0448, recon=1.0448, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.1365, recon=0.1365, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0813, recon=0.0813, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0426, recon=0.0426, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0431, recon=0.0431, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0568 (Recon: 0.0568, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0497 | Avg Valid recon Loss: 0.0497\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0321, recon=0.0321, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0377, recon=0.0377, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0362, recon=0.0362, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0444, recon=0.0444, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0346, recon=0.0346, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0362, recon=0.0362, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0363, recon=0.0363, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0376, recon=0.0376, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0443, recon=0.0443, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0556 (Recon: 0.0556, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0492 | Avg Valid recon Loss: 0.0492\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0319, recon=0.0319, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0421, recon=0.0421, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0286, recon=0.0286, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0301, recon=0.0301, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0259, recon=0.0259, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0427, recon=0.0427, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0310, recon=0.0310, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0423, recon=0.0423, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0306, recon=0.0306, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0544 (Recon: 0.0544, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0480\n",
      "\n",
      "[VRAE Run 76/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1702, recon=0.1702, kl=20.9874, beta=0.0000\n",
      "Batch 40, loss=0.1449, recon=0.1449, kl=47.7786, beta=0.0000\n",
      "Batch 60, loss=0.1453, recon=0.1453, kl=48.1127, beta=0.0000\n",
      "Batch 80, loss=0.1068, recon=0.1068, kl=54.3681, beta=0.0000\n",
      "Batch 100, loss=0.1707, recon=0.1707, kl=46.8926, beta=0.0000\n",
      "Batch 120, loss=0.0733, recon=0.0733, kl=42.3568, beta=0.0000\n",
      "Batch 140, loss=0.0634, recon=0.0634, kl=47.9853, beta=0.0000\n",
      "Batch 160, loss=0.0813, recon=0.0813, kl=54.9689, beta=0.0000\n",
      "Batch 180, loss=0.0686, recon=0.0686, kl=58.1638, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1840 (Recon: 0.1840, KL: 43.8043, Current Beta: 0.0000) | Avg Valid Loss: 0.0749 | Avg Valid recon Loss: 0.0749\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0834, recon=0.0834, kl=60.0572, beta=0.0000\n",
      "Batch 40, loss=0.0360, recon=0.0360, kl=58.9454, beta=0.0000\n",
      "Batch 60, loss=0.0514, recon=0.0514, kl=59.9701, beta=0.0000\n",
      "Batch 80, loss=0.0479, recon=0.0479, kl=58.0210, beta=0.0000\n",
      "Batch 100, loss=0.0563, recon=0.0563, kl=50.8569, beta=0.0000\n",
      "Batch 120, loss=0.0357, recon=0.0357, kl=48.1661, beta=0.0000\n",
      "Batch 140, loss=0.0710, recon=0.0710, kl=50.7255, beta=0.0000\n",
      "Batch 160, loss=0.1348, recon=0.1348, kl=56.9353, beta=0.0000\n",
      "Batch 180, loss=0.3648, recon=0.3648, kl=58.7894, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0763 (Recon: 0.0763, KL: 56.1025, Current Beta: 0.0000) | Avg Valid Loss: 0.0778 | Avg Valid recon Loss: 0.0778\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0534, recon=0.0534, kl=61.2831, beta=0.0000\n",
      "Batch 40, loss=0.0540, recon=0.0540, kl=56.9477, beta=0.0000\n",
      "Batch 60, loss=0.0426, recon=0.0426, kl=57.8841, beta=0.0000\n",
      "Batch 80, loss=0.0289, recon=0.0289, kl=57.2679, beta=0.0000\n",
      "Batch 100, loss=0.0392, recon=0.0392, kl=56.9069, beta=0.0000\n",
      "Batch 120, loss=0.1659, recon=0.1658, kl=57.6245, beta=0.0000\n",
      "Batch 140, loss=0.0621, recon=0.0621, kl=57.9363, beta=0.0000\n",
      "Batch 160, loss=0.0430, recon=0.0430, kl=56.6434, beta=0.0000\n",
      "Batch 180, loss=0.0477, recon=0.0477, kl=51.6818, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0688 (Recon: 0.0688, KL: 57.4309, Current Beta: 0.0000) | Avg Valid Loss: 0.0546 | Avg Valid recon Loss: 0.0546\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0425, recon=0.0425, kl=46.7672, beta=0.0000\n",
      "Batch 40, loss=0.0290, recon=0.0290, kl=45.7974, beta=0.0000\n",
      "Batch 60, loss=0.0340, recon=0.0340, kl=45.0820, beta=0.0000\n",
      "Batch 80, loss=0.1239, recon=0.1239, kl=46.5465, beta=0.0000\n",
      "Batch 100, loss=0.0535, recon=0.0535, kl=44.9735, beta=0.0000\n",
      "Batch 120, loss=0.0334, recon=0.0333, kl=49.4982, beta=0.0000\n",
      "Batch 140, loss=0.1434, recon=0.1434, kl=51.3153, beta=0.0000\n",
      "Batch 160, loss=0.0407, recon=0.0407, kl=49.9059, beta=0.0000\n",
      "Batch 180, loss=0.0473, recon=0.0473, kl=49.2713, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0638 (Recon: 0.0638, KL: 47.7582, Current Beta: 0.0000) | Avg Valid Loss: 0.0581 | Avg Valid recon Loss: 0.0581\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0435, recon=0.0435, kl=42.3397, beta=0.0000\n",
      "Batch 40, loss=0.0382, recon=0.0382, kl=35.9813, beta=0.0000\n",
      "Batch 60, loss=0.0474, recon=0.0474, kl=31.6784, beta=0.0000\n",
      "Batch 80, loss=0.0397, recon=0.0397, kl=29.4573, beta=0.0000\n",
      "Batch 100, loss=0.1519, recon=0.1519, kl=29.3808, beta=0.0000\n",
      "Batch 120, loss=0.0531, recon=0.0530, kl=34.6467, beta=0.0000\n",
      "Batch 140, loss=0.0451, recon=0.0451, kl=34.1171, beta=0.0000\n",
      "Batch 160, loss=0.0765, recon=0.0765, kl=35.2681, beta=0.0000\n",
      "Batch 180, loss=0.0454, recon=0.0454, kl=33.1707, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0604 (Recon: 0.0604, KL: 34.6882, Current Beta: 0.0000) | Avg Valid Loss: 0.0489 | Avg Valid recon Loss: 0.0489\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0546, recon=0.0545, kl=24.8105, beta=0.0000\n",
      "Batch 40, loss=0.0424, recon=0.0424, kl=20.3585, beta=0.0000\n",
      "Batch 60, loss=0.0324, recon=0.0324, kl=24.9783, beta=0.0000\n",
      "Batch 80, loss=0.0579, recon=0.0578, kl=22.7623, beta=0.0000\n",
      "Batch 100, loss=0.0342, recon=0.0341, kl=20.3614, beta=0.0000\n",
      "Batch 120, loss=0.0849, recon=0.0849, kl=20.7526, beta=0.0000\n",
      "Batch 140, loss=0.0394, recon=0.0394, kl=20.0575, beta=0.0000\n",
      "Batch 160, loss=0.0482, recon=0.0482, kl=20.4511, beta=0.0000\n",
      "Batch 180, loss=0.0452, recon=0.0451, kl=20.6246, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 22.2563, Current Beta: 0.0000) | Avg Valid Loss: 0.0486 | Avg Valid recon Loss: 0.0486\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0482, recon=0.0481, kl=10.7854, beta=0.0000\n",
      "Batch 40, loss=0.0416, recon=0.0416, kl=9.4076, beta=0.0000\n",
      "Batch 60, loss=0.0362, recon=0.0361, kl=11.0126, beta=0.0000\n",
      "Batch 80, loss=0.0600, recon=0.0599, kl=8.2311, beta=0.0000\n",
      "Batch 100, loss=0.0448, recon=0.0448, kl=7.6583, beta=0.0000\n",
      "Batch 120, loss=0.0502, recon=0.0501, kl=21.7286, beta=0.0000\n",
      "Batch 140, loss=0.0365, recon=0.0364, kl=21.6152, beta=0.0000\n",
      "Batch 160, loss=0.0349, recon=0.0348, kl=14.0494, beta=0.0000\n",
      "Batch 180, loss=0.0394, recon=0.0393, kl=12.0478, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0559 (Recon: 0.0558, KL: 13.4423, Current Beta: 0.0000) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0397, recon=0.0396, kl=5.5284, beta=0.0000\n",
      "Batch 40, loss=0.0413, recon=0.0413, kl=3.7348, beta=0.0000\n",
      "Batch 60, loss=0.0309, recon=0.0309, kl=4.8812, beta=0.0000\n",
      "Batch 80, loss=0.0262, recon=0.0262, kl=4.4367, beta=0.0000\n",
      "Batch 100, loss=0.0393, recon=0.0393, kl=2.8937, beta=0.0000\n",
      "Batch 120, loss=0.0350, recon=0.0350, kl=2.8268, beta=0.0000\n",
      "Batch 140, loss=0.0477, recon=0.0477, kl=1.9007, beta=0.0000\n",
      "Batch 160, loss=0.0253, recon=0.0253, kl=1.5623, beta=0.0000\n",
      "Batch 180, loss=0.0613, recon=0.0612, kl=2.2209, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 3.8008, Current Beta: 0.0000) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0372, recon=0.0372, kl=0.7901, beta=0.0000\n",
      "Batch 40, loss=0.0454, recon=0.0454, kl=0.4437, beta=0.0000\n",
      "Batch 60, loss=0.0350, recon=0.0350, kl=0.5519, beta=0.0000\n",
      "Batch 80, loss=0.0343, recon=0.0343, kl=0.6742, beta=0.0000\n",
      "Batch 100, loss=0.0291, recon=0.0291, kl=1.4685, beta=0.0000\n",
      "Batch 120, loss=0.0294, recon=0.0293, kl=1.7856, beta=0.0000\n",
      "Batch 140, loss=0.0270, recon=0.0269, kl=1.0817, beta=0.0000\n",
      "Batch 160, loss=0.0501, recon=0.0501, kl=0.7895, beta=0.0000\n",
      "Batch 180, loss=0.0390, recon=0.0390, kl=0.4801, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0493, KL: 0.9755, Current Beta: 0.0000) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0640, recon=0.0640, kl=0.0517, beta=0.0001\n",
      "Batch 40, loss=0.0385, recon=0.0385, kl=0.0392, beta=0.0001\n",
      "Batch 60, loss=0.0377, recon=0.0377, kl=0.0261, beta=0.0001\n",
      "Batch 80, loss=0.0337, recon=0.0336, kl=1.7059, beta=0.0001\n",
      "Batch 100, loss=0.0265, recon=0.0259, kl=5.3699, beta=0.0001\n",
      "Batch 120, loss=0.0469, recon=0.0467, kl=2.5377, beta=0.0001\n",
      "Batch 140, loss=0.0717, recon=0.0711, kl=5.2922, beta=0.0001\n",
      "Batch 160, loss=0.0461, recon=0.0456, kl=4.5478, beta=0.0001\n",
      "Batch 180, loss=0.0339, recon=0.0335, kl=4.0814, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0499, KL: 2.4866, Current Beta: 0.0001) | Avg Valid Loss: 0.0416 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0410, recon=0.0404, kl=1.9523, beta=0.0003\n",
      "Batch 40, loss=0.0284, recon=0.0281, kl=1.1906, beta=0.0003\n",
      "Batch 60, loss=0.0427, recon=0.0425, kl=0.6358, beta=0.0003\n",
      "Batch 80, loss=0.0447, recon=0.0435, kl=3.9351, beta=0.0003\n",
      "Batch 100, loss=0.0513, recon=0.0495, kl=6.1226, beta=0.0003\n",
      "Batch 120, loss=0.0383, recon=0.0368, kl=5.1057, beta=0.0003\n",
      "Batch 140, loss=0.0487, recon=0.0475, kl=4.0686, beta=0.0003\n",
      "Batch 160, loss=0.0399, recon=0.0389, kl=3.3776, beta=0.0003\n",
      "Batch 180, loss=0.0316, recon=0.0306, kl=3.1759, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0500 (Recon: 0.0491, KL: 3.2943, Current Beta: 0.0003) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0592, recon=0.0576, kl=2.1055, beta=0.0008\n",
      "Batch 40, loss=0.0394, recon=0.0378, kl=2.1066, beta=0.0008\n",
      "Batch 60, loss=0.0342, recon=0.0330, kl=1.5501, beta=0.0008\n",
      "Batch 80, loss=0.1640, recon=0.1634, kl=0.7790, beta=0.0008\n",
      "Batch 100, loss=0.0304, recon=0.0302, kl=0.2489, beta=0.0008\n",
      "Batch 120, loss=0.0456, recon=0.0442, kl=1.8431, beta=0.0008\n",
      "Batch 140, loss=0.0481, recon=0.0469, kl=1.6288, beta=0.0008\n",
      "Batch 160, loss=0.0991, recon=0.0983, kl=1.1003, beta=0.0008\n",
      "Batch 180, loss=0.0439, recon=0.0434, kl=0.7210, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0497, KL: 1.4367, Current Beta: 0.0008) | Avg Valid Loss: 0.0467 | Avg Valid recon Loss: 0.0461\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0417, recon=0.0410, kl=0.3679, beta=0.0018\n",
      "Batch 40, loss=0.0416, recon=0.0413, kl=0.1598, beta=0.0018\n",
      "Batch 60, loss=0.0572, recon=0.0571, kl=0.0658, beta=0.0018\n",
      "Batch 80, loss=0.0468, recon=0.0467, kl=0.0406, beta=0.0018\n",
      "Batch 100, loss=0.0568, recon=0.0568, kl=0.0364, beta=0.0018\n",
      "Batch 120, loss=0.0512, recon=0.0511, kl=0.0266, beta=0.0018\n",
      "Batch 140, loss=0.0413, recon=0.0413, kl=0.0315, beta=0.0018\n",
      "Batch 160, loss=0.0496, recon=0.0496, kl=0.0207, beta=0.0018\n",
      "Batch 180, loss=0.0522, recon=0.0521, kl=0.0122, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0532 (Recon: 0.0529, KL: 0.1220, Current Beta: 0.0018) | Avg Valid Loss: 0.0414 | Avg Valid recon Loss: 0.0414\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0308, recon=0.0307, kl=0.0041, beta=0.0038\n",
      "Batch 40, loss=0.0356, recon=0.0356, kl=0.0105, beta=0.0038\n",
      "Batch 60, loss=0.0312, recon=0.0312, kl=0.0012, beta=0.0038\n",
      "Batch 80, loss=0.0901, recon=0.0901, kl=0.0021, beta=0.0038\n",
      "Batch 100, loss=0.0531, recon=0.0531, kl=0.0032, beta=0.0038\n",
      "Batch 120, loss=0.0302, recon=0.0302, kl=0.0010, beta=0.0038\n",
      "Batch 140, loss=0.0253, recon=0.0253, kl=0.0017, beta=0.0038\n",
      "Batch 160, loss=0.0339, recon=0.0339, kl=0.0011, beta=0.0038\n",
      "Batch 180, loss=0.0486, recon=0.0486, kl=0.0006, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0502, KL: 0.0040, Current Beta: 0.0038) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0446, recon=0.0446, kl=0.0006, beta=0.0062\n",
      "Batch 40, loss=0.0377, recon=0.0377, kl=0.0005, beta=0.0062\n",
      "Batch 60, loss=0.0292, recon=0.0292, kl=0.0007, beta=0.0062\n",
      "Batch 80, loss=0.0596, recon=0.0596, kl=0.0043, beta=0.0062\n",
      "Batch 100, loss=0.0431, recon=0.0431, kl=0.0011, beta=0.0062\n",
      "Batch 120, loss=0.0405, recon=0.0405, kl=0.0013, beta=0.0062\n",
      "Batch 140, loss=0.0425, recon=0.0425, kl=0.0012, beta=0.0062\n",
      "Batch 160, loss=0.0463, recon=0.0463, kl=0.0011, beta=0.0062\n",
      "Batch 180, loss=0.0382, recon=0.0382, kl=0.0006, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0524, KL: 0.0031, Current Beta: 0.0062) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0477\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0601, recon=0.0601, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0783, recon=0.0783, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0400, recon=0.0400, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0515, recon=0.0515, kl=0.0004, beta=0.0100\n",
      "Batch 100, loss=0.0412, recon=0.0412, kl=0.0007, beta=0.0100\n",
      "Batch 120, loss=0.0306, recon=0.0305, kl=0.0027, beta=0.0100\n",
      "Batch 140, loss=0.0331, recon=0.0331, kl=0.0003, beta=0.0100\n",
      "Batch 160, loss=0.1219, recon=0.1219, kl=0.0007, beta=0.0100\n",
      "Batch 180, loss=0.0388, recon=0.0388, kl=0.0017, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0511 (Recon: 0.0511, KL: 0.0018, Current Beta: 0.0100) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0448\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1489, recon=0.1489, kl=0.0019, beta=0.0100\n",
      "Batch 40, loss=0.0606, recon=0.0606, kl=0.0006, beta=0.0100\n",
      "Batch 60, loss=0.0425, recon=0.0425, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0439, recon=0.0439, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0446, recon=0.0446, kl=0.0003, beta=0.0100\n",
      "Batch 120, loss=0.0398, recon=0.0398, kl=0.0007, beta=0.0100\n",
      "Batch 140, loss=0.0258, recon=0.0258, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0805, recon=0.0805, kl=0.0003, beta=0.0100\n",
      "Batch 180, loss=0.0484, recon=0.0483, kl=0.0032, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0498 (Recon: 0.0498, KL: 0.0012, Current Beta: 0.0100) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0455, recon=0.0455, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0380, recon=0.0380, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.0306, recon=0.0306, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0260, recon=0.0260, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0314, recon=0.0314, kl=0.0003, beta=0.0100\n",
      "Batch 120, loss=0.0621, recon=0.0621, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0318, recon=0.0317, kl=0.0023, beta=0.0100\n",
      "Batch 160, loss=0.0324, recon=0.0324, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0322, recon=0.0322, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0463, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0442 | Avg Valid recon Loss: 0.0442\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0448, recon=0.0448, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0329, recon=0.0329, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0395, recon=0.0395, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0542, recon=0.0542, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0486, recon=0.0486, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0415, recon=0.0415, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0308, recon=0.0308, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0354, recon=0.0354, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0462, recon=0.0462, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0499 (Recon: 0.0499, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0546, recon=0.0546, kl=0.0032, beta=0.0100\n",
      "Batch 40, loss=0.0276, recon=0.0276, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0617, recon=0.0616, kl=0.0038, beta=0.0100\n",
      "Batch 80, loss=0.0424, recon=0.0424, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.1044, recon=0.1043, kl=0.0015, beta=0.0100\n",
      "Batch 120, loss=0.0308, recon=0.0308, kl=0.0011, beta=0.0100\n",
      "Batch 140, loss=0.0513, recon=0.0513, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0448, recon=0.0448, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0255, recon=0.0255, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0464 (Recon: 0.0464, KL: 0.0013, Current Beta: 0.0100) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "\n",
      "[VRAE Run 77/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5882, recon=0.5882, kl=0.8253, beta=0.0000\n",
      "Batch 40, loss=0.5203, recon=0.5203, kl=2.3800, beta=0.0000\n",
      "Batch 60, loss=0.3147, recon=0.3147, kl=16.2601, beta=0.0000\n",
      "Batch 80, loss=0.2688, recon=0.2688, kl=35.7610, beta=0.0000\n",
      "Batch 100, loss=0.4005, recon=0.4005, kl=50.3672, beta=0.0000\n",
      "Batch 120, loss=0.3544, recon=0.3544, kl=59.7278, beta=0.0000\n",
      "Batch 140, loss=0.2958, recon=0.2958, kl=66.5256, beta=0.0000\n",
      "Batch 160, loss=0.2089, recon=0.2089, kl=70.7491, beta=0.0000\n",
      "Batch 180, loss=0.1483, recon=0.1483, kl=74.6616, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4091 (Recon: 0.4091, KL: 38.0397, Current Beta: 0.0000) | Avg Valid Loss: 0.2270 | Avg Valid recon Loss: 0.2270\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2419, recon=0.2419, kl=78.5535, beta=0.0000\n",
      "Batch 40, loss=0.1684, recon=0.1684, kl=82.0095, beta=0.0000\n",
      "Batch 60, loss=0.3573, recon=0.3573, kl=84.8386, beta=0.0000\n",
      "Batch 80, loss=0.2130, recon=0.2130, kl=87.4583, beta=0.0000\n",
      "Batch 100, loss=0.1593, recon=0.1593, kl=90.0387, beta=0.0000\n",
      "Batch 120, loss=0.2667, recon=0.2667, kl=92.6810, beta=0.0000\n",
      "Batch 140, loss=0.1128, recon=0.1128, kl=94.6495, beta=0.0000\n",
      "Batch 160, loss=0.1204, recon=0.1204, kl=96.1883, beta=0.0000\n",
      "Batch 180, loss=0.1057, recon=0.1057, kl=98.1833, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2115 (Recon: 0.2115, KL: 88.4192, Current Beta: 0.0000) | Avg Valid Loss: 0.1479 | Avg Valid recon Loss: 0.1479\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1363, recon=0.1363, kl=99.5378, beta=0.0000\n",
      "Batch 40, loss=0.1212, recon=0.1212, kl=99.0909, beta=0.0000\n",
      "Batch 60, loss=0.1188, recon=0.1188, kl=99.2743, beta=0.0000\n",
      "Batch 80, loss=0.1167, recon=0.1167, kl=99.0980, beta=0.0000\n",
      "Batch 100, loss=0.1522, recon=0.1522, kl=99.2393, beta=0.0000\n",
      "Batch 120, loss=0.0825, recon=0.0825, kl=99.2410, beta=0.0000\n",
      "Batch 140, loss=0.0772, recon=0.0772, kl=99.8069, beta=0.0000\n",
      "Batch 160, loss=0.0971, recon=0.0971, kl=99.4867, beta=0.0000\n",
      "Batch 180, loss=0.1052, recon=0.1052, kl=100.0604, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1568 (Recon: 0.1568, KL: 99.3488, Current Beta: 0.0000) | Avg Valid Loss: 0.1154 | Avg Valid recon Loss: 0.1154\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0833, recon=0.0832, kl=97.8545, beta=0.0000\n",
      "Batch 40, loss=0.2243, recon=0.2243, kl=93.9020, beta=0.0000\n",
      "Batch 60, loss=0.1067, recon=0.1066, kl=90.4363, beta=0.0000\n",
      "Batch 80, loss=0.1276, recon=0.1276, kl=87.3182, beta=0.0000\n",
      "Batch 100, loss=0.0742, recon=0.0742, kl=84.8713, beta=0.0000\n",
      "Batch 120, loss=0.1096, recon=0.1095, kl=84.2568, beta=0.0000\n",
      "Batch 140, loss=0.0839, recon=0.0839, kl=83.3100, beta=0.0000\n",
      "Batch 160, loss=0.0678, recon=0.0678, kl=81.7295, beta=0.0000\n",
      "Batch 180, loss=0.1537, recon=0.1537, kl=82.0331, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1257 (Recon: 0.1257, KL: 88.1648, Current Beta: 0.0000) | Avg Valid Loss: 0.0969 | Avg Valid recon Loss: 0.0968\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0768, recon=0.0767, kl=74.1652, beta=0.0000\n",
      "Batch 40, loss=0.1180, recon=0.1179, kl=61.6133, beta=0.0000\n",
      "Batch 60, loss=0.0639, recon=0.0638, kl=57.5577, beta=0.0000\n",
      "Batch 80, loss=0.0749, recon=0.0749, kl=53.9950, beta=0.0000\n",
      "Batch 100, loss=1.8014, recon=1.8014, kl=52.0489, beta=0.0000\n",
      "Batch 120, loss=0.1099, recon=0.1098, kl=48.5098, beta=0.0000\n",
      "Batch 140, loss=0.0517, recon=0.0517, kl=49.1227, beta=0.0000\n",
      "Batch 160, loss=0.0604, recon=0.0603, kl=48.1347, beta=0.0000\n",
      "Batch 180, loss=0.1117, recon=0.1116, kl=45.5293, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1073 (Recon: 0.1073, KL: 56.4442, Current Beta: 0.0000) | Avg Valid Loss: 0.0866 | Avg Valid recon Loss: 0.0865\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0718, recon=0.0717, kl=28.8901, beta=0.0000\n",
      "Batch 40, loss=0.1011, recon=0.1011, kl=24.4742, beta=0.0000\n",
      "Batch 60, loss=0.0638, recon=0.0637, kl=23.2826, beta=0.0000\n",
      "Batch 80, loss=0.0595, recon=0.0595, kl=22.0430, beta=0.0000\n",
      "Batch 100, loss=0.0808, recon=0.0807, kl=19.9999, beta=0.0000\n",
      "Batch 120, loss=0.0499, recon=0.0498, kl=21.3454, beta=0.0000\n",
      "Batch 140, loss=0.0683, recon=0.0682, kl=20.2042, beta=0.0000\n",
      "Batch 160, loss=0.0829, recon=0.0828, kl=18.1502, beta=0.0000\n",
      "Batch 180, loss=0.3367, recon=0.3367, kl=18.6941, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0956 (Recon: 0.0955, KL: 23.3422, Current Beta: 0.0000) | Avg Valid Loss: 0.0795 | Avg Valid recon Loss: 0.0794\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1338, recon=0.1337, kl=7.3375, beta=0.0000\n",
      "Batch 40, loss=0.0507, recon=0.0507, kl=7.7791, beta=0.0000\n",
      "Batch 60, loss=0.0758, recon=0.0757, kl=7.6734, beta=0.0000\n",
      "Batch 80, loss=0.0594, recon=0.0593, kl=7.0333, beta=0.0000\n",
      "Batch 100, loss=0.0896, recon=0.0896, kl=6.0604, beta=0.0000\n",
      "Batch 120, loss=0.0994, recon=0.0994, kl=5.7740, beta=0.0000\n",
      "Batch 140, loss=0.0599, recon=0.0598, kl=5.7609, beta=0.0000\n",
      "Batch 160, loss=0.0402, recon=0.0402, kl=5.2601, beta=0.0000\n",
      "Batch 180, loss=0.1078, recon=0.1078, kl=5.0291, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0873 (Recon: 0.0872, KL: 7.1700, Current Beta: 0.0000) | Avg Valid Loss: 0.0752 | Avg Valid recon Loss: 0.0752\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0833, recon=0.0833, kl=1.6909, beta=0.0000\n",
      "Batch 40, loss=0.0534, recon=0.0534, kl=2.4088, beta=0.0000\n",
      "Batch 60, loss=0.0749, recon=0.0748, kl=1.5531, beta=0.0000\n",
      "Batch 80, loss=0.0698, recon=0.0697, kl=1.5439, beta=0.0000\n",
      "Batch 100, loss=0.0576, recon=0.0576, kl=1.7706, beta=0.0000\n",
      "Batch 120, loss=0.0543, recon=0.0543, kl=1.1669, beta=0.0000\n",
      "Batch 140, loss=0.0736, recon=0.0736, kl=1.5182, beta=0.0000\n",
      "Batch 160, loss=0.0468, recon=0.0467, kl=1.1882, beta=0.0000\n",
      "Batch 180, loss=0.0522, recon=0.0522, kl=1.1224, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0813 (Recon: 0.0813, KL: 1.7491, Current Beta: 0.0000) | Avg Valid Loss: 0.0703 | Avg Valid recon Loss: 0.0703\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0556, recon=0.0556, kl=0.3284, beta=0.0000\n",
      "Batch 40, loss=0.0546, recon=0.0546, kl=0.4034, beta=0.0000\n",
      "Batch 60, loss=0.0777, recon=0.0777, kl=0.2659, beta=0.0000\n",
      "Batch 80, loss=0.0506, recon=0.0506, kl=0.2403, beta=0.0000\n",
      "Batch 100, loss=0.0725, recon=0.0724, kl=0.1848, beta=0.0000\n",
      "Batch 120, loss=0.0525, recon=0.0525, kl=0.2204, beta=0.0000\n",
      "Batch 140, loss=0.0841, recon=0.0841, kl=0.1372, beta=0.0000\n",
      "Batch 160, loss=0.0457, recon=0.0457, kl=0.1390, beta=0.0000\n",
      "Batch 180, loss=0.0423, recon=0.0423, kl=0.1496, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0766 (Recon: 0.0766, KL: 0.2767, Current Beta: 0.0000) | Avg Valid Loss: 0.0661 | Avg Valid recon Loss: 0.0661\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0536, recon=0.0536, kl=0.0362, beta=0.0001\n",
      "Batch 40, loss=0.0460, recon=0.0460, kl=0.0277, beta=0.0001\n",
      "Batch 60, loss=0.0562, recon=0.0562, kl=0.0224, beta=0.0001\n",
      "Batch 80, loss=0.0710, recon=0.0710, kl=0.0154, beta=0.0001\n",
      "Batch 100, loss=0.0663, recon=0.0663, kl=0.0132, beta=0.0001\n",
      "Batch 120, loss=0.1088, recon=0.1088, kl=0.0150, beta=0.0001\n",
      "Batch 140, loss=0.0355, recon=0.0355, kl=0.0079, beta=0.0001\n",
      "Batch 160, loss=0.0447, recon=0.0447, kl=0.0116, beta=0.0001\n",
      "Batch 180, loss=0.0576, recon=0.0576, kl=0.0101, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0726 (Recon: 0.0726, KL: 0.0232, Current Beta: 0.0001) | Avg Valid Loss: 0.0637 | Avg Valid recon Loss: 0.0637\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0654, recon=0.0654, kl=0.0014, beta=0.0003\n",
      "Batch 40, loss=0.0747, recon=0.0747, kl=0.0019, beta=0.0003\n",
      "Batch 60, loss=0.3262, recon=0.3262, kl=0.0019, beta=0.0003\n",
      "Batch 80, loss=0.0452, recon=0.0452, kl=0.0025, beta=0.0003\n",
      "Batch 100, loss=0.0413, recon=0.0413, kl=0.0015, beta=0.0003\n",
      "Batch 120, loss=0.0550, recon=0.0550, kl=0.0013, beta=0.0003\n",
      "Batch 140, loss=0.0493, recon=0.0493, kl=0.0030, beta=0.0003\n",
      "Batch 160, loss=0.0601, recon=0.0601, kl=0.0016, beta=0.0003\n",
      "Batch 180, loss=0.0486, recon=0.0486, kl=0.0011, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0697 (Recon: 0.0697, KL: 0.0023, Current Beta: 0.0003) | Avg Valid Loss: 0.0609 | Avg Valid recon Loss: 0.0609\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0364, recon=0.0364, kl=0.0008, beta=0.0008\n",
      "Batch 40, loss=0.0563, recon=0.0563, kl=0.0007, beta=0.0008\n",
      "Batch 60, loss=0.0532, recon=0.0532, kl=0.0006, beta=0.0008\n",
      "Batch 80, loss=0.0608, recon=0.0608, kl=0.0009, beta=0.0008\n",
      "Batch 100, loss=0.0560, recon=0.0560, kl=0.0006, beta=0.0008\n",
      "Batch 120, loss=0.0667, recon=0.0667, kl=0.0008, beta=0.0008\n",
      "Batch 140, loss=0.0412, recon=0.0412, kl=0.0005, beta=0.0008\n",
      "Batch 160, loss=0.0422, recon=0.0422, kl=0.0002, beta=0.0008\n",
      "Batch 180, loss=0.0368, recon=0.0368, kl=0.0004, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0668 (Recon: 0.0668, KL: 0.0006, Current Beta: 0.0008) | Avg Valid Loss: 0.0589 | Avg Valid recon Loss: 0.0589\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0575, recon=0.0575, kl=0.0002, beta=0.0018\n",
      "Batch 40, loss=0.0745, recon=0.0745, kl=0.0003, beta=0.0018\n",
      "Batch 60, loss=0.0611, recon=0.0611, kl=0.0003, beta=0.0018\n",
      "Batch 80, loss=0.0354, recon=0.0354, kl=0.0002, beta=0.0018\n",
      "Batch 100, loss=0.0701, recon=0.0701, kl=0.0002, beta=0.0018\n",
      "Batch 120, loss=0.0623, recon=0.0623, kl=0.0002, beta=0.0018\n",
      "Batch 140, loss=0.0382, recon=0.0382, kl=0.0001, beta=0.0018\n",
      "Batch 160, loss=0.0402, recon=0.0402, kl=0.0001, beta=0.0018\n",
      "Batch 180, loss=0.0517, recon=0.0517, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0649 (Recon: 0.0649, KL: 0.0003, Current Beta: 0.0018) | Avg Valid Loss: 0.0575 | Avg Valid recon Loss: 0.0575\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1960, recon=0.1960, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0429, recon=0.0429, kl=0.0003, beta=0.0038\n",
      "Batch 60, loss=0.0536, recon=0.0536, kl=0.0003, beta=0.0038\n",
      "Batch 80, loss=0.0567, recon=0.0567, kl=0.0001, beta=0.0038\n",
      "Batch 100, loss=0.0378, recon=0.0378, kl=0.0000, beta=0.0038\n",
      "Batch 120, loss=0.0624, recon=0.0624, kl=0.0000, beta=0.0038\n",
      "Batch 140, loss=0.0409, recon=0.0409, kl=0.0001, beta=0.0038\n",
      "Batch 160, loss=0.0287, recon=0.0287, kl=0.0001, beta=0.0038\n",
      "Batch 180, loss=0.0388, recon=0.0388, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0626 (Recon: 0.0626, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0553 | Avg Valid recon Loss: 0.0553\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0472, recon=0.0472, kl=0.0000, beta=0.0062\n",
      "Batch 40, loss=0.0785, recon=0.0785, kl=0.0004, beta=0.0062\n",
      "Batch 60, loss=0.0469, recon=0.0469, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0341, recon=0.0341, kl=0.0002, beta=0.0062\n",
      "Batch 100, loss=0.0677, recon=0.0677, kl=0.0003, beta=0.0062\n",
      "Batch 120, loss=0.0355, recon=0.0355, kl=0.0000, beta=0.0062\n",
      "Batch 140, loss=0.0744, recon=0.0744, kl=0.0000, beta=0.0062\n",
      "Batch 160, loss=0.0574, recon=0.0574, kl=0.0000, beta=0.0062\n",
      "Batch 180, loss=0.0626, recon=0.0626, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0609 (Recon: 0.0609, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0542 | Avg Valid recon Loss: 0.0542\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0356, recon=0.0356, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0631, recon=0.0631, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0364, recon=0.0364, kl=0.0003, beta=0.0100\n",
      "Batch 80, loss=0.0375, recon=0.0375, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0334, recon=0.0334, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0300, recon=0.0300, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0424, recon=0.0424, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0440, recon=0.0440, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0409, recon=0.0409, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0596 (Recon: 0.0596, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0527 | Avg Valid recon Loss: 0.0527\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0366, recon=0.0366, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0594, recon=0.0594, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0593, recon=0.0593, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0401, recon=0.0401, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0371, recon=0.0371, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0492, recon=0.0492, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0492, recon=0.0492, kl=0.0004, beta=0.0100\n",
      "Batch 160, loss=0.0432, recon=0.0432, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0499, recon=0.0499, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0581, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0751, recon=0.0751, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0310, recon=0.0310, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0600, recon=0.0600, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0333, recon=0.0333, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0280, recon=0.0280, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0383, recon=0.0383, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0393, recon=0.0393, kl=0.0002, beta=0.0100\n",
      "Batch 160, loss=0.0516, recon=0.0516, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0509, recon=0.0509, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0568 (Recon: 0.0568, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0505 | Avg Valid recon Loss: 0.0505\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0671, recon=0.0671, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0429, recon=0.0429, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0504, recon=0.0504, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0466, recon=0.0466, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0357, recon=0.0357, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0403, recon=0.0403, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0245, recon=0.0245, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.1605, recon=0.1605, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0415, recon=0.0415, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0491 | Avg Valid recon Loss: 0.0491\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0465, recon=0.0465, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0413, recon=0.0413, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0412, recon=0.0412, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0720, recon=0.0720, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0311, recon=0.0311, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0324, recon=0.0324, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0390, recon=0.0390, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0535, recon=0.0535, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.2025, recon=0.2025, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0544 (Recon: 0.0544, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0480\n",
      "\n",
      "[VRAE Run 78/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2335, recon=0.2335, kl=40.3406, beta=0.0000\n",
      "Batch 40, loss=0.1673, recon=0.1673, kl=70.3687, beta=0.0000\n",
      "Batch 60, loss=0.0951, recon=0.0951, kl=85.2991, beta=0.0000\n",
      "Batch 80, loss=0.0988, recon=0.0988, kl=88.3284, beta=0.0000\n",
      "Batch 100, loss=0.1974, recon=0.1974, kl=89.5581, beta=0.0000\n",
      "Batch 120, loss=0.1282, recon=0.1282, kl=108.9201, beta=0.0000\n",
      "Batch 140, loss=0.0521, recon=0.0521, kl=91.8132, beta=0.0000\n",
      "Batch 160, loss=0.0589, recon=0.0589, kl=104.2799, beta=0.0000\n",
      "Batch 180, loss=0.0562, recon=0.0562, kl=115.8194, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1817 (Recon: 0.1817, KL: 81.7684, Current Beta: 0.0000) | Avg Valid Loss: 0.0747 | Avg Valid recon Loss: 0.0747\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0578, recon=0.0578, kl=117.7301, beta=0.0000\n",
      "Batch 40, loss=0.0547, recon=0.0547, kl=104.4069, beta=0.0000\n",
      "Batch 60, loss=0.0903, recon=0.0903, kl=106.6707, beta=0.0000\n",
      "Batch 80, loss=0.1213, recon=0.1213, kl=99.1841, beta=0.0000\n",
      "Batch 100, loss=0.0606, recon=0.0605, kl=118.0258, beta=0.0000\n",
      "Batch 120, loss=0.0535, recon=0.0535, kl=132.8528, beta=0.0000\n",
      "Batch 140, loss=0.0416, recon=0.0416, kl=125.6988, beta=0.0000\n",
      "Batch 160, loss=0.0938, recon=0.0938, kl=111.8224, beta=0.0000\n",
      "Batch 180, loss=0.0702, recon=0.0702, kl=114.3706, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0807 (Recon: 0.0807, KL: 113.9239, Current Beta: 0.0000) | Avg Valid Loss: 0.0626 | Avg Valid recon Loss: 0.0626\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0530, recon=0.0530, kl=103.6647, beta=0.0000\n",
      "Batch 40, loss=0.0380, recon=0.0380, kl=96.0459, beta=0.0000\n",
      "Batch 60, loss=0.0472, recon=0.0471, kl=102.9461, beta=0.0000\n",
      "Batch 80, loss=0.0430, recon=0.0430, kl=103.6321, beta=0.0000\n",
      "Batch 100, loss=0.0340, recon=0.0340, kl=103.8602, beta=0.0000\n",
      "Batch 120, loss=0.0364, recon=0.0364, kl=105.3717, beta=0.0000\n",
      "Batch 140, loss=0.0352, recon=0.0352, kl=108.6534, beta=0.0000\n",
      "Batch 160, loss=0.0871, recon=0.0870, kl=102.3834, beta=0.0000\n",
      "Batch 180, loss=0.0936, recon=0.0936, kl=109.2216, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0656 (Recon: 0.0656, KL: 103.8487, Current Beta: 0.0000) | Avg Valid Loss: 0.0652 | Avg Valid recon Loss: 0.0652\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0381, recon=0.0381, kl=93.3114, beta=0.0000\n",
      "Batch 40, loss=0.0488, recon=0.0488, kl=85.2883, beta=0.0000\n",
      "Batch 60, loss=0.0946, recon=0.0946, kl=94.4051, beta=0.0000\n",
      "Batch 80, loss=0.0448, recon=0.0447, kl=89.2903, beta=0.0000\n",
      "Batch 100, loss=0.0525, recon=0.0525, kl=93.5569, beta=0.0000\n",
      "Batch 120, loss=0.0470, recon=0.0470, kl=89.1139, beta=0.0000\n",
      "Batch 140, loss=0.0722, recon=0.0722, kl=85.9184, beta=0.0000\n",
      "Batch 160, loss=0.0257, recon=0.0257, kl=86.7588, beta=0.0000\n",
      "Batch 180, loss=0.0717, recon=0.0717, kl=88.3786, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0659 (Recon: 0.0659, KL: 91.1751, Current Beta: 0.0000) | Avg Valid Loss: 0.0593 | Avg Valid recon Loss: 0.0592\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0484, recon=0.0484, kl=72.5488, beta=0.0000\n",
      "Batch 40, loss=0.0424, recon=0.0423, kl=75.7137, beta=0.0000\n",
      "Batch 60, loss=0.0731, recon=0.0730, kl=74.9981, beta=0.0000\n",
      "Batch 80, loss=0.0361, recon=0.0361, kl=74.8542, beta=0.0000\n",
      "Batch 100, loss=0.0697, recon=0.0696, kl=68.4722, beta=0.0000\n",
      "Batch 120, loss=0.0362, recon=0.0362, kl=69.8982, beta=0.0000\n",
      "Batch 140, loss=0.0683, recon=0.0683, kl=66.7850, beta=0.0000\n",
      "Batch 160, loss=0.2811, recon=0.2811, kl=65.4729, beta=0.0000\n",
      "Batch 180, loss=0.0972, recon=0.0972, kl=62.9768, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0587 (Recon: 0.0587, KL: 71.5311, Current Beta: 0.0000) | Avg Valid Loss: 0.0590 | Avg Valid recon Loss: 0.0589\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0610, recon=0.0609, kl=51.8773, beta=0.0000\n",
      "Batch 40, loss=0.0277, recon=0.0276, kl=45.5008, beta=0.0000\n",
      "Batch 60, loss=0.0329, recon=0.0328, kl=48.5305, beta=0.0000\n",
      "Batch 80, loss=0.0382, recon=0.0381, kl=53.2241, beta=0.0000\n",
      "Batch 100, loss=0.0784, recon=0.0783, kl=52.5810, beta=0.0000\n",
      "Batch 120, loss=0.0566, recon=0.0565, kl=47.1608, beta=0.0000\n",
      "Batch 140, loss=0.0705, recon=0.0704, kl=46.8202, beta=0.0000\n",
      "Batch 160, loss=0.1043, recon=0.1042, kl=57.4414, beta=0.0000\n",
      "Batch 180, loss=0.0543, recon=0.0542, kl=62.8889, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0588 (Recon: 0.0587, KL: 52.5182, Current Beta: 0.0000) | Avg Valid Loss: 0.0601 | Avg Valid recon Loss: 0.0600\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1990, recon=0.1988, kl=34.9783, beta=0.0000\n",
      "Batch 40, loss=0.0319, recon=0.0317, kl=30.2711, beta=0.0000\n",
      "Batch 60, loss=0.0356, recon=0.0353, kl=39.5367, beta=0.0000\n",
      "Batch 80, loss=0.0357, recon=0.0354, kl=61.5766, beta=0.0000\n",
      "Batch 100, loss=0.0460, recon=0.0457, kl=49.7757, beta=0.0000\n",
      "Batch 120, loss=0.0452, recon=0.0450, kl=38.6399, beta=0.0000\n",
      "Batch 140, loss=0.0504, recon=0.0502, kl=34.2885, beta=0.0000\n",
      "Batch 160, loss=0.0844, recon=0.0842, kl=31.9603, beta=0.0000\n",
      "Batch 180, loss=0.0396, recon=0.0394, kl=32.4154, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0578 (Recon: 0.0575, KL: 40.6947, Current Beta: 0.0000) | Avg Valid Loss: 0.0504 | Avg Valid recon Loss: 0.0503\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0439, recon=0.0437, kl=19.1185, beta=0.0000\n",
      "Batch 40, loss=0.0375, recon=0.0372, kl=20.5406, beta=0.0000\n",
      "Batch 60, loss=0.0467, recon=0.0464, kl=18.2159, beta=0.0000\n",
      "Batch 80, loss=0.0567, recon=0.0563, kl=26.6776, beta=0.0000\n",
      "Batch 100, loss=0.0355, recon=0.0348, kl=51.6342, beta=0.0000\n",
      "Batch 120, loss=0.0394, recon=0.0389, kl=38.3811, beta=0.0000\n",
      "Batch 140, loss=0.0338, recon=0.0333, kl=32.3293, beta=0.0000\n",
      "Batch 160, loss=0.0282, recon=0.0278, kl=23.1537, beta=0.0000\n",
      "Batch 180, loss=0.0369, recon=0.0366, kl=19.6502, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0556 (Recon: 0.0551, KL: 28.6747, Current Beta: 0.0000) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0363, recon=0.0359, kl=9.8866, beta=0.0000\n",
      "Batch 40, loss=0.0813, recon=0.0807, kl=16.8412, beta=0.0000\n",
      "Batch 60, loss=0.0421, recon=0.0416, kl=12.7797, beta=0.0000\n",
      "Batch 80, loss=0.1785, recon=0.1779, kl=14.5771, beta=0.0000\n",
      "Batch 100, loss=0.0403, recon=0.0393, kl=26.7128, beta=0.0000\n",
      "Batch 120, loss=0.0363, recon=0.0353, kl=22.8584, beta=0.0000\n",
      "Batch 140, loss=0.0393, recon=0.0384, kl=21.6094, beta=0.0000\n",
      "Batch 160, loss=0.0922, recon=0.0913, kl=21.7680, beta=0.0000\n",
      "Batch 180, loss=0.0468, recon=0.0461, kl=17.4502, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0558 (Recon: 0.0551, KL: 18.0511, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0445\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0370, recon=0.0358, kl=11.4250, beta=0.0001\n",
      "Batch 40, loss=0.0538, recon=0.0529, kl=7.9461, beta=0.0001\n",
      "Batch 60, loss=0.1798, recon=0.1791, kl=6.8631, beta=0.0001\n",
      "Batch 80, loss=0.0847, recon=0.0837, kl=9.0629, beta=0.0001\n",
      "Batch 100, loss=0.0476, recon=0.0455, kl=18.7633, beta=0.0001\n",
      "Batch 120, loss=0.1110, recon=0.1090, kl=18.7790, beta=0.0001\n",
      "Batch 140, loss=0.0670, recon=0.0653, kl=15.5479, beta=0.0001\n",
      "Batch 160, loss=0.0291, recon=0.0277, kl=12.3307, beta=0.0001\n",
      "Batch 180, loss=0.0348, recon=0.0333, kl=13.4347, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0575 (Recon: 0.0560, KL: 13.0848, Current Beta: 0.0001) | Avg Valid Loss: 0.0492 | Avg Valid recon Loss: 0.0476\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0352, recon=0.0327, kl=8.4247, beta=0.0003\n",
      "Batch 40, loss=0.0384, recon=0.0356, kl=9.5879, beta=0.0003\n",
      "Batch 60, loss=0.0585, recon=0.0553, kl=11.2308, beta=0.0003\n",
      "Batch 80, loss=0.1219, recon=0.1195, kl=8.0483, beta=0.0003\n",
      "Batch 100, loss=0.0329, recon=0.0308, kl=7.0574, beta=0.0003\n",
      "Batch 120, loss=0.0317, recon=0.0301, kl=5.5294, beta=0.0003\n",
      "Batch 140, loss=0.0381, recon=0.0368, kl=4.2578, beta=0.0003\n",
      "Batch 160, loss=0.0490, recon=0.0478, kl=4.3494, beta=0.0003\n",
      "Batch 180, loss=0.0406, recon=0.0391, kl=4.9653, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0511, KL: 7.5600, Current Beta: 0.0003) | Avg Valid Loss: 0.0437 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0595, recon=0.0566, kl=3.7888, beta=0.0008\n",
      "Batch 40, loss=0.0701, recon=0.0674, kl=3.4935, beta=0.0008\n",
      "Batch 60, loss=0.0342, recon=0.0314, kl=3.6194, beta=0.0008\n",
      "Batch 80, loss=0.0468, recon=0.0369, kl=12.9596, beta=0.0008\n",
      "Batch 100, loss=0.0511, recon=0.0346, kl=21.7591, beta=0.0008\n",
      "Batch 120, loss=0.0481, recon=0.0319, kl=21.2502, beta=0.0008\n",
      "Batch 140, loss=0.0424, recon=0.0284, kl=18.4649, beta=0.0008\n",
      "Batch 160, loss=0.0447, recon=0.0324, kl=16.2317, beta=0.0008\n",
      "Batch 180, loss=0.1504, recon=0.1396, kl=14.2522, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0686 (Recon: 0.0592, KL: 12.4100, Current Beta: 0.0008) | Avg Valid Loss: 0.0516 | Avg Valid recon Loss: 0.0428\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0482, recon=0.0362, kl=6.5809, beta=0.0018\n",
      "Batch 40, loss=0.0873, recon=0.0776, kl=5.3223, beta=0.0018\n",
      "Batch 60, loss=0.0757, recon=0.0625, kl=7.2565, beta=0.0018\n",
      "Batch 80, loss=0.1107, recon=0.0992, kl=6.2888, beta=0.0018\n",
      "Batch 100, loss=0.0522, recon=0.0439, kl=4.5424, beta=0.0018\n",
      "Batch 120, loss=0.0916, recon=0.0786, kl=7.1492, beta=0.0018\n",
      "Batch 140, loss=0.0535, recon=0.0378, kl=8.6177, beta=0.0018\n",
      "Batch 160, loss=0.0526, recon=0.0397, kl=7.1089, beta=0.0018\n",
      "Batch 180, loss=0.0453, recon=0.0352, kl=5.5512, beta=0.0018\n",
      "  â†’ Avg Train Loss: 6.4242 (Recon: 6.4121, KL: 6.6221, Current Beta: 0.0018) | Avg Valid Loss: 0.0571 | Avg Valid recon Loss: 0.0469\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0594, recon=0.0447, kl=3.9004, beta=0.0038\n",
      "Batch 40, loss=0.0516, recon=0.0410, kl=2.8210, beta=0.0038\n",
      "Batch 60, loss=0.0581, recon=0.0478, kl=2.7313, beta=0.0038\n",
      "Batch 80, loss=0.0604, recon=0.0482, kl=3.2448, beta=0.0038\n",
      "Batch 100, loss=0.0979, recon=0.0476, kl=13.3370, beta=0.0038\n",
      "Batch 120, loss=0.0865, recon=0.0371, kl=13.0880, beta=0.0038\n",
      "Batch 140, loss=0.0748, recon=0.0354, kl=10.4138, beta=0.0038\n",
      "Batch 160, loss=0.0672, recon=0.0336, kl=8.8856, beta=0.0038\n",
      "Batch 180, loss=0.0555, recon=0.0257, kl=7.9024, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1453 (Recon: 0.1174, KL: 7.3767, Current Beta: 0.0038) | Avg Valid Loss: 0.0741 | Avg Valid recon Loss: 0.0458\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1125, recon=0.0752, kl=5.9940, beta=0.0062\n",
      "Batch 40, loss=0.0763, recon=0.0467, kl=4.7455, beta=0.0062\n",
      "Batch 60, loss=0.0750, recon=0.0526, kl=3.5980, beta=0.0062\n",
      "Batch 80, loss=0.1073, recon=0.0606, kl=7.4945, beta=0.0062\n",
      "Batch 100, loss=0.0749, recon=0.0304, kl=7.1514, beta=0.0062\n",
      "Batch 120, loss=0.0887, recon=0.0453, kl=6.9691, beta=0.0062\n",
      "Batch 140, loss=0.0702, recon=0.0371, kl=5.3137, beta=0.0062\n",
      "Batch 160, loss=0.0772, recon=0.0512, kl=4.1820, beta=0.0062\n",
      "Batch 180, loss=0.0627, recon=0.0415, kl=3.4026, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.3833 (Recon: 0.3492, KL: 5.4692, Current Beta: 0.0062) | Avg Valid Loss: 0.0705 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1228, recon=0.0877, kl=3.5069, beta=0.0100\n",
      "Batch 40, loss=0.1052, recon=0.0587, kl=4.6454, beta=0.0100\n",
      "Batch 60, loss=0.0884, recon=0.0486, kl=3.9830, beta=0.0100\n",
      "Batch 80, loss=0.0771, recon=0.0499, kl=2.7202, beta=0.0100\n",
      "Batch 100, loss=0.0727, recon=0.0519, kl=2.0889, beta=0.0100\n",
      "Batch 120, loss=0.0734, recon=0.0571, kl=1.6305, beta=0.0100\n",
      "Batch 140, loss=0.1068, recon=0.0699, kl=3.6896, beta=0.0100\n",
      "Batch 160, loss=0.0789, recon=0.0431, kl=3.5753, beta=0.0100\n",
      "Batch 180, loss=0.0923, recon=0.0649, kl=2.7427, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1041 (Recon: 0.0712, KL: 3.2900, Current Beta: 0.0100) | Avg Valid Loss: 0.0812 | Avg Valid recon Loss: 0.0540\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0787, recon=0.0506, kl=2.8030, beta=0.0100\n",
      "Batch 40, loss=0.0754, recon=0.0477, kl=2.7635, beta=0.0100\n",
      "Batch 60, loss=0.0726, recon=0.0466, kl=2.6020, beta=0.0100\n",
      "Batch 80, loss=0.1322, recon=0.1085, kl=2.3701, beta=0.0100\n",
      "Batch 100, loss=0.0493, recon=0.0314, kl=1.7853, beta=0.0100\n",
      "Batch 120, loss=0.2132, recon=0.1987, kl=1.4529, beta=0.0100\n",
      "Batch 140, loss=0.1104, recon=0.0588, kl=5.1674, beta=0.0100\n",
      "Batch 160, loss=0.1503, recon=0.1041, kl=4.6222, beta=0.0100\n",
      "Batch 180, loss=0.0895, recon=0.0530, kl=3.6503, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1186 (Recon: 0.0882, KL: 3.0314, Current Beta: 0.0100) | Avg Valid Loss: 0.0913 | Avg Valid recon Loss: 0.0549\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0776, recon=0.0486, kl=2.8980, beta=0.0100\n",
      "Batch 40, loss=0.0723, recon=0.0492, kl=2.3120, beta=0.0100\n",
      "Batch 60, loss=0.0780, recon=0.0588, kl=1.9204, beta=0.0100\n",
      "Batch 80, loss=0.0538, recon=0.0370, kl=1.6773, beta=0.0100\n",
      "Batch 100, loss=0.0679, recon=0.0527, kl=1.5135, beta=0.0100\n",
      "Batch 120, loss=0.0917, recon=0.0657, kl=2.5937, beta=0.0100\n",
      "Batch 140, loss=0.0859, recon=0.0612, kl=2.4772, beta=0.0100\n",
      "Batch 160, loss=0.0573, recon=0.0364, kl=2.0867, beta=0.0100\n",
      "Batch 180, loss=0.0546, recon=0.0373, kl=1.7348, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0932 (Recon: 0.0710, KL: 2.2260, Current Beta: 0.0100) | Avg Valid Loss: 0.0674 | Avg Valid recon Loss: 0.0498\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0809, recon=0.0662, kl=1.4691, beta=0.0100\n",
      "Batch 40, loss=0.0590, recon=0.0471, kl=1.1897, beta=0.0100\n",
      "Batch 60, loss=0.0687, recon=0.0471, kl=2.1668, beta=0.0100\n",
      "Batch 80, loss=0.0740, recon=0.0489, kl=2.5059, beta=0.0100\n",
      "Batch 100, loss=0.1618, recon=0.1334, kl=2.8435, beta=0.0100\n",
      "Batch 120, loss=0.0648, recon=0.0415, kl=2.3286, beta=0.0100\n",
      "Batch 140, loss=0.0920, recon=0.0523, kl=3.9740, beta=0.0100\n",
      "Batch 160, loss=0.0831, recon=0.0430, kl=4.0088, beta=0.0100\n",
      "Batch 180, loss=0.0612, recon=0.0298, kl=3.1346, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0870 (Recon: 0.0616, KL: 2.5377, Current Beta: 0.0100) | Avg Valid Loss: 0.0777 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0772, recon=0.0516, kl=2.5646, beta=0.0100\n",
      "Batch 40, loss=0.0726, recon=0.0525, kl=2.0080, beta=0.0100\n",
      "Batch 60, loss=0.0454, recon=0.0291, kl=1.6323, beta=0.0100\n",
      "Batch 80, loss=0.2153, recon=0.1956, kl=1.9694, beta=0.0100\n",
      "Batch 100, loss=0.0521, recon=0.0385, kl=1.3607, beta=0.0100\n",
      "Batch 120, loss=0.0707, recon=0.0574, kl=1.3358, beta=0.0100\n",
      "Batch 140, loss=0.0386, recon=0.0268, kl=1.1831, beta=0.0100\n",
      "Batch 160, loss=0.0754, recon=0.0539, kl=2.1488, beta=0.0100\n",
      "Batch 180, loss=0.0828, recon=0.0476, kl=3.5269, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0803 (Recon: 0.0614, KL: 1.8983, Current Beta: 0.0100) | Avg Valid Loss: 0.0831 | Avg Valid recon Loss: 0.0476\n",
      "\n",
      "[VRAE Run 79/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3788, recon=0.3788, kl=0.3368, beta=0.0000\n",
      "Batch 40, loss=0.3531, recon=0.3531, kl=3.2068, beta=0.0000\n",
      "Batch 60, loss=0.2532, recon=0.2532, kl=11.3201, beta=0.0000\n",
      "Batch 80, loss=0.2467, recon=0.2467, kl=15.9904, beta=0.0000\n",
      "Batch 100, loss=0.2369, recon=0.2369, kl=19.3880, beta=0.0000\n",
      "Batch 120, loss=0.1516, recon=0.1516, kl=22.7594, beta=0.0000\n",
      "Batch 140, loss=0.1564, recon=0.1564, kl=24.4806, beta=0.0000\n",
      "Batch 160, loss=0.1760, recon=0.1760, kl=25.0930, beta=0.0000\n",
      "Batch 180, loss=0.1122, recon=0.1122, kl=26.3835, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3076 (Recon: 0.3076, KL: 15.2922, Current Beta: 0.0000) | Avg Valid Loss: 0.1381 | Avg Valid recon Loss: 0.1381\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1250, recon=0.1250, kl=28.0967, beta=0.0000\n",
      "Batch 40, loss=0.1417, recon=0.1417, kl=28.4503, beta=0.0000\n",
      "Batch 60, loss=0.1709, recon=0.1709, kl=29.3729, beta=0.0000\n",
      "Batch 80, loss=0.1090, recon=0.1090, kl=31.1285, beta=0.0000\n",
      "Batch 100, loss=0.0721, recon=0.0721, kl=32.2382, beta=0.0000\n",
      "Batch 120, loss=0.0837, recon=0.0837, kl=34.7502, beta=0.0000\n",
      "Batch 140, loss=0.1266, recon=0.1266, kl=36.5940, beta=0.0000\n",
      "Batch 160, loss=0.0993, recon=0.0993, kl=37.7993, beta=0.0000\n",
      "Batch 180, loss=0.1372, recon=0.1372, kl=36.4404, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1456 (Recon: 0.1456, KL: 32.2993, Current Beta: 0.0000) | Avg Valid Loss: 0.0978 | Avg Valid recon Loss: 0.0978\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1392, recon=0.1392, kl=37.9197, beta=0.0000\n",
      "Batch 40, loss=0.0895, recon=0.0895, kl=37.8977, beta=0.0000\n",
      "Batch 60, loss=0.0585, recon=0.0585, kl=36.2997, beta=0.0000\n",
      "Batch 80, loss=0.0905, recon=0.0905, kl=34.4474, beta=0.0000\n",
      "Batch 100, loss=0.0640, recon=0.0640, kl=34.8307, beta=0.0000\n",
      "Batch 120, loss=0.1271, recon=0.1271, kl=35.3054, beta=0.0000\n",
      "Batch 140, loss=0.0757, recon=0.0756, kl=36.5178, beta=0.0000\n",
      "Batch 160, loss=0.0656, recon=0.0656, kl=34.9599, beta=0.0000\n",
      "Batch 180, loss=0.2036, recon=0.2036, kl=34.3653, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1111 (Recon: 0.1111, KL: 35.9918, Current Beta: 0.0000) | Avg Valid Loss: 0.0810 | Avg Valid recon Loss: 0.0810\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0893, recon=0.0893, kl=36.4367, beta=0.0000\n",
      "Batch 40, loss=0.0509, recon=0.0509, kl=34.9255, beta=0.0000\n",
      "Batch 60, loss=0.0663, recon=0.0663, kl=36.0618, beta=0.0000\n",
      "Batch 80, loss=0.0697, recon=0.0696, kl=32.8439, beta=0.0000\n",
      "Batch 100, loss=0.0713, recon=0.0713, kl=29.9512, beta=0.0000\n",
      "Batch 120, loss=0.0871, recon=0.0871, kl=31.8553, beta=0.0000\n",
      "Batch 140, loss=0.0591, recon=0.0591, kl=32.7944, beta=0.0000\n",
      "Batch 160, loss=0.2567, recon=0.2567, kl=29.0208, beta=0.0000\n",
      "Batch 180, loss=0.0867, recon=0.0867, kl=28.0814, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0912 (Recon: 0.0912, KL: 32.9551, Current Beta: 0.0000) | Avg Valid Loss: 0.0709 | Avg Valid recon Loss: 0.0708\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0636, recon=0.0636, kl=25.1878, beta=0.0000\n",
      "Batch 40, loss=0.0615, recon=0.0615, kl=24.4768, beta=0.0000\n",
      "Batch 60, loss=0.0430, recon=0.0430, kl=21.8962, beta=0.0000\n",
      "Batch 80, loss=0.0856, recon=0.0856, kl=19.9247, beta=0.0000\n",
      "Batch 100, loss=0.1051, recon=0.1051, kl=19.8537, beta=0.0000\n",
      "Batch 120, loss=0.0555, recon=0.0555, kl=18.0559, beta=0.0000\n",
      "Batch 140, loss=0.0664, recon=0.0664, kl=18.0652, beta=0.0000\n",
      "Batch 160, loss=0.1112, recon=0.1112, kl=18.2306, beta=0.0000\n",
      "Batch 180, loss=0.0693, recon=0.0693, kl=18.3438, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0794 (Recon: 0.0794, KL: 21.0021, Current Beta: 0.0000) | Avg Valid Loss: 0.0655 | Avg Valid recon Loss: 0.0655\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0645, recon=0.0645, kl=13.5995, beta=0.0000\n",
      "Batch 40, loss=0.0489, recon=0.0489, kl=10.7621, beta=0.0000\n",
      "Batch 60, loss=0.0556, recon=0.0555, kl=10.0456, beta=0.0000\n",
      "Batch 80, loss=0.0453, recon=0.0452, kl=9.1949, beta=0.0000\n",
      "Batch 100, loss=0.0771, recon=0.0770, kl=9.8259, beta=0.0000\n",
      "Batch 120, loss=0.0517, recon=0.0517, kl=8.6691, beta=0.0000\n",
      "Batch 140, loss=0.0444, recon=0.0444, kl=8.7990, beta=0.0000\n",
      "Batch 160, loss=0.1030, recon=0.1029, kl=8.3257, beta=0.0000\n",
      "Batch 180, loss=0.0331, recon=0.0330, kl=9.4684, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0717 (Recon: 0.0716, KL: 10.1833, Current Beta: 0.0000) | Avg Valid Loss: 0.0608 | Avg Valid recon Loss: 0.0608\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0535, recon=0.0535, kl=5.5648, beta=0.0000\n",
      "Batch 40, loss=0.0487, recon=0.0486, kl=3.9566, beta=0.0000\n",
      "Batch 60, loss=0.0412, recon=0.0412, kl=4.2524, beta=0.0000\n",
      "Batch 80, loss=0.0403, recon=0.0403, kl=4.0015, beta=0.0000\n",
      "Batch 100, loss=0.0487, recon=0.0487, kl=4.3959, beta=0.0000\n",
      "Batch 120, loss=0.0365, recon=0.0365, kl=3.8711, beta=0.0000\n",
      "Batch 140, loss=0.0599, recon=0.0598, kl=3.5802, beta=0.0000\n",
      "Batch 160, loss=0.0391, recon=0.0390, kl=3.3471, beta=0.0000\n",
      "Batch 180, loss=0.0350, recon=0.0349, kl=4.1825, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0661 (Recon: 0.0660, KL: 4.4423, Current Beta: 0.0000) | Avg Valid Loss: 0.0570 | Avg Valid recon Loss: 0.0570\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0405, recon=0.0405, kl=1.4962, beta=0.0000\n",
      "Batch 40, loss=0.0825, recon=0.0824, kl=2.3252, beta=0.0000\n",
      "Batch 60, loss=0.0398, recon=0.0398, kl=1.3963, beta=0.0000\n",
      "Batch 80, loss=0.0718, recon=0.0718, kl=1.4287, beta=0.0000\n",
      "Batch 100, loss=0.0724, recon=0.0724, kl=1.2884, beta=0.0000\n",
      "Batch 120, loss=0.0410, recon=0.0410, kl=1.1681, beta=0.0000\n",
      "Batch 140, loss=0.0378, recon=0.0378, kl=1.7235, beta=0.0000\n",
      "Batch 160, loss=0.0579, recon=0.0579, kl=1.1482, beta=0.0000\n",
      "Batch 180, loss=0.0404, recon=0.0404, kl=1.3671, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0623 (Recon: 0.0623, KL: 1.6022, Current Beta: 0.0000) | Avg Valid Loss: 0.0551 | Avg Valid recon Loss: 0.0551\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0295, recon=0.0295, kl=0.4337, beta=0.0000\n",
      "Batch 40, loss=0.0375, recon=0.0375, kl=0.6892, beta=0.0000\n",
      "Batch 60, loss=0.0372, recon=0.0372, kl=0.3520, beta=0.0000\n",
      "Batch 80, loss=0.0328, recon=0.0327, kl=0.4769, beta=0.0000\n",
      "Batch 100, loss=0.0442, recon=0.0442, kl=0.4441, beta=0.0000\n",
      "Batch 120, loss=0.0332, recon=0.0332, kl=0.2911, beta=0.0000\n",
      "Batch 140, loss=0.0566, recon=0.0566, kl=0.2542, beta=0.0000\n",
      "Batch 160, loss=0.0411, recon=0.0411, kl=0.3751, beta=0.0000\n",
      "Batch 180, loss=0.0477, recon=0.0477, kl=0.4976, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0590 (Recon: 0.0590, KL: 0.4565, Current Beta: 0.0000) | Avg Valid Loss: 0.0522 | Avg Valid recon Loss: 0.0522\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0325, recon=0.0325, kl=0.0818, beta=0.0001\n",
      "Batch 40, loss=0.0415, recon=0.0415, kl=0.0516, beta=0.0001\n",
      "Batch 60, loss=0.0682, recon=0.0682, kl=0.0652, beta=0.0001\n",
      "Batch 80, loss=0.0507, recon=0.0507, kl=0.0223, beta=0.0001\n",
      "Batch 100, loss=0.0380, recon=0.0380, kl=0.0472, beta=0.0001\n",
      "Batch 120, loss=0.0306, recon=0.0306, kl=0.0189, beta=0.0001\n",
      "Batch 140, loss=0.0328, recon=0.0328, kl=0.0591, beta=0.0001\n",
      "Batch 160, loss=0.0328, recon=0.0328, kl=0.0315, beta=0.0001\n",
      "Batch 180, loss=0.0498, recon=0.0498, kl=0.0324, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0560 (Recon: 0.0560, KL: 0.0616, Current Beta: 0.0001) | Avg Valid Loss: 0.0506 | Avg Valid recon Loss: 0.0506\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0471, recon=0.0471, kl=0.0317, beta=0.0003\n",
      "Batch 40, loss=0.0514, recon=0.0514, kl=0.0088, beta=0.0003\n",
      "Batch 60, loss=0.0277, recon=0.0277, kl=0.0021, beta=0.0003\n",
      "Batch 80, loss=0.0363, recon=0.0363, kl=0.0035, beta=0.0003\n",
      "Batch 100, loss=0.0729, recon=0.0729, kl=0.0018, beta=0.0003\n",
      "Batch 120, loss=0.0471, recon=0.0471, kl=0.0063, beta=0.0003\n",
      "Batch 140, loss=0.0461, recon=0.0461, kl=0.0032, beta=0.0003\n",
      "Batch 160, loss=0.0311, recon=0.0311, kl=0.0055, beta=0.0003\n",
      "Batch 180, loss=0.0418, recon=0.0418, kl=0.0027, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0537 (Recon: 0.0537, KL: 0.0065, Current Beta: 0.0003) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0293, recon=0.0293, kl=0.0011, beta=0.0008\n",
      "Batch 40, loss=0.0334, recon=0.0334, kl=0.0004, beta=0.0008\n",
      "Batch 60, loss=0.0318, recon=0.0318, kl=0.0011, beta=0.0008\n",
      "Batch 80, loss=0.0618, recon=0.0618, kl=0.0009, beta=0.0008\n",
      "Batch 100, loss=0.0322, recon=0.0322, kl=0.0003, beta=0.0008\n",
      "Batch 120, loss=0.0431, recon=0.0431, kl=0.0007, beta=0.0008\n",
      "Batch 140, loss=0.0784, recon=0.0784, kl=0.0015, beta=0.0008\n",
      "Batch 160, loss=0.0255, recon=0.0255, kl=0.0007, beta=0.0008\n",
      "Batch 180, loss=0.0388, recon=0.0388, kl=0.0004, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0515 (Recon: 0.0515, KL: 0.0011, Current Beta: 0.0008) | Avg Valid Loss: 0.0471 | Avg Valid recon Loss: 0.0471\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0342, recon=0.0342, kl=0.0002, beta=0.0018\n",
      "Batch 40, loss=0.1357, recon=0.1357, kl=0.0001, beta=0.0018\n",
      "Batch 60, loss=0.2803, recon=0.2803, kl=0.0009, beta=0.0018\n",
      "Batch 80, loss=0.0278, recon=0.0278, kl=0.0002, beta=0.0018\n",
      "Batch 100, loss=0.1964, recon=0.1964, kl=0.0018, beta=0.0018\n",
      "Batch 120, loss=0.0335, recon=0.0335, kl=0.0003, beta=0.0018\n",
      "Batch 140, loss=0.0323, recon=0.0323, kl=0.0001, beta=0.0018\n",
      "Batch 160, loss=0.0714, recon=0.0714, kl=0.0002, beta=0.0018\n",
      "Batch 180, loss=0.0513, recon=0.0513, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0500 (Recon: 0.0500, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0449\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1051, recon=0.1051, kl=0.0003, beta=0.0038\n",
      "Batch 40, loss=0.0481, recon=0.0481, kl=0.0003, beta=0.0038\n",
      "Batch 60, loss=0.0570, recon=0.0570, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0708, recon=0.0708, kl=0.0002, beta=0.0038\n",
      "Batch 100, loss=0.0271, recon=0.0271, kl=0.0001, beta=0.0038\n",
      "Batch 120, loss=0.0447, recon=0.0447, kl=0.0001, beta=0.0038\n",
      "Batch 140, loss=0.0341, recon=0.0341, kl=0.0004, beta=0.0038\n",
      "Batch 160, loss=0.0537, recon=0.0537, kl=0.0002, beta=0.0038\n",
      "Batch 180, loss=0.0377, recon=0.0377, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0484 (Recon: 0.0484, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0439 | Avg Valid recon Loss: 0.0439\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0342, recon=0.0342, kl=0.0000, beta=0.0062\n",
      "Batch 40, loss=0.0407, recon=0.0407, kl=0.0004, beta=0.0062\n",
      "Batch 60, loss=0.0358, recon=0.0358, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0318, recon=0.0318, kl=0.0001, beta=0.0062\n",
      "Batch 100, loss=0.0329, recon=0.0329, kl=0.0002, beta=0.0062\n",
      "Batch 120, loss=0.0541, recon=0.0541, kl=0.0001, beta=0.0062\n",
      "Batch 140, loss=0.0451, recon=0.0451, kl=0.0003, beta=0.0062\n",
      "Batch 160, loss=0.0403, recon=0.0403, kl=0.0001, beta=0.0062\n",
      "Batch 180, loss=0.0208, recon=0.0208, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0473, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0343, recon=0.0343, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0283, recon=0.0283, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0387, recon=0.0387, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0715, recon=0.0715, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0415, recon=0.0415, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0265, recon=0.0265, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0251, recon=0.0251, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0367, recon=0.0367, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0460 (Recon: 0.0460, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0424 | Avg Valid recon Loss: 0.0424\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0557, recon=0.0557, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0269, recon=0.0269, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0237, recon=0.0237, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0520, recon=0.0520, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0329, recon=0.0329, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0232, recon=0.0232, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.7340, recon=0.7340, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0380, recon=0.0380, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0316, recon=0.0316, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0453 (Recon: 0.0453, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0409 | Avg Valid recon Loss: 0.0409\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0285, recon=0.0285, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0465, recon=0.0465, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0336, recon=0.0336, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.1215, recon=0.1215, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.1564, recon=0.1564, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0761, recon=0.0761, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0261, recon=0.0261, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0281, recon=0.0281, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0384, recon=0.0384, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0441 (Recon: 0.0441, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0396 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0420, recon=0.0420, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0236, recon=0.0236, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0250, recon=0.0250, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0374, recon=0.0374, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0290, recon=0.0290, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0338, recon=0.0338, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0277, recon=0.0277, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0506, recon=0.0506, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0489, recon=0.0489, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0396 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0314, recon=0.0314, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0332, recon=0.0332, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0203, recon=0.0203, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0470, recon=0.0470, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0512, recon=0.0512, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0442, recon=0.0442, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0265, recon=0.0265, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0245, recon=0.0245, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0430, recon=0.0430, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0426 (Recon: 0.0426, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "\n",
      "[VRAE Run 80/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1963, recon=0.1963, kl=20.3051, beta=0.0000\n",
      "Batch 40, loss=0.1225, recon=0.1225, kl=26.7167, beta=0.0000\n",
      "Batch 60, loss=0.0526, recon=0.0526, kl=26.3835, beta=0.0000\n",
      "Batch 80, loss=0.0762, recon=0.0762, kl=26.9609, beta=0.0000\n",
      "Batch 100, loss=0.0632, recon=0.0632, kl=26.9920, beta=0.0000\n",
      "Batch 120, loss=0.0956, recon=0.0956, kl=29.1538, beta=0.0000\n",
      "Batch 140, loss=0.1374, recon=0.1374, kl=32.3586, beta=0.0000\n",
      "Batch 160, loss=0.0757, recon=0.0757, kl=34.0786, beta=0.0000\n",
      "Batch 180, loss=0.0989, recon=0.0989, kl=31.1002, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1304 (Recon: 0.1304, KL: 27.2187, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0535, recon=0.0535, kl=29.4248, beta=0.0000\n",
      "Batch 40, loss=0.0476, recon=0.0476, kl=24.5251, beta=0.0000\n",
      "Batch 60, loss=0.0484, recon=0.0484, kl=28.6992, beta=0.0000\n",
      "Batch 80, loss=0.0455, recon=0.0455, kl=31.8878, beta=0.0000\n",
      "Batch 100, loss=0.0616, recon=0.0616, kl=31.8511, beta=0.0000\n",
      "Batch 120, loss=0.0404, recon=0.0404, kl=32.7705, beta=0.0000\n",
      "Batch 140, loss=0.0563, recon=0.0563, kl=33.6424, beta=0.0000\n",
      "Batch 160, loss=0.0898, recon=0.0898, kl=33.4842, beta=0.0000\n",
      "Batch 180, loss=0.0497, recon=0.0497, kl=33.9344, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0632 (Recon: 0.0632, KL: 30.9215, Current Beta: 0.0000) | Avg Valid Loss: 0.0505 | Avg Valid recon Loss: 0.0505\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=32.4366, beta=0.0000\n",
      "Batch 40, loss=0.0450, recon=0.0450, kl=31.9695, beta=0.0000\n",
      "Batch 60, loss=0.0290, recon=0.0290, kl=29.9344, beta=0.0000\n",
      "Batch 80, loss=0.0373, recon=0.0373, kl=29.8889, beta=0.0000\n",
      "Batch 100, loss=0.0460, recon=0.0460, kl=29.6318, beta=0.0000\n",
      "Batch 120, loss=0.0921, recon=0.0921, kl=32.1828, beta=0.0000\n",
      "Batch 140, loss=0.0503, recon=0.0503, kl=34.7522, beta=0.0000\n",
      "Batch 160, loss=0.0399, recon=0.0399, kl=34.7697, beta=0.0000\n",
      "Batch 180, loss=0.0367, recon=0.0367, kl=34.7101, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0586 (Recon: 0.0586, KL: 32.1852, Current Beta: 0.0000) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0499\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0368, recon=0.0368, kl=31.2019, beta=0.0000\n",
      "Batch 40, loss=0.0615, recon=0.0615, kl=29.1037, beta=0.0000\n",
      "Batch 60, loss=0.0420, recon=0.0420, kl=28.6454, beta=0.0000\n",
      "Batch 80, loss=0.0692, recon=0.0692, kl=27.5835, beta=0.0000\n",
      "Batch 100, loss=0.0347, recon=0.0347, kl=28.7730, beta=0.0000\n",
      "Batch 120, loss=0.0409, recon=0.0409, kl=27.7982, beta=0.0000\n",
      "Batch 140, loss=0.0253, recon=0.0253, kl=27.7939, beta=0.0000\n",
      "Batch 160, loss=0.0308, recon=0.0308, kl=28.2310, beta=0.0000\n",
      "Batch 180, loss=0.0458, recon=0.0458, kl=28.8136, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0522 (Recon: 0.0522, KL: 28.9298, Current Beta: 0.0000) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0301, recon=0.0300, kl=24.6610, beta=0.0000\n",
      "Batch 40, loss=0.0784, recon=0.0784, kl=21.9490, beta=0.0000\n",
      "Batch 60, loss=0.0319, recon=0.0319, kl=21.4796, beta=0.0000\n",
      "Batch 80, loss=0.0283, recon=0.0283, kl=21.6107, beta=0.0000\n",
      "Batch 100, loss=0.0781, recon=0.0781, kl=19.3240, beta=0.0000\n",
      "Batch 120, loss=0.0302, recon=0.0302, kl=19.1982, beta=0.0000\n",
      "Batch 140, loss=0.0292, recon=0.0292, kl=21.4999, beta=0.0000\n",
      "Batch 160, loss=0.0242, recon=0.0242, kl=22.3716, beta=0.0000\n",
      "Batch 180, loss=0.0237, recon=0.0237, kl=20.9585, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0472, KL: 21.8613, Current Beta: 0.0000) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0223, recon=0.0223, kl=17.6750, beta=0.0000\n",
      "Batch 40, loss=0.0276, recon=0.0276, kl=15.0274, beta=0.0000\n",
      "Batch 60, loss=0.0366, recon=0.0366, kl=13.5267, beta=0.0000\n",
      "Batch 80, loss=0.0207, recon=0.0206, kl=12.5992, beta=0.0000\n",
      "Batch 100, loss=0.0341, recon=0.0341, kl=13.9682, beta=0.0000\n",
      "Batch 120, loss=0.0435, recon=0.0435, kl=14.6907, beta=0.0000\n",
      "Batch 140, loss=0.0420, recon=0.0420, kl=13.4381, beta=0.0000\n",
      "Batch 160, loss=0.0294, recon=0.0293, kl=14.2493, beta=0.0000\n",
      "Batch 180, loss=0.0284, recon=0.0284, kl=14.3708, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0446, KL: 14.5819, Current Beta: 0.0000) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0356, recon=0.0356, kl=10.2358, beta=0.0000\n",
      "Batch 40, loss=0.0297, recon=0.0296, kl=8.6916, beta=0.0000\n",
      "Batch 60, loss=0.0564, recon=0.0563, kl=12.8467, beta=0.0000\n",
      "Batch 80, loss=0.0330, recon=0.0329, kl=11.4788, beta=0.0000\n",
      "Batch 100, loss=0.0490, recon=0.0490, kl=9.1065, beta=0.0000\n",
      "Batch 120, loss=0.0366, recon=0.0365, kl=8.0562, beta=0.0000\n",
      "Batch 140, loss=0.0293, recon=0.0293, kl=7.6531, beta=0.0000\n",
      "Batch 160, loss=0.0292, recon=0.0291, kl=8.3915, beta=0.0000\n",
      "Batch 180, loss=0.0387, recon=0.0386, kl=9.6602, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0435 (Recon: 0.0435, KL: 9.8582, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0495, recon=0.0495, kl=5.6360, beta=0.0000\n",
      "Batch 40, loss=0.0384, recon=0.0383, kl=4.3350, beta=0.0000\n",
      "Batch 60, loss=0.0330, recon=0.0329, kl=4.0888, beta=0.0000\n",
      "Batch 80, loss=0.0230, recon=0.0230, kl=3.3426, beta=0.0000\n",
      "Batch 100, loss=0.0769, recon=0.0768, kl=3.7895, beta=0.0000\n",
      "Batch 120, loss=0.1511, recon=0.1511, kl=2.6909, beta=0.0000\n",
      "Batch 140, loss=0.0397, recon=0.0396, kl=3.6736, beta=0.0000\n",
      "Batch 160, loss=0.0454, recon=0.0453, kl=6.7052, beta=0.0000\n",
      "Batch 180, loss=0.0300, recon=0.0298, kl=9.9209, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0459, KL: 4.8989, Current Beta: 0.0000) | Avg Valid Loss: 0.0386 | Avg Valid recon Loss: 0.0384\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0182, recon=0.0181, kl=2.5594, beta=0.0000\n",
      "Batch 40, loss=0.0253, recon=0.0253, kl=1.7001, beta=0.0000\n",
      "Batch 60, loss=0.0188, recon=0.0187, kl=1.1066, beta=0.0000\n",
      "Batch 80, loss=0.0724, recon=0.0723, kl=1.3870, beta=0.0000\n",
      "Batch 100, loss=0.0284, recon=0.0283, kl=1.8664, beta=0.0000\n",
      "Batch 120, loss=0.0385, recon=0.0385, kl=1.1084, beta=0.0000\n",
      "Batch 140, loss=0.0410, recon=0.0410, kl=0.6188, beta=0.0000\n",
      "Batch 160, loss=0.0305, recon=0.0305, kl=0.4444, beta=0.0000\n",
      "Batch 180, loss=0.0329, recon=0.0329, kl=0.5834, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0430, KL: 1.6973, Current Beta: 0.0000) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0431, recon=0.0431, kl=0.0605, beta=0.0001\n",
      "Batch 40, loss=0.0269, recon=0.0268, kl=0.2180, beta=0.0001\n",
      "Batch 60, loss=0.0276, recon=0.0276, kl=0.4379, beta=0.0001\n",
      "Batch 80, loss=0.0276, recon=0.0276, kl=0.1662, beta=0.0001\n",
      "Batch 100, loss=0.0263, recon=0.0262, kl=0.0967, beta=0.0001\n",
      "Batch 120, loss=0.0364, recon=0.0364, kl=0.0806, beta=0.0001\n",
      "Batch 140, loss=0.0579, recon=0.0579, kl=0.1356, beta=0.0001\n",
      "Batch 160, loss=0.0623, recon=0.0622, kl=0.1214, beta=0.0001\n",
      "Batch 180, loss=0.0363, recon=0.0363, kl=0.1904, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0438, KL: 0.1830, Current Beta: 0.0001) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1550, recon=0.1550, kl=0.0185, beta=0.0003\n",
      "Batch 40, loss=0.0226, recon=0.0226, kl=0.0204, beta=0.0003\n",
      "Batch 60, loss=0.0446, recon=0.0446, kl=0.0291, beta=0.0003\n",
      "Batch 80, loss=0.0451, recon=0.0451, kl=0.0155, beta=0.0003\n",
      "Batch 100, loss=0.0297, recon=0.0297, kl=0.0078, beta=0.0003\n",
      "Batch 120, loss=0.0233, recon=0.0232, kl=0.0182, beta=0.0003\n",
      "Batch 140, loss=0.0490, recon=0.0490, kl=0.0096, beta=0.0003\n",
      "Batch 160, loss=0.1281, recon=0.1281, kl=0.0060, beta=0.0003\n",
      "Batch 180, loss=0.0482, recon=0.0482, kl=0.0119, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0403 (Recon: 0.0403, KL: 0.0176, Current Beta: 0.0003) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0212, recon=0.0212, kl=0.0061, beta=0.0008\n",
      "Batch 40, loss=0.0290, recon=0.0290, kl=0.0071, beta=0.0008\n",
      "Batch 60, loss=0.0754, recon=0.0754, kl=0.0079, beta=0.0008\n",
      "Batch 80, loss=0.0381, recon=0.0381, kl=0.0110, beta=0.0008\n",
      "Batch 100, loss=0.0257, recon=0.0257, kl=0.0060, beta=0.0008\n",
      "Batch 120, loss=0.0452, recon=0.0452, kl=0.0054, beta=0.0008\n",
      "Batch 140, loss=0.0279, recon=0.0279, kl=0.0022, beta=0.0008\n",
      "Batch 160, loss=0.0210, recon=0.0210, kl=0.0034, beta=0.0008\n",
      "Batch 180, loss=0.0313, recon=0.0313, kl=0.0017, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0403 (Recon: 0.0403, KL: 0.0066, Current Beta: 0.0008) | Avg Valid Loss: 0.0350 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0263, recon=0.0263, kl=0.0008, beta=0.0018\n",
      "Batch 40, loss=0.0355, recon=0.0355, kl=0.0002, beta=0.0018\n",
      "Batch 60, loss=0.0317, recon=0.0317, kl=0.0010, beta=0.0018\n",
      "Batch 80, loss=0.0330, recon=0.0330, kl=0.0031, beta=0.0018\n",
      "Batch 100, loss=0.0246, recon=0.0246, kl=0.0016, beta=0.0018\n",
      "Batch 120, loss=0.0311, recon=0.0311, kl=0.0016, beta=0.0018\n",
      "Batch 140, loss=0.0302, recon=0.0302, kl=0.0024, beta=0.0018\n",
      "Batch 160, loss=0.0441, recon=0.0441, kl=0.0019, beta=0.0018\n",
      "Batch 180, loss=0.0363, recon=0.0362, kl=0.0018, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0384 (Recon: 0.0384, KL: 0.0023, Current Beta: 0.0018) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=0.0009, beta=0.0038\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=0.0007, beta=0.0038\n",
      "Batch 60, loss=0.0319, recon=0.0319, kl=0.0004, beta=0.0038\n",
      "Batch 80, loss=0.0256, recon=0.0256, kl=0.0005, beta=0.0038\n",
      "Batch 100, loss=0.0390, recon=0.0390, kl=0.0026, beta=0.0038\n",
      "Batch 120, loss=0.0253, recon=0.0253, kl=0.0013, beta=0.0038\n",
      "Batch 140, loss=0.0423, recon=0.0423, kl=0.0013, beta=0.0038\n",
      "Batch 160, loss=0.0371, recon=0.0371, kl=0.0015, beta=0.0038\n",
      "Batch 180, loss=0.0562, recon=0.0562, kl=0.0014, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0399 (Recon: 0.0399, KL: 0.0014, Current Beta: 0.0038) | Avg Valid Loss: 0.0321 | Avg Valid recon Loss: 0.0321\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0235, recon=0.0235, kl=0.0004, beta=0.0062\n",
      "Batch 40, loss=0.0237, recon=0.0237, kl=0.0006, beta=0.0062\n",
      "Batch 60, loss=0.0251, recon=0.0251, kl=0.0022, beta=0.0062\n",
      "Batch 80, loss=0.0378, recon=0.0378, kl=0.0005, beta=0.0062\n",
      "Batch 100, loss=0.1264, recon=0.1264, kl=0.0002, beta=0.0062\n",
      "Batch 120, loss=0.0209, recon=0.0209, kl=0.0001, beta=0.0062\n",
      "Batch 140, loss=0.0285, recon=0.0285, kl=0.0002, beta=0.0062\n",
      "Batch 160, loss=0.0253, recon=0.0253, kl=0.0004, beta=0.0062\n",
      "Batch 180, loss=0.0383, recon=0.0383, kl=0.0008, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0376 (Recon: 0.0376, KL: 0.0016, Current Beta: 0.0062) | Avg Valid Loss: 0.0326 | Avg Valid recon Loss: 0.0326\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0327, recon=0.0327, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0362, recon=0.0362, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0706, recon=0.0706, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.3604, recon=0.3604, kl=0.0003, beta=0.0100\n",
      "Batch 100, loss=0.0224, recon=0.0224, kl=0.0002, beta=0.0100\n",
      "Batch 120, loss=0.0204, recon=0.0204, kl=0.0002, beta=0.0100\n",
      "Batch 140, loss=0.0300, recon=0.0300, kl=0.0003, beta=0.0100\n",
      "Batch 160, loss=0.0191, recon=0.0191, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0273, recon=0.0273, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0375 (Recon: 0.0375, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0247, recon=0.0247, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0289, recon=0.0289, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0314, recon=0.0314, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0179, recon=0.0179, kl=0.0002, beta=0.0100\n",
      "Batch 100, loss=0.0388, recon=0.0388, kl=0.0004, beta=0.0100\n",
      "Batch 120, loss=0.0331, recon=0.0329, kl=0.0228, beta=0.0100\n",
      "Batch 140, loss=0.0231, recon=0.0231, kl=0.0004, beta=0.0100\n",
      "Batch 160, loss=0.0288, recon=0.0288, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0390, recon=0.0390, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0390, KL: 0.0007, Current Beta: 0.0100) | Avg Valid Loss: 0.0349 | Avg Valid recon Loss: 0.0349\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0320, recon=0.0320, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0488, recon=0.0488, kl=0.0004, beta=0.0100\n",
      "Batch 60, loss=0.0284, recon=0.0284, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0259, recon=0.0259, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0229, recon=0.0229, kl=0.0002, beta=0.0100\n",
      "Batch 120, loss=0.0243, recon=0.0243, kl=0.0003, beta=0.0100\n",
      "Batch 140, loss=0.0362, recon=0.0362, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0206, recon=0.0206, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0312, recon=0.0312, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0354, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0312 | Avg Valid recon Loss: 0.0311\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0347, recon=0.0347, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0370, recon=0.0370, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0232, recon=0.0232, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0213, recon=0.0213, kl=0.0002, beta=0.0100\n",
      "Batch 100, loss=0.0214, recon=0.0214, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0829, recon=0.0829, kl=0.0003, beta=0.0100\n",
      "Batch 140, loss=0.0356, recon=0.0356, kl=0.0006, beta=0.0100\n",
      "Batch 160, loss=0.0355, recon=0.0343, kl=0.1248, beta=0.0100\n",
      "Batch 180, loss=0.0296, recon=0.0295, kl=0.0095, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0387, KL: 0.0093, Current Beta: 0.0100) | Avg Valid Loss: 0.0298 | Avg Valid recon Loss: 0.0297\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0309, recon=0.0308, kl=0.0058, beta=0.0100\n",
      "Batch 40, loss=0.0197, recon=0.0197, kl=0.0009, beta=0.0100\n",
      "Batch 60, loss=0.0322, recon=0.0322, kl=0.0006, beta=0.0100\n",
      "Batch 80, loss=0.3316, recon=0.3316, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0869, recon=0.0869, kl=0.0006, beta=0.0100\n",
      "Batch 120, loss=0.0572, recon=0.0572, kl=0.0002, beta=0.0100\n",
      "Batch 140, loss=0.0259, recon=0.0259, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0202, recon=0.0202, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0310, recon=0.0310, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0395, KL: 0.0017, Current Beta: 0.0100) | Avg Valid Loss: 0.0335 | Avg Valid recon Loss: 0.0335\n",
      "\n",
      "[VRAE Run 81/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3891, recon=0.3891, kl=0.2958, beta=0.0000\n",
      "Batch 40, loss=0.2418, recon=0.2418, kl=1.4749, beta=0.0000\n",
      "Batch 60, loss=0.2172, recon=0.2172, kl=24.1821, beta=0.0000\n",
      "Batch 80, loss=0.2386, recon=0.2386, kl=37.9955, beta=0.0000\n",
      "Batch 100, loss=0.1669, recon=0.1669, kl=45.2258, beta=0.0000\n",
      "Batch 120, loss=0.1525, recon=0.1525, kl=52.2302, beta=0.0000\n",
      "Batch 140, loss=0.1671, recon=0.1671, kl=56.7963, beta=0.0000\n",
      "Batch 160, loss=0.1202, recon=0.1202, kl=60.7194, beta=0.0000\n",
      "Batch 180, loss=0.1591, recon=0.1591, kl=62.8149, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3100 (Recon: 0.3100, KL: 34.6914, Current Beta: 0.0000) | Avg Valid Loss: 0.1399 | Avg Valid recon Loss: 0.1399\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1294, recon=0.1294, kl=63.8936, beta=0.0000\n",
      "Batch 40, loss=0.2632, recon=0.2632, kl=65.8410, beta=0.0000\n",
      "Batch 60, loss=0.2147, recon=0.2147, kl=66.2485, beta=0.0000\n",
      "Batch 80, loss=0.1156, recon=0.1156, kl=68.8020, beta=0.0000\n",
      "Batch 100, loss=0.1971, recon=0.1971, kl=68.2392, beta=0.0000\n",
      "Batch 120, loss=0.1049, recon=0.1049, kl=67.2014, beta=0.0000\n",
      "Batch 140, loss=0.0903, recon=0.0903, kl=67.3592, beta=0.0000\n",
      "Batch 160, loss=0.0777, recon=0.0777, kl=66.0727, beta=0.0000\n",
      "Batch 180, loss=0.1232, recon=0.1232, kl=64.9986, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1439 (Recon: 0.1439, KL: 66.5045, Current Beta: 0.0000) | Avg Valid Loss: 0.0961 | Avg Valid recon Loss: 0.0961\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0996, recon=0.0996, kl=65.3799, beta=0.0000\n",
      "Batch 40, loss=0.0687, recon=0.0687, kl=62.2683, beta=0.0000\n",
      "Batch 60, loss=0.0736, recon=0.0736, kl=58.1858, beta=0.0000\n",
      "Batch 80, loss=0.0996, recon=0.0996, kl=54.6394, beta=0.0000\n",
      "Batch 100, loss=0.0931, recon=0.0931, kl=57.0635, beta=0.0000\n",
      "Batch 120, loss=0.0944, recon=0.0944, kl=57.4329, beta=0.0000\n",
      "Batch 140, loss=0.0600, recon=0.0600, kl=57.8088, beta=0.0000\n",
      "Batch 160, loss=0.0842, recon=0.0842, kl=62.6857, beta=0.0000\n",
      "Batch 180, loss=0.0632, recon=0.0632, kl=60.7107, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1082 (Recon: 0.1082, KL: 60.0124, Current Beta: 0.0000) | Avg Valid Loss: 0.0797 | Avg Valid recon Loss: 0.0796\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0921, recon=0.0920, kl=57.8799, beta=0.0000\n",
      "Batch 40, loss=0.0736, recon=0.0735, kl=50.4854, beta=0.0000\n",
      "Batch 60, loss=0.0584, recon=0.0584, kl=47.8260, beta=0.0000\n",
      "Batch 80, loss=0.0608, recon=0.0608, kl=47.9303, beta=0.0000\n",
      "Batch 100, loss=0.0521, recon=0.0521, kl=44.1846, beta=0.0000\n",
      "Batch 120, loss=0.0661, recon=0.0661, kl=44.6252, beta=0.0000\n",
      "Batch 140, loss=0.0695, recon=0.0695, kl=44.2864, beta=0.0000\n",
      "Batch 160, loss=0.0943, recon=0.0943, kl=45.8872, beta=0.0000\n",
      "Batch 180, loss=0.1006, recon=0.1006, kl=44.5200, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0881 (Recon: 0.0881, KL: 48.3219, Current Beta: 0.0000) | Avg Valid Loss: 0.0693 | Avg Valid recon Loss: 0.0693\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0445, recon=0.0445, kl=41.3292, beta=0.0000\n",
      "Batch 40, loss=0.0586, recon=0.0586, kl=33.2067, beta=0.0000\n",
      "Batch 60, loss=0.0468, recon=0.0468, kl=28.4872, beta=0.0000\n",
      "Batch 80, loss=0.0910, recon=0.0910, kl=29.7828, beta=0.0000\n",
      "Batch 100, loss=0.0513, recon=0.0513, kl=26.6928, beta=0.0000\n",
      "Batch 120, loss=0.0373, recon=0.0373, kl=25.7691, beta=0.0000\n",
      "Batch 140, loss=0.0387, recon=0.0386, kl=25.0418, beta=0.0000\n",
      "Batch 160, loss=0.0685, recon=0.0685, kl=24.2423, beta=0.0000\n",
      "Batch 180, loss=0.0579, recon=0.0579, kl=26.2242, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0767 (Recon: 0.0767, KL: 29.9633, Current Beta: 0.0000) | Avg Valid Loss: 0.0632 | Avg Valid recon Loss: 0.0632\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0405, recon=0.0404, kl=17.9252, beta=0.0000\n",
      "Batch 40, loss=0.0488, recon=0.0488, kl=13.5331, beta=0.0000\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=11.5524, beta=0.0000\n",
      "Batch 80, loss=0.0420, recon=0.0420, kl=13.3510, beta=0.0000\n",
      "Batch 100, loss=0.0474, recon=0.0474, kl=11.3711, beta=0.0000\n",
      "Batch 120, loss=0.0886, recon=0.0885, kl=12.9847, beta=0.0000\n",
      "Batch 140, loss=0.0439, recon=0.0438, kl=11.4945, beta=0.0000\n",
      "Batch 160, loss=0.0355, recon=0.0355, kl=10.7616, beta=0.0000\n",
      "Batch 180, loss=0.0365, recon=0.0365, kl=9.5178, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0692 (Recon: 0.0691, KL: 13.3803, Current Beta: 0.0000) | Avg Valid Loss: 0.0595 | Avg Valid recon Loss: 0.0595\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0482, recon=0.0482, kl=6.3348, beta=0.0000\n",
      "Batch 40, loss=0.0406, recon=0.0406, kl=4.5525, beta=0.0000\n",
      "Batch 60, loss=0.0432, recon=0.0432, kl=5.6470, beta=0.0000\n",
      "Batch 80, loss=0.0491, recon=0.0491, kl=4.3842, beta=0.0000\n",
      "Batch 100, loss=0.0322, recon=0.0321, kl=4.3083, beta=0.0000\n",
      "Batch 120, loss=0.0347, recon=0.0346, kl=4.0548, beta=0.0000\n",
      "Batch 140, loss=0.0763, recon=0.0762, kl=3.7350, beta=0.0000\n",
      "Batch 160, loss=0.0645, recon=0.0645, kl=4.1404, beta=0.0000\n",
      "Batch 180, loss=0.0362, recon=0.0362, kl=3.8638, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0637 (Recon: 0.0637, KL: 4.8650, Current Beta: 0.0000) | Avg Valid Loss: 0.0561 | Avg Valid recon Loss: 0.0561\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0506, recon=0.0506, kl=1.4974, beta=0.0000\n",
      "Batch 40, loss=0.0495, recon=0.0494, kl=1.7718, beta=0.0000\n",
      "Batch 60, loss=0.0301, recon=0.0301, kl=1.5294, beta=0.0000\n",
      "Batch 80, loss=0.0328, recon=0.0328, kl=2.0490, beta=0.0000\n",
      "Batch 100, loss=0.0529, recon=0.0528, kl=1.4394, beta=0.0000\n",
      "Batch 120, loss=0.0368, recon=0.0368, kl=1.2327, beta=0.0000\n",
      "Batch 140, loss=0.0498, recon=0.0497, kl=1.8846, beta=0.0000\n",
      "Batch 160, loss=0.0716, recon=0.0716, kl=1.3175, beta=0.0000\n",
      "Batch 180, loss=0.0499, recon=0.0498, kl=1.1828, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0601 (Recon: 0.0601, KL: 1.6672, Current Beta: 0.0000) | Avg Valid Loss: 0.0526 | Avg Valid recon Loss: 0.0526\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0441, recon=0.0441, kl=0.4960, beta=0.0000\n",
      "Batch 40, loss=0.0303, recon=0.0303, kl=0.3874, beta=0.0000\n",
      "Batch 60, loss=0.0365, recon=0.0365, kl=0.5237, beta=0.0000\n",
      "Batch 80, loss=1.0402, recon=1.0401, kl=0.4000, beta=0.0000\n",
      "Batch 100, loss=0.0329, recon=0.0329, kl=0.3831, beta=0.0000\n",
      "Batch 120, loss=0.1291, recon=0.1290, kl=0.3980, beta=0.0000\n",
      "Batch 140, loss=0.0510, recon=0.0509, kl=0.3109, beta=0.0000\n",
      "Batch 160, loss=0.0365, recon=0.0365, kl=0.3184, beta=0.0000\n",
      "Batch 180, loss=0.0307, recon=0.0307, kl=0.2657, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0570 (Recon: 0.0570, KL: 0.4464, Current Beta: 0.0000) | Avg Valid Loss: 0.0497 | Avg Valid recon Loss: 0.0497\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=0.0840, beta=0.0001\n",
      "Batch 40, loss=0.0412, recon=0.0412, kl=0.0794, beta=0.0001\n",
      "Batch 60, loss=0.0686, recon=0.0686, kl=0.0449, beta=0.0001\n",
      "Batch 80, loss=0.0613, recon=0.0613, kl=0.0329, beta=0.0001\n",
      "Batch 100, loss=0.0748, recon=0.0748, kl=0.0417, beta=0.0001\n",
      "Batch 120, loss=0.0418, recon=0.0418, kl=0.0468, beta=0.0001\n",
      "Batch 140, loss=0.1250, recon=0.1250, kl=0.0236, beta=0.0001\n",
      "Batch 160, loss=0.0388, recon=0.0388, kl=0.0368, beta=0.0001\n",
      "Batch 180, loss=0.0462, recon=0.0462, kl=0.0254, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0547, KL: 0.0649, Current Beta: 0.0001) | Avg Valid Loss: 0.0481 | Avg Valid recon Loss: 0.0481\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0438, recon=0.0438, kl=0.0046, beta=0.0003\n",
      "Batch 40, loss=0.0323, recon=0.0323, kl=0.0041, beta=0.0003\n",
      "Batch 60, loss=0.0307, recon=0.0307, kl=0.0038, beta=0.0003\n",
      "Batch 80, loss=0.0336, recon=0.0336, kl=0.0038, beta=0.0003\n",
      "Batch 100, loss=0.0868, recon=0.0868, kl=0.0039, beta=0.0003\n",
      "Batch 120, loss=0.0229, recon=0.0229, kl=0.0050, beta=0.0003\n",
      "Batch 140, loss=0.0451, recon=0.0451, kl=0.0033, beta=0.0003\n",
      "Batch 160, loss=0.0456, recon=0.0456, kl=0.0032, beta=0.0003\n",
      "Batch 180, loss=0.2189, recon=0.2189, kl=0.0026, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0522 (Recon: 0.0522, KL: 0.0054, Current Beta: 0.0003) | Avg Valid Loss: 0.0461 | Avg Valid recon Loss: 0.0461\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1552, recon=0.1552, kl=0.0009, beta=0.0008\n",
      "Batch 40, loss=0.0494, recon=0.0494, kl=0.0006, beta=0.0008\n",
      "Batch 60, loss=0.0325, recon=0.0325, kl=0.0006, beta=0.0008\n",
      "Batch 80, loss=0.0397, recon=0.0397, kl=0.0008, beta=0.0008\n",
      "Batch 100, loss=0.0427, recon=0.0427, kl=0.0004, beta=0.0008\n",
      "Batch 120, loss=0.0274, recon=0.0274, kl=0.0003, beta=0.0008\n",
      "Batch 140, loss=0.0268, recon=0.0268, kl=0.0008, beta=0.0008\n",
      "Batch 160, loss=0.0233, recon=0.0233, kl=0.0004, beta=0.0008\n",
      "Batch 180, loss=0.0748, recon=0.0748, kl=0.0017, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0507 (Recon: 0.0507, KL: 0.0011, Current Beta: 0.0008) | Avg Valid Loss: 0.0447 | Avg Valid recon Loss: 0.0447\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=0.0012, beta=0.0018\n",
      "Batch 40, loss=0.0316, recon=0.0316, kl=0.0002, beta=0.0018\n",
      "Batch 60, loss=0.0349, recon=0.0349, kl=0.0002, beta=0.0018\n",
      "Batch 80, loss=0.0357, recon=0.0357, kl=0.0005, beta=0.0018\n",
      "Batch 100, loss=0.0351, recon=0.0351, kl=0.0003, beta=0.0018\n",
      "Batch 120, loss=0.0282, recon=0.0282, kl=0.0003, beta=0.0018\n",
      "Batch 140, loss=0.0398, recon=0.0398, kl=0.0002, beta=0.0018\n",
      "Batch 160, loss=0.0317, recon=0.0317, kl=0.0002, beta=0.0018\n",
      "Batch 180, loss=0.1034, recon=0.1034, kl=0.0052, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0492 (Recon: 0.0492, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0305, recon=0.0305, kl=0.0002, beta=0.0038\n",
      "Batch 40, loss=0.0351, recon=0.0351, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.1099, recon=0.1099, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0265, recon=0.0265, kl=0.0002, beta=0.0038\n",
      "Batch 100, loss=0.0274, recon=0.0274, kl=0.0001, beta=0.0038\n",
      "Batch 120, loss=0.0546, recon=0.0546, kl=0.0001, beta=0.0038\n",
      "Batch 140, loss=0.0405, recon=0.0405, kl=0.0001, beta=0.0038\n",
      "Batch 160, loss=0.0292, recon=0.0292, kl=0.0002, beta=0.0038\n",
      "Batch 180, loss=0.0284, recon=0.0284, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0478 (Recon: 0.0478, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0424 | Avg Valid recon Loss: 0.0424\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0391, recon=0.0391, kl=0.0002, beta=0.0062\n",
      "Batch 40, loss=0.0327, recon=0.0327, kl=0.0003, beta=0.0062\n",
      "Batch 60, loss=0.0312, recon=0.0312, kl=0.0002, beta=0.0062\n",
      "Batch 80, loss=0.0247, recon=0.0247, kl=0.0001, beta=0.0062\n",
      "Batch 100, loss=0.0250, recon=0.0250, kl=0.0001, beta=0.0062\n",
      "Batch 120, loss=0.0379, recon=0.0379, kl=0.0000, beta=0.0062\n",
      "Batch 140, loss=0.0820, recon=0.0819, kl=0.0036, beta=0.0062\n",
      "Batch 160, loss=0.1204, recon=0.1204, kl=0.0006, beta=0.0062\n",
      "Batch 180, loss=0.0363, recon=0.0363, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0467 (Recon: 0.0467, KL: 0.0003, Current Beta: 0.0062) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0260, recon=0.0260, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0425, recon=0.0425, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0262, recon=0.0262, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0365, recon=0.0365, kl=0.0002, beta=0.0100\n",
      "Batch 100, loss=0.0243, recon=0.0243, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0353, recon=0.0353, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0312, recon=0.0312, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0299, recon=0.0299, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0292, recon=0.0292, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0456 (Recon: 0.0456, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0341, recon=0.0341, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0515, recon=0.0515, kl=0.0008, beta=0.0100\n",
      "Batch 60, loss=0.0441, recon=0.0441, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0464, recon=0.0464, kl=0.0009, beta=0.0100\n",
      "Batch 100, loss=0.0389, recon=0.0389, kl=0.0002, beta=0.0100\n",
      "Batch 120, loss=0.0319, recon=0.0319, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0361, recon=0.0361, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0333, recon=0.0333, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0278, recon=0.0278, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0447 (Recon: 0.0447, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0392\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0311, recon=0.0311, kl=0.0005, beta=0.0100\n",
      "Batch 40, loss=0.0523, recon=0.0523, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0424, recon=0.0424, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0560, recon=0.0560, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0440, recon=0.0440, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.1674, recon=0.1674, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0460, recon=0.0460, kl=0.0005, beta=0.0100\n",
      "Batch 160, loss=0.0254, recon=0.0253, kl=0.0003, beta=0.0100\n",
      "Batch 180, loss=0.0212, recon=0.0212, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0439 (Recon: 0.0439, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0384\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0364, recon=0.0364, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0346, recon=0.0346, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0356, recon=0.0356, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0299, recon=0.0299, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0356, recon=0.0356, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0360, recon=0.0360, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0347, recon=0.0347, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0657, recon=0.0657, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0409, recon=0.0409, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0429, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0362, recon=0.0362, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0398, recon=0.0398, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0309, recon=0.0309, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0271, recon=0.0271, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0180, recon=0.0180, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0261, recon=0.0261, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0292, recon=0.0292, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0316, recon=0.0316, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0298, recon=0.0298, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0365 | Avg Valid recon Loss: 0.0365\n",
      "\n",
      "[VRAE Run 82/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1641, recon=0.1641, kl=41.8477, beta=0.0000\n",
      "Batch 40, loss=0.1001, recon=0.1001, kl=46.1677, beta=0.0000\n",
      "Batch 60, loss=0.1116, recon=0.1116, kl=47.1207, beta=0.0000\n",
      "Batch 80, loss=0.0627, recon=0.0627, kl=52.0142, beta=0.0000\n",
      "Batch 100, loss=0.0738, recon=0.0738, kl=52.1291, beta=0.0000\n",
      "Batch 120, loss=0.1031, recon=0.1031, kl=59.5726, beta=0.0000\n",
      "Batch 140, loss=0.0516, recon=0.0516, kl=61.6771, beta=0.0000\n",
      "Batch 160, loss=0.0728, recon=0.0728, kl=76.6169, beta=0.0000\n",
      "Batch 180, loss=0.0547, recon=0.0547, kl=73.4035, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1361 (Recon: 0.1361, KL: 52.3850, Current Beta: 0.0000) | Avg Valid Loss: 0.0641 | Avg Valid recon Loss: 0.0641\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0574, recon=0.0574, kl=73.7539, beta=0.0000\n",
      "Batch 40, loss=0.0507, recon=0.0507, kl=74.3438, beta=0.0000\n",
      "Batch 60, loss=0.0353, recon=0.0353, kl=70.7609, beta=0.0000\n",
      "Batch 80, loss=0.0405, recon=0.0404, kl=71.7026, beta=0.0000\n",
      "Batch 100, loss=0.0599, recon=0.0599, kl=74.0894, beta=0.0000\n",
      "Batch 120, loss=0.0368, recon=0.0368, kl=73.4354, beta=0.0000\n",
      "Batch 140, loss=0.0467, recon=0.0467, kl=74.9196, beta=0.0000\n",
      "Batch 160, loss=0.0526, recon=0.0526, kl=76.2973, beta=0.0000\n",
      "Batch 180, loss=0.0413, recon=0.0413, kl=77.1209, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0656 (Recon: 0.0656, KL: 73.6785, Current Beta: 0.0000) | Avg Valid Loss: 0.0553 | Avg Valid recon Loss: 0.0553\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0401, recon=0.0401, kl=76.3397, beta=0.0000\n",
      "Batch 40, loss=0.0497, recon=0.0496, kl=75.2704, beta=0.0000\n",
      "Batch 60, loss=0.0659, recon=0.0659, kl=73.5397, beta=0.0000\n",
      "Batch 80, loss=0.0437, recon=0.0437, kl=71.2972, beta=0.0000\n",
      "Batch 100, loss=0.0465, recon=0.0464, kl=69.1281, beta=0.0000\n",
      "Batch 120, loss=0.0340, recon=0.0340, kl=68.0123, beta=0.0000\n",
      "Batch 140, loss=0.0471, recon=0.0471, kl=68.0509, beta=0.0000\n",
      "Batch 160, loss=0.0328, recon=0.0328, kl=67.7698, beta=0.0000\n",
      "Batch 180, loss=0.0401, recon=0.0400, kl=66.1354, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0555, KL: 71.3654, Current Beta: 0.0000) | Avg Valid Loss: 0.0560 | Avg Valid recon Loss: 0.0559\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0545, recon=0.0545, kl=59.6460, beta=0.0000\n",
      "Batch 40, loss=0.0456, recon=0.0456, kl=58.1109, beta=0.0000\n",
      "Batch 60, loss=0.0357, recon=0.0357, kl=58.4962, beta=0.0000\n",
      "Batch 80, loss=0.0303, recon=0.0302, kl=56.9228, beta=0.0000\n",
      "Batch 100, loss=0.0322, recon=0.0322, kl=56.4265, beta=0.0000\n",
      "Batch 120, loss=0.0457, recon=0.0457, kl=56.8680, beta=0.0000\n",
      "Batch 140, loss=0.0311, recon=0.0311, kl=56.3583, beta=0.0000\n",
      "Batch 160, loss=0.0378, recon=0.0378, kl=59.0881, beta=0.0000\n",
      "Batch 180, loss=0.8628, recon=0.8628, kl=59.1143, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0514 (Recon: 0.0514, KL: 58.2670, Current Beta: 0.0000) | Avg Valid Loss: 0.0556 | Avg Valid recon Loss: 0.0556\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0441, recon=0.0441, kl=55.7931, beta=0.0000\n",
      "Batch 40, loss=0.0339, recon=0.0339, kl=50.0849, beta=0.0000\n",
      "Batch 60, loss=0.0505, recon=0.0504, kl=49.1549, beta=0.0000\n",
      "Batch 80, loss=0.0349, recon=0.0349, kl=48.2696, beta=0.0000\n",
      "Batch 100, loss=0.0367, recon=0.0367, kl=46.4841, beta=0.0000\n",
      "Batch 120, loss=0.0307, recon=0.0306, kl=46.8531, beta=0.0000\n",
      "Batch 140, loss=0.0433, recon=0.0432, kl=46.5657, beta=0.0000\n",
      "Batch 160, loss=0.0450, recon=0.0450, kl=45.0295, beta=0.0000\n",
      "Batch 180, loss=0.0436, recon=0.0436, kl=43.5134, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0539, KL: 48.6899, Current Beta: 0.0000) | Avg Valid Loss: 0.0453 | Avg Valid recon Loss: 0.0453\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0375, recon=0.0374, kl=35.7628, beta=0.0000\n",
      "Batch 40, loss=0.0281, recon=0.0280, kl=31.0529, beta=0.0000\n",
      "Batch 60, loss=0.0308, recon=0.0308, kl=29.1001, beta=0.0000\n",
      "Batch 80, loss=0.0334, recon=0.0333, kl=29.2656, beta=0.0000\n",
      "Batch 100, loss=0.0410, recon=0.0410, kl=28.8442, beta=0.0000\n",
      "Batch 120, loss=0.0553, recon=0.0552, kl=27.1576, beta=0.0000\n",
      "Batch 140, loss=0.0367, recon=0.0366, kl=27.6611, beta=0.0000\n",
      "Batch 160, loss=0.0507, recon=0.0506, kl=27.4119, beta=0.0000\n",
      "Batch 180, loss=0.1513, recon=0.1512, kl=28.9828, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0483 (Recon: 0.0482, KL: 30.0330, Current Beta: 0.0000) | Avg Valid Loss: 0.0464 | Avg Valid recon Loss: 0.0463\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0461, recon=0.0460, kl=20.4829, beta=0.0000\n",
      "Batch 40, loss=0.1412, recon=0.1411, kl=16.9339, beta=0.0000\n",
      "Batch 60, loss=0.0620, recon=0.0619, kl=17.2793, beta=0.0000\n",
      "Batch 80, loss=0.1409, recon=0.1408, kl=15.1405, beta=0.0000\n",
      "Batch 100, loss=0.0267, recon=0.0266, kl=13.8854, beta=0.0000\n",
      "Batch 120, loss=0.0562, recon=0.0561, kl=14.2376, beta=0.0000\n",
      "Batch 140, loss=0.0417, recon=0.0417, kl=13.9746, beta=0.0000\n",
      "Batch 160, loss=0.0302, recon=0.0301, kl=13.4136, beta=0.0000\n",
      "Batch 180, loss=0.0248, recon=0.0247, kl=14.8809, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0471, KL: 16.2654, Current Beta: 0.0000) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0610, recon=0.0609, kl=8.4999, beta=0.0000\n",
      "Batch 40, loss=0.0572, recon=0.0571, kl=6.6382, beta=0.0000\n",
      "Batch 60, loss=0.0278, recon=0.0277, kl=6.5329, beta=0.0000\n",
      "Batch 80, loss=0.0322, recon=0.0321, kl=4.7840, beta=0.0000\n",
      "Batch 100, loss=0.0393, recon=0.0393, kl=4.3671, beta=0.0000\n",
      "Batch 120, loss=0.0259, recon=0.0258, kl=4.9033, beta=0.0000\n",
      "Batch 140, loss=0.0417, recon=0.0416, kl=8.5321, beta=0.0000\n",
      "Batch 160, loss=0.1242, recon=0.1240, kl=11.0683, beta=0.0000\n",
      "Batch 180, loss=0.0721, recon=0.0720, kl=8.0101, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0460, KL: 7.3306, Current Beta: 0.0000) | Avg Valid Loss: 0.0400 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0461, recon=0.0460, kl=1.8184, beta=0.0000\n",
      "Batch 40, loss=0.0370, recon=0.0369, kl=1.2886, beta=0.0000\n",
      "Batch 60, loss=0.0374, recon=0.0374, kl=1.2174, beta=0.0000\n",
      "Batch 80, loss=0.0293, recon=0.0292, kl=1.0722, beta=0.0000\n",
      "Batch 100, loss=0.0252, recon=0.0252, kl=0.6910, beta=0.0000\n",
      "Batch 120, loss=0.0532, recon=0.0532, kl=0.5450, beta=0.0000\n",
      "Batch 140, loss=0.0453, recon=0.0451, kl=4.7957, beta=0.0000\n",
      "Batch 160, loss=0.0342, recon=0.0338, kl=8.1098, beta=0.0000\n",
      "Batch 180, loss=0.0299, recon=0.0297, kl=3.8793, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0439, KL: 2.8396, Current Beta: 0.0000) | Avg Valid Loss: 0.0409 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0345, recon=0.0344, kl=0.7667, beta=0.0001\n",
      "Batch 40, loss=0.0314, recon=0.0313, kl=0.4690, beta=0.0001\n",
      "Batch 60, loss=0.0336, recon=0.0336, kl=0.1923, beta=0.0001\n",
      "Batch 80, loss=0.1388, recon=0.1388, kl=0.1204, beta=0.0001\n",
      "Batch 100, loss=0.0324, recon=0.0324, kl=0.1770, beta=0.0001\n",
      "Batch 120, loss=0.0591, recon=0.0591, kl=0.1282, beta=0.0001\n",
      "Batch 140, loss=0.0268, recon=0.0268, kl=0.1071, beta=0.0001\n",
      "Batch 160, loss=0.0367, recon=0.0367, kl=0.2831, beta=0.0001\n",
      "Batch 180, loss=0.0441, recon=0.0441, kl=0.1327, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0445, KL: 0.4277, Current Beta: 0.0001) | Avg Valid Loss: 0.0418 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0330, recon=0.0330, kl=0.0175, beta=0.0003\n",
      "Batch 40, loss=0.0306, recon=0.0306, kl=0.0189, beta=0.0003\n",
      "Batch 60, loss=0.0491, recon=0.0491, kl=0.0604, beta=0.0003\n",
      "Batch 80, loss=0.0421, recon=0.0421, kl=0.0760, beta=0.0003\n",
      "Batch 100, loss=0.0337, recon=0.0336, kl=0.0604, beta=0.0003\n",
      "Batch 120, loss=0.0746, recon=0.0746, kl=0.0459, beta=0.0003\n",
      "Batch 140, loss=0.0245, recon=0.0245, kl=0.0088, beta=0.0003\n",
      "Batch 160, loss=0.0278, recon=0.0278, kl=0.0080, beta=0.0003\n",
      "Batch 180, loss=0.0317, recon=0.0317, kl=0.0071, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 0.0424, Current Beta: 0.0003) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0283, recon=0.0283, kl=0.0030, beta=0.0008\n",
      "Batch 40, loss=0.0603, recon=0.0603, kl=0.0048, beta=0.0008\n",
      "Batch 60, loss=0.0256, recon=0.0256, kl=0.0105, beta=0.0008\n",
      "Batch 80, loss=0.0245, recon=0.0245, kl=0.0028, beta=0.0008\n",
      "Batch 100, loss=0.0210, recon=0.0210, kl=0.0025, beta=0.0008\n",
      "Batch 120, loss=0.0306, recon=0.0306, kl=0.0043, beta=0.0008\n",
      "Batch 140, loss=0.0243, recon=0.0243, kl=0.0044, beta=0.0008\n",
      "Batch 160, loss=0.0305, recon=0.0305, kl=0.0039, beta=0.0008\n",
      "Batch 180, loss=0.0299, recon=0.0299, kl=0.0038, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0399, KL: 0.0066, Current Beta: 0.0008) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0260, recon=0.0258, kl=0.0931, beta=0.0018\n",
      "Batch 40, loss=0.0877, recon=0.0876, kl=0.0193, beta=0.0018\n",
      "Batch 60, loss=0.0563, recon=0.0563, kl=0.0149, beta=0.0018\n",
      "Batch 80, loss=0.0346, recon=0.0346, kl=0.0078, beta=0.0018\n",
      "Batch 100, loss=0.0485, recon=0.0485, kl=0.0034, beta=0.0018\n",
      "Batch 120, loss=0.0309, recon=0.0309, kl=0.0019, beta=0.0018\n",
      "Batch 140, loss=0.0350, recon=0.0350, kl=0.0042, beta=0.0018\n",
      "Batch 160, loss=0.0296, recon=0.0296, kl=0.0017, beta=0.0018\n",
      "Batch 180, loss=0.0402, recon=0.0402, kl=0.0015, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0517 (Recon: 0.0517, KL: 0.0064, Current Beta: 0.0018) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0254, recon=0.0254, kl=0.0003, beta=0.0038\n",
      "Batch 40, loss=0.0275, recon=0.0275, kl=0.0005, beta=0.0038\n",
      "Batch 60, loss=0.0399, recon=0.0399, kl=0.0004, beta=0.0038\n",
      "Batch 80, loss=0.0268, recon=0.0268, kl=0.0015, beta=0.0038\n",
      "Batch 100, loss=0.0270, recon=0.0270, kl=0.0012, beta=0.0038\n",
      "Batch 120, loss=0.0395, recon=0.0395, kl=0.0011, beta=0.0038\n",
      "Batch 140, loss=0.0424, recon=0.0424, kl=0.0016, beta=0.0038\n",
      "Batch 160, loss=0.0350, recon=0.0350, kl=0.0006, beta=0.0038\n",
      "Batch 180, loss=0.0444, recon=0.0444, kl=0.0018, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0431, KL: 0.0020, Current Beta: 0.0038) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0199, recon=0.0199, kl=0.0012, beta=0.0062\n",
      "Batch 40, loss=0.0292, recon=0.0292, kl=0.0007, beta=0.0062\n",
      "Batch 60, loss=0.0507, recon=0.0507, kl=0.0011, beta=0.0062\n",
      "Batch 80, loss=0.0423, recon=0.0423, kl=0.0004, beta=0.0062\n",
      "Batch 100, loss=0.1159, recon=0.1158, kl=0.0100, beta=0.0062\n",
      "Batch 120, loss=0.0274, recon=0.0274, kl=0.0005, beta=0.0062\n",
      "Batch 140, loss=0.0418, recon=0.0418, kl=0.0006, beta=0.0062\n",
      "Batch 160, loss=0.1382, recon=0.1382, kl=0.0003, beta=0.0062\n",
      "Batch 180, loss=0.0568, recon=0.0568, kl=0.0006, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0417, KL: 0.0024, Current Beta: 0.0062) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0361\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0272, recon=0.0271, kl=0.0009, beta=0.0100\n",
      "Batch 40, loss=0.0290, recon=0.0290, kl=0.0015, beta=0.0100\n",
      "Batch 60, loss=0.0311, recon=0.0310, kl=0.0029, beta=0.0100\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=0.0013, beta=0.0100\n",
      "Batch 100, loss=0.0602, recon=0.0602, kl=0.0007, beta=0.0100\n",
      "Batch 120, loss=0.0663, recon=0.0663, kl=0.0008, beta=0.0100\n",
      "Batch 140, loss=0.0392, recon=0.0392, kl=0.0002, beta=0.0100\n",
      "Batch 160, loss=0.0241, recon=0.0241, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0245, recon=0.0245, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0434, KL: 0.0016, Current Beta: 0.0100) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0346\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0503, recon=0.0503, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0193, recon=0.0193, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0339, recon=0.0339, kl=0.0007, beta=0.0100\n",
      "Batch 80, loss=0.0395, recon=0.0395, kl=0.0002, beta=0.0100\n",
      "Batch 100, loss=0.0330, recon=0.0330, kl=0.0002, beta=0.0100\n",
      "Batch 120, loss=0.0397, recon=0.0397, kl=0.0005, beta=0.0100\n",
      "Batch 140, loss=0.0853, recon=0.0853, kl=0.0002, beta=0.0100\n",
      "Batch 160, loss=0.0412, recon=0.0412, kl=0.0004, beta=0.0100\n",
      "Batch 180, loss=0.0301, recon=0.0301, kl=0.0004, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 0.0006, Current Beta: 0.0100) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0310, recon=0.0310, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0354, recon=0.0354, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0489, recon=0.0489, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0255, recon=0.0255, kl=0.0002, beta=0.0100\n",
      "Batch 100, loss=0.0432, recon=0.0432, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0301, recon=0.0301, kl=0.0002, beta=0.0100\n",
      "Batch 140, loss=0.0472, recon=0.0472, kl=0.0002, beta=0.0100\n",
      "Batch 160, loss=0.0443, recon=0.0443, kl=0.0004, beta=0.0100\n",
      "Batch 180, loss=0.0484, recon=0.0484, kl=0.0010, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0410, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0363, recon=0.0363, kl=0.0005, beta=0.0100\n",
      "Batch 40, loss=0.0357, recon=0.0357, kl=0.0006, beta=0.0100\n",
      "Batch 60, loss=0.0510, recon=0.0510, kl=0.0005, beta=0.0100\n",
      "Batch 80, loss=0.0351, recon=0.0351, kl=0.0003, beta=0.0100\n",
      "Batch 100, loss=0.0559, recon=0.0559, kl=0.0002, beta=0.0100\n",
      "Batch 120, loss=0.0218, recon=0.0218, kl=0.0008, beta=0.0100\n",
      "Batch 140, loss=0.0276, recon=0.0276, kl=0.0004, beta=0.0100\n",
      "Batch 160, loss=0.0670, recon=0.0670, kl=0.0020, beta=0.0100\n",
      "Batch 180, loss=0.0461, recon=0.0461, kl=0.0007, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0387 (Recon: 0.0387, KL: 0.0008, Current Beta: 0.0100) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0327, recon=0.0327, kl=0.0005, beta=0.0100\n",
      "Batch 40, loss=0.1047, recon=0.1047, kl=0.0004, beta=0.0100\n",
      "Batch 60, loss=0.0217, recon=0.0216, kl=0.0005, beta=0.0100\n",
      "Batch 80, loss=0.0359, recon=0.0359, kl=0.0005, beta=0.0100\n",
      "Batch 100, loss=0.0294, recon=0.0294, kl=0.0007, beta=0.0100\n",
      "Batch 120, loss=0.0324, recon=0.0324, kl=0.0004, beta=0.0100\n",
      "Batch 140, loss=0.0221, recon=0.0221, kl=0.0003, beta=0.0100\n",
      "Batch 160, loss=0.0207, recon=0.0207, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0383, recon=0.0383, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0377, KL: 0.0006, Current Beta: 0.0100) | Avg Valid Loss: 0.0331 | Avg Valid recon Loss: 0.0331\n",
      "\n",
      "[VRAE Run 83/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4336, recon=0.4336, kl=0.5864, beta=0.0000\n",
      "Batch 40, loss=0.3896, recon=0.3896, kl=1.8118, beta=0.0000\n",
      "Batch 60, loss=0.2839, recon=0.2839, kl=36.4772, beta=0.0000\n",
      "Batch 80, loss=0.2691, recon=0.2691, kl=68.9359, beta=0.0000\n",
      "Batch 100, loss=0.2216, recon=0.2216, kl=88.1290, beta=0.0000\n",
      "Batch 120, loss=0.2207, recon=0.2207, kl=99.1992, beta=0.0000\n",
      "Batch 140, loss=0.2685, recon=0.2685, kl=105.7330, beta=0.0000\n",
      "Batch 160, loss=0.1332, recon=0.1332, kl=111.0336, beta=0.0000\n",
      "Batch 180, loss=0.1309, recon=0.1309, kl=116.8333, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3105 (Recon: 0.3105, KL: 63.7062, Current Beta: 0.0000) | Avg Valid Loss: 0.1383 | Avg Valid recon Loss: 0.1383\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1220, recon=0.1220, kl=120.9719, beta=0.0000\n",
      "Batch 40, loss=0.1622, recon=0.1622, kl=126.5849, beta=0.0000\n",
      "Batch 60, loss=0.1223, recon=0.1223, kl=127.9754, beta=0.0000\n",
      "Batch 80, loss=0.1144, recon=0.1144, kl=126.0789, beta=0.0000\n",
      "Batch 100, loss=0.1248, recon=0.1248, kl=126.0484, beta=0.0000\n",
      "Batch 120, loss=0.1066, recon=0.1066, kl=126.3901, beta=0.0000\n",
      "Batch 140, loss=0.0886, recon=0.0886, kl=128.0750, beta=0.0000\n",
      "Batch 160, loss=0.0914, recon=0.0914, kl=128.0739, beta=0.0000\n",
      "Batch 180, loss=0.0608, recon=0.0608, kl=128.6453, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1461 (Recon: 0.1461, KL: 125.8134, Current Beta: 0.0000) | Avg Valid Loss: 0.0981 | Avg Valid recon Loss: 0.0981\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0927, recon=0.0927, kl=121.9790, beta=0.0000\n",
      "Batch 40, loss=0.0684, recon=0.0683, kl=116.0509, beta=0.0000\n",
      "Batch 60, loss=0.1164, recon=0.1164, kl=114.6872, beta=0.0000\n",
      "Batch 80, loss=0.1023, recon=0.1023, kl=113.5186, beta=0.0000\n",
      "Batch 100, loss=0.0711, recon=0.0711, kl=110.1489, beta=0.0000\n",
      "Batch 120, loss=0.0746, recon=0.0746, kl=109.8126, beta=0.0000\n",
      "Batch 140, loss=0.0940, recon=0.0940, kl=111.7229, beta=0.0000\n",
      "Batch 160, loss=0.0840, recon=0.0840, kl=111.9870, beta=0.0000\n",
      "Batch 180, loss=0.0988, recon=0.0988, kl=110.2263, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1110 (Recon: 0.1110, KL: 114.2980, Current Beta: 0.0000) | Avg Valid Loss: 0.0801 | Avg Valid recon Loss: 0.0801\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0897, recon=0.0897, kl=101.9330, beta=0.0000\n",
      "Batch 40, loss=0.0932, recon=0.0932, kl=91.7271, beta=0.0000\n",
      "Batch 60, loss=0.0634, recon=0.0634, kl=84.6092, beta=0.0000\n",
      "Batch 80, loss=0.0646, recon=0.0646, kl=84.5608, beta=0.0000\n",
      "Batch 100, loss=0.0808, recon=0.0808, kl=78.8461, beta=0.0000\n",
      "Batch 120, loss=0.1602, recon=0.1602, kl=77.9147, beta=0.0000\n",
      "Batch 140, loss=0.0598, recon=0.0598, kl=79.7647, beta=0.0000\n",
      "Batch 160, loss=0.0488, recon=0.0488, kl=83.5124, beta=0.0000\n",
      "Batch 180, loss=0.0907, recon=0.0907, kl=79.1667, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0914 (Recon: 0.0914, KL: 86.3468, Current Beta: 0.0000) | Avg Valid Loss: 0.0720 | Avg Valid recon Loss: 0.0720\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0701, recon=0.0700, kl=60.9090, beta=0.0000\n",
      "Batch 40, loss=0.0558, recon=0.0557, kl=46.2603, beta=0.0000\n",
      "Batch 60, loss=0.0513, recon=0.0513, kl=44.2133, beta=0.0000\n",
      "Batch 80, loss=0.0510, recon=0.0509, kl=45.4396, beta=0.0000\n",
      "Batch 100, loss=0.0617, recon=0.0616, kl=45.1463, beta=0.0000\n",
      "Batch 120, loss=0.0579, recon=0.0578, kl=43.4152, beta=0.0000\n",
      "Batch 140, loss=0.0511, recon=0.0511, kl=41.0461, beta=0.0000\n",
      "Batch 160, loss=1.4462, recon=1.4461, kl=38.8026, beta=0.0000\n",
      "Batch 180, loss=0.0639, recon=0.0639, kl=40.1073, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0795 (Recon: 0.0794, KL: 46.7379, Current Beta: 0.0000) | Avg Valid Loss: 0.0646 | Avg Valid recon Loss: 0.0645\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0600, recon=0.0600, kl=22.4427, beta=0.0000\n",
      "Batch 40, loss=0.0895, recon=0.0895, kl=21.1412, beta=0.0000\n",
      "Batch 60, loss=0.0568, recon=0.0568, kl=18.0373, beta=0.0000\n",
      "Batch 80, loss=0.0458, recon=0.0457, kl=17.7387, beta=0.0000\n",
      "Batch 100, loss=0.0406, recon=0.0405, kl=16.9727, beta=0.0000\n",
      "Batch 120, loss=0.3767, recon=0.3767, kl=18.4091, beta=0.0000\n",
      "Batch 140, loss=0.0551, recon=0.0551, kl=16.8213, beta=0.0000\n",
      "Batch 160, loss=0.0540, recon=0.0540, kl=13.6500, beta=0.0000\n",
      "Batch 180, loss=0.0713, recon=0.0713, kl=15.6853, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0718 (Recon: 0.0718, KL: 19.1291, Current Beta: 0.0000) | Avg Valid Loss: 0.0590 | Avg Valid recon Loss: 0.0590\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1740, recon=0.1739, kl=6.8570, beta=0.0000\n",
      "Batch 40, loss=0.0387, recon=0.0387, kl=6.7140, beta=0.0000\n",
      "Batch 60, loss=1.1824, recon=1.1824, kl=4.9850, beta=0.0000\n",
      "Batch 80, loss=0.0460, recon=0.0459, kl=5.5784, beta=0.0000\n",
      "Batch 100, loss=0.0623, recon=0.0623, kl=5.3925, beta=0.0000\n",
      "Batch 120, loss=0.0567, recon=0.0567, kl=4.7999, beta=0.0000\n",
      "Batch 140, loss=0.0320, recon=0.0320, kl=6.3380, beta=0.0000\n",
      "Batch 160, loss=0.0529, recon=0.0529, kl=5.4784, beta=0.0000\n",
      "Batch 180, loss=0.1271, recon=0.1271, kl=4.0103, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0660 (Recon: 0.0660, KL: 6.0841, Current Beta: 0.0000) | Avg Valid Loss: 0.0555 | Avg Valid recon Loss: 0.0555\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0355, recon=0.0355, kl=2.3578, beta=0.0000\n",
      "Batch 40, loss=0.0557, recon=0.0557, kl=1.8617, beta=0.0000\n",
      "Batch 60, loss=0.0306, recon=0.0306, kl=1.9133, beta=0.0000\n",
      "Batch 80, loss=0.0356, recon=0.0356, kl=1.9203, beta=0.0000\n",
      "Batch 100, loss=0.0334, recon=0.0333, kl=1.7370, beta=0.0000\n",
      "Batch 120, loss=0.1480, recon=0.1480, kl=1.6182, beta=0.0000\n",
      "Batch 140, loss=0.0417, recon=0.0417, kl=1.6125, beta=0.0000\n",
      "Batch 160, loss=0.0528, recon=0.0528, kl=1.6918, beta=0.0000\n",
      "Batch 180, loss=0.0328, recon=0.0328, kl=1.1856, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0621 (Recon: 0.0621, KL: 1.8898, Current Beta: 0.0000) | Avg Valid Loss: 0.0534 | Avg Valid recon Loss: 0.0533\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0424, recon=0.0424, kl=0.5304, beta=0.0000\n",
      "Batch 40, loss=0.0513, recon=0.0513, kl=0.6817, beta=0.0000\n",
      "Batch 60, loss=0.0429, recon=0.0428, kl=0.4839, beta=0.0000\n",
      "Batch 80, loss=0.0542, recon=0.0542, kl=0.4996, beta=0.0000\n",
      "Batch 100, loss=0.0442, recon=0.0442, kl=0.3697, beta=0.0000\n",
      "Batch 120, loss=0.0509, recon=0.0509, kl=0.3370, beta=0.0000\n",
      "Batch 140, loss=0.0392, recon=0.0392, kl=0.3982, beta=0.0000\n",
      "Batch 160, loss=0.0411, recon=0.0411, kl=0.3187, beta=0.0000\n",
      "Batch 180, loss=0.0296, recon=0.0296, kl=0.2756, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0589 (Recon: 0.0589, KL: 0.4765, Current Beta: 0.0000) | Avg Valid Loss: 0.0505 | Avg Valid recon Loss: 0.0505\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0299, recon=0.0298, kl=0.0696, beta=0.0001\n",
      "Batch 40, loss=0.0454, recon=0.0454, kl=0.0870, beta=0.0001\n",
      "Batch 60, loss=0.0359, recon=0.0359, kl=0.0667, beta=0.0001\n",
      "Batch 80, loss=0.0327, recon=0.0327, kl=0.0411, beta=0.0001\n",
      "Batch 100, loss=0.0441, recon=0.0441, kl=0.0467, beta=0.0001\n",
      "Batch 120, loss=0.0401, recon=0.0401, kl=0.0468, beta=0.0001\n",
      "Batch 140, loss=0.0345, recon=0.0345, kl=0.0299, beta=0.0001\n",
      "Batch 160, loss=0.0327, recon=0.0327, kl=0.0204, beta=0.0001\n",
      "Batch 180, loss=0.0279, recon=0.0279, kl=0.0214, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0562 (Recon: 0.0562, KL: 0.0608, Current Beta: 0.0001) | Avg Valid Loss: 0.0492 | Avg Valid recon Loss: 0.0492\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0290, recon=0.0290, kl=0.0046, beta=0.0003\n",
      "Batch 40, loss=0.0341, recon=0.0341, kl=0.0067, beta=0.0003\n",
      "Batch 60, loss=0.0298, recon=0.0298, kl=0.0044, beta=0.0003\n",
      "Batch 80, loss=0.0285, recon=0.0285, kl=0.0034, beta=0.0003\n",
      "Batch 100, loss=0.0473, recon=0.0473, kl=0.0049, beta=0.0003\n",
      "Batch 120, loss=0.0473, recon=0.0473, kl=0.0017, beta=0.0003\n",
      "Batch 140, loss=0.1473, recon=0.1473, kl=0.0029, beta=0.0003\n",
      "Batch 160, loss=0.0305, recon=0.0305, kl=0.0017, beta=0.0003\n",
      "Batch 180, loss=0.0356, recon=0.0356, kl=0.0016, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0541 (Recon: 0.0541, KL: 0.0049, Current Beta: 0.0003) | Avg Valid Loss: 0.0470 | Avg Valid recon Loss: 0.0470\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0405, recon=0.0405, kl=0.0012, beta=0.0008\n",
      "Batch 40, loss=0.0303, recon=0.0303, kl=0.0010, beta=0.0008\n",
      "Batch 60, loss=0.0364, recon=0.0364, kl=0.0011, beta=0.0008\n",
      "Batch 80, loss=0.0548, recon=0.0548, kl=0.0008, beta=0.0008\n",
      "Batch 100, loss=0.0707, recon=0.0707, kl=0.0014, beta=0.0008\n",
      "Batch 120, loss=0.0343, recon=0.0343, kl=0.0006, beta=0.0008\n",
      "Batch 140, loss=0.0367, recon=0.0367, kl=0.0003, beta=0.0008\n",
      "Batch 160, loss=0.0393, recon=0.0393, kl=0.0005, beta=0.0008\n",
      "Batch 180, loss=0.0639, recon=0.0639, kl=0.0004, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0522 (Recon: 0.0522, KL: 0.0009, Current Beta: 0.0008) | Avg Valid Loss: 0.0446 | Avg Valid recon Loss: 0.0446\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0318, recon=0.0318, kl=0.0003, beta=0.0018\n",
      "Batch 40, loss=0.0259, recon=0.0259, kl=0.0007, beta=0.0018\n",
      "Batch 60, loss=0.0581, recon=0.0581, kl=0.0004, beta=0.0018\n",
      "Batch 80, loss=0.0828, recon=0.0828, kl=0.0007, beta=0.0018\n",
      "Batch 100, loss=0.8214, recon=0.8214, kl=0.0002, beta=0.0018\n",
      "Batch 120, loss=0.0464, recon=0.0464, kl=0.0003, beta=0.0018\n",
      "Batch 140, loss=0.0390, recon=0.0390, kl=0.0001, beta=0.0018\n",
      "Batch 160, loss=0.0380, recon=0.0380, kl=0.0001, beta=0.0018\n",
      "Batch 180, loss=0.0310, recon=0.0310, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0505 (Recon: 0.0505, KL: 0.0004, Current Beta: 0.0018) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1915, recon=0.1915, kl=0.0000, beta=0.0038\n",
      "Batch 40, loss=0.0340, recon=0.0340, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.0265, recon=0.0265, kl=0.0002, beta=0.0038\n",
      "Batch 80, loss=0.0325, recon=0.0325, kl=0.0002, beta=0.0038\n",
      "Batch 100, loss=0.0279, recon=0.0279, kl=0.0001, beta=0.0038\n",
      "Batch 120, loss=0.0359, recon=0.0359, kl=0.0003, beta=0.0038\n",
      "Batch 140, loss=0.2038, recon=0.2038, kl=0.0009, beta=0.0038\n",
      "Batch 160, loss=0.0320, recon=0.0320, kl=0.0001, beta=0.0038\n",
      "Batch 180, loss=0.0353, recon=0.0353, kl=0.0000, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0489 (Recon: 0.0489, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0429 | Avg Valid recon Loss: 0.0429\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0297, recon=0.0297, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0501, recon=0.0501, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0413, recon=0.0413, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0221, recon=0.0221, kl=0.0001, beta=0.0062\n",
      "Batch 100, loss=0.0362, recon=0.0362, kl=0.0000, beta=0.0062\n",
      "Batch 120, loss=0.0323, recon=0.0323, kl=0.0001, beta=0.0062\n",
      "Batch 140, loss=0.0306, recon=0.0306, kl=0.0001, beta=0.0062\n",
      "Batch 160, loss=0.0419, recon=0.0419, kl=0.0001, beta=0.0062\n",
      "Batch 180, loss=0.0274, recon=0.0274, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0478 (Recon: 0.0478, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0471, recon=0.0471, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0237, recon=0.0237, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0519, recon=0.0519, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0283, recon=0.0283, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0349, recon=0.0349, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0667, recon=0.0667, kl=0.0004, beta=0.0100\n",
      "Batch 140, loss=0.0410, recon=0.0410, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0413, recon=0.0413, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0299, recon=0.0299, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0464 (Recon: 0.0464, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0254, recon=0.0254, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0328, recon=0.0328, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0261, recon=0.0261, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0326, recon=0.0326, kl=0.0016, beta=0.0100\n",
      "Batch 100, loss=0.0278, recon=0.0278, kl=0.0006, beta=0.0100\n",
      "Batch 120, loss=0.0577, recon=0.0577, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.1426, recon=0.1426, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0341, recon=0.0341, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.1378, recon=0.1378, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0452 (Recon: 0.0452, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0370, recon=0.0370, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0269, recon=0.0269, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0321, recon=0.0321, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0322, recon=0.0322, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0514, recon=0.0514, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0220, recon=0.0220, kl=0.0003, beta=0.0100\n",
      "Batch 160, loss=0.1121, recon=0.1121, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0319, recon=0.0319, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0445 (Recon: 0.0445, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0394\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0526, recon=0.0526, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0391, recon=0.0391, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0540, recon=0.0540, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0348, recon=0.0348, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0361, recon=0.0361, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0267, recon=0.0267, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0233, recon=0.0233, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0456, recon=0.0456, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0334, recon=0.0334, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0436 (Recon: 0.0436, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0441, recon=0.0441, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0631, recon=0.0631, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0374, recon=0.0374, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0397, recon=0.0397, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0291, recon=0.0291, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0407, recon=0.0407, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0352, recon=0.0352, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0385, recon=0.0385, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0575, recon=0.0575, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0428, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0376\n",
      "\n",
      "[VRAE Run 84/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1747, recon=0.1747, kl=53.3701, beta=0.0000\n",
      "Batch 40, loss=0.1198, recon=0.1198, kl=86.2894, beta=0.0000\n",
      "Batch 60, loss=0.0771, recon=0.0771, kl=101.8699, beta=0.0000\n",
      "Batch 80, loss=0.1642, recon=0.1642, kl=83.9511, beta=0.0000\n",
      "Batch 100, loss=0.0515, recon=0.0515, kl=88.1549, beta=0.0000\n",
      "Batch 120, loss=0.0798, recon=0.0798, kl=120.6158, beta=0.0000\n",
      "Batch 140, loss=0.0612, recon=0.0612, kl=109.7153, beta=0.0000\n",
      "Batch 160, loss=0.0545, recon=0.0545, kl=109.8946, beta=0.0000\n",
      "Batch 180, loss=0.0753, recon=0.0753, kl=115.2065, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1268 (Recon: 0.1268, KL: 89.9546, Current Beta: 0.0000) | Avg Valid Loss: 0.0604 | Avg Valid recon Loss: 0.0604\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0428, recon=0.0428, kl=115.4821, beta=0.0000\n",
      "Batch 40, loss=0.0462, recon=0.0462, kl=117.0221, beta=0.0000\n",
      "Batch 60, loss=0.0560, recon=0.0560, kl=113.1927, beta=0.0000\n",
      "Batch 80, loss=0.0647, recon=0.0647, kl=111.9318, beta=0.0000\n",
      "Batch 100, loss=0.0553, recon=0.0553, kl=111.5994, beta=0.0000\n",
      "Batch 120, loss=0.0471, recon=0.0471, kl=111.1712, beta=0.0000\n",
      "Batch 140, loss=0.0517, recon=0.0517, kl=108.1664, beta=0.0000\n",
      "Batch 160, loss=0.0365, recon=0.0365, kl=101.7057, beta=0.0000\n",
      "Batch 180, loss=0.0436, recon=0.0436, kl=113.4995, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0644 (Recon: 0.0644, KL: 111.5477, Current Beta: 0.0000) | Avg Valid Loss: 0.0550 | Avg Valid recon Loss: 0.0550\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0498, recon=0.0498, kl=123.1396, beta=0.0000\n",
      "Batch 40, loss=0.0412, recon=0.0412, kl=109.0624, beta=0.0000\n",
      "Batch 60, loss=0.0427, recon=0.0427, kl=111.2891, beta=0.0000\n",
      "Batch 80, loss=0.0336, recon=0.0336, kl=112.3755, beta=0.0000\n",
      "Batch 100, loss=0.0447, recon=0.0447, kl=118.2005, beta=0.0000\n",
      "Batch 120, loss=0.0552, recon=0.0552, kl=116.4446, beta=0.0000\n",
      "Batch 140, loss=0.0313, recon=0.0313, kl=119.5665, beta=0.0000\n",
      "Batch 160, loss=0.0407, recon=0.0407, kl=117.7401, beta=0.0000\n",
      "Batch 180, loss=0.0473, recon=0.0473, kl=120.5765, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0554, KL: 116.5519, Current Beta: 0.0000) | Avg Valid Loss: 0.0490 | Avg Valid recon Loss: 0.0489\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0569, recon=0.0569, kl=101.6793, beta=0.0000\n",
      "Batch 40, loss=0.0411, recon=0.0411, kl=97.0609, beta=0.0000\n",
      "Batch 60, loss=0.0390, recon=0.0390, kl=94.3094, beta=0.0000\n",
      "Batch 80, loss=0.0387, recon=0.0387, kl=103.2330, beta=0.0000\n",
      "Batch 100, loss=0.0470, recon=0.0470, kl=97.5569, beta=0.0000\n",
      "Batch 120, loss=0.1630, recon=0.1629, kl=99.4037, beta=0.0000\n",
      "Batch 140, loss=0.0791, recon=0.0790, kl=104.7963, beta=0.0000\n",
      "Batch 160, loss=0.0375, recon=0.0375, kl=99.7976, beta=0.0000\n",
      "Batch 180, loss=0.0353, recon=0.0353, kl=95.3318, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0534, KL: 100.6238, Current Beta: 0.0000) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0412, recon=0.0411, kl=77.7785, beta=0.0000\n",
      "Batch 40, loss=0.0289, recon=0.0288, kl=81.5375, beta=0.0000\n",
      "Batch 60, loss=0.0537, recon=0.0536, kl=79.6440, beta=0.0000\n",
      "Batch 80, loss=0.0405, recon=0.0404, kl=76.4074, beta=0.0000\n",
      "Batch 100, loss=0.0508, recon=0.0507, kl=80.3880, beta=0.0000\n",
      "Batch 120, loss=0.0319, recon=0.0318, kl=85.5376, beta=0.0000\n",
      "Batch 140, loss=0.0327, recon=0.0326, kl=86.2166, beta=0.0000\n",
      "Batch 160, loss=0.0790, recon=0.0789, kl=81.2633, beta=0.0000\n",
      "Batch 180, loss=0.0266, recon=0.0265, kl=75.9477, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0500 (Recon: 0.0499, KL: 81.6211, Current Beta: 0.0000) | Avg Valid Loss: 0.0404 | Avg Valid recon Loss: 0.0404\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0329, recon=0.0328, kl=58.1702, beta=0.0000\n",
      "Batch 40, loss=0.0357, recon=0.0356, kl=50.5894, beta=0.0000\n",
      "Batch 60, loss=0.0362, recon=0.0361, kl=51.1284, beta=0.0000\n",
      "Batch 80, loss=0.0823, recon=0.0822, kl=50.9595, beta=0.0000\n",
      "Batch 100, loss=0.1138, recon=0.1137, kl=50.5859, beta=0.0000\n",
      "Batch 120, loss=0.0307, recon=0.0306, kl=52.9095, beta=0.0000\n",
      "Batch 140, loss=0.0330, recon=0.0329, kl=52.8141, beta=0.0000\n",
      "Batch 160, loss=0.0453, recon=0.0452, kl=60.2859, beta=0.0000\n",
      "Batch 180, loss=0.0473, recon=0.0472, kl=61.7671, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0471 (Recon: 0.0470, KL: 55.3708, Current Beta: 0.0000) | Avg Valid Loss: 0.0470 | Avg Valid recon Loss: 0.0469\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0361, recon=0.0359, kl=33.9301, beta=0.0000\n",
      "Batch 40, loss=0.0421, recon=0.0419, kl=34.3830, beta=0.0000\n",
      "Batch 60, loss=0.0504, recon=0.0502, kl=48.8229, beta=0.0000\n",
      "Batch 80, loss=0.0876, recon=0.0874, kl=41.6549, beta=0.0000\n",
      "Batch 100, loss=0.0290, recon=0.0287, kl=45.2339, beta=0.0000\n",
      "Batch 120, loss=0.0453, recon=0.0450, kl=51.4147, beta=0.0000\n",
      "Batch 140, loss=0.0306, recon=0.0303, kl=44.8815, beta=0.0000\n",
      "Batch 160, loss=0.0278, recon=0.0276, kl=38.3377, beta=0.0000\n",
      "Batch 180, loss=0.1501, recon=0.1499, kl=34.7457, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0500 (Recon: 0.0498, KL: 42.6564, Current Beta: 0.0000) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0430, recon=0.0427, kl=19.9103, beta=0.0000\n",
      "Batch 40, loss=0.0429, recon=0.0425, kl=28.2346, beta=0.0000\n",
      "Batch 60, loss=0.0494, recon=0.0488, kl=39.8938, beta=0.0000\n",
      "Batch 80, loss=0.0417, recon=0.0413, kl=27.3224, beta=0.0000\n",
      "Batch 100, loss=0.0255, recon=0.0252, kl=20.3172, beta=0.0000\n",
      "Batch 120, loss=0.0397, recon=0.0394, kl=18.3865, beta=0.0000\n",
      "Batch 140, loss=0.0552, recon=0.0550, kl=17.5812, beta=0.0000\n",
      "Batch 160, loss=0.0274, recon=0.0271, kl=19.2687, beta=0.0000\n",
      "Batch 180, loss=0.0349, recon=0.0346, kl=15.9485, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0456, KL: 23.7574, Current Beta: 0.0000) | Avg Valid Loss: 0.0366 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0342, recon=0.0338, kl=9.6845, beta=0.0000\n",
      "Batch 40, loss=0.0296, recon=0.0293, kl=7.1713, beta=0.0000\n",
      "Batch 60, loss=0.0262, recon=0.0259, kl=6.0862, beta=0.0000\n",
      "Batch 80, loss=0.0324, recon=0.0322, kl=5.0847, beta=0.0000\n",
      "Batch 100, loss=0.0259, recon=0.0257, kl=4.6092, beta=0.0000\n",
      "Batch 120, loss=0.0305, recon=0.0304, kl=3.9307, beta=0.0000\n",
      "Batch 140, loss=0.0422, recon=0.0420, kl=3.6702, beta=0.0000\n",
      "Batch 160, loss=0.1532, recon=0.1531, kl=4.0146, beta=0.0000\n",
      "Batch 180, loss=0.0411, recon=0.0410, kl=2.8957, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0426, KL: 5.9540, Current Beta: 0.0000) | Avg Valid Loss: 0.0503 | Avg Valid recon Loss: 0.0502\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0423, recon=0.0420, kl=2.3931, beta=0.0001\n",
      "Batch 40, loss=0.0352, recon=0.0348, kl=3.6681, beta=0.0001\n",
      "Batch 60, loss=0.0254, recon=0.0247, kl=6.8381, beta=0.0001\n",
      "Batch 80, loss=0.0389, recon=0.0382, kl=6.2338, beta=0.0001\n",
      "Batch 100, loss=0.0509, recon=0.0504, kl=4.5987, beta=0.0001\n",
      "Batch 120, loss=0.0340, recon=0.0337, kl=3.0910, beta=0.0001\n",
      "Batch 140, loss=0.0254, recon=0.0250, kl=3.0082, beta=0.0001\n",
      "Batch 160, loss=0.0367, recon=0.0363, kl=3.8099, beta=0.0001\n",
      "Batch 180, loss=0.0365, recon=0.0360, kl=4.4124, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0477, KL: 4.0920, Current Beta: 0.0001) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0359, recon=0.0331, kl=9.6162, beta=0.0003\n",
      "Batch 40, loss=0.0487, recon=0.0451, kl=12.1152, beta=0.0003\n",
      "Batch 60, loss=0.0557, recon=0.0526, kl=10.5837, beta=0.0003\n",
      "Batch 80, loss=0.0514, recon=0.0484, kl=10.4790, beta=0.0003\n",
      "Batch 100, loss=0.0422, recon=0.0368, kl=18.2430, beta=0.0003\n",
      "Batch 120, loss=0.1537, recon=0.1486, kl=17.5513, beta=0.0003\n",
      "Batch 140, loss=0.0368, recon=0.0297, kl=24.2201, beta=0.0003\n",
      "Batch 160, loss=0.0312, recon=0.0275, kl=12.7776, beta=0.0003\n",
      "Batch 180, loss=1896.2092, recon=1895.9333, kl=940.9725, beta=0.0003\n",
      "  â†’ Avg Train Loss: 7300.8727 (Recon: 7299.5485, KL: 4517.5108, Current Beta: 0.0003) | Avg Valid Loss: 30.8083 | Avg Valid recon Loss: 30.6593\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1130, recon=0.0923, kl=27.2058, beta=0.0008\n",
      "Batch 40, loss=0.0819, recon=0.0577, kl=31.9162, beta=0.0008\n",
      "Batch 60, loss=0.1740, recon=0.1589, kl=19.8544, beta=0.0008\n",
      "Batch 80, loss=0.2104, recon=0.1924, kl=23.8356, beta=0.0008\n",
      "Batch 100, loss=24.2050, recon=24.0638, kl=186.1045, beta=0.0008\n",
      "Batch 120, loss=90.8446, recon=90.8133, kl=41.2587, beta=0.0008\n",
      "Batch 140, loss=0.1252, recon=0.1062, kl=25.1293, beta=0.0008\n",
      "Batch 160, loss=0.1699, recon=0.1512, kl=24.7116, beta=0.0008\n",
      "Batch 180, loss=0.1320, recon=0.1129, kl=25.2231, beta=0.0008\n",
      "  â†’ Avg Train Loss: 46.0229 (Recon: 45.9916, KL: 41.2121, Current Beta: 0.0008) | Avg Valid Loss: 0.2306 | Avg Valid recon Loss: 0.2085\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1698, recon=0.1154, kl=29.8189, beta=0.0018\n",
      "Batch 40, loss=0.1908, recon=0.1092, kl=44.7557, beta=0.0018\n",
      "Batch 60, loss=0.1326, recon=0.0893, kl=23.7523, beta=0.0018\n",
      "Batch 80, loss=0.1404, recon=0.0901, kl=27.6002, beta=0.0018\n",
      "Batch 100, loss=0.1644, recon=0.1140, kl=27.6712, beta=0.0018\n",
      "Batch 120, loss=0.5829, recon=0.5325, kl=27.6298, beta=0.0018\n",
      "Batch 140, loss=0.1082, recon=0.0724, kl=19.6410, beta=0.0018\n",
      "Batch 160, loss=0.0918, recon=0.0586, kl=18.1932, beta=0.0018\n",
      "Batch 180, loss=0.1359, recon=0.1019, kl=18.6197, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.2166 (Recon: 0.1696, KL: 25.7812, Current Beta: 0.0018) | Avg Valid Loss: 0.1189 | Avg Valid recon Loss: 0.0811\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1293, recon=0.0659, kl=16.7884, beta=0.0038\n",
      "Batch 40, loss=0.1199, recon=0.0635, kl=14.9335, beta=0.0038\n",
      "Batch 60, loss=0.5370, recon=0.4538, kl=22.0132, beta=0.0038\n",
      "Batch 80, loss=0.0934, recon=0.0427, kl=13.4386, beta=0.0038\n",
      "Batch 100, loss=0.1355, recon=0.0597, kl=20.0923, beta=0.0038\n",
      "Batch 120, loss=0.1095, recon=0.0686, kl=10.8287, beta=0.0038\n",
      "Batch 140, loss=0.1326, recon=0.0941, kl=10.2005, beta=0.0038\n",
      "Batch 160, loss=0.1296, recon=0.0875, kl=11.1596, beta=0.0038\n",
      "Batch 180, loss=0.0821, recon=0.0512, kl=8.1995, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1448 (Recon: 0.0915, KL: 14.1099, Current Beta: 0.0038) | Avg Valid Loss: 0.1317 | Avg Valid recon Loss: 0.0927\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1270, recon=0.0598, kl=10.7957, beta=0.0062\n",
      "Batch 40, loss=0.1249, recon=0.0599, kl=10.4413, beta=0.0062\n",
      "Batch 60, loss=0.0934, recon=0.0507, kl=6.8690, beta=0.0062\n",
      "Batch 80, loss=0.1537, recon=0.0975, kl=9.0274, beta=0.0062\n",
      "Batch 100, loss=0.1578, recon=0.0977, kl=9.6463, beta=0.0062\n",
      "Batch 120, loss=0.1704, recon=0.0864, kl=13.5040, beta=0.0062\n",
      "Batch 140, loss=0.1291, recon=0.0799, kl=7.8983, beta=0.0062\n",
      "Batch 160, loss=0.1063, recon=0.0581, kl=7.7459, beta=0.0062\n",
      "Batch 180, loss=0.1137, recon=0.0711, kl=6.8536, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.1694 (Recon: 0.1108, KL: 9.4021, Current Beta: 0.0062) | Avg Valid Loss: 0.1396 | Avg Valid recon Loss: 0.0894\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1219, recon=0.0544, kl=6.7490, beta=0.0100\n",
      "Batch 40, loss=0.1698, recon=0.0704, kl=9.9395, beta=0.0100\n",
      "Batch 60, loss=0.1804, recon=0.1081, kl=7.2306, beta=0.0100\n",
      "Batch 80, loss=0.1681, recon=0.0902, kl=7.7843, beta=0.0100\n",
      "Batch 100, loss=0.1255, recon=0.0656, kl=5.9925, beta=0.0100\n",
      "Batch 120, loss=0.1213, recon=0.0683, kl=5.3022, beta=0.0100\n",
      "Batch 140, loss=0.1499, recon=0.0612, kl=8.8781, beta=0.0100\n",
      "Batch 160, loss=1.1564, recon=1.1072, kl=4.9201, beta=0.0100\n",
      "Batch 180, loss=0.1628, recon=0.1152, kl=4.7587, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1735 (Recon: 0.1096, KL: 6.3964, Current Beta: 0.0100) | Avg Valid Loss: 0.1423 | Avg Valid recon Loss: 0.0948\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1667, recon=0.1106, kl=5.6040, beta=0.0100\n",
      "Batch 40, loss=0.1028, recon=0.0646, kl=3.8269, beta=0.0100\n",
      "Batch 60, loss=0.1362, recon=0.0851, kl=5.1053, beta=0.0100\n",
      "Batch 80, loss=0.1213, recon=0.0759, kl=4.5377, beta=0.0100\n",
      "Batch 100, loss=0.1492, recon=0.0939, kl=5.5314, beta=0.0100\n",
      "Batch 120, loss=0.1452, recon=0.1152, kl=3.0052, beta=0.0100\n",
      "Batch 140, loss=1.7267, recon=1.6842, kl=4.2454, beta=0.0100\n",
      "Batch 160, loss=0.2657, recon=0.1007, kl=16.5028, beta=0.0100\n",
      "Batch 180, loss=0.1302, recon=0.0799, kl=5.0311, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1540 (Recon: 0.1083, KL: 4.5644, Current Beta: 0.0100) | Avg Valid Loss: 0.1240 | Avg Valid recon Loss: 0.0782\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1125, recon=0.0610, kl=5.1568, beta=0.0100\n",
      "Batch 40, loss=0.1076, recon=0.0792, kl=2.8425, beta=0.0100\n",
      "Batch 60, loss=0.2765, recon=0.2505, kl=2.6031, beta=0.0100\n",
      "Batch 80, loss=0.8831, recon=0.8335, kl=4.9580, beta=0.0100\n",
      "Batch 100, loss=0.3086, recon=0.2404, kl=6.8226, beta=0.0100\n",
      "Batch 120, loss=0.3320, recon=0.2827, kl=4.9224, beta=0.0100\n",
      "Batch 140, loss=0.3312, recon=0.2742, kl=5.7053, beta=0.0100\n",
      "Batch 160, loss=0.1872, recon=0.1352, kl=5.1954, beta=0.0100\n",
      "Batch 180, loss=0.1864, recon=0.1381, kl=4.8283, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.3482 (Recon: 0.3018, KL: 4.6448, Current Beta: 0.0100) | Avg Valid Loss: 0.1938 | Avg Valid recon Loss: 0.1440\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.2022, recon=0.1603, kl=4.1989, beta=0.0100\n",
      "Batch 40, loss=0.1650, recon=0.1283, kl=3.6753, beta=0.0100\n",
      "Batch 60, loss=0.1827, recon=0.1508, kl=3.1902, beta=0.0100\n",
      "Batch 80, loss=0.1612, recon=0.1284, kl=3.2857, beta=0.0100\n",
      "Batch 100, loss=0.3120, recon=0.2738, kl=3.8248, beta=0.0100\n",
      "Batch 120, loss=0.1107, recon=0.0826, kl=2.8058, beta=0.0100\n",
      "Batch 140, loss=0.1185, recon=0.0899, kl=2.8538, beta=0.0100\n",
      "Batch 160, loss=0.1668, recon=0.1479, kl=1.8850, beta=0.0100\n",
      "Batch 180, loss=0.3571, recon=0.3218, kl=3.5215, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.2048 (Recon: 0.1697, KL: 3.5096, Current Beta: 0.0100) | Avg Valid Loss: 1.3850 | Avg Valid recon Loss: 1.3520\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1288, recon=0.0964, kl=3.2432, beta=0.0100\n",
      "Batch 40, loss=0.1337, recon=0.0910, kl=4.2673, beta=0.0100\n",
      "Batch 60, loss=0.2290, recon=0.1747, kl=5.4294, beta=0.0100\n",
      "Batch 80, loss=0.1682, recon=0.1157, kl=5.2421, beta=0.0100\n",
      "Batch 100, loss=0.1591, recon=0.1298, kl=2.9278, beta=0.0100\n",
      "Batch 120, loss=0.1926, recon=0.1620, kl=3.0532, beta=0.0100\n",
      "Batch 140, loss=0.1676, recon=0.1192, kl=4.8405, beta=0.0100\n",
      "Batch 160, loss=0.1291, recon=0.0912, kl=3.7911, beta=0.0100\n",
      "Batch 180, loss=0.1133, recon=0.0703, kl=4.3043, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.2490 (Recon: 0.2092, KL: 3.9722, Current Beta: 0.0100) | Avg Valid Loss: 0.1404 | Avg Valid recon Loss: 0.0990\n",
      "\n",
      "[VRAE Run 85/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3004, recon=0.3004, kl=0.4680, beta=0.0000\n",
      "Batch 40, loss=0.1821, recon=0.1821, kl=9.4355, beta=0.0000\n",
      "Batch 60, loss=0.3532, recon=0.3532, kl=20.0829, beta=0.0000\n",
      "Batch 80, loss=0.1122, recon=0.1122, kl=24.8688, beta=0.0000\n",
      "Batch 100, loss=0.1133, recon=0.1133, kl=27.5261, beta=0.0000\n",
      "Batch 120, loss=0.0882, recon=0.0882, kl=28.1174, beta=0.0000\n",
      "Batch 140, loss=0.1044, recon=0.1044, kl=30.8583, beta=0.0000\n",
      "Batch 160, loss=0.1280, recon=0.1280, kl=32.0593, beta=0.0000\n",
      "Batch 180, loss=0.1082, recon=0.1082, kl=32.9907, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2247 (Recon: 0.2247, KL: 21.2605, Current Beta: 0.0000) | Avg Valid Loss: 0.0941 | Avg Valid recon Loss: 0.0941\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0697, recon=0.0697, kl=34.1623, beta=0.0000\n",
      "Batch 40, loss=0.0888, recon=0.0888, kl=37.2102, beta=0.0000\n",
      "Batch 60, loss=0.0906, recon=0.0906, kl=38.0007, beta=0.0000\n",
      "Batch 80, loss=0.0985, recon=0.0985, kl=40.8657, beta=0.0000\n",
      "Batch 100, loss=0.0786, recon=0.0786, kl=45.0258, beta=0.0000\n",
      "Batch 120, loss=0.0625, recon=0.0625, kl=45.3655, beta=0.0000\n",
      "Batch 140, loss=0.0971, recon=0.0971, kl=48.7253, beta=0.0000\n",
      "Batch 160, loss=0.0923, recon=0.0923, kl=43.5562, beta=0.0000\n",
      "Batch 180, loss=0.0641, recon=0.0641, kl=42.7499, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1094 (Recon: 0.1094, KL: 41.2834, Current Beta: 0.0000) | Avg Valid Loss: 0.0719 | Avg Valid recon Loss: 0.0719\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0734, recon=0.0734, kl=37.1751, beta=0.0000\n",
      "Batch 40, loss=0.0844, recon=0.0844, kl=34.9041, beta=0.0000\n",
      "Batch 60, loss=0.0464, recon=0.0464, kl=31.6723, beta=0.0000\n",
      "Batch 80, loss=0.0586, recon=0.0586, kl=34.8095, beta=0.0000\n",
      "Batch 100, loss=0.0576, recon=0.0576, kl=33.3968, beta=0.0000\n",
      "Batch 120, loss=0.0526, recon=0.0526, kl=32.8830, beta=0.0000\n",
      "Batch 140, loss=0.0783, recon=0.0783, kl=32.3256, beta=0.0000\n",
      "Batch 160, loss=0.0660, recon=0.0660, kl=34.7245, beta=0.0000\n",
      "Batch 180, loss=0.0891, recon=0.0891, kl=31.7572, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0846 (Recon: 0.0846, KL: 34.4699, Current Beta: 0.0000) | Avg Valid Loss: 0.0619 | Avg Valid recon Loss: 0.0619\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1548, recon=0.1548, kl=30.4078, beta=0.0000\n",
      "Batch 40, loss=0.0636, recon=0.0636, kl=24.6455, beta=0.0000\n",
      "Batch 60, loss=0.0646, recon=0.0646, kl=25.4584, beta=0.0000\n",
      "Batch 80, loss=0.0484, recon=0.0484, kl=26.9967, beta=0.0000\n",
      "Batch 100, loss=0.0452, recon=0.0452, kl=22.9192, beta=0.0000\n",
      "Batch 120, loss=0.2608, recon=0.2608, kl=21.0404, beta=0.0000\n",
      "Batch 140, loss=0.2218, recon=0.2218, kl=23.9566, beta=0.0000\n",
      "Batch 160, loss=0.0542, recon=0.0542, kl=25.2547, beta=0.0000\n",
      "Batch 180, loss=0.0534, recon=0.0534, kl=24.0626, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0712 (Recon: 0.0712, KL: 25.3364, Current Beta: 0.0000) | Avg Valid Loss: 0.0561 | Avg Valid recon Loss: 0.0561\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0458, recon=0.0458, kl=20.3012, beta=0.0000\n",
      "Batch 40, loss=0.0620, recon=0.0620, kl=16.1398, beta=0.0000\n",
      "Batch 60, loss=0.0535, recon=0.0535, kl=17.0652, beta=0.0000\n",
      "Batch 80, loss=0.0412, recon=0.0412, kl=13.6647, beta=0.0000\n",
      "Batch 100, loss=0.0353, recon=0.0353, kl=14.3220, beta=0.0000\n",
      "Batch 120, loss=0.0483, recon=0.0483, kl=15.4947, beta=0.0000\n",
      "Batch 140, loss=0.0315, recon=0.0315, kl=16.6563, beta=0.0000\n",
      "Batch 160, loss=0.0455, recon=0.0455, kl=16.2840, beta=0.0000\n",
      "Batch 180, loss=0.0641, recon=0.0641, kl=14.2967, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0621 (Recon: 0.0621, KL: 16.7113, Current Beta: 0.0000) | Avg Valid Loss: 0.0519 | Avg Valid recon Loss: 0.0519\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0419, recon=0.0418, kl=9.1201, beta=0.0000\n",
      "Batch 40, loss=0.0501, recon=0.0501, kl=7.8723, beta=0.0000\n",
      "Batch 60, loss=0.0417, recon=0.0417, kl=7.2199, beta=0.0000\n",
      "Batch 80, loss=0.0465, recon=0.0465, kl=8.3503, beta=0.0000\n",
      "Batch 100, loss=0.1547, recon=0.1547, kl=7.8292, beta=0.0000\n",
      "Batch 120, loss=0.0447, recon=0.0447, kl=7.5230, beta=0.0000\n",
      "Batch 140, loss=0.0343, recon=0.0343, kl=8.2577, beta=0.0000\n",
      "Batch 160, loss=0.0541, recon=0.0541, kl=7.6938, beta=0.0000\n",
      "Batch 180, loss=0.0369, recon=0.0368, kl=7.5103, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0561 (Recon: 0.0561, KL: 8.4059, Current Beta: 0.0000) | Avg Valid Loss: 0.0470 | Avg Valid recon Loss: 0.0470\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0467, recon=0.0466, kl=4.7588, beta=0.0000\n",
      "Batch 40, loss=0.0433, recon=0.0433, kl=3.2232, beta=0.0000\n",
      "Batch 60, loss=0.0357, recon=0.0357, kl=3.6418, beta=0.0000\n",
      "Batch 80, loss=0.0559, recon=0.0559, kl=3.8303, beta=0.0000\n",
      "Batch 100, loss=0.0465, recon=0.0465, kl=3.3790, beta=0.0000\n",
      "Batch 120, loss=0.0474, recon=0.0474, kl=3.2114, beta=0.0000\n",
      "Batch 140, loss=0.0292, recon=0.0292, kl=2.8980, beta=0.0000\n",
      "Batch 160, loss=0.0299, recon=0.0299, kl=2.8398, beta=0.0000\n",
      "Batch 180, loss=0.1820, recon=0.1820, kl=2.6456, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0517 (Recon: 0.0517, KL: 3.6616, Current Beta: 0.0000) | Avg Valid Loss: 0.0442 | Avg Valid recon Loss: 0.0442\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0251, recon=0.0251, kl=1.4532, beta=0.0000\n",
      "Batch 40, loss=0.8245, recon=0.8245, kl=1.0741, beta=0.0000\n",
      "Batch 60, loss=0.0315, recon=0.0315, kl=2.2260, beta=0.0000\n",
      "Batch 80, loss=0.0848, recon=0.0848, kl=1.3181, beta=0.0000\n",
      "Batch 100, loss=0.0405, recon=0.0404, kl=1.0586, beta=0.0000\n",
      "Batch 120, loss=0.0330, recon=0.0330, kl=1.0981, beta=0.0000\n",
      "Batch 140, loss=0.0609, recon=0.0609, kl=1.0079, beta=0.0000\n",
      "Batch 160, loss=0.0394, recon=0.0394, kl=1.1155, beta=0.0000\n",
      "Batch 180, loss=0.0438, recon=0.0438, kl=1.0871, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0489 (Recon: 0.0489, KL: 1.3848, Current Beta: 0.0000) | Avg Valid Loss: 0.0418 | Avg Valid recon Loss: 0.0418\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0327, recon=0.0327, kl=0.3035, beta=0.0000\n",
      "Batch 40, loss=0.0445, recon=0.0445, kl=0.2284, beta=0.0000\n",
      "Batch 60, loss=0.0279, recon=0.0279, kl=0.2352, beta=0.0000\n",
      "Batch 80, loss=0.0357, recon=0.0357, kl=0.2446, beta=0.0000\n",
      "Batch 100, loss=0.0483, recon=0.0483, kl=0.2398, beta=0.0000\n",
      "Batch 120, loss=0.0318, recon=0.0318, kl=0.1739, beta=0.0000\n",
      "Batch 140, loss=0.0256, recon=0.0256, kl=0.1743, beta=0.0000\n",
      "Batch 160, loss=0.0322, recon=0.0322, kl=0.1604, beta=0.0000\n",
      "Batch 180, loss=0.1347, recon=0.1347, kl=0.1636, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0464 (Recon: 0.0464, KL: 0.2587, Current Beta: 0.0000) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=0.0185, beta=0.0001\n",
      "Batch 40, loss=0.0246, recon=0.0246, kl=0.0271, beta=0.0001\n",
      "Batch 60, loss=0.0289, recon=0.0289, kl=0.0425, beta=0.0001\n",
      "Batch 80, loss=0.0255, recon=0.0255, kl=0.0167, beta=0.0001\n",
      "Batch 100, loss=0.0387, recon=0.0387, kl=0.0239, beta=0.0001\n",
      "Batch 120, loss=0.0262, recon=0.0262, kl=0.0121, beta=0.0001\n",
      "Batch 140, loss=0.0276, recon=0.0276, kl=0.0201, beta=0.0001\n",
      "Batch 160, loss=0.0242, recon=0.0242, kl=0.0094, beta=0.0001\n",
      "Batch 180, loss=0.0303, recon=0.0303, kl=0.0125, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0447 (Recon: 0.0447, KL: 0.0264, Current Beta: 0.0001) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0384\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0333, recon=0.0333, kl=0.0034, beta=0.0003\n",
      "Batch 40, loss=0.0642, recon=0.0642, kl=0.0032, beta=0.0003\n",
      "Batch 60, loss=0.0365, recon=0.0365, kl=0.0240, beta=0.0003\n",
      "Batch 80, loss=0.0298, recon=0.0298, kl=0.0122, beta=0.0003\n",
      "Batch 100, loss=0.0305, recon=0.0305, kl=0.0048, beta=0.0003\n",
      "Batch 120, loss=0.0330, recon=0.0330, kl=0.0013, beta=0.0003\n",
      "Batch 140, loss=0.0244, recon=0.0244, kl=0.0101, beta=0.0003\n",
      "Batch 160, loss=0.0330, recon=0.0330, kl=0.0017, beta=0.0003\n",
      "Batch 180, loss=0.0516, recon=0.0516, kl=0.0024, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0430, KL: 0.0052, Current Beta: 0.0003) | Avg Valid Loss: 0.0367 | Avg Valid recon Loss: 0.0367\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1014, recon=0.1014, kl=0.0009, beta=0.0008\n",
      "Batch 40, loss=0.0309, recon=0.0309, kl=0.0008, beta=0.0008\n",
      "Batch 60, loss=0.0503, recon=0.0503, kl=0.0013, beta=0.0008\n",
      "Batch 80, loss=0.0225, recon=0.0225, kl=0.0010, beta=0.0008\n",
      "Batch 100, loss=0.0586, recon=0.0586, kl=0.0004, beta=0.0008\n",
      "Batch 120, loss=0.0309, recon=0.0309, kl=0.0005, beta=0.0008\n",
      "Batch 140, loss=0.0295, recon=0.0295, kl=0.0015, beta=0.0008\n",
      "Batch 160, loss=0.0344, recon=0.0344, kl=0.0010, beta=0.0008\n",
      "Batch 180, loss=0.0322, recon=0.0322, kl=0.0005, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0414, KL: 0.0009, Current Beta: 0.0008) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0346, recon=0.0346, kl=0.0005, beta=0.0018\n",
      "Batch 40, loss=0.0255, recon=0.0255, kl=0.0003, beta=0.0018\n",
      "Batch 60, loss=0.0311, recon=0.0311, kl=0.0002, beta=0.0018\n",
      "Batch 80, loss=0.1308, recon=0.1308, kl=0.0003, beta=0.0018\n",
      "Batch 100, loss=0.0748, recon=0.0748, kl=0.0003, beta=0.0018\n",
      "Batch 120, loss=0.0325, recon=0.0325, kl=0.0003, beta=0.0018\n",
      "Batch 140, loss=0.0259, recon=0.0259, kl=0.0005, beta=0.0018\n",
      "Batch 160, loss=0.0232, recon=0.0232, kl=0.0002, beta=0.0018\n",
      "Batch 180, loss=0.1035, recon=0.1035, kl=0.0003, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0403 (Recon: 0.0403, KL: 0.0004, Current Beta: 0.0018) | Avg Valid Loss: 0.0348 | Avg Valid recon Loss: 0.0348\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0277, recon=0.0277, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0247, recon=0.0247, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.0359, recon=0.0359, kl=0.0002, beta=0.0038\n",
      "Batch 80, loss=0.0230, recon=0.0230, kl=0.0005, beta=0.0038\n",
      "Batch 100, loss=0.0307, recon=0.0307, kl=0.0001, beta=0.0038\n",
      "Batch 120, loss=0.0216, recon=0.0216, kl=0.0002, beta=0.0038\n",
      "Batch 140, loss=0.0279, recon=0.0279, kl=0.0002, beta=0.0038\n",
      "Batch 160, loss=0.0351, recon=0.0351, kl=0.0002, beta=0.0038\n",
      "Batch 180, loss=0.0518, recon=0.0518, kl=0.0002, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0393 (Recon: 0.0393, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0298, recon=0.0298, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0264, recon=0.0264, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0364, recon=0.0364, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0242, recon=0.0242, kl=0.0003, beta=0.0062\n",
      "Batch 100, loss=0.0374, recon=0.0374, kl=0.0001, beta=0.0062\n",
      "Batch 120, loss=0.0227, recon=0.0227, kl=0.0002, beta=0.0062\n",
      "Batch 140, loss=0.0263, recon=0.0263, kl=0.0001, beta=0.0062\n",
      "Batch 160, loss=0.0194, recon=0.0194, kl=0.0002, beta=0.0062\n",
      "Batch 180, loss=0.0192, recon=0.0192, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0386, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0240, recon=0.0240, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0328, recon=0.0328, kl=0.0007, beta=0.0100\n",
      "Batch 60, loss=0.0199, recon=0.0199, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0252, recon=0.0252, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0422, recon=0.0422, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0180, recon=0.0180, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0326, recon=0.0326, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0270, recon=0.0270, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0323, recon=0.0323, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0377, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0319 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0314, recon=0.0314, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0244, recon=0.0244, kl=0.0004, beta=0.0100\n",
      "Batch 60, loss=0.0258, recon=0.0258, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0547, recon=0.0547, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0534, recon=0.0534, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0312, recon=0.0312, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0415, recon=0.0415, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0210, recon=0.0210, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0204, recon=0.0204, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0370, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0315 | Avg Valid recon Loss: 0.0314\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0184, recon=0.0184, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0210, recon=0.0210, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0520, recon=0.0520, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0555, recon=0.0555, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0463, recon=0.0463, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0236, recon=0.0236, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0229, recon=0.0229, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.1422, recon=0.1422, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0236, recon=0.0236, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0365 (Recon: 0.0365, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0313 | Avg Valid recon Loss: 0.0313\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0349, recon=0.0349, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0229, recon=0.0229, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0183, recon=0.0183, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0203, recon=0.0203, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0422, recon=0.0422, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0300, recon=0.0300, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0224, recon=0.0224, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0260, recon=0.0260, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0356 (Recon: 0.0356, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0307\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0614, recon=0.0614, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0449, recon=0.0449, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0260, recon=0.0260, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0188, recon=0.0188, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0334, recon=0.0334, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0294, recon=0.0294, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0173, recon=0.0173, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0348, recon=0.0348, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0318, recon=0.0318, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0352 (Recon: 0.0352, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0304\n",
      "\n",
      "[VRAE Run 86/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1123, recon=0.1123, kl=24.1645, beta=0.0000\n",
      "Batch 40, loss=0.1412, recon=0.1412, kl=23.1481, beta=0.0000\n",
      "Batch 60, loss=0.1580, recon=0.1580, kl=25.5403, beta=0.0000\n",
      "Batch 80, loss=0.0663, recon=0.0663, kl=23.5558, beta=0.0000\n",
      "Batch 100, loss=0.0651, recon=0.0651, kl=25.8026, beta=0.0000\n",
      "Batch 120, loss=0.0460, recon=0.0460, kl=27.4780, beta=0.0000\n",
      "Batch 140, loss=0.0505, recon=0.0505, kl=28.0429, beta=0.0000\n",
      "Batch 160, loss=0.0346, recon=0.0346, kl=27.2592, beta=0.0000\n",
      "Batch 180, loss=0.0447, recon=0.0447, kl=30.4161, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1143 (Recon: 0.1143, KL: 24.3502, Current Beta: 0.0000) | Avg Valid Loss: 0.0544 | Avg Valid recon Loss: 0.0544\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0388, recon=0.0388, kl=29.2535, beta=0.0000\n",
      "Batch 40, loss=0.0625, recon=0.0625, kl=29.3479, beta=0.0000\n",
      "Batch 60, loss=0.0502, recon=0.0502, kl=26.2903, beta=0.0000\n",
      "Batch 80, loss=0.0315, recon=0.0315, kl=26.5886, beta=0.0000\n",
      "Batch 100, loss=0.0502, recon=0.0501, kl=24.9957, beta=0.0000\n",
      "Batch 120, loss=0.0414, recon=0.0414, kl=23.7107, beta=0.0000\n",
      "Batch 140, loss=0.0305, recon=0.0305, kl=23.2292, beta=0.0000\n",
      "Batch 160, loss=0.0305, recon=0.0305, kl=27.1530, beta=0.0000\n",
      "Batch 180, loss=0.0434, recon=0.0434, kl=28.6520, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0615 (Recon: 0.0615, KL: 27.2326, Current Beta: 0.0000) | Avg Valid Loss: 0.0468 | Avg Valid recon Loss: 0.0468\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0302, recon=0.0302, kl=29.3026, beta=0.0000\n",
      "Batch 40, loss=0.0619, recon=0.0619, kl=29.2914, beta=0.0000\n",
      "Batch 60, loss=0.0714, recon=0.0714, kl=31.0508, beta=0.0000\n",
      "Batch 80, loss=0.1440, recon=0.1440, kl=32.9440, beta=0.0000\n",
      "Batch 100, loss=0.0452, recon=0.0452, kl=31.5665, beta=0.0000\n",
      "Batch 120, loss=0.0289, recon=0.0289, kl=30.5179, beta=0.0000\n",
      "Batch 140, loss=0.0415, recon=0.0415, kl=33.7508, beta=0.0000\n",
      "Batch 160, loss=0.0413, recon=0.0413, kl=33.2002, beta=0.0000\n",
      "Batch 180, loss=0.0394, recon=0.0394, kl=32.4190, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0492 (Recon: 0.0492, KL: 31.5542, Current Beta: 0.0000) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0371, recon=0.0371, kl=30.9219, beta=0.0000\n",
      "Batch 40, loss=0.0547, recon=0.0547, kl=26.9652, beta=0.0000\n",
      "Batch 60, loss=0.0212, recon=0.0212, kl=26.6305, beta=0.0000\n",
      "Batch 80, loss=0.0910, recon=0.0910, kl=22.4942, beta=0.0000\n",
      "Batch 100, loss=0.0439, recon=0.0439, kl=23.8628, beta=0.0000\n",
      "Batch 120, loss=0.0342, recon=0.0342, kl=28.3853, beta=0.0000\n",
      "Batch 140, loss=0.1177, recon=0.1177, kl=28.5308, beta=0.0000\n",
      "Batch 160, loss=0.0258, recon=0.0258, kl=26.6939, beta=0.0000\n",
      "Batch 180, loss=0.0365, recon=0.0364, kl=25.7866, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0462, KL: 26.9358, Current Beta: 0.0000) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0243, recon=0.0243, kl=26.3190, beta=0.0000\n",
      "Batch 40, loss=0.0435, recon=0.0435, kl=25.1039, beta=0.0000\n",
      "Batch 60, loss=0.0241, recon=0.0240, kl=23.6320, beta=0.0000\n",
      "Batch 80, loss=0.0247, recon=0.0247, kl=22.7728, beta=0.0000\n",
      "Batch 100, loss=0.0491, recon=0.0491, kl=20.7594, beta=0.0000\n",
      "Batch 120, loss=0.0391, recon=0.0391, kl=21.7790, beta=0.0000\n",
      "Batch 140, loss=0.0235, recon=0.0235, kl=24.7646, beta=0.0000\n",
      "Batch 160, loss=0.0592, recon=0.0592, kl=25.3478, beta=0.0000\n",
      "Batch 180, loss=0.0683, recon=0.0683, kl=26.4964, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 24.0871, Current Beta: 0.0000) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=25.9644, beta=0.0000\n",
      "Batch 40, loss=0.0382, recon=0.0381, kl=23.7497, beta=0.0000\n",
      "Batch 60, loss=0.0307, recon=0.0306, kl=21.9480, beta=0.0000\n",
      "Batch 80, loss=0.0352, recon=0.0351, kl=18.8202, beta=0.0000\n",
      "Batch 100, loss=0.0442, recon=0.0442, kl=20.8412, beta=0.0000\n",
      "Batch 120, loss=0.0534, recon=0.0534, kl=23.0983, beta=0.0000\n",
      "Batch 140, loss=0.0529, recon=0.0528, kl=23.8250, beta=0.0000\n",
      "Batch 160, loss=0.0360, recon=0.0360, kl=22.6302, beta=0.0000\n",
      "Batch 180, loss=0.0240, recon=0.0240, kl=21.5380, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0449, KL: 22.7791, Current Beta: 0.0000) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0246, recon=0.0245, kl=17.4015, beta=0.0000\n",
      "Batch 40, loss=0.0326, recon=0.0325, kl=15.2297, beta=0.0000\n",
      "Batch 60, loss=0.0637, recon=0.0637, kl=14.6954, beta=0.0000\n",
      "Batch 80, loss=0.0650, recon=0.0649, kl=13.7958, beta=0.0000\n",
      "Batch 100, loss=0.0745, recon=0.0744, kl=14.9104, beta=0.0000\n",
      "Batch 120, loss=0.0579, recon=0.0578, kl=15.5277, beta=0.0000\n",
      "Batch 140, loss=0.0269, recon=0.0268, kl=19.2585, beta=0.0000\n",
      "Batch 160, loss=0.0222, recon=0.0221, kl=18.1144, beta=0.0000\n",
      "Batch 180, loss=0.0266, recon=0.0265, kl=19.0614, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0408 (Recon: 0.0407, KL: 16.5915, Current Beta: 0.0000) | Avg Valid Loss: 0.0354 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0194, recon=0.0192, kl=11.6938, beta=0.0000\n",
      "Batch 40, loss=0.0291, recon=0.0289, kl=12.9312, beta=0.0000\n",
      "Batch 60, loss=0.0241, recon=0.0239, kl=10.6444, beta=0.0000\n",
      "Batch 80, loss=0.0184, recon=0.0182, kl=10.7530, beta=0.0000\n",
      "Batch 100, loss=0.0255, recon=0.0253, kl=11.0626, beta=0.0000\n",
      "Batch 120, loss=0.0295, recon=0.0293, kl=9.9469, beta=0.0000\n",
      "Batch 140, loss=0.0280, recon=0.0279, kl=9.7169, beta=0.0000\n",
      "Batch 160, loss=0.0204, recon=0.0202, kl=9.3536, beta=0.0000\n",
      "Batch 180, loss=0.0284, recon=0.0283, kl=9.0573, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0364 (Recon: 0.0362, KL: 11.1441, Current Beta: 0.0000) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0391, recon=0.0389, kl=5.9687, beta=0.0000\n",
      "Batch 40, loss=0.0278, recon=0.0276, kl=4.5848, beta=0.0000\n",
      "Batch 60, loss=0.0289, recon=0.0287, kl=4.3017, beta=0.0000\n",
      "Batch 80, loss=0.0226, recon=0.0224, kl=4.2649, beta=0.0000\n",
      "Batch 100, loss=0.0379, recon=0.0378, kl=3.5839, beta=0.0000\n",
      "Batch 120, loss=0.0345, recon=0.0344, kl=3.9738, beta=0.0000\n",
      "Batch 140, loss=0.0646, recon=0.0645, kl=4.0998, beta=0.0000\n",
      "Batch 160, loss=0.0263, recon=0.0261, kl=4.5734, beta=0.0000\n",
      "Batch 180, loss=0.0262, recon=0.0261, kl=4.1182, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0376, KL: 4.6485, Current Beta: 0.0000) | Avg Valid Loss: 0.0306 | Avg Valid recon Loss: 0.0305\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0233, recon=0.0232, kl=0.6700, beta=0.0001\n",
      "Batch 40, loss=0.0415, recon=0.0414, kl=1.2854, beta=0.0001\n",
      "Batch 60, loss=0.0297, recon=0.0297, kl=0.5097, beta=0.0001\n",
      "Batch 80, loss=0.0162, recon=0.0162, kl=0.4711, beta=0.0001\n",
      "Batch 100, loss=0.0474, recon=0.0473, kl=0.5489, beta=0.0001\n",
      "Batch 120, loss=0.0233, recon=0.0232, kl=0.8082, beta=0.0001\n",
      "Batch 140, loss=0.0562, recon=0.0562, kl=0.8469, beta=0.0001\n",
      "Batch 160, loss=0.0318, recon=0.0317, kl=0.6960, beta=0.0001\n",
      "Batch 180, loss=0.0205, recon=0.0204, kl=0.7794, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0357, KL: 0.9297, Current Beta: 0.0001) | Avg Valid Loss: 0.0316 | Avg Valid recon Loss: 0.0315\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0280, recon=0.0280, kl=0.0530, beta=0.0003\n",
      "Batch 40, loss=0.0520, recon=0.0520, kl=0.1966, beta=0.0003\n",
      "Batch 60, loss=0.0213, recon=0.0213, kl=0.1009, beta=0.0003\n",
      "Batch 80, loss=0.0331, recon=0.0330, kl=0.3035, beta=0.0003\n",
      "Batch 100, loss=0.0461, recon=0.0460, kl=0.2800, beta=0.0003\n",
      "Batch 120, loss=0.0345, recon=0.0344, kl=0.1145, beta=0.0003\n",
      "Batch 140, loss=0.0291, recon=0.0289, kl=0.4805, beta=0.0003\n",
      "Batch 160, loss=0.0262, recon=0.0261, kl=0.3218, beta=0.0003\n",
      "Batch 180, loss=0.0308, recon=0.0307, kl=0.2952, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0376, KL: 0.2663, Current Beta: 0.0003) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0169, recon=0.0169, kl=0.0060, beta=0.0008\n",
      "Batch 40, loss=0.0291, recon=0.0291, kl=0.0204, beta=0.0008\n",
      "Batch 60, loss=0.0341, recon=0.0341, kl=0.0644, beta=0.0008\n",
      "Batch 80, loss=0.0260, recon=0.0260, kl=0.0193, beta=0.0008\n",
      "Batch 100, loss=0.0399, recon=0.0399, kl=0.0247, beta=0.0008\n",
      "Batch 120, loss=0.0353, recon=0.0353, kl=0.0097, beta=0.0008\n",
      "Batch 140, loss=0.0233, recon=0.0233, kl=0.0069, beta=0.0008\n",
      "Batch 160, loss=0.0265, recon=0.0265, kl=0.0081, beta=0.0008\n",
      "Batch 180, loss=0.0523, recon=0.0523, kl=0.0204, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0357 (Recon: 0.0357, KL: 0.0324, Current Beta: 0.0008) | Avg Valid Loss: 0.0299 | Avg Valid recon Loss: 0.0299\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0277, recon=0.0277, kl=0.0037, beta=0.0018\n",
      "Batch 40, loss=0.0236, recon=0.0236, kl=0.0043, beta=0.0018\n",
      "Batch 60, loss=0.0236, recon=0.0236, kl=0.0017, beta=0.0018\n",
      "Batch 80, loss=0.0302, recon=0.0302, kl=0.0059, beta=0.0018\n",
      "Batch 100, loss=0.0291, recon=0.0291, kl=0.0087, beta=0.0018\n",
      "Batch 120, loss=0.0267, recon=0.0267, kl=0.0026, beta=0.0018\n",
      "Batch 140, loss=0.0173, recon=0.0173, kl=0.0042, beta=0.0018\n",
      "Batch 160, loss=0.0590, recon=0.0590, kl=0.0018, beta=0.0018\n",
      "Batch 180, loss=0.0353, recon=0.0353, kl=0.0105, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0340 (Recon: 0.0339, KL: 0.0072, Current Beta: 0.0018) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0346\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0462, recon=0.0462, kl=0.0021, beta=0.0038\n",
      "Batch 40, loss=0.0268, recon=0.0267, kl=0.0260, beta=0.0038\n",
      "Batch 60, loss=0.0186, recon=0.0186, kl=0.0118, beta=0.0038\n",
      "Batch 80, loss=0.0297, recon=0.0297, kl=0.0029, beta=0.0038\n",
      "Batch 100, loss=0.0238, recon=0.0237, kl=0.0018, beta=0.0038\n",
      "Batch 120, loss=0.0295, recon=0.0295, kl=0.0014, beta=0.0038\n",
      "Batch 140, loss=0.0276, recon=0.0276, kl=0.0025, beta=0.0038\n",
      "Batch 160, loss=0.0430, recon=0.0429, kl=0.0039, beta=0.0038\n",
      "Batch 180, loss=0.0276, recon=0.0275, kl=0.0046, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0381 (Recon: 0.0380, KL: 0.0052, Current Beta: 0.0038) | Avg Valid Loss: 0.0326 | Avg Valid recon Loss: 0.0326\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0207, recon=0.0207, kl=0.0017, beta=0.0062\n",
      "Batch 40, loss=0.0401, recon=0.0401, kl=0.0012, beta=0.0062\n",
      "Batch 60, loss=0.0542, recon=0.0542, kl=0.0005, beta=0.0062\n",
      "Batch 80, loss=0.0208, recon=0.0208, kl=0.0010, beta=0.0062\n",
      "Batch 100, loss=0.0218, recon=0.0218, kl=0.0005, beta=0.0062\n",
      "Batch 120, loss=0.0279, recon=0.0279, kl=0.0008, beta=0.0062\n",
      "Batch 140, loss=0.0344, recon=0.0344, kl=0.0006, beta=0.0062\n",
      "Batch 160, loss=0.0393, recon=0.0392, kl=0.0017, beta=0.0062\n",
      "Batch 180, loss=0.1269, recon=0.1268, kl=0.0008, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0349 (Recon: 0.0349, KL: 0.0011, Current Beta: 0.0062) | Avg Valid Loss: 0.0344 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0208, recon=0.0208, kl=0.0006, beta=0.0100\n",
      "Batch 40, loss=0.0209, recon=0.0209, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.1189, recon=0.1189, kl=0.0051, beta=0.0100\n",
      "Batch 80, loss=0.0234, recon=0.0234, kl=0.0018, beta=0.0100\n",
      "Batch 100, loss=0.0254, recon=0.0254, kl=0.0007, beta=0.0100\n",
      "Batch 120, loss=0.0348, recon=0.0348, kl=0.0005, beta=0.0100\n",
      "Batch 140, loss=0.0239, recon=0.0239, kl=0.0005, beta=0.0100\n",
      "Batch 160, loss=0.0239, recon=0.0232, kl=0.0700, beta=0.0100\n",
      "Batch 180, loss=0.0439, recon=0.0439, kl=0.0029, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0376, KL: 0.0018, Current Beta: 0.0100) | Avg Valid Loss: 0.0563 | Avg Valid recon Loss: 0.0562\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.4605, recon=0.4605, kl=0.0029, beta=0.0100\n",
      "Batch 40, loss=0.0883, recon=0.0880, kl=0.0285, beta=0.0100\n",
      "Batch 60, loss=0.0410, recon=0.0410, kl=0.0070, beta=0.0100\n",
      "Batch 80, loss=0.0390, recon=0.0389, kl=0.0049, beta=0.0100\n",
      "Batch 100, loss=0.0283, recon=0.0283, kl=0.0015, beta=0.0100\n",
      "Batch 120, loss=0.0384, recon=0.0384, kl=0.0017, beta=0.0100\n",
      "Batch 140, loss=0.0415, recon=0.0415, kl=0.0013, beta=0.0100\n",
      "Batch 160, loss=0.0471, recon=0.0471, kl=0.0009, beta=0.0100\n",
      "Batch 180, loss=0.0298, recon=0.0298, kl=0.0004, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0534, KL: 0.0067, Current Beta: 0.0100) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0687, recon=0.0687, kl=0.0006, beta=0.0100\n",
      "Batch 40, loss=0.0489, recon=0.0487, kl=0.0215, beta=0.0100\n",
      "Batch 60, loss=0.0408, recon=0.0407, kl=0.0063, beta=0.0100\n",
      "Batch 80, loss=0.0377, recon=0.0377, kl=0.0010, beta=0.0100\n",
      "Batch 100, loss=0.0383, recon=0.0383, kl=0.0003, beta=0.0100\n",
      "Batch 120, loss=0.0172, recon=0.0172, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0351, recon=0.0351, kl=0.0002, beta=0.0100\n",
      "Batch 160, loss=0.1475, recon=0.1465, kl=0.1045, beta=0.0100\n",
      "Batch 180, loss=0.2594, recon=0.2503, kl=0.9070, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0720 (Recon: 0.0714, KL: 0.0599, Current Beta: 0.0100) | Avg Valid Loss: 0.2290 | Avg Valid recon Loss: 0.2193\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 87/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3050, recon=0.3050, kl=0.4374, beta=0.0000\n",
      "Batch 40, loss=0.3217, recon=0.3217, kl=18.5503, beta=0.0000\n",
      "Batch 60, loss=0.1646, recon=0.1646, kl=41.4238, beta=0.0000\n",
      "Batch 80, loss=0.1454, recon=0.1454, kl=50.9937, beta=0.0000\n",
      "Batch 100, loss=0.1291, recon=0.1291, kl=52.3818, beta=0.0000\n",
      "Batch 120, loss=0.1335, recon=0.1335, kl=51.9245, beta=0.0000\n",
      "Batch 140, loss=0.0854, recon=0.0854, kl=54.2524, beta=0.0000\n",
      "Batch 160, loss=0.1013, recon=0.1013, kl=56.1230, beta=0.0000\n",
      "Batch 180, loss=0.0894, recon=0.0894, kl=59.6166, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2254 (Recon: 0.2254, KL: 39.5812, Current Beta: 0.0000) | Avg Valid Loss: 0.0960 | Avg Valid recon Loss: 0.0960\n",
      "Epoch 2/20\n",
      "Batch 20, loss=1.8001, recon=1.8001, kl=59.2095, beta=0.0000\n",
      "Batch 40, loss=0.1073, recon=0.1073, kl=64.7719, beta=0.0000\n",
      "Batch 60, loss=0.0625, recon=0.0625, kl=63.3417, beta=0.0000\n",
      "Batch 80, loss=0.0822, recon=0.0822, kl=65.3766, beta=0.0000\n",
      "Batch 100, loss=0.0779, recon=0.0779, kl=64.3102, beta=0.0000\n",
      "Batch 120, loss=0.0937, recon=0.0937, kl=66.5939, beta=0.0000\n",
      "Batch 140, loss=0.0605, recon=0.0605, kl=62.1311, beta=0.0000\n",
      "Batch 160, loss=0.0574, recon=0.0574, kl=59.0259, beta=0.0000\n",
      "Batch 180, loss=0.0699, recon=0.0699, kl=60.3150, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1101 (Recon: 0.1101, KL: 62.7595, Current Beta: 0.0000) | Avg Valid Loss: 0.0728 | Avg Valid recon Loss: 0.0728\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0582, recon=0.0582, kl=61.7405, beta=0.0000\n",
      "Batch 40, loss=0.1590, recon=0.1590, kl=56.0658, beta=0.0000\n",
      "Batch 60, loss=0.0534, recon=0.0534, kl=56.8105, beta=0.0000\n",
      "Batch 80, loss=0.0422, recon=0.0422, kl=54.6073, beta=0.0000\n",
      "Batch 100, loss=0.0704, recon=0.0703, kl=54.9644, beta=0.0000\n",
      "Batch 120, loss=0.0560, recon=0.0560, kl=55.0396, beta=0.0000\n",
      "Batch 140, loss=0.0593, recon=0.0593, kl=49.6694, beta=0.0000\n",
      "Batch 160, loss=0.0521, recon=0.0521, kl=51.4904, beta=0.0000\n",
      "Batch 180, loss=0.0974, recon=0.0974, kl=53.8257, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0841 (Recon: 0.0841, KL: 55.0159, Current Beta: 0.0000) | Avg Valid Loss: 0.0616 | Avg Valid recon Loss: 0.0615\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0418, recon=0.0417, kl=52.1571, beta=0.0000\n",
      "Batch 40, loss=0.0560, recon=0.0560, kl=46.0252, beta=0.0000\n",
      "Batch 60, loss=0.0635, recon=0.0635, kl=40.4966, beta=0.0000\n",
      "Batch 80, loss=0.1302, recon=0.1302, kl=41.5984, beta=0.0000\n",
      "Batch 100, loss=0.0418, recon=0.0418, kl=35.1611, beta=0.0000\n",
      "Batch 120, loss=0.0567, recon=0.0566, kl=34.8487, beta=0.0000\n",
      "Batch 140, loss=0.0399, recon=0.0399, kl=33.3699, beta=0.0000\n",
      "Batch 160, loss=0.0458, recon=0.0458, kl=34.3204, beta=0.0000\n",
      "Batch 180, loss=0.0625, recon=0.0625, kl=34.9097, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0692 (Recon: 0.0692, KL: 40.1424, Current Beta: 0.0000) | Avg Valid Loss: 0.0545 | Avg Valid recon Loss: 0.0544\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0411, recon=0.0410, kl=30.3344, beta=0.0000\n",
      "Batch 40, loss=0.0452, recon=0.0452, kl=23.8994, beta=0.0000\n",
      "Batch 60, loss=0.0520, recon=0.0520, kl=22.9370, beta=0.0000\n",
      "Batch 80, loss=0.0419, recon=0.0418, kl=23.4600, beta=0.0000\n",
      "Batch 100, loss=0.0524, recon=0.0523, kl=22.1437, beta=0.0000\n",
      "Batch 120, loss=0.0378, recon=0.0378, kl=20.5309, beta=0.0000\n",
      "Batch 140, loss=0.0368, recon=0.0368, kl=21.0991, beta=0.0000\n",
      "Batch 160, loss=0.0376, recon=0.0375, kl=20.6423, beta=0.0000\n",
      "Batch 180, loss=0.0305, recon=0.0305, kl=18.8887, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0609 (Recon: 0.0609, KL: 23.1605, Current Beta: 0.0000) | Avg Valid Loss: 0.0502 | Avg Valid recon Loss: 0.0502\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0388, recon=0.0388, kl=13.3015, beta=0.0000\n",
      "Batch 40, loss=0.0394, recon=0.0393, kl=10.8894, beta=0.0000\n",
      "Batch 60, loss=0.0664, recon=0.0664, kl=9.4115, beta=0.0000\n",
      "Batch 80, loss=0.0462, recon=0.0462, kl=9.3807, beta=0.0000\n",
      "Batch 100, loss=0.0337, recon=0.0337, kl=10.5605, beta=0.0000\n",
      "Batch 120, loss=0.0298, recon=0.0298, kl=9.1902, beta=0.0000\n",
      "Batch 140, loss=0.0503, recon=0.0503, kl=8.1683, beta=0.0000\n",
      "Batch 160, loss=0.0467, recon=0.0467, kl=10.7833, beta=0.0000\n",
      "Batch 180, loss=0.9457, recon=0.9457, kl=9.3878, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 10.6054, Current Beta: 0.0000) | Avg Valid Loss: 0.0467 | Avg Valid recon Loss: 0.0467\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0378, recon=0.0378, kl=4.9006, beta=0.0000\n",
      "Batch 40, loss=0.0320, recon=0.0320, kl=4.0813, beta=0.0000\n",
      "Batch 60, loss=0.0260, recon=0.0260, kl=4.2342, beta=0.0000\n",
      "Batch 80, loss=0.2170, recon=0.2170, kl=4.5009, beta=0.0000\n",
      "Batch 100, loss=0.0318, recon=0.0318, kl=3.5232, beta=0.0000\n",
      "Batch 120, loss=0.0456, recon=0.0456, kl=4.4768, beta=0.0000\n",
      "Batch 140, loss=0.0347, recon=0.0347, kl=3.3850, beta=0.0000\n",
      "Batch 160, loss=0.0324, recon=0.0324, kl=3.5361, beta=0.0000\n",
      "Batch 180, loss=0.0292, recon=0.0292, kl=3.3714, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0517 (Recon: 0.0517, KL: 4.2622, Current Beta: 0.0000) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0432\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=1.2689, beta=0.0000\n",
      "Batch 40, loss=0.0380, recon=0.0380, kl=1.8181, beta=0.0000\n",
      "Batch 60, loss=0.1131, recon=0.1131, kl=0.9803, beta=0.0000\n",
      "Batch 80, loss=0.0369, recon=0.0369, kl=1.5259, beta=0.0000\n",
      "Batch 100, loss=0.0348, recon=0.0348, kl=1.1198, beta=0.0000\n",
      "Batch 120, loss=0.0372, recon=0.0371, kl=1.9349, beta=0.0000\n",
      "Batch 140, loss=0.0377, recon=0.0377, kl=1.5375, beta=0.0000\n",
      "Batch 160, loss=0.0418, recon=0.0418, kl=1.2395, beta=0.0000\n",
      "Batch 180, loss=0.0235, recon=0.0235, kl=1.0638, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0485, KL: 1.4935, Current Beta: 0.0000) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0344, recon=0.0344, kl=0.2643, beta=0.0000\n",
      "Batch 40, loss=0.0508, recon=0.0508, kl=0.5096, beta=0.0000\n",
      "Batch 60, loss=0.0394, recon=0.0393, kl=0.5345, beta=0.0000\n",
      "Batch 80, loss=0.0321, recon=0.0321, kl=0.2643, beta=0.0000\n",
      "Batch 100, loss=0.0332, recon=0.0332, kl=0.2670, beta=0.0000\n",
      "Batch 120, loss=0.0469, recon=0.0469, kl=0.3021, beta=0.0000\n",
      "Batch 140, loss=0.0326, recon=0.0326, kl=0.2683, beta=0.0000\n",
      "Batch 160, loss=0.0326, recon=0.0326, kl=0.1728, beta=0.0000\n",
      "Batch 180, loss=0.0399, recon=0.0399, kl=0.1481, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0461, KL: 0.3415, Current Beta: 0.0000) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0375, recon=0.0375, kl=0.0282, beta=0.0001\n",
      "Batch 40, loss=0.0374, recon=0.0374, kl=0.0255, beta=0.0001\n",
      "Batch 60, loss=0.0297, recon=0.0297, kl=0.0323, beta=0.0001\n",
      "Batch 80, loss=0.0246, recon=0.0246, kl=0.0183, beta=0.0001\n",
      "Batch 100, loss=0.0349, recon=0.0349, kl=0.0213, beta=0.0001\n",
      "Batch 120, loss=0.0711, recon=0.0711, kl=0.0151, beta=0.0001\n",
      "Batch 140, loss=0.0329, recon=0.0329, kl=0.0184, beta=0.0001\n",
      "Batch 160, loss=0.0297, recon=0.0297, kl=0.0111, beta=0.0001\n",
      "Batch 180, loss=0.0377, recon=0.0377, kl=0.0183, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0438, KL: 0.0282, Current Beta: 0.0001) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1020, recon=0.1020, kl=0.0032, beta=0.0003\n",
      "Batch 40, loss=0.0221, recon=0.0221, kl=0.0040, beta=0.0003\n",
      "Batch 60, loss=0.0581, recon=0.0581, kl=0.0035, beta=0.0003\n",
      "Batch 80, loss=0.0286, recon=0.0286, kl=0.0012, beta=0.0003\n",
      "Batch 100, loss=0.0575, recon=0.0575, kl=0.0037, beta=0.0003\n",
      "Batch 120, loss=0.0231, recon=0.0231, kl=0.0033, beta=0.0003\n",
      "Batch 140, loss=0.0376, recon=0.0376, kl=0.0075, beta=0.0003\n",
      "Batch 160, loss=0.0370, recon=0.0370, kl=0.0105, beta=0.0003\n",
      "Batch 180, loss=0.0382, recon=0.0382, kl=0.0023, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0424, KL: 0.0052, Current Beta: 0.0003) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=0.0032, beta=0.0008\n",
      "Batch 40, loss=0.0191, recon=0.0191, kl=0.0005, beta=0.0008\n",
      "Batch 60, loss=0.0337, recon=0.0337, kl=0.0004, beta=0.0008\n",
      "Batch 80, loss=0.0195, recon=0.0195, kl=0.0003, beta=0.0008\n",
      "Batch 100, loss=0.0314, recon=0.0314, kl=0.0005, beta=0.0008\n",
      "Batch 120, loss=0.0836, recon=0.0836, kl=0.0010, beta=0.0008\n",
      "Batch 140, loss=0.0278, recon=0.0278, kl=0.0004, beta=0.0008\n",
      "Batch 160, loss=0.0236, recon=0.0236, kl=0.0003, beta=0.0008\n",
      "Batch 180, loss=0.0230, recon=0.0230, kl=0.0007, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0412 (Recon: 0.0412, KL: 0.0009, Current Beta: 0.0008) | Avg Valid Loss: 0.0356 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0271, recon=0.0271, kl=0.0025, beta=0.0018\n",
      "Batch 40, loss=0.1341, recon=0.1341, kl=0.0003, beta=0.0018\n",
      "Batch 60, loss=0.0344, recon=0.0344, kl=0.0001, beta=0.0018\n",
      "Batch 80, loss=0.0363, recon=0.0363, kl=0.0002, beta=0.0018\n",
      "Batch 100, loss=0.0230, recon=0.0230, kl=0.0001, beta=0.0018\n",
      "Batch 120, loss=0.0479, recon=0.0479, kl=0.0002, beta=0.0018\n",
      "Batch 140, loss=0.0363, recon=0.0363, kl=0.0003, beta=0.0018\n",
      "Batch 160, loss=0.1176, recon=0.1176, kl=0.0040, beta=0.0018\n",
      "Batch 180, loss=0.0355, recon=0.0355, kl=0.0017, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0400, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0345\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0216, recon=0.0216, kl=0.0005, beta=0.0038\n",
      "Batch 40, loss=0.0507, recon=0.0507, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.0526, recon=0.0526, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0275, recon=0.0275, kl=0.0002, beta=0.0038\n",
      "Batch 100, loss=0.0524, recon=0.0524, kl=0.0018, beta=0.0038\n",
      "Batch 120, loss=0.0302, recon=0.0302, kl=0.0003, beta=0.0038\n",
      "Batch 140, loss=0.0385, recon=0.0385, kl=0.0001, beta=0.0038\n",
      "Batch 160, loss=0.0390, recon=0.0390, kl=0.0001, beta=0.0038\n",
      "Batch 180, loss=0.0285, recon=0.0285, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0355, recon=0.0354, kl=0.0006, beta=0.0062\n",
      "Batch 40, loss=0.0259, recon=0.0259, kl=0.0002, beta=0.0062\n",
      "Batch 60, loss=0.0417, recon=0.0417, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0246, recon=0.0246, kl=0.0000, beta=0.0062\n",
      "Batch 100, loss=0.1340, recon=0.1340, kl=0.0000, beta=0.0062\n",
      "Batch 120, loss=0.0282, recon=0.0282, kl=0.0000, beta=0.0062\n",
      "Batch 140, loss=0.0256, recon=0.0256, kl=0.0000, beta=0.0062\n",
      "Batch 160, loss=0.0367, recon=0.0367, kl=0.0000, beta=0.0062\n",
      "Batch 180, loss=0.0516, recon=0.0516, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0381 (Recon: 0.0381, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0329 | Avg Valid recon Loss: 0.0329\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0337, recon=0.0337, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0292, recon=0.0292, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0310, recon=0.0309, kl=0.0040, beta=0.0100\n",
      "Batch 80, loss=0.0234, recon=0.0234, kl=0.0007, beta=0.0100\n",
      "Batch 100, loss=0.0473, recon=0.0473, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0262, recon=0.0262, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0278, recon=0.0278, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0398, recon=0.0398, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0249, recon=0.0249, kl=0.0004, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0373 (Recon: 0.0373, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0324 | Avg Valid recon Loss: 0.0324\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0442, recon=0.0441, kl=0.0121, beta=0.0100\n",
      "Batch 40, loss=0.0295, recon=0.0295, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0357, recon=0.0357, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0224, recon=0.0224, kl=0.0002, beta=0.0100\n",
      "Batch 100, loss=0.0260, recon=0.0260, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0168, recon=0.0168, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0643, recon=0.0643, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0176, recon=0.0176, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0325, recon=0.0325, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0366 (Recon: 0.0365, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0349, recon=0.0349, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0224, recon=0.0224, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0324, recon=0.0324, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0473, recon=0.0473, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0237, recon=0.0237, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0359, recon=0.0359, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0228, recon=0.0228, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0193, recon=0.0193, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0335, recon=0.0335, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0359 (Recon: 0.0359, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0310 | Avg Valid recon Loss: 0.0310\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0213, recon=0.0213, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0287, recon=0.0287, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.1271, recon=0.1271, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0225, recon=0.0225, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0291, recon=0.0291, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.1503, recon=0.1503, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0221, recon=0.0221, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0206, recon=0.0206, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0389, recon=0.0389, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0354, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0307\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0241, recon=0.0241, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0374, recon=0.0374, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0415, recon=0.0415, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0340, recon=0.0340, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0406, recon=0.0406, kl=0.0003, beta=0.0100\n",
      "Batch 120, loss=0.0179, recon=0.0179, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0215, recon=0.0215, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0205, recon=0.0205, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0249, recon=0.0249, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0348 (Recon: 0.0348, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0302 | Avg Valid recon Loss: 0.0302\n",
      "\n",
      "[VRAE Run 88/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1560, recon=0.1560, kl=40.9051, beta=0.0000\n",
      "Batch 40, loss=0.0854, recon=0.0854, kl=46.3115, beta=0.0000\n",
      "Batch 60, loss=0.1020, recon=0.1020, kl=41.2133, beta=0.0000\n",
      "Batch 80, loss=0.1038, recon=0.1038, kl=45.6614, beta=0.0000\n",
      "Batch 100, loss=0.0606, recon=0.0606, kl=50.1097, beta=0.0000\n",
      "Batch 120, loss=0.0654, recon=0.0654, kl=58.6022, beta=0.0000\n",
      "Batch 140, loss=0.0521, recon=0.0521, kl=56.4660, beta=0.0000\n",
      "Batch 160, loss=0.0419, recon=0.0419, kl=44.4141, beta=0.0000\n",
      "Batch 180, loss=0.0297, recon=0.0297, kl=47.6715, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1193 (Recon: 0.1193, KL: 46.5801, Current Beta: 0.0000) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0559\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0717, recon=0.0717, kl=52.5630, beta=0.0000\n",
      "Batch 40, loss=0.0433, recon=0.0433, kl=56.0019, beta=0.0000\n",
      "Batch 60, loss=0.0424, recon=0.0424, kl=54.7393, beta=0.0000\n",
      "Batch 80, loss=0.0377, recon=0.0377, kl=48.7897, beta=0.0000\n",
      "Batch 100, loss=0.0390, recon=0.0390, kl=47.1969, beta=0.0000\n",
      "Batch 120, loss=0.0377, recon=0.0376, kl=92.4243, beta=0.0000\n",
      "Batch 140, loss=0.0580, recon=0.0580, kl=144.8984, beta=0.0000\n",
      "Batch 160, loss=0.0250, recon=0.0250, kl=145.4608, beta=0.0000\n",
      "Batch 180, loss=0.0352, recon=0.0352, kl=143.0706, beta=0.0000\n",
      "  â†’ Avg Train Loss: 8.5593 (Recon: 8.5593, KL: 397.6321, Current Beta: 0.0000) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0458\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0388, recon=0.0388, kl=142.9089, beta=0.0000\n",
      "Batch 40, loss=0.0360, recon=0.0360, kl=136.4518, beta=0.0000\n",
      "Batch 60, loss=0.0760, recon=0.0760, kl=134.9367, beta=0.0000\n",
      "Batch 80, loss=0.0323, recon=0.0323, kl=132.7995, beta=0.0000\n",
      "Batch 100, loss=0.0560, recon=0.0560, kl=131.9075, beta=0.0000\n",
      "Batch 120, loss=0.0447, recon=0.0447, kl=128.7021, beta=0.0000\n",
      "Batch 140, loss=0.1598, recon=0.1598, kl=128.6723, beta=0.0000\n",
      "Batch 160, loss=0.0424, recon=0.0424, kl=123.7518, beta=0.0000\n",
      "Batch 180, loss=0.0324, recon=0.0323, kl=126.1904, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0526, KL: 132.7762, Current Beta: 0.0000) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0713, recon=0.0712, kl=124.0559, beta=0.0000\n",
      "Batch 40, loss=0.0419, recon=0.0419, kl=119.7135, beta=0.0000\n",
      "Batch 60, loss=0.0315, recon=0.0315, kl=123.8574, beta=0.0000\n",
      "Batch 80, loss=0.0260, recon=0.0260, kl=125.1520, beta=0.0000\n",
      "Batch 100, loss=0.0485, recon=0.0484, kl=117.4300, beta=0.0000\n",
      "Batch 120, loss=0.0321, recon=0.0321, kl=116.2450, beta=0.0000\n",
      "Batch 140, loss=0.0294, recon=0.0294, kl=115.3447, beta=0.0000\n",
      "Batch 160, loss=0.0373, recon=0.0373, kl=110.2118, beta=0.0000\n",
      "Batch 180, loss=0.0294, recon=0.0294, kl=112.4070, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0464 (Recon: 0.0463, KL: 120.4595, Current Beta: 0.0000) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1265, recon=0.1264, kl=112.6000, beta=0.0000\n",
      "Batch 40, loss=0.0272, recon=0.0271, kl=107.3227, beta=0.0000\n",
      "Batch 60, loss=0.0434, recon=0.0433, kl=96.6428, beta=0.0000\n",
      "Batch 80, loss=0.0327, recon=0.0327, kl=97.0740, beta=0.0000\n",
      "Batch 100, loss=0.0238, recon=0.0237, kl=92.6502, beta=0.0000\n",
      "Batch 120, loss=0.0300, recon=0.0299, kl=95.7481, beta=0.0000\n",
      "Batch 140, loss=0.0268, recon=0.0268, kl=89.8443, beta=0.0000\n",
      "Batch 160, loss=0.0270, recon=0.0269, kl=88.2865, beta=0.0000\n",
      "Batch 180, loss=0.0357, recon=0.0357, kl=85.5264, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0427, KL: 97.9958, Current Beta: 0.0000) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0414, recon=0.0412, kl=77.3810, beta=0.0000\n",
      "Batch 40, loss=0.0364, recon=0.0362, kl=71.6165, beta=0.0000\n",
      "Batch 60, loss=0.0280, recon=0.0278, kl=68.0610, beta=0.0000\n",
      "Batch 80, loss=0.0212, recon=0.0211, kl=63.0071, beta=0.0000\n",
      "Batch 100, loss=0.0256, recon=0.0255, kl=59.4932, beta=0.0000\n",
      "Batch 120, loss=0.0219, recon=0.0218, kl=56.7520, beta=0.0000\n",
      "Batch 140, loss=0.0205, recon=0.0204, kl=52.3775, beta=0.0000\n",
      "Batch 160, loss=0.0255, recon=0.0254, kl=51.7677, beta=0.0000\n",
      "Batch 180, loss=0.0316, recon=0.0315, kl=50.5099, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0407, KL: 63.3677, Current Beta: 0.0000) | Avg Valid Loss: 0.0326 | Avg Valid recon Loss: 0.0325\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0374, recon=0.0372, kl=44.0503, beta=0.0000\n",
      "Batch 40, loss=0.0263, recon=0.0261, kl=38.2296, beta=0.0000\n",
      "Batch 60, loss=0.0255, recon=0.0253, kl=37.3570, beta=0.0000\n",
      "Batch 80, loss=0.0197, recon=0.0196, kl=34.6339, beta=0.0000\n",
      "Batch 100, loss=0.0404, recon=0.0402, kl=34.8581, beta=0.0000\n",
      "Batch 120, loss=0.0278, recon=0.0276, kl=36.0318, beta=0.0000\n",
      "Batch 140, loss=0.0239, recon=0.0237, kl=34.7941, beta=0.0000\n",
      "Batch 160, loss=0.0269, recon=0.0267, kl=36.3845, beta=0.0000\n",
      "Batch 180, loss=0.0274, recon=0.0272, kl=36.3673, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0372 (Recon: 0.0370, KL: 37.6147, Current Beta: 0.0000) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1226, recon=0.1222, kl=26.9092, beta=0.0000\n",
      "Batch 40, loss=0.0280, recon=0.0276, kl=25.6357, beta=0.0000\n",
      "Batch 60, loss=0.0426, recon=0.0422, kl=24.3207, beta=0.0000\n",
      "Batch 80, loss=0.0350, recon=0.0346, kl=24.1562, beta=0.0000\n",
      "Batch 100, loss=0.0398, recon=0.0395, kl=19.9317, beta=0.0000\n",
      "Batch 120, loss=0.0303, recon=0.0299, kl=21.7766, beta=0.0000\n",
      "Batch 140, loss=0.0331, recon=0.0328, kl=21.2668, beta=0.0000\n",
      "Batch 160, loss=0.0235, recon=0.0232, kl=19.5287, beta=0.0000\n",
      "Batch 180, loss=0.0374, recon=0.0371, kl=18.5987, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0419, KL: 23.3359, Current Beta: 0.0000) | Avg Valid Loss: 0.0354 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0319, recon=0.0315, kl=7.8494, beta=0.0000\n",
      "Batch 40, loss=0.0475, recon=0.0471, kl=9.5730, beta=0.0000\n",
      "Batch 60, loss=0.0315, recon=0.0312, kl=8.4176, beta=0.0000\n",
      "Batch 80, loss=0.0252, recon=0.0250, kl=6.5189, beta=0.0000\n",
      "Batch 100, loss=0.0347, recon=0.0344, kl=6.3840, beta=0.0000\n",
      "Batch 120, loss=0.0284, recon=0.0282, kl=6.5418, beta=0.0000\n",
      "Batch 140, loss=0.0208, recon=0.0205, kl=7.2910, beta=0.0000\n",
      "Batch 160, loss=0.0243, recon=0.0239, kl=8.6879, beta=0.0000\n",
      "Batch 180, loss=0.0170, recon=0.0167, kl=7.0124, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0354, KL: 8.2600, Current Beta: 0.0000) | Avg Valid Loss: 0.0329 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0298, recon=0.0295, kl=2.6595, beta=0.0001\n",
      "Batch 40, loss=0.0459, recon=0.0455, kl=3.5421, beta=0.0001\n",
      "Batch 60, loss=0.0256, recon=0.0253, kl=2.4271, beta=0.0001\n",
      "Batch 80, loss=0.0319, recon=0.0317, kl=1.8536, beta=0.0001\n",
      "Batch 100, loss=0.0446, recon=0.0445, kl=1.5992, beta=0.0001\n",
      "Batch 120, loss=0.0286, recon=0.0284, kl=2.4558, beta=0.0001\n",
      "Batch 140, loss=0.0381, recon=0.0380, kl=1.3432, beta=0.0001\n",
      "Batch 160, loss=0.0536, recon=0.0535, kl=0.9567, beta=0.0001\n",
      "Batch 180, loss=0.0491, recon=0.0488, kl=2.4850, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0414, KL: 2.2140, Current Beta: 0.0001) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0209, recon=0.0208, kl=0.4836, beta=0.0003\n",
      "Batch 40, loss=0.0255, recon=0.0254, kl=0.2697, beta=0.0003\n",
      "Batch 60, loss=0.0329, recon=0.0328, kl=0.2208, beta=0.0003\n",
      "Batch 80, loss=0.0441, recon=0.0440, kl=0.2504, beta=0.0003\n",
      "Batch 100, loss=0.0294, recon=0.0293, kl=0.6096, beta=0.0003\n",
      "Batch 120, loss=0.0192, recon=0.0191, kl=0.4006, beta=0.0003\n",
      "Batch 140, loss=0.0403, recon=0.0402, kl=0.2056, beta=0.0003\n",
      "Batch 160, loss=0.0389, recon=0.0389, kl=0.1702, beta=0.0003\n",
      "Batch 180, loss=0.0434, recon=0.0429, kl=1.6406, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0372 (Recon: 0.0370, KL: 0.5194, Current Beta: 0.0003) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0348\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0296, recon=0.0295, kl=0.1653, beta=0.0008\n",
      "Batch 40, loss=0.0236, recon=0.0235, kl=0.1081, beta=0.0008\n",
      "Batch 60, loss=0.0221, recon=0.0215, kl=0.6831, beta=0.0008\n",
      "Batch 80, loss=0.0374, recon=0.0373, kl=0.0942, beta=0.0008\n",
      "Batch 100, loss=0.0254, recon=0.0254, kl=0.0532, beta=0.0008\n",
      "Batch 120, loss=0.0259, recon=0.0258, kl=0.1077, beta=0.0008\n",
      "Batch 140, loss=0.0311, recon=0.0311, kl=0.0381, beta=0.0008\n",
      "Batch 160, loss=0.0177, recon=0.0177, kl=0.0445, beta=0.0008\n",
      "Batch 180, loss=0.0285, recon=0.0285, kl=0.0295, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0340 (Recon: 0.0339, KL: 0.1361, Current Beta: 0.0008) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0369, recon=0.0367, kl=0.1113, beta=0.0018\n",
      "Batch 40, loss=0.0312, recon=0.0311, kl=0.0505, beta=0.0018\n",
      "Batch 60, loss=0.0259, recon=0.0259, kl=0.0262, beta=0.0018\n",
      "Batch 80, loss=0.0517, recon=0.0517, kl=0.0211, beta=0.0018\n",
      "Batch 100, loss=0.0282, recon=0.0281, kl=0.0445, beta=0.0018\n",
      "Batch 120, loss=0.0315, recon=0.0314, kl=0.0662, beta=0.0018\n",
      "Batch 140, loss=0.0276, recon=0.0275, kl=0.0169, beta=0.0018\n",
      "Batch 160, loss=0.0297, recon=0.0295, kl=0.0933, beta=0.0018\n",
      "Batch 180, loss=0.0218, recon=0.0218, kl=0.0207, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0406 (Recon: 0.0405, KL: 0.0444, Current Beta: 0.0018) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0551, recon=0.0547, kl=0.1121, beta=0.0038\n",
      "Batch 40, loss=0.0359, recon=0.0358, kl=0.0445, beta=0.0038\n",
      "Batch 60, loss=0.0575, recon=0.0574, kl=0.0168, beta=0.0038\n",
      "Batch 80, loss=0.0248, recon=0.0247, kl=0.0126, beta=0.0038\n",
      "Batch 100, loss=0.0270, recon=0.0269, kl=0.0217, beta=0.0038\n",
      "Batch 120, loss=0.0180, recon=0.0179, kl=0.0069, beta=0.0038\n",
      "Batch 140, loss=0.0325, recon=0.0325, kl=0.0053, beta=0.0038\n",
      "Batch 160, loss=0.0208, recon=0.0207, kl=0.0125, beta=0.0038\n",
      "Batch 180, loss=0.0259, recon=0.0258, kl=0.0105, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0353 (Recon: 0.0352, KL: 0.0234, Current Beta: 0.0038) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0245, recon=0.0242, kl=0.0400, beta=0.0062\n",
      "Batch 40, loss=0.0214, recon=0.0213, kl=0.0124, beta=0.0062\n",
      "Batch 60, loss=0.0285, recon=0.0285, kl=0.0044, beta=0.0062\n",
      "Batch 80, loss=0.0259, recon=0.0259, kl=0.0054, beta=0.0062\n",
      "Batch 100, loss=0.0275, recon=0.0275, kl=0.0098, beta=0.0062\n",
      "Batch 120, loss=0.0558, recon=0.0558, kl=0.0059, beta=0.0062\n",
      "Batch 140, loss=0.1194, recon=0.1194, kl=0.0103, beta=0.0062\n",
      "Batch 160, loss=0.0698, recon=0.0697, kl=0.0167, beta=0.0062\n",
      "Batch 180, loss=0.0339, recon=0.0339, kl=0.0093, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0409, KL: 0.0129, Current Beta: 0.0062) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0268, recon=0.0268, kl=0.0038, beta=0.0100\n",
      "Batch 40, loss=0.0547, recon=0.0547, kl=0.0025, beta=0.0100\n",
      "Batch 60, loss=0.0313, recon=0.0312, kl=0.0080, beta=0.0100\n",
      "Batch 80, loss=0.0403, recon=0.0402, kl=0.0068, beta=0.0100\n",
      "Batch 100, loss=0.0275, recon=0.0275, kl=0.0048, beta=0.0100\n",
      "Batch 120, loss=0.0433, recon=0.0433, kl=0.0058, beta=0.0100\n",
      "Batch 140, loss=0.0293, recon=0.0292, kl=0.0039, beta=0.0100\n",
      "Batch 160, loss=0.0222, recon=0.0222, kl=0.0029, beta=0.0100\n",
      "Batch 180, loss=0.0385, recon=0.0385, kl=0.0018, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0399 (Recon: 0.0398, KL: 0.0087, Current Beta: 0.0100) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0325\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0312, recon=0.0312, kl=0.0011, beta=0.0100\n",
      "Batch 40, loss=0.0561, recon=0.0561, kl=0.0013, beta=0.0100\n",
      "Batch 60, loss=0.0213, recon=0.0213, kl=0.0023, beta=0.0100\n",
      "Batch 80, loss=0.0188, recon=0.0188, kl=0.0030, beta=0.0100\n",
      "Batch 100, loss=0.0182, recon=0.0181, kl=0.0016, beta=0.0100\n",
      "Batch 120, loss=0.0229, recon=0.0229, kl=0.0017, beta=0.0100\n",
      "Batch 140, loss=0.0222, recon=0.0220, kl=0.0125, beta=0.0100\n",
      "Batch 160, loss=0.0365, recon=0.0365, kl=0.0023, beta=0.0100\n",
      "Batch 180, loss=0.0411, recon=0.0410, kl=0.0028, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0353, KL: 0.0034, Current Beta: 0.0100) | Avg Valid Loss: 0.0333 | Avg Valid recon Loss: 0.0332\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0262, recon=0.0261, kl=0.0029, beta=0.0100\n",
      "Batch 40, loss=0.0399, recon=0.0399, kl=0.0026, beta=0.0100\n",
      "Batch 60, loss=0.0444, recon=0.0444, kl=0.0060, beta=0.0100\n",
      "Batch 80, loss=0.0348, recon=0.0342, kl=0.0683, beta=0.0100\n",
      "Batch 100, loss=0.0357, recon=0.0355, kl=0.0219, beta=0.0100\n",
      "Batch 120, loss=0.0308, recon=0.0307, kl=0.0062, beta=0.0100\n",
      "Batch 140, loss=0.0288, recon=0.0288, kl=0.0065, beta=0.0100\n",
      "Batch 160, loss=0.0449, recon=0.0448, kl=0.0076, beta=0.0100\n",
      "Batch 180, loss=0.0348, recon=0.0347, kl=0.0038, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0457, KL: 0.0187, Current Beta: 0.0100) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0497\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0358, recon=0.0358, kl=0.0048, beta=0.0100\n",
      "Batch 40, loss=0.0842, recon=0.0840, kl=0.0196, beta=0.0100\n",
      "Batch 60, loss=0.0580, recon=0.0574, kl=0.0659, beta=0.0100\n",
      "Batch 80, loss=0.1034, recon=0.1005, kl=0.2949, beta=0.0100\n",
      "Batch 100, loss=0.0791, recon=0.0704, kl=0.8715, beta=0.0100\n",
      "Batch 120, loss=0.0752, recon=0.0689, kl=0.6286, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 89/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5356, recon=0.5356, kl=2.2337, beta=0.0000\n",
      "Batch 40, loss=0.3088, recon=0.3088, kl=56.7324, beta=0.0000\n",
      "Batch 60, loss=0.1291, recon=0.1291, kl=88.0479, beta=0.0000\n",
      "Batch 80, loss=0.2241, recon=0.2241, kl=94.3284, beta=0.0000\n",
      "Batch 100, loss=0.1544, recon=0.1544, kl=98.4510, beta=0.0000\n",
      "Batch 120, loss=0.1170, recon=0.1170, kl=100.8729, beta=0.0000\n",
      "Batch 140, loss=0.1029, recon=0.1029, kl=103.4143, beta=0.0000\n",
      "Batch 160, loss=0.0960, recon=0.0960, kl=108.8794, beta=0.0000\n",
      "Batch 180, loss=0.1389, recon=0.1389, kl=124.6598, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2437 (Recon: 0.2437, KL: 79.7407, Current Beta: 0.0000) | Avg Valid Loss: 0.1034 | Avg Valid recon Loss: 0.1034\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0890, recon=0.0890, kl=125.0822, beta=0.0000\n",
      "Batch 40, loss=0.1469, recon=0.1469, kl=128.6133, beta=0.0000\n",
      "Batch 60, loss=0.0919, recon=0.0919, kl=127.6106, beta=0.0000\n",
      "Batch 80, loss=0.0945, recon=0.0945, kl=111.0548, beta=0.0000\n",
      "Batch 100, loss=0.1105, recon=0.1105, kl=112.6113, beta=0.0000\n",
      "Batch 120, loss=0.1335, recon=0.1335, kl=117.7859, beta=0.0000\n",
      "Batch 140, loss=0.1206, recon=0.1206, kl=117.6991, beta=0.0000\n",
      "Batch 160, loss=0.0801, recon=0.0801, kl=122.1614, beta=0.0000\n",
      "Batch 180, loss=0.1146, recon=0.1146, kl=123.9723, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1166 (Recon: 0.1166, KL: 120.6104, Current Beta: 0.0000) | Avg Valid Loss: 0.0755 | Avg Valid recon Loss: 0.0755\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0843, recon=0.0843, kl=120.8583, beta=0.0000\n",
      "Batch 40, loss=0.0852, recon=0.0852, kl=107.0824, beta=0.0000\n",
      "Batch 60, loss=0.1110, recon=0.1110, kl=88.9229, beta=0.0000\n",
      "Batch 80, loss=0.0627, recon=0.0626, kl=89.0181, beta=0.0000\n",
      "Batch 100, loss=0.0648, recon=0.0648, kl=95.3155, beta=0.0000\n",
      "Batch 120, loss=0.1298, recon=0.1298, kl=92.6449, beta=0.0000\n",
      "Batch 140, loss=0.0612, recon=0.0611, kl=88.8043, beta=0.0000\n",
      "Batch 160, loss=0.0610, recon=0.0610, kl=86.4112, beta=0.0000\n",
      "Batch 180, loss=0.0557, recon=0.0557, kl=93.0026, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0877 (Recon: 0.0877, KL: 97.7345, Current Beta: 0.0000) | Avg Valid Loss: 0.0632 | Avg Valid recon Loss: 0.0632\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0483, recon=0.0483, kl=84.5956, beta=0.0000\n",
      "Batch 40, loss=0.0625, recon=0.0625, kl=70.2248, beta=0.0000\n",
      "Batch 60, loss=0.0875, recon=0.0875, kl=63.1458, beta=0.0000\n",
      "Batch 80, loss=0.0505, recon=0.0505, kl=62.3389, beta=0.0000\n",
      "Batch 100, loss=0.0454, recon=0.0454, kl=65.5238, beta=0.0000\n",
      "Batch 120, loss=0.0733, recon=0.0733, kl=58.5769, beta=0.0000\n",
      "Batch 140, loss=0.2927, recon=0.2927, kl=60.1788, beta=0.0000\n",
      "Batch 160, loss=0.0611, recon=0.0611, kl=59.9005, beta=0.0000\n",
      "Batch 180, loss=0.0425, recon=0.0425, kl=57.2822, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0724 (Recon: 0.0724, KL: 66.5789, Current Beta: 0.0000) | Avg Valid Loss: 0.0588 | Avg Valid recon Loss: 0.0588\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0383, recon=0.0383, kl=51.6061, beta=0.0000\n",
      "Batch 40, loss=0.0403, recon=0.0403, kl=34.9405, beta=0.0000\n",
      "Batch 60, loss=1.1557, recon=1.1557, kl=34.2155, beta=0.0000\n",
      "Batch 80, loss=0.0571, recon=0.0571, kl=34.1766, beta=0.0000\n",
      "Batch 100, loss=0.0921, recon=0.0921, kl=35.1431, beta=0.0000\n",
      "Batch 120, loss=0.0641, recon=0.0641, kl=32.7201, beta=0.0000\n",
      "Batch 140, loss=0.0678, recon=0.0678, kl=32.7190, beta=0.0000\n",
      "Batch 160, loss=0.0338, recon=0.0338, kl=34.7919, beta=0.0000\n",
      "Batch 180, loss=0.0555, recon=0.0555, kl=34.0736, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0635 (Recon: 0.0634, KL: 36.9756, Current Beta: 0.0000) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0523\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0544, recon=0.0543, kl=20.9065, beta=0.0000\n",
      "Batch 40, loss=0.0397, recon=0.0397, kl=13.7684, beta=0.0000\n",
      "Batch 60, loss=0.0482, recon=0.0482, kl=15.2966, beta=0.0000\n",
      "Batch 80, loss=0.0416, recon=0.0415, kl=15.1633, beta=0.0000\n",
      "Batch 100, loss=0.0382, recon=0.0382, kl=14.4244, beta=0.0000\n",
      "Batch 120, loss=0.0393, recon=0.0393, kl=15.7503, beta=0.0000\n",
      "Batch 140, loss=0.0619, recon=0.0619, kl=16.9388, beta=0.0000\n",
      "Batch 160, loss=0.0467, recon=0.0466, kl=16.0328, beta=0.0000\n",
      "Batch 180, loss=0.0437, recon=0.0437, kl=15.1782, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0567 (Recon: 0.0567, KL: 16.9574, Current Beta: 0.0000) | Avg Valid Loss: 0.0490 | Avg Valid recon Loss: 0.0490\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0478, recon=0.0478, kl=7.4874, beta=0.0000\n",
      "Batch 40, loss=0.0289, recon=0.0289, kl=5.6745, beta=0.0000\n",
      "Batch 60, loss=0.0434, recon=0.0434, kl=6.8548, beta=0.0000\n",
      "Batch 80, loss=0.0498, recon=0.0498, kl=6.1333, beta=0.0000\n",
      "Batch 100, loss=0.0687, recon=0.0687, kl=5.2886, beta=0.0000\n",
      "Batch 120, loss=0.0544, recon=0.0544, kl=6.1137, beta=0.0000\n",
      "Batch 140, loss=0.0497, recon=0.0496, kl=5.9947, beta=0.0000\n",
      "Batch 160, loss=0.0306, recon=0.0306, kl=4.3986, beta=0.0000\n",
      "Batch 180, loss=0.0286, recon=0.0286, kl=4.1492, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0523, KL: 6.3627, Current Beta: 0.0000) | Avg Valid Loss: 0.0446 | Avg Valid recon Loss: 0.0445\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0447, recon=0.0447, kl=2.4795, beta=0.0000\n",
      "Batch 40, loss=0.0353, recon=0.0352, kl=2.4008, beta=0.0000\n",
      "Batch 60, loss=0.0260, recon=0.0259, kl=2.5621, beta=0.0000\n",
      "Batch 80, loss=0.0295, recon=0.0295, kl=2.6903, beta=0.0000\n",
      "Batch 100, loss=0.0402, recon=0.0402, kl=1.8406, beta=0.0000\n",
      "Batch 120, loss=0.0766, recon=0.0766, kl=1.7290, beta=0.0000\n",
      "Batch 140, loss=0.0325, recon=0.0325, kl=2.7821, beta=0.0000\n",
      "Batch 160, loss=0.0275, recon=0.0275, kl=1.9121, beta=0.0000\n",
      "Batch 180, loss=0.0291, recon=0.0291, kl=1.4553, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0491 (Recon: 0.0491, KL: 2.3169, Current Beta: 0.0000) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0280, recon=0.0279, kl=0.6459, beta=0.0000\n",
      "Batch 40, loss=0.0256, recon=0.0255, kl=1.0554, beta=0.0000\n",
      "Batch 60, loss=0.1832, recon=0.1832, kl=0.5365, beta=0.0000\n",
      "Batch 80, loss=0.0289, recon=0.0288, kl=0.7331, beta=0.0000\n",
      "Batch 100, loss=0.0322, recon=0.0321, kl=0.5026, beta=0.0000\n",
      "Batch 120, loss=0.0529, recon=0.0528, kl=0.7265, beta=0.0000\n",
      "Batch 140, loss=0.0297, recon=0.0297, kl=0.5260, beta=0.0000\n",
      "Batch 160, loss=0.2207, recon=0.2207, kl=0.4581, beta=0.0000\n",
      "Batch 180, loss=0.0293, recon=0.0293, kl=0.2804, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0465 (Recon: 0.0465, KL: 0.6575, Current Beta: 0.0000) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0281, recon=0.0281, kl=0.0911, beta=0.0001\n",
      "Batch 40, loss=0.0302, recon=0.0302, kl=0.0863, beta=0.0001\n",
      "Batch 60, loss=0.0327, recon=0.0327, kl=0.1063, beta=0.0001\n",
      "Batch 80, loss=0.0306, recon=0.0306, kl=0.0952, beta=0.0001\n",
      "Batch 100, loss=0.0283, recon=0.0283, kl=0.0526, beta=0.0001\n",
      "Batch 120, loss=0.0409, recon=0.0408, kl=0.0443, beta=0.0001\n",
      "Batch 140, loss=0.0301, recon=0.0301, kl=0.0261, beta=0.0001\n",
      "Batch 160, loss=0.0255, recon=0.0255, kl=0.0290, beta=0.0001\n",
      "Batch 180, loss=0.0377, recon=0.0377, kl=0.0306, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0448, KL: 0.0754, Current Beta: 0.0001) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0369, recon=0.0369, kl=0.0042, beta=0.0003\n",
      "Batch 40, loss=0.0317, recon=0.0317, kl=0.0039, beta=0.0003\n",
      "Batch 60, loss=0.0239, recon=0.0239, kl=0.0034, beta=0.0003\n",
      "Batch 80, loss=0.0288, recon=0.0288, kl=0.0088, beta=0.0003\n",
      "Batch 100, loss=0.0262, recon=0.0262, kl=0.0095, beta=0.0003\n",
      "Batch 120, loss=0.0442, recon=0.0442, kl=0.0049, beta=0.0003\n",
      "Batch 140, loss=0.0525, recon=0.0525, kl=0.0056, beta=0.0003\n",
      "Batch 160, loss=0.0226, recon=0.0225, kl=0.0042, beta=0.0003\n",
      "Batch 180, loss=0.0216, recon=0.0216, kl=0.0071, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0432, KL: 0.0070, Current Beta: 0.0003) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=0.0022, beta=0.0008\n",
      "Batch 40, loss=0.0493, recon=0.0493, kl=0.0009, beta=0.0008\n",
      "Batch 60, loss=0.0257, recon=0.0257, kl=0.0008, beta=0.0008\n",
      "Batch 80, loss=0.0350, recon=0.0350, kl=0.0006, beta=0.0008\n",
      "Batch 100, loss=0.0250, recon=0.0250, kl=0.0023, beta=0.0008\n",
      "Batch 120, loss=0.0286, recon=0.0286, kl=0.0010, beta=0.0008\n",
      "Batch 140, loss=0.0422, recon=0.0422, kl=0.0012, beta=0.0008\n",
      "Batch 160, loss=0.0604, recon=0.0604, kl=0.0014, beta=0.0008\n",
      "Batch 180, loss=0.0335, recon=0.0335, kl=0.0009, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0419, KL: 0.0016, Current Beta: 0.0008) | Avg Valid Loss: 0.0367 | Avg Valid recon Loss: 0.0367\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0274, recon=0.0274, kl=0.0009, beta=0.0018\n",
      "Batch 40, loss=0.0436, recon=0.0436, kl=0.0003, beta=0.0018\n",
      "Batch 60, loss=0.0296, recon=0.0296, kl=0.0003, beta=0.0018\n",
      "Batch 80, loss=0.0235, recon=0.0235, kl=0.0002, beta=0.0018\n",
      "Batch 100, loss=0.0214, recon=0.0214, kl=0.0002, beta=0.0018\n",
      "Batch 120, loss=0.0332, recon=0.0332, kl=0.0007, beta=0.0018\n",
      "Batch 140, loss=0.0338, recon=0.0338, kl=0.0002, beta=0.0018\n",
      "Batch 160, loss=0.0468, recon=0.0468, kl=0.0005, beta=0.0018\n",
      "Batch 180, loss=0.0248, recon=0.0248, kl=0.0004, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0410, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0360\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0548, recon=0.0548, kl=0.0003, beta=0.0038\n",
      "Batch 40, loss=0.1338, recon=0.1338, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.0397, recon=0.0397, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0450, recon=0.0450, kl=0.0003, beta=0.0038\n",
      "Batch 100, loss=0.0225, recon=0.0225, kl=0.0002, beta=0.0038\n",
      "Batch 120, loss=0.0422, recon=0.0422, kl=0.0002, beta=0.0038\n",
      "Batch 140, loss=0.0378, recon=0.0378, kl=0.0001, beta=0.0038\n",
      "Batch 160, loss=0.0360, recon=0.0360, kl=0.0001, beta=0.0038\n",
      "Batch 180, loss=0.0320, recon=0.0320, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0396 (Recon: 0.0396, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.0348 | Avg Valid recon Loss: 0.0348\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0543, recon=0.0543, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0350, recon=0.0350, kl=0.0002, beta=0.0062\n",
      "Batch 60, loss=0.0258, recon=0.0258, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=0.0000, beta=0.0062\n",
      "Batch 100, loss=0.0371, recon=0.0371, kl=0.0001, beta=0.0062\n",
      "Batch 120, loss=0.0443, recon=0.0443, kl=0.0003, beta=0.0062\n",
      "Batch 140, loss=0.0322, recon=0.0322, kl=0.0001, beta=0.0062\n",
      "Batch 160, loss=0.0356, recon=0.0356, kl=0.0000, beta=0.0062\n",
      "Batch 180, loss=0.0545, recon=0.0545, kl=0.0002, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0390, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0397, recon=0.0397, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0302, recon=0.0302, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0290, recon=0.0290, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.1078, recon=0.1078, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0363, recon=0.0363, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0284, recon=0.0284, kl=0.0007, beta=0.0100\n",
      "Batch 140, loss=0.0270, recon=0.0270, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0278, recon=0.0278, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0286, recon=0.0286, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0382, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0238, recon=0.0238, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0227, recon=0.0227, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0404, recon=0.0404, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0349, recon=0.0349, kl=0.0002, beta=0.0100\n",
      "Batch 100, loss=0.0308, recon=0.0308, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0275, recon=0.0275, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0239, recon=0.0239, kl=0.0002, beta=0.0100\n",
      "Batch 160, loss=0.0253, recon=0.0253, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0567, recon=0.0567, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0372 (Recon: 0.0372, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0326 | Avg Valid recon Loss: 0.0326\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0414, recon=0.0414, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0451, recon=0.0451, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0237, recon=0.0237, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0304, recon=0.0304, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0310, recon=0.0310, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0205, recon=0.0205, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0334, recon=0.0334, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0832, recon=0.0832, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0993, recon=0.0993, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0366 (Recon: 0.0366, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0318\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0246, recon=0.0246, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0567, recon=0.0567, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0466, recon=0.0466, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0462, recon=0.0462, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0213, recon=0.0213, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0565, recon=0.0565, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0334, recon=0.0334, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0205, recon=0.0205, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0344, recon=0.0344, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0361 (Recon: 0.0361, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0319 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0274, recon=0.0274, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0342, recon=0.0342, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0297, recon=0.0297, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0511, recon=0.0511, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0164, recon=0.0164, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0246, recon=0.0246, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0246, recon=0.0246, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0262, recon=0.0262, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0479, recon=0.0479, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0358, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0309 | Avg Valid recon Loss: 0.0309\n",
      "\n",
      "[VRAE Run 90/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1686, recon=0.1686, kl=50.3066, beta=0.0000\n",
      "Batch 40, loss=0.1008, recon=0.1008, kl=85.2044, beta=0.0000\n",
      "Batch 60, loss=0.0857, recon=0.0857, kl=80.0887, beta=0.0000\n",
      "Batch 80, loss=0.1116, recon=0.1116, kl=104.9845, beta=0.0000\n",
      "Batch 100, loss=0.0521, recon=0.0521, kl=104.5466, beta=0.0000\n",
      "Batch 120, loss=0.0506, recon=0.0506, kl=115.4190, beta=0.0000\n",
      "Batch 140, loss=0.0376, recon=0.0376, kl=89.0234, beta=0.0000\n",
      "Batch 160, loss=0.0360, recon=0.0360, kl=96.7104, beta=0.0000\n",
      "Batch 180, loss=0.0412, recon=0.0411, kl=113.4841, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1080 (Recon: 0.1080, KL: 89.1062, Current Beta: 0.0000) | Avg Valid Loss: 0.0527 | Avg Valid recon Loss: 0.0527\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0673, recon=0.0673, kl=116.6600, beta=0.0000\n",
      "Batch 40, loss=0.0397, recon=0.0397, kl=106.3143, beta=0.0000\n",
      "Batch 60, loss=0.0411, recon=0.0411, kl=103.0239, beta=0.0000\n",
      "Batch 80, loss=0.0262, recon=0.0262, kl=116.0894, beta=0.0000\n",
      "Batch 100, loss=0.0486, recon=0.0486, kl=123.2270, beta=0.0000\n",
      "Batch 120, loss=0.0571, recon=0.0571, kl=97.1266, beta=0.0000\n",
      "Batch 140, loss=0.0506, recon=0.0506, kl=105.1611, beta=0.0000\n",
      "Batch 160, loss=0.0311, recon=0.0311, kl=112.2594, beta=0.0000\n",
      "Batch 180, loss=0.0626, recon=0.0626, kl=87.6232, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0561 (Recon: 0.0561, KL: 107.7437, Current Beta: 0.0000) | Avg Valid Loss: 0.0536 | Avg Valid recon Loss: 0.0536\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0349, recon=0.0349, kl=105.5125, beta=0.0000\n",
      "Batch 40, loss=0.0250, recon=0.0250, kl=123.9894, beta=0.0000\n",
      "Batch 60, loss=0.2134, recon=0.2134, kl=109.4415, beta=0.0000\n",
      "Batch 80, loss=0.0266, recon=0.0266, kl=116.2507, beta=0.0000\n",
      "Batch 100, loss=0.0453, recon=0.0453, kl=152.7372, beta=0.0000\n",
      "Batch 120, loss=0.0825, recon=0.0825, kl=163.9084, beta=0.0000\n",
      "Batch 140, loss=0.0760, recon=0.0759, kl=234.4827, beta=0.0000\n",
      "Batch 160, loss=0.0710, recon=0.0710, kl=264.0116, beta=0.0000\n",
      "Batch 180, loss=0.0365, recon=0.0365, kl=266.5924, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1847 (Recon: 0.1847, KL: 161.1825, Current Beta: 0.0000) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0523, recon=0.0522, kl=267.7534, beta=0.0000\n",
      "Batch 40, loss=0.0239, recon=0.0238, kl=262.1662, beta=0.0000\n",
      "Batch 60, loss=0.0502, recon=0.0501, kl=262.6384, beta=0.0000\n",
      "Batch 80, loss=0.0258, recon=0.0257, kl=267.3929, beta=0.0000\n",
      "Batch 100, loss=0.0370, recon=0.0370, kl=266.2013, beta=0.0000\n",
      "Batch 120, loss=0.0306, recon=0.0305, kl=266.5121, beta=0.0000\n",
      "Batch 140, loss=0.0565, recon=0.0564, kl=261.8496, beta=0.0000\n",
      "Batch 160, loss=0.0340, recon=0.0339, kl=265.3094, beta=0.0000\n",
      "Batch 180, loss=0.0299, recon=0.0298, kl=260.0342, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0517 (Recon: 0.0517, KL: 264.1255, Current Beta: 0.0000) | Avg Valid Loss: 0.0428 | Avg Valid recon Loss: 0.0427\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0651, recon=0.0649, kl=265.5857, beta=0.0000\n",
      "Batch 40, loss=0.0290, recon=0.0288, kl=251.0545, beta=0.0000\n",
      "Batch 60, loss=0.0381, recon=0.0380, kl=240.5819, beta=0.0000\n",
      "Batch 80, loss=0.0303, recon=0.0301, kl=238.0595, beta=0.0000\n",
      "Batch 100, loss=0.0314, recon=0.0312, kl=232.5249, beta=0.0000\n",
      "Batch 120, loss=0.0389, recon=0.0388, kl=227.4869, beta=0.0000\n",
      "Batch 140, loss=0.0524, recon=0.0523, kl=219.2405, beta=0.0000\n",
      "Batch 160, loss=0.0424, recon=0.0422, kl=215.8991, beta=0.0000\n",
      "Batch 180, loss=0.0297, recon=0.0296, kl=209.1127, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0488 (Recon: 0.0486, KL: 234.2931, Current Beta: 0.0000) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0323, recon=0.0319, kl=198.6949, beta=0.0000\n",
      "Batch 40, loss=0.2125, recon=0.2121, kl=188.5118, beta=0.0000\n",
      "Batch 60, loss=0.0298, recon=0.0295, kl=170.2984, beta=0.0000\n",
      "Batch 80, loss=0.0291, recon=0.0288, kl=163.3855, beta=0.0000\n",
      "Batch 100, loss=0.0568, recon=0.0565, kl=152.0465, beta=0.0000\n",
      "Batch 120, loss=0.0228, recon=0.0225, kl=145.3505, beta=0.0000\n",
      "Batch 140, loss=0.0321, recon=0.0318, kl=138.3979, beta=0.0000\n",
      "Batch 160, loss=0.0274, recon=0.0271, kl=129.5697, beta=0.0000\n",
      "Batch 180, loss=0.0231, recon=0.0229, kl=122.0509, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0454, KL: 160.4881, Current Beta: 0.0000) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0365\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0269, recon=0.0263, kl=104.9050, beta=0.0000\n",
      "Batch 40, loss=0.0318, recon=0.0313, kl=90.3823, beta=0.0000\n",
      "Batch 60, loss=0.0414, recon=0.0409, kl=83.4551, beta=0.0000\n",
      "Batch 80, loss=0.0347, recon=0.0342, kl=79.1320, beta=0.0000\n",
      "Batch 100, loss=0.0350, recon=0.0346, kl=73.8990, beta=0.0000\n",
      "Batch 120, loss=0.0265, recon=0.0261, kl=69.5894, beta=0.0000\n",
      "Batch 140, loss=0.0229, recon=0.0225, kl=66.4573, beta=0.0000\n",
      "Batch 160, loss=0.0277, recon=0.0273, kl=63.3235, beta=0.0000\n",
      "Batch 180, loss=0.0629, recon=0.0625, kl=63.9364, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6250 (Recon: 0.6246, KL: 80.6390, Current Beta: 0.0000) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0398, recon=0.0377, kl=138.6187, beta=0.0000\n",
      "Batch 40, loss=0.0620, recon=0.0601, kl=126.3439, beta=0.0000\n",
      "Batch 60, loss=0.0412, recon=0.0394, kl=118.2283, beta=0.0000\n",
      "Batch 80, loss=0.0386, recon=0.0369, kl=108.1439, beta=0.0000\n",
      "Batch 100, loss=0.0265, recon=0.0251, kl=94.6528, beta=0.0000\n",
      "Batch 120, loss=0.0256, recon=0.0244, kl=79.8139, beta=0.0000\n",
      "Batch 140, loss=0.0259, recon=0.0248, kl=69.1722, beta=0.0000\n",
      "Batch 160, loss=0.0415, recon=0.0398, kl=112.2073, beta=0.0000\n",
      "Batch 180, loss=0.0504, recon=0.0485, kl=128.8096, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0591 (Recon: 0.0575, KL: 106.4402, Current Beta: 0.0000) | Avg Valid Loss: 0.2721 | Avg Valid recon Loss: 0.2701\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0810, recon=0.0768, kl=103.0809, beta=0.0000\n",
      "Batch 40, loss=0.0685, recon=0.0654, kl=76.7387, beta=0.0000\n",
      "Batch 60, loss=0.0498, recon=0.0472, kl=63.3473, beta=0.0000\n",
      "Batch 80, loss=0.0291, recon=0.0271, kl=49.2874, beta=0.0000\n",
      "Batch 100, loss=0.1741, recon=0.1715, kl=63.8064, beta=0.0000\n",
      "Batch 120, loss=0.0896, recon=0.0857, kl=95.2308, beta=0.0000\n",
      "Batch 140, loss=0.0760, recon=0.0720, kl=99.2708, beta=0.0000\n",
      "Batch 160, loss=0.0680, recon=0.0642, kl=94.1422, beta=0.0000\n",
      "Batch 180, loss=0.0618, recon=0.0581, kl=91.7500, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1039 (Recon: 0.1005, KL: 83.5992, Current Beta: 0.0000) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0529\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0522, recon=0.0433, kl=81.2470, beta=0.0001\n",
      "Batch 40, loss=0.0590, recon=0.0512, kl=70.6172, beta=0.0001\n",
      "Batch 60, loss=0.0495, recon=0.0425, kl=63.5667, beta=0.0001\n",
      "Batch 80, loss=54.1980, recon=54.1899, kl=73.7770, beta=0.0001\n",
      "Batch 100, loss=0.1662, recon=0.1561, kl=91.2718, beta=0.0001\n",
      "Batch 120, loss=0.2899, recon=0.2728, kl=156.0222, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 11/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0003) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 12/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0008) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 13/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0018) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 14/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0038) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0062) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 91/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7453, recon=0.7453, kl=0.2927, beta=0.0000\n",
      "Batch 40, loss=0.5562, recon=0.5562, kl=2.2361, beta=0.0000\n",
      "Batch 60, loss=0.3370, recon=0.3370, kl=9.1972, beta=0.0000\n",
      "Batch 80, loss=0.3613, recon=0.3613, kl=12.8610, beta=0.0000\n",
      "Batch 100, loss=0.3101, recon=0.3101, kl=15.2228, beta=0.0000\n",
      "Batch 120, loss=0.3066, recon=0.3066, kl=17.8215, beta=0.0000\n",
      "Batch 140, loss=0.2135, recon=0.2135, kl=20.1895, beta=0.0000\n",
      "Batch 160, loss=0.1254, recon=0.1254, kl=22.0159, beta=0.0000\n",
      "Batch 180, loss=0.3177, recon=0.3177, kl=23.8746, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4309 (Recon: 0.4309, KL: 12.5782, Current Beta: 0.0000) | Avg Valid Loss: 0.2104 | Avg Valid recon Loss: 0.2104\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1666, recon=0.1666, kl=25.8161, beta=0.0000\n",
      "Batch 40, loss=0.2065, recon=0.2065, kl=26.8955, beta=0.0000\n",
      "Batch 60, loss=0.1160, recon=0.1160, kl=28.0639, beta=0.0000\n",
      "Batch 80, loss=0.1789, recon=0.1789, kl=29.3249, beta=0.0000\n",
      "Batch 100, loss=0.1918, recon=0.1918, kl=30.4551, beta=0.0000\n",
      "Batch 120, loss=0.1474, recon=0.1474, kl=31.3464, beta=0.0000\n",
      "Batch 140, loss=0.1704, recon=0.1704, kl=32.2489, beta=0.0000\n",
      "Batch 160, loss=0.3593, recon=0.3593, kl=32.7903, beta=0.0000\n",
      "Batch 180, loss=0.1137, recon=0.1137, kl=33.5040, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1822 (Recon: 0.1822, KL: 29.5750, Current Beta: 0.0000) | Avg Valid Loss: 0.1328 | Avg Valid recon Loss: 0.1328\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1521, recon=0.1521, kl=33.7993, beta=0.0000\n",
      "Batch 40, loss=0.0860, recon=0.0860, kl=34.6691, beta=0.0000\n",
      "Batch 60, loss=0.1563, recon=0.1563, kl=35.1389, beta=0.0000\n",
      "Batch 80, loss=0.1223, recon=0.1223, kl=35.9625, beta=0.0000\n",
      "Batch 100, loss=0.1341, recon=0.1341, kl=36.0307, beta=0.0000\n",
      "Batch 120, loss=0.1155, recon=0.1155, kl=36.9310, beta=0.0000\n",
      "Batch 140, loss=0.0783, recon=0.0783, kl=37.4478, beta=0.0000\n",
      "Batch 160, loss=0.0725, recon=0.0725, kl=37.1926, beta=0.0000\n",
      "Batch 180, loss=0.1568, recon=0.1568, kl=37.5814, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1336 (Recon: 0.1336, KL: 35.9103, Current Beta: 0.0000) | Avg Valid Loss: 0.1073 | Avg Valid recon Loss: 0.1073\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0920, recon=0.0920, kl=37.4091, beta=0.0000\n",
      "Batch 40, loss=0.0979, recon=0.0979, kl=37.6808, beta=0.0000\n",
      "Batch 60, loss=0.1232, recon=0.1232, kl=37.3883, beta=0.0000\n",
      "Batch 80, loss=0.1218, recon=0.1218, kl=36.8362, beta=0.0000\n",
      "Batch 100, loss=0.1068, recon=0.1068, kl=36.3718, beta=0.0000\n",
      "Batch 120, loss=0.0682, recon=0.0682, kl=36.2648, beta=0.0000\n",
      "Batch 140, loss=0.0958, recon=0.0958, kl=36.7842, beta=0.0000\n",
      "Batch 160, loss=0.1086, recon=0.1086, kl=37.0398, beta=0.0000\n",
      "Batch 180, loss=0.1080, recon=0.1079, kl=36.7764, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1108 (Recon: 0.1107, KL: 37.0122, Current Beta: 0.0000) | Avg Valid Loss: 0.0921 | Avg Valid recon Loss: 0.0921\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0770, recon=0.0770, kl=36.5546, beta=0.0000\n",
      "Batch 40, loss=0.0923, recon=0.0922, kl=35.1927, beta=0.0000\n",
      "Batch 60, loss=0.0652, recon=0.0651, kl=34.3012, beta=0.0000\n",
      "Batch 80, loss=0.0624, recon=0.0624, kl=33.6381, beta=0.0000\n",
      "Batch 100, loss=0.0819, recon=0.0819, kl=33.1380, beta=0.0000\n",
      "Batch 120, loss=0.0502, recon=0.0501, kl=32.0893, beta=0.0000\n",
      "Batch 140, loss=0.0643, recon=0.0643, kl=31.1848, beta=0.0000\n",
      "Batch 160, loss=0.0666, recon=0.0666, kl=30.3817, beta=0.0000\n",
      "Batch 180, loss=0.0990, recon=0.0990, kl=29.9337, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0964 (Recon: 0.0964, KL: 33.3206, Current Beta: 0.0000) | Avg Valid Loss: 0.0835 | Avg Valid recon Loss: 0.0834\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0761, recon=0.0761, kl=27.1775, beta=0.0000\n",
      "Batch 40, loss=0.0610, recon=0.0610, kl=24.0626, beta=0.0000\n",
      "Batch 60, loss=0.1648, recon=0.1647, kl=22.6942, beta=0.0000\n",
      "Batch 80, loss=0.0668, recon=0.0668, kl=21.9436, beta=0.0000\n",
      "Batch 100, loss=0.4152, recon=0.4152, kl=20.7221, beta=0.0000\n",
      "Batch 120, loss=0.0735, recon=0.0735, kl=20.4644, beta=0.0000\n",
      "Batch 140, loss=0.0455, recon=0.0455, kl=21.2432, beta=0.0000\n",
      "Batch 160, loss=0.0819, recon=0.0819, kl=20.6746, beta=0.0000\n",
      "Batch 180, loss=0.0568, recon=0.0568, kl=20.2625, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0872 (Recon: 0.0871, KL: 22.6655, Current Beta: 0.0000) | Avg Valid Loss: 0.0770 | Avg Valid recon Loss: 0.0769\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0494, recon=0.0493, kl=15.4044, beta=0.0000\n",
      "Batch 40, loss=0.0656, recon=0.0656, kl=12.0902, beta=0.0000\n",
      "Batch 60, loss=0.0473, recon=0.0472, kl=11.3540, beta=0.0000\n",
      "Batch 80, loss=0.0878, recon=0.0877, kl=11.4737, beta=0.0000\n",
      "Batch 100, loss=0.0739, recon=0.0738, kl=11.0886, beta=0.0000\n",
      "Batch 120, loss=0.0600, recon=0.0599, kl=10.2159, beta=0.0000\n",
      "Batch 140, loss=0.0756, recon=0.0756, kl=10.2806, beta=0.0000\n",
      "Batch 160, loss=0.0584, recon=0.0584, kl=9.7006, beta=0.0000\n",
      "Batch 180, loss=0.0938, recon=0.0937, kl=9.9155, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0808 (Recon: 0.0807, KL: 11.7793, Current Beta: 0.0000) | Avg Valid Loss: 0.0708 | Avg Valid recon Loss: 0.0707\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0591, recon=0.0590, kl=5.8551, beta=0.0000\n",
      "Batch 40, loss=0.0729, recon=0.0728, kl=5.3776, beta=0.0000\n",
      "Batch 60, loss=0.0782, recon=0.0781, kl=5.1721, beta=0.0000\n",
      "Batch 80, loss=0.0660, recon=0.0659, kl=4.9707, beta=0.0000\n",
      "Batch 100, loss=0.0685, recon=0.0684, kl=4.7227, beta=0.0000\n",
      "Batch 120, loss=0.0639, recon=0.0639, kl=4.4960, beta=0.0000\n",
      "Batch 140, loss=0.0637, recon=0.0636, kl=4.3265, beta=0.0000\n",
      "Batch 160, loss=0.0598, recon=0.0597, kl=3.7958, beta=0.0000\n",
      "Batch 180, loss=0.0648, recon=0.0647, kl=3.6968, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0761 (Recon: 0.0760, KL: 5.0164, Current Beta: 0.0000) | Avg Valid Loss: 0.0673 | Avg Valid recon Loss: 0.0673\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0559, recon=0.0559, kl=1.5657, beta=0.0000\n",
      "Batch 40, loss=0.0594, recon=0.0593, kl=1.7398, beta=0.0000\n",
      "Batch 60, loss=0.0746, recon=0.0745, kl=1.4680, beta=0.0000\n",
      "Batch 80, loss=0.0522, recon=0.0521, kl=1.4235, beta=0.0000\n",
      "Batch 100, loss=0.0464, recon=0.0463, kl=1.3206, beta=0.0000\n",
      "Batch 120, loss=0.0485, recon=0.0484, kl=1.0572, beta=0.0000\n",
      "Batch 140, loss=0.0893, recon=0.0892, kl=1.1182, beta=0.0000\n",
      "Batch 160, loss=0.0462, recon=0.0462, kl=1.0047, beta=0.0000\n",
      "Batch 180, loss=0.0508, recon=0.0508, kl=0.9956, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0721 (Recon: 0.0720, KL: 1.4319, Current Beta: 0.0000) | Avg Valid Loss: 0.0631 | Avg Valid recon Loss: 0.0631\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0435, recon=0.0435, kl=0.1711, beta=0.0001\n",
      "Batch 40, loss=0.0444, recon=0.0443, kl=0.2054, beta=0.0001\n",
      "Batch 60, loss=0.0475, recon=0.0475, kl=0.1794, beta=0.0001\n",
      "Batch 80, loss=0.1121, recon=0.1121, kl=0.1821, beta=0.0001\n",
      "Batch 100, loss=0.0360, recon=0.0360, kl=0.1066, beta=0.0001\n",
      "Batch 120, loss=0.1940, recon=0.1940, kl=0.1074, beta=0.0001\n",
      "Batch 140, loss=0.0669, recon=0.0669, kl=0.1252, beta=0.0001\n",
      "Batch 160, loss=0.0403, recon=0.0403, kl=0.0824, beta=0.0001\n",
      "Batch 180, loss=0.0514, recon=0.0513, kl=0.0618, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0685 (Recon: 0.0685, KL: 0.1716, Current Beta: 0.0001) | Avg Valid Loss: 0.0623 | Avg Valid recon Loss: 0.0623\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0536, recon=0.0536, kl=0.0060, beta=0.0003\n",
      "Batch 40, loss=0.0466, recon=0.0466, kl=0.0148, beta=0.0003\n",
      "Batch 60, loss=0.0344, recon=0.0344, kl=0.0121, beta=0.0003\n",
      "Batch 80, loss=0.0550, recon=0.0550, kl=0.0089, beta=0.0003\n",
      "Batch 100, loss=0.0534, recon=0.0534, kl=0.0045, beta=0.0003\n",
      "Batch 120, loss=0.0536, recon=0.0536, kl=0.0076, beta=0.0003\n",
      "Batch 140, loss=0.0450, recon=0.0450, kl=0.0093, beta=0.0003\n",
      "Batch 160, loss=0.0874, recon=0.0874, kl=0.0055, beta=0.0003\n",
      "Batch 180, loss=0.0451, recon=0.0451, kl=0.0054, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0658 (Recon: 0.0658, KL: 0.0097, Current Beta: 0.0003) | Avg Valid Loss: 0.0585 | Avg Valid recon Loss: 0.0585\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0354, recon=0.0354, kl=0.0015, beta=0.0008\n",
      "Batch 40, loss=0.0402, recon=0.0402, kl=0.0013, beta=0.0008\n",
      "Batch 60, loss=0.0431, recon=0.0431, kl=0.0013, beta=0.0008\n",
      "Batch 80, loss=0.0336, recon=0.0336, kl=0.0009, beta=0.0008\n",
      "Batch 100, loss=0.0497, recon=0.0497, kl=0.0006, beta=0.0008\n",
      "Batch 120, loss=0.0338, recon=0.0338, kl=0.0008, beta=0.0008\n",
      "Batch 140, loss=0.0938, recon=0.0938, kl=0.0007, beta=0.0008\n",
      "Batch 160, loss=0.0695, recon=0.0695, kl=0.0012, beta=0.0008\n",
      "Batch 180, loss=0.0510, recon=0.0510, kl=0.0020, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0636 (Recon: 0.0636, KL: 0.0011, Current Beta: 0.0008) | Avg Valid Loss: 0.0565 | Avg Valid recon Loss: 0.0565\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0719, recon=0.0719, kl=0.0004, beta=0.0018\n",
      "Batch 40, loss=0.0805, recon=0.0805, kl=0.0009, beta=0.0018\n",
      "Batch 60, loss=0.0981, recon=0.0981, kl=0.0004, beta=0.0018\n",
      "Batch 80, loss=0.0472, recon=0.0472, kl=0.0002, beta=0.0018\n",
      "Batch 100, loss=0.0467, recon=0.0467, kl=0.0002, beta=0.0018\n",
      "Batch 120, loss=0.0420, recon=0.0420, kl=0.0002, beta=0.0018\n",
      "Batch 140, loss=0.0679, recon=0.0679, kl=0.0002, beta=0.0018\n",
      "Batch 160, loss=0.0623, recon=0.0623, kl=0.0003, beta=0.0018\n",
      "Batch 180, loss=0.1350, recon=0.1350, kl=0.0004, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0616 (Recon: 0.0616, KL: 0.0003, Current Beta: 0.0018) | Avg Valid Loss: 0.0542 | Avg Valid recon Loss: 0.0542\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1081, recon=0.1081, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0319, recon=0.0319, kl=0.0000, beta=0.0038\n",
      "Batch 60, loss=0.0458, recon=0.0458, kl=0.0000, beta=0.0038\n",
      "Batch 80, loss=0.0373, recon=0.0373, kl=0.0001, beta=0.0038\n",
      "Batch 100, loss=0.0398, recon=0.0398, kl=0.0002, beta=0.0038\n",
      "Batch 120, loss=0.0525, recon=0.0525, kl=0.0001, beta=0.0038\n",
      "Batch 140, loss=0.0346, recon=0.0346, kl=0.0001, beta=0.0038\n",
      "Batch 160, loss=0.0275, recon=0.0275, kl=0.0001, beta=0.0038\n",
      "Batch 180, loss=0.0371, recon=0.0371, kl=0.0002, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0598 (Recon: 0.0598, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0377, recon=0.0377, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0360, recon=0.0360, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0458, recon=0.0458, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0309, recon=0.0309, kl=0.0001, beta=0.0062\n",
      "Batch 100, loss=0.0435, recon=0.0435, kl=0.0000, beta=0.0062\n",
      "Batch 120, loss=0.0387, recon=0.0387, kl=0.0001, beta=0.0062\n",
      "Batch 140, loss=0.0375, recon=0.0375, kl=0.0001, beta=0.0062\n",
      "Batch 160, loss=0.0624, recon=0.0624, kl=0.0001, beta=0.0062\n",
      "Batch 180, loss=0.0306, recon=0.0306, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0581, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0517 | Avg Valid recon Loss: 0.0517\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0862, recon=0.0862, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.2185, recon=0.2185, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.1608, recon=0.1608, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0294, recon=0.0294, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0364, recon=0.0364, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.2722, recon=0.2722, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0300, recon=0.0300, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0336, recon=0.0336, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0510, recon=0.0510, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0567 (Recon: 0.0567, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0505 | Avg Valid recon Loss: 0.0505\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0361, recon=0.0361, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0617, recon=0.0617, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0343, recon=0.0343, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0281, recon=0.0281, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0528, recon=0.0527, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0432, recon=0.0432, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0418, recon=0.0418, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0489, recon=0.0489, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0309, recon=0.0309, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0556 (Recon: 0.0556, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0292, recon=0.0292, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0325, recon=0.0325, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0270, recon=0.0270, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0419, recon=0.0419, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0376, recon=0.0376, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0517, recon=0.0517, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0543, recon=0.0543, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0447, recon=0.0447, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0545, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0478\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0648, recon=0.0648, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0679, recon=0.0679, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0842, recon=0.0842, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0343, recon=0.0343, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0378, recon=0.0378, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0255, recon=0.0255, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0444, recon=0.0444, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0470, recon=0.0470, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0513, recon=0.0513, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0533, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0465\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.2276, recon=0.2276, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0501, recon=0.0501, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0393, recon=0.0393, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0327, recon=0.0327, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.1738, recon=0.1738, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0373, recon=0.0373, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0326, recon=0.0326, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0469, recon=0.0469, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0322, recon=0.0322, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0522 (Recon: 0.0522, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0455\n",
      "\n",
      "[VRAE Run 92/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2931, recon=0.2931, kl=16.0002, beta=0.0000\n",
      "Batch 40, loss=0.1322, recon=0.1322, kl=29.0272, beta=0.0000\n",
      "Batch 60, loss=0.1090, recon=0.1090, kl=35.0825, beta=0.0000\n",
      "Batch 80, loss=0.1348, recon=0.1348, kl=37.8615, beta=0.0000\n",
      "Batch 100, loss=0.1029, recon=0.1029, kl=40.0010, beta=0.0000\n",
      "Batch 120, loss=0.0873, recon=0.0873, kl=41.9510, beta=0.0000\n",
      "Batch 140, loss=0.0604, recon=0.0604, kl=42.7630, beta=0.0000\n",
      "Batch 160, loss=2.1709, recon=2.1709, kl=41.7754, beta=0.0000\n",
      "Batch 180, loss=0.1280, recon=0.1280, kl=44.2732, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1628 (Recon: 0.1628, KL: 34.0691, Current Beta: 0.0000) | Avg Valid Loss: 0.0925 | Avg Valid recon Loss: 0.0925\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0407, recon=0.0407, kl=45.1599, beta=0.0000\n",
      "Batch 40, loss=0.0523, recon=0.0523, kl=46.6535, beta=0.0000\n",
      "Batch 60, loss=0.1084, recon=0.1084, kl=45.5439, beta=0.0000\n",
      "Batch 80, loss=0.0556, recon=0.0556, kl=44.5402, beta=0.0000\n",
      "Batch 100, loss=0.0518, recon=0.0518, kl=46.0116, beta=0.0000\n",
      "Batch 120, loss=0.0643, recon=0.0643, kl=45.9398, beta=0.0000\n",
      "Batch 140, loss=0.0490, recon=0.0490, kl=45.0205, beta=0.0000\n",
      "Batch 160, loss=0.0379, recon=0.0379, kl=44.4629, beta=0.0000\n",
      "Batch 180, loss=0.0580, recon=0.0580, kl=44.9433, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0762 (Recon: 0.0762, KL: 45.3929, Current Beta: 0.0000) | Avg Valid Loss: 0.0588 | Avg Valid recon Loss: 0.0588\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0440, recon=0.0440, kl=44.2884, beta=0.0000\n",
      "Batch 40, loss=0.0850, recon=0.0850, kl=41.8359, beta=0.0000\n",
      "Batch 60, loss=0.0326, recon=0.0326, kl=41.5267, beta=0.0000\n",
      "Batch 80, loss=0.0843, recon=0.0843, kl=41.1379, beta=0.0000\n",
      "Batch 100, loss=0.0417, recon=0.0417, kl=38.9942, beta=0.0000\n",
      "Batch 120, loss=0.0528, recon=0.0528, kl=39.2582, beta=0.0000\n",
      "Batch 140, loss=0.0353, recon=0.0353, kl=39.2066, beta=0.0000\n",
      "Batch 160, loss=0.0476, recon=0.0476, kl=38.8437, beta=0.0000\n",
      "Batch 180, loss=0.0571, recon=0.0571, kl=39.6228, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0640 (Recon: 0.0640, KL: 40.6624, Current Beta: 0.0000) | Avg Valid Loss: 0.0518 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.2399, recon=0.2399, kl=34.6082, beta=0.0000\n",
      "Batch 40, loss=0.0647, recon=0.0647, kl=32.7715, beta=0.0000\n",
      "Batch 60, loss=0.0697, recon=0.0696, kl=31.6632, beta=0.0000\n",
      "Batch 80, loss=0.0615, recon=0.0615, kl=33.3168, beta=0.0000\n",
      "Batch 100, loss=0.0369, recon=0.0368, kl=30.7341, beta=0.0000\n",
      "Batch 120, loss=0.0537, recon=0.0537, kl=31.8020, beta=0.0000\n",
      "Batch 140, loss=0.0822, recon=0.0821, kl=28.2150, beta=0.0000\n",
      "Batch 160, loss=0.0250, recon=0.0250, kl=27.9015, beta=0.0000\n",
      "Batch 180, loss=0.0427, recon=0.0427, kl=31.2509, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0614 (Recon: 0.0614, KL: 31.7791, Current Beta: 0.0000) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0466\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0556, recon=0.0556, kl=25.6856, beta=0.0000\n",
      "Batch 40, loss=0.0429, recon=0.0428, kl=20.9162, beta=0.0000\n",
      "Batch 60, loss=0.0472, recon=0.0472, kl=23.2631, beta=0.0000\n",
      "Batch 80, loss=0.0371, recon=0.0371, kl=21.8832, beta=0.0000\n",
      "Batch 100, loss=0.0335, recon=0.0335, kl=18.8982, beta=0.0000\n",
      "Batch 120, loss=0.0367, recon=0.0367, kl=24.1348, beta=0.0000\n",
      "Batch 140, loss=0.0407, recon=0.0407, kl=26.6270, beta=0.0000\n",
      "Batch 160, loss=0.0461, recon=0.0461, kl=24.1611, beta=0.0000\n",
      "Batch 180, loss=0.0749, recon=0.0749, kl=22.5751, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0540, KL: 23.4992, Current Beta: 0.0000) | Avg Valid Loss: 0.0594 | Avg Valid recon Loss: 0.0593\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0265, recon=0.0264, kl=17.9992, beta=0.0000\n",
      "Batch 40, loss=0.0398, recon=0.0397, kl=14.1208, beta=0.0000\n",
      "Batch 60, loss=0.0400, recon=0.0399, kl=13.5821, beta=0.0000\n",
      "Batch 80, loss=0.0541, recon=0.0541, kl=17.5571, beta=0.0000\n",
      "Batch 100, loss=0.0313, recon=0.0313, kl=16.1131, beta=0.0000\n",
      "Batch 120, loss=0.0318, recon=0.0317, kl=16.5851, beta=0.0000\n",
      "Batch 140, loss=0.0555, recon=0.0555, kl=16.1696, beta=0.0000\n",
      "Batch 160, loss=0.0440, recon=0.0440, kl=13.9341, beta=0.0000\n",
      "Batch 180, loss=0.0687, recon=0.0687, kl=14.5921, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0549 (Recon: 0.0549, KL: 15.9324, Current Beta: 0.0000) | Avg Valid Loss: 0.0461 | Avg Valid recon Loss: 0.0460\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0369, recon=0.0368, kl=9.3200, beta=0.0000\n",
      "Batch 40, loss=0.0283, recon=0.0283, kl=7.2234, beta=0.0000\n",
      "Batch 60, loss=0.0315, recon=0.0314, kl=6.5284, beta=0.0000\n",
      "Batch 80, loss=0.0281, recon=0.0281, kl=7.2347, beta=0.0000\n",
      "Batch 100, loss=0.0443, recon=0.0442, kl=6.2889, beta=0.0000\n",
      "Batch 120, loss=0.0286, recon=0.0285, kl=5.7317, beta=0.0000\n",
      "Batch 140, loss=0.0256, recon=0.0255, kl=8.0107, beta=0.0000\n",
      "Batch 160, loss=0.0389, recon=0.0389, kl=9.0076, beta=0.0000\n",
      "Batch 180, loss=0.0426, recon=0.0426, kl=6.3776, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0488 (Recon: 0.0488, KL: 7.6683, Current Beta: 0.0000) | Avg Valid Loss: 0.0586 | Avg Valid recon Loss: 0.0586\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0329, recon=0.0329, kl=2.6346, beta=0.0000\n",
      "Batch 40, loss=0.0266, recon=0.0265, kl=3.6105, beta=0.0000\n",
      "Batch 60, loss=0.0782, recon=0.0781, kl=2.4722, beta=0.0000\n",
      "Batch 80, loss=0.0363, recon=0.0362, kl=3.5203, beta=0.0000\n",
      "Batch 100, loss=0.0285, recon=0.0284, kl=4.7707, beta=0.0000\n",
      "Batch 120, loss=0.0608, recon=0.0608, kl=3.0354, beta=0.0000\n",
      "Batch 140, loss=0.0338, recon=0.0338, kl=3.5493, beta=0.0000\n",
      "Batch 160, loss=0.0508, recon=0.0507, kl=2.7297, beta=0.0000\n",
      "Batch 180, loss=0.0281, recon=0.0280, kl=2.0406, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0521 (Recon: 0.0520, KL: 3.3885, Current Beta: 0.0000) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0449\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0440, recon=0.0440, kl=0.5078, beta=0.0000\n",
      "Batch 40, loss=0.0304, recon=0.0304, kl=0.4957, beta=0.0000\n",
      "Batch 60, loss=0.0335, recon=0.0334, kl=1.9064, beta=0.0000\n",
      "Batch 80, loss=0.0233, recon=0.0233, kl=0.7667, beta=0.0000\n",
      "Batch 100, loss=0.0433, recon=0.0433, kl=0.4635, beta=0.0000\n",
      "Batch 120, loss=0.0750, recon=0.0750, kl=0.3338, beta=0.0000\n",
      "Batch 140, loss=0.0359, recon=0.0359, kl=0.7909, beta=0.0000\n",
      "Batch 160, loss=0.0329, recon=0.0329, kl=0.4234, beta=0.0000\n",
      "Batch 180, loss=0.0525, recon=0.0525, kl=0.2212, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0468, KL: 0.7504, Current Beta: 0.0000) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0300, recon=0.0300, kl=0.0458, beta=0.0001\n",
      "Batch 40, loss=0.0370, recon=0.0370, kl=0.0635, beta=0.0001\n",
      "Batch 60, loss=0.0394, recon=0.0394, kl=0.0148, beta=0.0001\n",
      "Batch 80, loss=0.0258, recon=0.0258, kl=0.0175, beta=0.0001\n",
      "Batch 100, loss=0.0449, recon=0.0449, kl=0.0275, beta=0.0001\n",
      "Batch 120, loss=0.0385, recon=0.0385, kl=0.0247, beta=0.0001\n",
      "Batch 140, loss=0.0301, recon=0.0301, kl=0.0335, beta=0.0001\n",
      "Batch 160, loss=0.0536, recon=0.0536, kl=0.0282, beta=0.0001\n",
      "Batch 180, loss=0.0350, recon=0.0350, kl=0.0477, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 0.0401, Current Beta: 0.0001) | Avg Valid Loss: 0.0424 | Avg Valid recon Loss: 0.0424\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0496, recon=0.0496, kl=0.0027, beta=0.0003\n",
      "Batch 40, loss=0.0386, recon=0.0386, kl=0.0098, beta=0.0003\n",
      "Batch 60, loss=0.0243, recon=0.0243, kl=0.0021, beta=0.0003\n",
      "Batch 80, loss=0.0431, recon=0.0431, kl=0.0018, beta=0.0003\n",
      "Batch 100, loss=0.0293, recon=0.0293, kl=0.0023, beta=0.0003\n",
      "Batch 120, loss=0.0394, recon=0.0394, kl=0.0065, beta=0.0003\n",
      "Batch 140, loss=0.0276, recon=0.0276, kl=0.0317, beta=0.0003\n",
      "Batch 160, loss=0.0548, recon=0.0548, kl=0.0027, beta=0.0003\n",
      "Batch 180, loss=0.0349, recon=0.0348, kl=0.0925, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0431, KL: 0.0147, Current Beta: 0.0003) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0270, recon=0.0270, kl=0.0470, beta=0.0008\n",
      "Batch 40, loss=0.0302, recon=0.0301, kl=0.0088, beta=0.0008\n",
      "Batch 60, loss=0.1323, recon=0.1323, kl=0.0022, beta=0.0008\n",
      "Batch 80, loss=0.0392, recon=0.0392, kl=0.0018, beta=0.0008\n",
      "Batch 100, loss=0.0362, recon=0.0362, kl=0.0015, beta=0.0008\n",
      "Batch 120, loss=0.0312, recon=0.0312, kl=0.0008, beta=0.0008\n",
      "Batch 140, loss=0.0544, recon=0.0544, kl=0.0004, beta=0.0008\n",
      "Batch 160, loss=0.0535, recon=0.0535, kl=0.0008, beta=0.0008\n",
      "Batch 180, loss=0.0762, recon=0.0762, kl=0.0016, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0446, KL: 0.0146, Current Beta: 0.0008) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=0.0003, beta=0.0018\n",
      "Batch 40, loss=0.0702, recon=0.0702, kl=0.0003, beta=0.0018\n",
      "Batch 60, loss=0.0435, recon=0.0435, kl=0.0002, beta=0.0018\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=0.0003, beta=0.0018\n",
      "Batch 100, loss=0.1274, recon=0.1274, kl=0.0001, beta=0.0018\n",
      "Batch 120, loss=0.0282, recon=0.0282, kl=0.0001, beta=0.0018\n",
      "Batch 140, loss=0.0399, recon=0.0399, kl=0.0010, beta=0.0018\n",
      "Batch 160, loss=0.0401, recon=0.0401, kl=0.0004, beta=0.0018\n",
      "Batch 180, loss=0.0528, recon=0.0528, kl=0.0007, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0451 (Recon: 0.0451, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0605 | Avg Valid recon Loss: 0.0604\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0563, recon=0.0563, kl=0.0003, beta=0.0038\n",
      "Batch 40, loss=0.0249, recon=0.0249, kl=0.0003, beta=0.0038\n",
      "Batch 60, loss=0.0575, recon=0.0575, kl=0.0000, beta=0.0038\n",
      "Batch 80, loss=0.1274, recon=0.1274, kl=0.0002, beta=0.0038\n",
      "Batch 100, loss=0.0278, recon=0.0278, kl=0.0007, beta=0.0038\n",
      "Batch 120, loss=0.0690, recon=0.0690, kl=0.0001, beta=0.0038\n",
      "Batch 140, loss=0.0359, recon=0.0359, kl=0.0001, beta=0.0038\n",
      "Batch 160, loss=0.0515, recon=0.0515, kl=0.0004, beta=0.0038\n",
      "Batch 180, loss=0.0366, recon=0.0366, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0512 (Recon: 0.0511, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.0491 | Avg Valid recon Loss: 0.0491\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0475, recon=0.0475, kl=0.0000, beta=0.0062\n",
      "Batch 40, loss=0.0511, recon=0.0511, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0484, recon=0.0484, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0342, recon=0.0342, kl=0.0000, beta=0.0062\n",
      "Batch 100, loss=0.0691, recon=0.0691, kl=0.0000, beta=0.0062\n",
      "Batch 120, loss=0.0377, recon=0.0377, kl=0.0001, beta=0.0062\n",
      "Batch 140, loss=0.0321, recon=0.0321, kl=0.0011, beta=0.0062\n",
      "Batch 160, loss=0.0566, recon=0.0566, kl=0.0005, beta=0.0062\n",
      "Batch 180, loss=0.0468, recon=0.0468, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0521 (Recon: 0.0521, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0503 | Avg Valid recon Loss: 0.0503\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0667, recon=0.0667, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0286, recon=0.0286, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0382, recon=0.0382, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0458, recon=0.0458, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0274, recon=0.0274, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0303, recon=0.0303, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0467, recon=0.0467, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0224, recon=0.0224, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0368, recon=0.0368, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0445 (Recon: 0.0445, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0484 | Avg Valid recon Loss: 0.0484\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0413, recon=0.0413, kl=0.0019, beta=0.0100\n",
      "Batch 40, loss=0.0326, recon=0.0326, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0384, recon=0.0384, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0312, recon=0.0312, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.1071, recon=0.1071, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0305, recon=0.0305, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0650, recon=0.0650, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0440, recon=0.0440, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0244, recon=0.0244, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0465 (Recon: 0.0465, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0360 | Avg Valid recon Loss: 0.0360\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0253, recon=0.0253, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0353, recon=0.0353, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.1077, recon=0.1077, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0480, recon=0.0480, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0608, recon=0.0608, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0305, recon=0.0305, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0562, recon=0.0562, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0389, recon=0.0389, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0277, recon=0.0277, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0332, recon=0.0332, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0512, recon=0.0512, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0315, recon=0.0315, kl=0.0004, beta=0.0100\n",
      "Batch 80, loss=0.0621, recon=0.0621, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0644, recon=0.0644, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0434, recon=0.0434, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0326, recon=0.0326, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0381, recon=0.0381, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0344, recon=0.0344, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0440, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0195, recon=0.0195, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0209, recon=0.0209, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0489, recon=0.0489, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0361, recon=0.0361, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0290, recon=0.0290, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0847, recon=0.0847, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0302, recon=0.0302, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0405, recon=0.0405, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0472, recon=0.0472, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0420, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0353\n",
      "\n",
      "[VRAE Run 93/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6818, recon=0.6818, kl=0.4368, beta=0.0000\n",
      "Batch 40, loss=0.5947, recon=0.5947, kl=2.6791, beta=0.0000\n",
      "Batch 60, loss=0.4260, recon=0.4260, kl=14.7960, beta=0.0000\n",
      "Batch 80, loss=0.3612, recon=0.3612, kl=25.8383, beta=0.0000\n",
      "Batch 100, loss=0.3849, recon=0.3849, kl=34.0112, beta=0.0000\n",
      "Batch 120, loss=0.2088, recon=0.2088, kl=39.8840, beta=0.0000\n",
      "Batch 140, loss=0.3789, recon=0.3789, kl=44.1516, beta=0.0000\n",
      "Batch 160, loss=0.3830, recon=0.3830, kl=48.0950, beta=0.0000\n",
      "Batch 180, loss=0.2860, recon=0.2860, kl=52.3924, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4371 (Recon: 0.4371, KL: 26.5313, Current Beta: 0.0000) | Avg Valid Loss: 0.2218 | Avg Valid recon Loss: 0.2218\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1980, recon=0.1979, kl=55.2156, beta=0.0000\n",
      "Batch 40, loss=0.1756, recon=0.1756, kl=56.4722, beta=0.0000\n",
      "Batch 60, loss=0.2529, recon=0.2529, kl=58.4861, beta=0.0000\n",
      "Batch 80, loss=0.1297, recon=0.1297, kl=59.6627, beta=0.0000\n",
      "Batch 100, loss=0.1551, recon=0.1551, kl=61.0342, beta=0.0000\n",
      "Batch 120, loss=0.1626, recon=0.1626, kl=61.9779, beta=0.0000\n",
      "Batch 140, loss=0.1168, recon=0.1168, kl=63.4880, beta=0.0000\n",
      "Batch 160, loss=0.2213, recon=0.2213, kl=64.4472, beta=0.0000\n",
      "Batch 180, loss=0.1258, recon=0.1258, kl=66.8621, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1912 (Recon: 0.1912, KL: 60.1486, Current Beta: 0.0000) | Avg Valid Loss: 0.1414 | Avg Valid recon Loss: 0.1414\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1030, recon=0.1030, kl=67.2669, beta=0.0000\n",
      "Batch 40, loss=0.1353, recon=0.1353, kl=68.7447, beta=0.0000\n",
      "Batch 60, loss=0.0833, recon=0.0833, kl=70.0417, beta=0.0000\n",
      "Batch 80, loss=0.0998, recon=0.0997, kl=70.9121, beta=0.0000\n",
      "Batch 100, loss=0.1537, recon=0.1537, kl=70.6232, beta=0.0000\n",
      "Batch 120, loss=0.0779, recon=0.0779, kl=72.5595, beta=0.0000\n",
      "Batch 140, loss=0.1211, recon=0.1211, kl=72.8532, beta=0.0000\n",
      "Batch 160, loss=0.1157, recon=0.1157, kl=72.3365, beta=0.0000\n",
      "Batch 180, loss=0.0630, recon=0.0630, kl=73.3730, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1379 (Recon: 0.1379, KL: 70.6363, Current Beta: 0.0000) | Avg Valid Loss: 0.1124 | Avg Valid recon Loss: 0.1124\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0823, recon=0.0823, kl=71.8348, beta=0.0000\n",
      "Batch 40, loss=0.0961, recon=0.0961, kl=71.2181, beta=0.0000\n",
      "Batch 60, loss=0.1363, recon=0.1363, kl=70.3502, beta=0.0000\n",
      "Batch 80, loss=0.1767, recon=0.1767, kl=70.4605, beta=0.0000\n",
      "Batch 100, loss=0.0757, recon=0.0757, kl=70.1925, beta=0.0000\n",
      "Batch 120, loss=0.0757, recon=0.0757, kl=69.8506, beta=0.0000\n",
      "Batch 140, loss=0.0849, recon=0.0849, kl=69.0472, beta=0.0000\n",
      "Batch 160, loss=0.0651, recon=0.0651, kl=68.6273, beta=0.0000\n",
      "Batch 180, loss=0.0493, recon=0.0493, kl=68.2391, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1120 (Recon: 0.1120, KL: 70.1709, Current Beta: 0.0000) | Avg Valid Loss: 0.0946 | Avg Valid recon Loss: 0.0946\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1164, recon=0.1163, kl=67.0327, beta=0.0000\n",
      "Batch 40, loss=0.0579, recon=0.0578, kl=62.9912, beta=0.0000\n",
      "Batch 60, loss=0.1128, recon=0.1127, kl=58.8958, beta=0.0000\n",
      "Batch 80, loss=0.0871, recon=0.0870, kl=55.1532, beta=0.0000\n",
      "Batch 100, loss=0.0766, recon=0.0766, kl=53.6532, beta=0.0000\n",
      "Batch 120, loss=0.0814, recon=0.0814, kl=53.2708, beta=0.0000\n",
      "Batch 140, loss=0.0557, recon=0.0556, kl=51.7450, beta=0.0000\n",
      "Batch 160, loss=0.0650, recon=0.0650, kl=50.8906, beta=0.0000\n",
      "Batch 180, loss=0.0932, recon=0.0932, kl=48.2994, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0971 (Recon: 0.0971, KL: 56.7209, Current Beta: 0.0000) | Avg Valid Loss: 0.0836 | Avg Valid recon Loss: 0.0836\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0791, recon=0.0790, kl=43.6553, beta=0.0000\n",
      "Batch 40, loss=0.0843, recon=0.0843, kl=35.0832, beta=0.0000\n",
      "Batch 60, loss=0.0527, recon=0.0526, kl=30.3908, beta=0.0000\n",
      "Batch 80, loss=0.0745, recon=0.0744, kl=29.8381, beta=0.0000\n",
      "Batch 100, loss=0.0895, recon=0.0894, kl=30.5055, beta=0.0000\n",
      "Batch 120, loss=0.0704, recon=0.0703, kl=28.7897, beta=0.0000\n",
      "Batch 140, loss=0.0842, recon=0.0842, kl=27.5221, beta=0.0000\n",
      "Batch 160, loss=0.0857, recon=0.0856, kl=25.7889, beta=0.0000\n",
      "Batch 180, loss=0.0587, recon=0.0586, kl=26.7933, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0876 (Recon: 0.0875, KL: 32.2133, Current Beta: 0.0000) | Avg Valid Loss: 0.0774 | Avg Valid recon Loss: 0.0773\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0646, recon=0.0645, kl=17.5723, beta=0.0000\n",
      "Batch 40, loss=0.0728, recon=0.0727, kl=15.8666, beta=0.0000\n",
      "Batch 60, loss=0.0364, recon=0.0363, kl=14.5309, beta=0.0000\n",
      "Batch 80, loss=0.0435, recon=0.0434, kl=14.2696, beta=0.0000\n",
      "Batch 100, loss=0.0790, recon=0.0789, kl=13.5106, beta=0.0000\n",
      "Batch 120, loss=0.1115, recon=0.1114, kl=12.9217, beta=0.0000\n",
      "Batch 140, loss=0.0625, recon=0.0624, kl=12.1755, beta=0.0000\n",
      "Batch 160, loss=0.0675, recon=0.0674, kl=11.4943, beta=0.0000\n",
      "Batch 180, loss=0.0516, recon=0.0515, kl=11.9887, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0812 (Recon: 0.0811, KL: 14.5539, Current Beta: 0.0000) | Avg Valid Loss: 0.0726 | Avg Valid recon Loss: 0.0725\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0433, recon=0.0432, kl=7.2484, beta=0.0000\n",
      "Batch 40, loss=0.0701, recon=0.0700, kl=5.8606, beta=0.0000\n",
      "Batch 60, loss=0.0475, recon=0.0474, kl=5.3589, beta=0.0000\n",
      "Batch 80, loss=0.0605, recon=0.0604, kl=5.2293, beta=0.0000\n",
      "Batch 100, loss=0.0452, recon=0.0452, kl=5.4718, beta=0.0000\n",
      "Batch 120, loss=0.0350, recon=0.0349, kl=4.1686, beta=0.0000\n",
      "Batch 140, loss=0.0834, recon=0.0833, kl=4.2888, beta=0.0000\n",
      "Batch 160, loss=0.0626, recon=0.0626, kl=4.6340, beta=0.0000\n",
      "Batch 180, loss=0.0575, recon=0.0575, kl=3.7177, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0761 (Recon: 0.0760, KL: 5.4724, Current Beta: 0.0000) | Avg Valid Loss: 0.0677 | Avg Valid recon Loss: 0.0676\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0555, recon=0.0554, kl=2.4769, beta=0.0000\n",
      "Batch 40, loss=0.0378, recon=0.0377, kl=1.7700, beta=0.0000\n",
      "Batch 60, loss=0.0531, recon=0.0530, kl=1.2928, beta=0.0000\n",
      "Batch 80, loss=0.0544, recon=0.0544, kl=1.5489, beta=0.0000\n",
      "Batch 100, loss=0.0761, recon=0.0761, kl=1.4457, beta=0.0000\n",
      "Batch 120, loss=0.0443, recon=0.0442, kl=1.4093, beta=0.0000\n",
      "Batch 140, loss=0.0365, recon=0.0365, kl=1.0727, beta=0.0000\n",
      "Batch 160, loss=0.0448, recon=0.0448, kl=1.2243, beta=0.0000\n",
      "Batch 180, loss=0.0403, recon=0.0402, kl=1.0861, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0723 (Recon: 0.0723, KL: 1.5284, Current Beta: 0.0000) | Avg Valid Loss: 0.0645 | Avg Valid recon Loss: 0.0645\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0596, recon=0.0595, kl=0.4606, beta=0.0001\n",
      "Batch 40, loss=0.0645, recon=0.0645, kl=0.3711, beta=0.0001\n",
      "Batch 60, loss=0.0769, recon=0.0769, kl=0.3073, beta=0.0001\n",
      "Batch 80, loss=0.0600, recon=0.0600, kl=0.2447, beta=0.0001\n",
      "Batch 100, loss=0.0485, recon=0.0485, kl=0.1895, beta=0.0001\n",
      "Batch 120, loss=0.1012, recon=0.1012, kl=0.1382, beta=0.0001\n",
      "Batch 140, loss=0.0379, recon=0.0379, kl=0.1310, beta=0.0001\n",
      "Batch 160, loss=0.2316, recon=0.2316, kl=0.1023, beta=0.0001\n",
      "Batch 180, loss=0.0525, recon=0.0524, kl=0.0882, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0693 (Recon: 0.0692, KL: 0.2614, Current Beta: 0.0001) | Avg Valid Loss: 0.0622 | Avg Valid recon Loss: 0.0622\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0405, recon=0.0405, kl=0.0249, beta=0.0003\n",
      "Batch 40, loss=0.0436, recon=0.0436, kl=0.0102, beta=0.0003\n",
      "Batch 60, loss=0.0978, recon=0.0978, kl=0.0143, beta=0.0003\n",
      "Batch 80, loss=0.0661, recon=0.0661, kl=0.0154, beta=0.0003\n",
      "Batch 100, loss=0.0472, recon=0.0472, kl=0.0101, beta=0.0003\n",
      "Batch 120, loss=0.0347, recon=0.0347, kl=0.0078, beta=0.0003\n",
      "Batch 140, loss=0.0536, recon=0.0536, kl=0.0083, beta=0.0003\n",
      "Batch 160, loss=0.0615, recon=0.0615, kl=0.0047, beta=0.0003\n",
      "Batch 180, loss=0.0367, recon=0.0367, kl=0.0041, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0667 (Recon: 0.0667, KL: 0.0149, Current Beta: 0.0003) | Avg Valid Loss: 0.0600 | Avg Valid recon Loss: 0.0600\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0428, recon=0.0428, kl=0.0014, beta=0.0008\n",
      "Batch 40, loss=0.0358, recon=0.0358, kl=0.0006, beta=0.0008\n",
      "Batch 60, loss=0.0575, recon=0.0575, kl=0.0008, beta=0.0008\n",
      "Batch 80, loss=0.2556, recon=0.2556, kl=0.0010, beta=0.0008\n",
      "Batch 100, loss=0.0541, recon=0.0541, kl=0.0009, beta=0.0008\n",
      "Batch 120, loss=0.0640, recon=0.0640, kl=0.0005, beta=0.0008\n",
      "Batch 140, loss=0.0823, recon=0.0823, kl=0.0007, beta=0.0008\n",
      "Batch 160, loss=0.0343, recon=0.0343, kl=0.0005, beta=0.0008\n",
      "Batch 180, loss=0.0752, recon=0.0752, kl=0.0005, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0646 (Recon: 0.0646, KL: 0.0010, Current Beta: 0.0008) | Avg Valid Loss: 0.0573 | Avg Valid recon Loss: 0.0573\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0969, recon=0.0969, kl=0.0003, beta=0.0018\n",
      "Batch 40, loss=0.0477, recon=0.0477, kl=0.0001, beta=0.0018\n",
      "Batch 60, loss=0.0591, recon=0.0591, kl=0.0001, beta=0.0018\n",
      "Batch 80, loss=0.0465, recon=0.0465, kl=0.0002, beta=0.0018\n",
      "Batch 100, loss=0.0433, recon=0.0433, kl=0.0002, beta=0.0018\n",
      "Batch 120, loss=0.0333, recon=0.0333, kl=0.0001, beta=0.0018\n",
      "Batch 140, loss=0.0294, recon=0.0294, kl=0.0001, beta=0.0018\n",
      "Batch 160, loss=0.0314, recon=0.0314, kl=0.0004, beta=0.0018\n",
      "Batch 180, loss=0.0439, recon=0.0439, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0623 (Recon: 0.0623, KL: 0.0002, Current Beta: 0.0018) | Avg Valid Loss: 0.0555 | Avg Valid recon Loss: 0.0555\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0833, recon=0.0833, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0502, recon=0.0502, kl=0.0000, beta=0.0038\n",
      "Batch 60, loss=0.0461, recon=0.0461, kl=0.0000, beta=0.0038\n",
      "Batch 80, loss=0.0448, recon=0.0448, kl=0.0000, beta=0.0038\n",
      "Batch 100, loss=0.0379, recon=0.0379, kl=0.0000, beta=0.0038\n",
      "Batch 120, loss=0.0466, recon=0.0466, kl=0.0002, beta=0.0038\n",
      "Batch 140, loss=0.0438, recon=0.0438, kl=0.0001, beta=0.0038\n",
      "Batch 160, loss=0.0458, recon=0.0458, kl=0.0001, beta=0.0038\n",
      "Batch 180, loss=0.0409, recon=0.0409, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0607 (Recon: 0.0607, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0539 | Avg Valid recon Loss: 0.0539\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0443, recon=0.0443, kl=0.0000, beta=0.0062\n",
      "Batch 40, loss=0.0509, recon=0.0509, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0980, recon=0.0980, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0536, recon=0.0536, kl=0.0000, beta=0.0062\n",
      "Batch 100, loss=0.0323, recon=0.0323, kl=0.0001, beta=0.0062\n",
      "Batch 120, loss=0.0440, recon=0.0440, kl=0.0000, beta=0.0062\n",
      "Batch 140, loss=0.0394, recon=0.0393, kl=0.0001, beta=0.0062\n",
      "Batch 160, loss=0.0376, recon=0.0376, kl=0.0000, beta=0.0062\n",
      "Batch 180, loss=0.0359, recon=0.0359, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0593 (Recon: 0.0593, KL: 0.0000, Current Beta: 0.0062) | Avg Valid Loss: 0.0526 | Avg Valid recon Loss: 0.0526\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1650, recon=0.1650, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0565, recon=0.0565, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0313, recon=0.0313, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0827, recon=0.0827, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0531, recon=0.0531, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0952, recon=0.0952, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0731, recon=0.0731, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0276, recon=0.0276, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0413, recon=0.0413, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0511 | Avg Valid recon Loss: 0.0511\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0295, recon=0.0295, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0418, recon=0.0418, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0411, recon=0.0411, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0327, recon=0.0327, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0428, recon=0.0428, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0554, recon=0.0554, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0356, recon=0.0356, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0534, recon=0.0534, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0565 (Recon: 0.0565, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0504 | Avg Valid recon Loss: 0.0504\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0294, recon=0.0294, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0518, recon=0.0518, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0589, recon=0.0589, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0766, recon=0.0766, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0540, recon=0.0540, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0608, recon=0.0608, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0429, recon=0.0429, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.2269, recon=0.2269, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0298, recon=0.0298, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0555, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0494 | Avg Valid recon Loss: 0.0494\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0285, recon=0.0285, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0304, recon=0.0304, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0406, recon=0.0406, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0281, recon=0.0281, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.9531, recon=0.9531, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0303, recon=0.0303, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0426, recon=0.0426, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0269, recon=0.0269, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0406, recon=0.0406, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0543 (Recon: 0.0543, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0480\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0440, recon=0.0440, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.2171, recon=0.2171, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0386, recon=0.0386, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0331, recon=0.0331, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0282, recon=0.0282, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0350, recon=0.0350, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0986, recon=0.0986, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0261, recon=0.0261, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0438, recon=0.0438, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0534, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0471 | Avg Valid recon Loss: 0.0471\n",
      "\n",
      "[VRAE Run 94/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2601, recon=0.2601, kl=36.5072, beta=0.0000\n",
      "Batch 40, loss=0.1998, recon=0.1998, kl=47.6242, beta=0.0000\n",
      "Batch 60, loss=0.1812, recon=0.1812, kl=55.4047, beta=0.0000\n",
      "Batch 80, loss=0.1378, recon=0.1378, kl=55.0013, beta=0.0000\n",
      "Batch 100, loss=0.0819, recon=0.0819, kl=59.2888, beta=0.0000\n",
      "Batch 120, loss=0.1297, recon=0.1297, kl=58.0255, beta=0.0000\n",
      "Batch 140, loss=0.1100, recon=0.1100, kl=61.3973, beta=0.0000\n",
      "Batch 160, loss=0.0476, recon=0.0476, kl=67.1270, beta=0.0000\n",
      "Batch 180, loss=0.0919, recon=0.0919, kl=63.9782, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1713 (Recon: 0.1713, KL: 52.2458, Current Beta: 0.0000) | Avg Valid Loss: 0.0798 | Avg Valid recon Loss: 0.0798\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0532, recon=0.0532, kl=65.8798, beta=0.0000\n",
      "Batch 40, loss=0.0480, recon=0.0480, kl=64.6478, beta=0.0000\n",
      "Batch 60, loss=0.0450, recon=0.0449, kl=61.5208, beta=0.0000\n",
      "Batch 80, loss=0.0539, recon=0.0539, kl=63.8546, beta=0.0000\n",
      "Batch 100, loss=0.0557, recon=0.0557, kl=59.8707, beta=0.0000\n",
      "Batch 120, loss=0.0646, recon=0.0646, kl=63.2535, beta=0.0000\n",
      "Batch 140, loss=0.0721, recon=0.0721, kl=67.7896, beta=0.0000\n",
      "Batch 160, loss=0.0976, recon=0.0976, kl=62.4954, beta=0.0000\n",
      "Batch 180, loss=0.0514, recon=0.0514, kl=65.3498, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0782 (Recon: 0.0782, KL: 63.9897, Current Beta: 0.0000) | Avg Valid Loss: 0.0586 | Avg Valid recon Loss: 0.0586\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0378, recon=0.0378, kl=56.4413, beta=0.0000\n",
      "Batch 40, loss=0.0794, recon=0.0794, kl=47.8952, beta=0.0000\n",
      "Batch 60, loss=0.0419, recon=0.0418, kl=52.0960, beta=0.0000\n",
      "Batch 80, loss=0.1014, recon=0.1014, kl=56.3733, beta=0.0000\n",
      "Batch 100, loss=0.0294, recon=0.0294, kl=58.7330, beta=0.0000\n",
      "Batch 120, loss=0.0392, recon=0.0392, kl=59.2758, beta=0.0000\n",
      "Batch 140, loss=0.0731, recon=0.0731, kl=54.0173, beta=0.0000\n",
      "Batch 160, loss=0.0534, recon=0.0534, kl=55.8569, beta=0.0000\n",
      "Batch 180, loss=0.0539, recon=0.0539, kl=60.4676, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0624 (Recon: 0.0624, KL: 56.1049, Current Beta: 0.0000) | Avg Valid Loss: 0.0660 | Avg Valid recon Loss: 0.0660\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0334, recon=0.0334, kl=58.9347, beta=0.0000\n",
      "Batch 40, loss=0.0314, recon=0.0314, kl=54.5931, beta=0.0000\n",
      "Batch 60, loss=0.0345, recon=0.0345, kl=53.4960, beta=0.0000\n",
      "Batch 80, loss=0.0392, recon=0.0392, kl=49.8742, beta=0.0000\n",
      "Batch 100, loss=0.0350, recon=0.0350, kl=50.7960, beta=0.0000\n",
      "Batch 120, loss=0.0469, recon=0.0469, kl=53.1488, beta=0.0000\n",
      "Batch 140, loss=0.0431, recon=0.0431, kl=55.1033, beta=0.0000\n",
      "Batch 160, loss=0.0431, recon=0.0431, kl=55.9544, beta=0.0000\n",
      "Batch 180, loss=0.0341, recon=0.0341, kl=55.1770, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0606 (Recon: 0.0606, KL: 54.2336, Current Beta: 0.0000) | Avg Valid Loss: 0.0492 | Avg Valid recon Loss: 0.0492\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0569, recon=0.0568, kl=50.6638, beta=0.0000\n",
      "Batch 40, loss=0.0346, recon=0.0346, kl=42.6085, beta=0.0000\n",
      "Batch 60, loss=0.7972, recon=0.7972, kl=41.3441, beta=0.0000\n",
      "Batch 80, loss=0.0472, recon=0.0471, kl=41.7031, beta=0.0000\n",
      "Batch 100, loss=0.0598, recon=0.0597, kl=42.0322, beta=0.0000\n",
      "Batch 120, loss=0.0536, recon=0.0536, kl=40.7356, beta=0.0000\n",
      "Batch 140, loss=0.0402, recon=0.0401, kl=40.5578, beta=0.0000\n",
      "Batch 160, loss=0.1598, recon=0.1597, kl=42.5522, beta=0.0000\n",
      "Batch 180, loss=0.0466, recon=0.0465, kl=46.7177, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0523, KL: 43.1849, Current Beta: 0.0000) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0358, recon=0.0357, kl=31.6258, beta=0.0000\n",
      "Batch 40, loss=0.0774, recon=0.0773, kl=30.6538, beta=0.0000\n",
      "Batch 60, loss=0.0468, recon=0.0467, kl=32.0690, beta=0.0000\n",
      "Batch 80, loss=0.0398, recon=0.0398, kl=27.5678, beta=0.0000\n",
      "Batch 100, loss=0.0367, recon=0.0366, kl=30.9791, beta=0.0000\n",
      "Batch 120, loss=0.0312, recon=0.0312, kl=29.9949, beta=0.0000\n",
      "Batch 140, loss=0.0365, recon=0.0365, kl=31.7581, beta=0.0000\n",
      "Batch 160, loss=0.0252, recon=0.0252, kl=31.7136, beta=0.0000\n",
      "Batch 180, loss=0.0310, recon=0.0309, kl=28.3302, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0481, KL: 31.2583, Current Beta: 0.0000) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0475, recon=0.0474, kl=16.8843, beta=0.0000\n",
      "Batch 40, loss=0.0365, recon=0.0364, kl=17.0755, beta=0.0000\n",
      "Batch 60, loss=0.0361, recon=0.0360, kl=14.7704, beta=0.0000\n",
      "Batch 80, loss=0.0411, recon=0.0411, kl=13.8499, beta=0.0000\n",
      "Batch 100, loss=0.0315, recon=0.0314, kl=13.5370, beta=0.0000\n",
      "Batch 120, loss=0.0487, recon=0.0486, kl=16.3240, beta=0.0000\n",
      "Batch 140, loss=0.0314, recon=0.0314, kl=11.2713, beta=0.0000\n",
      "Batch 160, loss=0.0321, recon=0.0320, kl=14.0387, beta=0.0000\n",
      "Batch 180, loss=0.0352, recon=0.0351, kl=16.7041, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0454, KL: 15.3505, Current Beta: 0.0000) | Avg Valid Loss: 0.0440 | Avg Valid recon Loss: 0.0439\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0466, recon=0.0465, kl=5.7998, beta=0.0000\n",
      "Batch 40, loss=0.0316, recon=0.0315, kl=6.3423, beta=0.0000\n",
      "Batch 60, loss=0.0478, recon=0.0474, kl=25.2065, beta=0.0000\n",
      "Batch 80, loss=0.0309, recon=0.0305, kl=24.6855, beta=0.0000\n",
      "Batch 100, loss=0.0461, recon=0.0458, kl=18.9250, beta=0.0000\n",
      "Batch 120, loss=0.1519, recon=0.1516, kl=15.1354, beta=0.0000\n",
      "Batch 140, loss=0.0462, recon=0.0460, kl=13.4998, beta=0.0000\n",
      "Batch 160, loss=0.0329, recon=0.0328, kl=8.9014, beta=0.0000\n",
      "Batch 180, loss=0.0529, recon=0.0528, kl=7.4795, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0491 (Recon: 0.0488, KL: 13.8960, Current Beta: 0.0000) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0386\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0394, recon=0.0393, kl=3.6718, beta=0.0000\n",
      "Batch 40, loss=0.0415, recon=0.0414, kl=2.5251, beta=0.0000\n",
      "Batch 60, loss=0.0397, recon=0.0397, kl=1.5118, beta=0.0000\n",
      "Batch 80, loss=0.0479, recon=0.0479, kl=0.8255, beta=0.0000\n",
      "Batch 100, loss=0.0537, recon=0.0536, kl=2.3137, beta=0.0000\n",
      "Batch 120, loss=0.0745, recon=0.0744, kl=1.7419, beta=0.0000\n",
      "Batch 140, loss=0.0279, recon=0.0279, kl=0.6465, beta=0.0000\n",
      "Batch 160, loss=0.0200, recon=0.0200, kl=0.6372, beta=0.0000\n",
      "Batch 180, loss=0.0254, recon=0.0254, kl=0.3925, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0469, KL: 1.8346, Current Beta: 0.0000) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0311, recon=0.0311, kl=0.1120, beta=0.0001\n",
      "Batch 40, loss=0.0432, recon=0.0432, kl=0.1107, beta=0.0001\n",
      "Batch 60, loss=0.0328, recon=0.0327, kl=0.1259, beta=0.0001\n",
      "Batch 80, loss=0.0423, recon=0.0423, kl=0.0969, beta=0.0001\n",
      "Batch 100, loss=0.0295, recon=0.0295, kl=0.0422, beta=0.0001\n",
      "Batch 120, loss=0.0360, recon=0.0360, kl=0.0308, beta=0.0001\n",
      "Batch 140, loss=0.0267, recon=0.0267, kl=0.0206, beta=0.0001\n",
      "Batch 160, loss=0.5680, recon=0.5680, kl=0.0319, beta=0.0001\n",
      "Batch 180, loss=0.0372, recon=0.0372, kl=0.1987, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0420, KL: 0.1045, Current Beta: 0.0001) | Avg Valid Loss: 0.0429 | Avg Valid recon Loss: 0.0429\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0418, recon=0.0418, kl=0.0302, beta=0.0003\n",
      "Batch 40, loss=0.0387, recon=0.0387, kl=0.0185, beta=0.0003\n",
      "Batch 60, loss=0.0309, recon=0.0308, kl=0.1217, beta=0.0003\n",
      "Batch 80, loss=0.0320, recon=0.0320, kl=0.0593, beta=0.0003\n",
      "Batch 100, loss=0.1277, recon=0.1277, kl=0.0119, beta=0.0003\n",
      "Batch 120, loss=0.0487, recon=0.0486, kl=0.0107, beta=0.0003\n",
      "Batch 140, loss=0.0304, recon=0.0304, kl=0.0035, beta=0.0003\n",
      "Batch 160, loss=0.0296, recon=0.0296, kl=0.0187, beta=0.0003\n",
      "Batch 180, loss=0.0242, recon=0.0242, kl=0.0293, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0413 (Recon: 0.0413, KL: 0.0303, Current Beta: 0.0003) | Avg Valid Loss: 0.0362 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=0.0076, beta=0.0008\n",
      "Batch 40, loss=0.0510, recon=0.0510, kl=0.0011, beta=0.0008\n",
      "Batch 60, loss=0.0597, recon=0.0597, kl=0.0040, beta=0.0008\n",
      "Batch 80, loss=0.0499, recon=0.0498, kl=0.0166, beta=0.0008\n",
      "Batch 100, loss=0.0212, recon=0.0212, kl=0.0095, beta=0.0008\n",
      "Batch 120, loss=0.0395, recon=0.0395, kl=0.0030, beta=0.0008\n",
      "Batch 140, loss=0.0409, recon=0.0409, kl=0.0075, beta=0.0008\n",
      "Batch 160, loss=0.0285, recon=0.0285, kl=0.0008, beta=0.0008\n",
      "Batch 180, loss=0.0371, recon=0.0371, kl=0.0043, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0455, KL: 0.0058, Current Beta: 0.0008) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1019, recon=0.1018, kl=0.0024, beta=0.0018\n",
      "Batch 40, loss=0.0457, recon=0.0457, kl=0.0010, beta=0.0018\n",
      "Batch 60, loss=0.0340, recon=0.0340, kl=0.0007, beta=0.0018\n",
      "Batch 80, loss=0.1125, recon=0.1125, kl=0.0057, beta=0.0018\n",
      "Batch 100, loss=0.0369, recon=0.0369, kl=0.0100, beta=0.0018\n",
      "Batch 120, loss=0.0296, recon=0.0296, kl=0.0162, beta=0.0018\n",
      "Batch 140, loss=0.0782, recon=0.0782, kl=0.0168, beta=0.0018\n",
      "Batch 160, loss=0.0596, recon=0.0596, kl=0.0075, beta=0.0018\n",
      "Batch 180, loss=0.0441, recon=0.0441, kl=0.0018, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0507, KL: 0.0066, Current Beta: 0.0018) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0496\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0783, recon=0.0783, kl=0.0003, beta=0.0038\n",
      "Batch 40, loss=0.0389, recon=0.0388, kl=0.0007, beta=0.0038\n",
      "Batch 60, loss=0.0448, recon=0.0448, kl=0.0007, beta=0.0038\n",
      "Batch 80, loss=0.0429, recon=0.0429, kl=0.0009, beta=0.0038\n",
      "Batch 100, loss=0.0329, recon=0.0329, kl=0.0004, beta=0.0038\n",
      "Batch 120, loss=0.0402, recon=0.0402, kl=0.0002, beta=0.0038\n",
      "Batch 140, loss=0.0351, recon=0.0351, kl=0.0006, beta=0.0038\n",
      "Batch 160, loss=0.0501, recon=0.0501, kl=0.0002, beta=0.0038\n",
      "Batch 180, loss=0.0654, recon=0.0654, kl=0.0005, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0537 (Recon: 0.0537, KL: 0.0005, Current Beta: 0.0038) | Avg Valid Loss: 0.0514 | Avg Valid recon Loss: 0.0514\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0686, recon=0.0685, kl=0.0099, beta=0.0062\n",
      "Batch 40, loss=0.0864, recon=0.0864, kl=0.0018, beta=0.0062\n",
      "Batch 60, loss=0.0585, recon=0.0584, kl=0.0149, beta=0.0062\n",
      "Batch 80, loss=0.0524, recon=0.0524, kl=0.0022, beta=0.0062\n",
      "Batch 100, loss=0.0389, recon=0.0389, kl=0.0005, beta=0.0062\n",
      "Batch 120, loss=0.0393, recon=0.0393, kl=0.0004, beta=0.0062\n",
      "Batch 140, loss=0.0639, recon=0.0639, kl=0.0004, beta=0.0062\n",
      "Batch 160, loss=0.0287, recon=0.0287, kl=0.0004, beta=0.0062\n",
      "Batch 180, loss=0.0284, recon=0.0284, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0620 (Recon: 0.0619, KL: 0.0020, Current Beta: 0.0062) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0587, recon=0.0587, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0489, recon=0.0489, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0440, recon=0.0440, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0424, recon=0.0424, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0286, recon=0.0286, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0485, recon=0.0485, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0239, recon=0.0239, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0298, recon=0.0298, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0645, recon=0.0645, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0463, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0359 | Avg Valid recon Loss: 0.0359\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0348, recon=0.0348, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0217, recon=0.0217, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0351, recon=0.0351, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0228, recon=0.0228, kl=0.0005, beta=0.0100\n",
      "Batch 120, loss=0.0513, recon=0.0513, kl=0.0003, beta=0.0100\n",
      "Batch 140, loss=0.0258, recon=0.0258, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0288, recon=0.0288, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0284, recon=0.0284, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0419, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0462 | Avg Valid recon Loss: 0.0461\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0537, recon=0.0537, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0451, recon=0.0451, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0396, recon=0.0396, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0280, recon=0.0280, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0306, recon=0.0306, kl=0.0004, beta=0.0100\n",
      "Batch 120, loss=0.0411, recon=0.0411, kl=0.0002, beta=0.0100\n",
      "Batch 140, loss=0.0467, recon=0.0467, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0501, recon=0.0501, kl=0.0003, beta=0.0100\n",
      "Batch 180, loss=0.0561, recon=0.0561, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0469, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0543 | Avg Valid recon Loss: 0.0543\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0251, recon=0.0251, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0281, recon=0.0281, kl=0.0008, beta=0.0100\n",
      "Batch 80, loss=0.0285, recon=0.0285, kl=0.0005, beta=0.0100\n",
      "Batch 100, loss=0.0693, recon=0.0693, kl=0.0002, beta=0.0100\n",
      "Batch 120, loss=0.0291, recon=0.0291, kl=0.0004, beta=0.0100\n",
      "Batch 140, loss=0.1940, recon=0.1940, kl=0.0013, beta=0.0100\n",
      "Batch 160, loss=0.0346, recon=0.0346, kl=0.0004, beta=0.0100\n",
      "Batch 180, loss=0.0468, recon=0.0468, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0495, KL: 0.0006, Current Beta: 0.0100) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0485, recon=0.0485, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0245, recon=0.0245, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.1424, recon=0.1424, kl=0.0003, beta=0.0100\n",
      "Batch 80, loss=0.0293, recon=0.0293, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0314, recon=0.0314, kl=0.0012, beta=0.0100\n",
      "Batch 120, loss=0.0254, recon=0.0254, kl=0.0011, beta=0.0100\n",
      "Batch 140, loss=0.0421, recon=0.0421, kl=0.0005, beta=0.0100\n",
      "Batch 160, loss=0.0620, recon=0.0620, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0320, recon=0.0319, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0414, KL: 0.0006, Current Beta: 0.0100) | Avg Valid Loss: 0.0365 | Avg Valid recon Loss: 0.0365\n",
      "\n",
      "[VRAE Run 95/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7056, recon=0.7056, kl=1.1104, beta=0.0000\n",
      "Batch 40, loss=0.5500, recon=0.5500, kl=4.0695, beta=0.0000\n",
      "Batch 60, loss=0.5340, recon=0.5340, kl=25.2289, beta=0.0000\n",
      "Batch 80, loss=0.3582, recon=0.3582, kl=50.1497, beta=0.0000\n",
      "Batch 100, loss=0.2265, recon=0.2265, kl=60.2725, beta=0.0000\n",
      "Batch 120, loss=0.2879, recon=0.2879, kl=65.8619, beta=0.0000\n",
      "Batch 140, loss=0.4526, recon=0.4526, kl=72.8815, beta=0.0000\n",
      "Batch 160, loss=0.1946, recon=0.1946, kl=79.8614, beta=0.0000\n",
      "Batch 180, loss=0.2956, recon=0.2956, kl=85.1727, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4654 (Recon: 0.4654, KL: 45.1894, Current Beta: 0.0000) | Avg Valid Loss: 0.2358 | Avg Valid recon Loss: 0.2358\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1691, recon=0.1691, kl=90.8195, beta=0.0000\n",
      "Batch 40, loss=0.1221, recon=0.1221, kl=95.0170, beta=0.0000\n",
      "Batch 60, loss=0.1326, recon=0.1326, kl=98.9929, beta=0.0000\n",
      "Batch 80, loss=2.3985, recon=2.3985, kl=101.9023, beta=0.0000\n",
      "Batch 100, loss=0.2477, recon=0.2477, kl=106.5658, beta=0.0000\n",
      "Batch 120, loss=0.1185, recon=0.1185, kl=107.2116, beta=0.0000\n",
      "Batch 140, loss=0.1407, recon=0.1407, kl=108.8950, beta=0.0000\n",
      "Batch 160, loss=0.1702, recon=0.1702, kl=110.7121, beta=0.0000\n",
      "Batch 180, loss=0.0977, recon=0.0977, kl=112.7405, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1973 (Recon: 0.1973, KL: 102.2389, Current Beta: 0.0000) | Avg Valid Loss: 0.1425 | Avg Valid recon Loss: 0.1425\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1011, recon=0.1010, kl=113.9068, beta=0.0000\n",
      "Batch 40, loss=0.1101, recon=0.1100, kl=113.4998, beta=0.0000\n",
      "Batch 60, loss=0.1662, recon=0.1661, kl=115.1620, beta=0.0000\n",
      "Batch 80, loss=0.1328, recon=0.1328, kl=116.2456, beta=0.0000\n",
      "Batch 100, loss=0.1317, recon=0.1316, kl=117.4762, beta=0.0000\n",
      "Batch 120, loss=0.1259, recon=0.1259, kl=117.7922, beta=0.0000\n",
      "Batch 140, loss=0.1060, recon=0.1060, kl=118.6686, beta=0.0000\n",
      "Batch 160, loss=0.0996, recon=0.0996, kl=119.1150, beta=0.0000\n",
      "Batch 180, loss=0.0890, recon=0.0890, kl=120.3013, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1369 (Recon: 0.1369, KL: 116.5260, Current Beta: 0.0000) | Avg Valid Loss: 0.1089 | Avg Valid recon Loss: 0.1088\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0575, recon=0.0574, kl=118.5947, beta=0.0000\n",
      "Batch 40, loss=0.0878, recon=0.0878, kl=117.9447, beta=0.0000\n",
      "Batch 60, loss=0.0933, recon=0.0932, kl=115.8796, beta=0.0000\n",
      "Batch 80, loss=0.0663, recon=0.0663, kl=113.1382, beta=0.0000\n",
      "Batch 100, loss=0.2154, recon=0.2154, kl=111.9856, beta=0.0000\n",
      "Batch 120, loss=0.0685, recon=0.0685, kl=109.4625, beta=0.0000\n",
      "Batch 140, loss=0.0718, recon=0.0718, kl=108.2097, beta=0.0000\n",
      "Batch 160, loss=0.1407, recon=0.1406, kl=107.8091, beta=0.0000\n",
      "Batch 180, loss=0.1067, recon=0.1067, kl=106.7346, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1088 (Recon: 0.1088, KL: 112.8823, Current Beta: 0.0000) | Avg Valid Loss: 0.0915 | Avg Valid recon Loss: 0.0914\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1290, recon=0.1289, kl=99.8859, beta=0.0000\n",
      "Batch 40, loss=0.0685, recon=0.0684, kl=88.3613, beta=0.0000\n",
      "Batch 60, loss=0.5033, recon=0.5033, kl=79.8997, beta=0.0000\n",
      "Batch 80, loss=0.0884, recon=0.0884, kl=75.0511, beta=0.0000\n",
      "Batch 100, loss=0.0549, recon=0.0549, kl=71.5555, beta=0.0000\n",
      "Batch 120, loss=0.0634, recon=0.0634, kl=69.3115, beta=0.0000\n",
      "Batch 140, loss=0.0616, recon=0.0616, kl=65.7943, beta=0.0000\n",
      "Batch 160, loss=0.0706, recon=0.0705, kl=64.9500, beta=0.0000\n",
      "Batch 180, loss=0.0810, recon=0.0810, kl=62.3827, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0929 (Recon: 0.0929, KL: 77.3978, Current Beta: 0.0000) | Avg Valid Loss: 0.0816 | Avg Valid recon Loss: 0.0816\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0538, recon=0.0537, kl=46.6641, beta=0.0000\n",
      "Batch 40, loss=0.0647, recon=0.0646, kl=37.3427, beta=0.0000\n",
      "Batch 60, loss=0.0486, recon=0.0485, kl=38.7891, beta=0.0000\n",
      "Batch 80, loss=0.0399, recon=0.0398, kl=37.9918, beta=0.0000\n",
      "Batch 100, loss=0.1732, recon=0.1732, kl=36.3997, beta=0.0000\n",
      "Batch 120, loss=0.0707, recon=0.0707, kl=33.8826, beta=0.0000\n",
      "Batch 140, loss=0.0702, recon=0.0701, kl=33.6102, beta=0.0000\n",
      "Batch 160, loss=0.0730, recon=0.0730, kl=30.6298, beta=0.0000\n",
      "Batch 180, loss=0.0862, recon=0.0861, kl=31.6189, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0836 (Recon: 0.0835, KL: 38.0675, Current Beta: 0.0000) | Avg Valid Loss: 0.0740 | Avg Valid recon Loss: 0.0739\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2197, recon=0.2196, kl=17.3895, beta=0.0000\n",
      "Batch 40, loss=0.1903, recon=0.1902, kl=16.1652, beta=0.0000\n",
      "Batch 60, loss=0.1356, recon=0.1355, kl=14.4835, beta=0.0000\n",
      "Batch 80, loss=0.0659, recon=0.0659, kl=13.7935, beta=0.0000\n",
      "Batch 100, loss=0.0523, recon=0.0522, kl=14.6250, beta=0.0000\n",
      "Batch 120, loss=0.0437, recon=0.0436, kl=12.1911, beta=0.0000\n",
      "Batch 140, loss=0.0489, recon=0.0488, kl=12.0404, beta=0.0000\n",
      "Batch 160, loss=0.1469, recon=0.1468, kl=11.2310, beta=0.0000\n",
      "Batch 180, loss=0.0591, recon=0.0591, kl=9.3699, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0775 (Recon: 0.0774, KL: 14.5054, Current Beta: 0.0000) | Avg Valid Loss: 0.0688 | Avg Valid recon Loss: 0.0688\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0706, recon=0.0706, kl=4.4378, beta=0.0000\n",
      "Batch 40, loss=0.0534, recon=0.0533, kl=5.0952, beta=0.0000\n",
      "Batch 60, loss=0.0460, recon=0.0460, kl=4.5855, beta=0.0000\n",
      "Batch 80, loss=0.0625, recon=0.0624, kl=4.0014, beta=0.0000\n",
      "Batch 100, loss=0.0556, recon=0.0555, kl=3.7006, beta=0.0000\n",
      "Batch 120, loss=0.0752, recon=0.0752, kl=3.2465, beta=0.0000\n",
      "Batch 140, loss=0.0672, recon=0.0671, kl=3.9228, beta=0.0000\n",
      "Batch 160, loss=0.0417, recon=0.0417, kl=3.2069, beta=0.0000\n",
      "Batch 180, loss=0.0483, recon=0.0482, kl=3.3297, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0731 (Recon: 0.0731, KL: 4.2844, Current Beta: 0.0000) | Avg Valid Loss: 0.0656 | Avg Valid recon Loss: 0.0655\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0433, recon=0.0432, kl=1.4703, beta=0.0000\n",
      "Batch 40, loss=0.0863, recon=0.0863, kl=1.2614, beta=0.0000\n",
      "Batch 60, loss=0.0664, recon=0.0663, kl=1.2224, beta=0.0000\n",
      "Batch 80, loss=0.0355, recon=0.0355, kl=1.1012, beta=0.0000\n",
      "Batch 100, loss=0.0455, recon=0.0455, kl=0.9629, beta=0.0000\n",
      "Batch 120, loss=0.0731, recon=0.0730, kl=0.9378, beta=0.0000\n",
      "Batch 140, loss=0.0389, recon=0.0389, kl=0.6696, beta=0.0000\n",
      "Batch 160, loss=0.0410, recon=0.0409, kl=0.7596, beta=0.0000\n",
      "Batch 180, loss=0.0568, recon=0.0568, kl=0.7258, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0694 (Recon: 0.0694, KL: 1.0985, Current Beta: 0.0000) | Avg Valid Loss: 0.0624 | Avg Valid recon Loss: 0.0623\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0441, recon=0.0441, kl=0.2788, beta=0.0001\n",
      "Batch 40, loss=0.0625, recon=0.0625, kl=0.2174, beta=0.0001\n",
      "Batch 60, loss=0.0374, recon=0.0373, kl=0.1940, beta=0.0001\n",
      "Batch 80, loss=0.0359, recon=0.0359, kl=0.1623, beta=0.0001\n",
      "Batch 100, loss=0.0377, recon=0.0377, kl=0.1229, beta=0.0001\n",
      "Batch 120, loss=0.0394, recon=0.0394, kl=0.0973, beta=0.0001\n",
      "Batch 140, loss=0.0447, recon=0.0447, kl=0.0777, beta=0.0001\n",
      "Batch 160, loss=0.0713, recon=0.0713, kl=0.0598, beta=0.0001\n",
      "Batch 180, loss=0.0382, recon=0.0382, kl=0.0494, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0664 (Recon: 0.0664, KL: 0.1721, Current Beta: 0.0001) | Avg Valid Loss: 0.0602 | Avg Valid recon Loss: 0.0602\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0505, recon=0.0505, kl=0.0142, beta=0.0003\n",
      "Batch 40, loss=0.0526, recon=0.0526, kl=0.0130, beta=0.0003\n",
      "Batch 60, loss=0.0460, recon=0.0460, kl=0.0073, beta=0.0003\n",
      "Batch 80, loss=0.0473, recon=0.0473, kl=0.0048, beta=0.0003\n",
      "Batch 100, loss=0.0460, recon=0.0460, kl=0.0030, beta=0.0003\n",
      "Batch 120, loss=0.0503, recon=0.0503, kl=0.0033, beta=0.0003\n",
      "Batch 140, loss=0.0539, recon=0.0539, kl=0.0038, beta=0.0003\n",
      "Batch 160, loss=0.0462, recon=0.0462, kl=0.0032, beta=0.0003\n",
      "Batch 180, loss=0.0985, recon=0.0985, kl=0.0029, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0636 (Recon: 0.0636, KL: 0.0084, Current Beta: 0.0003) | Avg Valid Loss: 0.0567 | Avg Valid recon Loss: 0.0567\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0409, recon=0.0409, kl=0.0004, beta=0.0008\n",
      "Batch 40, loss=0.0429, recon=0.0429, kl=0.0006, beta=0.0008\n",
      "Batch 60, loss=0.0491, recon=0.0491, kl=0.0008, beta=0.0008\n",
      "Batch 80, loss=0.0406, recon=0.0406, kl=0.0007, beta=0.0008\n",
      "Batch 100, loss=0.0367, recon=0.0367, kl=0.0005, beta=0.0008\n",
      "Batch 120, loss=0.0393, recon=0.0393, kl=0.0002, beta=0.0008\n",
      "Batch 140, loss=0.0419, recon=0.0419, kl=0.0008, beta=0.0008\n",
      "Batch 160, loss=0.0592, recon=0.0592, kl=0.0009, beta=0.0008\n",
      "Batch 180, loss=0.0952, recon=0.0952, kl=0.0003, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0614 (Recon: 0.0614, KL: 0.0006, Current Beta: 0.0008) | Avg Valid Loss: 0.0553 | Avg Valid recon Loss: 0.0553\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0648, recon=0.0648, kl=0.0001, beta=0.0018\n",
      "Batch 40, loss=0.0782, recon=0.0782, kl=0.0002, beta=0.0018\n",
      "Batch 60, loss=0.0310, recon=0.0310, kl=0.0001, beta=0.0018\n",
      "Batch 80, loss=0.0306, recon=0.0306, kl=0.0001, beta=0.0018\n",
      "Batch 100, loss=0.0322, recon=0.0322, kl=0.0001, beta=0.0018\n",
      "Batch 120, loss=0.0394, recon=0.0394, kl=0.0002, beta=0.0018\n",
      "Batch 140, loss=0.0404, recon=0.0404, kl=0.0001, beta=0.0018\n",
      "Batch 160, loss=0.0443, recon=0.0443, kl=0.0001, beta=0.0018\n",
      "Batch 180, loss=0.0879, recon=0.0879, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0595 (Recon: 0.0595, KL: 0.0001, Current Beta: 0.0018) | Avg Valid Loss: 0.0546 | Avg Valid recon Loss: 0.0546\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0796, recon=0.0796, kl=0.0000, beta=0.0038\n",
      "Batch 40, loss=0.0468, recon=0.0468, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.0455, recon=0.0455, kl=0.0000, beta=0.0038\n",
      "Batch 80, loss=0.0477, recon=0.0477, kl=0.0000, beta=0.0038\n",
      "Batch 100, loss=0.0413, recon=0.0413, kl=0.0000, beta=0.0038\n",
      "Batch 120, loss=0.0613, recon=0.0613, kl=0.0001, beta=0.0038\n",
      "Batch 140, loss=0.0455, recon=0.0455, kl=0.0000, beta=0.0038\n",
      "Batch 160, loss=0.0416, recon=0.0416, kl=0.0000, beta=0.0038\n",
      "Batch 180, loss=0.0594, recon=0.0594, kl=0.0000, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0580 (Recon: 0.0579, KL: 0.0000, Current Beta: 0.0038) | Avg Valid Loss: 0.0523 | Avg Valid recon Loss: 0.0523\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0514, recon=0.0514, kl=0.0000, beta=0.0062\n",
      "Batch 40, loss=0.0354, recon=0.0354, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0428, recon=0.0428, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0322, recon=0.0322, kl=0.0000, beta=0.0062\n",
      "Batch 100, loss=0.0250, recon=0.0250, kl=0.0000, beta=0.0062\n",
      "Batch 120, loss=0.0318, recon=0.0318, kl=0.0000, beta=0.0062\n",
      "Batch 140, loss=0.0729, recon=0.0729, kl=0.0000, beta=0.0062\n",
      "Batch 160, loss=0.0485, recon=0.0485, kl=0.0000, beta=0.0062\n",
      "Batch 180, loss=0.2652, recon=0.2652, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0564 (Recon: 0.0564, KL: 0.0000, Current Beta: 0.0062) | Avg Valid Loss: 0.0508 | Avg Valid recon Loss: 0.0508\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0388, recon=0.0388, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0367, recon=0.0367, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0484, recon=0.0484, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0302, recon=0.0302, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0282, recon=0.0282, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0505, recon=0.0505, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0471, recon=0.0471, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0451, recon=0.0451, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0325, recon=0.0325, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0604, recon=0.0604, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0446, recon=0.0446, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0329, recon=0.0329, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0475, recon=0.0475, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0540, recon=0.0540, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.1192, recon=0.1192, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0666, recon=0.0666, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0446, recon=0.0446, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0292, recon=0.0292, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0539 (Recon: 0.0539, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0481 | Avg Valid recon Loss: 0.0481\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0605, recon=0.0605, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0303, recon=0.0303, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0336, recon=0.0336, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0494, recon=0.0494, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.1228, recon=0.1228, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0397, recon=0.0397, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0349, recon=0.0349, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.9383, recon=0.9383, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0379, recon=0.0379, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0528 (Recon: 0.0528, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0474\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0307, recon=0.0307, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0548, recon=0.0548, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0364, recon=0.0364, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0761, recon=0.0761, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0238, recon=0.0238, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0316, recon=0.0316, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0337, recon=0.0337, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0399, recon=0.0399, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0647, recon=0.0647, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0517 (Recon: 0.0517, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0469 | Avg Valid recon Loss: 0.0469\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0939, recon=0.0939, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0297, recon=0.0297, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0357, recon=0.0357, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0406, recon=0.0406, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0307, recon=0.0307, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0273, recon=0.0273, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0484, recon=0.0484, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0561, recon=0.0561, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0307, recon=0.0307, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0508, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0455\n",
      "\n",
      "[VRAE Run 96/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3131, recon=0.3131, kl=74.0902, beta=0.0000\n",
      "Batch 40, loss=0.2363, recon=0.2363, kl=92.3188, beta=0.0000\n",
      "Batch 60, loss=0.1126, recon=0.1126, kl=93.6982, beta=0.0000\n",
      "Batch 80, loss=0.0752, recon=0.0752, kl=104.4170, beta=0.0000\n",
      "Batch 100, loss=0.0852, recon=0.0852, kl=110.5252, beta=0.0000\n",
      "Batch 120, loss=0.0607, recon=0.0607, kl=101.7486, beta=0.0000\n",
      "Batch 140, loss=0.0629, recon=0.0629, kl=98.7991, beta=0.0000\n",
      "Batch 160, loss=0.0781, recon=0.0781, kl=108.8716, beta=0.0000\n",
      "Batch 180, loss=0.0938, recon=0.0938, kl=110.6646, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1650 (Recon: 0.1650, KL: 92.8123, Current Beta: 0.0000) | Avg Valid Loss: 0.0764 | Avg Valid recon Loss: 0.0764\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0635, recon=0.0635, kl=116.0941, beta=0.0000\n",
      "Batch 40, loss=0.0860, recon=0.0860, kl=115.6901, beta=0.0000\n",
      "Batch 60, loss=0.0824, recon=0.0824, kl=117.5503, beta=0.0000\n",
      "Batch 80, loss=0.0416, recon=0.0416, kl=124.2535, beta=0.0000\n",
      "Batch 100, loss=0.0493, recon=0.0493, kl=102.6607, beta=0.0000\n",
      "Batch 120, loss=0.0593, recon=0.0593, kl=112.1286, beta=0.0000\n",
      "Batch 140, loss=0.0566, recon=0.0565, kl=108.9448, beta=0.0000\n",
      "Batch 160, loss=0.0405, recon=0.0405, kl=122.6785, beta=0.0000\n",
      "Batch 180, loss=0.0637, recon=0.0637, kl=128.9934, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0778 (Recon: 0.0778, KL: 115.9511, Current Beta: 0.0000) | Avg Valid Loss: 0.0677 | Avg Valid recon Loss: 0.0677\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0456, recon=0.0456, kl=121.1992, beta=0.0000\n",
      "Batch 40, loss=0.0393, recon=0.0393, kl=115.9446, beta=0.0000\n",
      "Batch 60, loss=0.3198, recon=0.3198, kl=112.7742, beta=0.0000\n",
      "Batch 80, loss=0.0671, recon=0.0671, kl=107.4642, beta=0.0000\n",
      "Batch 100, loss=0.0388, recon=0.0388, kl=102.3657, beta=0.0000\n",
      "Batch 120, loss=0.0551, recon=0.0551, kl=107.1402, beta=0.0000\n",
      "Batch 140, loss=0.0562, recon=0.0561, kl=113.1416, beta=0.0000\n",
      "Batch 160, loss=0.0409, recon=0.0409, kl=119.6464, beta=0.0000\n",
      "Batch 180, loss=0.0357, recon=0.0357, kl=113.8579, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0654 (Recon: 0.0654, KL: 113.0780, Current Beta: 0.0000) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0566\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0484, recon=0.0484, kl=109.0466, beta=0.0000\n",
      "Batch 40, loss=0.0564, recon=0.0564, kl=102.1301, beta=0.0000\n",
      "Batch 60, loss=0.0409, recon=0.0409, kl=100.9225, beta=0.0000\n",
      "Batch 80, loss=0.0363, recon=0.0362, kl=100.9778, beta=0.0000\n",
      "Batch 100, loss=0.0461, recon=0.0461, kl=103.4006, beta=0.0000\n",
      "Batch 120, loss=0.0354, recon=0.0354, kl=111.7036, beta=0.0000\n",
      "Batch 140, loss=0.0451, recon=0.0451, kl=106.5659, beta=0.0000\n",
      "Batch 160, loss=0.0454, recon=0.0454, kl=100.2583, beta=0.0000\n",
      "Batch 180, loss=0.0684, recon=0.0684, kl=102.8663, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0570 (Recon: 0.0570, KL: 104.9771, Current Beta: 0.0000) | Avg Valid Loss: 0.0477 | Avg Valid recon Loss: 0.0477\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0348, recon=0.0348, kl=87.9419, beta=0.0000\n",
      "Batch 40, loss=0.0361, recon=0.0360, kl=77.5486, beta=0.0000\n",
      "Batch 60, loss=0.0688, recon=0.0688, kl=85.4811, beta=0.0000\n",
      "Batch 80, loss=0.0400, recon=0.0399, kl=96.7892, beta=0.0000\n",
      "Batch 100, loss=0.0333, recon=0.0333, kl=94.9802, beta=0.0000\n",
      "Batch 120, loss=0.0591, recon=0.0590, kl=91.0410, beta=0.0000\n",
      "Batch 140, loss=0.0538, recon=0.0538, kl=84.0397, beta=0.0000\n",
      "Batch 160, loss=0.0972, recon=0.0971, kl=80.6166, beta=0.0000\n",
      "Batch 180, loss=0.0311, recon=0.0310, kl=86.6607, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0523, KL: 87.8425, Current Beta: 0.0000) | Avg Valid Loss: 0.0434 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0570, recon=0.0569, kl=59.9075, beta=0.0000\n",
      "Batch 40, loss=0.0377, recon=0.0376, kl=53.6096, beta=0.0000\n",
      "Batch 60, loss=0.0276, recon=0.0274, kl=79.9673, beta=0.0000\n",
      "Batch 80, loss=0.1670, recon=0.1669, kl=71.9551, beta=0.0000\n",
      "Batch 100, loss=0.0368, recon=0.0367, kl=65.2663, beta=0.0000\n",
      "Batch 120, loss=0.0383, recon=0.0382, kl=54.9160, beta=0.0000\n",
      "Batch 140, loss=0.0324, recon=0.0323, kl=56.2040, beta=0.0000\n",
      "Batch 160, loss=0.0432, recon=0.0431, kl=64.2071, beta=0.0000\n",
      "Batch 180, loss=0.0443, recon=0.0441, kl=70.2233, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0503 (Recon: 0.0501, KL: 64.5719, Current Beta: 0.0000) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0477, recon=0.0475, kl=37.0452, beta=0.0000\n",
      "Batch 40, loss=0.0381, recon=0.0378, kl=45.6331, beta=0.0000\n",
      "Batch 60, loss=0.0291, recon=0.0289, kl=48.9119, beta=0.0000\n",
      "Batch 80, loss=0.0302, recon=0.0300, kl=40.7131, beta=0.0000\n",
      "Batch 100, loss=0.0315, recon=0.0313, kl=36.3014, beta=0.0000\n",
      "Batch 120, loss=0.0308, recon=0.0306, kl=36.3626, beta=0.0000\n",
      "Batch 140, loss=0.0617, recon=0.0615, kl=33.9094, beta=0.0000\n",
      "Batch 160, loss=0.0432, recon=0.0431, kl=27.4785, beta=0.0000\n",
      "Batch 180, loss=0.0457, recon=0.0455, kl=33.0940, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0461, KL: 38.4583, Current Beta: 0.0000) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0447\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0321, recon=0.0317, kl=29.0307, beta=0.0000\n",
      "Batch 40, loss=0.0315, recon=0.0311, kl=24.2759, beta=0.0000\n",
      "Batch 60, loss=0.0587, recon=0.0582, kl=31.4163, beta=0.0000\n",
      "Batch 80, loss=0.0292, recon=0.0288, kl=24.8926, beta=0.0000\n",
      "Batch 100, loss=0.0232, recon=0.0229, kl=16.4981, beta=0.0000\n",
      "Batch 120, loss=0.0310, recon=0.0308, kl=13.6626, beta=0.0000\n",
      "Batch 140, loss=0.0316, recon=0.0314, kl=15.8452, beta=0.0000\n",
      "Batch 160, loss=0.0369, recon=0.0367, kl=15.4225, beta=0.0000\n",
      "Batch 180, loss=0.0469, recon=0.0468, kl=10.2049, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0469, KL: 21.2035, Current Beta: 0.0000) | Avg Valid Loss: 0.0397 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0516, recon=0.0515, kl=2.1423, beta=0.0000\n",
      "Batch 40, loss=0.0327, recon=0.0326, kl=3.4746, beta=0.0000\n",
      "Batch 60, loss=0.0471, recon=0.0469, kl=3.7295, beta=0.0000\n",
      "Batch 80, loss=0.0313, recon=0.0311, kl=5.3468, beta=0.0000\n",
      "Batch 100, loss=0.0280, recon=0.0268, kl=28.7046, beta=0.0000\n",
      "Batch 120, loss=0.0235, recon=0.0226, kl=23.2163, beta=0.0000\n",
      "Batch 140, loss=0.0443, recon=0.0437, kl=13.7272, beta=0.0000\n",
      "Batch 160, loss=0.0245, recon=0.0240, kl=12.2397, beta=0.0000\n",
      "Batch 180, loss=0.0539, recon=0.0534, kl=10.3675, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0443 (Recon: 0.0438, KL: 10.8808, Current Beta: 0.0000) | Avg Valid Loss: 0.0624 | Avg Valid recon Loss: 0.0620\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0754, recon=0.0749, kl=4.9868, beta=0.0001\n",
      "Batch 40, loss=0.0501, recon=0.0498, kl=3.0291, beta=0.0001\n",
      "Batch 60, loss=0.0385, recon=0.0381, kl=3.8369, beta=0.0001\n",
      "Batch 80, loss=0.0767, recon=0.0764, kl=2.5334, beta=0.0001\n",
      "Batch 100, loss=0.0391, recon=0.0384, kl=5.8952, beta=0.0001\n",
      "Batch 120, loss=0.0505, recon=0.0501, kl=3.4753, beta=0.0001\n",
      "Batch 140, loss=0.0439, recon=0.0436, kl=2.6901, beta=0.0001\n",
      "Batch 160, loss=0.0457, recon=0.0455, kl=1.9452, beta=0.0001\n",
      "Batch 180, loss=0.0566, recon=0.0561, kl=4.0827, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0549 (Recon: 0.0545, KL: 3.5779, Current Beta: 0.0001) | Avg Valid Loss: 0.0477 | Avg Valid recon Loss: 0.0472\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0363, recon=0.0357, kl=2.0832, beta=0.0003\n",
      "Batch 40, loss=0.0240, recon=0.0235, kl=1.7816, beta=0.0003\n",
      "Batch 60, loss=0.0316, recon=0.0303, kl=4.5302, beta=0.0003\n",
      "Batch 80, loss=0.0390, recon=0.0380, kl=3.6109, beta=0.0003\n",
      "Batch 100, loss=0.0694, recon=0.0683, kl=3.8258, beta=0.0003\n",
      "Batch 120, loss=0.0619, recon=0.0611, kl=2.7692, beta=0.0003\n",
      "Batch 140, loss=0.1002, recon=0.0997, kl=1.7888, beta=0.0003\n",
      "Batch 160, loss=0.0386, recon=0.0382, kl=1.1126, beta=0.0003\n",
      "Batch 180, loss=0.0399, recon=0.0395, kl=1.4074, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0546 (Recon: 0.0538, KL: 2.7126, Current Beta: 0.0003) | Avg Valid Loss: 0.0534 | Avg Valid recon Loss: 0.0530\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0302, recon=0.0297, kl=0.7181, beta=0.0008\n",
      "Batch 40, loss=0.0403, recon=0.0400, kl=0.4138, beta=0.0008\n",
      "Batch 60, loss=0.0340, recon=0.0336, kl=0.5645, beta=0.0008\n",
      "Batch 80, loss=0.0324, recon=0.0322, kl=0.2861, beta=0.0008\n",
      "Batch 100, loss=0.0740, recon=0.0719, kl=2.7602, beta=0.0008\n",
      "Batch 120, loss=0.0516, recon=0.0484, kl=4.1947, beta=0.0008\n",
      "Batch 140, loss=0.0558, recon=0.0521, kl=4.8488, beta=0.0008\n",
      "Batch 160, loss=0.0654, recon=0.0606, kl=6.3666, beta=0.0008\n",
      "Batch 180, loss=0.0391, recon=0.0351, kl=5.2116, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0580 (Recon: 0.0561, KL: 2.5224, Current Beta: 0.0008) | Avg Valid Loss: 0.0511 | Avg Valid recon Loss: 0.0473\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0713, recon=0.0660, kl=2.9391, beta=0.0018\n",
      "Batch 40, loss=0.0385, recon=0.0363, kl=1.2108, beta=0.0018\n",
      "Batch 60, loss=0.0601, recon=0.0557, kl=2.4217, beta=0.0018\n",
      "Batch 80, loss=0.0412, recon=0.0375, kl=2.0179, beta=0.0018\n",
      "Batch 100, loss=0.0615, recon=0.0593, kl=1.2323, beta=0.0018\n",
      "Batch 120, loss=0.0336, recon=0.0320, kl=0.8606, beta=0.0018\n",
      "Batch 140, loss=0.0379, recon=0.0361, kl=0.9873, beta=0.0018\n",
      "Batch 160, loss=0.0277, recon=0.0259, kl=1.0061, beta=0.0018\n",
      "Batch 180, loss=0.0390, recon=0.0378, kl=0.6785, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0544 (Recon: 0.0513, KL: 1.7033, Current Beta: 0.0018) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0526, recon=0.0516, kl=0.2515, beta=0.0038\n",
      "Batch 40, loss=0.1146, recon=0.1137, kl=0.2535, beta=0.0038\n",
      "Batch 60, loss=0.0283, recon=0.0276, kl=0.1849, beta=0.0038\n",
      "Batch 80, loss=0.0409, recon=0.0405, kl=0.0965, beta=0.0038\n",
      "Batch 100, loss=0.0316, recon=0.0313, kl=0.0711, beta=0.0038\n",
      "Batch 120, loss=0.0334, recon=0.0332, kl=0.0543, beta=0.0038\n",
      "Batch 140, loss=0.0369, recon=0.0355, kl=0.3883, beta=0.0038\n",
      "Batch 160, loss=0.0575, recon=0.0541, kl=0.8983, beta=0.0038\n",
      "Batch 180, loss=0.0441, recon=0.0425, kl=0.4196, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0456 (Recon: 0.0445, KL: 0.3052, Current Beta: 0.0038) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0376, recon=0.0367, kl=0.1387, beta=0.0062\n",
      "Batch 40, loss=0.0446, recon=0.0442, kl=0.0610, beta=0.0062\n",
      "Batch 60, loss=0.0244, recon=0.0242, kl=0.0239, beta=0.0062\n",
      "Batch 80, loss=0.0388, recon=0.0387, kl=0.0117, beta=0.0062\n",
      "Batch 100, loss=0.0387, recon=0.0387, kl=0.0099, beta=0.0062\n",
      "Batch 120, loss=0.0348, recon=0.0347, kl=0.0050, beta=0.0062\n",
      "Batch 140, loss=0.0575, recon=0.0575, kl=0.0049, beta=0.0062\n",
      "Batch 160, loss=0.0325, recon=0.0325, kl=0.0054, beta=0.0062\n",
      "Batch 180, loss=0.0304, recon=0.0304, kl=0.0030, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0481 (Recon: 0.0478, KL: 0.0482, Current Beta: 0.0062) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0280, recon=0.0280, kl=0.0005, beta=0.0100\n",
      "Batch 40, loss=0.0270, recon=0.0270, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.0243, recon=0.0243, kl=0.0016, beta=0.0100\n",
      "Batch 80, loss=0.0414, recon=0.0414, kl=0.0002, beta=0.0100\n",
      "Batch 100, loss=0.0474, recon=0.0474, kl=0.0004, beta=0.0100\n",
      "Batch 120, loss=0.0565, recon=0.0565, kl=0.0006, beta=0.0100\n",
      "Batch 140, loss=0.0306, recon=0.0306, kl=0.0002, beta=0.0100\n",
      "Batch 160, loss=0.0333, recon=0.0333, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0423, recon=0.0423, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0425, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0528 | Avg Valid recon Loss: 0.0528\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0639, recon=0.0639, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0455, recon=0.0455, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0533, recon=0.0533, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0702, recon=0.0702, kl=0.0018, beta=0.0100\n",
      "Batch 100, loss=0.0504, recon=0.0504, kl=0.0003, beta=0.0100\n",
      "Batch 120, loss=0.0477, recon=0.0477, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0266, recon=0.0266, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0275, recon=0.0275, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0360, recon=0.0360, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0476 (Recon: 0.0476, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0252, recon=0.0252, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0294, recon=0.0294, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.0634, recon=0.0634, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0296, recon=0.0295, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0590, recon=0.0590, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0459, recon=0.0459, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0304, recon=0.0304, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0402, recon=0.0402, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0459, recon=0.0459, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0574, recon=0.0574, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0328, recon=0.0328, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0797, recon=0.0797, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0364, recon=0.0364, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0371, recon=0.0371, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0294, recon=0.0294, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0334, recon=0.0334, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0451, recon=0.0451, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0337, recon=0.0337, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0472, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0354, recon=0.0354, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0276, recon=0.0276, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0257, recon=0.0257, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0344, recon=0.0344, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0412, recon=0.0412, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0232, recon=0.0232, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0732, recon=0.0732, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0720, recon=0.0720, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0417, recon=0.0417, kl=0.0004, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0352\n",
      "\n",
      "[VRAE Run 97/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5061, recon=0.5061, kl=0.6205, beta=0.0000\n",
      "Batch 40, loss=0.3639, recon=0.3639, kl=12.0534, beta=0.0000\n",
      "Batch 60, loss=0.2893, recon=0.2893, kl=19.8406, beta=0.0000\n",
      "Batch 80, loss=0.1550, recon=0.1550, kl=24.9744, beta=0.0000\n",
      "Batch 100, loss=0.1552, recon=0.1552, kl=29.1609, beta=0.0000\n",
      "Batch 120, loss=0.1984, recon=0.1984, kl=31.4629, beta=0.0000\n",
      "Batch 140, loss=0.3387, recon=0.3387, kl=34.2555, beta=0.0000\n",
      "Batch 160, loss=0.1867, recon=0.1867, kl=36.4368, beta=0.0000\n",
      "Batch 180, loss=0.1127, recon=0.1127, kl=38.1458, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2873 (Recon: 0.2873, KL: 23.4441, Current Beta: 0.0000) | Avg Valid Loss: 0.1263 | Avg Valid recon Loss: 0.1263\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1348, recon=0.1348, kl=39.1131, beta=0.0000\n",
      "Batch 40, loss=0.1696, recon=0.1696, kl=38.4568, beta=0.0000\n",
      "Batch 60, loss=0.1104, recon=0.1104, kl=38.4312, beta=0.0000\n",
      "Batch 80, loss=0.0918, recon=0.0918, kl=39.8880, beta=0.0000\n",
      "Batch 100, loss=0.1678, recon=0.1678, kl=41.5073, beta=0.0000\n",
      "Batch 120, loss=0.0928, recon=0.0928, kl=42.7416, beta=0.0000\n",
      "Batch 140, loss=0.0825, recon=0.0825, kl=43.4760, beta=0.0000\n",
      "Batch 160, loss=0.0889, recon=0.0889, kl=43.8689, beta=0.0000\n",
      "Batch 180, loss=0.0756, recon=0.0756, kl=44.9143, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1261 (Recon: 0.1261, KL: 41.0871, Current Beta: 0.0000) | Avg Valid Loss: 0.0895 | Avg Valid recon Loss: 0.0895\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0696, recon=0.0696, kl=44.4006, beta=0.0000\n",
      "Batch 40, loss=0.0830, recon=0.0830, kl=44.1793, beta=0.0000\n",
      "Batch 60, loss=0.1026, recon=0.1026, kl=45.1488, beta=0.0000\n",
      "Batch 80, loss=0.0758, recon=0.0758, kl=44.5608, beta=0.0000\n",
      "Batch 100, loss=0.0821, recon=0.0821, kl=44.5108, beta=0.0000\n",
      "Batch 120, loss=0.0584, recon=0.0584, kl=44.5107, beta=0.0000\n",
      "Batch 140, loss=0.0611, recon=0.0611, kl=43.3921, beta=0.0000\n",
      "Batch 160, loss=0.0578, recon=0.0578, kl=43.6281, beta=0.0000\n",
      "Batch 180, loss=0.0720, recon=0.0720, kl=44.3277, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0955 (Recon: 0.0955, KL: 44.4626, Current Beta: 0.0000) | Avg Valid Loss: 0.0750 | Avg Valid recon Loss: 0.0750\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.4155, recon=0.4155, kl=41.9584, beta=0.0000\n",
      "Batch 40, loss=0.0896, recon=0.0896, kl=39.9211, beta=0.0000\n",
      "Batch 60, loss=0.0582, recon=0.0582, kl=38.3000, beta=0.0000\n",
      "Batch 80, loss=0.0526, recon=0.0526, kl=39.2651, beta=0.0000\n",
      "Batch 100, loss=0.1245, recon=0.1245, kl=39.8730, beta=0.0000\n",
      "Batch 120, loss=0.0740, recon=0.0740, kl=40.3044, beta=0.0000\n",
      "Batch 140, loss=0.0844, recon=0.0844, kl=40.7832, beta=0.0000\n",
      "Batch 160, loss=0.2517, recon=0.2516, kl=41.8816, beta=0.0000\n",
      "Batch 180, loss=0.0529, recon=0.0528, kl=40.1850, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0808 (Recon: 0.0808, KL: 40.5375, Current Beta: 0.0000) | Avg Valid Loss: 0.0651 | Avg Valid recon Loss: 0.0651\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0560, recon=0.0560, kl=36.7568, beta=0.0000\n",
      "Batch 40, loss=0.2111, recon=0.2110, kl=32.1812, beta=0.0000\n",
      "Batch 60, loss=0.0844, recon=0.0844, kl=29.9090, beta=0.0000\n",
      "Batch 80, loss=0.0491, recon=0.0491, kl=29.4539, beta=0.0000\n",
      "Batch 100, loss=0.0673, recon=0.0673, kl=29.3387, beta=0.0000\n",
      "Batch 120, loss=0.1068, recon=0.1068, kl=29.1190, beta=0.0000\n",
      "Batch 140, loss=0.0423, recon=0.0423, kl=27.2690, beta=0.0000\n",
      "Batch 160, loss=0.0712, recon=0.0711, kl=26.5536, beta=0.0000\n",
      "Batch 180, loss=0.0530, recon=0.0530, kl=27.9183, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0719 (Recon: 0.0718, KL: 30.3946, Current Beta: 0.0000) | Avg Valid Loss: 0.0602 | Avg Valid recon Loss: 0.0602\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0364, recon=0.0364, kl=26.6821, beta=0.0000\n",
      "Batch 40, loss=0.0660, recon=0.0660, kl=20.0083, beta=0.0000\n",
      "Batch 60, loss=0.0434, recon=0.0433, kl=17.9708, beta=0.0000\n",
      "Batch 80, loss=0.0541, recon=0.0541, kl=18.4404, beta=0.0000\n",
      "Batch 100, loss=0.0632, recon=0.0632, kl=17.9440, beta=0.0000\n",
      "Batch 120, loss=0.0335, recon=0.0335, kl=17.2591, beta=0.0000\n",
      "Batch 140, loss=0.0426, recon=0.0425, kl=15.4610, beta=0.0000\n",
      "Batch 160, loss=0.0521, recon=0.0521, kl=14.8396, beta=0.0000\n",
      "Batch 180, loss=0.0727, recon=0.0727, kl=15.5995, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0664 (Recon: 0.0663, KL: 18.8783, Current Beta: 0.0000) | Avg Valid Loss: 0.0571 | Avg Valid recon Loss: 0.0570\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0521, recon=0.0520, kl=9.9721, beta=0.0000\n",
      "Batch 40, loss=0.0438, recon=0.0438, kl=8.9517, beta=0.0000\n",
      "Batch 60, loss=0.0309, recon=0.0308, kl=8.2709, beta=0.0000\n",
      "Batch 80, loss=0.0434, recon=0.0434, kl=8.7149, beta=0.0000\n",
      "Batch 100, loss=0.0424, recon=0.0424, kl=8.7837, beta=0.0000\n",
      "Batch 120, loss=0.0673, recon=0.0673, kl=8.8624, beta=0.0000\n",
      "Batch 140, loss=0.0405, recon=0.0404, kl=6.6492, beta=0.0000\n",
      "Batch 160, loss=0.0571, recon=0.0571, kl=8.3280, beta=0.0000\n",
      "Batch 180, loss=0.0422, recon=0.0421, kl=6.8063, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0620 (Recon: 0.0619, KL: 8.7581, Current Beta: 0.0000) | Avg Valid Loss: 0.0532 | Avg Valid recon Loss: 0.0531\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0371, recon=0.0370, kl=3.8041, beta=0.0000\n",
      "Batch 40, loss=0.0517, recon=0.0517, kl=4.2607, beta=0.0000\n",
      "Batch 60, loss=0.0398, recon=0.0398, kl=3.7078, beta=0.0000\n",
      "Batch 80, loss=0.0656, recon=0.0655, kl=4.0532, beta=0.0000\n",
      "Batch 100, loss=0.0696, recon=0.0695, kl=3.8865, beta=0.0000\n",
      "Batch 120, loss=0.0541, recon=0.0540, kl=3.3675, beta=0.0000\n",
      "Batch 140, loss=0.0630, recon=0.0629, kl=3.8035, beta=0.0000\n",
      "Batch 160, loss=0.0320, recon=0.0320, kl=2.6832, beta=0.0000\n",
      "Batch 180, loss=0.0262, recon=0.0262, kl=2.7710, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0589 (Recon: 0.0588, KL: 3.7113, Current Beta: 0.0000) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0509\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0428, recon=0.0427, kl=1.6191, beta=0.0000\n",
      "Batch 40, loss=0.0433, recon=0.0432, kl=1.7701, beta=0.0000\n",
      "Batch 60, loss=0.0332, recon=0.0331, kl=1.6518, beta=0.0000\n",
      "Batch 80, loss=0.0772, recon=0.0771, kl=1.3741, beta=0.0000\n",
      "Batch 100, loss=0.0388, recon=0.0387, kl=1.0905, beta=0.0000\n",
      "Batch 120, loss=0.0418, recon=0.0417, kl=1.1444, beta=0.0000\n",
      "Batch 140, loss=0.0375, recon=0.0375, kl=1.0583, beta=0.0000\n",
      "Batch 160, loss=0.0317, recon=0.0317, kl=1.1900, beta=0.0000\n",
      "Batch 180, loss=0.0335, recon=0.0335, kl=1.3319, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0559 (Recon: 0.0558, KL: 1.3754, Current Beta: 0.0000) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0477\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0498, recon=0.0498, kl=0.6093, beta=0.0001\n",
      "Batch 40, loss=0.0421, recon=0.0421, kl=0.7727, beta=0.0001\n",
      "Batch 60, loss=0.0343, recon=0.0342, kl=0.3626, beta=0.0001\n",
      "Batch 80, loss=0.0397, recon=0.0397, kl=0.4761, beta=0.0001\n",
      "Batch 100, loss=0.0380, recon=0.0380, kl=0.1757, beta=0.0001\n",
      "Batch 120, loss=0.0418, recon=0.0418, kl=0.2079, beta=0.0001\n",
      "Batch 140, loss=0.0434, recon=0.0434, kl=0.2706, beta=0.0001\n",
      "Batch 160, loss=0.0260, recon=0.0260, kl=0.2356, beta=0.0001\n",
      "Batch 180, loss=0.0488, recon=0.0487, kl=0.1164, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0532, KL: 0.3764, Current Beta: 0.0001) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0465\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.8346, recon=0.8346, kl=0.0402, beta=0.0003\n",
      "Batch 40, loss=0.0434, recon=0.0434, kl=0.0427, beta=0.0003\n",
      "Batch 60, loss=0.0256, recon=0.0256, kl=0.0372, beta=0.0003\n",
      "Batch 80, loss=0.0719, recon=0.0719, kl=0.0271, beta=0.0003\n",
      "Batch 100, loss=0.0309, recon=0.0309, kl=0.0112, beta=0.0003\n",
      "Batch 120, loss=0.0572, recon=0.0572, kl=0.0316, beta=0.0003\n",
      "Batch 140, loss=0.0378, recon=0.0378, kl=0.0102, beta=0.0003\n",
      "Batch 160, loss=0.0237, recon=0.0237, kl=0.0346, beta=0.0003\n",
      "Batch 180, loss=0.0439, recon=0.0439, kl=0.0132, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0513 (Recon: 0.0513, KL: 0.0292, Current Beta: 0.0003) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0232, recon=0.0232, kl=0.0070, beta=0.0008\n",
      "Batch 40, loss=0.0420, recon=0.0420, kl=0.0025, beta=0.0008\n",
      "Batch 60, loss=0.0529, recon=0.0529, kl=0.0010, beta=0.0008\n",
      "Batch 80, loss=0.1347, recon=0.1347, kl=0.0035, beta=0.0008\n",
      "Batch 100, loss=0.0501, recon=0.0501, kl=0.0026, beta=0.0008\n",
      "Batch 120, loss=0.1771, recon=0.1771, kl=0.0035, beta=0.0008\n",
      "Batch 140, loss=0.0384, recon=0.0384, kl=0.0032, beta=0.0008\n",
      "Batch 160, loss=0.0374, recon=0.0374, kl=0.0015, beta=0.0008\n",
      "Batch 180, loss=0.0359, recon=0.0359, kl=0.0038, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0496, KL: 0.0031, Current Beta: 0.0008) | Avg Valid Loss: 0.0432 | Avg Valid recon Loss: 0.0432\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0435, recon=0.0435, kl=0.0009, beta=0.0018\n",
      "Batch 40, loss=0.0504, recon=0.0504, kl=0.0005, beta=0.0018\n",
      "Batch 60, loss=0.0320, recon=0.0320, kl=0.0056, beta=0.0018\n",
      "Batch 80, loss=0.0831, recon=0.0831, kl=0.0018, beta=0.0018\n",
      "Batch 100, loss=0.0261, recon=0.0261, kl=0.0008, beta=0.0018\n",
      "Batch 120, loss=0.0503, recon=0.0503, kl=0.0008, beta=0.0018\n",
      "Batch 140, loss=0.0560, recon=0.0560, kl=0.0003, beta=0.0018\n",
      "Batch 160, loss=0.0420, recon=0.0420, kl=0.0003, beta=0.0018\n",
      "Batch 180, loss=0.0590, recon=0.0590, kl=0.0009, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0478, KL: 0.0010, Current Beta: 0.0018) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0299, recon=0.0299, kl=0.0003, beta=0.0038\n",
      "Batch 40, loss=0.0491, recon=0.0491, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.0364, recon=0.0364, kl=0.0003, beta=0.0038\n",
      "Batch 80, loss=0.0255, recon=0.0255, kl=0.0001, beta=0.0038\n",
      "Batch 100, loss=0.0283, recon=0.0283, kl=0.0001, beta=0.0038\n",
      "Batch 120, loss=0.0416, recon=0.0416, kl=0.0002, beta=0.0038\n",
      "Batch 140, loss=0.0296, recon=0.0296, kl=0.0001, beta=0.0038\n",
      "Batch 160, loss=0.0325, recon=0.0325, kl=0.0001, beta=0.0038\n",
      "Batch 180, loss=0.0281, recon=0.0281, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0465 (Recon: 0.0465, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0381, recon=0.0381, kl=0.0004, beta=0.0062\n",
      "Batch 40, loss=0.0311, recon=0.0311, kl=0.0002, beta=0.0062\n",
      "Batch 60, loss=0.0303, recon=0.0303, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0438, recon=0.0438, kl=0.0001, beta=0.0062\n",
      "Batch 100, loss=0.0331, recon=0.0331, kl=0.0001, beta=0.0062\n",
      "Batch 120, loss=0.0268, recon=0.0268, kl=0.0001, beta=0.0062\n",
      "Batch 140, loss=0.0385, recon=0.0385, kl=0.0002, beta=0.0062\n",
      "Batch 160, loss=0.0339, recon=0.0339, kl=0.0002, beta=0.0062\n",
      "Batch 180, loss=0.0593, recon=0.0593, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0451 (Recon: 0.0451, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0436, recon=0.0436, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0315, recon=0.0315, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0326, recon=0.0326, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0289, recon=0.0289, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0467, recon=0.0467, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0252, recon=0.0252, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0400, recon=0.0400, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0521, recon=0.0521, kl=0.0019, beta=0.0100\n",
      "Batch 180, loss=0.0406, recon=0.0406, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0394\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0281, recon=0.0281, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0228, recon=0.0228, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0373, recon=0.0373, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0322, recon=0.0322, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0823, recon=0.0823, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0330, recon=0.0330, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.6318, recon=0.6318, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0262, recon=0.0262, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0613, recon=0.0613, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0550, recon=0.0550, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0333, recon=0.0333, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0384, recon=0.0384, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0233, recon=0.0233, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0620, recon=0.0620, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0239, recon=0.0239, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0424, recon=0.0424, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0377, recon=0.0377, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0290, recon=0.0290, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0423, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0235, recon=0.0235, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0294, recon=0.0294, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0343, recon=0.0343, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0248, recon=0.0248, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.1137, recon=0.1137, kl=0.0004, beta=0.0100\n",
      "Batch 120, loss=0.0418, recon=0.0418, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0382, recon=0.0382, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0343, recon=0.0343, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0291, recon=0.0291, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0416, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0228, recon=0.0228, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0329, recon=0.0329, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0272, recon=0.0272, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0280, recon=0.0280, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0522, recon=0.0522, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0297, recon=0.0297, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0288, recon=0.0288, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0279, recon=0.0279, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0395, recon=0.0395, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0408 (Recon: 0.0408, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0352\n",
      "\n",
      "[VRAE Run 98/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1946, recon=0.1946, kl=19.6997, beta=0.0000\n",
      "Batch 40, loss=0.1211, recon=0.1211, kl=26.2535, beta=0.0000\n",
      "Batch 60, loss=0.0975, recon=0.0975, kl=29.8414, beta=0.0000\n",
      "Batch 80, loss=0.0857, recon=0.0857, kl=27.6922, beta=0.0000\n",
      "Batch 100, loss=0.1782, recon=0.1782, kl=31.0937, beta=0.0000\n",
      "Batch 120, loss=0.0608, recon=0.0608, kl=32.8109, beta=0.0000\n",
      "Batch 140, loss=0.0461, recon=0.0461, kl=35.4495, beta=0.0000\n",
      "Batch 160, loss=0.0391, recon=0.0391, kl=35.5041, beta=0.0000\n",
      "Batch 180, loss=0.0543, recon=0.0543, kl=32.8559, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1387 (Recon: 0.1387, KL: 28.6951, Current Beta: 0.0000) | Avg Valid Loss: 0.0620 | Avg Valid recon Loss: 0.0620\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0358, recon=0.0357, kl=35.0523, beta=0.0000\n",
      "Batch 40, loss=0.0970, recon=0.0970, kl=34.0137, beta=0.0000\n",
      "Batch 60, loss=0.1269, recon=0.1269, kl=31.8658, beta=0.0000\n",
      "Batch 80, loss=0.0526, recon=0.0525, kl=33.5508, beta=0.0000\n",
      "Batch 100, loss=0.0379, recon=0.0379, kl=34.2607, beta=0.0000\n",
      "Batch 120, loss=0.0621, recon=0.0621, kl=31.8268, beta=0.0000\n",
      "Batch 140, loss=0.0352, recon=0.0352, kl=31.3459, beta=0.0000\n",
      "Batch 160, loss=0.0463, recon=0.0463, kl=34.1640, beta=0.0000\n",
      "Batch 180, loss=0.0549, recon=0.0549, kl=34.2511, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0661 (Recon: 0.0661, KL: 33.3772, Current Beta: 0.0000) | Avg Valid Loss: 0.0487 | Avg Valid recon Loss: 0.0487\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0363, recon=0.0363, kl=32.8089, beta=0.0000\n",
      "Batch 40, loss=0.0280, recon=0.0280, kl=31.9384, beta=0.0000\n",
      "Batch 60, loss=0.0335, recon=0.0335, kl=33.7410, beta=0.0000\n",
      "Batch 80, loss=0.0441, recon=0.0441, kl=29.7841, beta=0.0000\n",
      "Batch 100, loss=0.0273, recon=0.0273, kl=30.0173, beta=0.0000\n",
      "Batch 120, loss=0.0411, recon=0.0411, kl=32.6878, beta=0.0000\n",
      "Batch 140, loss=0.0653, recon=0.0653, kl=32.8796, beta=0.0000\n",
      "Batch 160, loss=0.0514, recon=0.0514, kl=32.1237, beta=0.0000\n",
      "Batch 180, loss=0.0734, recon=0.0734, kl=31.4481, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0553 (Recon: 0.0553, KL: 31.9265, Current Beta: 0.0000) | Avg Valid Loss: 0.0601 | Avg Valid recon Loss: 0.0601\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0318, recon=0.0318, kl=31.6861, beta=0.0000\n",
      "Batch 40, loss=0.0333, recon=0.0333, kl=30.7321, beta=0.0000\n",
      "Batch 60, loss=0.0658, recon=0.0658, kl=26.8452, beta=0.0000\n",
      "Batch 80, loss=0.0257, recon=0.0256, kl=28.1872, beta=0.0000\n",
      "Batch 100, loss=0.0405, recon=0.0405, kl=27.4103, beta=0.0000\n",
      "Batch 120, loss=0.0629, recon=0.0629, kl=29.4082, beta=0.0000\n",
      "Batch 140, loss=0.0641, recon=0.0641, kl=31.4508, beta=0.0000\n",
      "Batch 160, loss=0.0424, recon=0.0424, kl=31.3162, beta=0.0000\n",
      "Batch 180, loss=0.0504, recon=0.0504, kl=31.2480, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0562 (Recon: 0.0562, KL: 29.7338, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0358, recon=0.0358, kl=30.1655, beta=0.0000\n",
      "Batch 40, loss=0.0520, recon=0.0520, kl=25.4275, beta=0.0000\n",
      "Batch 60, loss=0.0289, recon=0.0289, kl=23.2410, beta=0.0000\n",
      "Batch 80, loss=0.0342, recon=0.0342, kl=27.2499, beta=0.0000\n",
      "Batch 100, loss=0.0928, recon=0.0928, kl=24.8488, beta=0.0000\n",
      "Batch 120, loss=0.0275, recon=0.0275, kl=23.6326, beta=0.0000\n",
      "Batch 140, loss=0.0233, recon=0.0233, kl=22.6059, beta=0.0000\n",
      "Batch 160, loss=0.0392, recon=0.0392, kl=23.8671, beta=0.0000\n",
      "Batch 180, loss=0.0411, recon=0.0411, kl=23.8134, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0484 (Recon: 0.0484, KL: 25.1548, Current Beta: 0.0000) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0412, recon=0.0412, kl=17.7085, beta=0.0000\n",
      "Batch 40, loss=0.1070, recon=0.1069, kl=18.8687, beta=0.0000\n",
      "Batch 60, loss=0.0313, recon=0.0312, kl=18.5997, beta=0.0000\n",
      "Batch 80, loss=0.0303, recon=0.0302, kl=22.3264, beta=0.0000\n",
      "Batch 100, loss=0.0303, recon=0.0303, kl=20.3384, beta=0.0000\n",
      "Batch 120, loss=0.1050, recon=0.1050, kl=18.8968, beta=0.0000\n",
      "Batch 140, loss=0.0305, recon=0.0305, kl=17.7811, beta=0.0000\n",
      "Batch 160, loss=0.0487, recon=0.0487, kl=17.0239, beta=0.0000\n",
      "Batch 180, loss=0.0321, recon=0.0321, kl=15.9906, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0424, KL: 18.6995, Current Beta: 0.0000) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0288, recon=0.0288, kl=10.3533, beta=0.0000\n",
      "Batch 40, loss=0.0460, recon=0.0459, kl=10.2362, beta=0.0000\n",
      "Batch 60, loss=0.0256, recon=0.0255, kl=9.8667, beta=0.0000\n",
      "Batch 80, loss=0.0260, recon=0.0259, kl=9.2604, beta=0.0000\n",
      "Batch 100, loss=0.0199, recon=0.0199, kl=8.3199, beta=0.0000\n",
      "Batch 120, loss=0.0421, recon=0.0420, kl=14.6673, beta=0.0000\n",
      "Batch 140, loss=0.0458, recon=0.0457, kl=13.3557, beta=0.0000\n",
      "Batch 160, loss=0.0377, recon=0.0376, kl=13.6704, beta=0.0000\n",
      "Batch 180, loss=0.0214, recon=0.0213, kl=14.2044, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0413 (Recon: 0.0413, KL: 11.6866, Current Beta: 0.0000) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0360\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0366, recon=0.0365, kl=7.4309, beta=0.0000\n",
      "Batch 40, loss=0.0550, recon=0.0549, kl=6.6009, beta=0.0000\n",
      "Batch 60, loss=0.0318, recon=0.0317, kl=5.6362, beta=0.0000\n",
      "Batch 80, loss=0.0424, recon=0.0423, kl=5.5580, beta=0.0000\n",
      "Batch 100, loss=0.0847, recon=0.0846, kl=7.4505, beta=0.0000\n",
      "Batch 120, loss=0.0287, recon=0.0286, kl=7.1694, beta=0.0000\n",
      "Batch 140, loss=0.0218, recon=0.0217, kl=5.4330, beta=0.0000\n",
      "Batch 160, loss=0.0209, recon=0.0209, kl=4.5903, beta=0.0000\n",
      "Batch 180, loss=0.0182, recon=0.0182, kl=3.6571, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0394, KL: 6.4747, Current Beta: 0.0000) | Avg Valid Loss: 0.0315 | Avg Valid recon Loss: 0.0315\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0238, recon=0.0237, kl=1.4525, beta=0.0000\n",
      "Batch 40, loss=0.0255, recon=0.0254, kl=1.2356, beta=0.0000\n",
      "Batch 60, loss=0.0288, recon=0.0288, kl=1.3326, beta=0.0000\n",
      "Batch 80, loss=0.0226, recon=0.0225, kl=1.2951, beta=0.0000\n",
      "Batch 100, loss=0.1082, recon=0.1082, kl=1.1870, beta=0.0000\n",
      "Batch 120, loss=0.0252, recon=0.0251, kl=1.2893, beta=0.0000\n",
      "Batch 140, loss=0.0370, recon=0.0369, kl=1.7383, beta=0.0000\n",
      "Batch 160, loss=0.0270, recon=0.0270, kl=1.9359, beta=0.0000\n",
      "Batch 180, loss=0.0326, recon=0.0325, kl=2.0960, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0396 (Recon: 0.0395, KL: 1.5267, Current Beta: 0.0000) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0414\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0405, recon=0.0402, kl=3.1238, beta=0.0001\n",
      "Batch 40, loss=0.0405, recon=0.0402, kl=2.1370, beta=0.0001\n",
      "Batch 60, loss=0.0333, recon=0.0331, kl=1.3993, beta=0.0001\n",
      "Batch 80, loss=0.0463, recon=0.0462, kl=1.0168, beta=0.0001\n",
      "Batch 100, loss=0.0270, recon=0.0269, kl=0.6266, beta=0.0001\n",
      "Batch 120, loss=0.0296, recon=0.0296, kl=0.4026, beta=0.0001\n",
      "Batch 140, loss=0.0310, recon=0.0309, kl=0.9351, beta=0.0001\n",
      "Batch 160, loss=0.0474, recon=0.0473, kl=1.0704, beta=0.0001\n",
      "Batch 180, loss=0.0214, recon=0.0213, kl=0.7779, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0414, KL: 1.3783, Current Beta: 0.0001) | Avg Valid Loss: 0.0306 | Avg Valid recon Loss: 0.0306\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0197, recon=0.0196, kl=0.2278, beta=0.0003\n",
      "Batch 40, loss=0.0222, recon=0.0222, kl=0.0590, beta=0.0003\n",
      "Batch 60, loss=0.0280, recon=0.0279, kl=0.0642, beta=0.0003\n",
      "Batch 80, loss=0.0287, recon=0.0286, kl=0.0706, beta=0.0003\n",
      "Batch 100, loss=0.0403, recon=0.0402, kl=0.0371, beta=0.0003\n",
      "Batch 120, loss=0.0263, recon=0.0262, kl=0.0232, beta=0.0003\n",
      "Batch 140, loss=0.0237, recon=0.0237, kl=0.0152, beta=0.0003\n",
      "Batch 160, loss=0.0352, recon=0.0352, kl=0.0114, beta=0.0003\n",
      "Batch 180, loss=0.1931, recon=0.1931, kl=0.0491, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0414, KL: 0.0956, Current Beta: 0.0003) | Avg Valid Loss: 0.1059 | Avg Valid recon Loss: 0.1059\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0842, recon=0.0841, kl=0.1048, beta=0.0008\n",
      "Batch 40, loss=0.0423, recon=0.0422, kl=0.0397, beta=0.0008\n",
      "Batch 60, loss=0.0521, recon=0.0520, kl=0.1138, beta=0.0008\n",
      "Batch 80, loss=0.1061, recon=0.1060, kl=0.0554, beta=0.0008\n",
      "Batch 100, loss=0.0839, recon=0.0836, kl=0.4523, beta=0.0008\n",
      "Batch 120, loss=0.0469, recon=0.0467, kl=0.2367, beta=0.0008\n",
      "Batch 140, loss=0.0355, recon=0.0354, kl=0.0351, beta=0.0008\n",
      "Batch 160, loss=0.0946, recon=0.0946, kl=0.0191, beta=0.0008\n",
      "Batch 180, loss=0.0792, recon=0.0792, kl=0.0193, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0737 (Recon: 0.0736, KL: 0.1228, Current Beta: 0.0008) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0332, recon=0.0332, kl=0.0187, beta=0.0018\n",
      "Batch 40, loss=0.0557, recon=0.0557, kl=0.0264, beta=0.0018\n",
      "Batch 60, loss=0.0478, recon=0.0478, kl=0.0114, beta=0.0018\n",
      "Batch 80, loss=0.0485, recon=0.0485, kl=0.0029, beta=0.0018\n",
      "Batch 100, loss=0.0652, recon=0.0652, kl=0.0015, beta=0.0018\n",
      "Batch 120, loss=0.0355, recon=0.0355, kl=0.0013, beta=0.0018\n",
      "Batch 140, loss=0.0245, recon=0.0245, kl=0.0011, beta=0.0018\n",
      "Batch 160, loss=0.0246, recon=0.0246, kl=0.0003, beta=0.0018\n",
      "Batch 180, loss=0.0206, recon=0.0206, kl=0.0007, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0540, KL: 0.0079, Current Beta: 0.0018) | Avg Valid Loss: 0.0349 | Avg Valid recon Loss: 0.0349\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0310, recon=0.0310, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0243, recon=0.0243, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.0925, recon=0.0925, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0350, recon=0.0350, kl=0.0003, beta=0.0038\n",
      "Batch 100, loss=0.0424, recon=0.0424, kl=0.0004, beta=0.0038\n",
      "Batch 120, loss=0.0215, recon=0.0215, kl=0.0041, beta=0.0038\n",
      "Batch 140, loss=0.0265, recon=0.0265, kl=0.0005, beta=0.0038\n",
      "Batch 160, loss=0.0268, recon=0.0268, kl=0.0004, beta=0.0038\n",
      "Batch 180, loss=0.0268, recon=0.0268, kl=0.0005, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0401 (Recon: 0.0401, KL: 0.0007, Current Beta: 0.0038) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0574, recon=0.0574, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0684, recon=0.0684, kl=0.0002, beta=0.0062\n",
      "Batch 60, loss=0.0279, recon=0.0279, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0168, recon=0.0168, kl=0.0002, beta=0.0062\n",
      "Batch 100, loss=0.0254, recon=0.0254, kl=0.0001, beta=0.0062\n",
      "Batch 120, loss=0.0390, recon=0.0390, kl=0.0004, beta=0.0062\n",
      "Batch 140, loss=0.0333, recon=0.0333, kl=0.0002, beta=0.0062\n",
      "Batch 160, loss=0.0270, recon=0.0270, kl=0.0001, beta=0.0062\n",
      "Batch 180, loss=0.0505, recon=0.0505, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0369 (Recon: 0.0369, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0301 | Avg Valid recon Loss: 0.0301\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0403, recon=0.0403, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0294, recon=0.0294, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0494, recon=0.0494, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0276, recon=0.0276, kl=0.0003, beta=0.0100\n",
      "Batch 100, loss=0.0470, recon=0.0470, kl=0.0003, beta=0.0100\n",
      "Batch 120, loss=0.0243, recon=0.0243, kl=0.0003, beta=0.0100\n",
      "Batch 140, loss=0.0320, recon=0.0320, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0500, recon=0.0500, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0392, recon=0.0392, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0385 (Recon: 0.0385, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0300 | Avg Valid recon Loss: 0.0300\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0386, recon=0.0386, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0192, recon=0.0192, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0279, recon=0.0279, kl=0.0007, beta=0.0100\n",
      "Batch 80, loss=0.0284, recon=0.0284, kl=0.0003, beta=0.0100\n",
      "Batch 100, loss=0.0225, recon=0.0225, kl=0.0003, beta=0.0100\n",
      "Batch 120, loss=0.0352, recon=0.0352, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0456, recon=0.0456, kl=0.0002, beta=0.0100\n",
      "Batch 160, loss=0.0385, recon=0.0385, kl=0.0004, beta=0.0100\n",
      "Batch 180, loss=0.0389, recon=0.0389, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0405, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0498 | Avg Valid recon Loss: 0.0498\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0281, recon=0.0281, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0512, recon=0.0512, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.0942, recon=0.0942, kl=0.0013, beta=0.0100\n",
      "Batch 80, loss=0.0488, recon=0.0488, kl=0.0029, beta=0.0100\n",
      "Batch 100, loss=0.0339, recon=0.0339, kl=0.0009, beta=0.0100\n",
      "Batch 120, loss=0.0442, recon=0.0442, kl=0.0002, beta=0.0100\n",
      "Batch 140, loss=0.0241, recon=0.0241, kl=0.0002, beta=0.0100\n",
      "Batch 160, loss=0.0513, recon=0.0513, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0313, recon=0.0313, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0511 (Recon: 0.0511, KL: 0.0006, Current Beta: 0.0100) | Avg Valid Loss: 0.0325 | Avg Valid recon Loss: 0.0325\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0184, recon=0.0184, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0375, recon=0.0375, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.0644, recon=0.0644, kl=0.0003, beta=0.0100\n",
      "Batch 80, loss=0.0661, recon=0.0661, kl=0.0004, beta=0.0100\n",
      "Batch 100, loss=0.0415, recon=0.0415, kl=0.0019, beta=0.0100\n",
      "Batch 120, loss=0.0344, recon=0.0344, kl=0.0005, beta=0.0100\n",
      "Batch 140, loss=0.0239, recon=0.0239, kl=0.0004, beta=0.0100\n",
      "Batch 160, loss=0.0314, recon=0.0314, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0219, recon=0.0219, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0402 (Recon: 0.0402, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0323 | Avg Valid recon Loss: 0.0323\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0420, recon=0.0420, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0178, recon=0.0178, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0184, recon=0.0184, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0236, recon=0.0236, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0306, recon=0.0306, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0250, recon=0.0250, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0548, recon=0.0548, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0345, recon=0.0345, kl=0.0007, beta=0.0100\n",
      "Batch 180, loss=0.0436, recon=0.0436, kl=0.0016, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0393 (Recon: 0.0393, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0399\n",
      "\n",
      "[VRAE Run 99/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4446, recon=0.4446, kl=0.6761, beta=0.0000\n",
      "Batch 40, loss=0.5343, recon=0.5343, kl=15.2857, beta=0.0000\n",
      "Batch 60, loss=0.2262, recon=0.2262, kl=30.0852, beta=0.0000\n",
      "Batch 80, loss=0.1579, recon=0.1579, kl=40.3745, beta=0.0000\n",
      "Batch 100, loss=0.2356, recon=0.2356, kl=49.1111, beta=0.0000\n",
      "Batch 120, loss=0.2138, recon=0.2138, kl=55.2736, beta=0.0000\n",
      "Batch 140, loss=0.1180, recon=0.1180, kl=61.8430, beta=0.0000\n",
      "Batch 160, loss=0.0766, recon=0.0766, kl=64.3218, beta=0.0000\n",
      "Batch 180, loss=0.1342, recon=0.1342, kl=64.4352, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2922 (Recon: 0.2922, KL: 39.0105, Current Beta: 0.0000) | Avg Valid Loss: 0.1271 | Avg Valid recon Loss: 0.1271\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0818, recon=0.0818, kl=65.7115, beta=0.0000\n",
      "Batch 40, loss=0.1025, recon=0.1025, kl=67.8564, beta=0.0000\n",
      "Batch 60, loss=0.1806, recon=0.1806, kl=70.4821, beta=0.0000\n",
      "Batch 80, loss=0.0919, recon=0.0919, kl=71.6298, beta=0.0000\n",
      "Batch 100, loss=0.1133, recon=0.1133, kl=75.2427, beta=0.0000\n",
      "Batch 120, loss=0.1398, recon=0.1398, kl=77.1562, beta=0.0000\n",
      "Batch 140, loss=0.0705, recon=0.0705, kl=79.4249, beta=0.0000\n",
      "Batch 160, loss=0.1319, recon=0.1319, kl=80.3223, beta=0.0000\n",
      "Batch 180, loss=0.0962, recon=0.0962, kl=82.2785, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1269 (Recon: 0.1269, KL: 73.4701, Current Beta: 0.0000) | Avg Valid Loss: 0.0907 | Avg Valid recon Loss: 0.0907\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1062, recon=0.1061, kl=81.4208, beta=0.0000\n",
      "Batch 40, loss=0.0617, recon=0.0617, kl=81.2963, beta=0.0000\n",
      "Batch 60, loss=0.1175, recon=0.1175, kl=81.2957, beta=0.0000\n",
      "Batch 80, loss=0.1039, recon=0.1039, kl=81.5257, beta=0.0000\n",
      "Batch 100, loss=0.0763, recon=0.0763, kl=80.8037, beta=0.0000\n",
      "Batch 120, loss=0.0650, recon=0.0650, kl=80.9496, beta=0.0000\n",
      "Batch 140, loss=0.0824, recon=0.0824, kl=81.0702, beta=0.0000\n",
      "Batch 160, loss=0.0743, recon=0.0743, kl=83.7840, beta=0.0000\n",
      "Batch 180, loss=0.0526, recon=0.0526, kl=82.8852, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0973 (Recon: 0.0973, KL: 81.5239, Current Beta: 0.0000) | Avg Valid Loss: 0.0757 | Avg Valid recon Loss: 0.0757\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0726, recon=0.0725, kl=80.2358, beta=0.0000\n",
      "Batch 40, loss=0.0519, recon=0.0518, kl=76.7397, beta=0.0000\n",
      "Batch 60, loss=0.0651, recon=0.0651, kl=72.8230, beta=0.0000\n",
      "Batch 80, loss=0.0480, recon=0.0480, kl=71.8925, beta=0.0000\n",
      "Batch 100, loss=0.0481, recon=0.0481, kl=69.2753, beta=0.0000\n",
      "Batch 120, loss=0.0601, recon=0.0601, kl=69.3272, beta=0.0000\n",
      "Batch 140, loss=0.2156, recon=0.2156, kl=67.4146, beta=0.0000\n",
      "Batch 160, loss=0.0743, recon=0.0743, kl=68.7594, beta=0.0000\n",
      "Batch 180, loss=0.0457, recon=0.0457, kl=66.3620, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0816 (Recon: 0.0815, KL: 72.3265, Current Beta: 0.0000) | Avg Valid Loss: 0.0656 | Avg Valid recon Loss: 0.0655\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0527, recon=0.0527, kl=60.5786, beta=0.0000\n",
      "Batch 40, loss=0.1269, recon=0.1269, kl=54.3933, beta=0.0000\n",
      "Batch 60, loss=0.0463, recon=0.0462, kl=49.4132, beta=0.0000\n",
      "Batch 80, loss=0.0628, recon=0.0628, kl=45.8044, beta=0.0000\n",
      "Batch 100, loss=0.0729, recon=0.0729, kl=44.7421, beta=0.0000\n",
      "Batch 120, loss=0.0483, recon=0.0482, kl=44.3946, beta=0.0000\n",
      "Batch 140, loss=0.0621, recon=0.0620, kl=45.0436, beta=0.0000\n",
      "Batch 160, loss=0.0543, recon=0.0543, kl=44.0117, beta=0.0000\n",
      "Batch 180, loss=0.0522, recon=0.0522, kl=43.5783, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0717 (Recon: 0.0716, KL: 49.1468, Current Beta: 0.0000) | Avg Valid Loss: 0.0606 | Avg Valid recon Loss: 0.0605\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0551, recon=0.0550, kl=36.1593, beta=0.0000\n",
      "Batch 40, loss=0.0388, recon=0.0387, kl=26.0619, beta=0.0000\n",
      "Batch 60, loss=0.0455, recon=0.0454, kl=25.5969, beta=0.0000\n",
      "Batch 80, loss=0.0813, recon=0.0813, kl=23.8626, beta=0.0000\n",
      "Batch 100, loss=0.0496, recon=0.0495, kl=23.3462, beta=0.0000\n",
      "Batch 120, loss=0.0364, recon=0.0363, kl=24.3475, beta=0.0000\n",
      "Batch 140, loss=0.0467, recon=0.0466, kl=21.3645, beta=0.0000\n",
      "Batch 160, loss=0.0451, recon=0.0451, kl=20.7827, beta=0.0000\n",
      "Batch 180, loss=0.0484, recon=0.0484, kl=20.4289, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0655 (Recon: 0.0654, KL: 25.8756, Current Beta: 0.0000) | Avg Valid Loss: 0.0569 | Avg Valid recon Loss: 0.0569\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0308, recon=0.0307, kl=12.1635, beta=0.0000\n",
      "Batch 40, loss=0.0405, recon=0.0404, kl=11.2788, beta=0.0000\n",
      "Batch 60, loss=0.0717, recon=0.0716, kl=10.7433, beta=0.0000\n",
      "Batch 80, loss=0.0418, recon=0.0418, kl=10.4212, beta=0.0000\n",
      "Batch 100, loss=0.0699, recon=0.0699, kl=10.9278, beta=0.0000\n",
      "Batch 120, loss=0.0387, recon=0.0387, kl=9.8641, beta=0.0000\n",
      "Batch 140, loss=0.0377, recon=0.0377, kl=9.7734, beta=0.0000\n",
      "Batch 160, loss=0.0554, recon=0.0553, kl=8.7099, beta=0.0000\n",
      "Batch 180, loss=0.0381, recon=0.0381, kl=8.6862, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0610 (Recon: 0.0609, KL: 10.9792, Current Beta: 0.0000) | Avg Valid Loss: 0.0523 | Avg Valid recon Loss: 0.0522\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0511, recon=0.0511, kl=4.0343, beta=0.0000\n",
      "Batch 40, loss=0.0341, recon=0.0340, kl=4.3139, beta=0.0000\n",
      "Batch 60, loss=0.0431, recon=0.0430, kl=4.0680, beta=0.0000\n",
      "Batch 80, loss=0.0394, recon=0.0393, kl=3.8236, beta=0.0000\n",
      "Batch 100, loss=0.0358, recon=0.0358, kl=3.5443, beta=0.0000\n",
      "Batch 120, loss=0.0507, recon=0.0507, kl=3.4331, beta=0.0000\n",
      "Batch 140, loss=0.0527, recon=0.0526, kl=3.0880, beta=0.0000\n",
      "Batch 160, loss=0.0346, recon=0.0345, kl=2.9324, beta=0.0000\n",
      "Batch 180, loss=0.0481, recon=0.0481, kl=3.0710, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0580 (Recon: 0.0579, KL: 3.9408, Current Beta: 0.0000) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0434, recon=0.0433, kl=1.2616, beta=0.0000\n",
      "Batch 40, loss=0.0318, recon=0.0317, kl=1.4230, beta=0.0000\n",
      "Batch 60, loss=0.0553, recon=0.0553, kl=1.4637, beta=0.0000\n",
      "Batch 80, loss=0.0371, recon=0.0370, kl=0.9291, beta=0.0000\n",
      "Batch 100, loss=0.0373, recon=0.0373, kl=1.1390, beta=0.0000\n",
      "Batch 120, loss=0.0389, recon=0.0389, kl=0.8283, beta=0.0000\n",
      "Batch 140, loss=0.0408, recon=0.0408, kl=1.1293, beta=0.0000\n",
      "Batch 160, loss=0.0420, recon=0.0419, kl=0.8653, beta=0.0000\n",
      "Batch 180, loss=0.0333, recon=0.0333, kl=0.7950, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 1.2390, Current Beta: 0.0000) | Avg Valid Loss: 0.0481 | Avg Valid recon Loss: 0.0480\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0422, recon=0.0422, kl=0.2042, beta=0.0001\n",
      "Batch 40, loss=0.0345, recon=0.0345, kl=0.2089, beta=0.0001\n",
      "Batch 60, loss=0.0303, recon=0.0303, kl=0.2704, beta=0.0001\n",
      "Batch 80, loss=0.0730, recon=0.0730, kl=0.1178, beta=0.0001\n",
      "Batch 100, loss=0.0414, recon=0.0414, kl=0.1171, beta=0.0001\n",
      "Batch 120, loss=0.0379, recon=0.0379, kl=0.1242, beta=0.0001\n",
      "Batch 140, loss=0.0391, recon=0.0391, kl=0.1508, beta=0.0001\n",
      "Batch 160, loss=0.0383, recon=0.0382, kl=0.1363, beta=0.0001\n",
      "Batch 180, loss=0.0332, recon=0.0332, kl=0.0823, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0531 (Recon: 0.0531, KL: 0.1888, Current Beta: 0.0001) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0458\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0692, recon=0.0692, kl=0.0090, beta=0.0003\n",
      "Batch 40, loss=0.0300, recon=0.0300, kl=0.0102, beta=0.0003\n",
      "Batch 60, loss=0.0771, recon=0.0771, kl=0.0121, beta=0.0003\n",
      "Batch 80, loss=0.0237, recon=0.0237, kl=0.0081, beta=0.0003\n",
      "Batch 100, loss=0.0449, recon=0.0449, kl=0.0125, beta=0.0003\n",
      "Batch 120, loss=0.0334, recon=0.0334, kl=0.0225, beta=0.0003\n",
      "Batch 140, loss=0.0423, recon=0.0423, kl=0.0030, beta=0.0003\n",
      "Batch 160, loss=0.0323, recon=0.0323, kl=0.0042, beta=0.0003\n",
      "Batch 180, loss=0.0284, recon=0.0284, kl=0.0057, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0510 (Recon: 0.0509, KL: 0.0130, Current Beta: 0.0003) | Avg Valid Loss: 0.0447 | Avg Valid recon Loss: 0.0447\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0855, recon=0.0855, kl=0.0032, beta=0.0008\n",
      "Batch 40, loss=0.0255, recon=0.0255, kl=0.0009, beta=0.0008\n",
      "Batch 60, loss=0.0251, recon=0.0251, kl=0.0007, beta=0.0008\n",
      "Batch 80, loss=0.0369, recon=0.0369, kl=0.0016, beta=0.0008\n",
      "Batch 100, loss=0.0367, recon=0.0367, kl=0.0009, beta=0.0008\n",
      "Batch 120, loss=0.0402, recon=0.0402, kl=0.0008, beta=0.0008\n",
      "Batch 140, loss=0.0363, recon=0.0363, kl=0.0006, beta=0.0008\n",
      "Batch 160, loss=0.0260, recon=0.0260, kl=0.0007, beta=0.0008\n",
      "Batch 180, loss=0.0345, recon=0.0345, kl=0.0005, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0493 (Recon: 0.0493, KL: 0.0014, Current Beta: 0.0008) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=0.0004, beta=0.0018\n",
      "Batch 40, loss=0.0352, recon=0.0352, kl=0.0003, beta=0.0018\n",
      "Batch 60, loss=0.0319, recon=0.0319, kl=0.0006, beta=0.0018\n",
      "Batch 80, loss=0.0525, recon=0.0525, kl=0.0003, beta=0.0018\n",
      "Batch 100, loss=0.0391, recon=0.0391, kl=0.0003, beta=0.0018\n",
      "Batch 120, loss=0.0400, recon=0.0400, kl=0.0007, beta=0.0018\n",
      "Batch 140, loss=0.0494, recon=0.0494, kl=0.0003, beta=0.0018\n",
      "Batch 160, loss=0.0425, recon=0.0425, kl=0.0004, beta=0.0018\n",
      "Batch 180, loss=0.1407, recon=0.1407, kl=0.0004, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0478 (Recon: 0.0478, KL: 0.0004, Current Beta: 0.0018) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0304, recon=0.0304, kl=0.0002, beta=0.0038\n",
      "Batch 40, loss=0.0346, recon=0.0346, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.0351, recon=0.0351, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0487, recon=0.0487, kl=0.0006, beta=0.0038\n",
      "Batch 100, loss=0.0299, recon=0.0299, kl=0.0002, beta=0.0038\n",
      "Batch 120, loss=0.0429, recon=0.0429, kl=0.0002, beta=0.0038\n",
      "Batch 140, loss=0.0329, recon=0.0329, kl=0.0002, beta=0.0038\n",
      "Batch 160, loss=0.0356, recon=0.0356, kl=0.0001, beta=0.0038\n",
      "Batch 180, loss=0.0260, recon=0.0260, kl=0.0003, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0465 (Recon: 0.0465, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.7315, recon=0.7315, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0389, recon=0.0389, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0432, recon=0.0432, kl=0.0002, beta=0.0062\n",
      "Batch 80, loss=0.0352, recon=0.0352, kl=0.0001, beta=0.0062\n",
      "Batch 100, loss=0.0282, recon=0.0282, kl=0.0001, beta=0.0062\n",
      "Batch 120, loss=0.0196, recon=0.0196, kl=0.0000, beta=0.0062\n",
      "Batch 140, loss=0.0296, recon=0.0296, kl=0.0001, beta=0.0062\n",
      "Batch 160, loss=0.0312, recon=0.0312, kl=0.0000, beta=0.0062\n",
      "Batch 180, loss=0.0241, recon=0.0241, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0453 (Recon: 0.0453, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0393 | Avg Valid recon Loss: 0.0393\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0272, recon=0.0272, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0422, recon=0.0421, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0425, recon=0.0425, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.1231, recon=0.1231, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0281, recon=0.0281, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0493, recon=0.0493, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0290, recon=0.0290, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0340, recon=0.0340, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0433, recon=0.0433, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0441 (Recon: 0.0441, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0386 | Avg Valid recon Loss: 0.0386\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0362, recon=0.0362, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0308, recon=0.0308, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.1622, recon=0.1622, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0404, recon=0.0404, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0234, recon=0.0234, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0815, recon=0.0815, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0266, recon=0.0266, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0606, recon=0.0606, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0279, recon=0.0279, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0328, recon=0.0328, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0278, recon=0.0278, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0524, recon=0.0524, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0490, recon=0.0490, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0295, recon=0.0295, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0342, recon=0.0342, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0333, recon=0.0333, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0253, recon=0.0253, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0408, recon=0.0408, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0424, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0659, recon=0.0659, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0300, recon=0.0300, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0315, recon=0.0315, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0266, recon=0.0266, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0224, recon=0.0224, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0237, recon=0.0237, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0409, recon=0.0409, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0457, recon=0.0457, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0415, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0319, recon=0.0319, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0214, recon=0.0214, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0278, recon=0.0278, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0314, recon=0.0314, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0226, recon=0.0226, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0236, recon=0.0235, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0179, recon=0.0179, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0380, recon=0.0380, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0428, recon=0.0428, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0408 (Recon: 0.0408, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "\n",
      "[VRAE Run 100/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1816, recon=0.1816, kl=32.1853, beta=0.0000\n",
      "Batch 40, loss=0.1220, recon=0.1220, kl=45.3807, beta=0.0000\n",
      "Batch 60, loss=0.0682, recon=0.0682, kl=51.0573, beta=0.0000\n",
      "Batch 80, loss=0.0705, recon=0.0705, kl=55.9627, beta=0.0000\n",
      "Batch 100, loss=0.0510, recon=0.0510, kl=56.0639, beta=0.0000\n",
      "Batch 120, loss=0.0409, recon=0.0409, kl=57.8892, beta=0.0000\n",
      "Batch 140, loss=0.0576, recon=0.0576, kl=65.4575, beta=0.0000\n",
      "Batch 160, loss=0.0609, recon=0.0609, kl=43.5699, beta=0.0000\n",
      "Batch 180, loss=0.0975, recon=0.0975, kl=58.0857, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1296 (Recon: 0.1296, KL: 48.8408, Current Beta: 0.0000) | Avg Valid Loss: 0.0651 | Avg Valid recon Loss: 0.0651\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0623, recon=0.0623, kl=69.9951, beta=0.0000\n",
      "Batch 40, loss=0.1037, recon=0.1037, kl=64.3436, beta=0.0000\n",
      "Batch 60, loss=0.0383, recon=0.0383, kl=53.7942, beta=0.0000\n",
      "Batch 80, loss=0.0459, recon=0.0459, kl=54.8773, beta=0.0000\n",
      "Batch 100, loss=0.0708, recon=0.0708, kl=55.9435, beta=0.0000\n",
      "Batch 120, loss=0.1031, recon=0.1031, kl=58.5058, beta=0.0000\n",
      "Batch 140, loss=0.0515, recon=0.0515, kl=64.5859, beta=0.0000\n",
      "Batch 160, loss=0.0418, recon=0.0418, kl=62.9125, beta=0.0000\n",
      "Batch 180, loss=0.0496, recon=0.0496, kl=58.5753, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0632 (Recon: 0.0632, KL: 60.5472, Current Beta: 0.0000) | Avg Valid Loss: 0.0515 | Avg Valid recon Loss: 0.0515\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0681, recon=0.0681, kl=61.2285, beta=0.0000\n",
      "Batch 40, loss=0.0295, recon=0.0295, kl=60.9048, beta=0.0000\n",
      "Batch 60, loss=0.0380, recon=0.0380, kl=61.5699, beta=0.0000\n",
      "Batch 80, loss=0.0488, recon=0.0488, kl=66.7621, beta=0.0000\n",
      "Batch 100, loss=0.0375, recon=0.0375, kl=59.3034, beta=0.0000\n",
      "Batch 120, loss=0.0488, recon=0.0488, kl=59.3358, beta=0.0000\n",
      "Batch 140, loss=0.0532, recon=0.0532, kl=61.6769, beta=0.0000\n",
      "Batch 160, loss=0.0274, recon=0.0274, kl=77.2571, beta=0.0000\n",
      "Batch 180, loss=0.0380, recon=0.0380, kl=65.6885, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0506 (Recon: 0.0506, KL: 63.3567, Current Beta: 0.0000) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0458\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0268, recon=0.0267, kl=67.5284, beta=0.0000\n",
      "Batch 40, loss=0.0324, recon=0.0324, kl=70.2680, beta=0.0000\n",
      "Batch 60, loss=0.0392, recon=0.0392, kl=68.3478, beta=0.0000\n",
      "Batch 80, loss=0.0340, recon=0.0340, kl=69.5481, beta=0.0000\n",
      "Batch 100, loss=0.0293, recon=0.0293, kl=70.3650, beta=0.0000\n",
      "Batch 120, loss=0.0251, recon=0.0251, kl=40.6069, beta=0.0000\n",
      "Batch 140, loss=0.0340, recon=0.0340, kl=74.9745, beta=0.0000\n",
      "Batch 160, loss=0.0333, recon=0.0333, kl=70.4409, beta=0.0000\n",
      "Batch 180, loss=0.0466, recon=0.0466, kl=64.5906, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0481 (Recon: 0.0481, KL: 68.0020, Current Beta: 0.0000) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0348, recon=0.0348, kl=56.7999, beta=0.0000\n",
      "Batch 40, loss=0.0768, recon=0.0767, kl=35.1886, beta=0.0000\n",
      "Batch 60, loss=0.0792, recon=0.0792, kl=49.5286, beta=0.0000\n",
      "Batch 80, loss=0.0423, recon=0.0422, kl=51.9355, beta=0.0000\n",
      "Batch 100, loss=0.0727, recon=0.0727, kl=49.0841, beta=0.0000\n",
      "Batch 120, loss=0.0480, recon=0.0479, kl=50.1492, beta=0.0000\n",
      "Batch 140, loss=0.0315, recon=0.0315, kl=49.8827, beta=0.0000\n",
      "Batch 160, loss=0.0280, recon=0.0279, kl=49.5526, beta=0.0000\n",
      "Batch 180, loss=0.0398, recon=0.0398, kl=49.9707, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0480, KL: 50.2143, Current Beta: 0.0000) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0361, recon=0.0360, kl=34.2260, beta=0.0000\n",
      "Batch 40, loss=0.1489, recon=0.1488, kl=45.2272, beta=0.0000\n",
      "Batch 60, loss=0.0214, recon=0.0214, kl=36.5628, beta=0.0000\n",
      "Batch 80, loss=0.0414, recon=0.0413, kl=38.3733, beta=0.0000\n",
      "Batch 100, loss=0.0526, recon=0.0525, kl=36.9044, beta=0.0000\n",
      "Batch 120, loss=0.0490, recon=0.0489, kl=42.4737, beta=0.0000\n",
      "Batch 140, loss=0.0653, recon=0.0652, kl=39.4298, beta=0.0000\n",
      "Batch 160, loss=0.0330, recon=0.0329, kl=33.9839, beta=0.0000\n",
      "Batch 180, loss=0.0234, recon=0.0234, kl=33.9552, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0469, KL: 38.4268, Current Beta: 0.0000) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.5686, recon=0.5685, kl=19.6340, beta=0.0000\n",
      "Batch 40, loss=0.0435, recon=0.0433, kl=39.7320, beta=0.0000\n",
      "Batch 60, loss=0.0385, recon=0.0383, kl=30.5393, beta=0.0000\n",
      "Batch 80, loss=0.0456, recon=0.0455, kl=26.1850, beta=0.0000\n",
      "Batch 100, loss=0.0275, recon=0.0273, kl=28.9140, beta=0.0000\n",
      "Batch 120, loss=0.0276, recon=0.0274, kl=23.2622, beta=0.0000\n",
      "Batch 140, loss=0.0289, recon=0.0288, kl=21.6432, beta=0.0000\n",
      "Batch 160, loss=0.0263, recon=0.0262, kl=20.1636, beta=0.0000\n",
      "Batch 180, loss=0.0270, recon=0.0269, kl=20.5284, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0460, KL: 26.3175, Current Beta: 0.0000) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0299, recon=0.0298, kl=10.5137, beta=0.0000\n",
      "Batch 40, loss=0.0248, recon=0.0246, kl=14.4410, beta=0.0000\n",
      "Batch 60, loss=0.1186, recon=0.1184, kl=9.9884, beta=0.0000\n",
      "Batch 80, loss=0.0249, recon=0.0248, kl=10.0431, beta=0.0000\n",
      "Batch 100, loss=0.0232, recon=0.0230, kl=11.0893, beta=0.0000\n",
      "Batch 120, loss=0.0577, recon=0.0575, kl=11.8112, beta=0.0000\n",
      "Batch 140, loss=0.0557, recon=0.0555, kl=14.2997, beta=0.0000\n",
      "Batch 160, loss=0.0458, recon=0.0455, kl=18.5832, beta=0.0000\n",
      "Batch 180, loss=0.0336, recon=0.0333, kl=21.2713, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0515 (Recon: 0.0513, KL: 13.6251, Current Beta: 0.0000) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0324, recon=0.0320, kl=8.4677, beta=0.0000\n",
      "Batch 40, loss=0.0239, recon=0.0235, kl=8.8578, beta=0.0000\n",
      "Batch 60, loss=0.0315, recon=0.0310, kl=11.5489, beta=0.0000\n",
      "Batch 80, loss=0.0271, recon=0.0268, kl=9.5157, beta=0.0000\n",
      "Batch 100, loss=0.6161, recon=0.6157, kl=8.4323, beta=0.0000\n",
      "Batch 120, loss=0.0798, recon=0.0795, kl=8.5418, beta=0.0000\n",
      "Batch 140, loss=0.0236, recon=0.0232, kl=8.1746, beta=0.0000\n",
      "Batch 160, loss=0.0452, recon=0.0449, kl=6.7963, beta=0.0000\n",
      "Batch 180, loss=0.0429, recon=0.0426, kl=6.0668, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0507 (Recon: 0.0503, KL: 9.0578, Current Beta: 0.0000) | Avg Valid Loss: 0.0447 | Avg Valid recon Loss: 0.0445\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0253, recon=0.0246, kl=6.2966, beta=0.0001\n",
      "Batch 40, loss=0.0339, recon=0.0334, kl=4.7936, beta=0.0001\n",
      "Batch 60, loss=0.0262, recon=0.0258, kl=3.4036, beta=0.0001\n",
      "Batch 80, loss=0.0284, recon=0.0282, kl=1.4449, beta=0.0001\n",
      "Batch 100, loss=0.0381, recon=0.0380, kl=1.1952, beta=0.0001\n",
      "Batch 120, loss=0.0302, recon=0.0301, kl=0.7686, beta=0.0001\n",
      "Batch 140, loss=0.1004, recon=0.1003, kl=0.2716, beta=0.0001\n",
      "Batch 160, loss=0.0262, recon=0.0262, kl=0.4868, beta=0.0001\n",
      "Batch 180, loss=0.0274, recon=0.0273, kl=0.6945, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0412 (Recon: 0.0410, KL: 2.4142, Current Beta: 0.0001) | Avg Valid Loss: 0.0328 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0325, recon=0.0324, kl=0.1481, beta=0.0003\n",
      "Batch 40, loss=0.0237, recon=0.0236, kl=0.1209, beta=0.0003\n",
      "Batch 60, loss=0.0290, recon=0.0290, kl=0.0643, beta=0.0003\n",
      "Batch 80, loss=0.0387, recon=0.0387, kl=0.0425, beta=0.0003\n",
      "Batch 100, loss=0.0295, recon=0.0294, kl=0.0423, beta=0.0003\n",
      "Batch 120, loss=0.0349, recon=0.0348, kl=0.1154, beta=0.0003\n",
      "Batch 140, loss=0.0328, recon=0.0328, kl=0.2895, beta=0.0003\n",
      "Batch 160, loss=0.0476, recon=0.0476, kl=0.0611, beta=0.0003\n",
      "Batch 180, loss=0.0344, recon=0.0344, kl=0.0458, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0364 (Recon: 0.0363, KL: 0.1340, Current Beta: 0.0003) | Avg Valid Loss: 0.0469 | Avg Valid recon Loss: 0.0469\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0580, recon=0.0579, kl=0.0191, beta=0.0008\n",
      "Batch 40, loss=0.0721, recon=0.0719, kl=0.1755, beta=0.0008\n",
      "Batch 60, loss=0.0504, recon=0.0502, kl=0.2429, beta=0.0008\n",
      "Batch 80, loss=0.0295, recon=0.0295, kl=0.0446, beta=0.0008\n",
      "Batch 100, loss=0.0469, recon=0.0469, kl=0.0579, beta=0.0008\n",
      "Batch 120, loss=0.0313, recon=0.0313, kl=0.0068, beta=0.0008\n",
      "Batch 140, loss=0.0285, recon=0.0285, kl=0.0153, beta=0.0008\n",
      "Batch 160, loss=0.0342, recon=0.0342, kl=0.0063, beta=0.0008\n",
      "Batch 180, loss=0.0331, recon=0.0331, kl=0.0060, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0520 (Recon: 0.0520, KL: 0.0613, Current Beta: 0.0008) | Avg Valid Loss: 0.0349 | Avg Valid recon Loss: 0.0349\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0291, recon=0.0291, kl=0.0029, beta=0.0018\n",
      "Batch 40, loss=0.0232, recon=0.0232, kl=0.0010, beta=0.0018\n",
      "Batch 60, loss=0.0470, recon=0.0470, kl=0.0027, beta=0.0018\n",
      "Batch 80, loss=0.0550, recon=0.0550, kl=0.0044, beta=0.0018\n",
      "Batch 100, loss=0.0595, recon=0.0595, kl=0.0036, beta=0.0018\n",
      "Batch 120, loss=0.0320, recon=0.0320, kl=0.0053, beta=0.0018\n",
      "Batch 140, loss=0.0273, recon=0.0273, kl=0.0109, beta=0.0018\n",
      "Batch 160, loss=0.0274, recon=0.0274, kl=0.0033, beta=0.0018\n",
      "Batch 180, loss=0.0346, recon=0.0345, kl=0.0039, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0393 (Recon: 0.0393, KL: 0.0044, Current Beta: 0.0018) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0530, recon=0.0530, kl=0.0081, beta=0.0038\n",
      "Batch 40, loss=0.0281, recon=0.0280, kl=0.0066, beta=0.0038\n",
      "Batch 60, loss=0.0345, recon=0.0345, kl=0.0083, beta=0.0038\n",
      "Batch 80, loss=0.0384, recon=0.0383, kl=0.0029, beta=0.0038\n",
      "Batch 100, loss=0.0201, recon=0.0201, kl=0.0010, beta=0.0038\n",
      "Batch 120, loss=0.1477, recon=0.1477, kl=0.0005, beta=0.0038\n",
      "Batch 140, loss=0.0181, recon=0.0181, kl=0.0018, beta=0.0038\n",
      "Batch 160, loss=0.0278, recon=0.0278, kl=0.0004, beta=0.0038\n",
      "Batch 180, loss=0.0249, recon=0.0249, kl=0.0006, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0428, KL: 0.0037, Current Beta: 0.0038) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0389, recon=0.0389, kl=0.0009, beta=0.0062\n",
      "Batch 40, loss=0.0362, recon=0.0362, kl=0.0007, beta=0.0062\n",
      "Batch 60, loss=0.0211, recon=0.0211, kl=0.0004, beta=0.0062\n",
      "Batch 80, loss=0.0236, recon=0.0236, kl=0.0002, beta=0.0062\n",
      "Batch 100, loss=0.0240, recon=0.0240, kl=0.0002, beta=0.0062\n",
      "Batch 120, loss=0.0279, recon=0.0279, kl=0.0001, beta=0.0062\n",
      "Batch 140, loss=0.0202, recon=0.0202, kl=0.0001, beta=0.0062\n",
      "Batch 160, loss=0.0549, recon=0.0549, kl=0.0004, beta=0.0062\n",
      "Batch 180, loss=0.1072, recon=0.1071, kl=0.0144, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 0.0013, Current Beta: 0.0062) | Avg Valid Loss: 0.0774 | Avg Valid recon Loss: 0.0772\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0882, recon=0.0877, kl=0.0452, beta=0.0100\n",
      "Batch 40, loss=0.0953, recon=0.0928, kl=0.2526, beta=0.0100\n",
      "Batch 60, loss=0.0408, recon=0.0403, kl=0.0518, beta=0.0100\n",
      "Batch 80, loss=0.0490, recon=0.0488, kl=0.0156, beta=0.0100\n",
      "Batch 100, loss=0.0609, recon=0.0609, kl=0.0055, beta=0.0100\n",
      "Batch 120, loss=0.0377, recon=0.0376, kl=0.0019, beta=0.0100\n",
      "Batch 140, loss=0.1036, recon=0.1036, kl=0.0007, beta=0.0100\n",
      "Batch 160, loss=0.0459, recon=0.0459, kl=0.0006, beta=0.0100\n",
      "Batch 180, loss=0.0238, recon=0.0238, kl=0.0004, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0681 (Recon: 0.0678, KL: 0.0331, Current Beta: 0.0100) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0307, recon=0.0307, kl=0.0005, beta=0.0100\n",
      "Batch 40, loss=0.0218, recon=0.0218, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0170, recon=0.0169, kl=0.0039, beta=0.0100\n",
      "Batch 80, loss=0.0374, recon=0.0374, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0369, recon=0.0369, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0306, recon=0.0306, kl=0.0005, beta=0.0100\n",
      "Batch 140, loss=0.0488, recon=0.0488, kl=0.0076, beta=0.0100\n",
      "Batch 160, loss=0.0321, recon=0.0321, kl=0.0003, beta=0.0100\n",
      "Batch 180, loss=0.0260, recon=0.0260, kl=0.0004, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0394 (Recon: 0.0394, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0252, recon=0.0252, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0223, recon=0.0223, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0253, recon=0.0253, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0248, recon=0.0248, kl=0.0017, beta=0.0100\n",
      "Batch 100, loss=0.0228, recon=0.0228, kl=0.0010, beta=0.0100\n",
      "Batch 120, loss=0.0175, recon=0.0175, kl=0.0004, beta=0.0100\n",
      "Batch 140, loss=0.0462, recon=0.0462, kl=0.0002, beta=0.0100\n",
      "Batch 160, loss=0.0255, recon=0.0255, kl=0.0002, beta=0.0100\n",
      "Batch 180, loss=0.0349, recon=0.0349, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0354, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0386\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0323, recon=0.0323, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0410, recon=0.0410, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0232, recon=0.0232, kl=0.0003, beta=0.0100\n",
      "Batch 80, loss=0.0267, recon=0.0267, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0208, recon=0.0208, kl=0.0002, beta=0.0100\n",
      "Batch 120, loss=0.0488, recon=0.0488, kl=0.0003, beta=0.0100\n",
      "Batch 140, loss=0.0439, recon=0.0439, kl=0.0037, beta=0.0100\n",
      "Batch 160, loss=0.0319, recon=0.0319, kl=0.0009, beta=0.0100\n",
      "Batch 180, loss=0.0186, recon=0.0186, kl=0.0007, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0429, KL: 0.0007, Current Beta: 0.0100) | Avg Valid Loss: 0.0336 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0211, recon=0.0211, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0199, recon=0.0199, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0221, recon=0.0221, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0339, recon=0.0338, kl=0.0141, beta=0.0100\n",
      "Batch 100, loss=0.0374, recon=0.0374, kl=0.0006, beta=0.0100\n",
      "Batch 120, loss=0.0289, recon=0.0289, kl=0.0023, beta=0.0100\n",
      "Batch 140, loss=0.0236, recon=0.0236, kl=0.0003, beta=0.0100\n",
      "Batch 160, loss=0.0294, recon=0.0294, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0310, recon=0.0310, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0354, KL: 0.0015, Current Beta: 0.0100) | Avg Valid Loss: 0.0290 | Avg Valid recon Loss: 0.0290\n",
      "\n",
      "[VRAE Run 101/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4045, recon=0.4045, kl=1.3776, beta=0.0000\n",
      "Batch 40, loss=0.2103, recon=0.2103, kl=31.7041, beta=0.0000\n",
      "Batch 60, loss=0.5521, recon=0.5521, kl=65.6888, beta=0.0000\n",
      "Batch 80, loss=0.1641, recon=0.1641, kl=85.7663, beta=0.0000\n",
      "Batch 100, loss=0.1492, recon=0.1492, kl=101.3806, beta=0.0000\n",
      "Batch 120, loss=0.1318, recon=0.1318, kl=112.2324, beta=0.0000\n",
      "Batch 140, loss=0.1077, recon=0.1076, kl=121.9089, beta=0.0000\n",
      "Batch 160, loss=0.1720, recon=0.1720, kl=127.0662, beta=0.0000\n",
      "Batch 180, loss=0.0959, recon=0.0959, kl=128.1377, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3040 (Recon: 0.3040, KL: 79.4322, Current Beta: 0.0000) | Avg Valid Loss: 0.1295 | Avg Valid recon Loss: 0.1295\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2532, recon=0.2532, kl=130.3428, beta=0.0000\n",
      "Batch 40, loss=0.1190, recon=0.1190, kl=133.9667, beta=0.0000\n",
      "Batch 60, loss=0.1294, recon=0.1294, kl=134.0802, beta=0.0000\n",
      "Batch 80, loss=0.1274, recon=0.1274, kl=137.4432, beta=0.0000\n",
      "Batch 100, loss=0.1133, recon=0.1133, kl=138.8035, beta=0.0000\n",
      "Batch 120, loss=0.0923, recon=0.0923, kl=140.7672, beta=0.0000\n",
      "Batch 140, loss=0.0972, recon=0.0972, kl=142.8454, beta=0.0000\n",
      "Batch 160, loss=0.2353, recon=0.2353, kl=147.5748, beta=0.0000\n",
      "Batch 180, loss=0.0932, recon=0.0932, kl=146.5287, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1271 (Recon: 0.1271, KL: 138.2856, Current Beta: 0.0000) | Avg Valid Loss: 0.0905 | Avg Valid recon Loss: 0.0905\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0436, recon=0.0435, kl=143.3556, beta=0.0000\n",
      "Batch 40, loss=0.0712, recon=0.0712, kl=144.3161, beta=0.0000\n",
      "Batch 60, loss=0.0699, recon=0.0698, kl=144.3527, beta=0.0000\n",
      "Batch 80, loss=0.1219, recon=0.1219, kl=141.2989, beta=0.0000\n",
      "Batch 100, loss=0.0873, recon=0.0873, kl=139.1622, beta=0.0000\n",
      "Batch 120, loss=0.0549, recon=0.0549, kl=137.6407, beta=0.0000\n",
      "Batch 140, loss=0.1319, recon=0.1319, kl=137.1915, beta=0.0000\n",
      "Batch 160, loss=0.0716, recon=0.0716, kl=138.6947, beta=0.0000\n",
      "Batch 180, loss=0.1021, recon=0.1021, kl=138.3850, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0945 (Recon: 0.0945, KL: 140.9279, Current Beta: 0.0000) | Avg Valid Loss: 0.0733 | Avg Valid recon Loss: 0.0733\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0742, recon=0.0742, kl=131.8026, beta=0.0000\n",
      "Batch 40, loss=0.0583, recon=0.0583, kl=121.7943, beta=0.0000\n",
      "Batch 60, loss=0.0821, recon=0.0820, kl=115.5739, beta=0.0000\n",
      "Batch 80, loss=0.3991, recon=0.3991, kl=113.6093, beta=0.0000\n",
      "Batch 100, loss=0.0441, recon=0.0440, kl=110.4677, beta=0.0000\n",
      "Batch 120, loss=0.0532, recon=0.0531, kl=108.9272, beta=0.0000\n",
      "Batch 140, loss=0.0817, recon=0.0817, kl=107.0081, beta=0.0000\n",
      "Batch 160, loss=0.0504, recon=0.0504, kl=102.6776, beta=0.0000\n",
      "Batch 180, loss=0.0503, recon=0.0503, kl=100.1476, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0787 (Recon: 0.0787, KL: 114.7510, Current Beta: 0.0000) | Avg Valid Loss: 0.0642 | Avg Valid recon Loss: 0.0642\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0465, recon=0.0465, kl=88.7576, beta=0.0000\n",
      "Batch 40, loss=0.0536, recon=0.0535, kl=73.6435, beta=0.0000\n",
      "Batch 60, loss=0.0734, recon=0.0733, kl=65.6574, beta=0.0000\n",
      "Batch 80, loss=0.0509, recon=0.0509, kl=65.9156, beta=0.0000\n",
      "Batch 100, loss=0.0484, recon=0.0484, kl=64.3034, beta=0.0000\n",
      "Batch 120, loss=0.0976, recon=0.0976, kl=61.6652, beta=0.0000\n",
      "Batch 140, loss=0.0501, recon=0.0500, kl=67.3125, beta=0.0000\n",
      "Batch 160, loss=0.0800, recon=0.0800, kl=60.3415, beta=0.0000\n",
      "Batch 180, loss=0.0532, recon=0.0532, kl=56.7766, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0701 (Recon: 0.0701, KL: 69.5752, Current Beta: 0.0000) | Avg Valid Loss: 0.0595 | Avg Valid recon Loss: 0.0594\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0470, recon=0.0469, kl=37.0951, beta=0.0000\n",
      "Batch 40, loss=0.0752, recon=0.0752, kl=33.2823, beta=0.0000\n",
      "Batch 60, loss=0.0443, recon=0.0442, kl=31.3693, beta=0.0000\n",
      "Batch 80, loss=0.0459, recon=0.0458, kl=35.8118, beta=0.0000\n",
      "Batch 100, loss=0.0353, recon=0.0352, kl=29.6143, beta=0.0000\n",
      "Batch 120, loss=0.0478, recon=0.0478, kl=28.9219, beta=0.0000\n",
      "Batch 140, loss=0.0419, recon=0.0418, kl=27.9718, beta=0.0000\n",
      "Batch 160, loss=0.0709, recon=0.0708, kl=26.0264, beta=0.0000\n",
      "Batch 180, loss=0.0441, recon=0.0440, kl=25.6856, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0640 (Recon: 0.0639, KL: 32.4331, Current Beta: 0.0000) | Avg Valid Loss: 0.0549 | Avg Valid recon Loss: 0.0548\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0376, recon=0.0375, kl=14.4401, beta=0.0000\n",
      "Batch 40, loss=0.0589, recon=0.0588, kl=12.9967, beta=0.0000\n",
      "Batch 60, loss=0.0937, recon=0.0936, kl=11.2883, beta=0.0000\n",
      "Batch 80, loss=0.0312, recon=0.0311, kl=10.9294, beta=0.0000\n",
      "Batch 100, loss=0.2579, recon=0.2578, kl=10.2304, beta=0.0000\n",
      "Batch 120, loss=0.2893, recon=0.2892, kl=11.5889, beta=0.0000\n",
      "Batch 140, loss=0.0497, recon=0.0497, kl=9.3577, beta=0.0000\n",
      "Batch 160, loss=0.0649, recon=0.0648, kl=10.4044, beta=0.0000\n",
      "Batch 180, loss=0.0435, recon=0.0434, kl=8.9167, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0595 (Recon: 0.0595, KL: 11.9519, Current Beta: 0.0000) | Avg Valid Loss: 0.0517 | Avg Valid recon Loss: 0.0516\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0295, recon=0.0294, kl=5.0106, beta=0.0000\n",
      "Batch 40, loss=0.0405, recon=0.0404, kl=6.2586, beta=0.0000\n",
      "Batch 60, loss=0.0442, recon=0.0441, kl=4.3818, beta=0.0000\n",
      "Batch 80, loss=0.0526, recon=0.0525, kl=3.9649, beta=0.0000\n",
      "Batch 100, loss=0.0408, recon=0.0408, kl=3.8587, beta=0.0000\n",
      "Batch 120, loss=0.0325, recon=0.0324, kl=3.5811, beta=0.0000\n",
      "Batch 140, loss=0.0342, recon=0.0341, kl=3.9051, beta=0.0000\n",
      "Batch 160, loss=0.0360, recon=0.0359, kl=3.4015, beta=0.0000\n",
      "Batch 180, loss=0.0379, recon=0.0379, kl=3.3417, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0561 (Recon: 0.0560, KL: 4.3141, Current Beta: 0.0000) | Avg Valid Loss: 0.0489 | Avg Valid recon Loss: 0.0489\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0390, recon=0.0389, kl=1.5920, beta=0.0000\n",
      "Batch 40, loss=0.0593, recon=0.0592, kl=1.9227, beta=0.0000\n",
      "Batch 60, loss=0.0308, recon=0.0308, kl=1.7691, beta=0.0000\n",
      "Batch 80, loss=0.1040, recon=0.1040, kl=1.3655, beta=0.0000\n",
      "Batch 100, loss=0.0381, recon=0.0381, kl=1.6501, beta=0.0000\n",
      "Batch 120, loss=0.0437, recon=0.0437, kl=1.1012, beta=0.0000\n",
      "Batch 140, loss=0.0444, recon=0.0443, kl=1.4014, beta=0.0000\n",
      "Batch 160, loss=0.0660, recon=0.0659, kl=1.2028, beta=0.0000\n",
      "Batch 180, loss=0.0352, recon=0.0352, kl=1.0857, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0539 (Recon: 0.0538, KL: 1.5860, Current Beta: 0.0000) | Avg Valid Loss: 0.0471 | Avg Valid recon Loss: 0.0471\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0317, recon=0.0317, kl=0.5189, beta=0.0001\n",
      "Batch 40, loss=0.0344, recon=0.0344, kl=0.5436, beta=0.0001\n",
      "Batch 60, loss=0.0373, recon=0.0373, kl=0.4205, beta=0.0001\n",
      "Batch 80, loss=0.0340, recon=0.0340, kl=0.4254, beta=0.0001\n",
      "Batch 100, loss=0.0341, recon=0.0340, kl=0.3131, beta=0.0001\n",
      "Batch 120, loss=0.0342, recon=0.0341, kl=0.3031, beta=0.0001\n",
      "Batch 140, loss=0.0426, recon=0.0426, kl=0.2775, beta=0.0001\n",
      "Batch 160, loss=0.0445, recon=0.0445, kl=0.2716, beta=0.0001\n",
      "Batch 180, loss=0.0368, recon=0.0368, kl=0.2717, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0515, KL: 0.4066, Current Beta: 0.0001) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0449\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0317, recon=0.0317, kl=0.0327, beta=0.0003\n",
      "Batch 40, loss=0.0293, recon=0.0293, kl=0.0749, beta=0.0003\n",
      "Batch 60, loss=0.0241, recon=0.0240, kl=0.0496, beta=0.0003\n",
      "Batch 80, loss=0.0318, recon=0.0318, kl=0.0279, beta=0.0003\n",
      "Batch 100, loss=0.0287, recon=0.0287, kl=0.0191, beta=0.0003\n",
      "Batch 120, loss=0.0306, recon=0.0306, kl=0.0410, beta=0.0003\n",
      "Batch 140, loss=0.0477, recon=0.0476, kl=0.0288, beta=0.0003\n",
      "Batch 160, loss=0.1109, recon=0.1109, kl=0.0179, beta=0.0003\n",
      "Batch 180, loss=0.0243, recon=0.0243, kl=0.0143, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0496, KL: 0.0411, Current Beta: 0.0003) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0403, recon=0.0403, kl=0.0012, beta=0.0008\n",
      "Batch 40, loss=0.0219, recon=0.0219, kl=0.0021, beta=0.0008\n",
      "Batch 60, loss=0.0336, recon=0.0336, kl=0.0016, beta=0.0008\n",
      "Batch 80, loss=0.0320, recon=0.0320, kl=0.0016, beta=0.0008\n",
      "Batch 100, loss=0.1524, recon=0.1524, kl=0.0046, beta=0.0008\n",
      "Batch 120, loss=0.0531, recon=0.0531, kl=0.0010, beta=0.0008\n",
      "Batch 140, loss=0.0414, recon=0.0414, kl=0.0016, beta=0.0008\n",
      "Batch 160, loss=0.0330, recon=0.0330, kl=0.0016, beta=0.0008\n",
      "Batch 180, loss=0.0411, recon=0.0411, kl=0.0010, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0480, KL: 0.0023, Current Beta: 0.0008) | Avg Valid Loss: 0.0419 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0239, recon=0.0239, kl=0.0002, beta=0.0018\n",
      "Batch 40, loss=0.0349, recon=0.0349, kl=0.0006, beta=0.0018\n",
      "Batch 60, loss=0.0281, recon=0.0281, kl=0.0002, beta=0.0018\n",
      "Batch 80, loss=0.0391, recon=0.0391, kl=0.0002, beta=0.0018\n",
      "Batch 100, loss=0.0295, recon=0.0295, kl=0.0008, beta=0.0018\n",
      "Batch 120, loss=0.0462, recon=0.0462, kl=0.0004, beta=0.0018\n",
      "Batch 140, loss=0.0657, recon=0.0657, kl=0.0003, beta=0.0018\n",
      "Batch 160, loss=0.0350, recon=0.0350, kl=0.0008, beta=0.0018\n",
      "Batch 180, loss=0.0332, recon=0.0332, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0466, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0405 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0427, recon=0.0427, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0470, recon=0.0470, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.0299, recon=0.0299, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0502, recon=0.0502, kl=0.0001, beta=0.0038\n",
      "Batch 100, loss=0.0273, recon=0.0273, kl=0.0001, beta=0.0038\n",
      "Batch 120, loss=0.0299, recon=0.0299, kl=0.0001, beta=0.0038\n",
      "Batch 140, loss=0.0273, recon=0.0273, kl=0.0001, beta=0.0038\n",
      "Batch 160, loss=0.0289, recon=0.0289, kl=0.0001, beta=0.0038\n",
      "Batch 180, loss=0.0441, recon=0.0441, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0454 (Recon: 0.0454, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0294, recon=0.0294, kl=0.0003, beta=0.0062\n",
      "Batch 40, loss=0.0317, recon=0.0317, kl=0.0002, beta=0.0062\n",
      "Batch 60, loss=0.1058, recon=0.1058, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0231, recon=0.0231, kl=0.0000, beta=0.0062\n",
      "Batch 100, loss=0.0369, recon=0.0369, kl=0.0016, beta=0.0062\n",
      "Batch 120, loss=0.0205, recon=0.0205, kl=0.0002, beta=0.0062\n",
      "Batch 140, loss=0.0381, recon=0.0381, kl=0.0001, beta=0.0062\n",
      "Batch 160, loss=0.0316, recon=0.0316, kl=0.0000, beta=0.0062\n",
      "Batch 180, loss=0.0293, recon=0.0293, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0443 (Recon: 0.0443, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0303, recon=0.0303, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.6570, recon=0.6570, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.1177, recon=0.1177, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0478, recon=0.0478, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0308, recon=0.0308, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0519, recon=0.0519, kl=0.0008, beta=0.0100\n",
      "Batch 140, loss=0.0362, recon=0.0362, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0231, recon=0.0231, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0506, recon=0.0506, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0378 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0306, recon=0.0306, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0430, recon=0.0430, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0237, recon=0.0237, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.1154, recon=0.1154, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0484, recon=0.0484, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0363, recon=0.0363, kl=0.0002, beta=0.0100\n",
      "Batch 140, loss=0.0218, recon=0.0218, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0226, recon=0.0226, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0298, recon=0.0298, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0425, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0265, recon=0.0265, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0472, recon=0.0472, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0394, recon=0.0394, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0348, recon=0.0348, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0343, recon=0.0343, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0235, recon=0.0235, kl=0.0002, beta=0.0100\n",
      "Batch 140, loss=0.0284, recon=0.0284, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0341, recon=0.0341, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0285, recon=0.0285, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0417, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0359 | Avg Valid recon Loss: 0.0359\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.6078, recon=0.6078, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0313, recon=0.0313, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0244, recon=0.0244, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0178, recon=0.0178, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0248, recon=0.0248, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0328, recon=0.0328, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0236, recon=0.0236, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0431, recon=0.0431, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0378, recon=0.0378, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0410, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0156, recon=0.0156, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0315, recon=0.0315, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0276, recon=0.0276, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.1537, recon=0.1537, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0287, recon=0.0287, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0333, recon=0.0333, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0218, recon=0.0218, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0185, recon=0.0185, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0179, recon=0.0179, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0402 (Recon: 0.0402, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0358\n",
      "\n",
      "[VRAE Run 102/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1538, recon=0.1538, kl=41.3136, beta=0.0000\n",
      "Batch 40, loss=0.1042, recon=0.1042, kl=100.0808, beta=0.0000\n",
      "Batch 60, loss=0.0899, recon=0.0899, kl=81.6088, beta=0.0000\n",
      "Batch 80, loss=0.0682, recon=0.0682, kl=91.8874, beta=0.0000\n",
      "Batch 100, loss=0.5273, recon=0.5273, kl=94.1857, beta=0.0000\n",
      "Batch 120, loss=0.0529, recon=0.0529, kl=108.2460, beta=0.0000\n",
      "Batch 140, loss=0.0446, recon=0.0446, kl=118.7513, beta=0.0000\n",
      "Batch 160, loss=0.1205, recon=0.1205, kl=95.8080, beta=0.0000\n",
      "Batch 180, loss=0.0674, recon=0.0674, kl=107.1756, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1309 (Recon: 0.1308, KL: 88.3079, Current Beta: 0.0000) | Avg Valid Loss: 0.0594 | Avg Valid recon Loss: 0.0594\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0593, recon=0.0593, kl=123.8851, beta=0.0000\n",
      "Batch 40, loss=0.0288, recon=0.0288, kl=110.8395, beta=0.0000\n",
      "Batch 60, loss=0.0463, recon=0.0463, kl=111.2956, beta=0.0000\n",
      "Batch 80, loss=0.0388, recon=0.0388, kl=109.1776, beta=0.0000\n",
      "Batch 100, loss=0.1162, recon=0.1162, kl=113.7178, beta=0.0000\n",
      "Batch 120, loss=0.0409, recon=0.0409, kl=109.7840, beta=0.0000\n",
      "Batch 140, loss=0.0475, recon=0.0475, kl=117.6189, beta=0.0000\n",
      "Batch 160, loss=0.0361, recon=0.0361, kl=135.2781, beta=0.0000\n",
      "Batch 180, loss=0.0454, recon=0.0454, kl=138.6963, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0586 (Recon: 0.0586, KL: 117.9954, Current Beta: 0.0000) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0436, recon=0.0436, kl=129.6332, beta=0.0000\n",
      "Batch 40, loss=0.0372, recon=0.0372, kl=102.9773, beta=0.0000\n",
      "Batch 60, loss=0.0359, recon=0.0358, kl=111.5418, beta=0.0000\n",
      "Batch 80, loss=0.0448, recon=0.0448, kl=118.1058, beta=0.0000\n",
      "Batch 100, loss=0.0445, recon=0.0445, kl=124.5658, beta=0.0000\n",
      "Batch 120, loss=0.0438, recon=0.0438, kl=120.4451, beta=0.0000\n",
      "Batch 140, loss=0.0423, recon=0.0423, kl=119.1412, beta=0.0000\n",
      "Batch 160, loss=0.0430, recon=0.0430, kl=124.7082, beta=0.0000\n",
      "Batch 180, loss=0.0405, recon=0.0405, kl=127.8638, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0520 (Recon: 0.0520, KL: 120.4744, Current Beta: 0.0000) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0343, recon=0.0342, kl=116.6552, beta=0.0000\n",
      "Batch 40, loss=0.0315, recon=0.0314, kl=102.5736, beta=0.0000\n",
      "Batch 60, loss=0.0473, recon=0.0473, kl=97.7133, beta=0.0000\n",
      "Batch 80, loss=0.0465, recon=0.0465, kl=104.5807, beta=0.0000\n",
      "Batch 100, loss=0.0243, recon=0.0243, kl=93.5425, beta=0.0000\n",
      "Batch 120, loss=0.0627, recon=0.0626, kl=111.8545, beta=0.0000\n",
      "Batch 140, loss=0.0617, recon=0.0617, kl=116.8762, beta=0.0000\n",
      "Batch 160, loss=0.0484, recon=0.0483, kl=118.3092, beta=0.0000\n",
      "Batch 180, loss=0.0346, recon=0.0346, kl=117.6683, beta=0.0000\n",
      "  â†’ Avg Train Loss: 9.0880 (Recon: 9.0879, KL: 147.5267, Current Beta: 0.0000) | Avg Valid Loss: 0.0424 | Avg Valid recon Loss: 0.0424\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0268, recon=0.0268, kl=120.0949, beta=0.0000\n",
      "Batch 40, loss=0.0300, recon=0.0299, kl=117.6174, beta=0.0000\n",
      "Batch 60, loss=0.0294, recon=0.0293, kl=120.6014, beta=0.0000\n",
      "Batch 80, loss=0.0410, recon=0.0409, kl=125.1932, beta=0.0000\n",
      "Batch 100, loss=0.0270, recon=0.0269, kl=122.8420, beta=0.0000\n",
      "Batch 120, loss=0.0412, recon=0.0411, kl=122.0756, beta=0.0000\n",
      "Batch 140, loss=0.0298, recon=0.0297, kl=125.1347, beta=0.0000\n",
      "Batch 160, loss=0.0733, recon=0.0732, kl=123.0425, beta=0.0000\n",
      "Batch 180, loss=0.2269, recon=0.2268, kl=123.1037, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0448, KL: 121.9170, Current Beta: 0.0000) | Avg Valid Loss: 0.0498 | Avg Valid recon Loss: 0.0497\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0320, recon=0.0317, kl=115.3897, beta=0.0000\n",
      "Batch 40, loss=0.0435, recon=0.0433, kl=106.1100, beta=0.0000\n",
      "Batch 60, loss=0.0250, recon=0.0248, kl=103.3759, beta=0.0000\n",
      "Batch 80, loss=0.0405, recon=0.0403, kl=103.3485, beta=0.0000\n",
      "Batch 100, loss=0.0569, recon=0.0566, kl=102.4005, beta=0.0000\n",
      "Batch 120, loss=0.1707, recon=0.1705, kl=106.2058, beta=0.0000\n",
      "Batch 140, loss=0.0352, recon=0.0350, kl=104.3628, beta=0.0000\n",
      "Batch 160, loss=0.0276, recon=0.0274, kl=101.5339, beta=0.0000\n",
      "Batch 180, loss=0.0466, recon=0.0464, kl=97.6035, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0490 (Recon: 0.0488, KL: 105.7630, Current Beta: 0.0000) | Avg Valid Loss: 0.0385 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0266, recon=0.0261, kl=81.9435, beta=0.0000\n",
      "Batch 40, loss=0.0247, recon=0.0243, kl=73.9289, beta=0.0000\n",
      "Batch 60, loss=0.0277, recon=0.0273, kl=69.5752, beta=0.0000\n",
      "Batch 80, loss=0.0671, recon=0.0667, kl=68.8808, beta=0.0000\n",
      "Batch 100, loss=0.0348, recon=0.0344, kl=70.0805, beta=0.0000\n",
      "Batch 120, loss=0.0589, recon=0.0585, kl=67.8615, beta=0.0000\n",
      "Batch 140, loss=0.0311, recon=0.0308, kl=67.9633, beta=0.0000\n",
      "Batch 160, loss=0.0255, recon=0.0251, kl=67.5454, beta=0.0000\n",
      "Batch 180, loss=0.0435, recon=0.0431, kl=59.5781, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0430, KL: 71.1320, Current Beta: 0.0000) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0276, recon=0.0270, kl=42.9582, beta=0.0000\n",
      "Batch 40, loss=0.0187, recon=0.0181, kl=39.2333, beta=0.0000\n",
      "Batch 60, loss=0.0235, recon=0.0229, kl=38.8033, beta=0.0000\n",
      "Batch 80, loss=0.0425, recon=0.0420, kl=32.2368, beta=0.0000\n",
      "Batch 100, loss=0.0230, recon=0.0226, kl=30.9069, beta=0.0000\n",
      "Batch 120, loss=0.0208, recon=0.0204, kl=29.0488, beta=0.0000\n",
      "Batch 140, loss=0.0291, recon=0.0287, kl=24.8418, beta=0.0000\n",
      "Batch 160, loss=0.0230, recon=0.0226, kl=25.2587, beta=0.0000\n",
      "Batch 180, loss=0.0197, recon=0.0194, kl=23.4433, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0367 (Recon: 0.0362, KL: 33.8485, Current Beta: 0.0000) | Avg Valid Loss: 0.0322 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0254, recon=0.0248, kl=13.9448, beta=0.0000\n",
      "Batch 40, loss=0.0218, recon=0.0214, kl=11.3798, beta=0.0000\n",
      "Batch 60, loss=0.0546, recon=0.0542, kl=11.1054, beta=0.0000\n",
      "Batch 80, loss=0.0347, recon=0.0343, kl=10.4864, beta=0.0000\n",
      "Batch 100, loss=0.0290, recon=0.0286, kl=9.6151, beta=0.0000\n",
      "Batch 120, loss=0.0256, recon=0.0252, kl=8.6862, beta=0.0000\n",
      "Batch 140, loss=0.0359, recon=0.0355, kl=9.8725, beta=0.0000\n",
      "Batch 160, loss=0.0391, recon=0.0387, kl=9.1258, beta=0.0000\n",
      "Batch 180, loss=0.0432, recon=0.0429, kl=8.1129, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0369 (Recon: 0.0364, KL: 11.2463, Current Beta: 0.0000) | Avg Valid Loss: 0.0522 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0369, recon=0.0362, kl=6.8317, beta=0.0001\n",
      "Batch 40, loss=0.0310, recon=0.0298, kl=10.9169, beta=0.0001\n",
      "Batch 60, loss=0.0355, recon=0.0346, kl=8.3363, beta=0.0001\n",
      "Batch 80, loss=0.1268, recon=0.1258, kl=8.7767, beta=0.0001\n",
      "Batch 100, loss=0.0427, recon=0.0416, kl=9.3270, beta=0.0001\n",
      "Batch 120, loss=0.0406, recon=0.0399, kl=6.4278, beta=0.0001\n",
      "Batch 140, loss=0.1663, recon=0.1656, kl=6.3350, beta=0.0001\n",
      "Batch 160, loss=0.0329, recon=0.0323, kl=5.5332, beta=0.0001\n",
      "Batch 180, loss=0.0385, recon=0.0379, kl=5.2774, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0528 (Recon: 0.0520, KL: 7.4370, Current Beta: 0.0001) | Avg Valid Loss: 0.0354 | Avg Valid recon Loss: 0.0348\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0524, recon=0.0506, kl=6.3499, beta=0.0003\n",
      "Batch 40, loss=0.0333, recon=0.0321, kl=4.2282, beta=0.0003\n",
      "Batch 60, loss=0.0383, recon=0.0368, kl=5.2012, beta=0.0003\n",
      "Batch 80, loss=0.0321, recon=0.0310, kl=3.7165, beta=0.0003\n",
      "Batch 100, loss=0.0550, recon=0.0541, kl=2.9812, beta=0.0003\n",
      "Batch 120, loss=0.0240, recon=0.0226, kl=4.6651, beta=0.0003\n",
      "Batch 140, loss=0.0337, recon=0.0326, kl=3.5710, beta=0.0003\n",
      "Batch 160, loss=0.0318, recon=0.0309, kl=2.9729, beta=0.0003\n",
      "Batch 180, loss=0.0644, recon=0.0632, kl=3.8518, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0473, KL: 4.1477, Current Beta: 0.0003) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0462\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0430, recon=0.0404, kl=3.4530, beta=0.0008\n",
      "Batch 40, loss=0.0405, recon=0.0383, kl=2.8438, beta=0.0008\n",
      "Batch 60, loss=0.0497, recon=0.0323, kl=22.8816, beta=0.0008\n",
      "Batch 80, loss=0.0689, recon=0.0606, kl=10.9222, beta=0.0008\n",
      "Batch 100, loss=0.0568, recon=0.0497, kl=9.3192, beta=0.0008\n",
      "Batch 120, loss=0.0945, recon=0.0896, kl=6.4241, beta=0.0008\n",
      "Batch 140, loss=0.0698, recon=0.0646, kl=6.7881, beta=0.0008\n",
      "Batch 160, loss=0.0271, recon=0.0217, kl=7.1929, beta=0.0008\n",
      "Batch 180, loss=0.0409, recon=0.0368, kl=5.4771, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0566 (Recon: 0.0505, KL: 8.0390, Current Beta: 0.0008) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0354, recon=0.0272, kl=4.4595, beta=0.0018\n",
      "Batch 40, loss=0.0379, recon=0.0281, kl=5.3571, beta=0.0018\n",
      "Batch 60, loss=0.0470, recon=0.0349, kl=6.6803, beta=0.0018\n",
      "Batch 80, loss=0.0491, recon=0.0395, kl=5.2525, beta=0.0018\n",
      "Batch 100, loss=0.0409, recon=0.0334, kl=4.1086, beta=0.0018\n",
      "Batch 120, loss=0.0378, recon=0.0250, kl=6.9804, beta=0.0018\n",
      "Batch 140, loss=0.0351, recon=0.0230, kl=6.6686, beta=0.0018\n",
      "Batch 160, loss=0.0426, recon=0.0324, kl=5.5912, beta=0.0018\n",
      "Batch 180, loss=0.0292, recon=0.0214, kl=4.2500, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0421, KL: 5.3200, Current Beta: 0.0018) | Avg Valid Loss: 0.0404 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0438, recon=0.0317, kl=3.2143, beta=0.0038\n",
      "Batch 40, loss=0.0383, recon=0.0295, kl=2.3455, beta=0.0038\n",
      "Batch 60, loss=0.0706, recon=0.0603, kl=2.7375, beta=0.0038\n",
      "Batch 80, loss=0.0618, recon=0.0503, kl=3.0413, beta=0.0038\n",
      "Batch 100, loss=0.3260, recon=0.3096, kl=4.3590, beta=0.0038\n",
      "Batch 120, loss=0.0723, recon=0.0555, kl=4.4400, beta=0.0038\n",
      "Batch 140, loss=0.0924, recon=0.0791, kl=3.5176, beta=0.0038\n",
      "Batch 160, loss=0.0516, recon=0.0415, kl=2.6832, beta=0.0038\n",
      "Batch 180, loss=0.0848, recon=0.0711, kl=3.6473, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0769 (Recon: 0.0643, KL: 3.3478, Current Beta: 0.0038) | Avg Valid Loss: 0.0689 | Avg Valid recon Loss: 0.0550\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0604, recon=0.0415, kl=3.0346, beta=0.0062\n",
      "Batch 40, loss=0.0428, recon=0.0283, kl=2.3287, beta=0.0062\n",
      "Batch 60, loss=4.0139, recon=4.0012, kl=2.0379, beta=0.0062\n",
      "Batch 80, loss=0.1294, recon=0.0887, kl=6.5287, beta=0.0062\n",
      "Batch 100, loss=0.3036, recon=0.2600, kl=7.0043, beta=0.0062\n",
      "Batch 120, loss=0.1271, recon=0.0805, kl=7.4972, beta=0.0062\n",
      "Batch 140, loss=0.1551, recon=0.1148, kl=6.4623, beta=0.0062\n",
      "Batch 160, loss=0.0843, recon=0.0418, kl=6.8195, beta=0.0062\n",
      "Batch 180, loss=0.0827, recon=0.0447, kl=6.0926, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.1401 (Recon: 0.1074, KL: 5.2448, Current Beta: 0.0062) | Avg Valid Loss: 0.0954 | Avg Valid recon Loss: 0.0581\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0881, recon=0.0398, kl=4.8300, beta=0.0100\n",
      "Batch 40, loss=0.0898, recon=0.0523, kl=3.7478, beta=0.0100\n",
      "Batch 60, loss=0.0849, recon=0.0455, kl=3.9374, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 103/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3033, recon=0.3033, kl=2.5505, beta=0.0000\n",
      "Batch 40, loss=0.2336, recon=0.2336, kl=21.4226, beta=0.0000\n",
      "Batch 60, loss=0.1372, recon=0.1372, kl=30.0687, beta=0.0000\n",
      "Batch 80, loss=0.1317, recon=0.1317, kl=32.7092, beta=0.0000\n",
      "Batch 100, loss=0.0918, recon=0.0918, kl=40.3508, beta=0.0000\n",
      "Batch 120, loss=0.0861, recon=0.0861, kl=46.7924, beta=0.0000\n",
      "Batch 140, loss=0.0966, recon=0.0966, kl=46.7817, beta=0.0000\n",
      "Batch 160, loss=0.0977, recon=0.0977, kl=47.4224, beta=0.0000\n",
      "Batch 180, loss=0.0739, recon=0.0739, kl=45.6656, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2043 (Recon: 0.2043, KL: 32.4694, Current Beta: 0.0000) | Avg Valid Loss: 0.0848 | Avg Valid recon Loss: 0.0848\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0944, recon=0.0944, kl=45.7209, beta=0.0000\n",
      "Batch 40, loss=0.0726, recon=0.0726, kl=50.7656, beta=0.0000\n",
      "Batch 60, loss=0.1028, recon=0.1028, kl=52.6999, beta=0.0000\n",
      "Batch 80, loss=0.0890, recon=0.0890, kl=52.6826, beta=0.0000\n",
      "Batch 100, loss=0.3844, recon=0.3844, kl=57.3755, beta=0.0000\n",
      "Batch 120, loss=0.0549, recon=0.0549, kl=54.8192, beta=0.0000\n",
      "Batch 140, loss=0.0601, recon=0.0601, kl=58.0435, beta=0.0000\n",
      "Batch 160, loss=0.0544, recon=0.0544, kl=56.9854, beta=0.0000\n",
      "Batch 180, loss=0.0406, recon=0.0406, kl=58.3681, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0890 (Recon: 0.0890, KL: 53.6204, Current Beta: 0.0000) | Avg Valid Loss: 0.0645 | Avg Valid recon Loss: 0.0645\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0421, recon=0.0421, kl=59.8741, beta=0.0000\n",
      "Batch 40, loss=0.0564, recon=0.0564, kl=59.0930, beta=0.0000\n",
      "Batch 60, loss=0.0477, recon=0.0477, kl=60.2404, beta=0.0000\n",
      "Batch 80, loss=0.0698, recon=0.0698, kl=61.2023, beta=0.0000\n",
      "Batch 100, loss=0.0635, recon=0.0635, kl=57.3356, beta=0.0000\n",
      "Batch 120, loss=0.0715, recon=0.0715, kl=52.6885, beta=0.0000\n",
      "Batch 140, loss=0.0452, recon=0.0452, kl=54.0850, beta=0.0000\n",
      "Batch 160, loss=0.0582, recon=0.0582, kl=55.3996, beta=0.0000\n",
      "Batch 180, loss=0.0577, recon=0.0577, kl=55.3194, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0701 (Recon: 0.0701, KL: 57.6023, Current Beta: 0.0000) | Avg Valid Loss: 0.0535 | Avg Valid recon Loss: 0.0535\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0406, recon=0.0406, kl=53.9592, beta=0.0000\n",
      "Batch 40, loss=0.0439, recon=0.0439, kl=45.0892, beta=0.0000\n",
      "Batch 60, loss=0.0427, recon=0.0427, kl=45.3628, beta=0.0000\n",
      "Batch 80, loss=0.0549, recon=0.0548, kl=44.2881, beta=0.0000\n",
      "Batch 100, loss=0.0355, recon=0.0355, kl=42.1128, beta=0.0000\n",
      "Batch 120, loss=0.0336, recon=0.0336, kl=39.0825, beta=0.0000\n",
      "Batch 140, loss=0.0312, recon=0.0312, kl=41.1352, beta=0.0000\n",
      "Batch 160, loss=0.0298, recon=0.0298, kl=41.1052, beta=0.0000\n",
      "Batch 180, loss=0.0281, recon=0.0281, kl=40.4210, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0597 (Recon: 0.0597, KL: 44.1970, Current Beta: 0.0000) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0299, recon=0.0299, kl=36.4782, beta=0.0000\n",
      "Batch 40, loss=0.0286, recon=0.0285, kl=30.3735, beta=0.0000\n",
      "Batch 60, loss=0.0295, recon=0.0295, kl=26.2068, beta=0.0000\n",
      "Batch 80, loss=0.0388, recon=0.0388, kl=27.8597, beta=0.0000\n",
      "Batch 100, loss=0.0546, recon=0.0546, kl=24.8554, beta=0.0000\n",
      "Batch 120, loss=0.0343, recon=0.0343, kl=23.1218, beta=0.0000\n",
      "Batch 140, loss=0.0431, recon=0.0431, kl=30.5283, beta=0.0000\n",
      "Batch 160, loss=0.0359, recon=0.0359, kl=28.9035, beta=0.0000\n",
      "Batch 180, loss=0.0317, recon=0.0316, kl=25.3408, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0526, KL: 29.1158, Current Beta: 0.0000) | Avg Valid Loss: 0.0428 | Avg Valid recon Loss: 0.0428\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0297, recon=0.0296, kl=19.4748, beta=0.0000\n",
      "Batch 40, loss=0.0427, recon=0.0427, kl=17.2086, beta=0.0000\n",
      "Batch 60, loss=0.0259, recon=0.0259, kl=16.7029, beta=0.0000\n",
      "Batch 80, loss=0.0379, recon=0.0379, kl=15.5900, beta=0.0000\n",
      "Batch 100, loss=0.0273, recon=0.0272, kl=15.5468, beta=0.0000\n",
      "Batch 120, loss=0.0406, recon=0.0406, kl=13.0063, beta=0.0000\n",
      "Batch 140, loss=0.0337, recon=0.0336, kl=14.9968, beta=0.0000\n",
      "Batch 160, loss=0.0260, recon=0.0260, kl=14.6374, beta=0.0000\n",
      "Batch 180, loss=0.0288, recon=0.0288, kl=12.9530, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0472, KL: 16.1605, Current Beta: 0.0000) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0238, recon=0.0237, kl=9.8398, beta=0.0000\n",
      "Batch 40, loss=0.0293, recon=0.0293, kl=10.7900, beta=0.0000\n",
      "Batch 60, loss=0.0311, recon=0.0311, kl=7.3829, beta=0.0000\n",
      "Batch 80, loss=0.0400, recon=0.0399, kl=7.4002, beta=0.0000\n",
      "Batch 100, loss=0.1410, recon=0.1410, kl=7.7060, beta=0.0000\n",
      "Batch 120, loss=0.0257, recon=0.0257, kl=6.3613, beta=0.0000\n",
      "Batch 140, loss=0.0517, recon=0.0516, kl=7.6044, beta=0.0000\n",
      "Batch 160, loss=0.0272, recon=0.0271, kl=5.6793, beta=0.0000\n",
      "Batch 180, loss=0.0304, recon=0.0303, kl=6.5153, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0435 (Recon: 0.0435, KL: 7.9445, Current Beta: 0.0000) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0354, recon=0.0354, kl=2.6726, beta=0.0000\n",
      "Batch 40, loss=0.0330, recon=0.0329, kl=3.4825, beta=0.0000\n",
      "Batch 60, loss=0.0333, recon=0.0333, kl=2.9818, beta=0.0000\n",
      "Batch 80, loss=0.0224, recon=0.0224, kl=2.7515, beta=0.0000\n",
      "Batch 100, loss=0.0297, recon=0.0297, kl=3.8584, beta=0.0000\n",
      "Batch 120, loss=0.0351, recon=0.0351, kl=2.6436, beta=0.0000\n",
      "Batch 140, loss=0.0286, recon=0.0285, kl=2.9266, beta=0.0000\n",
      "Batch 160, loss=0.0225, recon=0.0224, kl=2.5302, beta=0.0000\n",
      "Batch 180, loss=0.0321, recon=0.0320, kl=4.3649, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0411 (Recon: 0.0411, KL: 3.2585, Current Beta: 0.0000) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0262, recon=0.0262, kl=1.2815, beta=0.0000\n",
      "Batch 40, loss=0.0298, recon=0.0297, kl=1.3256, beta=0.0000\n",
      "Batch 60, loss=0.0329, recon=0.0329, kl=1.1921, beta=0.0000\n",
      "Batch 80, loss=0.0234, recon=0.0233, kl=1.2349, beta=0.0000\n",
      "Batch 100, loss=0.0232, recon=0.0231, kl=2.4625, beta=0.0000\n",
      "Batch 120, loss=0.0417, recon=0.0417, kl=0.7615, beta=0.0000\n",
      "Batch 140, loss=0.0200, recon=0.0199, kl=1.0936, beta=0.0000\n",
      "Batch 160, loss=0.0278, recon=0.0278, kl=0.9141, beta=0.0000\n",
      "Batch 180, loss=0.0296, recon=0.0296, kl=1.2190, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0391, KL: 1.3426, Current Beta: 0.0000) | Avg Valid Loss: 0.0336 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0315, recon=0.0315, kl=0.1140, beta=0.0001\n",
      "Batch 40, loss=0.0198, recon=0.0197, kl=0.3003, beta=0.0001\n",
      "Batch 60, loss=0.0218, recon=0.0217, kl=0.2322, beta=0.0001\n",
      "Batch 80, loss=0.0476, recon=0.0476, kl=0.1137, beta=0.0001\n",
      "Batch 100, loss=0.0287, recon=0.0286, kl=0.3086, beta=0.0001\n",
      "Batch 120, loss=0.0304, recon=0.0303, kl=0.1653, beta=0.0001\n",
      "Batch 140, loss=0.0320, recon=0.0320, kl=0.1423, beta=0.0001\n",
      "Batch 160, loss=0.0393, recon=0.0393, kl=0.1526, beta=0.0001\n",
      "Batch 180, loss=0.0207, recon=0.0207, kl=0.0790, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0376 (Recon: 0.0376, KL: 0.2193, Current Beta: 0.0001) | Avg Valid Loss: 0.0325 | Avg Valid recon Loss: 0.0325\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0230, recon=0.0230, kl=0.0026, beta=0.0003\n",
      "Batch 40, loss=0.0296, recon=0.0296, kl=0.0217, beta=0.0003\n",
      "Batch 60, loss=0.0298, recon=0.0298, kl=0.0087, beta=0.0003\n",
      "Batch 80, loss=0.0472, recon=0.0471, kl=0.0238, beta=0.0003\n",
      "Batch 100, loss=0.0397, recon=0.0397, kl=0.0102, beta=0.0003\n",
      "Batch 120, loss=0.0224, recon=0.0224, kl=0.0059, beta=0.0003\n",
      "Batch 140, loss=0.0302, recon=0.0302, kl=0.0123, beta=0.0003\n",
      "Batch 160, loss=0.0238, recon=0.0237, kl=0.0053, beta=0.0003\n",
      "Batch 180, loss=0.0246, recon=0.0246, kl=0.0053, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0361 (Recon: 0.0361, KL: 0.0170, Current Beta: 0.0003) | Avg Valid Loss: 0.0324 | Avg Valid recon Loss: 0.0324\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0301, recon=0.0301, kl=0.0058, beta=0.0008\n",
      "Batch 40, loss=0.0412, recon=0.0412, kl=0.0024, beta=0.0008\n",
      "Batch 60, loss=0.0246, recon=0.0246, kl=0.0017, beta=0.0008\n",
      "Batch 80, loss=0.0432, recon=0.0432, kl=0.0009, beta=0.0008\n",
      "Batch 100, loss=0.1560, recon=0.1560, kl=0.0011, beta=0.0008\n",
      "Batch 120, loss=0.0219, recon=0.0219, kl=0.0015, beta=0.0008\n",
      "Batch 140, loss=0.0180, recon=0.0180, kl=0.0009, beta=0.0008\n",
      "Batch 160, loss=0.0213, recon=0.0213, kl=0.0047, beta=0.0008\n",
      "Batch 180, loss=0.0933, recon=0.0933, kl=0.0037, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0352 (Recon: 0.0352, KL: 0.0037, Current Beta: 0.0008) | Avg Valid Loss: 0.0308 | Avg Valid recon Loss: 0.0308\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0236, recon=0.0236, kl=0.0011, beta=0.0018\n",
      "Batch 40, loss=0.0209, recon=0.0209, kl=0.0008, beta=0.0018\n",
      "Batch 60, loss=0.0287, recon=0.0287, kl=0.0003, beta=0.0018\n",
      "Batch 80, loss=0.0470, recon=0.0470, kl=0.0002, beta=0.0018\n",
      "Batch 100, loss=0.0566, recon=0.0566, kl=0.0004, beta=0.0018\n",
      "Batch 120, loss=0.0306, recon=0.0306, kl=0.0002, beta=0.0018\n",
      "Batch 140, loss=0.0232, recon=0.0232, kl=0.0002, beta=0.0018\n",
      "Batch 160, loss=0.0742, recon=0.0742, kl=0.0012, beta=0.0018\n",
      "Batch 180, loss=0.0252, recon=0.0252, kl=0.0004, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0342 (Recon: 0.0342, KL: 0.0008, Current Beta: 0.0018) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0307\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1063, recon=0.1063, kl=0.0004, beta=0.0038\n",
      "Batch 40, loss=0.0273, recon=0.0273, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.0315, recon=0.0315, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0334, recon=0.0334, kl=0.0003, beta=0.0038\n",
      "Batch 100, loss=0.0312, recon=0.0312, kl=0.0001, beta=0.0038\n",
      "Batch 120, loss=0.0457, recon=0.0457, kl=0.0002, beta=0.0038\n",
      "Batch 140, loss=0.0308, recon=0.0308, kl=0.0003, beta=0.0038\n",
      "Batch 160, loss=0.0184, recon=0.0184, kl=0.0007, beta=0.0038\n",
      "Batch 180, loss=0.0206, recon=0.0206, kl=0.0004, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0335 (Recon: 0.0335, KL: 0.0004, Current Beta: 0.0038) | Avg Valid Loss: 0.0308 | Avg Valid recon Loss: 0.0308\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0170, recon=0.0170, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0198, recon=0.0198, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0564, recon=0.0564, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0554, recon=0.0554, kl=0.0001, beta=0.0062\n",
      "Batch 100, loss=0.0252, recon=0.0252, kl=0.0001, beta=0.0062\n",
      "Batch 120, loss=0.0290, recon=0.0290, kl=0.0000, beta=0.0062\n",
      "Batch 140, loss=0.0287, recon=0.0287, kl=0.0001, beta=0.0062\n",
      "Batch 160, loss=0.0208, recon=0.0208, kl=0.0001, beta=0.0062\n",
      "Batch 180, loss=0.0266, recon=0.0266, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0335 (Recon: 0.0335, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0287 | Avg Valid recon Loss: 0.0287\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0227, recon=0.0227, kl=0.0004, beta=0.0100\n",
      "Batch 40, loss=0.0309, recon=0.0309, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0281, recon=0.0281, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0226, recon=0.0226, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0145, recon=0.0145, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0150, recon=0.0150, kl=0.0001, beta=0.0100\n",
      "Batch 140, loss=0.0332, recon=0.0332, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0147, recon=0.0147, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0204, recon=0.0204, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0327 (Recon: 0.0327, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0296 | Avg Valid recon Loss: 0.0296\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0388, recon=0.0388, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0238, recon=0.0238, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0400, recon=0.0400, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0197, recon=0.0197, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0199, recon=0.0199, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0220, recon=0.0220, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0257, recon=0.0257, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0204, recon=0.0204, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0241, recon=0.0241, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0325 (Recon: 0.0325, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0274 | Avg Valid recon Loss: 0.0274\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0196, recon=0.0195, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0251, recon=0.0251, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0172, recon=0.0172, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0196, recon=0.0196, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0237, recon=0.0237, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0218, recon=0.0218, kl=0.0001, beta=0.0100\n",
      "Batch 160, loss=0.0197, recon=0.0197, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0191, recon=0.0191, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0313 (Recon: 0.0313, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0273 | Avg Valid recon Loss: 0.0273\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0414, recon=0.0414, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0185, recon=0.0185, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0170, recon=0.0170, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.3415, recon=0.3415, kl=0.0005, beta=0.0100\n",
      "Batch 100, loss=0.0339, recon=0.0339, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0284, recon=0.0284, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0320, recon=0.0320, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.1154, recon=0.1154, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0391, recon=0.0391, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0304 (Recon: 0.0304, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0271 | Avg Valid recon Loss: 0.0271\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0329, recon=0.0329, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0256, recon=0.0256, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0196, recon=0.0196, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0141, recon=0.0141, kl=0.0001, beta=0.0100\n",
      "Batch 100, loss=0.0446, recon=0.0446, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0232, recon=0.0232, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0264, recon=0.0264, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0205, recon=0.0205, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0277, recon=0.0277, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0301 (Recon: 0.0301, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0272 | Avg Valid recon Loss: 0.0272\n",
      "\n",
      "[VRAE Run 104/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1965, recon=0.1965, kl=12.1746, beta=0.0000\n",
      "Batch 40, loss=0.1140, recon=0.1140, kl=24.1157, beta=0.0000\n",
      "Batch 60, loss=0.0899, recon=0.0899, kl=28.1121, beta=0.0000\n",
      "Batch 80, loss=0.0790, recon=0.0790, kl=27.3934, beta=0.0000\n",
      "Batch 100, loss=0.0591, recon=0.0591, kl=29.1452, beta=0.0000\n",
      "Batch 120, loss=0.0972, recon=0.0972, kl=25.0742, beta=0.0000\n",
      "Batch 140, loss=0.0725, recon=0.0725, kl=28.7112, beta=0.0000\n",
      "Batch 160, loss=0.0370, recon=0.0370, kl=29.6132, beta=0.0000\n",
      "Batch 180, loss=0.0768, recon=0.0768, kl=27.9878, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1118 (Recon: 0.1118, KL: 24.9841, Current Beta: 0.0000) | Avg Valid Loss: 0.0558 | Avg Valid recon Loss: 0.0558\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0465, recon=0.0465, kl=29.2588, beta=0.0000\n",
      "Batch 40, loss=0.0530, recon=0.0530, kl=30.0086, beta=0.0000\n",
      "Batch 60, loss=0.0279, recon=0.0279, kl=32.6200, beta=0.0000\n",
      "Batch 80, loss=0.0336, recon=0.0336, kl=28.6824, beta=0.0000\n",
      "Batch 100, loss=0.0468, recon=0.0468, kl=30.6304, beta=0.0000\n",
      "Batch 120, loss=0.2262, recon=0.2262, kl=26.3087, beta=0.0000\n",
      "Batch 140, loss=0.1031, recon=0.1031, kl=29.5800, beta=0.0000\n",
      "Batch 160, loss=0.0601, recon=0.0601, kl=32.1067, beta=0.0000\n",
      "Batch 180, loss=0.0433, recon=0.0433, kl=35.4991, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0624 (Recon: 0.0624, KL: 29.9754, Current Beta: 0.0000) | Avg Valid Loss: 0.0611 | Avg Valid recon Loss: 0.0611\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0341, recon=0.0341, kl=34.9516, beta=0.0000\n",
      "Batch 40, loss=0.8575, recon=0.8575, kl=35.7371, beta=0.0000\n",
      "Batch 60, loss=0.0328, recon=0.0328, kl=34.4384, beta=0.0000\n",
      "Batch 80, loss=0.0440, recon=0.0440, kl=36.9438, beta=0.0000\n",
      "Batch 100, loss=0.0312, recon=0.0312, kl=26.2005, beta=0.0000\n",
      "Batch 120, loss=0.0975, recon=0.0975, kl=30.2441, beta=0.0000\n",
      "Batch 140, loss=0.0295, recon=0.0295, kl=35.2943, beta=0.0000\n",
      "Batch 160, loss=0.0277, recon=0.0277, kl=33.9266, beta=0.0000\n",
      "Batch 180, loss=0.0329, recon=0.0329, kl=32.8555, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0513 (Recon: 0.0513, KL: 33.2468, Current Beta: 0.0000) | Avg Valid Loss: 0.0432 | Avg Valid recon Loss: 0.0432\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0525, recon=0.0525, kl=31.7751, beta=0.0000\n",
      "Batch 40, loss=0.0311, recon=0.0311, kl=34.1167, beta=0.0000\n",
      "Batch 60, loss=0.0864, recon=0.0864, kl=36.8307, beta=0.0000\n",
      "Batch 80, loss=0.0280, recon=0.0280, kl=27.3055, beta=0.0000\n",
      "Batch 100, loss=0.0396, recon=0.0396, kl=36.5786, beta=0.0000\n",
      "Batch 120, loss=0.0330, recon=0.0330, kl=36.0519, beta=0.0000\n",
      "Batch 140, loss=0.0611, recon=0.0611, kl=41.6159, beta=0.0000\n",
      "Batch 160, loss=0.0398, recon=0.0398, kl=40.9265, beta=0.0000\n",
      "Batch 180, loss=0.0252, recon=0.0252, kl=40.5636, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0494, KL: 36.6915, Current Beta: 0.0000) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0419, recon=0.0418, kl=38.6958, beta=0.0000\n",
      "Batch 40, loss=0.0364, recon=0.0364, kl=36.0931, beta=0.0000\n",
      "Batch 60, loss=0.0287, recon=0.0287, kl=36.0768, beta=0.0000\n",
      "Batch 80, loss=0.0286, recon=0.0286, kl=35.2766, beta=0.0000\n",
      "Batch 100, loss=0.0286, recon=0.0285, kl=33.4130, beta=0.0000\n",
      "Batch 120, loss=0.0237, recon=0.0237, kl=32.3138, beta=0.0000\n",
      "Batch 140, loss=0.0420, recon=0.0420, kl=31.0294, beta=0.0000\n",
      "Batch 160, loss=0.0480, recon=0.0480, kl=32.2888, beta=0.0000\n",
      "Batch 180, loss=0.0408, recon=0.0408, kl=33.2872, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0430, KL: 34.6459, Current Beta: 0.0000) | Avg Valid Loss: 0.0453 | Avg Valid recon Loss: 0.0453\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0421, recon=0.0421, kl=31.6650, beta=0.0000\n",
      "Batch 40, loss=0.0556, recon=0.0555, kl=28.2284, beta=0.0000\n",
      "Batch 60, loss=0.0759, recon=0.0759, kl=19.0260, beta=0.0000\n",
      "Batch 80, loss=0.0317, recon=0.0317, kl=30.3236, beta=0.0000\n",
      "Batch 100, loss=0.0256, recon=0.0256, kl=28.7604, beta=0.0000\n",
      "Batch 120, loss=0.1557, recon=0.1556, kl=23.7316, beta=0.0000\n",
      "Batch 140, loss=0.0401, recon=0.0400, kl=32.5531, beta=0.0000\n",
      "Batch 160, loss=0.0401, recon=0.0400, kl=32.4575, beta=0.0000\n",
      "Batch 180, loss=0.0218, recon=0.0218, kl=32.0659, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0559 (Recon: 0.0558, KL: 29.3028, Current Beta: 0.0000) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0195, recon=0.0193, kl=29.1461, beta=0.0000\n",
      "Batch 40, loss=0.0238, recon=0.0237, kl=25.6752, beta=0.0000\n",
      "Batch 60, loss=0.0301, recon=0.0299, kl=26.0228, beta=0.0000\n",
      "Batch 80, loss=0.0544, recon=0.0543, kl=27.7536, beta=0.0000\n",
      "Batch 100, loss=0.0342, recon=0.0340, kl=28.6594, beta=0.0000\n",
      "Batch 120, loss=0.0639, recon=0.0637, kl=27.8465, beta=0.0000\n",
      "Batch 140, loss=0.0580, recon=0.0579, kl=27.3781, beta=0.0000\n",
      "Batch 160, loss=0.1174, recon=0.1173, kl=27.7454, beta=0.0000\n",
      "Batch 180, loss=0.1591, recon=0.1589, kl=26.1165, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0526, KL: 27.3821, Current Beta: 0.0000) | Avg Valid Loss: 0.0704 | Avg Valid recon Loss: 0.0702\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0312, recon=0.0309, kl=21.2810, beta=0.0000\n",
      "Batch 40, loss=0.0710, recon=0.0707, kl=21.6781, beta=0.0000\n",
      "Batch 60, loss=0.0574, recon=0.0571, kl=20.5681, beta=0.0000\n",
      "Batch 80, loss=0.0235, recon=0.0232, kl=16.8191, beta=0.0000\n",
      "Batch 100, loss=0.0413, recon=0.0410, kl=18.3503, beta=0.0000\n",
      "Batch 120, loss=0.0384, recon=0.0381, kl=21.5995, beta=0.0000\n",
      "Batch 140, loss=0.0455, recon=0.0452, kl=23.9455, beta=0.0000\n",
      "Batch 160, loss=0.0292, recon=0.0289, kl=21.2868, beta=0.0000\n",
      "Batch 180, loss=0.0400, recon=0.0396, kl=23.6072, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0549 (Recon: 0.0546, KL: 21.3294, Current Beta: 0.0000) | Avg Valid Loss: 0.0532 | Avg Valid recon Loss: 0.0528\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0639, recon=0.0632, kl=15.2715, beta=0.0000\n",
      "Batch 40, loss=0.0659, recon=0.0651, kl=18.5113, beta=0.0000\n",
      "Batch 60, loss=0.0923, recon=0.0915, kl=19.1670, beta=0.0000\n",
      "Batch 80, loss=0.0548, recon=0.0540, kl=21.6176, beta=0.0000\n",
      "Batch 100, loss=0.0570, recon=0.0562, kl=20.8704, beta=0.0000\n",
      "Batch 120, loss=0.0438, recon=0.0430, kl=19.0000, beta=0.0000\n",
      "Batch 140, loss=0.0368, recon=0.0361, kl=17.6658, beta=0.0000\n",
      "Batch 160, loss=0.0399, recon=0.0392, kl=18.1628, beta=0.0000\n",
      "Batch 180, loss=0.0285, recon=0.0278, kl=17.4510, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0660 (Recon: 0.0652, KL: 19.1347, Current Beta: 0.0000) | Avg Valid Loss: 0.0429 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0567, recon=0.0553, kl=12.9440, beta=0.0001\n",
      "Batch 40, loss=0.0519, recon=0.0507, kl=10.6349, beta=0.0001\n",
      "Batch 60, loss=0.3504, recon=0.3490, kl=12.6584, beta=0.0001\n",
      "Batch 80, loss=0.1040, recon=0.1011, kl=26.2116, beta=0.0001\n",
      "Batch 100, loss=0.0490, recon=0.0462, kl=25.1206, beta=0.0001\n",
      "Batch 120, loss=0.0647, recon=0.0624, kl=20.9076, beta=0.0001\n",
      "Batch 140, loss=1.7547, recon=1.7515, kl=29.1646, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 11/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0003) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 12/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0008) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 13/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0018) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 14/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0038) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0062) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 105/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4079, recon=0.4079, kl=1.1297, beta=0.0000\n",
      "Batch 40, loss=0.2077, recon=0.2077, kl=31.1468, beta=0.0000\n",
      "Batch 60, loss=0.1480, recon=0.1480, kl=45.5971, beta=0.0000\n",
      "Batch 80, loss=0.0976, recon=0.0976, kl=52.0300, beta=0.0000\n",
      "Batch 100, loss=0.1384, recon=0.1384, kl=57.9908, beta=0.0000\n",
      "Batch 120, loss=0.1301, recon=0.1301, kl=64.2595, beta=0.0000\n",
      "Batch 140, loss=0.5995, recon=0.5995, kl=70.5663, beta=0.0000\n",
      "Batch 160, loss=0.0950, recon=0.0949, kl=78.1099, beta=0.0000\n",
      "Batch 180, loss=0.0689, recon=0.0689, kl=76.7734, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2055 (Recon: 0.2055, KL: 49.4293, Current Beta: 0.0000) | Avg Valid Loss: 0.0871 | Avg Valid recon Loss: 0.0871\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0750, recon=0.0750, kl=82.5943, beta=0.0000\n",
      "Batch 40, loss=0.1177, recon=0.1177, kl=78.3565, beta=0.0000\n",
      "Batch 60, loss=0.0760, recon=0.0760, kl=79.8184, beta=0.0000\n",
      "Batch 80, loss=0.1025, recon=0.1025, kl=75.9203, beta=0.0000\n",
      "Batch 100, loss=0.0629, recon=0.0629, kl=74.3793, beta=0.0000\n",
      "Batch 120, loss=0.0607, recon=0.0607, kl=83.1329, beta=0.0000\n",
      "Batch 140, loss=0.0763, recon=0.0763, kl=82.4892, beta=0.0000\n",
      "Batch 160, loss=0.0723, recon=0.0723, kl=74.5789, beta=0.0000\n",
      "Batch 180, loss=0.1789, recon=0.1789, kl=77.4034, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0937 (Recon: 0.0937, KL: 78.6150, Current Beta: 0.0000) | Avg Valid Loss: 0.0657 | Avg Valid recon Loss: 0.0657\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0504, recon=0.0504, kl=79.3629, beta=0.0000\n",
      "Batch 40, loss=0.0483, recon=0.0483, kl=70.8248, beta=0.0000\n",
      "Batch 60, loss=0.0593, recon=0.0593, kl=66.0007, beta=0.0000\n",
      "Batch 80, loss=0.0480, recon=0.0480, kl=68.2894, beta=0.0000\n",
      "Batch 100, loss=0.0444, recon=0.0444, kl=74.7564, beta=0.0000\n",
      "Batch 120, loss=0.0642, recon=0.0642, kl=71.4750, beta=0.0000\n",
      "Batch 140, loss=0.0680, recon=0.0680, kl=69.9275, beta=0.0000\n",
      "Batch 160, loss=0.0740, recon=0.0740, kl=67.7609, beta=0.0000\n",
      "Batch 180, loss=0.0534, recon=0.0534, kl=67.9506, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0709 (Recon: 0.0709, KL: 70.9174, Current Beta: 0.0000) | Avg Valid Loss: 0.0540 | Avg Valid recon Loss: 0.0540\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0346, recon=0.0346, kl=62.2108, beta=0.0000\n",
      "Batch 40, loss=0.0388, recon=0.0388, kl=56.4821, beta=0.0000\n",
      "Batch 60, loss=0.0508, recon=0.0508, kl=53.2094, beta=0.0000\n",
      "Batch 80, loss=0.0634, recon=0.0634, kl=50.8081, beta=0.0000\n",
      "Batch 100, loss=0.0502, recon=0.0501, kl=49.0450, beta=0.0000\n",
      "Batch 120, loss=0.0458, recon=0.0457, kl=49.7832, beta=0.0000\n",
      "Batch 140, loss=0.0403, recon=0.0403, kl=51.9550, beta=0.0000\n",
      "Batch 160, loss=0.0749, recon=0.0748, kl=47.7467, beta=0.0000\n",
      "Batch 180, loss=0.2113, recon=0.2113, kl=47.9749, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0603 (Recon: 0.0603, KL: 53.1749, Current Beta: 0.0000) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0493, recon=0.0493, kl=39.6296, beta=0.0000\n",
      "Batch 40, loss=0.0298, recon=0.0298, kl=37.8756, beta=0.0000\n",
      "Batch 60, loss=0.0479, recon=0.0479, kl=32.9891, beta=0.0000\n",
      "Batch 80, loss=0.0418, recon=0.0418, kl=35.9078, beta=0.0000\n",
      "Batch 100, loss=0.0580, recon=0.0580, kl=36.0364, beta=0.0000\n",
      "Batch 120, loss=0.0438, recon=0.0438, kl=35.6365, beta=0.0000\n",
      "Batch 140, loss=0.0385, recon=0.0384, kl=29.7598, beta=0.0000\n",
      "Batch 160, loss=0.0351, recon=0.0351, kl=32.4447, beta=0.0000\n",
      "Batch 180, loss=0.0304, recon=0.0303, kl=31.9776, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0528, KL: 35.5256, Current Beta: 0.0000) | Avg Valid Loss: 0.0454 | Avg Valid recon Loss: 0.0454\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0408, recon=0.0407, kl=23.9171, beta=0.0000\n",
      "Batch 40, loss=0.0401, recon=0.0401, kl=17.2625, beta=0.0000\n",
      "Batch 60, loss=0.0357, recon=0.0356, kl=19.8943, beta=0.0000\n",
      "Batch 80, loss=0.0259, recon=0.0259, kl=19.1974, beta=0.0000\n",
      "Batch 100, loss=0.0350, recon=0.0349, kl=18.1516, beta=0.0000\n",
      "Batch 120, loss=0.0462, recon=0.0462, kl=17.1780, beta=0.0000\n",
      "Batch 140, loss=0.0254, recon=0.0254, kl=18.1848, beta=0.0000\n",
      "Batch 160, loss=0.0939, recon=0.0939, kl=17.0729, beta=0.0000\n",
      "Batch 180, loss=0.0711, recon=0.0710, kl=15.9106, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0478, KL: 19.2560, Current Beta: 0.0000) | Avg Valid Loss: 0.0424 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0297, recon=0.0296, kl=9.8521, beta=0.0000\n",
      "Batch 40, loss=0.0314, recon=0.0314, kl=8.5831, beta=0.0000\n",
      "Batch 60, loss=0.0531, recon=0.0531, kl=7.7926, beta=0.0000\n",
      "Batch 80, loss=0.0251, recon=0.0250, kl=6.7523, beta=0.0000\n",
      "Batch 100, loss=0.1063, recon=0.1063, kl=7.6802, beta=0.0000\n",
      "Batch 120, loss=0.0536, recon=0.0536, kl=7.5091, beta=0.0000\n",
      "Batch 140, loss=0.0915, recon=0.0915, kl=8.2844, beta=0.0000\n",
      "Batch 160, loss=0.0352, recon=0.0352, kl=7.6135, beta=0.0000\n",
      "Batch 180, loss=0.0405, recon=0.0405, kl=6.9760, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0443 (Recon: 0.0443, KL: 8.3167, Current Beta: 0.0000) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0257, recon=0.0257, kl=2.8071, beta=0.0000\n",
      "Batch 40, loss=0.0620, recon=0.0619, kl=3.2177, beta=0.0000\n",
      "Batch 60, loss=0.0196, recon=0.0196, kl=3.0511, beta=0.0000\n",
      "Batch 80, loss=0.2264, recon=0.2263, kl=4.2073, beta=0.0000\n",
      "Batch 100, loss=0.1167, recon=0.1166, kl=3.2227, beta=0.0000\n",
      "Batch 120, loss=0.0292, recon=0.0292, kl=2.6733, beta=0.0000\n",
      "Batch 140, loss=0.0396, recon=0.0395, kl=2.5998, beta=0.0000\n",
      "Batch 160, loss=0.0435, recon=0.0435, kl=2.2134, beta=0.0000\n",
      "Batch 180, loss=0.0279, recon=0.0279, kl=2.4228, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0415, KL: 3.1161, Current Beta: 0.0000) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0361\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0298, recon=0.0298, kl=0.6365, beta=0.0000\n",
      "Batch 40, loss=0.0267, recon=0.0267, kl=1.1040, beta=0.0000\n",
      "Batch 60, loss=0.1240, recon=0.1239, kl=0.6270, beta=0.0000\n",
      "Batch 80, loss=0.0312, recon=0.0311, kl=0.5395, beta=0.0000\n",
      "Batch 100, loss=0.0330, recon=0.0330, kl=0.5148, beta=0.0000\n",
      "Batch 120, loss=0.0571, recon=0.0570, kl=0.7009, beta=0.0000\n",
      "Batch 140, loss=0.0797, recon=0.0797, kl=0.6287, beta=0.0000\n",
      "Batch 160, loss=0.0288, recon=0.0288, kl=0.7675, beta=0.0000\n",
      "Batch 180, loss=0.0329, recon=0.0329, kl=0.5526, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0395, KL: 0.7669, Current Beta: 0.0000) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0194, recon=0.0194, kl=0.1046, beta=0.0001\n",
      "Batch 40, loss=0.0346, recon=0.0346, kl=0.2658, beta=0.0001\n",
      "Batch 60, loss=0.0287, recon=0.0287, kl=0.1257, beta=0.0001\n",
      "Batch 80, loss=0.0319, recon=0.0319, kl=0.1140, beta=0.0001\n",
      "Batch 100, loss=0.0347, recon=0.0347, kl=0.0570, beta=0.0001\n",
      "Batch 120, loss=0.0333, recon=0.0333, kl=0.0696, beta=0.0001\n",
      "Batch 140, loss=0.0369, recon=0.0369, kl=0.0606, beta=0.0001\n",
      "Batch 160, loss=0.0367, recon=0.0367, kl=0.0412, beta=0.0001\n",
      "Batch 180, loss=0.0703, recon=0.0703, kl=0.0595, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0381 (Recon: 0.0381, KL: 0.1168, Current Beta: 0.0001) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0226, recon=0.0226, kl=0.0180, beta=0.0003\n",
      "Batch 40, loss=0.0240, recon=0.0240, kl=0.0063, beta=0.0003\n",
      "Batch 60, loss=0.0221, recon=0.0221, kl=0.0030, beta=0.0003\n",
      "Batch 80, loss=0.0399, recon=0.0399, kl=0.0139, beta=0.0003\n",
      "Batch 100, loss=0.0385, recon=0.0385, kl=0.0042, beta=0.0003\n",
      "Batch 120, loss=0.0303, recon=0.0303, kl=0.0214, beta=0.0003\n",
      "Batch 140, loss=0.0223, recon=0.0223, kl=0.0031, beta=0.0003\n",
      "Batch 160, loss=0.1135, recon=0.1135, kl=0.0118, beta=0.0003\n",
      "Batch 180, loss=0.0231, recon=0.0231, kl=0.0128, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0365 (Recon: 0.0365, KL: 0.0121, Current Beta: 0.0003) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0318\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0253, recon=0.0253, kl=0.0013, beta=0.0008\n",
      "Batch 40, loss=0.0320, recon=0.0320, kl=0.0008, beta=0.0008\n",
      "Batch 60, loss=0.0274, recon=0.0274, kl=0.0005, beta=0.0008\n",
      "Batch 80, loss=0.0380, recon=0.0380, kl=0.0014, beta=0.0008\n",
      "Batch 100, loss=0.0214, recon=0.0214, kl=0.0008, beta=0.0008\n",
      "Batch 120, loss=0.0210, recon=0.0210, kl=0.0006, beta=0.0008\n",
      "Batch 140, loss=0.0212, recon=0.0212, kl=0.0049, beta=0.0008\n",
      "Batch 160, loss=0.0334, recon=0.0334, kl=0.0014, beta=0.0008\n",
      "Batch 180, loss=0.0366, recon=0.0366, kl=0.0008, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0354, KL: 0.0015, Current Beta: 0.0008) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0304\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0208, recon=0.0208, kl=0.0002, beta=0.0018\n",
      "Batch 40, loss=0.0199, recon=0.0199, kl=0.0001, beta=0.0018\n",
      "Batch 60, loss=0.0426, recon=0.0426, kl=0.0013, beta=0.0018\n",
      "Batch 80, loss=0.0370, recon=0.0370, kl=0.0002, beta=0.0018\n",
      "Batch 100, loss=0.0205, recon=0.0205, kl=0.0001, beta=0.0018\n",
      "Batch 120, loss=0.0250, recon=0.0250, kl=0.0005, beta=0.0018\n",
      "Batch 140, loss=0.0410, recon=0.0410, kl=0.0002, beta=0.0018\n",
      "Batch 160, loss=0.0418, recon=0.0418, kl=0.0001, beta=0.0018\n",
      "Batch 180, loss=0.0360, recon=0.0360, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0344 (Recon: 0.0344, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0304\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0300, recon=0.0300, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0165, recon=0.0165, kl=0.0000, beta=0.0038\n",
      "Batch 60, loss=0.0239, recon=0.0239, kl=0.0000, beta=0.0038\n",
      "Batch 80, loss=0.0232, recon=0.0232, kl=0.0000, beta=0.0038\n",
      "Batch 100, loss=0.0253, recon=0.0253, kl=0.0001, beta=0.0038\n",
      "Batch 120, loss=0.0259, recon=0.0259, kl=0.0000, beta=0.0038\n",
      "Batch 140, loss=0.0249, recon=0.0249, kl=0.0000, beta=0.0038\n",
      "Batch 160, loss=0.0283, recon=0.0283, kl=0.0001, beta=0.0038\n",
      "Batch 180, loss=0.0303, recon=0.0303, kl=0.0000, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0335 (Recon: 0.0335, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0291 | Avg Valid recon Loss: 0.0291\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0331, recon=0.0331, kl=0.0000, beta=0.0062\n",
      "Batch 40, loss=0.0342, recon=0.0342, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0197, recon=0.0197, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0195, recon=0.0195, kl=0.0000, beta=0.0062\n",
      "Batch 100, loss=0.0237, recon=0.0237, kl=0.0002, beta=0.0062\n",
      "Batch 120, loss=0.0211, recon=0.0211, kl=0.0000, beta=0.0062\n",
      "Batch 140, loss=0.0417, recon=0.0417, kl=0.0001, beta=0.0062\n",
      "Batch 160, loss=0.0266, recon=0.0266, kl=0.0000, beta=0.0062\n",
      "Batch 180, loss=0.0273, recon=0.0273, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0330 (Recon: 0.0330, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0301 | Avg Valid recon Loss: 0.0301\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0228, recon=0.0228, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0242, recon=0.0242, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0602, recon=0.0602, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0310, recon=0.0310, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0226, recon=0.0226, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0198, recon=0.0198, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0207, recon=0.0207, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0257, recon=0.0257, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0204, recon=0.0204, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0322 (Recon: 0.0322, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0304\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0275, recon=0.0275, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.1103, recon=0.1103, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.1270, recon=0.1270, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0264, recon=0.0264, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0212, recon=0.0212, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0192, recon=0.0192, kl=0.0002, beta=0.0100\n",
      "Batch 140, loss=0.0232, recon=0.0232, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0184, recon=0.0184, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0176, recon=0.0176, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0325 (Recon: 0.0325, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0295 | Avg Valid recon Loss: 0.0295\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0200, recon=0.0200, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0321, recon=0.0321, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0255, recon=0.0255, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0471, recon=0.0471, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0400, recon=0.0400, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0214, recon=0.0214, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0290, recon=0.0290, kl=0.0003, beta=0.0100\n",
      "Batch 160, loss=0.0247, recon=0.0247, kl=0.0001, beta=0.0100\n",
      "Batch 180, loss=0.0276, recon=0.0276, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0329 (Recon: 0.0329, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0272 | Avg Valid recon Loss: 0.0272\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0265, recon=0.0265, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0398, recon=0.0398, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0268, recon=0.0268, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0276, recon=0.0276, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0983, recon=0.0983, kl=0.0001, beta=0.0100\n",
      "Batch 120, loss=0.0214, recon=0.0214, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0179, recon=0.0179, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0209, recon=0.0209, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0215, recon=0.0215, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0306 (Recon: 0.0306, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0271 | Avg Valid recon Loss: 0.0271\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0435, recon=0.0435, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0261, recon=0.0260, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0497, recon=0.0497, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0243, recon=0.0243, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0209, recon=0.0209, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0213, recon=0.0213, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0199, recon=0.0199, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0494, recon=0.0494, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0216, recon=0.0216, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0300 (Recon: 0.0300, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0264 | Avg Valid recon Loss: 0.0264\n",
      "\n",
      "[VRAE Run 106/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1873, recon=0.1873, kl=38.3306, beta=0.0000\n",
      "Batch 40, loss=0.0703, recon=0.0703, kl=45.5464, beta=0.0000\n",
      "Batch 60, loss=0.1456, recon=0.1456, kl=43.6212, beta=0.0000\n",
      "Batch 80, loss=0.0711, recon=0.0711, kl=53.7311, beta=0.0000\n",
      "Batch 100, loss=0.1071, recon=0.1071, kl=35.8573, beta=0.0000\n",
      "Batch 120, loss=0.0603, recon=0.0603, kl=52.8227, beta=0.0000\n",
      "Batch 140, loss=0.0506, recon=0.0506, kl=58.9823, beta=0.0000\n",
      "Batch 160, loss=0.2754, recon=0.2754, kl=66.7039, beta=0.0000\n",
      "Batch 180, loss=0.0661, recon=0.0661, kl=66.3330, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1142 (Recon: 0.1142, KL: 48.5105, Current Beta: 0.0000) | Avg Valid Loss: 0.0671 | Avg Valid recon Loss: 0.0671\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0665, recon=0.0665, kl=67.3517, beta=0.0000\n",
      "Batch 40, loss=0.0496, recon=0.0496, kl=62.7721, beta=0.0000\n",
      "Batch 60, loss=0.0381, recon=0.0381, kl=59.3774, beta=0.0000\n",
      "Batch 80, loss=0.0408, recon=0.0408, kl=48.4733, beta=0.0000\n",
      "Batch 100, loss=0.0321, recon=0.0321, kl=56.9463, beta=0.0000\n",
      "Batch 120, loss=0.0445, recon=0.0445, kl=62.0375, beta=0.0000\n",
      "Batch 140, loss=0.0591, recon=0.0591, kl=56.7658, beta=0.0000\n",
      "Batch 160, loss=0.0500, recon=0.0500, kl=61.4472, beta=0.0000\n",
      "Batch 180, loss=0.0404, recon=0.0404, kl=66.6355, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0571 (Recon: 0.0571, KL: 59.9433, Current Beta: 0.0000) | Avg Valid Loss: 0.0511 | Avg Valid recon Loss: 0.0511\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0302, recon=0.0302, kl=69.1114, beta=0.0000\n",
      "Batch 40, loss=0.0487, recon=0.0487, kl=66.5200, beta=0.0000\n",
      "Batch 60, loss=0.0352, recon=0.0352, kl=63.5920, beta=0.0000\n",
      "Batch 80, loss=0.0322, recon=0.0322, kl=50.2394, beta=0.0000\n",
      "Batch 100, loss=0.0979, recon=0.0979, kl=60.6202, beta=0.0000\n",
      "Batch 120, loss=0.0331, recon=0.0331, kl=65.0493, beta=0.0000\n",
      "Batch 140, loss=0.0430, recon=0.0430, kl=61.4519, beta=0.0000\n",
      "Batch 160, loss=0.0305, recon=0.0305, kl=60.5863, beta=0.0000\n",
      "Batch 180, loss=0.0219, recon=0.0219, kl=64.4732, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0539 (Recon: 0.0539, KL: 62.1663, Current Beta: 0.0000) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0409, recon=0.0409, kl=69.0221, beta=0.0000\n",
      "Batch 40, loss=0.0262, recon=0.0262, kl=68.3401, beta=0.0000\n",
      "Batch 60, loss=0.0411, recon=0.0411, kl=64.0629, beta=0.0000\n",
      "Batch 80, loss=0.0298, recon=0.0298, kl=58.4065, beta=0.0000\n",
      "Batch 100, loss=0.0669, recon=0.0669, kl=62.4570, beta=0.0000\n",
      "Batch 120, loss=0.0225, recon=0.0225, kl=62.7463, beta=0.0000\n",
      "Batch 140, loss=0.0249, recon=0.0248, kl=61.4394, beta=0.0000\n",
      "Batch 160, loss=0.0192, recon=0.0191, kl=60.8807, beta=0.0000\n",
      "Batch 180, loss=0.6060, recon=0.6060, kl=65.6545, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0416, KL: 63.9580, Current Beta: 0.0000) | Avg Valid Loss: 0.0968 | Avg Valid recon Loss: 0.0968\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0924, recon=0.0923, kl=92.7656, beta=0.0000\n",
      "Batch 40, loss=0.0659, recon=0.0658, kl=78.2971, beta=0.0000\n",
      "Batch 60, loss=0.0411, recon=0.0411, kl=85.0173, beta=0.0000\n",
      "Batch 80, loss=0.0419, recon=0.0419, kl=88.0464, beta=0.0000\n",
      "Batch 100, loss=0.0379, recon=0.0379, kl=86.9343, beta=0.0000\n",
      "Batch 120, loss=0.0295, recon=0.0294, kl=88.0762, beta=0.0000\n",
      "Batch 140, loss=0.0380, recon=0.0379, kl=88.5439, beta=0.0000\n",
      "Batch 160, loss=0.0280, recon=0.0280, kl=88.4563, beta=0.0000\n",
      "Batch 180, loss=0.0457, recon=0.0457, kl=88.9031, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0794 (Recon: 0.0793, KL: 83.7440, Current Beta: 0.0000) | Avg Valid Loss: 0.0527 | Avg Valid recon Loss: 0.0527\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0541, recon=0.0539, kl=96.3521, beta=0.0000\n",
      "Batch 40, loss=0.0282, recon=0.0280, kl=84.0638, beta=0.0000\n",
      "Batch 60, loss=0.0380, recon=0.0378, kl=90.7158, beta=0.0000\n",
      "Batch 80, loss=0.0406, recon=0.0404, kl=87.6070, beta=0.0000\n",
      "Batch 100, loss=0.0258, recon=0.0256, kl=92.0938, beta=0.0000\n",
      "Batch 120, loss=0.0604, recon=0.0602, kl=96.4682, beta=0.0000\n",
      "Batch 140, loss=0.1532, recon=0.1530, kl=97.7069, beta=0.0000\n",
      "Batch 160, loss=0.0323, recon=0.0321, kl=96.7978, beta=0.0000\n",
      "Batch 180, loss=0.0445, recon=0.0444, kl=95.5305, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0515 (Recon: 0.0514, KL: 92.7021, Current Beta: 0.0000) | Avg Valid Loss: 0.0529 | Avg Valid recon Loss: 0.0527\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0696, recon=0.0691, kl=90.1807, beta=0.0000\n",
      "Batch 40, loss=0.0227, recon=0.0222, kl=82.8737, beta=0.0000\n",
      "Batch 60, loss=0.0680, recon=0.0676, kl=76.8734, beta=0.0000\n",
      "Batch 80, loss=0.0686, recon=0.0682, kl=77.8180, beta=0.0000\n",
      "Batch 100, loss=0.0444, recon=0.0440, kl=81.5250, beta=0.0000\n",
      "Batch 120, loss=0.1482, recon=0.1478, kl=81.4201, beta=0.0000\n",
      "Batch 140, loss=0.0386, recon=0.0381, kl=78.8540, beta=0.0000\n",
      "Batch 160, loss=0.0423, recon=0.0419, kl=77.8925, beta=0.0000\n",
      "Batch 180, loss=0.0571, recon=0.0567, kl=75.7024, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0574 (Recon: 0.0570, KL: 81.2814, Current Beta: 0.0000) | Avg Valid Loss: 0.0491 | Avg Valid recon Loss: 0.0487\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0254, recon=0.0244, kl=65.3367, beta=0.0000\n",
      "Batch 40, loss=0.1494, recon=0.1485, kl=61.0019, beta=0.0000\n",
      "Batch 60, loss=0.0294, recon=0.0285, kl=56.7371, beta=0.0000\n",
      "Batch 80, loss=0.0234, recon=0.0225, kl=57.8059, beta=0.0000\n",
      "Batch 100, loss=0.0289, recon=0.0281, kl=52.3378, beta=0.0000\n",
      "Batch 120, loss=0.0463, recon=0.0455, kl=52.9113, beta=0.0000\n",
      "Batch 140, loss=0.0709, recon=0.0701, kl=57.4599, beta=0.0000\n",
      "Batch 160, loss=0.0501, recon=0.0492, kl=58.3566, beta=0.0000\n",
      "Batch 180, loss=0.0410, recon=0.0402, kl=55.1871, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0456 (Recon: 0.0448, KL: 57.7718, Current Beta: 0.0000) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0424\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0598, recon=0.0579, kl=47.4017, beta=0.0000\n",
      "Batch 40, loss=0.0395, recon=0.0378, kl=40.6664, beta=0.0000\n",
      "Batch 60, loss=0.0404, recon=0.0388, kl=38.0661, beta=0.0000\n",
      "Batch 80, loss=0.0238, recon=0.0223, kl=37.6438, beta=0.0000\n",
      "Batch 100, loss=0.0215, recon=0.0201, kl=35.9680, beta=0.0000\n",
      "Batch 120, loss=0.0331, recon=0.0317, kl=35.0790, beta=0.0000\n",
      "Batch 140, loss=0.0372, recon=0.0358, kl=35.2049, beta=0.0000\n",
      "Batch 160, loss=0.0195, recon=0.0180, kl=35.3234, beta=0.0000\n",
      "Batch 180, loss=0.0508, recon=0.0494, kl=35.3941, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0408, KL: 38.3367, Current Beta: 0.0000) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0458\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0358, recon=0.0326, kl=29.0268, beta=0.0001\n",
      "Batch 40, loss=0.0617, recon=0.0589, kl=24.9554, beta=0.0001\n",
      "Batch 60, loss=0.0796, recon=0.0768, kl=26.0182, beta=0.0001\n",
      "Batch 80, loss=0.0793, recon=0.0769, kl=21.4316, beta=0.0001\n",
      "Batch 100, loss=0.0267, recon=0.0244, kl=20.9825, beta=0.0001\n",
      "Batch 120, loss=0.1137, recon=0.1116, kl=19.0925, beta=0.0001\n",
      "Batch 140, loss=0.0470, recon=0.0452, kl=16.9376, beta=0.0001\n",
      "Batch 160, loss=0.0662, recon=0.0642, kl=18.5286, beta=0.0001\n",
      "Batch 180, loss=0.0440, recon=0.0420, kl=18.4325, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0553 (Recon: 0.0528, KL: 22.6530, Current Beta: 0.0001) | Avg Valid Loss: 0.0481 | Avg Valid recon Loss: 0.0460\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0354, recon=0.0326, kl=9.4621, beta=0.0003\n",
      "Batch 40, loss=0.0473, recon=0.0444, kl=9.9136, beta=0.0003\n",
      "Batch 60, loss=0.0320, recon=0.0298, kl=7.5469, beta=0.0003\n",
      "Batch 80, loss=0.0257, recon=0.0240, kl=5.7025, beta=0.0003\n",
      "Batch 100, loss=0.0713, recon=0.0698, kl=5.2487, beta=0.0003\n",
      "Batch 120, loss=0.0334, recon=0.0321, kl=4.4678, beta=0.0003\n",
      "Batch 140, loss=0.0251, recon=0.0241, kl=3.4541, beta=0.0003\n",
      "Batch 160, loss=0.0744, recon=0.0729, kl=4.9871, beta=0.0003\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0003) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 12/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0008) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 13/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0018) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 14/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0038) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0062) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 107/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2623, recon=0.2623, kl=2.0567, beta=0.0000\n",
      "Batch 40, loss=0.2071, recon=0.2071, kl=68.1631, beta=0.0000\n",
      "Batch 60, loss=0.1880, recon=0.1880, kl=94.7083, beta=0.0000\n",
      "Batch 80, loss=0.1334, recon=0.1334, kl=112.0628, beta=0.0000\n",
      "Batch 100, loss=0.0889, recon=0.0889, kl=124.4242, beta=0.0000\n",
      "Batch 120, loss=0.0887, recon=0.0887, kl=133.0920, beta=0.0000\n",
      "Batch 140, loss=0.1139, recon=0.1139, kl=137.2565, beta=0.0000\n",
      "Batch 160, loss=0.0849, recon=0.0849, kl=147.2352, beta=0.0000\n",
      "Batch 180, loss=0.0845, recon=0.0845, kl=148.3394, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2099 (Recon: 0.2099, KL: 100.2911, Current Beta: 0.0000) | Avg Valid Loss: 0.0939 | Avg Valid recon Loss: 0.0939\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0969, recon=0.0969, kl=144.5455, beta=0.0000\n",
      "Batch 40, loss=0.0667, recon=0.0667, kl=138.7375, beta=0.0000\n",
      "Batch 60, loss=0.1041, recon=0.1041, kl=141.8772, beta=0.0000\n",
      "Batch 80, loss=0.0636, recon=0.0636, kl=142.0372, beta=0.0000\n",
      "Batch 100, loss=0.0477, recon=0.0477, kl=147.9048, beta=0.0000\n",
      "Batch 120, loss=0.0912, recon=0.0911, kl=153.6016, beta=0.0000\n",
      "Batch 140, loss=1.4717, recon=1.4717, kl=154.9424, beta=0.0000\n",
      "Batch 160, loss=0.0471, recon=0.0471, kl=149.5529, beta=0.0000\n",
      "Batch 180, loss=0.0566, recon=0.0566, kl=147.0681, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0954 (Recon: 0.0954, KL: 146.3974, Current Beta: 0.0000) | Avg Valid Loss: 0.0629 | Avg Valid recon Loss: 0.0629\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0634, recon=0.0634, kl=142.0582, beta=0.0000\n",
      "Batch 40, loss=0.0467, recon=0.0467, kl=132.8412, beta=0.0000\n",
      "Batch 60, loss=0.0448, recon=0.0448, kl=115.3260, beta=0.0000\n",
      "Batch 80, loss=0.0536, recon=0.0536, kl=134.2641, beta=0.0000\n",
      "Batch 100, loss=0.0479, recon=0.0478, kl=131.1836, beta=0.0000\n",
      "Batch 120, loss=0.0352, recon=0.0352, kl=128.6655, beta=0.0000\n",
      "Batch 140, loss=0.0417, recon=0.0417, kl=116.1843, beta=0.0000\n",
      "Batch 160, loss=0.1592, recon=0.1592, kl=123.8572, beta=0.0000\n",
      "Batch 180, loss=0.0304, recon=0.0304, kl=124.6497, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0713 (Recon: 0.0713, KL: 129.4419, Current Beta: 0.0000) | Avg Valid Loss: 0.0543 | Avg Valid recon Loss: 0.0543\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0556, recon=0.0555, kl=111.1260, beta=0.0000\n",
      "Batch 40, loss=0.0577, recon=0.0576, kl=98.8560, beta=0.0000\n",
      "Batch 60, loss=0.0463, recon=0.0462, kl=88.8446, beta=0.0000\n",
      "Batch 80, loss=0.0368, recon=0.0368, kl=89.8512, beta=0.0000\n",
      "Batch 100, loss=0.0624, recon=0.0624, kl=90.9977, beta=0.0000\n",
      "Batch 120, loss=0.0504, recon=0.0504, kl=85.4316, beta=0.0000\n",
      "Batch 140, loss=0.0493, recon=0.0493, kl=85.5345, beta=0.0000\n",
      "Batch 160, loss=0.0484, recon=0.0484, kl=85.1015, beta=0.0000\n",
      "Batch 180, loss=0.0392, recon=0.0392, kl=84.2211, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0607 (Recon: 0.0607, KL: 93.1516, Current Beta: 0.0000) | Avg Valid Loss: 0.0477 | Avg Valid recon Loss: 0.0476\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1021, recon=0.1020, kl=67.1259, beta=0.0000\n",
      "Batch 40, loss=0.0359, recon=0.0359, kl=55.0524, beta=0.0000\n",
      "Batch 60, loss=0.0395, recon=0.0395, kl=53.8689, beta=0.0000\n",
      "Batch 80, loss=0.0399, recon=0.0398, kl=53.0862, beta=0.0000\n",
      "Batch 100, loss=0.0326, recon=0.0326, kl=50.9351, beta=0.0000\n",
      "Batch 120, loss=0.0646, recon=0.0645, kl=46.1392, beta=0.0000\n",
      "Batch 140, loss=0.0322, recon=0.0321, kl=48.6330, beta=0.0000\n",
      "Batch 160, loss=0.0320, recon=0.0320, kl=48.0222, beta=0.0000\n",
      "Batch 180, loss=0.0420, recon=0.0420, kl=44.0812, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0536 (Recon: 0.0535, KL: 54.1361, Current Beta: 0.0000) | Avg Valid Loss: 0.0446 | Avg Valid recon Loss: 0.0445\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0438, recon=0.0437, kl=30.2592, beta=0.0000\n",
      "Batch 40, loss=0.0332, recon=0.0332, kl=22.7764, beta=0.0000\n",
      "Batch 60, loss=0.7480, recon=0.7480, kl=23.9516, beta=0.0000\n",
      "Batch 80, loss=0.0530, recon=0.0529, kl=24.9111, beta=0.0000\n",
      "Batch 100, loss=0.0341, recon=0.0341, kl=26.3429, beta=0.0000\n",
      "Batch 120, loss=0.0392, recon=0.0392, kl=25.7766, beta=0.0000\n",
      "Batch 140, loss=0.0298, recon=0.0297, kl=22.9881, beta=0.0000\n",
      "Batch 160, loss=0.0311, recon=0.0310, kl=21.6195, beta=0.0000\n",
      "Batch 180, loss=0.0660, recon=0.0660, kl=20.7346, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0485, KL: 25.5822, Current Beta: 0.0000) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0299, recon=0.0299, kl=12.7357, beta=0.0000\n",
      "Batch 40, loss=0.0380, recon=0.0380, kl=9.9720, beta=0.0000\n",
      "Batch 60, loss=0.0301, recon=0.0300, kl=11.9584, beta=0.0000\n",
      "Batch 80, loss=0.0229, recon=0.0229, kl=11.2810, beta=0.0000\n",
      "Batch 100, loss=0.1262, recon=0.1262, kl=9.9549, beta=0.0000\n",
      "Batch 120, loss=0.0235, recon=0.0234, kl=11.5110, beta=0.0000\n",
      "Batch 140, loss=0.0436, recon=0.0436, kl=9.5882, beta=0.0000\n",
      "Batch 160, loss=0.0396, recon=0.0395, kl=9.1190, beta=0.0000\n",
      "Batch 180, loss=0.0515, recon=0.0515, kl=7.9911, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0445 (Recon: 0.0444, KL: 10.9442, Current Beta: 0.0000) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0297, recon=0.0296, kl=2.6859, beta=0.0000\n",
      "Batch 40, loss=0.0311, recon=0.0310, kl=4.3115, beta=0.0000\n",
      "Batch 60, loss=0.0419, recon=0.0419, kl=3.2606, beta=0.0000\n",
      "Batch 80, loss=0.2560, recon=0.2559, kl=2.8536, beta=0.0000\n",
      "Batch 100, loss=0.0470, recon=0.0470, kl=3.4357, beta=0.0000\n",
      "Batch 120, loss=0.0253, recon=0.0253, kl=3.3019, beta=0.0000\n",
      "Batch 140, loss=0.0354, recon=0.0354, kl=2.9946, beta=0.0000\n",
      "Batch 160, loss=0.0286, recon=0.0286, kl=2.4923, beta=0.0000\n",
      "Batch 180, loss=0.0234, recon=0.0233, kl=2.3462, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0417, KL: 3.3938, Current Beta: 0.0000) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0474, recon=0.0474, kl=1.0307, beta=0.0000\n",
      "Batch 40, loss=0.0633, recon=0.0633, kl=1.2272, beta=0.0000\n",
      "Batch 60, loss=0.0186, recon=0.0185, kl=1.2416, beta=0.0000\n",
      "Batch 80, loss=0.0249, recon=0.0248, kl=1.1724, beta=0.0000\n",
      "Batch 100, loss=0.0295, recon=0.0295, kl=0.6834, beta=0.0000\n",
      "Batch 120, loss=0.0324, recon=0.0324, kl=0.8076, beta=0.0000\n",
      "Batch 140, loss=0.0227, recon=0.0227, kl=0.7853, beta=0.0000\n",
      "Batch 160, loss=0.0476, recon=0.0475, kl=0.8642, beta=0.0000\n",
      "Batch 180, loss=0.0225, recon=0.0225, kl=0.7526, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0397 (Recon: 0.0396, KL: 1.0219, Current Beta: 0.0000) | Avg Valid Loss: 0.0343 | Avg Valid recon Loss: 0.0343\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0159, recon=0.0158, kl=0.1562, beta=0.0001\n",
      "Batch 40, loss=0.0247, recon=0.0247, kl=0.1732, beta=0.0001\n",
      "Batch 60, loss=0.0242, recon=0.0242, kl=0.2441, beta=0.0001\n",
      "Batch 80, loss=0.0280, recon=0.0280, kl=0.1475, beta=0.0001\n",
      "Batch 100, loss=0.0200, recon=0.0199, kl=0.2994, beta=0.0001\n",
      "Batch 120, loss=0.0186, recon=0.0186, kl=0.1066, beta=0.0001\n",
      "Batch 140, loss=0.0243, recon=0.0242, kl=0.1090, beta=0.0001\n",
      "Batch 160, loss=0.0997, recon=0.0997, kl=0.1549, beta=0.0001\n",
      "Batch 180, loss=0.0275, recon=0.0275, kl=0.0725, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0377, KL: 0.1969, Current Beta: 0.0001) | Avg Valid Loss: 0.0329 | Avg Valid recon Loss: 0.0329\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0275, recon=0.0275, kl=0.0226, beta=0.0003\n",
      "Batch 40, loss=0.0412, recon=0.0412, kl=0.0176, beta=0.0003\n",
      "Batch 60, loss=0.0218, recon=0.0218, kl=0.0082, beta=0.0003\n",
      "Batch 80, loss=0.0212, recon=0.0212, kl=0.0083, beta=0.0003\n",
      "Batch 100, loss=0.0458, recon=0.0458, kl=0.0057, beta=0.0003\n",
      "Batch 120, loss=0.0207, recon=0.0207, kl=0.0245, beta=0.0003\n",
      "Batch 140, loss=0.0202, recon=0.0202, kl=0.0107, beta=0.0003\n",
      "Batch 160, loss=0.0354, recon=0.0354, kl=0.0070, beta=0.0003\n",
      "Batch 180, loss=0.0205, recon=0.0205, kl=0.0087, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0362, KL: 0.0140, Current Beta: 0.0003) | Avg Valid Loss: 0.0320 | Avg Valid recon Loss: 0.0320\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0260, recon=0.0260, kl=0.0016, beta=0.0008\n",
      "Batch 40, loss=0.0351, recon=0.0351, kl=0.0011, beta=0.0008\n",
      "Batch 60, loss=0.0209, recon=0.0209, kl=0.0016, beta=0.0008\n",
      "Batch 80, loss=0.0220, recon=0.0220, kl=0.0010, beta=0.0008\n",
      "Batch 100, loss=0.0296, recon=0.0296, kl=0.0006, beta=0.0008\n",
      "Batch 120, loss=0.0229, recon=0.0229, kl=0.0006, beta=0.0008\n",
      "Batch 140, loss=0.0228, recon=0.0228, kl=0.0009, beta=0.0008\n",
      "Batch 160, loss=0.0247, recon=0.0247, kl=0.0008, beta=0.0008\n",
      "Batch 180, loss=0.0226, recon=0.0226, kl=0.0082, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0352 (Recon: 0.0352, KL: 0.0016, Current Beta: 0.0008) | Avg Valid Loss: 0.0319 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0306, recon=0.0306, kl=0.0008, beta=0.0018\n",
      "Batch 40, loss=0.0200, recon=0.0200, kl=0.0002, beta=0.0018\n",
      "Batch 60, loss=0.0194, recon=0.0194, kl=0.0004, beta=0.0018\n",
      "Batch 80, loss=0.0176, recon=0.0176, kl=0.0002, beta=0.0018\n",
      "Batch 100, loss=0.0238, recon=0.0238, kl=0.0002, beta=0.0018\n",
      "Batch 120, loss=0.0648, recon=0.0648, kl=0.0003, beta=0.0018\n",
      "Batch 140, loss=0.0561, recon=0.0561, kl=0.0002, beta=0.0018\n",
      "Batch 160, loss=0.0454, recon=0.0454, kl=0.0002, beta=0.0018\n",
      "Batch 180, loss=0.0197, recon=0.0197, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0344 (Recon: 0.0344, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0300 | Avg Valid recon Loss: 0.0300\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0385, recon=0.0385, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0228, recon=0.0228, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=0.0000, beta=0.0038\n",
      "Batch 80, loss=0.0255, recon=0.0255, kl=0.0004, beta=0.0038\n",
      "Batch 100, loss=0.0320, recon=0.0320, kl=0.0001, beta=0.0038\n",
      "Batch 120, loss=0.0335, recon=0.0335, kl=0.0000, beta=0.0038\n",
      "Batch 140, loss=0.0199, recon=0.0199, kl=0.0000, beta=0.0038\n",
      "Batch 160, loss=0.0304, recon=0.0304, kl=0.0000, beta=0.0038\n",
      "Batch 180, loss=0.0335, recon=0.0335, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0335 (Recon: 0.0335, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0290 | Avg Valid recon Loss: 0.0290\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0414, recon=0.0414, kl=0.0000, beta=0.0062\n",
      "Batch 40, loss=0.0199, recon=0.0199, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0160, recon=0.0160, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=0.0007, beta=0.0062\n",
      "Batch 100, loss=0.0229, recon=0.0229, kl=0.0001, beta=0.0062\n",
      "Batch 120, loss=0.0360, recon=0.0360, kl=0.0000, beta=0.0062\n",
      "Batch 140, loss=0.0317, recon=0.0317, kl=0.0000, beta=0.0062\n",
      "Batch 160, loss=0.0252, recon=0.0252, kl=0.0000, beta=0.0062\n",
      "Batch 180, loss=0.0308, recon=0.0308, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0326 (Recon: 0.0326, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0281 | Avg Valid recon Loss: 0.0281\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0259, recon=0.0259, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0380, recon=0.0380, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0716, recon=0.0716, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0231, recon=0.0231, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0235, recon=0.0235, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0219, recon=0.0219, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0568, recon=0.0568, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0219, recon=0.0219, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0205, recon=0.0205, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0319 (Recon: 0.0319, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0280 | Avg Valid recon Loss: 0.0280\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0216, recon=0.0216, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0455, recon=0.0455, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0178, recon=0.0178, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0284, recon=0.0284, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0295, recon=0.0295, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0232, recon=0.0232, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0159, recon=0.0159, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.1253, recon=0.1253, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0190, recon=0.0190, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0313 (Recon: 0.0313, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0276 | Avg Valid recon Loss: 0.0276\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0272, recon=0.0272, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0239, recon=0.0239, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.1036, recon=0.1036, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0204, recon=0.0204, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0485, recon=0.0485, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0220, recon=0.0220, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0204, recon=0.0204, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0316, recon=0.0316, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0221, recon=0.0221, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0312 (Recon: 0.0312, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0280 | Avg Valid recon Loss: 0.0280\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0260, recon=0.0260, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0216, recon=0.0216, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0231, recon=0.0231, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0186, recon=0.0186, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0376, recon=0.0376, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0293, recon=0.0293, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0270, recon=0.0270, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0207, recon=0.0207, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0257, recon=0.0257, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0305 (Recon: 0.0305, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0266 | Avg Valid recon Loss: 0.0266\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0289, recon=0.0289, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0218, recon=0.0218, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0349, recon=0.0349, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0238, recon=0.0238, kl=0.0000, beta=0.0100\n",
      "Batch 100, loss=0.0187, recon=0.0187, kl=0.0000, beta=0.0100\n",
      "Batch 120, loss=0.0168, recon=0.0168, kl=0.0000, beta=0.0100\n",
      "Batch 140, loss=0.0270, recon=0.0270, kl=0.0000, beta=0.0100\n",
      "Batch 160, loss=0.0324, recon=0.0324, kl=0.0000, beta=0.0100\n",
      "Batch 180, loss=0.0271, recon=0.0271, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0303 (Recon: 0.0303, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0268 | Avg Valid recon Loss: 0.0268\n",
      "\n",
      "[VRAE Run 108/324] Training with params: {'batch_size': 32, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1291, recon=0.1291, kl=82.3225, beta=0.0000\n",
      "Batch 40, loss=0.0748, recon=0.0748, kl=78.3278, beta=0.0000\n",
      "Batch 60, loss=0.1117, recon=0.1117, kl=87.5936, beta=0.0000\n",
      "Batch 80, loss=0.0624, recon=0.0624, kl=111.4294, beta=0.0000\n",
      "Batch 100, loss=0.0688, recon=0.0688, kl=120.2547, beta=0.0000\n",
      "Batch 120, loss=0.1063, recon=0.1063, kl=111.0076, beta=0.0000\n",
      "Batch 140, loss=0.0717, recon=0.0717, kl=132.2832, beta=0.0000\n",
      "Batch 160, loss=0.0407, recon=0.0407, kl=126.9233, beta=0.0000\n",
      "Batch 180, loss=0.1560, recon=0.1560, kl=133.6459, beta=0.0000\n",
      "  â†’ Avg Train Loss: 67.2482 (Recon: 67.2482, KL: 2580.1660, Current Beta: 0.0000) | Avg Valid Loss: 0.0527 | Avg Valid recon Loss: 0.0527\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0350, recon=0.0350, kl=145.3998, beta=0.0000\n",
      "Batch 40, loss=0.0256, recon=0.0256, kl=138.3775, beta=0.0000\n",
      "Batch 60, loss=0.0361, recon=0.0361, kl=120.5768, beta=0.0000\n",
      "Batch 80, loss=0.0362, recon=0.0362, kl=120.2608, beta=0.0000\n",
      "Batch 100, loss=0.0491, recon=0.0491, kl=126.7487, beta=0.0000\n",
      "Batch 120, loss=0.0277, recon=0.0277, kl=129.1094, beta=0.0000\n",
      "Batch 140, loss=0.0269, recon=0.0269, kl=135.6511, beta=0.0000\n",
      "Batch 160, loss=0.0463, recon=0.0463, kl=139.4441, beta=0.0000\n",
      "Batch 180, loss=0.0621, recon=0.0621, kl=144.8127, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0603 (Recon: 0.0603, KL: 134.1342, Current Beta: 0.0000) | Avg Valid Loss: 0.0582 | Avg Valid recon Loss: 0.0582\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0351, recon=0.0351, kl=144.1679, beta=0.0000\n",
      "Batch 40, loss=0.0548, recon=0.0548, kl=144.0715, beta=0.0000\n",
      "Batch 60, loss=0.0579, recon=0.0579, kl=146.8957, beta=0.0000\n",
      "Batch 80, loss=0.0616, recon=0.0616, kl=148.3042, beta=0.0000\n",
      "Batch 100, loss=0.0512, recon=0.0511, kl=149.2753, beta=0.0000\n",
      "Batch 120, loss=0.0714, recon=0.0714, kl=151.7354, beta=0.0000\n",
      "Batch 140, loss=0.0397, recon=0.0397, kl=151.4548, beta=0.0000\n",
      "Batch 160, loss=0.0542, recon=0.0542, kl=153.2811, beta=0.0000\n",
      "Batch 180, loss=0.0328, recon=0.0327, kl=155.6057, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0554, KL: 148.6956, Current Beta: 0.0000) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0203, recon=0.0203, kl=157.9195, beta=0.0000\n",
      "Batch 40, loss=0.0439, recon=0.0438, kl=159.0192, beta=0.0000\n",
      "Batch 60, loss=0.0398, recon=0.0397, kl=161.3107, beta=0.0000\n",
      "Batch 80, loss=0.0296, recon=0.0295, kl=161.6893, beta=0.0000\n",
      "Batch 100, loss=0.0513, recon=0.0513, kl=162.8082, beta=0.0000\n",
      "Batch 120, loss=0.0219, recon=0.0219, kl=164.6175, beta=0.0000\n",
      "Batch 140, loss=0.0370, recon=0.0369, kl=162.7562, beta=0.0000\n",
      "Batch 160, loss=0.0320, recon=0.0320, kl=162.9720, beta=0.0000\n",
      "Batch 180, loss=0.0460, recon=0.0459, kl=163.4256, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0484, KL: 161.6218, Current Beta: 0.0000) | Avg Valid Loss: 0.0404 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0255, recon=0.0254, kl=161.8526, beta=0.0000\n",
      "Batch 40, loss=0.0488, recon=0.0486, kl=160.3982, beta=0.0000\n",
      "Batch 60, loss=0.0429, recon=0.0427, kl=160.4779, beta=0.0000\n",
      "Batch 80, loss=0.0743, recon=0.0742, kl=156.9369, beta=0.0000\n",
      "Batch 100, loss=0.0416, recon=0.0415, kl=153.5844, beta=0.0000\n",
      "Batch 120, loss=0.0342, recon=0.0341, kl=152.3676, beta=0.0000\n",
      "Batch 140, loss=0.0265, recon=0.0263, kl=153.2247, beta=0.0000\n",
      "Batch 160, loss=0.0272, recon=0.0271, kl=151.3098, beta=0.0000\n",
      "Batch 180, loss=0.0308, recon=0.0306, kl=150.7226, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0481, KL: 156.3019, Current Beta: 0.0000) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0795, recon=0.0792, kl=146.3231, beta=0.0000\n",
      "Batch 40, loss=0.0280, recon=0.0277, kl=138.3015, beta=0.0000\n",
      "Batch 60, loss=0.0621, recon=0.0618, kl=132.6092, beta=0.0000\n",
      "Batch 80, loss=0.0414, recon=0.0412, kl=132.6770, beta=0.0000\n",
      "Batch 100, loss=0.0548, recon=0.0546, kl=134.7980, beta=0.0000\n",
      "Batch 120, loss=0.0620, recon=0.0617, kl=133.9730, beta=0.0000\n",
      "Batch 140, loss=0.0300, recon=0.0297, kl=132.4878, beta=0.0000\n",
      "Batch 160, loss=0.0370, recon=0.0367, kl=134.5159, beta=0.0000\n",
      "Batch 180, loss=0.0571, recon=0.0568, kl=132.0271, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0444 (Recon: 0.0442, KL: 136.3713, Current Beta: 0.0000) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0245, recon=0.0238, kl=117.3672, beta=0.0000\n",
      "Batch 40, loss=0.0232, recon=0.0227, kl=103.5836, beta=0.0000\n",
      "Batch 60, loss=0.0177, recon=0.0172, kl=98.0124, beta=0.0000\n",
      "Batch 80, loss=0.1122, recon=0.1116, kl=107.9932, beta=0.0000\n",
      "Batch 100, loss=2.9811, recon=2.9803, kl=144.9477, beta=0.0000\n",
      "Batch 120, loss=29.7215, recon=29.7205, kl=193.1540, beta=0.0000\n",
      "Batch 140, loss=2.4480, recon=2.4472, kl=139.4135, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 8/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 9/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 10/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 11/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0003\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0003) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 12/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0008\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0008) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 13/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0018\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0018) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 14/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0038\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0038) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0062\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0062) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 120, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 140, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 160, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 180, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 109/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7563, recon=0.7563, kl=0.2584, beta=0.0000\n",
      "Batch 40, loss=0.5009, recon=0.5009, kl=0.6754, beta=0.0000\n",
      "Batch 60, loss=0.3863, recon=0.3863, kl=3.4419, beta=0.0000\n",
      "Batch 80, loss=0.3324, recon=0.3324, kl=11.1002, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6293 (Recon: 0.6293, KL: 3.6162, Current Beta: 0.0000) | Avg Valid Loss: 0.3941 | Avg Valid recon Loss: 0.3941\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.4897, recon=0.4897, kl=17.6788, beta=0.0000\n",
      "Batch 40, loss=0.2422, recon=0.2422, kl=21.1449, beta=0.0000\n",
      "Batch 60, loss=0.2352, recon=0.2352, kl=23.8161, beta=0.0000\n",
      "Batch 80, loss=0.2678, recon=0.2678, kl=25.1923, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3215 (Recon: 0.3215, KL: 21.2206, Current Beta: 0.0000) | Avg Valid Loss: 0.2473 | Avg Valid recon Loss: 0.2473\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1703, recon=0.1703, kl=27.2217, beta=0.0000\n",
      "Batch 40, loss=0.2326, recon=0.2326, kl=28.6557, beta=0.0000\n",
      "Batch 60, loss=0.2169, recon=0.2169, kl=29.1077, beta=0.0000\n",
      "Batch 80, loss=0.2869, recon=0.2869, kl=30.2644, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2391 (Recon: 0.2391, KL: 28.6513, Current Beta: 0.0000) | Avg Valid Loss: 0.1877 | Avg Valid recon Loss: 0.1877\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1536, recon=0.1536, kl=31.7130, beta=0.0000\n",
      "Batch 40, loss=0.1536, recon=0.1536, kl=32.7823, beta=0.0000\n",
      "Batch 60, loss=0.1533, recon=0.1533, kl=33.8041, beta=0.0000\n",
      "Batch 80, loss=0.1502, recon=0.1502, kl=34.2729, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1959 (Recon: 0.1959, KL: 32.8713, Current Beta: 0.0000) | Avg Valid Loss: 0.1560 | Avg Valid recon Loss: 0.1560\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1610, recon=0.1610, kl=35.2020, beta=0.0000\n",
      "Batch 40, loss=0.1578, recon=0.1578, kl=35.8655, beta=0.0000\n",
      "Batch 60, loss=0.1487, recon=0.1487, kl=36.7227, beta=0.0000\n",
      "Batch 80, loss=0.1131, recon=0.1131, kl=37.3456, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1691 (Recon: 0.1691, KL: 36.0339, Current Beta: 0.0000) | Avg Valid Loss: 0.1351 | Avg Valid recon Loss: 0.1351\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0997, recon=0.0997, kl=37.8636, beta=0.0000\n",
      "Batch 40, loss=0.1100, recon=0.1100, kl=38.0410, beta=0.0000\n",
      "Batch 60, loss=0.2050, recon=0.2050, kl=38.3411, beta=0.0000\n",
      "Batch 80, loss=0.1464, recon=0.1464, kl=38.5952, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1496 (Recon: 0.1496, KL: 38.1060, Current Beta: 0.0000) | Avg Valid Loss: 0.1206 | Avg Valid recon Loss: 0.1206\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0948, recon=0.0948, kl=38.4153, beta=0.0000\n",
      "Batch 40, loss=0.1102, recon=0.1102, kl=38.0985, beta=0.0000\n",
      "Batch 60, loss=0.0903, recon=0.0903, kl=38.1314, beta=0.0000\n",
      "Batch 80, loss=0.1201, recon=0.1201, kl=38.4385, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1346 (Recon: 0.1346, KL: 38.2269, Current Beta: 0.0000) | Avg Valid Loss: 0.1095 | Avg Valid recon Loss: 0.1095\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1056, recon=0.1056, kl=37.8672, beta=0.0000\n",
      "Batch 40, loss=0.0892, recon=0.0892, kl=37.2227, beta=0.0000\n",
      "Batch 60, loss=0.0986, recon=0.0986, kl=36.7696, beta=0.0000\n",
      "Batch 80, loss=0.1000, recon=0.1000, kl=35.7269, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1223 (Recon: 0.1223, KL: 37.0299, Current Beta: 0.0000) | Avg Valid Loss: 0.1010 | Avg Valid recon Loss: 0.1010\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0958, recon=0.0958, kl=34.0968, beta=0.0000\n",
      "Batch 40, loss=0.0810, recon=0.0810, kl=32.2715, beta=0.0000\n",
      "Batch 60, loss=0.0897, recon=0.0897, kl=30.5944, beta=0.0000\n",
      "Batch 80, loss=0.3375, recon=0.3375, kl=29.4919, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1131 (Recon: 0.1131, KL: 31.9494, Current Beta: 0.0000) | Avg Valid Loss: 0.0938 | Avg Valid recon Loss: 0.0937\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1156, recon=0.1156, kl=25.6484, beta=0.0000\n",
      "Batch 40, loss=0.1160, recon=0.1160, kl=20.7683, beta=0.0000\n",
      "Batch 60, loss=0.0910, recon=0.0910, kl=19.0613, beta=0.0000\n",
      "Batch 80, loss=0.1006, recon=0.1006, kl=18.1035, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1051 (Recon: 0.1051, KL: 21.7282, Current Beta: 0.0000) | Avg Valid Loss: 0.0881 | Avg Valid recon Loss: 0.0881\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0633, recon=0.0632, kl=14.0310, beta=0.0000\n",
      "Batch 40, loss=0.0694, recon=0.0694, kl=10.0491, beta=0.0000\n",
      "Batch 60, loss=0.0843, recon=0.0842, kl=10.2267, beta=0.0000\n",
      "Batch 80, loss=0.0826, recon=0.0826, kl=9.6937, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0986 (Recon: 0.0985, KL: 11.7951, Current Beta: 0.0000) | Avg Valid Loss: 0.0840 | Avg Valid recon Loss: 0.0839\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0705, recon=0.0705, kl=5.0732, beta=0.0000\n",
      "Batch 40, loss=0.0689, recon=0.0689, kl=5.0002, beta=0.0000\n",
      "Batch 60, loss=0.1419, recon=0.1419, kl=4.0501, beta=0.0000\n",
      "Batch 80, loss=0.0638, recon=0.0638, kl=3.8839, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0931 (Recon: 0.0930, KL: 4.9549, Current Beta: 0.0000) | Avg Valid Loss: 0.0799 | Avg Valid recon Loss: 0.0798\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0767, recon=0.0767, kl=1.5723, beta=0.0000\n",
      "Batch 40, loss=0.0917, recon=0.0917, kl=1.2951, beta=0.0000\n",
      "Batch 60, loss=0.1107, recon=0.1107, kl=1.2237, beta=0.0000\n",
      "Batch 80, loss=0.0534, recon=0.0534, kl=0.9059, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0877 (Recon: 0.0877, KL: 1.4959, Current Beta: 0.0000) | Avg Valid Loss: 0.0768 | Avg Valid recon Loss: 0.0768\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0680, recon=0.0680, kl=0.2861, beta=0.0000\n",
      "Batch 40, loss=0.0637, recon=0.0637, kl=0.2637, beta=0.0000\n",
      "Batch 60, loss=0.0748, recon=0.0748, kl=0.2387, beta=0.0000\n",
      "Batch 80, loss=0.1995, recon=0.1995, kl=0.1506, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0846 (Recon: 0.0846, KL: 0.2871, Current Beta: 0.0000) | Avg Valid Loss: 0.0738 | Avg Valid recon Loss: 0.0738\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0450, recon=0.0450, kl=0.0756, beta=0.0001\n",
      "Batch 40, loss=0.0740, recon=0.0740, kl=0.0759, beta=0.0001\n",
      "Batch 60, loss=0.2483, recon=0.2483, kl=0.0652, beta=0.0001\n",
      "Batch 80, loss=0.1162, recon=0.1162, kl=0.0592, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0814 (Recon: 0.0814, KL: 0.0733, Current Beta: 0.0001) | Avg Valid Loss: 0.0711 | Avg Valid recon Loss: 0.0711\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0623, recon=0.0623, kl=0.0170, beta=0.0001\n",
      "Batch 40, loss=0.0608, recon=0.0608, kl=0.0184, beta=0.0001\n",
      "Batch 60, loss=0.0470, recon=0.0470, kl=0.0119, beta=0.0001\n",
      "Batch 80, loss=0.0607, recon=0.0607, kl=0.0135, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0761 (Recon: 0.0761, KL: 0.0203, Current Beta: 0.0001) | Avg Valid Loss: 0.0690 | Avg Valid recon Loss: 0.0690\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0682, recon=0.0682, kl=0.0129, beta=0.0001\n",
      "Batch 40, loss=0.0636, recon=0.0636, kl=0.0091, beta=0.0001\n",
      "Batch 60, loss=0.0590, recon=0.0590, kl=0.0086, beta=0.0001\n",
      "Batch 80, loss=0.0382, recon=0.0382, kl=0.0073, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0757 (Recon: 0.0757, KL: 0.0110, Current Beta: 0.0001) | Avg Valid Loss: 0.0673 | Avg Valid recon Loss: 0.0673\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0461, recon=0.0461, kl=0.0079, beta=0.0001\n",
      "Batch 40, loss=0.0431, recon=0.0431, kl=0.0087, beta=0.0001\n",
      "Batch 60, loss=0.6633, recon=0.6633, kl=0.0090, beta=0.0001\n",
      "Batch 80, loss=0.0486, recon=0.0486, kl=0.0065, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0732 (Recon: 0.0732, KL: 0.0076, Current Beta: 0.0001) | Avg Valid Loss: 0.0655 | Avg Valid recon Loss: 0.0655\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1101, recon=0.1101, kl=0.0114, beta=0.0001\n",
      "Batch 40, loss=0.0524, recon=0.0524, kl=0.0050, beta=0.0001\n",
      "Batch 60, loss=0.0442, recon=0.0442, kl=0.0065, beta=0.0001\n",
      "Batch 80, loss=0.0580, recon=0.0580, kl=0.0066, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0709 (Recon: 0.0709, KL: 0.0068, Current Beta: 0.0001) | Avg Valid Loss: 0.0633 | Avg Valid recon Loss: 0.0633\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0570, recon=0.0570, kl=0.0037, beta=0.0001\n",
      "Batch 40, loss=0.0818, recon=0.0818, kl=0.0044, beta=0.0001\n",
      "Batch 60, loss=0.0513, recon=0.0513, kl=0.0146, beta=0.0001\n",
      "Batch 80, loss=0.0864, recon=0.0864, kl=0.0057, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0688 (Recon: 0.0688, KL: 0.0064, Current Beta: 0.0001) | Avg Valid Loss: 0.0623 | Avg Valid recon Loss: 0.0623\n",
      "\n",
      "[VRAE Run 110/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2495, recon=0.2495, kl=17.3331, beta=0.0000\n",
      "Batch 40, loss=0.2238, recon=0.2238, kl=22.9412, beta=0.0000\n",
      "Batch 60, loss=0.1830, recon=0.1830, kl=32.0890, beta=0.0000\n",
      "Batch 80, loss=0.0884, recon=0.0884, kl=36.2361, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2281 (Recon: 0.2281, KL: 23.3694, Current Beta: 0.0000) | Avg Valid Loss: 0.0946 | Avg Valid recon Loss: 0.0946\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0803, recon=0.0803, kl=34.7227, beta=0.0000\n",
      "Batch 40, loss=0.0634, recon=0.0634, kl=36.1609, beta=0.0000\n",
      "Batch 60, loss=0.0791, recon=0.0791, kl=37.0349, beta=0.0000\n",
      "Batch 80, loss=0.0585, recon=0.0585, kl=33.9527, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0938 (Recon: 0.0938, KL: 35.3863, Current Beta: 0.0000) | Avg Valid Loss: 0.0699 | Avg Valid recon Loss: 0.0699\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2403, recon=0.2403, kl=34.2706, beta=0.0000\n",
      "Batch 40, loss=0.0510, recon=0.0510, kl=36.1455, beta=0.0000\n",
      "Batch 60, loss=0.0453, recon=0.0453, kl=35.6597, beta=0.0000\n",
      "Batch 80, loss=0.0613, recon=0.0613, kl=35.9476, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0740 (Recon: 0.0740, KL: 35.2939, Current Beta: 0.0000) | Avg Valid Loss: 0.0621 | Avg Valid recon Loss: 0.0621\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0552, recon=0.0552, kl=36.4697, beta=0.0000\n",
      "Batch 40, loss=0.0431, recon=0.0431, kl=36.0593, beta=0.0000\n",
      "Batch 60, loss=0.0411, recon=0.0411, kl=35.5595, beta=0.0000\n",
      "Batch 80, loss=0.0320, recon=0.0320, kl=37.3678, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0666 (Recon: 0.0666, KL: 36.4683, Current Beta: 0.0000) | Avg Valid Loss: 0.0556 | Avg Valid recon Loss: 0.0556\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0961, recon=0.0961, kl=38.5597, beta=0.0000\n",
      "Batch 40, loss=0.0471, recon=0.0471, kl=40.6453, beta=0.0000\n",
      "Batch 60, loss=0.0463, recon=0.0463, kl=37.5628, beta=0.0000\n",
      "Batch 80, loss=0.0508, recon=0.0508, kl=37.4262, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0627 (Recon: 0.0627, KL: 38.2959, Current Beta: 0.0000) | Avg Valid Loss: 0.0534 | Avg Valid recon Loss: 0.0534\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0470, recon=0.0470, kl=36.3282, beta=0.0000\n",
      "Batch 40, loss=0.0763, recon=0.0763, kl=39.8569, beta=0.0000\n",
      "Batch 60, loss=0.0410, recon=0.0410, kl=39.5358, beta=0.0000\n",
      "Batch 80, loss=0.1042, recon=0.1042, kl=37.5314, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0597 (Recon: 0.0597, KL: 38.3005, Current Beta: 0.0000) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0496\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0357, recon=0.0357, kl=37.6260, beta=0.0000\n",
      "Batch 40, loss=0.0343, recon=0.0343, kl=36.0307, beta=0.0000\n",
      "Batch 60, loss=0.0498, recon=0.0498, kl=35.7208, beta=0.0000\n",
      "Batch 80, loss=0.0528, recon=0.0528, kl=33.9447, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0571 (Recon: 0.0571, KL: 35.9719, Current Beta: 0.0000) | Avg Valid Loss: 0.0483 | Avg Valid recon Loss: 0.0483\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0485, recon=0.0485, kl=32.1659, beta=0.0000\n",
      "Batch 40, loss=0.1227, recon=0.1227, kl=28.4476, beta=0.0000\n",
      "Batch 60, loss=0.1287, recon=0.1286, kl=26.7871, beta=0.0000\n",
      "Batch 80, loss=0.0516, recon=0.0516, kl=25.9033, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0544 (Recon: 0.0544, KL: 29.0279, Current Beta: 0.0000) | Avg Valid Loss: 0.0487 | Avg Valid recon Loss: 0.0487\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0560, recon=0.0560, kl=25.6042, beta=0.0000\n",
      "Batch 40, loss=0.0290, recon=0.0290, kl=23.3513, beta=0.0000\n",
      "Batch 60, loss=0.0393, recon=0.0393, kl=23.3877, beta=0.0000\n",
      "Batch 80, loss=0.0323, recon=0.0323, kl=21.3454, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0531 (Recon: 0.0531, KL: 23.8653, Current Beta: 0.0000) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0471, recon=0.0471, kl=18.2996, beta=0.0000\n",
      "Batch 40, loss=0.0598, recon=0.0598, kl=16.2676, beta=0.0000\n",
      "Batch 60, loss=0.0307, recon=0.0307, kl=17.4949, beta=0.0000\n",
      "Batch 80, loss=0.0357, recon=0.0357, kl=17.8366, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0516, KL: 17.9124, Current Beta: 0.0000) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0355, recon=0.0355, kl=10.0129, beta=0.0000\n",
      "Batch 40, loss=0.0302, recon=0.0302, kl=11.4970, beta=0.0000\n",
      "Batch 60, loss=0.1012, recon=0.1012, kl=10.6990, beta=0.0000\n",
      "Batch 80, loss=0.0391, recon=0.0390, kl=8.3911, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0490 (Recon: 0.0490, KL: 10.6803, Current Beta: 0.0000) | Avg Valid Loss: 0.0418 | Avg Valid recon Loss: 0.0418\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0671, recon=0.0670, kl=3.8773, beta=0.0000\n",
      "Batch 40, loss=0.0369, recon=0.0368, kl=5.0613, beta=0.0000\n",
      "Batch 60, loss=0.0437, recon=0.0436, kl=3.6922, beta=0.0000\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=3.6497, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0487 (Recon: 0.0486, KL: 4.4674, Current Beta: 0.0000) | Avg Valid Loss: 0.0409 | Avg Valid recon Loss: 0.0409\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0520, recon=0.0520, kl=1.1487, beta=0.0000\n",
      "Batch 40, loss=0.0328, recon=0.0328, kl=0.4472, beta=0.0000\n",
      "Batch 60, loss=0.0347, recon=0.0347, kl=0.9181, beta=0.0000\n",
      "Batch 80, loss=0.0398, recon=0.0398, kl=0.7590, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 1.1640, Current Beta: 0.0000) | Avg Valid Loss: 0.0453 | Avg Valid recon Loss: 0.0453\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=0.2170, beta=0.0000\n",
      "Batch 40, loss=0.0401, recon=0.0401, kl=0.5596, beta=0.0000\n",
      "Batch 60, loss=0.0977, recon=0.0977, kl=0.2055, beta=0.0000\n",
      "Batch 80, loss=0.0551, recon=0.0551, kl=0.2258, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0499 (Recon: 0.0499, KL: 0.3305, Current Beta: 0.0000) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0380, recon=0.0380, kl=0.0619, beta=0.0001\n",
      "Batch 40, loss=0.0731, recon=0.0731, kl=0.0621, beta=0.0001\n",
      "Batch 60, loss=0.0462, recon=0.0462, kl=0.0329, beta=0.0001\n",
      "Batch 80, loss=0.0401, recon=0.0401, kl=0.2168, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0466, KL: 0.1039, Current Beta: 0.0001) | Avg Valid Loss: 0.0385 | Avg Valid recon Loss: 0.0385\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0367, recon=0.0366, kl=0.2531, beta=0.0001\n",
      "Batch 40, loss=0.0537, recon=0.0537, kl=0.0297, beta=0.0001\n",
      "Batch 60, loss=0.0380, recon=0.0380, kl=0.0299, beta=0.0001\n",
      "Batch 80, loss=0.0458, recon=0.0458, kl=0.0591, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0466, KL: 0.1493, Current Beta: 0.0001) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0413, recon=0.0413, kl=0.0185, beta=0.0001\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=0.0176, beta=0.0001\n",
      "Batch 60, loss=0.0393, recon=0.0393, kl=0.0111, beta=0.0001\n",
      "Batch 80, loss=0.0395, recon=0.0395, kl=0.0064, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0451 (Recon: 0.0451, KL: 0.0158, Current Beta: 0.0001) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0277, recon=0.0277, kl=0.0088, beta=0.0001\n",
      "Batch 40, loss=0.0313, recon=0.0313, kl=0.0047, beta=0.0001\n",
      "Batch 60, loss=0.0497, recon=0.0497, kl=0.0392, beta=0.0001\n",
      "Batch 80, loss=0.0781, recon=0.0781, kl=0.0172, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0449, KL: 0.0163, Current Beta: 0.0001) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0386, recon=0.0385, kl=0.0868, beta=0.0001\n",
      "Batch 40, loss=0.0602, recon=0.0602, kl=0.0290, beta=0.0001\n",
      "Batch 60, loss=0.0913, recon=0.0913, kl=0.0253, beta=0.0001\n",
      "Batch 80, loss=0.0595, recon=0.0595, kl=0.0085, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0450, KL: 0.0363, Current Beta: 0.0001) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0444, recon=0.0444, kl=0.0114, beta=0.0001\n",
      "Batch 40, loss=0.0473, recon=0.0473, kl=0.0122, beta=0.0001\n",
      "Batch 60, loss=0.0356, recon=0.0356, kl=0.0148, beta=0.0001\n",
      "Batch 80, loss=0.0413, recon=0.0413, kl=0.0109, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0432, KL: 0.0116, Current Beta: 0.0001) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0361\n",
      "\n",
      "[VRAE Run 111/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7071, recon=0.7071, kl=0.6614, beta=0.0000\n",
      "Batch 40, loss=0.5091, recon=0.5091, kl=2.3754, beta=0.0000\n",
      "Batch 60, loss=0.5151, recon=0.5151, kl=11.0101, beta=0.0000\n",
      "Batch 80, loss=0.3053, recon=0.3053, kl=21.3626, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5973 (Recon: 0.5973, KL: 8.2004, Current Beta: 0.0000) | Avg Valid Loss: 0.3751 | Avg Valid recon Loss: 0.3751\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2770, recon=0.2770, kl=33.2418, beta=0.0000\n",
      "Batch 40, loss=0.2249, recon=0.2249, kl=38.0818, beta=0.0000\n",
      "Batch 60, loss=0.2537, recon=0.2537, kl=42.1080, beta=0.0000\n",
      "Batch 80, loss=0.2308, recon=0.2308, kl=45.5063, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3135 (Recon: 0.3135, KL: 38.4794, Current Beta: 0.0000) | Avg Valid Loss: 0.2445 | Avg Valid recon Loss: 0.2445\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1571, recon=0.1571, kl=48.7609, beta=0.0000\n",
      "Batch 40, loss=0.2381, recon=0.2381, kl=51.2848, beta=0.0000\n",
      "Batch 60, loss=0.1554, recon=0.1554, kl=52.2824, beta=0.0000\n",
      "Batch 80, loss=0.1732, recon=0.1732, kl=54.2579, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2387 (Recon: 0.2387, KL: 51.0735, Current Beta: 0.0000) | Avg Valid Loss: 0.1857 | Avg Valid recon Loss: 0.1857\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1240, recon=0.1240, kl=57.1025, beta=0.0000\n",
      "Batch 40, loss=0.1678, recon=0.1678, kl=58.9103, beta=0.0000\n",
      "Batch 60, loss=0.2057, recon=0.2057, kl=60.8759, beta=0.0000\n",
      "Batch 80, loss=0.1295, recon=0.1295, kl=62.8077, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1972 (Recon: 0.1972, KL: 59.4362, Current Beta: 0.0000) | Avg Valid Loss: 0.1531 | Avg Valid recon Loss: 0.1531\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1739, recon=0.1739, kl=64.8385, beta=0.0000\n",
      "Batch 40, loss=0.1223, recon=0.1223, kl=66.4869, beta=0.0000\n",
      "Batch 60, loss=0.1276, recon=0.1276, kl=67.5074, beta=0.0000\n",
      "Batch 80, loss=0.1179, recon=0.1179, kl=68.8380, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1698 (Recon: 0.1698, KL: 66.6251, Current Beta: 0.0000) | Avg Valid Loss: 0.1325 | Avg Valid recon Loss: 0.1325\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1071, recon=0.1071, kl=70.7321, beta=0.0000\n",
      "Batch 40, loss=0.2459, recon=0.2459, kl=70.9329, beta=0.0000\n",
      "Batch 60, loss=0.0945, recon=0.0945, kl=72.1092, beta=0.0000\n",
      "Batch 80, loss=0.1532, recon=0.1532, kl=73.4281, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1481 (Recon: 0.1481, KL: 71.7069, Current Beta: 0.0000) | Avg Valid Loss: 0.1175 | Avg Valid recon Loss: 0.1175\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.3139, recon=0.3139, kl=73.1138, beta=0.0000\n",
      "Batch 40, loss=0.1061, recon=0.1061, kl=73.8880, beta=0.0000\n",
      "Batch 60, loss=0.1061, recon=0.1061, kl=73.7328, beta=0.0000\n",
      "Batch 80, loss=0.1229, recon=0.1229, kl=74.4962, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1320 (Recon: 0.1320, KL: 73.9575, Current Beta: 0.0000) | Avg Valid Loss: 0.1071 | Avg Valid recon Loss: 0.1071\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1015, recon=0.1015, kl=73.9818, beta=0.0000\n",
      "Batch 40, loss=0.1172, recon=0.1172, kl=73.3792, beta=0.0000\n",
      "Batch 60, loss=0.1101, recon=0.1101, kl=72.2241, beta=0.0000\n",
      "Batch 80, loss=0.1159, recon=0.1159, kl=71.5233, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1210 (Recon: 0.1210, KL: 72.9038, Current Beta: 0.0000) | Avg Valid Loss: 0.0991 | Avg Valid recon Loss: 0.0991\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0872, recon=0.0871, kl=68.3510, beta=0.0000\n",
      "Batch 40, loss=0.0863, recon=0.0863, kl=63.7402, beta=0.0000\n",
      "Batch 60, loss=0.0804, recon=0.0803, kl=60.1157, beta=0.0000\n",
      "Batch 80, loss=0.0787, recon=0.0786, kl=56.5119, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1116 (Recon: 0.1116, KL: 63.2014, Current Beta: 0.0000) | Avg Valid Loss: 0.0925 | Avg Valid recon Loss: 0.0925\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0831, recon=0.0831, kl=48.3743, beta=0.0000\n",
      "Batch 40, loss=0.1228, recon=0.1228, kl=39.1793, beta=0.0000\n",
      "Batch 60, loss=0.8812, recon=0.8811, kl=36.3693, beta=0.0000\n",
      "Batch 80, loss=0.0842, recon=0.0842, kl=33.9538, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1042 (Recon: 0.1041, KL: 41.1276, Current Beta: 0.0000) | Avg Valid Loss: 0.0878 | Avg Valid recon Loss: 0.0878\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0563, recon=0.0562, kl=23.0511, beta=0.0000\n",
      "Batch 40, loss=0.0997, recon=0.0996, kl=19.2639, beta=0.0000\n",
      "Batch 60, loss=0.0876, recon=0.0875, kl=18.4635, beta=0.0000\n",
      "Batch 80, loss=0.0695, recon=0.0695, kl=16.1157, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0973 (Recon: 0.0972, KL: 20.4895, Current Beta: 0.0000) | Avg Valid Loss: 0.0826 | Avg Valid recon Loss: 0.0826\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0582, recon=0.0582, kl=7.8829, beta=0.0000\n",
      "Batch 40, loss=0.1070, recon=0.1070, kl=7.7066, beta=0.0000\n",
      "Batch 60, loss=0.0514, recon=0.0514, kl=6.5873, beta=0.0000\n",
      "Batch 80, loss=0.0779, recon=0.0778, kl=6.0101, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0924 (Recon: 0.0923, KL: 7.8564, Current Beta: 0.0000) | Avg Valid Loss: 0.0796 | Avg Valid recon Loss: 0.0796\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0677, recon=0.0677, kl=2.1321, beta=0.0000\n",
      "Batch 40, loss=0.0581, recon=0.0580, kl=2.1397, beta=0.0000\n",
      "Batch 60, loss=0.0606, recon=0.0606, kl=2.4835, beta=0.0000\n",
      "Batch 80, loss=0.0717, recon=0.0717, kl=1.8978, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0879 (Recon: 0.0879, KL: 2.4811, Current Beta: 0.0000) | Avg Valid Loss: 0.0763 | Avg Valid recon Loss: 0.0763\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0617, recon=0.0617, kl=0.9061, beta=0.0000\n",
      "Batch 40, loss=0.0407, recon=0.0407, kl=0.9702, beta=0.0000\n",
      "Batch 60, loss=0.0651, recon=0.0651, kl=0.6824, beta=0.0000\n",
      "Batch 80, loss=0.0686, recon=0.0686, kl=0.6350, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0837 (Recon: 0.0837, KL: 0.8950, Current Beta: 0.0000) | Avg Valid Loss: 0.0734 | Avg Valid recon Loss: 0.0733\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0502, recon=0.0501, kl=0.3613, beta=0.0001\n",
      "Batch 40, loss=0.0817, recon=0.0817, kl=0.3310, beta=0.0001\n",
      "Batch 60, loss=0.0526, recon=0.0526, kl=0.1893, beta=0.0001\n",
      "Batch 80, loss=0.2540, recon=0.2540, kl=0.1934, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0808 (Recon: 0.0807, KL: 0.2986, Current Beta: 0.0001) | Avg Valid Loss: 0.0714 | Avg Valid recon Loss: 0.0713\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0452, recon=0.0452, kl=0.0699, beta=0.0001\n",
      "Batch 40, loss=0.0812, recon=0.0812, kl=0.0635, beta=0.0001\n",
      "Batch 60, loss=0.0733, recon=0.0732, kl=0.0496, beta=0.0001\n",
      "Batch 80, loss=0.0565, recon=0.0565, kl=0.0439, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0780 (Recon: 0.0780, KL: 0.0730, Current Beta: 0.0001) | Avg Valid Loss: 0.0695 | Avg Valid recon Loss: 0.0695\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0568, recon=0.0568, kl=0.0296, beta=0.0001\n",
      "Batch 40, loss=0.0587, recon=0.0587, kl=0.0296, beta=0.0001\n",
      "Batch 60, loss=0.0616, recon=0.0616, kl=0.0259, beta=0.0001\n",
      "Batch 80, loss=0.0536, recon=0.0536, kl=0.0170, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0753 (Recon: 0.0753, KL: 0.0273, Current Beta: 0.0001) | Avg Valid Loss: 0.0672 | Avg Valid recon Loss: 0.0672\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0461, recon=0.0461, kl=0.0167, beta=0.0001\n",
      "Batch 40, loss=0.0359, recon=0.0359, kl=0.0157, beta=0.0001\n",
      "Batch 60, loss=0.0696, recon=0.0696, kl=0.0151, beta=0.0001\n",
      "Batch 80, loss=0.0680, recon=0.0680, kl=0.0142, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0734 (Recon: 0.0734, KL: 0.0176, Current Beta: 0.0001) | Avg Valid Loss: 0.0653 | Avg Valid recon Loss: 0.0653\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0771, recon=0.0771, kl=0.0123, beta=0.0001\n",
      "Batch 40, loss=0.0426, recon=0.0426, kl=0.0084, beta=0.0001\n",
      "Batch 60, loss=0.0677, recon=0.0677, kl=0.0069, beta=0.0001\n",
      "Batch 80, loss=0.0897, recon=0.0897, kl=0.0087, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0712 (Recon: 0.0712, KL: 0.0105, Current Beta: 0.0001) | Avg Valid Loss: 0.0636 | Avg Valid recon Loss: 0.0636\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0568, recon=0.0568, kl=0.0058, beta=0.0001\n",
      "Batch 40, loss=0.0522, recon=0.0522, kl=0.0106, beta=0.0001\n",
      "Batch 60, loss=0.0473, recon=0.0473, kl=0.0076, beta=0.0001\n",
      "Batch 80, loss=0.0597, recon=0.0597, kl=0.0061, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0687 (Recon: 0.0687, KL: 0.0082, Current Beta: 0.0001) | Avg Valid Loss: 0.0620 | Avg Valid recon Loss: 0.0620\n",
      "\n",
      "[VRAE Run 112/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2299, recon=0.2299, kl=36.8793, beta=0.0000\n",
      "Batch 40, loss=0.1997, recon=0.1997, kl=54.3449, beta=0.0000\n",
      "Batch 60, loss=0.1064, recon=0.1064, kl=57.0632, beta=0.0000\n",
      "Batch 80, loss=0.0807, recon=0.0807, kl=62.5009, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2465 (Recon: 0.2465, KL: 46.0868, Current Beta: 0.0000) | Avg Valid Loss: 0.0966 | Avg Valid recon Loss: 0.0966\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0847, recon=0.0847, kl=64.3004, beta=0.0000\n",
      "Batch 40, loss=0.0847, recon=0.0847, kl=64.3455, beta=0.0000\n",
      "Batch 60, loss=0.0593, recon=0.0593, kl=67.4234, beta=0.0000\n",
      "Batch 80, loss=0.2958, recon=0.2958, kl=71.2462, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0985 (Recon: 0.0985, KL: 66.9280, Current Beta: 0.0000) | Avg Valid Loss: 0.0757 | Avg Valid recon Loss: 0.0757\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1026, recon=0.1026, kl=73.6744, beta=0.0000\n",
      "Batch 40, loss=0.0437, recon=0.0437, kl=74.8434, beta=0.0000\n",
      "Batch 60, loss=0.0516, recon=0.0516, kl=74.3461, beta=0.0000\n",
      "Batch 80, loss=0.0493, recon=0.0493, kl=74.7812, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0784 (Recon: 0.0784, KL: 74.4702, Current Beta: 0.0000) | Avg Valid Loss: 0.0689 | Avg Valid recon Loss: 0.0689\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0542, recon=0.0542, kl=75.0598, beta=0.0000\n",
      "Batch 40, loss=0.0953, recon=0.0953, kl=68.2307, beta=0.0000\n",
      "Batch 60, loss=0.0376, recon=0.0376, kl=62.4836, beta=0.0000\n",
      "Batch 80, loss=0.0381, recon=0.0381, kl=66.0136, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0690 (Recon: 0.0690, KL: 68.9501, Current Beta: 0.0000) | Avg Valid Loss: 0.0565 | Avg Valid recon Loss: 0.0565\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0375, recon=0.0375, kl=74.8738, beta=0.0000\n",
      "Batch 40, loss=0.0760, recon=0.0760, kl=78.4226, beta=0.0000\n",
      "Batch 60, loss=0.0661, recon=0.0661, kl=73.7694, beta=0.0000\n",
      "Batch 80, loss=0.0391, recon=0.0391, kl=69.3497, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0629 (Recon: 0.0629, KL: 73.8120, Current Beta: 0.0000) | Avg Valid Loss: 0.0529 | Avg Valid recon Loss: 0.0529\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0370, recon=0.0370, kl=70.5463, beta=0.0000\n",
      "Batch 40, loss=0.0335, recon=0.0335, kl=68.3128, beta=0.0000\n",
      "Batch 60, loss=0.0444, recon=0.0444, kl=72.4194, beta=0.0000\n",
      "Batch 80, loss=0.0416, recon=0.0416, kl=72.9846, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0594 (Recon: 0.0594, KL: 70.9658, Current Beta: 0.0000) | Avg Valid Loss: 0.0565 | Avg Valid recon Loss: 0.0565\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0507, recon=0.0507, kl=66.9659, beta=0.0000\n",
      "Batch 40, loss=0.0393, recon=0.0393, kl=67.2086, beta=0.0000\n",
      "Batch 60, loss=0.0891, recon=0.0891, kl=71.3752, beta=0.0000\n",
      "Batch 80, loss=0.0637, recon=0.0637, kl=75.9955, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0582 (Recon: 0.0582, KL: 70.9713, Current Beta: 0.0000) | Avg Valid Loss: 0.0522 | Avg Valid recon Loss: 0.0522\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0963, recon=0.0963, kl=67.5360, beta=0.0000\n",
      "Batch 40, loss=0.0630, recon=0.0629, kl=64.1479, beta=0.0000\n",
      "Batch 60, loss=0.0330, recon=0.0330, kl=60.9968, beta=0.0000\n",
      "Batch 80, loss=0.0488, recon=0.0488, kl=61.6001, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0561 (Recon: 0.0561, KL: 64.2249, Current Beta: 0.0000) | Avg Valid Loss: 0.0476 | Avg Valid recon Loss: 0.0476\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0462, recon=0.0461, kl=54.6276, beta=0.0000\n",
      "Batch 40, loss=0.0541, recon=0.0540, kl=49.5657, beta=0.0000\n",
      "Batch 60, loss=0.0337, recon=0.0337, kl=46.6406, beta=0.0000\n",
      "Batch 80, loss=0.0385, recon=0.0384, kl=46.0996, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0540, KL: 50.5475, Current Beta: 0.0000) | Avg Valid Loss: 0.0473 | Avg Valid recon Loss: 0.0473\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0422, recon=0.0421, kl=38.0041, beta=0.0000\n",
      "Batch 40, loss=0.0314, recon=0.0314, kl=30.8863, beta=0.0000\n",
      "Batch 60, loss=0.0456, recon=0.0455, kl=30.2598, beta=0.0000\n",
      "Batch 80, loss=0.0441, recon=0.0441, kl=31.1397, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0540, KL: 34.3398, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0547, recon=0.0546, kl=22.0461, beta=0.0000\n",
      "Batch 40, loss=0.0355, recon=0.0354, kl=18.0724, beta=0.0000\n",
      "Batch 60, loss=0.0980, recon=0.0980, kl=17.1422, beta=0.0000\n",
      "Batch 80, loss=0.0414, recon=0.0414, kl=17.7124, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0526 (Recon: 0.0526, KL: 19.6859, Current Beta: 0.0000) | Avg Valid Loss: 0.0547 | Avg Valid recon Loss: 0.0546\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0365, recon=0.0364, kl=7.1588, beta=0.0000\n",
      "Batch 40, loss=0.0405, recon=0.0404, kl=6.8501, beta=0.0000\n",
      "Batch 60, loss=0.0365, recon=0.0365, kl=5.0641, beta=0.0000\n",
      "Batch 80, loss=0.0394, recon=0.0393, kl=6.9264, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0523, KL: 7.4525, Current Beta: 0.0000) | Avg Valid Loss: 0.0442 | Avg Valid recon Loss: 0.0442\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0402, recon=0.0402, kl=0.9456, beta=0.0000\n",
      "Batch 40, loss=0.0364, recon=0.0363, kl=3.8819, beta=0.0000\n",
      "Batch 60, loss=0.0492, recon=0.0492, kl=1.7321, beta=0.0000\n",
      "Batch 80, loss=0.0431, recon=0.0431, kl=1.1191, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0489 (Recon: 0.0488, KL: 2.2637, Current Beta: 0.0000) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0428, recon=0.0428, kl=0.5497, beta=0.0000\n",
      "Batch 40, loss=0.0569, recon=0.0569, kl=0.5165, beta=0.0000\n",
      "Batch 60, loss=0.0313, recon=0.0313, kl=0.2131, beta=0.0000\n",
      "Batch 80, loss=0.0313, recon=0.0313, kl=0.1069, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0473, KL: 0.4574, Current Beta: 0.0000) | Avg Valid Loss: 0.0418 | Avg Valid recon Loss: 0.0418\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0434, recon=0.0434, kl=0.0337, beta=0.0001\n",
      "Batch 40, loss=0.0287, recon=0.0287, kl=0.1332, beta=0.0001\n",
      "Batch 60, loss=0.0398, recon=0.0398, kl=0.1016, beta=0.0001\n",
      "Batch 80, loss=0.0457, recon=0.0456, kl=0.1108, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0471, KL: 0.0850, Current Beta: 0.0001) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0893, recon=0.0893, kl=0.1066, beta=0.0001\n",
      "Batch 40, loss=0.0258, recon=0.0258, kl=0.0493, beta=0.0001\n",
      "Batch 60, loss=0.0413, recon=0.0413, kl=0.0372, beta=0.0001\n",
      "Batch 80, loss=0.0317, recon=0.0317, kl=0.0158, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0514 (Recon: 0.0514, KL: 0.0679, Current Beta: 0.0001) | Avg Valid Loss: 0.0414 | Avg Valid recon Loss: 0.0414\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0341, recon=0.0341, kl=0.0386, beta=0.0001\n",
      "Batch 40, loss=0.0443, recon=0.0443, kl=0.0753, beta=0.0001\n",
      "Batch 60, loss=0.0293, recon=0.0293, kl=0.3641, beta=0.0001\n",
      "Batch 80, loss=0.0349, recon=0.0349, kl=0.0780, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0466, KL: 0.1443, Current Beta: 0.0001) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0395, recon=0.0395, kl=0.0274, beta=0.0001\n",
      "Batch 40, loss=0.0511, recon=0.0511, kl=0.0238, beta=0.0001\n",
      "Batch 60, loss=0.0393, recon=0.0393, kl=0.0176, beta=0.0001\n",
      "Batch 80, loss=0.3181, recon=0.3181, kl=0.0165, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 0.0224, Current Beta: 0.0001) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0524, recon=0.0524, kl=0.2535, beta=0.0001\n",
      "Batch 40, loss=0.0601, recon=0.0601, kl=0.0534, beta=0.0001\n",
      "Batch 60, loss=0.0375, recon=0.0375, kl=0.0268, beta=0.0001\n",
      "Batch 80, loss=0.0762, recon=0.0762, kl=0.0582, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0450, KL: 0.0907, Current Beta: 0.0001) | Avg Valid Loss: 0.0397 | Avg Valid recon Loss: 0.0397\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0326, recon=0.0326, kl=0.0209, beta=0.0001\n",
      "Batch 40, loss=0.0388, recon=0.0388, kl=0.1025, beta=0.0001\n",
      "Batch 60, loss=0.0245, recon=0.0245, kl=0.0200, beta=0.0001\n",
      "Batch 80, loss=0.0591, recon=0.0591, kl=0.0333, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0445 (Recon: 0.0445, KL: 0.0355, Current Beta: 0.0001) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "\n",
      "[VRAE Run 113/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7579, recon=0.7579, kl=0.8204, beta=0.0000\n",
      "Batch 40, loss=0.3369, recon=0.3369, kl=2.6138, beta=0.0000\n",
      "Batch 60, loss=0.5133, recon=0.5133, kl=26.0666, beta=0.0000\n",
      "Batch 80, loss=0.3864, recon=0.3864, kl=51.3228, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5941 (Recon: 0.5941, KL: 18.4999, Current Beta: 0.0000) | Avg Valid Loss: 0.3680 | Avg Valid recon Loss: 0.3680\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2602, recon=0.2602, kl=69.0776, beta=0.0000\n",
      "Batch 40, loss=0.3319, recon=0.3319, kl=77.3897, beta=0.0000\n",
      "Batch 60, loss=0.2586, recon=0.2586, kl=85.6637, beta=0.0000\n",
      "Batch 80, loss=0.2790, recon=0.2790, kl=92.6521, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3105 (Recon: 0.3105, KL: 79.0764, Current Beta: 0.0000) | Avg Valid Loss: 0.2429 | Avg Valid recon Loss: 0.2429\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2008, recon=0.2008, kl=103.9253, beta=0.0000\n",
      "Batch 40, loss=0.2522, recon=0.2522, kl=111.2416, beta=0.0000\n",
      "Batch 60, loss=0.2544, recon=0.2544, kl=116.3771, beta=0.0000\n",
      "Batch 80, loss=0.1499, recon=0.1499, kl=120.5683, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2381 (Recon: 0.2381, KL: 111.4925, Current Beta: 0.0000) | Avg Valid Loss: 0.1872 | Avg Valid recon Loss: 0.1872\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1539, recon=0.1539, kl=125.6927, beta=0.0000\n",
      "Batch 40, loss=0.1893, recon=0.1893, kl=129.8782, beta=0.0000\n",
      "Batch 60, loss=0.1926, recon=0.1926, kl=133.8560, beta=0.0000\n",
      "Batch 80, loss=0.1335, recon=0.1335, kl=136.5642, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1973 (Recon: 0.1973, KL: 130.6818, Current Beta: 0.0000) | Avg Valid Loss: 0.1568 | Avg Valid recon Loss: 0.1568\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1840, recon=0.1840, kl=141.1778, beta=0.0000\n",
      "Batch 40, loss=0.1513, recon=0.1513, kl=143.1632, beta=0.0000\n",
      "Batch 60, loss=0.1209, recon=0.1209, kl=144.5464, beta=0.0000\n",
      "Batch 80, loss=0.2087, recon=0.2087, kl=144.6325, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1704 (Recon: 0.1704, KL: 143.1506, Current Beta: 0.0000) | Avg Valid Loss: 0.1347 | Avg Valid recon Loss: 0.1347\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1117, recon=0.1117, kl=147.3735, beta=0.0000\n",
      "Batch 40, loss=0.1192, recon=0.1192, kl=147.7847, beta=0.0000\n",
      "Batch 60, loss=0.4459, recon=0.4459, kl=147.5517, beta=0.0000\n",
      "Batch 80, loss=0.0916, recon=0.0915, kl=149.3095, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1505 (Recon: 0.1505, KL: 148.0509, Current Beta: 0.0000) | Avg Valid Loss: 0.1198 | Avg Valid recon Loss: 0.1197\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0831, recon=0.0831, kl=148.4027, beta=0.0000\n",
      "Batch 40, loss=0.0975, recon=0.0974, kl=147.1097, beta=0.0000\n",
      "Batch 60, loss=0.0851, recon=0.0851, kl=146.6207, beta=0.0000\n",
      "Batch 80, loss=0.1027, recon=0.1027, kl=146.2429, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1347 (Recon: 0.1347, KL: 147.2855, Current Beta: 0.0000) | Avg Valid Loss: 0.1106 | Avg Valid recon Loss: 0.1106\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0882, recon=0.0882, kl=142.0417, beta=0.0000\n",
      "Batch 40, loss=0.0989, recon=0.0989, kl=137.0130, beta=0.0000\n",
      "Batch 60, loss=0.0825, recon=0.0825, kl=132.6944, beta=0.0000\n",
      "Batch 80, loss=0.0981, recon=0.0981, kl=129.1246, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1226 (Recon: 0.1226, KL: 136.0944, Current Beta: 0.0000) | Avg Valid Loss: 0.1001 | Avg Valid recon Loss: 0.1000\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0981, recon=0.0980, kl=111.9863, beta=0.0000\n",
      "Batch 40, loss=0.0671, recon=0.0671, kl=94.9746, beta=0.0000\n",
      "Batch 60, loss=0.0871, recon=0.0871, kl=82.7656, beta=0.0000\n",
      "Batch 80, loss=0.1063, recon=0.1062, kl=78.4188, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1116 (Recon: 0.1115, KL: 95.6658, Current Beta: 0.0000) | Avg Valid Loss: 0.0932 | Avg Valid recon Loss: 0.0931\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0651, recon=0.0650, kl=57.1891, beta=0.0000\n",
      "Batch 40, loss=0.0801, recon=0.0801, kl=45.7532, beta=0.0000\n",
      "Batch 60, loss=0.0838, recon=0.0837, kl=43.3292, beta=0.0000\n",
      "Batch 80, loss=0.0656, recon=0.0655, kl=42.8981, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1033 (Recon: 0.1033, KL: 50.3430, Current Beta: 0.0000) | Avg Valid Loss: 0.0876 | Avg Valid recon Loss: 0.0875\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0898, recon=0.0897, kl=24.9107, beta=0.0000\n",
      "Batch 40, loss=0.0702, recon=0.0701, kl=21.2731, beta=0.0000\n",
      "Batch 60, loss=0.0659, recon=0.0658, kl=19.5454, beta=0.0000\n",
      "Batch 80, loss=0.0937, recon=0.0937, kl=19.3182, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0969 (Recon: 0.0968, KL: 22.7780, Current Beta: 0.0000) | Avg Valid Loss: 0.0830 | Avg Valid recon Loss: 0.0830\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.2013, recon=0.2012, kl=9.3310, beta=0.0000\n",
      "Batch 40, loss=0.0978, recon=0.0978, kl=6.1462, beta=0.0000\n",
      "Batch 60, loss=0.0588, recon=0.0588, kl=5.5444, beta=0.0000\n",
      "Batch 80, loss=0.0938, recon=0.0937, kl=6.7404, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0906 (Recon: 0.0905, KL: 7.5183, Current Beta: 0.0000) | Avg Valid Loss: 0.0792 | Avg Valid recon Loss: 0.0792\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0582, recon=0.0582, kl=2.1458, beta=0.0000\n",
      "Batch 40, loss=0.0641, recon=0.0641, kl=2.0302, beta=0.0000\n",
      "Batch 60, loss=0.0625, recon=0.0625, kl=1.7955, beta=0.0000\n",
      "Batch 80, loss=0.0594, recon=0.0594, kl=1.8815, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0864 (Recon: 0.0864, KL: 2.2496, Current Beta: 0.0000) | Avg Valid Loss: 0.0756 | Avg Valid recon Loss: 0.0756\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0608, recon=0.0608, kl=0.7651, beta=0.0000\n",
      "Batch 40, loss=0.0602, recon=0.0602, kl=0.7535, beta=0.0000\n",
      "Batch 60, loss=0.0567, recon=0.0567, kl=0.6078, beta=0.0000\n",
      "Batch 80, loss=0.0388, recon=0.0388, kl=0.5030, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0827 (Recon: 0.0827, KL: 0.7285, Current Beta: 0.0000) | Avg Valid Loss: 0.0732 | Avg Valid recon Loss: 0.0732\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0782, recon=0.0782, kl=0.3323, beta=0.0001\n",
      "Batch 40, loss=0.0579, recon=0.0579, kl=0.3348, beta=0.0001\n",
      "Batch 60, loss=0.0545, recon=0.0545, kl=0.1922, beta=0.0001\n",
      "Batch 80, loss=0.0508, recon=0.0508, kl=0.1481, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0794 (Recon: 0.0794, KL: 0.2688, Current Beta: 0.0001) | Avg Valid Loss: 0.0703 | Avg Valid recon Loss: 0.0703\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0815, recon=0.0815, kl=0.0957, beta=0.0001\n",
      "Batch 40, loss=0.0523, recon=0.0523, kl=0.0530, beta=0.0001\n",
      "Batch 60, loss=0.0674, recon=0.0674, kl=0.0494, beta=0.0001\n",
      "Batch 80, loss=0.2293, recon=0.2293, kl=0.0383, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0767 (Recon: 0.0767, KL: 0.0647, Current Beta: 0.0001) | Avg Valid Loss: 0.0684 | Avg Valid recon Loss: 0.0684\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0604, recon=0.0604, kl=0.0429, beta=0.0001\n",
      "Batch 40, loss=0.1210, recon=0.1210, kl=0.0273, beta=0.0001\n",
      "Batch 60, loss=0.0577, recon=0.0577, kl=0.0233, beta=0.0001\n",
      "Batch 80, loss=0.0477, recon=0.0477, kl=0.0254, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0740 (Recon: 0.0740, KL: 0.0290, Current Beta: 0.0001) | Avg Valid Loss: 0.0663 | Avg Valid recon Loss: 0.0663\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0485, recon=0.0485, kl=0.0229, beta=0.0001\n",
      "Batch 40, loss=0.0727, recon=0.0727, kl=0.0123, beta=0.0001\n",
      "Batch 60, loss=0.0623, recon=0.0623, kl=0.0092, beta=0.0001\n",
      "Batch 80, loss=0.0995, recon=0.0995, kl=0.0086, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0721 (Recon: 0.0721, KL: 0.0144, Current Beta: 0.0001) | Avg Valid Loss: 0.0647 | Avg Valid recon Loss: 0.0647\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0424, recon=0.0424, kl=0.0113, beta=0.0001\n",
      "Batch 40, loss=0.0616, recon=0.0616, kl=0.0103, beta=0.0001\n",
      "Batch 60, loss=0.0509, recon=0.0509, kl=0.0059, beta=0.0001\n",
      "Batch 80, loss=0.0501, recon=0.0501, kl=0.0045, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0700 (Recon: 0.0700, KL: 0.0084, Current Beta: 0.0001) | Avg Valid Loss: 0.0629 | Avg Valid recon Loss: 0.0629\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1228, recon=0.1228, kl=0.0053, beta=0.0001\n",
      "Batch 40, loss=0.0608, recon=0.0608, kl=0.0042, beta=0.0001\n",
      "Batch 60, loss=0.0828, recon=0.0828, kl=0.0049, beta=0.0001\n",
      "Batch 80, loss=0.0656, recon=0.0656, kl=0.0038, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0686 (Recon: 0.0686, KL: 0.0047, Current Beta: 0.0001) | Avg Valid Loss: 0.0612 | Avg Valid recon Loss: 0.0612\n",
      "\n",
      "[VRAE Run 114/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2585, recon=0.2585, kl=66.1044, beta=0.0000\n",
      "Batch 40, loss=0.1921, recon=0.1921, kl=86.2439, beta=0.0000\n",
      "Batch 60, loss=0.1339, recon=0.1339, kl=84.6228, beta=0.0000\n",
      "Batch 80, loss=0.1120, recon=0.1120, kl=106.7966, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2564 (Recon: 0.2564, KL: 77.1495, Current Beta: 0.0000) | Avg Valid Loss: 0.0997 | Avg Valid recon Loss: 0.0997\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0672, recon=0.0672, kl=121.6214, beta=0.0000\n",
      "Batch 40, loss=0.0683, recon=0.0683, kl=112.0024, beta=0.0000\n",
      "Batch 60, loss=0.1040, recon=0.1040, kl=99.0904, beta=0.0000\n",
      "Batch 80, loss=0.0641, recon=0.0641, kl=112.5669, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0987 (Recon: 0.0987, KL: 112.9984, Current Beta: 0.0000) | Avg Valid Loss: 0.0737 | Avg Valid recon Loss: 0.0737\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1841, recon=0.1841, kl=130.1730, beta=0.0000\n",
      "Batch 40, loss=0.0445, recon=0.0445, kl=134.6008, beta=0.0000\n",
      "Batch 60, loss=0.0615, recon=0.0615, kl=137.0786, beta=0.0000\n",
      "Batch 80, loss=0.0657, recon=0.0657, kl=133.1189, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0780 (Recon: 0.0780, KL: 132.3483, Current Beta: 0.0000) | Avg Valid Loss: 0.0626 | Avg Valid recon Loss: 0.0626\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0491, recon=0.0491, kl=123.8386, beta=0.0000\n",
      "Batch 40, loss=0.0760, recon=0.0760, kl=97.0150, beta=0.0000\n",
      "Batch 60, loss=0.0732, recon=0.0732, kl=106.8134, beta=0.0000\n",
      "Batch 80, loss=0.0522, recon=0.0522, kl=121.2940, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0699 (Recon: 0.0699, KL: 114.6967, Current Beta: 0.0000) | Avg Valid Loss: 0.0579 | Avg Valid recon Loss: 0.0579\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0600, recon=0.0600, kl=113.4708, beta=0.0000\n",
      "Batch 40, loss=0.0439, recon=0.0439, kl=118.7554, beta=0.0000\n",
      "Batch 60, loss=0.0507, recon=0.0507, kl=125.8841, beta=0.0000\n",
      "Batch 80, loss=0.0553, recon=0.0553, kl=132.1878, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0629 (Recon: 0.0629, KL: 123.0846, Current Beta: 0.0000) | Avg Valid Loss: 0.0531 | Avg Valid recon Loss: 0.0531\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0653, recon=0.0653, kl=126.4611, beta=0.0000\n",
      "Batch 40, loss=0.0610, recon=0.0610, kl=129.2973, beta=0.0000\n",
      "Batch 60, loss=0.0384, recon=0.0384, kl=132.5555, beta=0.0000\n",
      "Batch 80, loss=0.0448, recon=0.0448, kl=129.7975, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0601 (Recon: 0.0601, KL: 129.5159, Current Beta: 0.0000) | Avg Valid Loss: 0.0497 | Avg Valid recon Loss: 0.0497\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=131.6458, beta=0.0000\n",
      "Batch 40, loss=0.0457, recon=0.0457, kl=126.6429, beta=0.0000\n",
      "Batch 60, loss=0.0470, recon=0.0470, kl=125.3309, beta=0.0000\n",
      "Batch 80, loss=0.0314, recon=0.0314, kl=124.5837, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0566 (Recon: 0.0566, KL: 126.7651, Current Beta: 0.0000) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0396, recon=0.0396, kl=111.6434, beta=0.0000\n",
      "Batch 40, loss=0.0513, recon=0.0512, kl=99.4487, beta=0.0000\n",
      "Batch 60, loss=0.0453, recon=0.0452, kl=98.8880, beta=0.0000\n",
      "Batch 80, loss=0.0530, recon=0.0530, kl=103.8164, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0509 (Recon: 0.0509, KL: 105.6082, Current Beta: 0.0000) | Avg Valid Loss: 0.0477 | Avg Valid recon Loss: 0.0477\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.5039, recon=0.5039, kl=87.0496, beta=0.0000\n",
      "Batch 40, loss=0.0471, recon=0.0471, kl=80.9184, beta=0.0000\n",
      "Batch 60, loss=0.0387, recon=0.0387, kl=81.5903, beta=0.0000\n",
      "Batch 80, loss=0.0392, recon=0.0392, kl=81.7902, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 84.6691, Current Beta: 0.0000) | Avg Valid Loss: 0.0462 | Avg Valid recon Loss: 0.0461\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0558, recon=0.0557, kl=56.6968, beta=0.0000\n",
      "Batch 40, loss=0.0430, recon=0.0429, kl=51.7851, beta=0.0000\n",
      "Batch 60, loss=0.0673, recon=0.0672, kl=76.3322, beta=0.0000\n",
      "Batch 80, loss=0.0415, recon=0.0414, kl=69.9318, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0528, KL: 64.3913, Current Beta: 0.0000) | Avg Valid Loss: 0.0442 | Avg Valid recon Loss: 0.0442\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0391, recon=0.0390, kl=42.1123, beta=0.0000\n",
      "Batch 40, loss=0.0380, recon=0.0379, kl=38.1857, beta=0.0000\n",
      "Batch 60, loss=0.0373, recon=0.0372, kl=30.9421, beta=0.0000\n",
      "Batch 80, loss=0.0366, recon=0.0364, kl=48.9615, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0528 (Recon: 0.0527, KL: 42.6500, Current Beta: 0.0000) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0428\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0438, recon=0.0436, kl=22.0992, beta=0.0000\n",
      "Batch 40, loss=0.0276, recon=0.0275, kl=23.8718, beta=0.0000\n",
      "Batch 60, loss=0.0317, recon=0.0315, kl=22.0659, beta=0.0000\n",
      "Batch 80, loss=0.0349, recon=0.0347, kl=22.4662, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0499 (Recon: 0.0497, KL: 25.3490, Current Beta: 0.0000) | Avg Valid Loss: 0.0424 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0392, recon=0.0391, kl=4.7380, beta=0.0000\n",
      "Batch 40, loss=0.0562, recon=0.0557, kl=24.8899, beta=0.0000\n",
      "Batch 60, loss=0.0358, recon=0.0354, kl=20.4222, beta=0.0000\n",
      "Batch 80, loss=0.0338, recon=0.0336, kl=13.0588, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0484 (Recon: 0.0481, KL: 15.7527, Current Beta: 0.0000) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0386, recon=0.0385, kl=4.8473, beta=0.0000\n",
      "Batch 40, loss=0.0922, recon=0.0921, kl=3.9151, beta=0.0000\n",
      "Batch 60, loss=0.1436, recon=0.1434, kl=5.5448, beta=0.0000\n",
      "Batch 80, loss=0.0444, recon=0.0441, kl=9.1577, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0491, KL: 6.1893, Current Beta: 0.0000) | Avg Valid Loss: 0.0442 | Avg Valid recon Loss: 0.0440\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0393, recon=0.0391, kl=3.7107, beta=0.0001\n",
      "Batch 40, loss=0.0357, recon=0.0354, kl=4.9696, beta=0.0001\n",
      "Batch 60, loss=0.0541, recon=0.0539, kl=2.8742, beta=0.0001\n",
      "Batch 80, loss=0.0443, recon=0.0439, kl=6.5636, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0492 (Recon: 0.0489, KL: 4.7072, Current Beta: 0.0001) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0418\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0435, recon=0.0431, kl=4.2532, beta=0.0001\n",
      "Batch 40, loss=0.0312, recon=0.0309, kl=2.7772, beta=0.0001\n",
      "Batch 60, loss=0.0349, recon=0.0346, kl=3.8433, beta=0.0001\n",
      "Batch 80, loss=0.0527, recon=0.0523, kl=3.9779, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0503 (Recon: 0.0499, KL: 4.0428, Current Beta: 0.0001) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0432\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0385, recon=0.0380, kl=4.3776, beta=0.0001\n",
      "Batch 40, loss=0.1026, recon=0.1016, kl=10.8065, beta=0.0001\n",
      "Batch 60, loss=0.0471, recon=0.0460, kl=11.2832, beta=0.0001\n",
      "Batch 80, loss=0.0645, recon=0.0640, kl=4.9615, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0494, KL: 7.5523, Current Beta: 0.0001) | Avg Valid Loss: 0.0404 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0496, recon=0.0488, kl=8.7522, beta=0.0001\n",
      "Batch 40, loss=0.0334, recon=0.0326, kl=7.5953, beta=0.0001\n",
      "Batch 60, loss=0.0313, recon=0.0306, kl=6.0339, beta=0.0001\n",
      "Batch 80, loss=0.0402, recon=0.0397, kl=4.9763, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0465, KL: 7.1544, Current Beta: 0.0001) | Avg Valid Loss: 0.0400 | Avg Valid recon Loss: 0.0394\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0359, recon=0.0354, kl=5.3987, beta=0.0001\n",
      "Batch 40, loss=0.0423, recon=0.0419, kl=4.2110, beta=0.0001\n",
      "Batch 60, loss=0.0375, recon=0.0370, kl=4.7621, beta=0.0001\n",
      "Batch 80, loss=0.0343, recon=0.0338, kl=5.3647, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0475 (Recon: 0.0469, KL: 5.1799, Current Beta: 0.0001) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0439, recon=0.0434, kl=4.8040, beta=0.0001\n",
      "Batch 40, loss=0.0491, recon=0.0487, kl=4.0776, beta=0.0001\n",
      "Batch 60, loss=0.0376, recon=0.0372, kl=3.4994, beta=0.0001\n",
      "Batch 80, loss=0.0517, recon=0.0514, kl=3.6541, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0454 (Recon: 0.0450, KL: 4.0716, Current Beta: 0.0001) | Avg Valid Loss: 0.0396 | Avg Valid recon Loss: 0.0392\n",
      "\n",
      "[VRAE Run 115/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4156, recon=0.4156, kl=0.2657, beta=0.0000\n",
      "Batch 40, loss=0.3188, recon=0.3188, kl=1.3593, beta=0.0000\n",
      "Batch 60, loss=0.2149, recon=0.2149, kl=11.2634, beta=0.0000\n",
      "Batch 80, loss=0.2865, recon=0.2865, kl=17.5973, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4072 (Recon: 0.4072, KL: 6.9599, Current Beta: 0.0000) | Avg Valid Loss: 0.2100 | Avg Valid recon Loss: 0.2100\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2502, recon=0.2502, kl=23.0700, beta=0.0000\n",
      "Batch 40, loss=0.1717, recon=0.1717, kl=25.7396, beta=0.0000\n",
      "Batch 60, loss=0.1574, recon=0.1574, kl=28.5184, beta=0.0000\n",
      "Batch 80, loss=0.1263, recon=0.1263, kl=30.0050, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1964 (Recon: 0.1964, KL: 26.2476, Current Beta: 0.0000) | Avg Valid Loss: 0.1364 | Avg Valid recon Loss: 0.1364\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1291, recon=0.1291, kl=32.0903, beta=0.0000\n",
      "Batch 40, loss=0.0949, recon=0.0949, kl=34.0015, beta=0.0000\n",
      "Batch 60, loss=0.1152, recon=0.1152, kl=36.8046, beta=0.0000\n",
      "Batch 80, loss=0.0851, recon=0.0851, kl=36.3314, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1525 (Recon: 0.1525, KL: 34.3009, Current Beta: 0.0000) | Avg Valid Loss: 0.1092 | Avg Valid recon Loss: 0.1092\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0915, recon=0.0915, kl=38.9416, beta=0.0000\n",
      "Batch 40, loss=0.1368, recon=0.1368, kl=41.6127, beta=0.0000\n",
      "Batch 60, loss=0.1238, recon=0.1238, kl=42.9036, beta=0.0000\n",
      "Batch 80, loss=0.1034, recon=0.1034, kl=42.9473, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1278 (Recon: 0.1278, KL: 41.1020, Current Beta: 0.0000) | Avg Valid Loss: 0.0949 | Avg Valid recon Loss: 0.0949\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0676, recon=0.0676, kl=44.3294, beta=0.0000\n",
      "Batch 40, loss=0.0972, recon=0.0972, kl=42.6877, beta=0.0000\n",
      "Batch 60, loss=0.0894, recon=0.0894, kl=44.4257, beta=0.0000\n",
      "Batch 80, loss=0.1045, recon=0.1045, kl=44.6662, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1077 (Recon: 0.1077, KL: 43.9443, Current Beta: 0.0000) | Avg Valid Loss: 0.0841 | Avg Valid recon Loss: 0.0841\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0924, recon=0.0924, kl=47.8798, beta=0.0000\n",
      "Batch 40, loss=0.0505, recon=0.0505, kl=50.8341, beta=0.0000\n",
      "Batch 60, loss=0.0751, recon=0.0751, kl=52.1851, beta=0.0000\n",
      "Batch 80, loss=0.1051, recon=0.1051, kl=51.4616, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0980 (Recon: 0.0980, KL: 50.1806, Current Beta: 0.0000) | Avg Valid Loss: 0.0768 | Avg Valid recon Loss: 0.0768\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0789, recon=0.0789, kl=51.1921, beta=0.0000\n",
      "Batch 40, loss=0.0427, recon=0.0427, kl=51.2211, beta=0.0000\n",
      "Batch 60, loss=0.1318, recon=0.1318, kl=51.9707, beta=0.0000\n",
      "Batch 80, loss=0.1085, recon=0.1085, kl=52.7812, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0888 (Recon: 0.0888, KL: 51.9365, Current Beta: 0.0000) | Avg Valid Loss: 0.0709 | Avg Valid recon Loss: 0.0709\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0669, recon=0.0669, kl=50.1721, beta=0.0000\n",
      "Batch 40, loss=0.0430, recon=0.0430, kl=47.8006, beta=0.0000\n",
      "Batch 60, loss=0.3054, recon=0.3054, kl=46.8785, beta=0.0000\n",
      "Batch 80, loss=0.0599, recon=0.0599, kl=45.9194, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0818 (Recon: 0.0818, KL: 48.1487, Current Beta: 0.0000) | Avg Valid Loss: 0.0687 | Avg Valid recon Loss: 0.0687\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0714, recon=0.0714, kl=41.5133, beta=0.0000\n",
      "Batch 40, loss=0.0538, recon=0.0538, kl=37.6881, beta=0.0000\n",
      "Batch 60, loss=0.0537, recon=0.0537, kl=34.6266, beta=0.0000\n",
      "Batch 80, loss=0.0524, recon=0.0524, kl=32.8233, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0759 (Recon: 0.0759, KL: 37.4878, Current Beta: 0.0000) | Avg Valid Loss: 0.0646 | Avg Valid recon Loss: 0.0646\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0701, recon=0.0701, kl=26.5268, beta=0.0000\n",
      "Batch 40, loss=0.0632, recon=0.0632, kl=22.9889, beta=0.0000\n",
      "Batch 60, loss=0.0589, recon=0.0589, kl=21.3674, beta=0.0000\n",
      "Batch 80, loss=0.0736, recon=0.0736, kl=20.2789, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0717 (Recon: 0.0716, KL: 23.8343, Current Beta: 0.0000) | Avg Valid Loss: 0.0619 | Avg Valid recon Loss: 0.0619\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0512, recon=0.0512, kl=12.8140, beta=0.0000\n",
      "Batch 40, loss=0.2104, recon=0.2104, kl=11.0906, beta=0.0000\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=10.4727, beta=0.0000\n",
      "Batch 80, loss=0.0470, recon=0.0470, kl=9.3555, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0682 (Recon: 0.0682, KL: 11.7544, Current Beta: 0.0000) | Avg Valid Loss: 0.0597 | Avg Valid recon Loss: 0.0597\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0572, recon=0.0572, kl=4.7513, beta=0.0000\n",
      "Batch 40, loss=0.0512, recon=0.0512, kl=4.8635, beta=0.0000\n",
      "Batch 60, loss=0.0474, recon=0.0474, kl=3.7854, beta=0.0000\n",
      "Batch 80, loss=0.0990, recon=0.0990, kl=3.7599, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0651 (Recon: 0.0651, KL: 4.6976, Current Beta: 0.0000) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0574\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0392, recon=0.0392, kl=1.3104, beta=0.0000\n",
      "Batch 40, loss=0.0410, recon=0.0410, kl=1.5661, beta=0.0000\n",
      "Batch 60, loss=0.0561, recon=0.0561, kl=1.4855, beta=0.0000\n",
      "Batch 80, loss=0.0358, recon=0.0358, kl=1.2165, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0626 (Recon: 0.0626, KL: 1.6421, Current Beta: 0.0000) | Avg Valid Loss: 0.0561 | Avg Valid recon Loss: 0.0561\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0798, recon=0.0798, kl=0.7065, beta=0.0000\n",
      "Batch 40, loss=0.0394, recon=0.0394, kl=0.5191, beta=0.0000\n",
      "Batch 60, loss=0.0584, recon=0.0584, kl=0.3630, beta=0.0000\n",
      "Batch 80, loss=0.0472, recon=0.0472, kl=0.4643, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0601 (Recon: 0.0600, KL: 0.5365, Current Beta: 0.0000) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0541\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0361, recon=0.0361, kl=0.1612, beta=0.0001\n",
      "Batch 40, loss=0.0447, recon=0.0447, kl=0.1692, beta=0.0001\n",
      "Batch 60, loss=0.0514, recon=0.0513, kl=0.1566, beta=0.0001\n",
      "Batch 80, loss=0.0450, recon=0.0450, kl=0.1658, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0585 (Recon: 0.0585, KL: 0.1594, Current Beta: 0.0001) | Avg Valid Loss: 0.0521 | Avg Valid recon Loss: 0.0520\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0403, recon=0.0402, kl=0.0315, beta=0.0001\n",
      "Batch 40, loss=0.0550, recon=0.0550, kl=0.0570, beta=0.0001\n",
      "Batch 60, loss=0.0358, recon=0.0358, kl=0.0213, beta=0.0001\n",
      "Batch 80, loss=0.0441, recon=0.0441, kl=0.0148, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0565 (Recon: 0.0565, KL: 0.0405, Current Beta: 0.0001) | Avg Valid Loss: 0.0511 | Avg Valid recon Loss: 0.0511\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0415, recon=0.0415, kl=0.0201, beta=0.0001\n",
      "Batch 40, loss=0.0426, recon=0.0426, kl=0.0255, beta=0.0001\n",
      "Batch 60, loss=0.0406, recon=0.0406, kl=0.0103, beta=0.0001\n",
      "Batch 80, loss=0.0400, recon=0.0400, kl=0.0271, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 0.0178, Current Beta: 0.0001) | Avg Valid Loss: 0.0498 | Avg Valid recon Loss: 0.0498\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0359, recon=0.0359, kl=0.0128, beta=0.0001\n",
      "Batch 40, loss=0.5900, recon=0.5900, kl=0.0164, beta=0.0001\n",
      "Batch 60, loss=0.0305, recon=0.0305, kl=0.0170, beta=0.0001\n",
      "Batch 80, loss=0.0673, recon=0.0673, kl=0.0166, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0540, KL: 0.0150, Current Beta: 0.0001) | Avg Valid Loss: 0.0487 | Avg Valid recon Loss: 0.0487\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=0.0126, beta=0.0001\n",
      "Batch 40, loss=0.0440, recon=0.0440, kl=0.0094, beta=0.0001\n",
      "Batch 60, loss=0.0534, recon=0.0534, kl=0.0083, beta=0.0001\n",
      "Batch 80, loss=0.0278, recon=0.0278, kl=0.0088, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 0.0108, Current Beta: 0.0001) | Avg Valid Loss: 0.0468 | Avg Valid recon Loss: 0.0468\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0333, recon=0.0333, kl=0.0063, beta=0.0001\n",
      "Batch 40, loss=0.0348, recon=0.0348, kl=0.0064, beta=0.0001\n",
      "Batch 60, loss=0.0388, recon=0.0388, kl=0.0075, beta=0.0001\n",
      "Batch 80, loss=0.0470, recon=0.0470, kl=0.0061, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0516, KL: 0.0081, Current Beta: 0.0001) | Avg Valid Loss: 0.0464 | Avg Valid recon Loss: 0.0464\n",
      "\n",
      "[VRAE Run 116/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1326, recon=0.1326, kl=23.7738, beta=0.0000\n",
      "Batch 40, loss=0.1035, recon=0.1035, kl=28.2181, beta=0.0000\n",
      "Batch 60, loss=0.0669, recon=0.0669, kl=31.4333, beta=0.0000\n",
      "Batch 80, loss=0.0888, recon=0.0888, kl=35.3769, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1746 (Recon: 0.1746, KL: 26.6465, Current Beta: 0.0000) | Avg Valid Loss: 0.0742 | Avg Valid recon Loss: 0.0742\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0551, recon=0.0551, kl=33.0941, beta=0.0000\n",
      "Batch 40, loss=0.0481, recon=0.0481, kl=33.9778, beta=0.0000\n",
      "Batch 60, loss=0.0737, recon=0.0737, kl=37.7395, beta=0.0000\n",
      "Batch 80, loss=0.0458, recon=0.0458, kl=32.3405, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0760 (Recon: 0.0760, KL: 34.3843, Current Beta: 0.0000) | Avg Valid Loss: 0.0582 | Avg Valid recon Loss: 0.0582\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0362, recon=0.0362, kl=31.7672, beta=0.0000\n",
      "Batch 40, loss=0.0468, recon=0.0468, kl=37.0354, beta=0.0000\n",
      "Batch 60, loss=0.0408, recon=0.0408, kl=33.3029, beta=0.0000\n",
      "Batch 80, loss=0.0486, recon=0.0486, kl=36.4555, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0614 (Recon: 0.0614, KL: 33.9543, Current Beta: 0.0000) | Avg Valid Loss: 0.0503 | Avg Valid recon Loss: 0.0503\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0437, recon=0.0437, kl=41.3451, beta=0.0000\n",
      "Batch 40, loss=0.0359, recon=0.0359, kl=38.1171, beta=0.0000\n",
      "Batch 60, loss=0.0419, recon=0.0419, kl=37.9274, beta=0.0000\n",
      "Batch 80, loss=0.0329, recon=0.0329, kl=35.0396, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0555, KL: 38.0606, Current Beta: 0.0000) | Avg Valid Loss: 0.0476 | Avg Valid recon Loss: 0.0476\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=36.3824, beta=0.0000\n",
      "Batch 40, loss=0.0413, recon=0.0413, kl=28.3443, beta=0.0000\n",
      "Batch 60, loss=0.0472, recon=0.0472, kl=30.9308, beta=0.0000\n",
      "Batch 80, loss=0.0444, recon=0.0444, kl=34.2022, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0531 (Recon: 0.0531, KL: 33.1490, Current Beta: 0.0000) | Avg Valid Loss: 0.0437 | Avg Valid recon Loss: 0.0437\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0503, recon=0.0503, kl=37.3674, beta=0.0000\n",
      "Batch 40, loss=0.1141, recon=0.1141, kl=37.9255, beta=0.0000\n",
      "Batch 60, loss=0.0365, recon=0.0365, kl=35.9886, beta=0.0000\n",
      "Batch 80, loss=0.0463, recon=0.0463, kl=37.1264, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0491 (Recon: 0.0491, KL: 36.9819, Current Beta: 0.0000) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0317, recon=0.0317, kl=36.1128, beta=0.0000\n",
      "Batch 40, loss=0.0978, recon=0.0978, kl=34.6903, beta=0.0000\n",
      "Batch 60, loss=0.0357, recon=0.0357, kl=35.4059, beta=0.0000\n",
      "Batch 80, loss=0.0365, recon=0.0365, kl=36.6205, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0461, KL: 35.8415, Current Beta: 0.0000) | Avg Valid Loss: 0.0443 | Avg Valid recon Loss: 0.0443\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0469, recon=0.0469, kl=34.9435, beta=0.0000\n",
      "Batch 40, loss=0.0449, recon=0.0449, kl=34.6913, beta=0.0000\n",
      "Batch 60, loss=0.0445, recon=0.0445, kl=33.4422, beta=0.0000\n",
      "Batch 80, loss=0.0364, recon=0.0364, kl=33.3963, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0489 (Recon: 0.0489, KL: 34.3812, Current Beta: 0.0000) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0306, recon=0.0306, kl=30.6137, beta=0.0000\n",
      "Batch 40, loss=0.0388, recon=0.0388, kl=26.8987, beta=0.0000\n",
      "Batch 60, loss=0.0334, recon=0.0334, kl=25.1186, beta=0.0000\n",
      "Batch 80, loss=0.0419, recon=0.0419, kl=24.5381, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0440, KL: 27.2840, Current Beta: 0.0000) | Avg Valid Loss: 0.0432 | Avg Valid recon Loss: 0.0432\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0417, recon=0.0417, kl=22.5780, beta=0.0000\n",
      "Batch 40, loss=0.0372, recon=0.0372, kl=18.8856, beta=0.0000\n",
      "Batch 60, loss=0.0529, recon=0.0529, kl=17.6969, beta=0.0000\n",
      "Batch 80, loss=0.0263, recon=0.0262, kl=17.3308, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0462, KL: 19.7471, Current Beta: 0.0000) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0335, recon=0.0334, kl=12.5229, beta=0.0000\n",
      "Batch 40, loss=0.0413, recon=0.0413, kl=8.9127, beta=0.0000\n",
      "Batch 60, loss=0.0434, recon=0.0433, kl=9.7432, beta=0.0000\n",
      "Batch 80, loss=0.0869, recon=0.0868, kl=10.2443, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0434, KL: 11.2251, Current Beta: 0.0000) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0377, recon=0.0376, kl=7.0111, beta=0.0000\n",
      "Batch 40, loss=0.0355, recon=0.0355, kl=6.1722, beta=0.0000\n",
      "Batch 60, loss=0.0600, recon=0.0599, kl=5.4458, beta=0.0000\n",
      "Batch 80, loss=0.0720, recon=0.0720, kl=4.1611, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0451 (Recon: 0.0451, KL: 6.4266, Current Beta: 0.0000) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0246, recon=0.0246, kl=1.3448, beta=0.0000\n",
      "Batch 40, loss=0.0421, recon=0.0420, kl=1.6817, beta=0.0000\n",
      "Batch 60, loss=0.0452, recon=0.0451, kl=2.0454, beta=0.0000\n",
      "Batch 80, loss=0.0534, recon=0.0534, kl=0.9399, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0432, KL: 1.7193, Current Beta: 0.0000) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=0.5595, beta=0.0000\n",
      "Batch 40, loss=0.0290, recon=0.0290, kl=0.2078, beta=0.0000\n",
      "Batch 60, loss=0.0241, recon=0.0241, kl=0.2956, beta=0.0000\n",
      "Batch 80, loss=0.0396, recon=0.0396, kl=0.4255, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0415, KL: 0.4264, Current Beta: 0.0000) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0370, recon=0.0370, kl=0.1102, beta=0.0001\n",
      "Batch 40, loss=0.0246, recon=0.0246, kl=0.0551, beta=0.0001\n",
      "Batch 60, loss=0.0301, recon=0.0301, kl=0.0571, beta=0.0001\n",
      "Batch 80, loss=0.0242, recon=0.0242, kl=0.0440, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0400, KL: 0.1019, Current Beta: 0.0001) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0208, recon=0.0208, kl=0.0785, beta=0.0001\n",
      "Batch 40, loss=0.0228, recon=0.0228, kl=0.0302, beta=0.0001\n",
      "Batch 60, loss=0.0349, recon=0.0349, kl=0.0297, beta=0.0001\n",
      "Batch 80, loss=0.0392, recon=0.0392, kl=0.0262, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0382, KL: 0.0589, Current Beta: 0.0001) | Avg Valid Loss: 0.0335 | Avg Valid recon Loss: 0.0335\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0307, recon=0.0307, kl=0.1173, beta=0.0001\n",
      "Batch 40, loss=0.0417, recon=0.0417, kl=0.0231, beta=0.0001\n",
      "Batch 60, loss=0.0317, recon=0.0316, kl=0.0273, beta=0.0001\n",
      "Batch 80, loss=0.0277, recon=0.0277, kl=0.0157, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0368 (Recon: 0.0368, KL: 0.0412, Current Beta: 0.0001) | Avg Valid Loss: 0.0349 | Avg Valid recon Loss: 0.0349\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0307, recon=0.0307, kl=0.0394, beta=0.0001\n",
      "Batch 40, loss=0.0298, recon=0.0298, kl=0.0545, beta=0.0001\n",
      "Batch 60, loss=0.0259, recon=0.0259, kl=0.0287, beta=0.0001\n",
      "Batch 80, loss=0.0379, recon=0.0379, kl=0.0844, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0382, KL: 0.0509, Current Beta: 0.0001) | Avg Valid Loss: 0.0324 | Avg Valid recon Loss: 0.0324\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0227, recon=0.0227, kl=0.0182, beta=0.0001\n",
      "Batch 40, loss=0.0276, recon=0.0276, kl=0.0290, beta=0.0001\n",
      "Batch 60, loss=0.0274, recon=0.0274, kl=0.0332, beta=0.0001\n",
      "Batch 80, loss=0.0226, recon=0.0226, kl=0.0389, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0357 (Recon: 0.0357, KL: 0.0359, Current Beta: 0.0001) | Avg Valid Loss: 0.0322 | Avg Valid recon Loss: 0.0322\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0378, recon=0.0378, kl=0.0461, beta=0.0001\n",
      "Batch 40, loss=0.0208, recon=0.0207, kl=0.0332, beta=0.0001\n",
      "Batch 60, loss=0.0307, recon=0.0307, kl=0.0836, beta=0.0001\n",
      "Batch 80, loss=0.0268, recon=0.0268, kl=0.0117, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0358, KL: 0.0498, Current Beta: 0.0001) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0334\n",
      "\n",
      "[VRAE Run 117/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6098, recon=0.6098, kl=0.4762, beta=0.0000\n",
      "Batch 40, loss=0.3321, recon=0.3321, kl=5.0005, beta=0.0000\n",
      "Batch 60, loss=0.7104, recon=0.7104, kl=30.1472, beta=0.0000\n",
      "Batch 80, loss=1.4055, recon=1.4055, kl=46.3269, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4491 (Recon: 0.4491, KL: 18.7189, Current Beta: 0.0000) | Avg Valid Loss: 0.2191 | Avg Valid recon Loss: 0.2191\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2564, recon=0.2564, kl=62.1189, beta=0.0000\n",
      "Batch 40, loss=0.1789, recon=0.1789, kl=66.7280, beta=0.0000\n",
      "Batch 60, loss=0.1775, recon=0.1775, kl=69.8842, beta=0.0000\n",
      "Batch 80, loss=0.1253, recon=0.1253, kl=70.4656, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1995 (Recon: 0.1995, KL: 66.0312, Current Beta: 0.0000) | Avg Valid Loss: 0.1409 | Avg Valid recon Loss: 0.1409\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1711, recon=0.1711, kl=71.1800, beta=0.0000\n",
      "Batch 40, loss=0.1677, recon=0.1677, kl=74.6029, beta=0.0000\n",
      "Batch 60, loss=0.1819, recon=0.1819, kl=82.9155, beta=0.0000\n",
      "Batch 80, loss=0.1171, recon=0.1171, kl=84.2129, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1525 (Recon: 0.1525, KL: 77.6100, Current Beta: 0.0000) | Avg Valid Loss: 0.1122 | Avg Valid recon Loss: 0.1122\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0953, recon=0.0953, kl=92.1976, beta=0.0000\n",
      "Batch 40, loss=0.0848, recon=0.0848, kl=91.4831, beta=0.0000\n",
      "Batch 60, loss=0.1237, recon=0.1237, kl=89.5395, beta=0.0000\n",
      "Batch 80, loss=0.0943, recon=0.0943, kl=90.2206, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1274 (Recon: 0.1274, KL: 90.5152, Current Beta: 0.0000) | Avg Valid Loss: 0.0959 | Avg Valid recon Loss: 0.0959\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0818, recon=0.0818, kl=92.6447, beta=0.0000\n",
      "Batch 40, loss=0.0781, recon=0.0781, kl=92.6923, beta=0.0000\n",
      "Batch 60, loss=0.0967, recon=0.0967, kl=94.4243, beta=0.0000\n",
      "Batch 80, loss=0.0979, recon=0.0978, kl=94.3897, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1096 (Recon: 0.1096, KL: 93.1403, Current Beta: 0.0000) | Avg Valid Loss: 0.0851 | Avg Valid recon Loss: 0.0851\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0846, recon=0.0846, kl=92.7328, beta=0.0000\n",
      "Batch 40, loss=0.0733, recon=0.0733, kl=93.3268, beta=0.0000\n",
      "Batch 60, loss=0.0890, recon=0.0890, kl=91.2469, beta=0.0000\n",
      "Batch 80, loss=0.0749, recon=0.0749, kl=87.6034, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0971 (Recon: 0.0971, KL: 91.3900, Current Beta: 0.0000) | Avg Valid Loss: 0.0782 | Avg Valid recon Loss: 0.0782\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0615, recon=0.0615, kl=87.4277, beta=0.0000\n",
      "Batch 40, loss=0.0955, recon=0.0954, kl=86.4418, beta=0.0000\n",
      "Batch 60, loss=0.1764, recon=0.1764, kl=86.4741, beta=0.0000\n",
      "Batch 80, loss=0.2572, recon=0.2572, kl=84.8712, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0881 (Recon: 0.0881, KL: 86.3531, Current Beta: 0.0000) | Avg Valid Loss: 0.0731 | Avg Valid recon Loss: 0.0731\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1138, recon=0.1138, kl=81.2719, beta=0.0000\n",
      "Batch 40, loss=0.0462, recon=0.0462, kl=75.5249, beta=0.0000\n",
      "Batch 60, loss=0.7364, recon=0.7364, kl=67.9675, beta=0.0000\n",
      "Batch 80, loss=0.0635, recon=0.0635, kl=67.2820, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0814 (Recon: 0.0814, KL: 74.3211, Current Beta: 0.0000) | Avg Valid Loss: 0.0688 | Avg Valid recon Loss: 0.0687\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0434, recon=0.0434, kl=60.1560, beta=0.0000\n",
      "Batch 40, loss=0.0389, recon=0.0389, kl=52.1970, beta=0.0000\n",
      "Batch 60, loss=0.0551, recon=0.0551, kl=46.1692, beta=0.0000\n",
      "Batch 80, loss=0.0643, recon=0.0643, kl=44.1104, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0756 (Recon: 0.0755, KL: 52.7265, Current Beta: 0.0000) | Avg Valid Loss: 0.0661 | Avg Valid recon Loss: 0.0661\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0568, recon=0.0568, kl=33.7327, beta=0.0000\n",
      "Batch 40, loss=0.0930, recon=0.0929, kl=26.1850, beta=0.0000\n",
      "Batch 60, loss=0.0624, recon=0.0623, kl=24.8936, beta=0.0000\n",
      "Batch 80, loss=0.0482, recon=0.0482, kl=25.3512, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0707 (Recon: 0.0707, KL: 29.7252, Current Beta: 0.0000) | Avg Valid Loss: 0.0626 | Avg Valid recon Loss: 0.0626\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0476, recon=0.0476, kl=12.5512, beta=0.0000\n",
      "Batch 40, loss=0.0496, recon=0.0496, kl=11.9668, beta=0.0000\n",
      "Batch 60, loss=0.1557, recon=0.1557, kl=11.6961, beta=0.0000\n",
      "Batch 80, loss=0.0507, recon=0.0507, kl=11.3636, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0679 (Recon: 0.0678, KL: 13.1902, Current Beta: 0.0000) | Avg Valid Loss: 0.0599 | Avg Valid recon Loss: 0.0599\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0679, recon=0.0679, kl=4.6474, beta=0.0000\n",
      "Batch 40, loss=0.0373, recon=0.0373, kl=5.5427, beta=0.0000\n",
      "Batch 60, loss=0.0642, recon=0.0641, kl=4.9877, beta=0.0000\n",
      "Batch 80, loss=0.0490, recon=0.0490, kl=5.0007, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0648 (Recon: 0.0648, KL: 5.4623, Current Beta: 0.0000) | Avg Valid Loss: 0.0582 | Avg Valid recon Loss: 0.0582\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0373, recon=0.0372, kl=2.5187, beta=0.0000\n",
      "Batch 40, loss=0.0439, recon=0.0439, kl=2.1215, beta=0.0000\n",
      "Batch 60, loss=0.0451, recon=0.0451, kl=2.0771, beta=0.0000\n",
      "Batch 80, loss=0.0473, recon=0.0473, kl=1.8129, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0625 (Recon: 0.0624, KL: 2.1825, Current Beta: 0.0000) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0566\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1524, recon=0.1524, kl=0.7175, beta=0.0000\n",
      "Batch 40, loss=0.0270, recon=0.0269, kl=0.9793, beta=0.0000\n",
      "Batch 60, loss=0.0580, recon=0.0579, kl=0.7374, beta=0.0000\n",
      "Batch 80, loss=0.0383, recon=0.0382, kl=0.8490, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0604 (Recon: 0.0603, KL: 0.9569, Current Beta: 0.0000) | Avg Valid Loss: 0.0547 | Avg Valid recon Loss: 0.0547\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0406, recon=0.0405, kl=0.3194, beta=0.0001\n",
      "Batch 40, loss=0.0470, recon=0.0470, kl=0.2684, beta=0.0001\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=0.5378, beta=0.0001\n",
      "Batch 80, loss=0.0437, recon=0.0436, kl=0.2432, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0584 (Recon: 0.0584, KL: 0.3579, Current Beta: 0.0001) | Avg Valid Loss: 0.0527 | Avg Valid recon Loss: 0.0526\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0488, recon=0.0488, kl=0.1320, beta=0.0001\n",
      "Batch 40, loss=0.0461, recon=0.0461, kl=0.0661, beta=0.0001\n",
      "Batch 60, loss=0.0594, recon=0.0594, kl=0.0983, beta=0.0001\n",
      "Batch 80, loss=0.0413, recon=0.0413, kl=0.0668, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0566 (Recon: 0.0566, KL: 0.1027, Current Beta: 0.0001) | Avg Valid Loss: 0.0512 | Avg Valid recon Loss: 0.0512\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0408, recon=0.0408, kl=0.0655, beta=0.0001\n",
      "Batch 40, loss=0.0337, recon=0.0337, kl=0.0392, beta=0.0001\n",
      "Batch 60, loss=0.0327, recon=0.0327, kl=0.0373, beta=0.0001\n",
      "Batch 80, loss=0.0446, recon=0.0446, kl=0.0184, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 0.0429, Current Beta: 0.0001) | Avg Valid Loss: 0.0500 | Avg Valid recon Loss: 0.0500\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0354, recon=0.0354, kl=0.0230, beta=0.0001\n",
      "Batch 40, loss=0.0383, recon=0.0383, kl=0.0166, beta=0.0001\n",
      "Batch 60, loss=0.0421, recon=0.0421, kl=0.0240, beta=0.0001\n",
      "Batch 80, loss=0.1317, recon=0.1317, kl=0.0230, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0538 (Recon: 0.0538, KL: 0.0228, Current Beta: 0.0001) | Avg Valid Loss: 0.0489 | Avg Valid recon Loss: 0.0489\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0513, recon=0.0512, kl=0.0118, beta=0.0001\n",
      "Batch 40, loss=0.0535, recon=0.0535, kl=0.0241, beta=0.0001\n",
      "Batch 60, loss=0.0347, recon=0.0347, kl=0.0087, beta=0.0001\n",
      "Batch 80, loss=0.0358, recon=0.0358, kl=0.0124, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0525 (Recon: 0.0525, KL: 0.0168, Current Beta: 0.0001) | Avg Valid Loss: 0.0482 | Avg Valid recon Loss: 0.0482\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0504, recon=0.0504, kl=0.0075, beta=0.0001\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=0.0048, beta=0.0001\n",
      "Batch 60, loss=0.0338, recon=0.0338, kl=0.0100, beta=0.0001\n",
      "Batch 80, loss=0.0339, recon=0.0339, kl=0.0077, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0516, KL: 0.0078, Current Beta: 0.0001) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0472\n",
      "\n",
      "[VRAE Run 118/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1953, recon=0.1953, kl=41.6587, beta=0.0000\n",
      "Batch 40, loss=0.1143, recon=0.1143, kl=49.5796, beta=0.0000\n",
      "Batch 60, loss=0.1785, recon=0.1785, kl=55.6423, beta=0.0000\n",
      "Batch 80, loss=0.9830, recon=0.9830, kl=59.8673, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1775 (Recon: 0.1775, KL: 46.4971, Current Beta: 0.0000) | Avg Valid Loss: 0.0759 | Avg Valid recon Loss: 0.0759\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0785, recon=0.0785, kl=55.5046, beta=0.0000\n",
      "Batch 40, loss=0.0585, recon=0.0585, kl=55.3752, beta=0.0000\n",
      "Batch 60, loss=0.0497, recon=0.0497, kl=60.7920, beta=0.0000\n",
      "Batch 80, loss=0.0550, recon=0.0550, kl=67.7396, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0764 (Recon: 0.0764, KL: 60.0467, Current Beta: 0.0000) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0574\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0503, recon=0.0503, kl=72.9134, beta=0.0000\n",
      "Batch 40, loss=0.1579, recon=0.1579, kl=70.1282, beta=0.0000\n",
      "Batch 60, loss=0.0390, recon=0.0390, kl=70.4293, beta=0.0000\n",
      "Batch 80, loss=0.5855, recon=0.5855, kl=75.2608, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0615 (Recon: 0.0615, KL: 72.5096, Current Beta: 0.0000) | Avg Valid Loss: 0.0525 | Avg Valid recon Loss: 0.0525\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0452, recon=0.0452, kl=73.5633, beta=0.0000\n",
      "Batch 40, loss=0.0422, recon=0.0422, kl=74.0803, beta=0.0000\n",
      "Batch 60, loss=0.0328, recon=0.0328, kl=74.3716, beta=0.0000\n",
      "Batch 80, loss=0.0321, recon=0.0321, kl=73.1155, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0566 (Recon: 0.0566, KL: 74.3811, Current Beta: 0.0000) | Avg Valid Loss: 0.0463 | Avg Valid recon Loss: 0.0463\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=71.3019, beta=0.0000\n",
      "Batch 40, loss=0.0305, recon=0.0305, kl=71.3099, beta=0.0000\n",
      "Batch 60, loss=0.0392, recon=0.0392, kl=69.6013, beta=0.0000\n",
      "Batch 80, loss=0.0469, recon=0.0469, kl=71.2030, beta=0.0000\n",
      "  â†’ Avg Train Loss: 1.6017 (Recon: 1.6017, KL: 92.3606, Current Beta: 0.0000) | Avg Valid Loss: 0.0477 | Avg Valid recon Loss: 0.0477\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0592, recon=0.0592, kl=56.5203, beta=0.0000\n",
      "Batch 40, loss=0.0447, recon=0.0447, kl=45.8587, beta=0.0000\n",
      "Batch 60, loss=0.0366, recon=0.0366, kl=47.4426, beta=0.0000\n",
      "Batch 80, loss=0.0323, recon=0.0323, kl=49.9388, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0505 (Recon: 0.0505, KL: 55.5714, Current Beta: 0.0000) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0433, recon=0.0433, kl=53.8275, beta=0.0000\n",
      "Batch 40, loss=0.0315, recon=0.0315, kl=56.5189, beta=0.0000\n",
      "Batch 60, loss=0.0418, recon=0.0418, kl=58.2943, beta=0.0000\n",
      "Batch 80, loss=0.0502, recon=0.0502, kl=60.1956, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0472, KL: 56.6798, Current Beta: 0.0000) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0286, recon=0.0286, kl=62.6509, beta=0.0000\n",
      "Batch 40, loss=0.0387, recon=0.0387, kl=64.9480, beta=0.0000\n",
      "Batch 60, loss=0.0415, recon=0.0415, kl=66.2723, beta=0.0000\n",
      "Batch 80, loss=0.0315, recon=0.0315, kl=66.7617, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 64.8419, Current Beta: 0.0000) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0372, recon=0.0372, kl=68.7647, beta=0.0000\n",
      "Batch 40, loss=0.0346, recon=0.0346, kl=69.4948, beta=0.0000\n",
      "Batch 60, loss=0.0330, recon=0.0330, kl=69.8848, beta=0.0000\n",
      "Batch 80, loss=0.0374, recon=0.0374, kl=69.9771, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 69.5889, Current Beta: 0.0000) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0319, recon=0.0319, kl=69.1441, beta=0.0000\n",
      "Batch 40, loss=0.0459, recon=0.0459, kl=66.4320, beta=0.0000\n",
      "Batch 60, loss=0.0286, recon=0.0285, kl=65.2165, beta=0.0000\n",
      "Batch 80, loss=0.0471, recon=0.0470, kl=64.0481, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0386, KL: 66.5310, Current Beta: 0.0000) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0357, recon=0.0356, kl=58.7958, beta=0.0000\n",
      "Batch 40, loss=0.0375, recon=0.0374, kl=53.5240, beta=0.0000\n",
      "Batch 60, loss=0.0378, recon=0.0376, kl=49.8329, beta=0.0000\n",
      "Batch 80, loss=0.0480, recon=0.0479, kl=47.6200, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0412 (Recon: 0.0410, KL: 53.4338, Current Beta: 0.0000) | Avg Valid Loss: 0.0409 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0425, recon=0.0422, kl=41.3804, beta=0.0000\n",
      "Batch 40, loss=0.0311, recon=0.0308, kl=37.6245, beta=0.0000\n",
      "Batch 60, loss=0.0280, recon=0.0277, kl=35.5098, beta=0.0000\n",
      "Batch 80, loss=0.0259, recon=0.0256, kl=33.9979, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0426 (Recon: 0.0423, KL: 37.9972, Current Beta: 0.0000) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0367\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0370, recon=0.0365, kl=26.3256, beta=0.0000\n",
      "Batch 40, loss=0.0315, recon=0.0311, kl=22.8608, beta=0.0000\n",
      "Batch 60, loss=0.0280, recon=0.0276, kl=22.5187, beta=0.0000\n",
      "Batch 80, loss=0.0412, recon=0.0409, kl=19.9347, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0425, KL: 23.9826, Current Beta: 0.0000) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0385\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0324, recon=0.0319, kl=14.9954, beta=0.0000\n",
      "Batch 40, loss=0.0439, recon=0.0433, kl=14.4454, beta=0.0000\n",
      "Batch 60, loss=0.0364, recon=0.0360, kl=11.1398, beta=0.0000\n",
      "Batch 80, loss=0.0373, recon=0.0369, kl=10.2910, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0417, KL: 13.3097, Current Beta: 0.0000) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0293, recon=0.0290, kl=5.7774, beta=0.0001\n",
      "Batch 40, loss=0.0624, recon=0.0619, kl=7.8434, beta=0.0001\n",
      "Batch 60, loss=0.0363, recon=0.0360, kl=4.7767, beta=0.0001\n",
      "Batch 80, loss=0.0302, recon=0.0300, kl=4.3980, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0396, KL: 6.0204, Current Beta: 0.0001) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0365\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0827, recon=0.0825, kl=2.4193, beta=0.0001\n",
      "Batch 40, loss=0.0386, recon=0.0383, kl=2.8172, beta=0.0001\n",
      "Batch 60, loss=0.0295, recon=0.0292, kl=2.4514, beta=0.0001\n",
      "Batch 80, loss=0.0285, recon=0.0284, kl=1.7156, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0386, KL: 2.4199, Current Beta: 0.0001) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0291, recon=0.0290, kl=1.6339, beta=0.0001\n",
      "Batch 40, loss=0.0303, recon=0.0302, kl=1.0342, beta=0.0001\n",
      "Batch 60, loss=0.0324, recon=0.0323, kl=1.3457, beta=0.0001\n",
      "Batch 80, loss=0.0368, recon=0.0367, kl=0.9292, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0407, KL: 1.2326, Current Beta: 0.0001) | Avg Valid Loss: 0.0340 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0245, recon=0.0244, kl=0.8396, beta=0.0001\n",
      "Batch 40, loss=0.0260, recon=0.0259, kl=0.9817, beta=0.0001\n",
      "Batch 60, loss=0.0236, recon=0.0235, kl=0.5192, beta=0.0001\n",
      "Batch 80, loss=0.0343, recon=0.0342, kl=0.9616, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0399, KL: 0.7995, Current Beta: 0.0001) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.2378, recon=0.2377, kl=0.9617, beta=0.0001\n",
      "Batch 40, loss=0.0355, recon=0.0355, kl=0.5628, beta=0.0001\n",
      "Batch 60, loss=0.0902, recon=0.0902, kl=0.3803, beta=0.0001\n",
      "Batch 80, loss=0.0412, recon=0.0412, kl=0.6211, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0428, KL: 0.6414, Current Beta: 0.0001) | Avg Valid Loss: 0.0340 | Avg Valid recon Loss: 0.0340\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0285, recon=0.0284, kl=0.6136, beta=0.0001\n",
      "Batch 40, loss=0.0721, recon=0.0721, kl=0.3659, beta=0.0001\n",
      "Batch 60, loss=0.0289, recon=0.0288, kl=0.3925, beta=0.0001\n",
      "Batch 80, loss=0.0349, recon=0.0349, kl=0.3985, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0381, KL: 0.4266, Current Beta: 0.0001) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0338\n",
      "\n",
      "[VRAE Run 119/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4178, recon=0.4178, kl=1.3221, beta=0.0000\n",
      "Batch 40, loss=0.2947, recon=0.2947, kl=36.5034, beta=0.0000\n",
      "Batch 60, loss=0.7316, recon=0.7316, kl=76.0607, beta=0.0000\n",
      "Batch 80, loss=0.1899, recon=0.1899, kl=96.9382, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3939 (Recon: 0.3939, KL: 47.2815, Current Beta: 0.0000) | Avg Valid Loss: 0.1986 | Avg Valid recon Loss: 0.1986\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1626, recon=0.1626, kl=114.3223, beta=0.0000\n",
      "Batch 40, loss=0.1542, recon=0.1542, kl=123.5584, beta=0.0000\n",
      "Batch 60, loss=0.2671, recon=0.2671, kl=129.6435, beta=0.0000\n",
      "Batch 80, loss=0.1233, recon=0.1233, kl=133.2862, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1901 (Recon: 0.1901, KL: 123.4943, Current Beta: 0.0000) | Avg Valid Loss: 0.1314 | Avg Valid recon Loss: 0.1314\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1552, recon=0.1552, kl=139.1719, beta=0.0000\n",
      "Batch 40, loss=0.1086, recon=0.1086, kl=144.6832, beta=0.0000\n",
      "Batch 60, loss=0.1603, recon=0.1603, kl=151.8278, beta=0.0000\n",
      "Batch 80, loss=0.0897, recon=0.0897, kl=158.1236, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1461 (Recon: 0.1461, KL: 147.2520, Current Beta: 0.0000) | Avg Valid Loss: 0.1083 | Avg Valid recon Loss: 0.1083\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0903, recon=0.0903, kl=163.9455, beta=0.0000\n",
      "Batch 40, loss=0.1546, recon=0.1546, kl=167.3199, beta=0.0000\n",
      "Batch 60, loss=0.1042, recon=0.1042, kl=169.9898, beta=0.0000\n",
      "Batch 80, loss=0.1178, recon=0.1178, kl=171.8112, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1216 (Recon: 0.1216, KL: 167.5424, Current Beta: 0.0000) | Avg Valid Loss: 0.0915 | Avg Valid recon Loss: 0.0915\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0824, recon=0.0824, kl=174.4972, beta=0.0000\n",
      "Batch 40, loss=0.1314, recon=0.1314, kl=175.9474, beta=0.0000\n",
      "Batch 60, loss=0.0743, recon=0.0743, kl=175.2202, beta=0.0000\n",
      "Batch 80, loss=0.0816, recon=0.0816, kl=176.4149, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1048 (Recon: 0.1048, KL: 174.9592, Current Beta: 0.0000) | Avg Valid Loss: 0.0814 | Avg Valid recon Loss: 0.0814\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0967, recon=0.0967, kl=176.2933, beta=0.0000\n",
      "Batch 40, loss=0.1057, recon=0.1057, kl=176.1348, beta=0.0000\n",
      "Batch 60, loss=0.0785, recon=0.0785, kl=178.2782, beta=0.0000\n",
      "Batch 80, loss=0.0535, recon=0.0535, kl=177.9165, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0925 (Recon: 0.0925, KL: 176.8993, Current Beta: 0.0000) | Avg Valid Loss: 0.0751 | Avg Valid recon Loss: 0.0751\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0816, recon=0.0816, kl=172.2820, beta=0.0000\n",
      "Batch 40, loss=0.1325, recon=0.1325, kl=168.5035, beta=0.0000\n",
      "Batch 60, loss=0.0911, recon=0.0911, kl=165.1299, beta=0.0000\n",
      "Batch 80, loss=0.0574, recon=0.0574, kl=162.7189, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0834 (Recon: 0.0834, KL: 167.7305, Current Beta: 0.0000) | Avg Valid Loss: 0.0694 | Avg Valid recon Loss: 0.0694\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0592, recon=0.0592, kl=151.3204, beta=0.0000\n",
      "Batch 40, loss=0.0406, recon=0.0406, kl=138.5547, beta=0.0000\n",
      "Batch 60, loss=0.0538, recon=0.0538, kl=124.3078, beta=0.0000\n",
      "Batch 80, loss=0.0451, recon=0.0451, kl=118.6319, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0748 (Recon: 0.0748, KL: 135.6678, Current Beta: 0.0000) | Avg Valid Loss: 0.0657 | Avg Valid recon Loss: 0.0657\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0649, recon=0.0649, kl=99.4348, beta=0.0000\n",
      "Batch 40, loss=0.0637, recon=0.0636, kl=83.6286, beta=0.0000\n",
      "Batch 60, loss=0.0568, recon=0.0567, kl=76.4811, beta=0.0000\n",
      "Batch 80, loss=0.0480, recon=0.0480, kl=73.3002, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0715 (Recon: 0.0715, KL: 86.6316, Current Beta: 0.0000) | Avg Valid Loss: 0.0624 | Avg Valid recon Loss: 0.0624\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1289, recon=0.1288, kl=49.4185, beta=0.0000\n",
      "Batch 40, loss=0.0502, recon=0.0501, kl=39.5139, beta=0.0000\n",
      "Batch 60, loss=0.0670, recon=0.0669, kl=41.5623, beta=0.0000\n",
      "Batch 80, loss=0.0790, recon=0.0789, kl=39.4012, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0681 (Recon: 0.0681, KL: 45.7666, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0410, recon=0.0409, kl=17.9584, beta=0.0000\n",
      "Batch 40, loss=0.0568, recon=0.0567, kl=18.5859, beta=0.0000\n",
      "Batch 60, loss=0.0613, recon=0.0613, kl=16.0821, beta=0.0000\n",
      "Batch 80, loss=0.0434, recon=0.0434, kl=15.4849, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0651 (Recon: 0.0650, KL: 19.1905, Current Beta: 0.0000) | Avg Valid Loss: 0.0575 | Avg Valid recon Loss: 0.0574\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0401, recon=0.0401, kl=5.7625, beta=0.0000\n",
      "Batch 40, loss=0.0464, recon=0.0464, kl=6.1398, beta=0.0000\n",
      "Batch 60, loss=0.0536, recon=0.0535, kl=6.6427, beta=0.0000\n",
      "Batch 80, loss=0.0535, recon=0.0535, kl=4.6921, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0624 (Recon: 0.0623, KL: 6.7888, Current Beta: 0.0000) | Avg Valid Loss: 0.0556 | Avg Valid recon Loss: 0.0556\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0427, recon=0.0426, kl=2.7456, beta=0.0000\n",
      "Batch 40, loss=0.0588, recon=0.0587, kl=2.1752, beta=0.0000\n",
      "Batch 60, loss=0.0392, recon=0.0391, kl=2.1480, beta=0.0000\n",
      "Batch 80, loss=0.0545, recon=0.0545, kl=1.7729, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0603 (Recon: 0.0602, KL: 2.5723, Current Beta: 0.0000) | Avg Valid Loss: 0.0535 | Avg Valid recon Loss: 0.0535\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0299, recon=0.0298, kl=1.0893, beta=0.0000\n",
      "Batch 40, loss=0.0404, recon=0.0404, kl=1.2809, beta=0.0000\n",
      "Batch 60, loss=0.0429, recon=0.0429, kl=0.9643, beta=0.0000\n",
      "Batch 80, loss=0.0380, recon=0.0379, kl=0.8939, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0585 (Recon: 0.0585, KL: 1.1377, Current Beta: 0.0000) | Avg Valid Loss: 0.0521 | Avg Valid recon Loss: 0.0521\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0311, recon=0.0311, kl=0.4026, beta=0.0001\n",
      "Batch 40, loss=0.0821, recon=0.0821, kl=0.4061, beta=0.0001\n",
      "Batch 60, loss=0.0524, recon=0.0524, kl=0.3750, beta=0.0001\n",
      "Batch 80, loss=0.0412, recon=0.0412, kl=0.3650, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0567 (Recon: 0.0567, KL: 0.4608, Current Beta: 0.0001) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0487, recon=0.0487, kl=0.0915, beta=0.0001\n",
      "Batch 40, loss=0.0507, recon=0.0507, kl=0.1978, beta=0.0001\n",
      "Batch 60, loss=0.0391, recon=0.0391, kl=0.0837, beta=0.0001\n",
      "Batch 80, loss=0.0450, recon=0.0450, kl=0.1073, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 0.1318, Current Beta: 0.0001) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0496\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0376, recon=0.0376, kl=0.0623, beta=0.0001\n",
      "Batch 40, loss=0.0295, recon=0.0295, kl=0.0538, beta=0.0001\n",
      "Batch 60, loss=0.0524, recon=0.0524, kl=0.0855, beta=0.0001\n",
      "Batch 80, loss=0.0357, recon=0.0357, kl=0.0567, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0540, KL: 0.0653, Current Beta: 0.0001) | Avg Valid Loss: 0.0486 | Avg Valid recon Loss: 0.0486\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0629, recon=0.0629, kl=0.0273, beta=0.0001\n",
      "Batch 40, loss=0.0382, recon=0.0382, kl=0.0343, beta=0.0001\n",
      "Batch 60, loss=0.0323, recon=0.0323, kl=0.0289, beta=0.0001\n",
      "Batch 80, loss=0.0506, recon=0.0506, kl=0.0263, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0528 (Recon: 0.0528, KL: 0.0303, Current Beta: 0.0001) | Avg Valid Loss: 0.0475 | Avg Valid recon Loss: 0.0475\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0893, recon=0.0893, kl=0.0259, beta=0.0001\n",
      "Batch 40, loss=0.0409, recon=0.0409, kl=0.0147, beta=0.0001\n",
      "Batch 60, loss=0.0428, recon=0.0428, kl=0.0220, beta=0.0001\n",
      "Batch 80, loss=0.0289, recon=0.0289, kl=0.0181, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0516, KL: 0.0220, Current Beta: 0.0001) | Avg Valid Loss: 0.0467 | Avg Valid recon Loss: 0.0467\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0348, recon=0.0348, kl=0.0277, beta=0.0001\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=0.0183, beta=0.0001\n",
      "Batch 60, loss=0.0346, recon=0.0346, kl=0.0289, beta=0.0001\n",
      "Batch 80, loss=0.0297, recon=0.0297, kl=0.0178, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0506 (Recon: 0.0506, KL: 0.0218, Current Beta: 0.0001) | Avg Valid Loss: 0.0451 | Avg Valid recon Loss: 0.0451\n",
      "\n",
      "[VRAE Run 120/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2314, recon=0.2314, kl=62.6823, beta=0.0000\n",
      "Batch 40, loss=0.1229, recon=0.1229, kl=91.5356, beta=0.0000\n",
      "Batch 60, loss=0.1016, recon=0.1016, kl=117.1876, beta=0.0000\n",
      "Batch 80, loss=0.0813, recon=0.0813, kl=109.4973, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1728 (Recon: 0.1728, KL: 86.5534, Current Beta: 0.0000) | Avg Valid Loss: 0.0722 | Avg Valid recon Loss: 0.0722\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0686, recon=0.0686, kl=121.3773, beta=0.0000\n",
      "Batch 40, loss=0.0577, recon=0.0577, kl=119.2992, beta=0.0000\n",
      "Batch 60, loss=0.0482, recon=0.0482, kl=121.2192, beta=0.0000\n",
      "Batch 80, loss=0.0480, recon=0.0480, kl=106.9778, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0753 (Recon: 0.0753, KL: 116.2128, Current Beta: 0.0000) | Avg Valid Loss: 0.0582 | Avg Valid recon Loss: 0.0582\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0752, recon=0.0752, kl=119.6095, beta=0.0000\n",
      "Batch 40, loss=0.1407, recon=0.1407, kl=114.8151, beta=0.0000\n",
      "Batch 60, loss=0.2079, recon=0.2079, kl=129.5093, beta=0.0000\n",
      "Batch 80, loss=0.0502, recon=0.0502, kl=131.1401, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0621 (Recon: 0.0621, KL: 122.0442, Current Beta: 0.0000) | Avg Valid Loss: 0.0515 | Avg Valid recon Loss: 0.0515\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0325, recon=0.0325, kl=133.1632, beta=0.0000\n",
      "Batch 40, loss=0.0519, recon=0.0519, kl=130.5089, beta=0.0000\n",
      "Batch 60, loss=0.0361, recon=0.0361, kl=133.3903, beta=0.0000\n",
      "Batch 80, loss=0.0362, recon=0.0362, kl=135.5182, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0557 (Recon: 0.0557, KL: 134.5889, Current Beta: 0.0000) | Avg Valid Loss: 0.0464 | Avg Valid recon Loss: 0.0464\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=124.4375, beta=0.0000\n",
      "Batch 40, loss=0.0407, recon=0.0407, kl=126.1896, beta=0.0000\n",
      "Batch 60, loss=0.0560, recon=0.0560, kl=130.2490, beta=0.0000\n",
      "Batch 80, loss=0.0374, recon=0.0374, kl=129.0323, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0525 (Recon: 0.0525, KL: 128.0724, Current Beta: 0.0000) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0278, recon=0.0278, kl=140.6928, beta=0.0000\n",
      "Batch 40, loss=0.4425, recon=0.4425, kl=146.1653, beta=0.0000\n",
      "Batch 60, loss=0.0344, recon=0.0344, kl=136.1312, beta=0.0000\n",
      "Batch 80, loss=0.0340, recon=0.0340, kl=119.1735, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0506 (Recon: 0.0506, KL: 135.0285, Current Beta: 0.0000) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0347, recon=0.0347, kl=125.3139, beta=0.0000\n",
      "Batch 40, loss=0.0382, recon=0.0382, kl=122.0801, beta=0.0000\n",
      "Batch 60, loss=0.0505, recon=0.0505, kl=123.0370, beta=0.0000\n",
      "Batch 80, loss=0.0336, recon=0.0336, kl=121.0337, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0487 (Recon: 0.0487, KL: 122.6906, Current Beta: 0.0000) | Avg Valid Loss: 0.0419 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0383, recon=0.0383, kl=120.6191, beta=0.0000\n",
      "Batch 40, loss=0.0365, recon=0.0365, kl=115.5005, beta=0.0000\n",
      "Batch 60, loss=0.0350, recon=0.0350, kl=115.6961, beta=0.0000\n",
      "Batch 80, loss=0.0284, recon=0.0284, kl=111.7869, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0456, KL: 116.4989, Current Beta: 0.0000) | Avg Valid Loss: 0.0400 | Avg Valid recon Loss: 0.0400\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0358, recon=0.0357, kl=90.4848, beta=0.0000\n",
      "Batch 40, loss=0.0355, recon=0.0355, kl=87.1592, beta=0.0000\n",
      "Batch 60, loss=0.0368, recon=0.0368, kl=93.2722, beta=0.0000\n",
      "Batch 80, loss=0.0484, recon=0.0484, kl=92.5977, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 93.1195, Current Beta: 0.0000) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0852, recon=0.0852, kl=61.6855, beta=0.0000\n",
      "Batch 40, loss=0.0547, recon=0.0547, kl=71.5468, beta=0.0000\n",
      "Batch 60, loss=0.0765, recon=0.0765, kl=71.3542, beta=0.0000\n",
      "Batch 80, loss=0.0348, recon=0.0348, kl=63.5964, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0427, KL: 70.0632, Current Beta: 0.0000) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0509, recon=0.0507, kl=39.1454, beta=0.0000\n",
      "Batch 40, loss=0.0371, recon=0.0370, kl=44.6881, beta=0.0000\n",
      "Batch 60, loss=0.0330, recon=0.0329, kl=47.2295, beta=0.0000\n",
      "Batch 80, loss=0.0370, recon=0.0369, kl=38.7582, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0417, KL: 45.1253, Current Beta: 0.0000) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0341, recon=0.0339, kl=29.0138, beta=0.0000\n",
      "Batch 40, loss=0.0710, recon=0.0708, kl=26.1971, beta=0.0000\n",
      "Batch 60, loss=0.0311, recon=0.0309, kl=28.1222, beta=0.0000\n",
      "Batch 80, loss=0.0279, recon=0.0277, kl=24.4967, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0416, KL: 29.1111, Current Beta: 0.0000) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0269, recon=0.0266, kl=15.0393, beta=0.0000\n",
      "Batch 40, loss=0.0259, recon=0.0253, kl=30.8210, beta=0.0000\n",
      "Batch 60, loss=0.0450, recon=0.0446, kl=21.5570, beta=0.0000\n",
      "Batch 80, loss=0.0536, recon=0.0534, kl=11.5370, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0411 (Recon: 0.0407, KL: 18.9431, Current Beta: 0.0000) | Avg Valid Loss: 0.0354 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0302, recon=0.0298, kl=10.9758, beta=0.0000\n",
      "Batch 40, loss=0.0361, recon=0.0359, kl=7.4981, beta=0.0000\n",
      "Batch 60, loss=0.0232, recon=0.0230, kl=6.4295, beta=0.0000\n",
      "Batch 80, loss=0.0313, recon=0.0311, kl=3.4774, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0394 (Recon: 0.0391, KL: 7.7485, Current Beta: 0.0000) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0470, recon=0.0464, kl=8.7513, beta=0.0001\n",
      "Batch 40, loss=0.0398, recon=0.0396, kl=4.0501, beta=0.0001\n",
      "Batch 60, loss=0.0680, recon=0.0678, kl=3.4488, beta=0.0001\n",
      "Batch 80, loss=0.0331, recon=0.0330, kl=3.0437, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0407, KL: 5.5369, Current Beta: 0.0001) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.2182, recon=0.2174, kl=8.3512, beta=0.0001\n",
      "Batch 40, loss=0.0383, recon=0.0374, kl=8.8434, beta=0.0001\n",
      "Batch 60, loss=0.0406, recon=0.0400, kl=5.7360, beta=0.0001\n",
      "Batch 80, loss=0.0274, recon=0.0269, kl=4.5295, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0398, KL: 6.4461, Current Beta: 0.0001) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0349, recon=0.0341, kl=7.6113, beta=0.0001\n",
      "Batch 40, loss=0.0342, recon=0.0335, kl=7.3174, beta=0.0001\n",
      "Batch 60, loss=0.0303, recon=0.0298, kl=4.8990, beta=0.0001\n",
      "Batch 80, loss=0.0255, recon=0.0246, kl=8.5307, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0380, KL: 6.7117, Current Beta: 0.0001) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0253, recon=0.0247, kl=6.5955, beta=0.0001\n",
      "Batch 40, loss=0.0231, recon=0.0225, kl=5.5644, beta=0.0001\n",
      "Batch 60, loss=0.0333, recon=0.0328, kl=4.6505, beta=0.0001\n",
      "Batch 80, loss=0.0281, recon=0.0276, kl=4.4595, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0387 (Recon: 0.0381, KL: 5.6287, Current Beta: 0.0001) | Avg Valid Loss: 0.0326 | Avg Valid recon Loss: 0.0321\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0345, recon=0.0341, kl=4.8193, beta=0.0001\n",
      "Batch 40, loss=0.0344, recon=0.0340, kl=4.3794, beta=0.0001\n",
      "Batch 60, loss=0.0297, recon=0.0293, kl=3.7272, beta=0.0001\n",
      "Batch 80, loss=0.0292, recon=0.0286, kl=5.4547, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0381 (Recon: 0.0376, KL: 4.6558, Current Beta: 0.0001) | Avg Valid Loss: 0.0322 | Avg Valid recon Loss: 0.0316\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0464, recon=0.0458, kl=5.7803, beta=0.0001\n",
      "Batch 40, loss=0.0332, recon=0.0327, kl=5.0469, beta=0.0001\n",
      "Batch 60, loss=0.0328, recon=0.0323, kl=4.3552, beta=0.0001\n",
      "Batch 80, loss=0.0281, recon=0.0277, kl=4.2871, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0368 (Recon: 0.0363, KL: 4.9528, Current Beta: 0.0001) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0326\n",
      "\n",
      "[VRAE Run 121/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3688, recon=0.3688, kl=0.6187, beta=0.0000\n",
      "Batch 40, loss=0.2179, recon=0.2179, kl=15.6391, beta=0.0000\n",
      "Batch 60, loss=0.1375, recon=0.1375, kl=24.9422, beta=0.0000\n",
      "Batch 80, loss=0.1568, recon=0.1568, kl=33.0541, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3114 (Recon: 0.3114, KL: 16.7592, Current Beta: 0.0000) | Avg Valid Loss: 0.1270 | Avg Valid recon Loss: 0.1270\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1169, recon=0.1169, kl=36.4233, beta=0.0000\n",
      "Batch 40, loss=0.1201, recon=0.1201, kl=40.0348, beta=0.0000\n",
      "Batch 60, loss=0.1328, recon=0.1328, kl=43.7776, beta=0.0000\n",
      "Batch 80, loss=0.1050, recon=0.1050, kl=47.6788, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1430 (Recon: 0.1430, KL: 41.6598, Current Beta: 0.0000) | Avg Valid Loss: 0.0918 | Avg Valid recon Loss: 0.0918\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1080, recon=0.1080, kl=57.2633, beta=0.0000\n",
      "Batch 40, loss=0.2081, recon=0.2081, kl=55.9562, beta=0.0000\n",
      "Batch 60, loss=0.1076, recon=0.1076, kl=66.8980, beta=0.0000\n",
      "Batch 80, loss=0.0715, recon=0.0715, kl=67.9895, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1125 (Recon: 0.1125, KL: 60.6686, Current Beta: 0.0000) | Avg Valid Loss: 0.0777 | Avg Valid recon Loss: 0.0777\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0705, recon=0.0705, kl=71.7065, beta=0.0000\n",
      "Batch 40, loss=0.0669, recon=0.0669, kl=67.7653, beta=0.0000\n",
      "Batch 60, loss=0.0805, recon=0.0805, kl=68.6999, beta=0.0000\n",
      "Batch 80, loss=0.0707, recon=0.0707, kl=71.5726, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0932 (Recon: 0.0932, KL: 69.8421, Current Beta: 0.0000) | Avg Valid Loss: 0.0688 | Avg Valid recon Loss: 0.0688\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0657, recon=0.0657, kl=70.1804, beta=0.0000\n",
      "Batch 40, loss=0.0679, recon=0.0679, kl=72.2588, beta=0.0000\n",
      "Batch 60, loss=0.0642, recon=0.0641, kl=69.4291, beta=0.0000\n",
      "Batch 80, loss=0.0667, recon=0.0667, kl=66.9606, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0806 (Recon: 0.0806, KL: 68.8266, Current Beta: 0.0000) | Avg Valid Loss: 0.0629 | Avg Valid recon Loss: 0.0629\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0570, recon=0.0570, kl=68.4660, beta=0.0000\n",
      "Batch 40, loss=0.0447, recon=0.0447, kl=67.4059, beta=0.0000\n",
      "Batch 60, loss=0.0622, recon=0.0622, kl=67.3972, beta=0.0000\n",
      "Batch 80, loss=0.0694, recon=0.0694, kl=66.6969, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0719 (Recon: 0.0719, KL: 67.3036, Current Beta: 0.0000) | Avg Valid Loss: 0.0585 | Avg Valid recon Loss: 0.0585\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0607, recon=0.0607, kl=64.3598, beta=0.0000\n",
      "Batch 40, loss=0.0548, recon=0.0548, kl=60.1614, beta=0.0000\n",
      "Batch 60, loss=0.0615, recon=0.0615, kl=58.8314, beta=0.0000\n",
      "Batch 80, loss=0.0592, recon=0.0592, kl=53.9865, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0661 (Recon: 0.0661, KL: 60.1603, Current Beta: 0.0000) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0537\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0364, recon=0.0364, kl=49.4377, beta=0.0000\n",
      "Batch 40, loss=0.1006, recon=0.1006, kl=43.9629, beta=0.0000\n",
      "Batch 60, loss=0.0409, recon=0.0409, kl=42.2064, beta=0.0000\n",
      "Batch 80, loss=0.0481, recon=0.0480, kl=41.3526, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0615 (Recon: 0.0615, KL: 45.6954, Current Beta: 0.0000) | Avg Valid Loss: 0.0514 | Avg Valid recon Loss: 0.0514\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0443, recon=0.0443, kl=33.6424, beta=0.0000\n",
      "Batch 40, loss=0.0433, recon=0.0433, kl=30.3658, beta=0.0000\n",
      "Batch 60, loss=0.0588, recon=0.0588, kl=30.3942, beta=0.0000\n",
      "Batch 80, loss=0.0615, recon=0.0615, kl=29.7545, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 31.9837, Current Beta: 0.0000) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0482, recon=0.0482, kl=19.9840, beta=0.0000\n",
      "Batch 40, loss=0.0371, recon=0.0371, kl=16.3346, beta=0.0000\n",
      "Batch 60, loss=0.0377, recon=0.0377, kl=17.0490, beta=0.0000\n",
      "Batch 80, loss=0.0420, recon=0.0419, kl=15.5338, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0544 (Recon: 0.0544, KL: 18.3332, Current Beta: 0.0000) | Avg Valid Loss: 0.0463 | Avg Valid recon Loss: 0.0463\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0362, recon=0.0362, kl=9.9485, beta=0.0000\n",
      "Batch 40, loss=0.0507, recon=0.0507, kl=9.6680, beta=0.0000\n",
      "Batch 60, loss=0.0381, recon=0.0381, kl=9.0391, beta=0.0000\n",
      "Batch 80, loss=0.0884, recon=0.0884, kl=8.0651, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0524, KL: 9.6912, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0554, recon=0.0554, kl=3.8794, beta=0.0000\n",
      "Batch 40, loss=0.0414, recon=0.0414, kl=4.2095, beta=0.0000\n",
      "Batch 60, loss=0.0461, recon=0.0461, kl=3.7785, beta=0.0000\n",
      "Batch 80, loss=0.0365, recon=0.0365, kl=3.2366, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0503 (Recon: 0.0503, KL: 4.0559, Current Beta: 0.0000) | Avg Valid Loss: 0.0432 | Avg Valid recon Loss: 0.0432\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0904, recon=0.0904, kl=1.7937, beta=0.0000\n",
      "Batch 40, loss=0.0302, recon=0.0301, kl=1.9401, beta=0.0000\n",
      "Batch 60, loss=0.0418, recon=0.0418, kl=1.5679, beta=0.0000\n",
      "Batch 80, loss=0.0385, recon=0.0385, kl=1.6833, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0484, KL: 1.8322, Current Beta: 0.0000) | Avg Valid Loss: 0.0416 | Avg Valid recon Loss: 0.0416\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0339, recon=0.0339, kl=0.7120, beta=0.0000\n",
      "Batch 40, loss=0.0464, recon=0.0463, kl=0.8689, beta=0.0000\n",
      "Batch 60, loss=0.0445, recon=0.0445, kl=0.5797, beta=0.0000\n",
      "Batch 80, loss=0.0363, recon=0.0363, kl=0.6390, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0468 (Recon: 0.0467, KL: 0.7290, Current Beta: 0.0000) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0368, recon=0.0368, kl=0.4330, beta=0.0001\n",
      "Batch 40, loss=0.0262, recon=0.0262, kl=0.1872, beta=0.0001\n",
      "Batch 60, loss=0.1490, recon=0.1490, kl=0.2562, beta=0.0001\n",
      "Batch 80, loss=0.0541, recon=0.0541, kl=0.1474, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 0.2735, Current Beta: 0.0001) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0394\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0481, recon=0.0481, kl=0.0846, beta=0.0001\n",
      "Batch 40, loss=0.0329, recon=0.0329, kl=0.0322, beta=0.0001\n",
      "Batch 60, loss=0.0317, recon=0.0317, kl=0.0459, beta=0.0001\n",
      "Batch 80, loss=0.0430, recon=0.0430, kl=0.0170, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0449, KL: 0.0543, Current Beta: 0.0001) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0488, recon=0.0488, kl=0.0274, beta=0.0001\n",
      "Batch 40, loss=0.0415, recon=0.0415, kl=0.0367, beta=0.0001\n",
      "Batch 60, loss=0.0379, recon=0.0379, kl=0.0204, beta=0.0001\n",
      "Batch 80, loss=0.0278, recon=0.0278, kl=0.0164, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 0.0296, Current Beta: 0.0001) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0384\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0305, recon=0.0305, kl=0.0302, beta=0.0001\n",
      "Batch 40, loss=0.0614, recon=0.0614, kl=0.0112, beta=0.0001\n",
      "Batch 60, loss=0.0489, recon=0.0488, kl=0.0130, beta=0.0001\n",
      "Batch 80, loss=0.0313, recon=0.0313, kl=0.0118, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0426 (Recon: 0.0426, KL: 0.0177, Current Beta: 0.0001) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0352, recon=0.0352, kl=0.0054, beta=0.0001\n",
      "Batch 40, loss=0.0345, recon=0.0345, kl=0.0074, beta=0.0001\n",
      "Batch 60, loss=0.0341, recon=0.0341, kl=0.0080, beta=0.0001\n",
      "Batch 80, loss=0.0436, recon=0.0436, kl=0.0095, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0420, KL: 0.0102, Current Beta: 0.0001) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0292, recon=0.0292, kl=0.0054, beta=0.0001\n",
      "Batch 40, loss=0.0367, recon=0.0367, kl=0.0077, beta=0.0001\n",
      "Batch 60, loss=0.0427, recon=0.0427, kl=0.0061, beta=0.0001\n",
      "Batch 80, loss=0.0273, recon=0.0273, kl=0.0064, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0408 (Recon: 0.0408, KL: 0.0101, Current Beta: 0.0001) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0355\n",
      "\n",
      "[VRAE Run 122/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1383, recon=0.1383, kl=21.1713, beta=0.0000\n",
      "Batch 40, loss=0.0863, recon=0.0863, kl=21.7017, beta=0.0000\n",
      "Batch 60, loss=0.0644, recon=0.0644, kl=24.9433, beta=0.0000\n",
      "Batch 80, loss=0.0530, recon=0.0530, kl=31.8518, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1467 (Recon: 0.1467, KL: 23.7289, Current Beta: 0.0000) | Avg Valid Loss: 0.0677 | Avg Valid recon Loss: 0.0677\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0423, recon=0.0423, kl=31.6726, beta=0.0000\n",
      "Batch 40, loss=0.0692, recon=0.0692, kl=34.6513, beta=0.0000\n",
      "Batch 60, loss=0.0749, recon=0.0749, kl=32.5163, beta=0.0000\n",
      "Batch 80, loss=0.0373, recon=0.0373, kl=36.2378, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0665 (Recon: 0.0665, KL: 33.6518, Current Beta: 0.0000) | Avg Valid Loss: 0.0708 | Avg Valid recon Loss: 0.0708\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1614, recon=0.1614, kl=47.2785, beta=0.0000\n",
      "Batch 40, loss=0.0379, recon=0.0379, kl=37.5382, beta=0.0000\n",
      "Batch 60, loss=0.0562, recon=0.0562, kl=31.6865, beta=0.0000\n",
      "Batch 80, loss=0.0317, recon=0.0317, kl=33.1197, beta=0.0000\n",
      "  â†’ Avg Train Loss: 106.5522 (Recon: 106.5522, KL: 48179.7065, Current Beta: 0.0000) | Avg Valid Loss: 0.0434 | Avg Valid recon Loss: 0.0434\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0522, recon=0.0522, kl=36.4911, beta=0.0000\n",
      "Batch 40, loss=0.0477, recon=0.0477, kl=35.0993, beta=0.0000\n",
      "Batch 60, loss=0.0512, recon=0.0512, kl=35.4569, beta=0.0000\n",
      "Batch 80, loss=0.0559, recon=0.0559, kl=35.6384, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 35.4250, Current Beta: 0.0000) | Avg Valid Loss: 0.0406 | Avg Valid recon Loss: 0.0406\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0260, recon=0.0260, kl=35.8964, beta=0.0000\n",
      "Batch 40, loss=0.0358, recon=0.0358, kl=34.9711, beta=0.0000\n",
      "Batch 60, loss=0.0411, recon=0.0411, kl=32.5846, beta=0.0000\n",
      "Batch 80, loss=0.0304, recon=0.0304, kl=31.4678, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0462, KL: 34.1281, Current Beta: 0.0000) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0384\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0403, recon=0.0403, kl=34.9958, beta=0.0000\n",
      "Batch 40, loss=0.0386, recon=0.0386, kl=34.7238, beta=0.0000\n",
      "Batch 60, loss=0.0330, recon=0.0330, kl=33.5198, beta=0.0000\n",
      "Batch 80, loss=0.0839, recon=0.0839, kl=30.1563, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0416, KL: 33.4519, Current Beta: 0.0000) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0292, recon=0.0292, kl=30.4330, beta=0.0000\n",
      "Batch 40, loss=0.0304, recon=0.0304, kl=30.7947, beta=0.0000\n",
      "Batch 60, loss=0.0296, recon=0.0296, kl=29.5355, beta=0.0000\n",
      "Batch 80, loss=0.0260, recon=0.0260, kl=28.4598, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0420, KL: 30.0739, Current Beta: 0.0000) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0297, recon=0.0297, kl=30.1987, beta=0.0000\n",
      "Batch 40, loss=0.0313, recon=0.0313, kl=30.7955, beta=0.0000\n",
      "Batch 60, loss=0.0351, recon=0.0351, kl=30.9190, beta=0.0000\n",
      "Batch 80, loss=0.0453, recon=0.0452, kl=31.6290, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0382, KL: 30.4814, Current Beta: 0.0000) | Avg Valid Loss: 0.0316 | Avg Valid recon Loss: 0.0316\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0311, recon=0.0311, kl=32.6052, beta=0.0000\n",
      "Batch 40, loss=0.0784, recon=0.0784, kl=29.8463, beta=0.0000\n",
      "Batch 60, loss=0.0281, recon=0.0281, kl=27.6983, beta=0.0000\n",
      "Batch 80, loss=0.0265, recon=0.0265, kl=27.2885, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0350 (Recon: 0.0350, KL: 29.5588, Current Beta: 0.0000) | Avg Valid Loss: 0.0328 | Avg Valid recon Loss: 0.0328\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0309, recon=0.0309, kl=25.1612, beta=0.0000\n",
      "Batch 40, loss=0.0257, recon=0.0257, kl=23.3974, beta=0.0000\n",
      "Batch 60, loss=0.0366, recon=0.0366, kl=21.9589, beta=0.0000\n",
      "Batch 80, loss=0.0266, recon=0.0265, kl=21.2988, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0344 (Recon: 0.0344, KL: 23.3963, Current Beta: 0.0000) | Avg Valid Loss: 0.0306 | Avg Valid recon Loss: 0.0306\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0469, recon=0.0469, kl=19.3333, beta=0.0000\n",
      "Batch 40, loss=0.0383, recon=0.0382, kl=18.1096, beta=0.0000\n",
      "Batch 60, loss=0.0242, recon=0.0241, kl=16.9365, beta=0.0000\n",
      "Batch 80, loss=0.0247, recon=0.0247, kl=16.6928, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0334 (Recon: 0.0333, KL: 18.1834, Current Beta: 0.0000) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0304\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0280, recon=0.0279, kl=12.2502, beta=0.0000\n",
      "Batch 40, loss=0.0275, recon=0.0274, kl=10.0647, beta=0.0000\n",
      "Batch 60, loss=0.1776, recon=0.1775, kl=10.3846, beta=0.0000\n",
      "Batch 80, loss=0.0364, recon=0.0363, kl=11.4153, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0329 (Recon: 0.0328, KL: 11.6450, Current Beta: 0.0000) | Avg Valid Loss: 0.0301 | Avg Valid recon Loss: 0.0300\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0222, recon=0.0221, kl=6.6164, beta=0.0000\n",
      "Batch 40, loss=0.0313, recon=0.0312, kl=5.0687, beta=0.0000\n",
      "Batch 60, loss=0.0229, recon=0.0228, kl=6.3152, beta=0.0000\n",
      "Batch 80, loss=0.0224, recon=0.0223, kl=4.9415, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0315 (Recon: 0.0313, KL: 6.4281, Current Beta: 0.0000) | Avg Valid Loss: 0.0290 | Avg Valid recon Loss: 0.0289\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0265, recon=0.0264, kl=3.4574, beta=0.0000\n",
      "Batch 40, loss=0.0194, recon=0.0193, kl=2.7351, beta=0.0000\n",
      "Batch 60, loss=0.0245, recon=0.0244, kl=2.3267, beta=0.0000\n",
      "Batch 80, loss=0.0317, recon=0.0316, kl=3.1225, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0315 (Recon: 0.0314, KL: 3.1331, Current Beta: 0.0000) | Avg Valid Loss: 0.0287 | Avg Valid recon Loss: 0.0286\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0209, recon=0.0208, kl=1.2114, beta=0.0001\n",
      "Batch 40, loss=0.0241, recon=0.0240, kl=1.6020, beta=0.0001\n",
      "Batch 60, loss=0.0277, recon=0.0276, kl=1.4016, beta=0.0001\n",
      "Batch 80, loss=0.0216, recon=0.0216, kl=0.5535, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0304 (Recon: 0.0303, KL: 1.3623, Current Beta: 0.0001) | Avg Valid Loss: 0.0259 | Avg Valid recon Loss: 0.0259\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0215, recon=0.0215, kl=0.3054, beta=0.0001\n",
      "Batch 40, loss=0.0218, recon=0.0218, kl=0.3995, beta=0.0001\n",
      "Batch 60, loss=0.0210, recon=0.0209, kl=0.2994, beta=0.0001\n",
      "Batch 80, loss=0.0172, recon=0.0171, kl=0.2525, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0282 (Recon: 0.0282, KL: 0.3380, Current Beta: 0.0001) | Avg Valid Loss: 0.0260 | Avg Valid recon Loss: 0.0260\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0286, recon=0.0286, kl=0.2559, beta=0.0001\n",
      "Batch 40, loss=0.0214, recon=0.0214, kl=0.2371, beta=0.0001\n",
      "Batch 60, loss=0.0297, recon=0.0297, kl=0.2025, beta=0.0001\n",
      "Batch 80, loss=0.0351, recon=0.0351, kl=0.1931, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0284 (Recon: 0.0284, KL: 0.2736, Current Beta: 0.0001) | Avg Valid Loss: 0.0282 | Avg Valid recon Loss: 0.0282\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0285, recon=0.0285, kl=0.1639, beta=0.0001\n",
      "Batch 40, loss=0.0185, recon=0.0185, kl=0.2251, beta=0.0001\n",
      "Batch 60, loss=0.0355, recon=0.0355, kl=0.2064, beta=0.0001\n",
      "Batch 80, loss=0.0333, recon=0.0333, kl=0.3117, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0332 (Recon: 0.0332, KL: 0.2186, Current Beta: 0.0001) | Avg Valid Loss: 0.0279 | Avg Valid recon Loss: 0.0279\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0217, recon=0.0216, kl=0.8292, beta=0.0001\n",
      "Batch 40, loss=0.0257, recon=0.0257, kl=0.2867, beta=0.0001\n",
      "Batch 60, loss=0.0200, recon=0.0200, kl=0.1333, beta=0.0001\n",
      "Batch 80, loss=0.0200, recon=0.0200, kl=0.1002, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0297 (Recon: 0.0297, KL: 0.3205, Current Beta: 0.0001) | Avg Valid Loss: 0.0295 | Avg Valid recon Loss: 0.0295\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0222, recon=0.0222, kl=0.2896, beta=0.0001\n",
      "Batch 40, loss=0.0180, recon=0.0180, kl=0.1884, beta=0.0001\n",
      "Batch 60, loss=0.0275, recon=0.0275, kl=0.1508, beta=0.0001\n",
      "Batch 80, loss=0.0354, recon=0.0354, kl=0.1606, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0309 (Recon: 0.0309, KL: 0.2527, Current Beta: 0.0001) | Avg Valid Loss: 0.0295 | Avg Valid recon Loss: 0.0295\n",
      "\n",
      "[VRAE Run 123/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3244, recon=0.3244, kl=1.1077, beta=0.0000\n",
      "Batch 40, loss=0.1914, recon=0.1914, kl=30.6659, beta=0.0000\n",
      "Batch 60, loss=0.1330, recon=0.1330, kl=45.7108, beta=0.0000\n",
      "Batch 80, loss=1.1154, recon=1.1154, kl=54.0734, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2813 (Recon: 0.2813, KL: 29.5434, Current Beta: 0.0000) | Avg Valid Loss: 0.1217 | Avg Valid recon Loss: 0.1217\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1017, recon=0.1017, kl=61.1543, beta=0.0000\n",
      "Batch 40, loss=0.1178, recon=0.1178, kl=69.5381, beta=0.0000\n",
      "Batch 60, loss=0.1768, recon=0.1768, kl=78.5740, beta=0.0000\n",
      "Batch 80, loss=0.0850, recon=0.0850, kl=88.9064, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1389 (Recon: 0.1389, KL: 72.6884, Current Beta: 0.0000) | Avg Valid Loss: 0.0895 | Avg Valid recon Loss: 0.0895\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0892, recon=0.0892, kl=82.4495, beta=0.0000\n",
      "Batch 40, loss=0.0931, recon=0.0931, kl=79.9171, beta=0.0000\n",
      "Batch 60, loss=0.1019, recon=0.1019, kl=84.1212, beta=0.0000\n",
      "Batch 80, loss=0.1021, recon=0.1021, kl=90.1592, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1104 (Recon: 0.1104, KL: 84.8802, Current Beta: 0.0000) | Avg Valid Loss: 0.0765 | Avg Valid recon Loss: 0.0765\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0791, recon=0.0791, kl=83.7829, beta=0.0000\n",
      "Batch 40, loss=0.0979, recon=0.0979, kl=88.6455, beta=0.0000\n",
      "Batch 60, loss=0.0614, recon=0.0614, kl=84.7689, beta=0.0000\n",
      "Batch 80, loss=0.0801, recon=0.0801, kl=91.2069, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0916 (Recon: 0.0916, KL: 87.7417, Current Beta: 0.0000) | Avg Valid Loss: 0.0660 | Avg Valid recon Loss: 0.0660\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0588, recon=0.0588, kl=93.2737, beta=0.0000\n",
      "Batch 40, loss=0.0590, recon=0.0590, kl=91.3018, beta=0.0000\n",
      "Batch 60, loss=0.0447, recon=0.0447, kl=86.3684, beta=0.0000\n",
      "Batch 80, loss=0.0564, recon=0.0564, kl=86.8549, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0794 (Recon: 0.0794, KL: 89.9091, Current Beta: 0.0000) | Avg Valid Loss: 0.0614 | Avg Valid recon Loss: 0.0614\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0633, recon=0.0633, kl=83.9585, beta=0.0000\n",
      "Batch 40, loss=0.2003, recon=0.2003, kl=83.0160, beta=0.0000\n",
      "Batch 60, loss=0.0480, recon=0.0480, kl=84.9397, beta=0.0000\n",
      "Batch 80, loss=0.0772, recon=0.0772, kl=81.6259, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0717 (Recon: 0.0717, KL: 82.9347, Current Beta: 0.0000) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0566\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0573, recon=0.0573, kl=79.4081, beta=0.0000\n",
      "Batch 40, loss=0.0961, recon=0.0961, kl=77.9811, beta=0.0000\n",
      "Batch 60, loss=0.1346, recon=0.1346, kl=76.5359, beta=0.0000\n",
      "Batch 80, loss=0.0682, recon=0.0682, kl=71.9506, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0651 (Recon: 0.0651, KL: 77.1767, Current Beta: 0.0000) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0537\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0602, recon=0.0602, kl=67.1648, beta=0.0000\n",
      "Batch 40, loss=0.0361, recon=0.0360, kl=66.0487, beta=0.0000\n",
      "Batch 60, loss=0.0496, recon=0.0496, kl=58.9088, beta=0.0000\n",
      "Batch 80, loss=0.0388, recon=0.0388, kl=55.1178, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0612 (Recon: 0.0612, KL: 62.8963, Current Beta: 0.0000) | Avg Valid Loss: 0.0518 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0529, recon=0.0529, kl=46.3795, beta=0.0000\n",
      "Batch 40, loss=0.0372, recon=0.0372, kl=38.5648, beta=0.0000\n",
      "Batch 60, loss=0.0477, recon=0.0477, kl=38.4603, beta=0.0000\n",
      "Batch 80, loss=0.0342, recon=0.0342, kl=37.2759, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0575 (Recon: 0.0575, KL: 41.4850, Current Beta: 0.0000) | Avg Valid Loss: 0.0484 | Avg Valid recon Loss: 0.0484\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0451, recon=0.0450, kl=26.1416, beta=0.0000\n",
      "Batch 40, loss=0.0281, recon=0.0280, kl=19.7370, beta=0.0000\n",
      "Batch 60, loss=0.0425, recon=0.0425, kl=23.3929, beta=0.0000\n",
      "Batch 80, loss=0.0913, recon=0.0913, kl=21.6561, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0547, KL: 24.3851, Current Beta: 0.0000) | Avg Valid Loss: 0.0481 | Avg Valid recon Loss: 0.0481\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0420, recon=0.0419, kl=11.9422, beta=0.0000\n",
      "Batch 40, loss=0.0491, recon=0.0491, kl=11.0983, beta=0.0000\n",
      "Batch 60, loss=0.0774, recon=0.0773, kl=11.7108, beta=0.0000\n",
      "Batch 80, loss=0.0415, recon=0.0415, kl=9.6584, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0523, KL: 11.9594, Current Beta: 0.0000) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0434, recon=0.0433, kl=4.2042, beta=0.0000\n",
      "Batch 40, loss=0.0431, recon=0.0431, kl=4.6832, beta=0.0000\n",
      "Batch 60, loss=0.0374, recon=0.0374, kl=4.6149, beta=0.0000\n",
      "Batch 80, loss=0.0468, recon=0.0467, kl=4.7148, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0499 (Recon: 0.0498, KL: 4.9094, Current Beta: 0.0000) | Avg Valid Loss: 0.0443 | Avg Valid recon Loss: 0.0443\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0479, recon=0.0478, kl=2.1290, beta=0.0000\n",
      "Batch 40, loss=0.0358, recon=0.0358, kl=2.1149, beta=0.0000\n",
      "Batch 60, loss=0.0297, recon=0.0297, kl=1.7511, beta=0.0000\n",
      "Batch 80, loss=0.0297, recon=0.0296, kl=1.7517, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 1.9308, Current Beta: 0.0000) | Avg Valid Loss: 0.0418 | Avg Valid recon Loss: 0.0418\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.3663, recon=0.3663, kl=0.7247, beta=0.0000\n",
      "Batch 40, loss=0.0362, recon=0.0361, kl=0.4740, beta=0.0000\n",
      "Batch 60, loss=0.0435, recon=0.0434, kl=0.5668, beta=0.0000\n",
      "Batch 80, loss=0.0382, recon=0.0381, kl=0.5556, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0469, KL: 0.6301, Current Beta: 0.0000) | Avg Valid Loss: 0.0406 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0324, recon=0.0324, kl=0.1575, beta=0.0001\n",
      "Batch 40, loss=0.0319, recon=0.0319, kl=0.1010, beta=0.0001\n",
      "Batch 60, loss=0.0332, recon=0.0332, kl=0.1179, beta=0.0001\n",
      "Batch 80, loss=0.0496, recon=0.0496, kl=0.0727, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0453 (Recon: 0.0453, KL: 0.1487, Current Beta: 0.0001) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0250, recon=0.0250, kl=0.0274, beta=0.0001\n",
      "Batch 40, loss=0.0281, recon=0.0281, kl=0.0351, beta=0.0001\n",
      "Batch 60, loss=0.0321, recon=0.0321, kl=0.0203, beta=0.0001\n",
      "Batch 80, loss=0.0336, recon=0.0336, kl=0.0151, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 0.0268, Current Beta: 0.0001) | Avg Valid Loss: 0.0393 | Avg Valid recon Loss: 0.0393\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0382, recon=0.0382, kl=0.0226, beta=0.0001\n",
      "Batch 40, loss=0.0294, recon=0.0294, kl=0.0131, beta=0.0001\n",
      "Batch 60, loss=0.0431, recon=0.0431, kl=0.0130, beta=0.0001\n",
      "Batch 80, loss=0.0724, recon=0.0724, kl=0.0184, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0431, KL: 0.0172, Current Beta: 0.0001) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1011, recon=0.1011, kl=0.0129, beta=0.0001\n",
      "Batch 40, loss=0.0303, recon=0.0303, kl=0.0135, beta=0.0001\n",
      "Batch 60, loss=0.0412, recon=0.0412, kl=0.0082, beta=0.0001\n",
      "Batch 80, loss=0.0400, recon=0.0400, kl=0.0098, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0415, KL: 0.0143, Current Beta: 0.0001) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0274, recon=0.0274, kl=0.0094, beta=0.0001\n",
      "Batch 40, loss=0.0300, recon=0.0300, kl=0.0128, beta=0.0001\n",
      "Batch 60, loss=0.0349, recon=0.0349, kl=0.0149, beta=0.0001\n",
      "Batch 80, loss=0.0275, recon=0.0275, kl=0.0115, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0413 (Recon: 0.0413, KL: 0.0141, Current Beta: 0.0001) | Avg Valid Loss: 0.0365 | Avg Valid recon Loss: 0.0365\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0298, recon=0.0298, kl=0.0085, beta=0.0001\n",
      "Batch 40, loss=0.0569, recon=0.0569, kl=0.0101, beta=0.0001\n",
      "Batch 60, loss=0.0516, recon=0.0516, kl=0.0097, beta=0.0001\n",
      "Batch 80, loss=0.0267, recon=0.0267, kl=0.0095, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0405, KL: 0.0108, Current Beta: 0.0001) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0358\n",
      "\n",
      "[VRAE Run 124/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1271, recon=0.1271, kl=35.6712, beta=0.0000\n",
      "Batch 40, loss=0.0842, recon=0.0842, kl=58.3609, beta=0.0000\n",
      "Batch 60, loss=0.0602, recon=0.0602, kl=69.3436, beta=0.0000\n",
      "Batch 80, loss=0.0627, recon=0.0627, kl=68.1554, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1503 (Recon: 0.1503, KL: 53.1414, Current Beta: 0.0000) | Avg Valid Loss: 0.0668 | Avg Valid recon Loss: 0.0668\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0511, recon=0.0511, kl=67.9028, beta=0.0000\n",
      "Batch 40, loss=0.0690, recon=0.0690, kl=60.8097, beta=0.0000\n",
      "Batch 60, loss=0.0641, recon=0.0641, kl=64.6830, beta=0.0000\n",
      "Batch 80, loss=0.0468, recon=0.0468, kl=66.8406, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0652 (Recon: 0.0652, KL: 65.2651, Current Beta: 0.0000) | Avg Valid Loss: 0.0551 | Avg Valid recon Loss: 0.0551\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0463, recon=0.0463, kl=58.3757, beta=0.0000\n",
      "Batch 40, loss=0.0378, recon=0.0378, kl=61.7953, beta=0.0000\n",
      "Batch 60, loss=0.0355, recon=0.0355, kl=65.9192, beta=0.0000\n",
      "Batch 80, loss=0.0445, recon=0.0445, kl=72.6708, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 65.1097, Current Beta: 0.0000) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0337, recon=0.0337, kl=70.3108, beta=0.0000\n",
      "Batch 40, loss=0.0330, recon=0.0330, kl=70.0173, beta=0.0000\n",
      "Batch 60, loss=0.0418, recon=0.0418, kl=70.0604, beta=0.0000\n",
      "Batch 80, loss=0.0383, recon=0.0383, kl=68.1514, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0507 (Recon: 0.0507, KL: 69.6037, Current Beta: 0.0000) | Avg Valid Loss: 0.0446 | Avg Valid recon Loss: 0.0446\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=69.4943, beta=0.0000\n",
      "Batch 40, loss=0.0409, recon=0.0409, kl=72.1199, beta=0.0000\n",
      "Batch 60, loss=0.0293, recon=0.0293, kl=68.3799, beta=0.0000\n",
      "Batch 80, loss=0.1135, recon=0.1135, kl=69.1861, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0440, KL: 69.5108, Current Beta: 0.0000) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0635, recon=0.0635, kl=70.6714, beta=0.0000\n",
      "Batch 40, loss=0.0301, recon=0.0301, kl=73.3139, beta=0.0000\n",
      "Batch 60, loss=0.0928, recon=0.0928, kl=63.7126, beta=0.0000\n",
      "Batch 80, loss=0.0694, recon=0.0694, kl=63.3131, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0435 (Recon: 0.0435, KL: 67.4292, Current Beta: 0.0000) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0373, recon=0.0373, kl=69.6336, beta=0.0000\n",
      "Batch 40, loss=0.0268, recon=0.0268, kl=68.2059, beta=0.0000\n",
      "Batch 60, loss=0.0561, recon=0.0561, kl=63.2756, beta=0.0000\n",
      "Batch 80, loss=0.0739, recon=0.0739, kl=64.0891, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0401 (Recon: 0.0401, KL: 66.3863, Current Beta: 0.0000) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0450, recon=0.0450, kl=63.3193, beta=0.0000\n",
      "Batch 40, loss=0.0314, recon=0.0314, kl=64.8255, beta=0.0000\n",
      "Batch 60, loss=0.0657, recon=0.0657, kl=64.8736, beta=0.0000\n",
      "Batch 80, loss=0.0397, recon=0.0397, kl=64.4665, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0381, KL: 64.3799, Current Beta: 0.0000) | Avg Valid Loss: 0.0344 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.2257, recon=0.2257, kl=53.3777, beta=0.0000\n",
      "Batch 40, loss=0.0381, recon=0.0381, kl=48.2893, beta=0.0000\n",
      "Batch 60, loss=0.0245, recon=0.0245, kl=51.8192, beta=0.0000\n",
      "Batch 80, loss=0.0219, recon=0.0219, kl=53.5387, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0370, KL: 52.9208, Current Beta: 0.0000) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0332\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0258, recon=0.0257, kl=44.5064, beta=0.0000\n",
      "Batch 40, loss=0.0452, recon=0.0452, kl=41.0897, beta=0.0000\n",
      "Batch 60, loss=0.0666, recon=0.0665, kl=41.3730, beta=0.0000\n",
      "Batch 80, loss=0.0369, recon=0.0369, kl=40.6632, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0359 (Recon: 0.0358, KL: 42.5659, Current Beta: 0.0000) | Avg Valid Loss: 0.0324 | Avg Valid recon Loss: 0.0324\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0265, recon=0.0264, kl=31.6691, beta=0.0000\n",
      "Batch 40, loss=0.0251, recon=0.0250, kl=30.2778, beta=0.0000\n",
      "Batch 60, loss=0.1767, recon=0.1766, kl=29.1522, beta=0.0000\n",
      "Batch 80, loss=0.0368, recon=0.0367, kl=30.5645, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0353 (Recon: 0.0352, KL: 31.4237, Current Beta: 0.0000) | Avg Valid Loss: 0.0325 | Avg Valid recon Loss: 0.0324\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0261, recon=0.0259, kl=20.2360, beta=0.0000\n",
      "Batch 40, loss=0.0513, recon=0.0512, kl=18.2141, beta=0.0000\n",
      "Batch 60, loss=0.0256, recon=0.0255, kl=14.5819, beta=0.0000\n",
      "Batch 80, loss=0.0435, recon=0.0434, kl=15.9570, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0348 (Recon: 0.0347, KL: 18.9036, Current Beta: 0.0000) | Avg Valid Loss: 0.0323 | Avg Valid recon Loss: 0.0322\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0262, recon=0.0260, kl=8.7246, beta=0.0000\n",
      "Batch 40, loss=0.0254, recon=0.0252, kl=10.1507, beta=0.0000\n",
      "Batch 60, loss=0.0263, recon=0.0262, kl=7.0414, beta=0.0000\n",
      "Batch 80, loss=0.0360, recon=0.0359, kl=6.4970, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0341 (Recon: 0.0340, KL: 9.3999, Current Beta: 0.0000) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0730, recon=0.0728, kl=5.7184, beta=0.0000\n",
      "Batch 40, loss=0.0200, recon=0.0199, kl=4.1083, beta=0.0000\n",
      "Batch 60, loss=0.0494, recon=0.0493, kl=3.1240, beta=0.0000\n",
      "Batch 80, loss=0.0215, recon=0.0214, kl=2.1120, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0328 (Recon: 0.0327, KL: 3.9303, Current Beta: 0.0000) | Avg Valid Loss: 0.0292 | Avg Valid recon Loss: 0.0291\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0239, recon=0.0238, kl=2.2221, beta=0.0001\n",
      "Batch 40, loss=0.0206, recon=0.0205, kl=1.2873, beta=0.0001\n",
      "Batch 60, loss=0.0265, recon=0.0264, kl=2.2546, beta=0.0001\n",
      "Batch 80, loss=0.0495, recon=0.0494, kl=2.0624, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0317 (Recon: 0.0316, KL: 1.8095, Current Beta: 0.0001) | Avg Valid Loss: 0.0293 | Avg Valid recon Loss: 0.0292\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0442, recon=0.0442, kl=0.4926, beta=0.0001\n",
      "Batch 40, loss=0.0231, recon=0.0231, kl=0.6146, beta=0.0001\n",
      "Batch 60, loss=0.0179, recon=0.0178, kl=0.3476, beta=0.0001\n",
      "Batch 80, loss=0.0269, recon=0.0269, kl=0.1850, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0321 (Recon: 0.0321, KL: 0.5100, Current Beta: 0.0001) | Avg Valid Loss: 0.0302 | Avg Valid recon Loss: 0.0302\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0305, recon=0.0305, kl=0.1971, beta=0.0001\n",
      "Batch 40, loss=0.0418, recon=0.0418, kl=0.2204, beta=0.0001\n",
      "Batch 60, loss=0.0303, recon=0.0303, kl=0.2198, beta=0.0001\n",
      "Batch 80, loss=0.0329, recon=0.0328, kl=0.1642, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0308 (Recon: 0.0307, KL: 0.1935, Current Beta: 0.0001) | Avg Valid Loss: 0.0276 | Avg Valid recon Loss: 0.0276\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0268, recon=0.0268, kl=0.1691, beta=0.0001\n",
      "Batch 40, loss=0.0243, recon=0.0243, kl=0.1903, beta=0.0001\n",
      "Batch 60, loss=0.0280, recon=0.0279, kl=0.3481, beta=0.0001\n",
      "Batch 80, loss=0.0231, recon=0.0231, kl=0.2462, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0297 (Recon: 0.0297, KL: 0.2234, Current Beta: 0.0001) | Avg Valid Loss: 0.0271 | Avg Valid recon Loss: 0.0271\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0811, recon=0.0811, kl=0.4516, beta=0.0001\n",
      "Batch 40, loss=0.0708, recon=0.0707, kl=0.2482, beta=0.0001\n",
      "Batch 60, loss=0.0248, recon=0.0248, kl=0.1251, beta=0.0001\n",
      "Batch 80, loss=0.0217, recon=0.0217, kl=0.1456, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0291 (Recon: 0.0291, KL: 0.2368, Current Beta: 0.0001) | Avg Valid Loss: 0.0257 | Avg Valid recon Loss: 0.0257\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0281, recon=0.0281, kl=0.1713, beta=0.0001\n",
      "Batch 40, loss=0.0255, recon=0.0255, kl=0.0905, beta=0.0001\n",
      "Batch 60, loss=0.0502, recon=0.0502, kl=0.0669, beta=0.0001\n",
      "Batch 80, loss=0.0313, recon=0.0313, kl=0.1093, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0306 (Recon: 0.0306, KL: 0.1225, Current Beta: 0.0001) | Avg Valid Loss: 0.0311 | Avg Valid recon Loss: 0.0310\n",
      "\n",
      "[VRAE Run 125/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2616, recon=0.2616, kl=1.1805, beta=0.0000\n",
      "Batch 40, loss=0.2373, recon=0.2373, kl=60.6353, beta=0.0000\n",
      "Batch 60, loss=0.1967, recon=0.1967, kl=102.9530, beta=0.0000\n",
      "Batch 80, loss=0.1261, recon=0.1261, kl=119.1078, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2974 (Recon: 0.2974, KL: 63.7624, Current Beta: 0.0000) | Avg Valid Loss: 0.1285 | Avg Valid recon Loss: 0.1285\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0993, recon=0.0993, kl=125.8593, beta=0.0000\n",
      "Batch 40, loss=0.1722, recon=0.1722, kl=134.1341, beta=0.0000\n",
      "Batch 60, loss=0.3818, recon=0.3818, kl=144.2728, beta=0.0000\n",
      "Batch 80, loss=0.0937, recon=0.0937, kl=150.6219, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1440 (Recon: 0.1440, KL: 137.2134, Current Beta: 0.0000) | Avg Valid Loss: 0.0947 | Avg Valid recon Loss: 0.0947\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1099, recon=0.1099, kl=162.0563, beta=0.0000\n",
      "Batch 40, loss=0.1147, recon=0.1147, kl=160.4805, beta=0.0000\n",
      "Batch 60, loss=0.0897, recon=0.0897, kl=156.7241, beta=0.0000\n",
      "Batch 80, loss=0.0685, recon=0.0685, kl=155.7554, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1147 (Recon: 0.1147, KL: 158.3944, Current Beta: 0.0000) | Avg Valid Loss: 0.0789 | Avg Valid recon Loss: 0.0789\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0645, recon=0.0645, kl=165.6311, beta=0.0000\n",
      "Batch 40, loss=0.8661, recon=0.8661, kl=167.6774, beta=0.0000\n",
      "Batch 60, loss=0.0720, recon=0.0720, kl=163.4924, beta=0.0000\n",
      "Batch 80, loss=0.0547, recon=0.0547, kl=160.4219, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0951 (Recon: 0.0951, KL: 163.9973, Current Beta: 0.0000) | Avg Valid Loss: 0.0692 | Avg Valid recon Loss: 0.0692\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0743, recon=0.0743, kl=170.9396, beta=0.0000\n",
      "Batch 40, loss=0.0833, recon=0.0833, kl=170.6721, beta=0.0000\n",
      "Batch 60, loss=0.0749, recon=0.0749, kl=162.6378, beta=0.0000\n",
      "Batch 80, loss=0.0518, recon=0.0518, kl=162.2384, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0822 (Recon: 0.0822, KL: 165.8795, Current Beta: 0.0000) | Avg Valid Loss: 0.0633 | Avg Valid recon Loss: 0.0633\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0586, recon=0.0586, kl=162.3580, beta=0.0000\n",
      "Batch 40, loss=0.0603, recon=0.0603, kl=163.5234, beta=0.0000\n",
      "Batch 60, loss=0.1820, recon=0.1820, kl=161.2068, beta=0.0000\n",
      "Batch 80, loss=0.0561, recon=0.0561, kl=160.7088, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0737 (Recon: 0.0737, KL: 161.8810, Current Beta: 0.0000) | Avg Valid Loss: 0.0596 | Avg Valid recon Loss: 0.0596\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1557, recon=0.1557, kl=151.2343, beta=0.0000\n",
      "Batch 40, loss=0.0526, recon=0.0526, kl=142.7074, beta=0.0000\n",
      "Batch 60, loss=0.0372, recon=0.0372, kl=145.6300, beta=0.0000\n",
      "Batch 80, loss=0.0448, recon=0.0448, kl=142.4540, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0670 (Recon: 0.0670, KL: 146.8577, Current Beta: 0.0000) | Avg Valid Loss: 0.0556 | Avg Valid recon Loss: 0.0556\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0508, recon=0.0508, kl=122.6589, beta=0.0000\n",
      "Batch 40, loss=0.0929, recon=0.0929, kl=110.5282, beta=0.0000\n",
      "Batch 60, loss=0.0420, recon=0.0420, kl=107.0619, beta=0.0000\n",
      "Batch 80, loss=0.0463, recon=0.0463, kl=102.5883, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0626 (Recon: 0.0626, KL: 112.7773, Current Beta: 0.0000) | Avg Valid Loss: 0.0532 | Avg Valid recon Loss: 0.0532\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0432, recon=0.0431, kl=79.2740, beta=0.0000\n",
      "Batch 40, loss=0.0561, recon=0.0560, kl=68.0942, beta=0.0000\n",
      "Batch 60, loss=0.0376, recon=0.0375, kl=62.8522, beta=0.0000\n",
      "Batch 80, loss=0.0375, recon=0.0375, kl=65.3771, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0590 (Recon: 0.0590, KL: 71.3833, Current Beta: 0.0000) | Avg Valid Loss: 0.0516 | Avg Valid recon Loss: 0.0516\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0493, recon=0.0492, kl=39.6443, beta=0.0000\n",
      "Batch 40, loss=0.0348, recon=0.0348, kl=31.0801, beta=0.0000\n",
      "Batch 60, loss=0.0570, recon=0.0570, kl=34.6967, beta=0.0000\n",
      "Batch 80, loss=0.0361, recon=0.0361, kl=29.0827, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0556 (Recon: 0.0556, KL: 37.2187, Current Beta: 0.0000) | Avg Valid Loss: 0.0487 | Avg Valid recon Loss: 0.0487\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0332, recon=0.0332, kl=14.6125, beta=0.0000\n",
      "Batch 40, loss=0.0391, recon=0.0390, kl=12.9677, beta=0.0000\n",
      "Batch 60, loss=0.0466, recon=0.0465, kl=12.5760, beta=0.0000\n",
      "Batch 80, loss=0.0798, recon=0.0798, kl=13.8402, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0530 (Recon: 0.0529, KL: 15.4649, Current Beta: 0.0000) | Avg Valid Loss: 0.0468 | Avg Valid recon Loss: 0.0468\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0378, recon=0.0377, kl=4.9812, beta=0.0000\n",
      "Batch 40, loss=0.0555, recon=0.0554, kl=6.1184, beta=0.0000\n",
      "Batch 60, loss=0.0423, recon=0.0423, kl=4.4089, beta=0.0000\n",
      "Batch 80, loss=0.0322, recon=0.0322, kl=5.1783, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0508, KL: 5.6661, Current Beta: 0.0000) | Avg Valid Loss: 0.0448 | Avg Valid recon Loss: 0.0448\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0369, recon=0.0368, kl=2.2949, beta=0.0000\n",
      "Batch 40, loss=0.0420, recon=0.0420, kl=2.8414, beta=0.0000\n",
      "Batch 60, loss=0.0349, recon=0.0349, kl=1.6423, beta=0.0000\n",
      "Batch 80, loss=0.0259, recon=0.0259, kl=1.9499, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0489 (Recon: 0.0489, KL: 2.2693, Current Beta: 0.0000) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0291, recon=0.0291, kl=0.9160, beta=0.0000\n",
      "Batch 40, loss=0.0409, recon=0.0409, kl=1.2680, beta=0.0000\n",
      "Batch 60, loss=0.0431, recon=0.0430, kl=0.9489, beta=0.0000\n",
      "Batch 80, loss=0.0332, recon=0.0332, kl=0.8886, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0476 (Recon: 0.0476, KL: 1.0129, Current Beta: 0.0000) | Avg Valid Loss: 0.0416 | Avg Valid recon Loss: 0.0416\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0386, recon=0.0386, kl=0.3342, beta=0.0001\n",
      "Batch 40, loss=0.0393, recon=0.0393, kl=0.3515, beta=0.0001\n",
      "Batch 60, loss=0.0376, recon=0.0376, kl=0.3191, beta=0.0001\n",
      "Batch 80, loss=0.0393, recon=0.0393, kl=0.3344, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0462, KL: 0.3789, Current Beta: 0.0001) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0484, recon=0.0484, kl=0.1013, beta=0.0001\n",
      "Batch 40, loss=0.0372, recon=0.0372, kl=0.0737, beta=0.0001\n",
      "Batch 60, loss=0.0269, recon=0.0268, kl=0.0972, beta=0.0001\n",
      "Batch 80, loss=0.0382, recon=0.0381, kl=0.0746, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0450, KL: 0.1100, Current Beta: 0.0001) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0289, recon=0.0289, kl=0.0788, beta=0.0001\n",
      "Batch 40, loss=0.0844, recon=0.0844, kl=0.0554, beta=0.0001\n",
      "Batch 60, loss=0.0333, recon=0.0333, kl=0.0441, beta=0.0001\n",
      "Batch 80, loss=0.0430, recon=0.0430, kl=0.0408, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 0.0563, Current Beta: 0.0001) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0588, recon=0.0588, kl=0.0518, beta=0.0001\n",
      "Batch 40, loss=0.0328, recon=0.0328, kl=0.0342, beta=0.0001\n",
      "Batch 60, loss=0.0346, recon=0.0346, kl=0.0425, beta=0.0001\n",
      "Batch 80, loss=0.0284, recon=0.0284, kl=0.0349, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0427 (Recon: 0.0427, KL: 0.0396, Current Beta: 0.0001) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0287, recon=0.0286, kl=0.0277, beta=0.0001\n",
      "Batch 40, loss=0.0348, recon=0.0348, kl=0.0176, beta=0.0001\n",
      "Batch 60, loss=0.0259, recon=0.0258, kl=0.0187, beta=0.0001\n",
      "Batch 80, loss=0.0569, recon=0.0569, kl=0.0300, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0419, KL: 0.0252, Current Beta: 0.0001) | Avg Valid Loss: 0.0365 | Avg Valid recon Loss: 0.0365\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0549, recon=0.0549, kl=0.0204, beta=0.0001\n",
      "Batch 40, loss=0.0327, recon=0.0327, kl=0.0201, beta=0.0001\n",
      "Batch 60, loss=0.0289, recon=0.0289, kl=0.0183, beta=0.0001\n",
      "Batch 80, loss=0.0876, recon=0.0876, kl=0.0276, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0413 (Recon: 0.0413, KL: 0.0202, Current Beta: 0.0001) | Avg Valid Loss: 0.0359 | Avg Valid recon Loss: 0.0359\n",
      "\n",
      "[VRAE Run 126/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1344, recon=0.1344, kl=81.9590, beta=0.0000\n",
      "Batch 40, loss=0.1125, recon=0.1125, kl=73.6427, beta=0.0000\n",
      "Batch 60, loss=0.1657, recon=0.1657, kl=89.6077, beta=0.0000\n",
      "Batch 80, loss=0.0617, recon=0.0617, kl=116.5437, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1500 (Recon: 0.1500, KL: 80.4095, Current Beta: 0.0000) | Avg Valid Loss: 0.0644 | Avg Valid recon Loss: 0.0644\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.6344, recon=0.6344, kl=101.8070, beta=0.0000\n",
      "Batch 40, loss=0.0427, recon=0.0427, kl=97.5108, beta=0.0000\n",
      "Batch 60, loss=0.0483, recon=0.0483, kl=114.6217, beta=0.0000\n",
      "Batch 80, loss=0.0401, recon=0.0401, kl=134.8893, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0680 (Recon: 0.0680, KL: 112.8692, Current Beta: 0.0000) | Avg Valid Loss: 0.0494 | Avg Valid recon Loss: 0.0494\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0572, recon=0.0572, kl=120.5496, beta=0.0000\n",
      "Batch 40, loss=0.0522, recon=0.0522, kl=96.5154, beta=0.0000\n",
      "Batch 60, loss=0.0401, recon=0.0401, kl=115.4349, beta=0.0000\n",
      "Batch 80, loss=0.0418, recon=0.0418, kl=135.0447, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0571 (Recon: 0.0571, KL: 116.9409, Current Beta: 0.0000) | Avg Valid Loss: 0.0443 | Avg Valid recon Loss: 0.0443\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0324, recon=0.0324, kl=117.0759, beta=0.0000\n",
      "Batch 40, loss=0.0505, recon=0.0505, kl=124.8840, beta=0.0000\n",
      "Batch 60, loss=0.0545, recon=0.0545, kl=238.3882, beta=0.0000\n",
      "Batch 80, loss=0.0355, recon=0.0355, kl=147.5238, beta=0.0000\n",
      "  â†’ Avg Train Loss: 50837842.7656 (Recon: 50837836.9878, KL: 2367312451.8753, Current Beta: 0.0000) | Avg Valid Loss: 0.0500 | Avg Valid recon Loss: 0.0500\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0975, recon=0.0975, kl=282.1457, beta=0.0000\n",
      "Batch 40, loss=0.1125, recon=0.1124, kl=420.1336, beta=0.0000\n",
      "Batch 60, loss=0.0601, recon=0.0601, kl=436.4769, beta=0.0000\n",
      "Batch 80, loss=0.0730, recon=0.0730, kl=436.2728, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5545 (Recon: 0.5545, KL: 378.5968, Current Beta: 0.0000) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0541\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0908, recon=0.0908, kl=437.2290, beta=0.0000\n",
      "Batch 40, loss=0.0579, recon=0.0579, kl=435.7717, beta=0.0000\n",
      "Batch 60, loss=0.0349, recon=0.0349, kl=435.6302, beta=0.0000\n",
      "Batch 80, loss=0.0349, recon=0.0349, kl=437.1941, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0523, KL: 436.0098, Current Beta: 0.0000) | Avg Valid Loss: 0.0475 | Avg Valid recon Loss: 0.0475\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0327, recon=0.0327, kl=438.8704, beta=0.0000\n",
      "Batch 40, loss=0.0441, recon=0.0441, kl=434.6695, beta=0.0000\n",
      "Batch 60, loss=0.0432, recon=0.0431, kl=433.7147, beta=0.0000\n",
      "Batch 80, loss=0.0568, recon=0.0568, kl=440.0831, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0487 (Recon: 0.0487, KL: 436.8379, Current Beta: 0.0000) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0480\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0464, recon=0.0463, kl=437.1467, beta=0.0000\n",
      "Batch 40, loss=0.0411, recon=0.0410, kl=434.7507, beta=0.0000\n",
      "Batch 60, loss=0.0378, recon=0.0377, kl=438.9092, beta=0.0000\n",
      "Batch 80, loss=0.0405, recon=0.0405, kl=435.1874, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0479, KL: 436.0548, Current Beta: 0.0000) | Avg Valid Loss: 0.0397 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0262, recon=0.0260, kl=431.7066, beta=0.0000\n",
      "Batch 40, loss=0.0289, recon=0.0288, kl=429.7982, beta=0.0000\n",
      "Batch 60, loss=0.0277, recon=0.0275, kl=431.8983, beta=0.0000\n",
      "Batch 80, loss=0.0444, recon=0.0442, kl=430.0487, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0436 (Recon: 0.0434, KL: 432.8492, Current Beta: 0.0000) | Avg Valid Loss: 0.0424 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0373, recon=0.0368, kl=425.1061, beta=0.0000\n",
      "Batch 40, loss=0.0462, recon=0.0457, kl=425.6584, beta=0.0000\n",
      "Batch 60, loss=0.0289, recon=0.0285, kl=419.6897, beta=0.0000\n",
      "Batch 80, loss=0.0292, recon=0.0288, kl=413.5342, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0435, KL: 421.5039, Current Beta: 0.0000) | Avg Valid Loss: 0.0385 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0386, recon=0.0374, kl=409.4713, beta=0.0000\n",
      "Batch 40, loss=0.0815, recon=0.0803, kl=400.8878, beta=0.0000\n",
      "Batch 60, loss=0.0453, recon=0.0441, kl=391.5369, beta=0.0000\n",
      "Batch 80, loss=0.0416, recon=0.0405, kl=373.9029, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0407, KL: 393.4774, Current Beta: 0.0000) | Avg Valid Loss: 0.0362 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0374, recon=0.0347, kl=358.0385, beta=0.0000\n",
      "Batch 40, loss=0.0425, recon=0.0399, kl=341.2509, beta=0.0000\n",
      "Batch 60, loss=0.0553, recon=0.0529, kl=319.4364, beta=0.0000\n",
      "Batch 80, loss=0.0286, recon=0.0263, kl=298.2239, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0411 (Recon: 0.0386, KL: 333.7175, Current Beta: 0.0000) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0295, recon=0.0248, kl=259.6044, beta=0.0000\n",
      "Batch 40, loss=0.0422, recon=0.0382, kl=215.1028, beta=0.0000\n",
      "Batch 60, loss=0.0281, recon=0.0249, kl=172.8459, beta=0.0000\n",
      "Batch 80, loss=0.0259, recon=0.0233, kl=141.5205, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0427 (Recon: 0.0389, KL: 208.2855, Current Beta: 0.0000) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0352, recon=0.0312, kl=106.1179, beta=0.0000\n",
      "Batch 40, loss=0.0534, recon=0.0503, kl=81.3649, beta=0.0000\n",
      "Batch 60, loss=0.0221, recon=0.0199, kl=58.7469, beta=0.0000\n",
      "Batch 80, loss=0.0367, recon=0.0349, kl=49.5204, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0402 (Recon: 0.0372, KL: 79.3422, Current Beta: 0.0000) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0334\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0287, recon=0.0267, kl=32.8028, beta=0.0001\n",
      "Batch 40, loss=0.0283, recon=0.0268, kl=24.1295, beta=0.0001\n",
      "Batch 60, loss=0.0307, recon=0.0292, kl=24.2694, beta=0.0001\n",
      "Batch 80, loss=0.0252, recon=0.0238, kl=22.2491, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0393 (Recon: 0.0375, KL: 28.6350, Current Beta: 0.0001) | Avg Valid Loss: 0.0335 | Avg Valid recon Loss: 0.0323\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0252, recon=0.0235, kl=17.2291, beta=0.0001\n",
      "Batch 40, loss=0.0292, recon=0.0277, kl=14.4719, beta=0.0001\n",
      "Batch 60, loss=0.0325, recon=0.0311, kl=14.0338, beta=0.0001\n",
      "Batch 80, loss=0.0345, recon=0.0334, kl=11.0675, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0373 (Recon: 0.0358, KL: 14.7618, Current Beta: 0.0001) | Avg Valid Loss: 0.1116 | Avg Valid recon Loss: 0.1105\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0729, recon=0.0719, kl=10.4807, beta=0.0001\n",
      "Batch 40, loss=0.0287, recon=0.0278, kl=8.9941, beta=0.0001\n",
      "Batch 60, loss=0.0351, recon=0.0340, kl=11.1125, beta=0.0001\n",
      "Batch 80, loss=0.0253, recon=0.0245, kl=7.3031, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0361 (Recon: 0.0351, KL: 9.7644, Current Beta: 0.0001) | Avg Valid Loss: 0.2029 | Avg Valid recon Loss: 0.2020\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0607, recon=0.0599, kl=7.4706, beta=0.0001\n",
      "Batch 40, loss=0.0392, recon=0.0382, kl=9.8335, beta=0.0001\n",
      "Batch 60, loss=0.0504, recon=0.0495, kl=8.8042, beta=0.0001\n",
      "Batch 80, loss=0.0245, recon=0.0238, kl=6.7359, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0348 (Recon: 0.0340, KL: 8.4255, Current Beta: 0.0001) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0321\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0229, recon=0.0222, kl=7.4884, beta=0.0001\n",
      "Batch 40, loss=0.0309, recon=0.0299, kl=9.7598, beta=0.0001\n",
      "Batch 60, loss=0.0195, recon=0.0189, kl=5.7943, beta=0.0001\n",
      "Batch 80, loss=0.0198, recon=0.0185, kl=12.9750, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0344 (Recon: 0.0335, KL: 8.9236, Current Beta: 0.0001) | Avg Valid Loss: 0.1312 | Avg Valid recon Loss: 0.1302\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0315, recon=0.0306, kl=8.7367, beta=0.0001\n",
      "Batch 40, loss=0.0285, recon=0.0279, kl=5.6694, beta=0.0001\n",
      "Batch 60, loss=0.0633, recon=0.0625, kl=7.4566, beta=0.0001\n",
      "Batch 80, loss=0.0351, recon=0.0337, kl=13.5579, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0334 (Recon: 0.0326, KL: 8.5397, Current Beta: 0.0001) | Avg Valid Loss: 0.1142 | Avg Valid recon Loss: 0.1129\n",
      "\n",
      "[VRAE Run 127/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.8949, recon=0.8949, kl=0.4869, beta=0.0000\n",
      "Batch 40, loss=0.6125, recon=0.6125, kl=3.1717, beta=0.0000\n",
      "Batch 60, loss=0.4136, recon=0.4136, kl=9.5345, beta=0.0000\n",
      "Batch 80, loss=0.3156, recon=0.3156, kl=14.9751, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5682 (Recon: 0.5682, KL: 6.2952, Current Beta: 0.0000) | Avg Valid Loss: 0.3639 | Avg Valid recon Loss: 0.3639\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3071, recon=0.3071, kl=19.4584, beta=0.0000\n",
      "Batch 40, loss=0.2644, recon=0.2644, kl=21.4540, beta=0.0000\n",
      "Batch 60, loss=0.2457, recon=0.2457, kl=23.7297, beta=0.0000\n",
      "Batch 80, loss=0.2071, recon=0.2071, kl=24.9587, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2861 (Recon: 0.2861, KL: 21.8706, Current Beta: 0.0000) | Avg Valid Loss: 0.2126 | Avg Valid recon Loss: 0.2126\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1872, recon=0.1872, kl=27.5437, beta=0.0000\n",
      "Batch 40, loss=0.1315, recon=0.1315, kl=28.5788, beta=0.0000\n",
      "Batch 60, loss=0.2089, recon=0.2089, kl=30.0032, beta=0.0000\n",
      "Batch 80, loss=0.1024, recon=0.1024, kl=31.3073, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2025 (Recon: 0.2025, KL: 29.1760, Current Beta: 0.0000) | Avg Valid Loss: 0.1601 | Avg Valid recon Loss: 0.1601\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1270, recon=0.1270, kl=34.0550, beta=0.0000\n",
      "Batch 40, loss=0.1318, recon=0.1318, kl=35.7330, beta=0.0000\n",
      "Batch 60, loss=0.0982, recon=0.0982, kl=36.4361, beta=0.0000\n",
      "Batch 80, loss=0.1195, recon=0.1195, kl=38.2502, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1602 (Recon: 0.1602, KL: 35.8027, Current Beta: 0.0000) | Avg Valid Loss: 0.1334 | Avg Valid recon Loss: 0.1334\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1007, recon=0.1007, kl=40.3032, beta=0.0000\n",
      "Batch 40, loss=0.1129, recon=0.1129, kl=40.8630, beta=0.0000\n",
      "Batch 60, loss=0.0960, recon=0.0960, kl=40.9219, beta=0.0000\n",
      "Batch 80, loss=0.0849, recon=0.0849, kl=41.0969, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1375 (Recon: 0.1375, KL: 40.6508, Current Beta: 0.0000) | Avg Valid Loss: 0.1164 | Avg Valid recon Loss: 0.1164\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0875, recon=0.0875, kl=42.2048, beta=0.0000\n",
      "Batch 40, loss=0.2726, recon=0.2726, kl=41.7169, beta=0.0000\n",
      "Batch 60, loss=0.0884, recon=0.0884, kl=42.0344, beta=0.0000\n",
      "Batch 80, loss=0.1152, recon=0.1152, kl=42.5129, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1216 (Recon: 0.1216, KL: 42.0039, Current Beta: 0.0000) | Avg Valid Loss: 0.1058 | Avg Valid recon Loss: 0.1058\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1359, recon=0.1359, kl=42.0931, beta=0.0000\n",
      "Batch 40, loss=0.0804, recon=0.0804, kl=42.5650, beta=0.0000\n",
      "Batch 60, loss=0.0938, recon=0.0938, kl=42.9196, beta=0.0000\n",
      "Batch 80, loss=0.1089, recon=0.1089, kl=43.4079, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1101 (Recon: 0.1101, KL: 42.7346, Current Beta: 0.0000) | Avg Valid Loss: 0.0976 | Avg Valid recon Loss: 0.0976\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0822, recon=0.0822, kl=43.5932, beta=0.0000\n",
      "Batch 40, loss=0.0859, recon=0.0858, kl=43.1239, beta=0.0000\n",
      "Batch 60, loss=0.0801, recon=0.0801, kl=42.4885, beta=0.0000\n",
      "Batch 80, loss=0.1209, recon=0.1209, kl=42.4365, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1011 (Recon: 0.1010, KL: 43.0172, Current Beta: 0.0000) | Avg Valid Loss: 0.0914 | Avg Valid recon Loss: 0.0914\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1407, recon=0.1407, kl=41.0305, beta=0.0000\n",
      "Batch 40, loss=0.0738, recon=0.0738, kl=41.0474, beta=0.0000\n",
      "Batch 60, loss=0.0770, recon=0.0770, kl=39.6247, beta=0.0000\n",
      "Batch 80, loss=0.1221, recon=0.1221, kl=38.1714, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0945 (Recon: 0.0945, KL: 40.2711, Current Beta: 0.0000) | Avg Valid Loss: 0.0852 | Avg Valid recon Loss: 0.0852\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0988, recon=0.0987, kl=33.0011, beta=0.0000\n",
      "Batch 40, loss=0.0547, recon=0.0547, kl=30.4434, beta=0.0000\n",
      "Batch 60, loss=0.0787, recon=0.0787, kl=27.7709, beta=0.0000\n",
      "Batch 80, loss=0.0821, recon=0.0821, kl=26.5909, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0890 (Recon: 0.0890, KL: 30.2283, Current Beta: 0.0000) | Avg Valid Loss: 0.0815 | Avg Valid recon Loss: 0.0815\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0994, recon=0.0993, kl=19.9961, beta=0.0000\n",
      "Batch 40, loss=0.0702, recon=0.0702, kl=16.3781, beta=0.0000\n",
      "Batch 60, loss=0.1977, recon=0.1976, kl=15.5332, beta=0.0000\n",
      "Batch 80, loss=0.0642, recon=0.0642, kl=14.1766, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0849 (Recon: 0.0848, KL: 17.4042, Current Beta: 0.0000) | Avg Valid Loss: 0.0780 | Avg Valid recon Loss: 0.0780\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0745, recon=0.0745, kl=8.1930, beta=0.0000\n",
      "Batch 40, loss=0.0811, recon=0.0811, kl=8.2809, beta=0.0000\n",
      "Batch 60, loss=0.0538, recon=0.0537, kl=6.6796, beta=0.0000\n",
      "Batch 80, loss=0.0602, recon=0.0602, kl=6.0207, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0810 (Recon: 0.0809, KL: 7.8705, Current Beta: 0.0000) | Avg Valid Loss: 0.0758 | Avg Valid recon Loss: 0.0757\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1394, recon=0.1393, kl=3.4741, beta=0.0000\n",
      "Batch 40, loss=0.0532, recon=0.0532, kl=2.7819, beta=0.0000\n",
      "Batch 60, loss=0.0526, recon=0.0526, kl=2.8299, beta=0.0000\n",
      "Batch 80, loss=0.0554, recon=0.0553, kl=2.9844, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0781 (Recon: 0.0780, KL: 3.2075, Current Beta: 0.0000) | Avg Valid Loss: 0.0719 | Avg Valid recon Loss: 0.0718\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0447, recon=0.0447, kl=1.2235, beta=0.0000\n",
      "Batch 40, loss=0.0775, recon=0.0775, kl=1.4590, beta=0.0000\n",
      "Batch 60, loss=0.1309, recon=0.1308, kl=1.2876, beta=0.0000\n",
      "Batch 80, loss=0.0515, recon=0.0515, kl=1.0958, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0751 (Recon: 0.0750, KL: 1.3119, Current Beta: 0.0000) | Avg Valid Loss: 0.0693 | Avg Valid recon Loss: 0.0692\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0478, recon=0.0478, kl=0.5187, beta=0.0001\n",
      "Batch 40, loss=0.0428, recon=0.0428, kl=0.4941, beta=0.0001\n",
      "Batch 60, loss=0.0563, recon=0.0562, kl=0.4349, beta=0.0001\n",
      "Batch 80, loss=0.0801, recon=0.0801, kl=0.3720, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0729 (Recon: 0.0729, KL: 0.5433, Current Beta: 0.0001) | Avg Valid Loss: 0.0677 | Avg Valid recon Loss: 0.0677\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0525, recon=0.0525, kl=0.1572, beta=0.0001\n",
      "Batch 40, loss=0.0584, recon=0.0583, kl=0.1350, beta=0.0001\n",
      "Batch 60, loss=0.0462, recon=0.0462, kl=0.1223, beta=0.0001\n",
      "Batch 80, loss=0.0599, recon=0.0598, kl=0.0890, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0707 (Recon: 0.0707, KL: 0.1676, Current Beta: 0.0001) | Avg Valid Loss: 0.0647 | Avg Valid recon Loss: 0.0647\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0393, recon=0.0393, kl=0.0842, beta=0.0001\n",
      "Batch 40, loss=0.0675, recon=0.0675, kl=0.0682, beta=0.0001\n",
      "Batch 60, loss=0.0367, recon=0.0367, kl=0.0591, beta=0.0001\n",
      "Batch 80, loss=0.0813, recon=0.0813, kl=0.0254, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0687 (Recon: 0.0687, KL: 0.0608, Current Beta: 0.0001) | Avg Valid Loss: 0.0631 | Avg Valid recon Loss: 0.0631\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0644, recon=0.0644, kl=0.0323, beta=0.0001\n",
      "Batch 40, loss=0.0481, recon=0.0481, kl=0.0308, beta=0.0001\n",
      "Batch 60, loss=0.0550, recon=0.0550, kl=0.0318, beta=0.0001\n",
      "Batch 80, loss=0.0476, recon=0.0476, kl=0.0237, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0669 (Recon: 0.0669, KL: 0.0311, Current Beta: 0.0001) | Avg Valid Loss: 0.0618 | Avg Valid recon Loss: 0.0618\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0575, recon=0.0575, kl=0.0207, beta=0.0001\n",
      "Batch 40, loss=0.0487, recon=0.0486, kl=0.0286, beta=0.0001\n",
      "Batch 60, loss=0.0478, recon=0.0478, kl=0.0194, beta=0.0001\n",
      "Batch 80, loss=0.0538, recon=0.0538, kl=0.0254, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0654 (Recon: 0.0654, KL: 0.0231, Current Beta: 0.0001) | Avg Valid Loss: 0.0604 | Avg Valid recon Loss: 0.0604\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1869, recon=0.1869, kl=0.0313, beta=0.0001\n",
      "Batch 40, loss=0.0728, recon=0.0728, kl=0.0077, beta=0.0001\n",
      "Batch 60, loss=0.0527, recon=0.0527, kl=0.0089, beta=0.0001\n",
      "Batch 80, loss=0.0414, recon=0.0414, kl=0.0148, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0642 (Recon: 0.0642, KL: 0.0141, Current Beta: 0.0001) | Avg Valid Loss: 0.0583 | Avg Valid recon Loss: 0.0583\n",
      "\n",
      "[VRAE Run 128/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2809, recon=0.2809, kl=15.3532, beta=0.0000\n",
      "Batch 40, loss=0.1024, recon=0.1024, kl=27.9837, beta=0.0000\n",
      "Batch 60, loss=0.1059, recon=0.1059, kl=32.8092, beta=0.0000\n",
      "Batch 80, loss=0.0701, recon=0.0701, kl=34.6031, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2376 (Recon: 0.2376, KL: 25.4452, Current Beta: 0.0000) | Avg Valid Loss: 0.0962 | Avg Valid recon Loss: 0.0962\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1633, recon=0.1633, kl=36.3116, beta=0.0000\n",
      "Batch 40, loss=0.0641, recon=0.0641, kl=37.3662, beta=0.0000\n",
      "Batch 60, loss=0.0800, recon=0.0800, kl=38.7894, beta=0.0000\n",
      "Batch 80, loss=0.0616, recon=0.0616, kl=41.7154, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0916 (Recon: 0.0916, KL: 38.2048, Current Beta: 0.0000) | Avg Valid Loss: 0.0722 | Avg Valid recon Loss: 0.0722\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0503, recon=0.0503, kl=44.1017, beta=0.0000\n",
      "Batch 40, loss=0.0405, recon=0.0405, kl=44.4696, beta=0.0000\n",
      "Batch 60, loss=0.0529, recon=0.0529, kl=45.4914, beta=0.0000\n",
      "Batch 80, loss=0.0407, recon=0.0407, kl=45.9822, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0726 (Recon: 0.0726, KL: 44.7718, Current Beta: 0.0000) | Avg Valid Loss: 0.0619 | Avg Valid recon Loss: 0.0619\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0642, recon=0.0642, kl=47.6964, beta=0.0000\n",
      "Batch 40, loss=0.1684, recon=0.1684, kl=48.0779, beta=0.0000\n",
      "Batch 60, loss=0.0470, recon=0.0470, kl=49.1519, beta=0.0000\n",
      "Batch 80, loss=0.0638, recon=0.0638, kl=50.2899, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0622 (Recon: 0.0622, KL: 48.5525, Current Beta: 0.0000) | Avg Valid Loss: 0.0596 | Avg Valid recon Loss: 0.0596\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0386, recon=0.0386, kl=50.4598, beta=0.0000\n",
      "Batch 40, loss=0.0518, recon=0.0518, kl=51.5951, beta=0.0000\n",
      "Batch 60, loss=0.0443, recon=0.0443, kl=51.5507, beta=0.0000\n",
      "Batch 80, loss=0.0467, recon=0.0467, kl=51.9302, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0589 (Recon: 0.0589, KL: 51.4336, Current Beta: 0.0000) | Avg Valid Loss: 0.0543 | Avg Valid recon Loss: 0.0543\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0373, recon=0.0373, kl=51.6999, beta=0.0000\n",
      "Batch 40, loss=0.0697, recon=0.0697, kl=50.4893, beta=0.0000\n",
      "Batch 60, loss=0.0447, recon=0.0447, kl=49.9797, beta=0.0000\n",
      "Batch 80, loss=0.0298, recon=0.0298, kl=49.9683, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0551 (Recon: 0.0551, KL: 50.4695, Current Beta: 0.0000) | Avg Valid Loss: 0.0461 | Avg Valid recon Loss: 0.0461\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0499, recon=0.0499, kl=50.3030, beta=0.0000\n",
      "Batch 40, loss=0.0683, recon=0.0683, kl=49.1952, beta=0.0000\n",
      "Batch 60, loss=0.0505, recon=0.0505, kl=47.5216, beta=0.0000\n",
      "Batch 80, loss=0.0431, recon=0.0431, kl=46.5348, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0507 (Recon: 0.0507, KL: 48.7084, Current Beta: 0.0000) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0493, recon=0.0493, kl=44.2640, beta=0.0000\n",
      "Batch 40, loss=0.0276, recon=0.0276, kl=41.2242, beta=0.0000\n",
      "Batch 60, loss=0.0303, recon=0.0303, kl=36.0995, beta=0.0000\n",
      "Batch 80, loss=0.0332, recon=0.0332, kl=34.6131, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 39.8116, Current Beta: 0.0000) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0450\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0339, recon=0.0339, kl=28.8891, beta=0.0000\n",
      "Batch 40, loss=0.0426, recon=0.0426, kl=26.9018, beta=0.0000\n",
      "Batch 60, loss=0.0350, recon=0.0349, kl=29.2798, beta=0.0000\n",
      "Batch 80, loss=0.3465, recon=0.3465, kl=29.9250, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0463, KL: 29.7045, Current Beta: 0.0000) | Avg Valid Loss: 0.0418 | Avg Valid recon Loss: 0.0418\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=19.5267, beta=0.0000\n",
      "Batch 40, loss=0.0351, recon=0.0351, kl=17.7416, beta=0.0000\n",
      "Batch 60, loss=0.0288, recon=0.0288, kl=16.2566, beta=0.0000\n",
      "Batch 80, loss=0.0480, recon=0.0480, kl=16.8355, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0458, KL: 18.6731, Current Beta: 0.0000) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0409\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0861, recon=0.0861, kl=8.4623, beta=0.0000\n",
      "Batch 40, loss=0.0497, recon=0.0497, kl=12.2461, beta=0.0000\n",
      "Batch 60, loss=0.0414, recon=0.0414, kl=10.0090, beta=0.0000\n",
      "Batch 80, loss=0.0348, recon=0.0347, kl=9.1173, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0436 (Recon: 0.0436, KL: 10.5373, Current Beta: 0.0000) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0298, recon=0.0298, kl=2.8056, beta=0.0000\n",
      "Batch 40, loss=0.0361, recon=0.0361, kl=10.0788, beta=0.0000\n",
      "Batch 60, loss=0.0309, recon=0.0309, kl=4.8264, beta=0.0000\n",
      "Batch 80, loss=0.0369, recon=0.0369, kl=4.6700, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0422, KL: 5.7338, Current Beta: 0.0000) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0240, recon=0.0240, kl=0.7816, beta=0.0000\n",
      "Batch 40, loss=0.0279, recon=0.0278, kl=1.5834, beta=0.0000\n",
      "Batch 60, loss=0.0284, recon=0.0284, kl=0.7343, beta=0.0000\n",
      "Batch 80, loss=0.0471, recon=0.0470, kl=0.4692, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0414, KL: 1.1170, Current Beta: 0.0000) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0500, recon=0.0500, kl=0.0776, beta=0.0000\n",
      "Batch 40, loss=0.0418, recon=0.0418, kl=0.6223, beta=0.0000\n",
      "Batch 60, loss=0.0330, recon=0.0330, kl=0.1635, beta=0.0000\n",
      "Batch 80, loss=0.0312, recon=0.0312, kl=0.2082, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0452 (Recon: 0.0452, KL: 0.2612, Current Beta: 0.0000) | Avg Valid Loss: 0.0396 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0558, recon=0.0558, kl=0.0218, beta=0.0001\n",
      "Batch 40, loss=0.1110, recon=0.1110, kl=0.0708, beta=0.0001\n",
      "Batch 60, loss=0.0327, recon=0.0327, kl=0.1380, beta=0.0001\n",
      "Batch 80, loss=0.0303, recon=0.0303, kl=0.0497, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0436, KL: 0.0988, Current Beta: 0.0001) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0677, recon=0.0677, kl=0.0266, beta=0.0001\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=0.0125, beta=0.0001\n",
      "Batch 60, loss=0.0275, recon=0.0275, kl=0.0064, beta=0.0001\n",
      "Batch 80, loss=0.0299, recon=0.0299, kl=0.0230, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0406 (Recon: 0.0405, KL: 0.0202, Current Beta: 0.0001) | Avg Valid Loss: 0.0344 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0262, recon=0.0262, kl=0.0221, beta=0.0001\n",
      "Batch 40, loss=0.0323, recon=0.0323, kl=0.0211, beta=0.0001\n",
      "Batch 60, loss=0.0215, recon=0.0215, kl=0.0110, beta=0.0001\n",
      "Batch 80, loss=0.0323, recon=0.0323, kl=0.0068, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0388, KL: 0.0178, Current Beta: 0.0001) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0337\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0252, recon=0.0252, kl=0.0472, beta=0.0001\n",
      "Batch 40, loss=0.0942, recon=0.0942, kl=0.0055, beta=0.0001\n",
      "Batch 60, loss=0.0302, recon=0.0302, kl=0.0361, beta=0.0001\n",
      "Batch 80, loss=0.0297, recon=0.0297, kl=0.0223, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0386, KL: 0.0307, Current Beta: 0.0001) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0786, recon=0.0786, kl=0.0250, beta=0.0001\n",
      "Batch 40, loss=0.0275, recon=0.0275, kl=0.0306, beta=0.0001\n",
      "Batch 60, loss=0.0294, recon=0.0294, kl=0.0105, beta=0.0001\n",
      "Batch 80, loss=0.0527, recon=0.0527, kl=0.0169, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0413 (Recon: 0.0413, KL: 0.0201, Current Beta: 0.0001) | Avg Valid Loss: 0.0448 | Avg Valid recon Loss: 0.0448\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0331, recon=0.0331, kl=0.0043, beta=0.0001\n",
      "Batch 40, loss=0.0309, recon=0.0309, kl=0.0042, beta=0.0001\n",
      "Batch 60, loss=0.0370, recon=0.0370, kl=0.0191, beta=0.0001\n",
      "Batch 80, loss=0.0293, recon=0.0293, kl=0.0305, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0400, KL: 0.0158, Current Beta: 0.0001) | Avg Valid Loss: 0.0354 | Avg Valid recon Loss: 0.0354\n",
      "\n",
      "[VRAE Run 129/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.8310, recon=0.8310, kl=0.6154, beta=0.0000\n",
      "Batch 40, loss=0.4669, recon=0.4669, kl=2.0337, beta=0.0000\n",
      "Batch 60, loss=0.4745, recon=0.4745, kl=11.1222, beta=0.0000\n",
      "Batch 80, loss=0.3109, recon=0.3109, kl=23.1028, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6056 (Recon: 0.6056, KL: 8.4523, Current Beta: 0.0000) | Avg Valid Loss: 0.3830 | Avg Valid recon Loss: 0.3830\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3370, recon=0.3370, kl=33.4558, beta=0.0000\n",
      "Batch 40, loss=0.2471, recon=0.2471, kl=38.5199, beta=0.0000\n",
      "Batch 60, loss=0.2323, recon=0.2323, kl=44.1107, beta=0.0000\n",
      "Batch 80, loss=0.2395, recon=0.2395, kl=48.8023, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2988 (Recon: 0.2988, KL: 39.9468, Current Beta: 0.0000) | Avg Valid Loss: 0.2254 | Avg Valid recon Loss: 0.2254\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1487, recon=0.1487, kl=54.6357, beta=0.0000\n",
      "Batch 40, loss=0.1569, recon=0.1569, kl=58.4040, beta=0.0000\n",
      "Batch 60, loss=0.2237, recon=0.2237, kl=61.6349, beta=0.0000\n",
      "Batch 80, loss=0.1770, recon=0.1770, kl=64.5030, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2089 (Recon: 0.2089, KL: 58.9002, Current Beta: 0.0000) | Avg Valid Loss: 0.1657 | Avg Valid recon Loss: 0.1657\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1185, recon=0.1185, kl=67.1869, beta=0.0000\n",
      "Batch 40, loss=0.1055, recon=0.1055, kl=68.8433, beta=0.0000\n",
      "Batch 60, loss=0.1392, recon=0.1392, kl=71.8009, beta=0.0000\n",
      "Batch 80, loss=0.1241, recon=0.1241, kl=74.1632, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1649 (Recon: 0.1649, KL: 70.0843, Current Beta: 0.0000) | Avg Valid Loss: 0.1356 | Avg Valid recon Loss: 0.1356\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1236, recon=0.1236, kl=76.6499, beta=0.0000\n",
      "Batch 40, loss=0.1418, recon=0.1418, kl=77.8789, beta=0.0000\n",
      "Batch 60, loss=0.1037, recon=0.1037, kl=78.9553, beta=0.0000\n",
      "Batch 80, loss=0.1845, recon=0.1845, kl=79.6969, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1397 (Recon: 0.1397, KL: 78.0131, Current Beta: 0.0000) | Avg Valid Loss: 0.1171 | Avg Valid recon Loss: 0.1171\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0849, recon=0.0849, kl=82.1657, beta=0.0000\n",
      "Batch 40, loss=0.1223, recon=0.1223, kl=83.5242, beta=0.0000\n",
      "Batch 60, loss=0.0952, recon=0.0952, kl=84.4987, beta=0.0000\n",
      "Batch 80, loss=0.0721, recon=0.0721, kl=85.0992, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1222 (Recon: 0.1222, KL: 83.4162, Current Beta: 0.0000) | Avg Valid Loss: 0.1051 | Avg Valid recon Loss: 0.1051\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0930, recon=0.0930, kl=85.7866, beta=0.0000\n",
      "Batch 40, loss=0.0639, recon=0.0639, kl=87.4276, beta=0.0000\n",
      "Batch 60, loss=0.1195, recon=0.1195, kl=87.8156, beta=0.0000\n",
      "Batch 80, loss=0.0747, recon=0.0747, kl=87.4679, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1102 (Recon: 0.1102, KL: 86.9532, Current Beta: 0.0000) | Avg Valid Loss: 0.0963 | Avg Valid recon Loss: 0.0963\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0593, recon=0.0593, kl=85.9152, beta=0.0000\n",
      "Batch 40, loss=0.0768, recon=0.0768, kl=85.0862, beta=0.0000\n",
      "Batch 60, loss=0.0708, recon=0.0708, kl=84.7091, beta=0.0000\n",
      "Batch 80, loss=0.0759, recon=0.0759, kl=82.6977, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1014 (Recon: 0.1014, KL: 84.8146, Current Beta: 0.0000) | Avg Valid Loss: 0.0905 | Avg Valid recon Loss: 0.0905\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0549, recon=0.0549, kl=80.3319, beta=0.0000\n",
      "Batch 40, loss=0.0657, recon=0.0657, kl=74.3089, beta=0.0000\n",
      "Batch 60, loss=0.1488, recon=0.1487, kl=73.0751, beta=0.0000\n",
      "Batch 80, loss=0.0556, recon=0.0556, kl=70.9518, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0947 (Recon: 0.0947, KL: 75.5851, Current Beta: 0.0000) | Avg Valid Loss: 0.0846 | Avg Valid recon Loss: 0.0846\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0715, recon=0.0714, kl=61.7728, beta=0.0000\n",
      "Batch 40, loss=0.0748, recon=0.0747, kl=51.2981, beta=0.0000\n",
      "Batch 60, loss=0.0950, recon=0.0950, kl=44.6499, beta=0.0000\n",
      "Batch 80, loss=0.0580, recon=0.0579, kl=43.7249, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0895 (Recon: 0.0895, KL: 52.4962, Current Beta: 0.0000) | Avg Valid Loss: 0.0802 | Avg Valid recon Loss: 0.0802\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0656, recon=0.0655, kl=32.3149, beta=0.0000\n",
      "Batch 40, loss=0.0790, recon=0.0789, kl=26.5070, beta=0.0000\n",
      "Batch 60, loss=0.0925, recon=0.0924, kl=24.2781, beta=0.0000\n",
      "Batch 80, loss=0.0748, recon=0.0747, kl=23.5955, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0851 (Recon: 0.0850, KL: 28.5023, Current Beta: 0.0000) | Avg Valid Loss: 0.0766 | Avg Valid recon Loss: 0.0765\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0606, recon=0.0605, kl=12.2451, beta=0.0000\n",
      "Batch 40, loss=0.0677, recon=0.0676, kl=11.6463, beta=0.0000\n",
      "Batch 60, loss=0.0715, recon=0.0715, kl=10.7549, beta=0.0000\n",
      "Batch 80, loss=0.0578, recon=0.0577, kl=9.9472, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0815 (Recon: 0.0814, KL: 12.4048, Current Beta: 0.0000) | Avg Valid Loss: 0.0730 | Avg Valid recon Loss: 0.0729\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0547, recon=0.0546, kl=5.1831, beta=0.0000\n",
      "Batch 40, loss=0.0657, recon=0.0656, kl=4.4156, beta=0.0000\n",
      "Batch 60, loss=0.0573, recon=0.0572, kl=4.7190, beta=0.0000\n",
      "Batch 80, loss=0.0679, recon=0.0678, kl=4.7189, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0788 (Recon: 0.0787, KL: 4.8302, Current Beta: 0.0000) | Avg Valid Loss: 0.0702 | Avg Valid recon Loss: 0.0702\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0611, recon=0.0610, kl=2.7491, beta=0.0000\n",
      "Batch 40, loss=0.0651, recon=0.0651, kl=2.0994, beta=0.0000\n",
      "Batch 60, loss=0.0827, recon=0.0826, kl=2.0769, beta=0.0000\n",
      "Batch 80, loss=0.1553, recon=0.1553, kl=1.6617, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0755 (Recon: 0.0754, KL: 2.1417, Current Beta: 0.0000) | Avg Valid Loss: 0.0680 | Avg Valid recon Loss: 0.0680\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0780, recon=0.0779, kl=1.1318, beta=0.0001\n",
      "Batch 40, loss=0.0510, recon=0.0509, kl=0.9596, beta=0.0001\n",
      "Batch 60, loss=0.1155, recon=0.1154, kl=0.9272, beta=0.0001\n",
      "Batch 80, loss=0.0547, recon=0.0547, kl=0.8591, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0727 (Recon: 0.0727, KL: 1.0485, Current Beta: 0.0001) | Avg Valid Loss: 0.0660 | Avg Valid recon Loss: 0.0659\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0489, recon=0.0488, kl=0.4899, beta=0.0001\n",
      "Batch 40, loss=0.0460, recon=0.0460, kl=0.4083, beta=0.0001\n",
      "Batch 60, loss=0.0752, recon=0.0752, kl=0.3645, beta=0.0001\n",
      "Batch 80, loss=0.0608, recon=0.0608, kl=0.2778, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0706 (Recon: 0.0706, KL: 0.4169, Current Beta: 0.0001) | Avg Valid Loss: 0.0639 | Avg Valid recon Loss: 0.0639\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0457, recon=0.0457, kl=0.1814, beta=0.0001\n",
      "Batch 40, loss=0.0520, recon=0.0520, kl=0.1521, beta=0.0001\n",
      "Batch 60, loss=0.0430, recon=0.0430, kl=0.1263, beta=0.0001\n",
      "Batch 80, loss=0.0482, recon=0.0482, kl=0.1345, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0684 (Recon: 0.0684, KL: 0.1603, Current Beta: 0.0001) | Avg Valid Loss: 0.0624 | Avg Valid recon Loss: 0.0624\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0704, recon=0.0704, kl=0.0927, beta=0.0001\n",
      "Batch 40, loss=0.0592, recon=0.0592, kl=0.0759, beta=0.0001\n",
      "Batch 60, loss=0.0432, recon=0.0432, kl=0.0721, beta=0.0001\n",
      "Batch 80, loss=0.0478, recon=0.0478, kl=0.0344, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0662 (Recon: 0.0662, KL: 0.0735, Current Beta: 0.0001) | Avg Valid Loss: 0.0604 | Avg Valid recon Loss: 0.0604\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0427, recon=0.0427, kl=0.0519, beta=0.0001\n",
      "Batch 40, loss=0.0496, recon=0.0496, kl=0.0428, beta=0.0001\n",
      "Batch 60, loss=0.0435, recon=0.0435, kl=0.0749, beta=0.0001\n",
      "Batch 80, loss=0.0564, recon=0.0564, kl=0.0401, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0649 (Recon: 0.0649, KL: 0.0509, Current Beta: 0.0001) | Avg Valid Loss: 0.0592 | Avg Valid recon Loss: 0.0592\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0672, recon=0.0672, kl=0.0545, beta=0.0001\n",
      "Batch 40, loss=0.0353, recon=0.0353, kl=0.0377, beta=0.0001\n",
      "Batch 60, loss=0.0374, recon=0.0374, kl=0.0484, beta=0.0001\n",
      "Batch 80, loss=0.0491, recon=0.0491, kl=0.0252, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0637 (Recon: 0.0637, KL: 0.0417, Current Beta: 0.0001) | Avg Valid Loss: 0.0591 | Avg Valid recon Loss: 0.0591\n",
      "\n",
      "[VRAE Run 130/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1887, recon=0.1887, kl=26.7255, beta=0.0000\n",
      "Batch 40, loss=0.1364, recon=0.1364, kl=49.3735, beta=0.0000\n",
      "Batch 60, loss=0.1195, recon=0.1195, kl=60.5539, beta=0.0000\n",
      "Batch 80, loss=0.0853, recon=0.0853, kl=68.0193, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2150 (Recon: 0.2150, KL: 46.0782, Current Beta: 0.0000) | Avg Valid Loss: 0.1123 | Avg Valid recon Loss: 0.1123\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1022, recon=0.1022, kl=72.4351, beta=0.0000\n",
      "Batch 40, loss=0.0530, recon=0.0530, kl=78.0842, beta=0.0000\n",
      "Batch 60, loss=0.0544, recon=0.0544, kl=80.6415, beta=0.0000\n",
      "Batch 80, loss=0.0492, recon=0.0492, kl=84.4993, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0887 (Recon: 0.0887, KL: 77.8651, Current Beta: 0.0000) | Avg Valid Loss: 0.0682 | Avg Valid recon Loss: 0.0682\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0702, recon=0.0702, kl=86.9115, beta=0.0000\n",
      "Batch 40, loss=0.0663, recon=0.0663, kl=80.0579, beta=0.0000\n",
      "Batch 60, loss=0.0529, recon=0.0529, kl=76.2328, beta=0.0000\n",
      "Batch 80, loss=0.0546, recon=0.0546, kl=80.0569, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0705 (Recon: 0.0705, KL: 81.7678, Current Beta: 0.0000) | Avg Valid Loss: 0.0605 | Avg Valid recon Loss: 0.0605\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0578, recon=0.0578, kl=74.1987, beta=0.0000\n",
      "Batch 40, loss=0.0623, recon=0.0623, kl=73.4014, beta=0.0000\n",
      "Batch 60, loss=0.0546, recon=0.0546, kl=84.0123, beta=0.0000\n",
      "Batch 80, loss=0.0369, recon=0.0369, kl=82.1127, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0619 (Recon: 0.0619, KL: 78.7433, Current Beta: 0.0000) | Avg Valid Loss: 0.0518 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0477, recon=0.0477, kl=74.2062, beta=0.0000\n",
      "Batch 40, loss=0.1382, recon=0.1382, kl=77.9083, beta=0.0000\n",
      "Batch 60, loss=0.0517, recon=0.0517, kl=76.7597, beta=0.0000\n",
      "Batch 80, loss=0.0352, recon=0.0352, kl=78.6617, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0568 (Recon: 0.0568, KL: 76.6370, Current Beta: 0.0000) | Avg Valid Loss: 0.0486 | Avg Valid recon Loss: 0.0486\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0382, recon=0.0382, kl=78.5707, beta=0.0000\n",
      "Batch 40, loss=0.0375, recon=0.0375, kl=78.5339, beta=0.0000\n",
      "Batch 60, loss=0.0434, recon=0.0434, kl=76.1725, beta=0.0000\n",
      "Batch 80, loss=0.0472, recon=0.0472, kl=76.9585, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0529, KL: 77.6558, Current Beta: 0.0000) | Avg Valid Loss: 0.0443 | Avg Valid recon Loss: 0.0443\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0487, recon=0.0487, kl=65.1184, beta=0.0000\n",
      "Batch 40, loss=0.0385, recon=0.0385, kl=70.9549, beta=0.0000\n",
      "Batch 60, loss=0.0286, recon=0.0286, kl=76.3349, beta=0.0000\n",
      "Batch 80, loss=0.0365, recon=0.0365, kl=77.2805, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0499 (Recon: 0.0499, KL: 72.7253, Current Beta: 0.0000) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0297, recon=0.0297, kl=63.5677, beta=0.0000\n",
      "Batch 40, loss=0.0421, recon=0.0421, kl=60.7175, beta=0.0000\n",
      "Batch 60, loss=0.0364, recon=0.0364, kl=59.3037, beta=0.0000\n",
      "Batch 80, loss=0.0686, recon=0.0686, kl=61.1675, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0480, KL: 62.1228, Current Beta: 0.0000) | Avg Valid Loss: 0.0416 | Avg Valid recon Loss: 0.0416\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0508, recon=0.0508, kl=54.0744, beta=0.0000\n",
      "Batch 40, loss=0.0435, recon=0.0435, kl=46.0959, beta=0.0000\n",
      "Batch 60, loss=0.0876, recon=0.0876, kl=48.6632, beta=0.0000\n",
      "Batch 80, loss=0.0367, recon=0.0367, kl=44.6313, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0467 (Recon: 0.0467, KL: 49.8043, Current Beta: 0.0000) | Avg Valid Loss: 0.0470 | Avg Valid recon Loss: 0.0470\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0368, recon=0.0368, kl=33.9446, beta=0.0000\n",
      "Batch 40, loss=0.0357, recon=0.0356, kl=37.2522, beta=0.0000\n",
      "Batch 60, loss=0.0388, recon=0.0387, kl=38.9756, beta=0.0000\n",
      "Batch 80, loss=0.0373, recon=0.0373, kl=34.1787, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0461, KL: 37.5515, Current Beta: 0.0000) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0380, recon=0.0379, kl=18.8710, beta=0.0000\n",
      "Batch 40, loss=0.0484, recon=0.0483, kl=24.2046, beta=0.0000\n",
      "Batch 60, loss=0.0313, recon=0.0312, kl=21.5683, beta=0.0000\n",
      "Batch 80, loss=0.0530, recon=0.0529, kl=19.4735, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0498 (Recon: 0.0498, KL: 22.3376, Current Beta: 0.0000) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0448\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0314, recon=0.0313, kl=7.3451, beta=0.0000\n",
      "Batch 40, loss=0.0965, recon=0.0964, kl=12.6005, beta=0.0000\n",
      "Batch 60, loss=0.0388, recon=0.0387, kl=13.1268, beta=0.0000\n",
      "Batch 80, loss=0.0534, recon=0.0534, kl=8.5920, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0490 (Recon: 0.0489, KL: 11.3585, Current Beta: 0.0000) | Avg Valid Loss: 0.0473 | Avg Valid recon Loss: 0.0473\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0532, recon=0.0532, kl=1.5585, beta=0.0000\n",
      "Batch 40, loss=0.0329, recon=0.0329, kl=3.3367, beta=0.0000\n",
      "Batch 60, loss=0.0495, recon=0.0495, kl=1.9533, beta=0.0000\n",
      "Batch 80, loss=0.0334, recon=0.0333, kl=8.4440, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0436 (Recon: 0.0435, KL: 3.9780, Current Beta: 0.0000) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0625, recon=0.0624, kl=0.5969, beta=0.0000\n",
      "Batch 40, loss=0.0758, recon=0.0758, kl=0.9060, beta=0.0000\n",
      "Batch 60, loss=0.0335, recon=0.0335, kl=1.1038, beta=0.0000\n",
      "Batch 80, loss=0.0351, recon=0.0351, kl=0.6088, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0420, KL: 1.0772, Current Beta: 0.0000) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0458\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0331, recon=0.0331, kl=0.2295, beta=0.0001\n",
      "Batch 40, loss=0.0376, recon=0.0376, kl=0.1057, beta=0.0001\n",
      "Batch 60, loss=0.0370, recon=0.0370, kl=0.1489, beta=0.0001\n",
      "Batch 80, loss=0.0473, recon=0.0472, kl=0.4863, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0459, KL: 0.2733, Current Beta: 0.0001) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0301, recon=0.0301, kl=0.1014, beta=0.0001\n",
      "Batch 40, loss=0.0256, recon=0.0256, kl=0.0372, beta=0.0001\n",
      "Batch 60, loss=0.0282, recon=0.0282, kl=0.0251, beta=0.0001\n",
      "Batch 80, loss=0.0750, recon=0.0750, kl=0.0210, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0410, KL: 0.1041, Current Beta: 0.0001) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0348, recon=0.0348, kl=0.0350, beta=0.0001\n",
      "Batch 40, loss=0.0351, recon=0.0351, kl=0.0165, beta=0.0001\n",
      "Batch 60, loss=0.0380, recon=0.0380, kl=0.0183, beta=0.0001\n",
      "Batch 80, loss=0.0301, recon=0.0301, kl=0.0758, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0428, KL: 0.0377, Current Beta: 0.0001) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0331\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0423, recon=0.0423, kl=0.2401, beta=0.0001\n",
      "Batch 40, loss=0.0229, recon=0.0229, kl=0.1482, beta=0.0001\n",
      "Batch 60, loss=0.0537, recon=0.0537, kl=0.0467, beta=0.0001\n",
      "Batch 80, loss=0.0656, recon=0.0656, kl=0.0216, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0379 (Recon: 0.0379, KL: 0.1181, Current Beta: 0.0001) | Avg Valid Loss: 0.0328 | Avg Valid recon Loss: 0.0328\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0300, recon=0.0300, kl=0.0243, beta=0.0001\n",
      "Batch 40, loss=0.0320, recon=0.0320, kl=0.0236, beta=0.0001\n",
      "Batch 60, loss=0.0286, recon=0.0285, kl=0.1484, beta=0.0001\n",
      "Batch 80, loss=0.0241, recon=0.0241, kl=0.0758, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0376 (Recon: 0.0376, KL: 0.0618, Current Beta: 0.0001) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0333\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0307, recon=0.0307, kl=0.0477, beta=0.0001\n",
      "Batch 40, loss=0.0222, recon=0.0222, kl=0.0571, beta=0.0001\n",
      "Batch 60, loss=0.0497, recon=0.0497, kl=0.0225, beta=0.0001\n",
      "Batch 80, loss=0.0265, recon=0.0265, kl=0.0248, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0375 (Recon: 0.0375, KL: 0.0390, Current Beta: 0.0001) | Avg Valid Loss: 0.0303 | Avg Valid recon Loss: 0.0303\n",
      "\n",
      "[VRAE Run 131/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5980, recon=0.5980, kl=1.1433, beta=0.0000\n",
      "Batch 40, loss=0.5113, recon=0.5113, kl=6.0623, beta=0.0000\n",
      "Batch 60, loss=0.4014, recon=0.4014, kl=31.2430, beta=0.0000\n",
      "Batch 80, loss=0.2955, recon=0.2955, kl=58.6224, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5829 (Recon: 0.5829, KL: 22.1225, Current Beta: 0.0000) | Avg Valid Loss: 0.3705 | Avg Valid recon Loss: 0.3705\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.4728, recon=0.4728, kl=81.3446, beta=0.0000\n",
      "Batch 40, loss=0.3433, recon=0.3433, kl=90.2155, beta=0.0000\n",
      "Batch 60, loss=0.2127, recon=0.2127, kl=98.3826, beta=0.0000\n",
      "Batch 80, loss=0.1922, recon=0.1922, kl=104.7431, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2910 (Recon: 0.2910, KL: 91.3534, Current Beta: 0.0000) | Avg Valid Loss: 0.2146 | Avg Valid recon Loss: 0.2146\n",
      "Epoch 3/20\n",
      "Batch 20, loss=1.2657, recon=1.2657, kl=111.2343, beta=0.0000\n",
      "Batch 40, loss=0.1782, recon=0.1782, kl=115.2693, beta=0.0000\n",
      "Batch 60, loss=0.1522, recon=0.1522, kl=119.7374, beta=0.0000\n",
      "Batch 80, loss=0.1831, recon=0.1831, kl=123.5032, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2021 (Recon: 0.2021, KL: 116.3149, Current Beta: 0.0000) | Avg Valid Loss: 0.1601 | Avg Valid recon Loss: 0.1601\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1401, recon=0.1401, kl=127.7589, beta=0.0000\n",
      "Batch 40, loss=0.1906, recon=0.1906, kl=130.5639, beta=0.0000\n",
      "Batch 60, loss=0.1829, recon=0.1829, kl=131.9278, beta=0.0000\n",
      "Batch 80, loss=0.1143, recon=0.1143, kl=134.2874, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1595 (Recon: 0.1595, KL: 130.5826, Current Beta: 0.0000) | Avg Valid Loss: 0.1331 | Avg Valid recon Loss: 0.1331\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1496, recon=0.1496, kl=138.0922, beta=0.0000\n",
      "Batch 40, loss=0.3773, recon=0.3773, kl=141.4944, beta=0.0000\n",
      "Batch 60, loss=0.1034, recon=0.1034, kl=144.5090, beta=0.0000\n",
      "Batch 80, loss=0.1453, recon=0.1453, kl=147.1389, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1352 (Recon: 0.1352, KL: 142.0886, Current Beta: 0.0000) | Avg Valid Loss: 0.1142 | Avg Valid recon Loss: 0.1142\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0902, recon=0.0902, kl=149.9552, beta=0.0000\n",
      "Batch 40, loss=0.0682, recon=0.0682, kl=152.2139, beta=0.0000\n",
      "Batch 60, loss=0.1272, recon=0.1272, kl=154.1120, beta=0.0000\n",
      "Batch 80, loss=0.0772, recon=0.0772, kl=156.0926, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1173 (Recon: 0.1173, KL: 152.5977, Current Beta: 0.0000) | Avg Valid Loss: 0.1024 | Avg Valid recon Loss: 0.1024\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1305, recon=0.1305, kl=157.8208, beta=0.0000\n",
      "Batch 40, loss=0.0778, recon=0.0777, kl=158.8955, beta=0.0000\n",
      "Batch 60, loss=0.0862, recon=0.0862, kl=159.3999, beta=0.0000\n",
      "Batch 80, loss=0.1173, recon=0.1173, kl=160.2808, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1061 (Recon: 0.1061, KL: 158.8981, Current Beta: 0.0000) | Avg Valid Loss: 0.0948 | Avg Valid recon Loss: 0.0948\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0707, recon=0.0707, kl=159.8417, beta=0.0000\n",
      "Batch 40, loss=0.0559, recon=0.0559, kl=158.4415, beta=0.0000\n",
      "Batch 60, loss=0.1076, recon=0.1076, kl=155.9067, beta=0.0000\n",
      "Batch 80, loss=0.0673, recon=0.0673, kl=154.4550, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0978 (Recon: 0.0978, KL: 157.6196, Current Beta: 0.0000) | Avg Valid Loss: 0.0882 | Avg Valid recon Loss: 0.0882\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0762, recon=0.0761, kl=147.6986, beta=0.0000\n",
      "Batch 40, loss=0.0595, recon=0.0594, kl=138.1863, beta=0.0000\n",
      "Batch 60, loss=0.0697, recon=0.0696, kl=130.3288, beta=0.0000\n",
      "Batch 80, loss=0.1004, recon=0.1003, kl=122.7301, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0917 (Recon: 0.0917, KL: 136.4985, Current Beta: 0.0000) | Avg Valid Loss: 0.0838 | Avg Valid recon Loss: 0.0838\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0888, recon=0.0887, kl=96.3042, beta=0.0000\n",
      "Batch 40, loss=0.0658, recon=0.0657, kl=77.8282, beta=0.0000\n",
      "Batch 60, loss=0.2140, recon=0.2139, kl=68.6451, beta=0.0000\n",
      "Batch 80, loss=0.0672, recon=0.0671, kl=65.3175, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0863 (Recon: 0.0862, KL: 81.0602, Current Beta: 0.0000) | Avg Valid Loss: 0.0788 | Avg Valid recon Loss: 0.0788\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0773, recon=0.0772, kl=35.9205, beta=0.0000\n",
      "Batch 40, loss=0.0545, recon=0.0544, kl=37.5280, beta=0.0000\n",
      "Batch 60, loss=0.0570, recon=0.0569, kl=34.1534, beta=0.0000\n",
      "Batch 80, loss=0.0717, recon=0.0716, kl=32.4076, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0826 (Recon: 0.0825, KL: 38.5494, Current Beta: 0.0000) | Avg Valid Loss: 0.0757 | Avg Valid recon Loss: 0.0756\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0470, recon=0.0469, kl=17.1424, beta=0.0000\n",
      "Batch 40, loss=0.1138, recon=0.1137, kl=13.4599, beta=0.0000\n",
      "Batch 60, loss=0.0404, recon=0.0403, kl=12.3515, beta=0.0000\n",
      "Batch 80, loss=0.0538, recon=0.0537, kl=10.7126, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0790 (Recon: 0.0789, KL: 14.4331, Current Beta: 0.0000) | Avg Valid Loss: 0.0725 | Avg Valid recon Loss: 0.0724\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0635, recon=0.0634, kl=5.2109, beta=0.0000\n",
      "Batch 40, loss=0.0601, recon=0.0600, kl=4.2151, beta=0.0000\n",
      "Batch 60, loss=0.0504, recon=0.0503, kl=4.5201, beta=0.0000\n",
      "Batch 80, loss=0.1095, recon=0.1094, kl=3.7570, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0760 (Recon: 0.0759, KL: 4.9197, Current Beta: 0.0000) | Avg Valid Loss: 0.0698 | Avg Valid recon Loss: 0.0697\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1074, recon=0.1073, kl=2.6632, beta=0.0000\n",
      "Batch 40, loss=0.1042, recon=0.1041, kl=1.5302, beta=0.0000\n",
      "Batch 60, loss=0.0557, recon=0.0556, kl=1.6972, beta=0.0000\n",
      "Batch 80, loss=0.0618, recon=0.0617, kl=1.1368, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0736 (Recon: 0.0735, KL: 1.8134, Current Beta: 0.0000) | Avg Valid Loss: 0.0668 | Avg Valid recon Loss: 0.0668\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0426, recon=0.0426, kl=0.8632, beta=0.0001\n",
      "Batch 40, loss=0.0601, recon=0.0601, kl=0.7245, beta=0.0001\n",
      "Batch 60, loss=0.0542, recon=0.0542, kl=0.5933, beta=0.0001\n",
      "Batch 80, loss=0.0432, recon=0.0431, kl=0.6592, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0714 (Recon: 0.0714, KL: 0.7267, Current Beta: 0.0001) | Avg Valid Loss: 0.0652 | Avg Valid recon Loss: 0.0651\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0522, recon=0.0522, kl=0.2650, beta=0.0001\n",
      "Batch 40, loss=0.0478, recon=0.0478, kl=0.1746, beta=0.0001\n",
      "Batch 60, loss=0.0436, recon=0.0436, kl=0.2568, beta=0.0001\n",
      "Batch 80, loss=0.0548, recon=0.0548, kl=0.1681, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0691 (Recon: 0.0691, KL: 0.2382, Current Beta: 0.0001) | Avg Valid Loss: 0.0635 | Avg Valid recon Loss: 0.0635\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0461, recon=0.0461, kl=0.1072, beta=0.0001\n",
      "Batch 40, loss=0.0474, recon=0.0474, kl=0.1081, beta=0.0001\n",
      "Batch 60, loss=0.0396, recon=0.0396, kl=0.0840, beta=0.0001\n",
      "Batch 80, loss=0.0524, recon=0.0524, kl=0.0747, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0674 (Recon: 0.0674, KL: 0.0939, Current Beta: 0.0001) | Avg Valid Loss: 0.0619 | Avg Valid recon Loss: 0.0619\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0563, recon=0.0563, kl=0.0459, beta=0.0001\n",
      "Batch 40, loss=0.0420, recon=0.0420, kl=0.0392, beta=0.0001\n",
      "Batch 60, loss=0.0460, recon=0.0460, kl=0.0342, beta=0.0001\n",
      "Batch 80, loss=0.0574, recon=0.0574, kl=0.0360, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0656 (Recon: 0.0656, KL: 0.0407, Current Beta: 0.0001) | Avg Valid Loss: 0.0608 | Avg Valid recon Loss: 0.0608\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0442, recon=0.0442, kl=0.0332, beta=0.0001\n",
      "Batch 40, loss=0.0725, recon=0.0725, kl=0.0392, beta=0.0001\n",
      "Batch 60, loss=0.0549, recon=0.0549, kl=0.0279, beta=0.0001\n",
      "Batch 80, loss=0.0525, recon=0.0525, kl=0.0276, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0645 (Recon: 0.0645, KL: 0.0308, Current Beta: 0.0001) | Avg Valid Loss: 0.0590 | Avg Valid recon Loss: 0.0590\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0405, recon=0.0405, kl=0.0267, beta=0.0001\n",
      "Batch 40, loss=0.0889, recon=0.0889, kl=0.0192, beta=0.0001\n",
      "Batch 60, loss=0.0868, recon=0.0868, kl=0.0176, beta=0.0001\n",
      "Batch 80, loss=0.0403, recon=0.0403, kl=0.0161, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0630 (Recon: 0.0630, KL: 0.0203, Current Beta: 0.0001) | Avg Valid Loss: 0.0577 | Avg Valid recon Loss: 0.0577\n",
      "\n",
      "[VRAE Run 132/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2439, recon=0.2439, kl=54.6838, beta=0.0000\n",
      "Batch 40, loss=0.1711, recon=0.1711, kl=85.3429, beta=0.0000\n",
      "Batch 60, loss=0.1247, recon=0.1247, kl=92.5015, beta=0.0000\n",
      "Batch 80, loss=0.1002, recon=0.1002, kl=118.9857, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2287 (Recon: 0.2287, KL: 78.9674, Current Beta: 0.0000) | Avg Valid Loss: 0.0936 | Avg Valid recon Loss: 0.0936\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1619, recon=0.1619, kl=127.0165, beta=0.0000\n",
      "Batch 40, loss=0.0847, recon=0.0847, kl=124.8541, beta=0.0000\n",
      "Batch 60, loss=0.0587, recon=0.0587, kl=124.9346, beta=0.0000\n",
      "Batch 80, loss=0.0672, recon=0.0672, kl=134.6728, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0960 (Recon: 0.0960, KL: 126.8406, Current Beta: 0.0000) | Avg Valid Loss: 0.0713 | Avg Valid recon Loss: 0.0713\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2007, recon=0.2007, kl=139.0567, beta=0.0000\n",
      "Batch 40, loss=0.0876, recon=0.0876, kl=134.2549, beta=0.0000\n",
      "Batch 60, loss=0.0401, recon=0.0401, kl=129.6991, beta=0.0000\n",
      "Batch 80, loss=0.0478, recon=0.0478, kl=114.4649, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0736 (Recon: 0.0736, KL: 130.6184, Current Beta: 0.0000) | Avg Valid Loss: 0.0609 | Avg Valid recon Loss: 0.0609\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0826, recon=0.0826, kl=119.5990, beta=0.0000\n",
      "Batch 40, loss=0.1167, recon=0.1167, kl=130.0629, beta=0.0000\n",
      "Batch 60, loss=0.0637, recon=0.0637, kl=137.1398, beta=0.0000\n",
      "Batch 80, loss=0.0986, recon=0.0986, kl=143.7430, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0649 (Recon: 0.0649, KL: 130.0958, Current Beta: 0.0000) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0541\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0517, recon=0.0517, kl=158.1942, beta=0.0000\n",
      "Batch 40, loss=0.0492, recon=0.0492, kl=157.8781, beta=0.0000\n",
      "Batch 60, loss=0.0471, recon=0.0471, kl=153.3261, beta=0.0000\n",
      "Batch 80, loss=0.0384, recon=0.0384, kl=151.5811, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0590 (Recon: 0.0590, KL: 155.1783, Current Beta: 0.0000) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0614, recon=0.0614, kl=143.4569, beta=0.0000\n",
      "Batch 40, loss=0.0479, recon=0.0479, kl=134.4164, beta=0.0000\n",
      "Batch 60, loss=0.0479, recon=0.0478, kl=140.7529, beta=0.0000\n",
      "Batch 80, loss=0.0446, recon=0.0446, kl=149.3708, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0555, KL: 141.3768, Current Beta: 0.0000) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=130.0033, beta=0.0000\n",
      "Batch 40, loss=0.0513, recon=0.0513, kl=145.9860, beta=0.0000\n",
      "Batch 60, loss=0.0457, recon=0.0457, kl=133.9695, beta=0.0000\n",
      "Batch 80, loss=0.0608, recon=0.0608, kl=125.8818, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0538 (Recon: 0.0538, KL: 133.5492, Current Beta: 0.0000) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0358, recon=0.0358, kl=119.3873, beta=0.0000\n",
      "Batch 40, loss=0.0319, recon=0.0319, kl=114.0769, beta=0.0000\n",
      "Batch 60, loss=0.0451, recon=0.0451, kl=116.7428, beta=0.0000\n",
      "Batch 80, loss=0.0789, recon=0.0789, kl=123.4957, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0502, KL: 118.4050, Current Beta: 0.0000) | Avg Valid Loss: 0.0446 | Avg Valid recon Loss: 0.0446\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0451, recon=0.0450, kl=97.0310, beta=0.0000\n",
      "Batch 40, loss=0.0397, recon=0.0397, kl=93.1552, beta=0.0000\n",
      "Batch 60, loss=0.0384, recon=0.0384, kl=93.1062, beta=0.0000\n",
      "Batch 80, loss=0.0417, recon=0.0416, kl=106.1228, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0469, KL: 100.1069, Current Beta: 0.0000) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0294, recon=0.0293, kl=77.6491, beta=0.0000\n",
      "Batch 40, loss=0.0436, recon=0.0435, kl=85.9438, beta=0.0000\n",
      "Batch 60, loss=0.0573, recon=0.0572, kl=72.6298, beta=0.0000\n",
      "Batch 80, loss=0.0386, recon=0.0385, kl=77.5072, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0453 (Recon: 0.0452, KL: 79.9459, Current Beta: 0.0000) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0317, recon=0.0316, kl=44.1530, beta=0.0000\n",
      "Batch 40, loss=0.0302, recon=0.0301, kl=50.3890, beta=0.0000\n",
      "Batch 60, loss=0.1165, recon=0.1164, kl=47.1627, beta=0.0000\n",
      "Batch 80, loss=0.0340, recon=0.0338, kl=77.1386, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0459, KL: 55.5972, Current Beta: 0.0000) | Avg Valid Loss: 0.0409 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0293, recon=0.0290, kl=30.7368, beta=0.0000\n",
      "Batch 40, loss=0.0323, recon=0.0320, kl=38.0019, beta=0.0000\n",
      "Batch 60, loss=0.0593, recon=0.0591, kl=26.4503, beta=0.0000\n",
      "Batch 80, loss=0.0852, recon=0.0849, kl=42.6203, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0435 (Recon: 0.0432, KL: 37.3932, Current Beta: 0.0000) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0382, recon=0.0380, kl=11.6985, beta=0.0000\n",
      "Batch 40, loss=0.0455, recon=0.0452, kl=13.7967, beta=0.0000\n",
      "Batch 60, loss=0.0433, recon=0.0431, kl=12.8104, beta=0.0000\n",
      "Batch 80, loss=0.0365, recon=0.0363, kl=9.8137, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0436 (Recon: 0.0433, KL: 14.0044, Current Beta: 0.0000) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0249, recon=0.0248, kl=1.6944, beta=0.0000\n",
      "Batch 40, loss=0.0450, recon=0.0449, kl=1.5266, beta=0.0000\n",
      "Batch 60, loss=0.0276, recon=0.0274, kl=5.8777, beta=0.0000\n",
      "Batch 80, loss=0.0309, recon=0.0306, kl=7.8994, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0411 (Recon: 0.0409, KL: 4.3924, Current Beta: 0.0000) | Avg Valid Loss: 0.0367 | Avg Valid recon Loss: 0.0365\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0281, recon=0.0280, kl=1.9002, beta=0.0001\n",
      "Batch 40, loss=0.0299, recon=0.0298, kl=0.6481, beta=0.0001\n",
      "Batch 60, loss=0.0338, recon=0.0337, kl=0.9592, beta=0.0001\n",
      "Batch 80, loss=0.0301, recon=0.0300, kl=1.8521, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0408, KL: 1.7292, Current Beta: 0.0001) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0292, recon=0.0291, kl=0.3605, beta=0.0001\n",
      "Batch 40, loss=0.0290, recon=0.0290, kl=0.0731, beta=0.0001\n",
      "Batch 60, loss=0.0925, recon=0.0925, kl=0.0624, beta=0.0001\n",
      "Batch 80, loss=0.0377, recon=0.0377, kl=0.1208, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0457, KL: 0.2833, Current Beta: 0.0001) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0447, recon=0.0446, kl=0.1968, beta=0.0001\n",
      "Batch 40, loss=0.0550, recon=0.0550, kl=0.0917, beta=0.0001\n",
      "Batch 60, loss=0.0486, recon=0.0486, kl=0.0516, beta=0.0001\n",
      "Batch 80, loss=0.0763, recon=0.0763, kl=0.3113, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0533, KL: 0.1844, Current Beta: 0.0001) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0367\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0389, recon=0.0387, kl=1.8968, beta=0.0001\n",
      "Batch 40, loss=0.0968, recon=0.0968, kl=0.7915, beta=0.0001\n",
      "Batch 60, loss=0.0454, recon=0.0454, kl=0.3360, beta=0.0001\n",
      "Batch 80, loss=0.0327, recon=0.0327, kl=0.5437, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0428, KL: 0.9507, Current Beta: 0.0001) | Avg Valid Loss: 0.0356 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0266, recon=0.0265, kl=0.0949, beta=0.0001\n",
      "Batch 40, loss=0.0269, recon=0.0269, kl=0.1230, beta=0.0001\n",
      "Batch 60, loss=0.0290, recon=0.0289, kl=0.1957, beta=0.0001\n",
      "Batch 80, loss=0.0261, recon=0.0261, kl=0.2286, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0394 (Recon: 0.0394, KL: 0.1736, Current Beta: 0.0001) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0315, recon=0.0315, kl=0.0391, beta=0.0001\n",
      "Batch 40, loss=0.0249, recon=0.0249, kl=0.0174, beta=0.0001\n",
      "Batch 60, loss=0.0413, recon=0.0413, kl=0.0142, beta=0.0001\n",
      "Batch 80, loss=0.0304, recon=0.0304, kl=0.4019, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0391, KL: 0.1460, Current Beta: 0.0001) | Avg Valid Loss: 0.0354 | Avg Valid recon Loss: 0.0352\n",
      "\n",
      "[VRAE Run 133/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7186, recon=0.7186, kl=1.1536, beta=0.0000\n",
      "Batch 40, loss=0.3742, recon=0.3742, kl=8.6676, beta=0.0000\n",
      "Batch 60, loss=0.2341, recon=0.2341, kl=17.1411, beta=0.0000\n",
      "Batch 80, loss=0.2667, recon=0.2667, kl=23.1032, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4216 (Recon: 0.4216, KL: 11.2242, Current Beta: 0.0000) | Avg Valid Loss: 0.1929 | Avg Valid recon Loss: 0.1929\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1603, recon=0.1603, kl=31.7067, beta=0.0000\n",
      "Batch 40, loss=0.1830, recon=0.1830, kl=36.2579, beta=0.0000\n",
      "Batch 60, loss=0.1132, recon=0.1132, kl=38.0465, beta=0.0000\n",
      "Batch 80, loss=0.1218, recon=0.1218, kl=38.8407, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1726 (Recon: 0.1726, KL: 35.2904, Current Beta: 0.0000) | Avg Valid Loss: 0.1214 | Avg Valid recon Loss: 0.1214\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1211, recon=0.1211, kl=39.1268, beta=0.0000\n",
      "Batch 40, loss=0.0882, recon=0.0882, kl=40.8976, beta=0.0000\n",
      "Batch 60, loss=0.1025, recon=0.1025, kl=40.3992, beta=0.0000\n",
      "Batch 80, loss=0.1072, recon=0.1072, kl=41.9216, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1270 (Recon: 0.1270, KL: 40.2964, Current Beta: 0.0000) | Avg Valid Loss: 0.0980 | Avg Valid recon Loss: 0.0980\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0897, recon=0.0897, kl=42.2867, beta=0.0000\n",
      "Batch 40, loss=0.1050, recon=0.1050, kl=43.5385, beta=0.0000\n",
      "Batch 60, loss=0.0722, recon=0.0722, kl=44.7566, beta=0.0000\n",
      "Batch 80, loss=0.0667, recon=0.0667, kl=44.4680, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1064 (Recon: 0.1064, KL: 43.4941, Current Beta: 0.0000) | Avg Valid Loss: 0.0863 | Avg Valid recon Loss: 0.0863\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0703, recon=0.0703, kl=46.6759, beta=0.0000\n",
      "Batch 40, loss=0.0715, recon=0.0715, kl=46.8163, beta=0.0000\n",
      "Batch 60, loss=0.0560, recon=0.0560, kl=46.7982, beta=0.0000\n",
      "Batch 80, loss=0.0689, recon=0.0689, kl=47.3663, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0934 (Recon: 0.0934, KL: 46.8742, Current Beta: 0.0000) | Avg Valid Loss: 0.0790 | Avg Valid recon Loss: 0.0790\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0441, recon=0.0441, kl=48.5523, beta=0.0000\n",
      "Batch 40, loss=0.0602, recon=0.0602, kl=49.6427, beta=0.0000\n",
      "Batch 60, loss=0.0625, recon=0.0625, kl=49.0919, beta=0.0000\n",
      "Batch 80, loss=0.0590, recon=0.0590, kl=49.6766, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0844 (Recon: 0.0844, KL: 49.1219, Current Beta: 0.0000) | Avg Valid Loss: 0.0729 | Avg Valid recon Loss: 0.0729\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1077, recon=0.1077, kl=50.7262, beta=0.0000\n",
      "Batch 40, loss=0.0560, recon=0.0560, kl=50.8568, beta=0.0000\n",
      "Batch 60, loss=0.0517, recon=0.0517, kl=50.7801, beta=0.0000\n",
      "Batch 80, loss=0.0650, recon=0.0650, kl=51.2794, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0779 (Recon: 0.0779, KL: 50.7951, Current Beta: 0.0000) | Avg Valid Loss: 0.0678 | Avg Valid recon Loss: 0.0678\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0470, recon=0.0470, kl=50.0912, beta=0.0000\n",
      "Batch 40, loss=0.0559, recon=0.0559, kl=48.9460, beta=0.0000\n",
      "Batch 60, loss=0.0855, recon=0.0855, kl=48.6109, beta=0.0000\n",
      "Batch 80, loss=0.0554, recon=0.0554, kl=47.5904, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0727 (Recon: 0.0727, KL: 49.1104, Current Beta: 0.0000) | Avg Valid Loss: 0.0638 | Avg Valid recon Loss: 0.0638\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0519, recon=0.0519, kl=44.2865, beta=0.0000\n",
      "Batch 40, loss=0.0554, recon=0.0554, kl=40.9367, beta=0.0000\n",
      "Batch 60, loss=0.0516, recon=0.0516, kl=39.0834, beta=0.0000\n",
      "Batch 80, loss=0.0688, recon=0.0687, kl=38.3353, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0685 (Recon: 0.0684, KL: 41.4054, Current Beta: 0.0000) | Avg Valid Loss: 0.0613 | Avg Valid recon Loss: 0.0612\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0487, recon=0.0487, kl=31.8235, beta=0.0000\n",
      "Batch 40, loss=0.0600, recon=0.0600, kl=27.1132, beta=0.0000\n",
      "Batch 60, loss=0.0434, recon=0.0434, kl=24.4929, beta=0.0000\n",
      "Batch 80, loss=0.0669, recon=0.0669, kl=25.6450, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0653 (Recon: 0.0653, KL: 28.2991, Current Beta: 0.0000) | Avg Valid Loss: 0.0584 | Avg Valid recon Loss: 0.0584\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0364, recon=0.0364, kl=16.8195, beta=0.0000\n",
      "Batch 40, loss=0.0626, recon=0.0626, kl=14.7123, beta=0.0000\n",
      "Batch 60, loss=0.0606, recon=0.0606, kl=14.8160, beta=0.0000\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=13.4500, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0625 (Recon: 0.0624, KL: 16.0303, Current Beta: 0.0000) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0558\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0593, recon=0.0592, kl=6.3821, beta=0.0000\n",
      "Batch 40, loss=0.0630, recon=0.0630, kl=7.7845, beta=0.0000\n",
      "Batch 60, loss=0.0446, recon=0.0445, kl=6.7869, beta=0.0000\n",
      "Batch 80, loss=0.0520, recon=0.0520, kl=7.3809, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0600 (Recon: 0.0599, KL: 7.8090, Current Beta: 0.0000) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0541\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1018, recon=0.1018, kl=3.0101, beta=0.0000\n",
      "Batch 40, loss=0.0418, recon=0.0417, kl=2.7167, beta=0.0000\n",
      "Batch 60, loss=0.0454, recon=0.0454, kl=2.6065, beta=0.0000\n",
      "Batch 80, loss=0.0334, recon=0.0334, kl=2.2114, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0580 (Recon: 0.0580, KL: 3.1170, Current Beta: 0.0000) | Avg Valid Loss: 0.0523 | Avg Valid recon Loss: 0.0522\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0511, recon=0.0510, kl=1.1323, beta=0.0000\n",
      "Batch 40, loss=0.0487, recon=0.0486, kl=1.3413, beta=0.0000\n",
      "Batch 60, loss=0.0394, recon=0.0394, kl=1.1222, beta=0.0000\n",
      "Batch 80, loss=0.0502, recon=0.0501, kl=0.8964, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0562 (Recon: 0.0562, KL: 1.3070, Current Beta: 0.0000) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0509\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0618, recon=0.0617, kl=0.5886, beta=0.0001\n",
      "Batch 40, loss=0.0427, recon=0.0426, kl=0.7107, beta=0.0001\n",
      "Batch 60, loss=0.0542, recon=0.0541, kl=0.4301, beta=0.0001\n",
      "Batch 80, loss=0.0427, recon=0.0427, kl=0.3778, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0550 (Recon: 0.0550, KL: 0.5722, Current Beta: 0.0001) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0492\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1153, recon=0.1152, kl=0.2620, beta=0.0001\n",
      "Batch 40, loss=0.0494, recon=0.0493, kl=0.1114, beta=0.0001\n",
      "Batch 60, loss=0.0574, recon=0.0574, kl=0.1087, beta=0.0001\n",
      "Batch 80, loss=0.0666, recon=0.0666, kl=0.1233, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0535 (Recon: 0.0535, KL: 0.1622, Current Beta: 0.0001) | Avg Valid Loss: 0.0482 | Avg Valid recon Loss: 0.0482\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.4642, recon=0.4642, kl=0.0696, beta=0.0001\n",
      "Batch 40, loss=0.0362, recon=0.0362, kl=0.1771, beta=0.0001\n",
      "Batch 60, loss=0.0259, recon=0.0259, kl=0.0499, beta=0.0001\n",
      "Batch 80, loss=0.0657, recon=0.0657, kl=0.0554, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0521 (Recon: 0.0521, KL: 0.0795, Current Beta: 0.0001) | Avg Valid Loss: 0.0473 | Avg Valid recon Loss: 0.0473\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0490, recon=0.0490, kl=0.0632, beta=0.0001\n",
      "Batch 40, loss=0.0662, recon=0.0662, kl=0.0192, beta=0.0001\n",
      "Batch 60, loss=0.0350, recon=0.0350, kl=0.0394, beta=0.0001\n",
      "Batch 80, loss=0.0329, recon=0.0329, kl=0.0332, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0497, KL: 0.0405, Current Beta: 0.0001) | Avg Valid Loss: 0.0462 | Avg Valid recon Loss: 0.0462\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0348, recon=0.0348, kl=0.0276, beta=0.0001\n",
      "Batch 40, loss=0.0392, recon=0.0392, kl=0.0260, beta=0.0001\n",
      "Batch 60, loss=0.0377, recon=0.0377, kl=0.0148, beta=0.0001\n",
      "Batch 80, loss=0.1401, recon=0.1401, kl=0.0128, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0500 (Recon: 0.0500, KL: 0.0397, Current Beta: 0.0001) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0449\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0441, recon=0.0441, kl=0.0475, beta=0.0001\n",
      "Batch 40, loss=0.0350, recon=0.0350, kl=0.0182, beta=0.0001\n",
      "Batch 60, loss=0.0353, recon=0.0353, kl=0.0159, beta=0.0001\n",
      "Batch 80, loss=0.0409, recon=0.0409, kl=0.0119, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0489 (Recon: 0.0489, KL: 0.0522, Current Beta: 0.0001) | Avg Valid Loss: 0.0437 | Avg Valid recon Loss: 0.0437\n",
      "\n",
      "[VRAE Run 134/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1698, recon=0.1698, kl=27.5932, beta=0.0000\n",
      "Batch 40, loss=0.2922, recon=0.2922, kl=36.0285, beta=0.0000\n",
      "Batch 60, loss=0.0746, recon=0.0746, kl=40.3509, beta=0.0000\n",
      "Batch 80, loss=0.0836, recon=0.0836, kl=42.1882, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1713 (Recon: 0.1713, KL: 33.3655, Current Beta: 0.0000) | Avg Valid Loss: 0.0785 | Avg Valid recon Loss: 0.0785\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0520, recon=0.0520, kl=39.2756, beta=0.0000\n",
      "Batch 40, loss=0.0718, recon=0.0718, kl=36.8749, beta=0.0000\n",
      "Batch 60, loss=0.0403, recon=0.0403, kl=42.6557, beta=0.0000\n",
      "Batch 80, loss=0.0574, recon=0.0574, kl=45.2840, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0714 (Recon: 0.0714, KL: 41.0799, Current Beta: 0.0000) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0566\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0381, recon=0.0381, kl=46.1398, beta=0.0000\n",
      "Batch 40, loss=0.0516, recon=0.0516, kl=46.6890, beta=0.0000\n",
      "Batch 60, loss=0.0373, recon=0.0373, kl=48.7432, beta=0.0000\n",
      "Batch 80, loss=0.0551, recon=0.0551, kl=45.8783, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0587 (Recon: 0.0587, KL: 46.4105, Current Beta: 0.0000) | Avg Valid Loss: 0.0454 | Avg Valid recon Loss: 0.0454\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0417, recon=0.0417, kl=46.1698, beta=0.0000\n",
      "Batch 40, loss=0.0519, recon=0.0519, kl=47.2456, beta=0.0000\n",
      "Batch 60, loss=0.0597, recon=0.0597, kl=47.2847, beta=0.0000\n",
      "Batch 80, loss=0.0333, recon=0.0333, kl=46.2927, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0511 (Recon: 0.0511, KL: 46.9382, Current Beta: 0.0000) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=45.5711, beta=0.0000\n",
      "Batch 40, loss=0.1058, recon=0.1058, kl=49.6524, beta=0.0000\n",
      "Batch 60, loss=0.0290, recon=0.0290, kl=46.3045, beta=0.0000\n",
      "Batch 80, loss=0.0344, recon=0.0344, kl=46.7244, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0452 (Recon: 0.0452, KL: 46.6090, Current Beta: 0.0000) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0461, recon=0.0461, kl=50.1928, beta=0.0000\n",
      "Batch 40, loss=0.0475, recon=0.0475, kl=47.6572, beta=0.0000\n",
      "Batch 60, loss=0.0297, recon=0.0297, kl=51.1470, beta=0.0000\n",
      "Batch 80, loss=0.0339, recon=0.0339, kl=46.0685, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0464 (Recon: 0.0464, KL: 48.4421, Current Beta: 0.0000) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0191, recon=0.0191, kl=43.9271, beta=0.0000\n",
      "Batch 40, loss=0.0295, recon=0.0295, kl=40.0356, beta=0.0000\n",
      "Batch 60, loss=0.0228, recon=0.0228, kl=39.9842, beta=0.0000\n",
      "Batch 80, loss=0.0474, recon=0.0474, kl=42.5530, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0409, KL: 42.2877, Current Beta: 0.0000) | Avg Valid Loss: 0.0362 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0357, recon=0.0357, kl=39.8488, beta=0.0000\n",
      "Batch 40, loss=0.0282, recon=0.0282, kl=34.3627, beta=0.0000\n",
      "Batch 60, loss=0.0628, recon=0.0628, kl=34.5473, beta=0.0000\n",
      "Batch 80, loss=0.0272, recon=0.0272, kl=32.6508, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0354, KL: 36.2326, Current Beta: 0.0000) | Avg Valid Loss: 0.0343 | Avg Valid recon Loss: 0.0343\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0290, recon=0.0290, kl=31.4526, beta=0.0000\n",
      "Batch 40, loss=0.0373, recon=0.0373, kl=25.7623, beta=0.0000\n",
      "Batch 60, loss=0.1058, recon=0.1058, kl=25.7192, beta=0.0000\n",
      "Batch 80, loss=0.0303, recon=0.0302, kl=26.5762, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0413 (Recon: 0.0413, KL: 28.0432, Current Beta: 0.0000) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0422, recon=0.0422, kl=18.2286, beta=0.0000\n",
      "Batch 40, loss=0.0410, recon=0.0409, kl=22.6672, beta=0.0000\n",
      "Batch 60, loss=0.0415, recon=0.0415, kl=21.2658, beta=0.0000\n",
      "Batch 80, loss=0.0353, recon=0.0353, kl=18.1996, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0428, KL: 20.3000, Current Beta: 0.0000) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0294, recon=0.0294, kl=14.0276, beta=0.0000\n",
      "Batch 40, loss=0.0292, recon=0.0292, kl=11.9286, beta=0.0000\n",
      "Batch 60, loss=0.0211, recon=0.0211, kl=13.1754, beta=0.0000\n",
      "Batch 80, loss=0.0385, recon=0.0385, kl=12.5307, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0363 (Recon: 0.0363, KL: 13.1209, Current Beta: 0.0000) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0299, recon=0.0299, kl=7.3006, beta=0.0000\n",
      "Batch 40, loss=0.0226, recon=0.0225, kl=5.9273, beta=0.0000\n",
      "Batch 60, loss=0.0286, recon=0.0286, kl=4.3433, beta=0.0000\n",
      "Batch 80, loss=0.0325, recon=0.0324, kl=7.5265, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0348 (Recon: 0.0347, KL: 6.2420, Current Beta: 0.0000) | Avg Valid Loss: 0.0336 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0377, recon=0.0377, kl=1.9485, beta=0.0000\n",
      "Batch 40, loss=0.0310, recon=0.0309, kl=1.4374, beta=0.0000\n",
      "Batch 60, loss=0.0319, recon=0.0319, kl=2.1389, beta=0.0000\n",
      "Batch 80, loss=0.0318, recon=0.0317, kl=1.7141, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0361 (Recon: 0.0360, KL: 2.0006, Current Beta: 0.0000) | Avg Valid Loss: 0.0290 | Avg Valid recon Loss: 0.0289\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0318, recon=0.0318, kl=0.5172, beta=0.0000\n",
      "Batch 40, loss=0.0347, recon=0.0347, kl=0.3407, beta=0.0000\n",
      "Batch 60, loss=0.0569, recon=0.0569, kl=0.4343, beta=0.0000\n",
      "Batch 80, loss=0.0290, recon=0.0289, kl=0.6732, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0488 (Recon: 0.0488, KL: 0.6932, Current Beta: 0.0000) | Avg Valid Loss: 0.0406 | Avg Valid recon Loss: 0.0406\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0237, recon=0.0237, kl=0.3687, beta=0.0001\n",
      "Batch 40, loss=0.0868, recon=0.0868, kl=0.1606, beta=0.0001\n",
      "Batch 60, loss=0.0393, recon=0.0393, kl=0.1767, beta=0.0001\n",
      "Batch 80, loss=0.0430, recon=0.0430, kl=0.2141, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0480, KL: 0.2898, Current Beta: 0.0001) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0899, recon=0.0899, kl=0.1855, beta=0.0001\n",
      "Batch 40, loss=0.0250, recon=0.0249, kl=0.2832, beta=0.0001\n",
      "Batch 60, loss=0.0370, recon=0.0370, kl=0.1212, beta=0.0001\n",
      "Batch 80, loss=0.0190, recon=0.0190, kl=0.0285, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0382, KL: 0.1537, Current Beta: 0.0001) | Avg Valid Loss: 0.0349 | Avg Valid recon Loss: 0.0349\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0410, recon=0.0410, kl=0.0309, beta=0.0001\n",
      "Batch 40, loss=0.0337, recon=0.0337, kl=0.0461, beta=0.0001\n",
      "Batch 60, loss=0.0564, recon=0.0564, kl=0.0264, beta=0.0001\n",
      "Batch 80, loss=0.0387, recon=0.0387, kl=0.0466, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0415, KL: 0.0406, Current Beta: 0.0001) | Avg Valid Loss: 0.0385 | Avg Valid recon Loss: 0.0385\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0271, recon=0.0271, kl=0.1377, beta=0.0001\n",
      "Batch 40, loss=0.0277, recon=0.0277, kl=0.0448, beta=0.0001\n",
      "Batch 60, loss=0.0244, recon=0.0244, kl=0.0509, beta=0.0001\n",
      "Batch 80, loss=0.0532, recon=0.0532, kl=0.0638, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0405, KL: 0.0844, Current Beta: 0.0001) | Avg Valid Loss: 0.0694 | Avg Valid recon Loss: 0.0694\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0312, recon=0.0312, kl=0.1891, beta=0.0001\n",
      "Batch 40, loss=0.0377, recon=0.0377, kl=0.2360, beta=0.0001\n",
      "Batch 60, loss=0.0258, recon=0.0258, kl=0.1330, beta=0.0001\n",
      "Batch 80, loss=0.0542, recon=0.0542, kl=0.0619, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0427 (Recon: 0.0427, KL: 0.1466, Current Beta: 0.0001) | Avg Valid Loss: 0.0349 | Avg Valid recon Loss: 0.0349\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0324, recon=0.0323, kl=0.1613, beta=0.0001\n",
      "Batch 40, loss=0.0348, recon=0.0348, kl=0.1746, beta=0.0001\n",
      "Batch 60, loss=0.0500, recon=0.0500, kl=0.1114, beta=0.0001\n",
      "Batch 80, loss=0.0241, recon=0.0241, kl=0.1732, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0408 (Recon: 0.0408, KL: 0.1477, Current Beta: 0.0001) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0342\n",
      "\n",
      "[VRAE Run 135/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4172, recon=0.4172, kl=0.8888, beta=0.0000\n",
      "Batch 40, loss=0.7550, recon=0.7550, kl=19.5166, beta=0.0000\n",
      "Batch 60, loss=0.1932, recon=0.1932, kl=38.6480, beta=0.0000\n",
      "Batch 80, loss=0.1838, recon=0.1838, kl=49.2797, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3989 (Recon: 0.3989, KL: 24.4378, Current Beta: 0.0000) | Avg Valid Loss: 0.1925 | Avg Valid recon Loss: 0.1925\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1733, recon=0.1733, kl=59.4690, beta=0.0000\n",
      "Batch 40, loss=0.1470, recon=0.1470, kl=65.5487, beta=0.0000\n",
      "Batch 60, loss=0.1192, recon=0.1192, kl=72.1918, beta=0.0000\n",
      "Batch 80, loss=0.1229, recon=0.1229, kl=75.2636, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1743 (Recon: 0.1743, KL: 66.5879, Current Beta: 0.0000) | Avg Valid Loss: 0.1219 | Avg Valid recon Loss: 0.1219\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1288, recon=0.1288, kl=80.5794, beta=0.0000\n",
      "Batch 40, loss=0.1325, recon=0.1325, kl=83.8084, beta=0.0000\n",
      "Batch 60, loss=0.0876, recon=0.0876, kl=86.8484, beta=0.0000\n",
      "Batch 80, loss=0.1257, recon=0.1257, kl=88.7744, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1296 (Recon: 0.1296, KL: 84.0190, Current Beta: 0.0000) | Avg Valid Loss: 0.0975 | Avg Valid recon Loss: 0.0975\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0789, recon=0.0789, kl=94.3856, beta=0.0000\n",
      "Batch 40, loss=0.0719, recon=0.0719, kl=96.6629, beta=0.0000\n",
      "Batch 60, loss=0.0712, recon=0.0712, kl=97.2902, beta=0.0000\n",
      "Batch 80, loss=0.0758, recon=0.0758, kl=98.3962, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1053 (Recon: 0.1053, KL: 95.7620, Current Beta: 0.0000) | Avg Valid Loss: 0.0845 | Avg Valid recon Loss: 0.0845\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0621, recon=0.0621, kl=100.9039, beta=0.0000\n",
      "Batch 40, loss=0.0556, recon=0.0556, kl=103.4258, beta=0.0000\n",
      "Batch 60, loss=0.3391, recon=0.3391, kl=106.4884, beta=0.0000\n",
      "Batch 80, loss=0.0884, recon=0.0884, kl=107.5652, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0913 (Recon: 0.0913, KL: 103.8672, Current Beta: 0.0000) | Avg Valid Loss: 0.0767 | Avg Valid recon Loss: 0.0767\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0552, recon=0.0552, kl=110.0173, beta=0.0000\n",
      "Batch 40, loss=0.0729, recon=0.0729, kl=110.5991, beta=0.0000\n",
      "Batch 60, loss=0.2380, recon=0.2380, kl=113.8103, beta=0.0000\n",
      "Batch 80, loss=0.0690, recon=0.0690, kl=116.6065, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0821 (Recon: 0.0821, KL: 112.4685, Current Beta: 0.0000) | Avg Valid Loss: 0.0700 | Avg Valid recon Loss: 0.0700\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0665, recon=0.0665, kl=115.7002, beta=0.0000\n",
      "Batch 40, loss=0.0521, recon=0.0521, kl=111.9130, beta=0.0000\n",
      "Batch 60, loss=0.0533, recon=0.0533, kl=111.4763, beta=0.0000\n",
      "Batch 80, loss=0.0488, recon=0.0488, kl=112.1505, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0752 (Recon: 0.0752, KL: 112.8644, Current Beta: 0.0000) | Avg Valid Loss: 0.0650 | Avg Valid recon Loss: 0.0649\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0549, recon=0.0549, kl=107.5126, beta=0.0000\n",
      "Batch 40, loss=0.0371, recon=0.0371, kl=104.5436, beta=0.0000\n",
      "Batch 60, loss=0.0855, recon=0.0855, kl=99.1669, beta=0.0000\n",
      "Batch 80, loss=0.0484, recon=0.0484, kl=98.9830, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0702 (Recon: 0.0702, KL: 103.2622, Current Beta: 0.0000) | Avg Valid Loss: 0.0611 | Avg Valid recon Loss: 0.0610\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0613, recon=0.0612, kl=85.2596, beta=0.0000\n",
      "Batch 40, loss=0.0881, recon=0.0881, kl=78.2864, beta=0.0000\n",
      "Batch 60, loss=0.0657, recon=0.0657, kl=71.9927, beta=0.0000\n",
      "Batch 80, loss=0.0603, recon=0.0603, kl=67.7236, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0660 (Recon: 0.0660, KL: 77.5913, Current Beta: 0.0000) | Avg Valid Loss: 0.0580 | Avg Valid recon Loss: 0.0579\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0621, recon=0.0621, kl=52.3284, beta=0.0000\n",
      "Batch 40, loss=0.0661, recon=0.0661, kl=45.5296, beta=0.0000\n",
      "Batch 60, loss=0.0523, recon=0.0523, kl=41.5049, beta=0.0000\n",
      "Batch 80, loss=0.0455, recon=0.0455, kl=39.4846, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0630 (Recon: 0.0629, KL: 46.6277, Current Beta: 0.0000) | Avg Valid Loss: 0.0560 | Avg Valid recon Loss: 0.0560\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.5575, recon=0.5575, kl=24.3540, beta=0.0000\n",
      "Batch 40, loss=0.0522, recon=0.0521, kl=23.2642, beta=0.0000\n",
      "Batch 60, loss=0.0538, recon=0.0537, kl=21.4966, beta=0.0000\n",
      "Batch 80, loss=0.0287, recon=0.0286, kl=23.1120, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0601 (Recon: 0.0601, KL: 24.0754, Current Beta: 0.0000) | Avg Valid Loss: 0.0542 | Avg Valid recon Loss: 0.0541\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0615, recon=0.0614, kl=10.0411, beta=0.0000\n",
      "Batch 40, loss=0.0391, recon=0.0390, kl=10.9048, beta=0.0000\n",
      "Batch 60, loss=0.0341, recon=0.0340, kl=9.9597, beta=0.0000\n",
      "Batch 80, loss=0.0474, recon=0.0474, kl=9.5942, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0582 (Recon: 0.0581, KL: 11.1522, Current Beta: 0.0000) | Avg Valid Loss: 0.0530 | Avg Valid recon Loss: 0.0530\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0746, recon=0.0745, kl=4.7980, beta=0.0000\n",
      "Batch 40, loss=0.0382, recon=0.0381, kl=4.9487, beta=0.0000\n",
      "Batch 60, loss=0.0399, recon=0.0398, kl=4.3510, beta=0.0000\n",
      "Batch 80, loss=0.0302, recon=0.0302, kl=4.2088, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0562 (Recon: 0.0561, KL: 4.8017, Current Beta: 0.0000) | Avg Valid Loss: 0.0501 | Avg Valid recon Loss: 0.0501\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1484, recon=0.1484, kl=1.9060, beta=0.0000\n",
      "Batch 40, loss=0.0343, recon=0.0343, kl=2.1038, beta=0.0000\n",
      "Batch 60, loss=0.0613, recon=0.0612, kl=1.6596, beta=0.0000\n",
      "Batch 80, loss=0.0473, recon=0.0472, kl=1.6545, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0544, KL: 2.1342, Current Beta: 0.0000) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0487\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0432, recon=0.0431, kl=1.0810, beta=0.0001\n",
      "Batch 40, loss=0.0332, recon=0.0331, kl=1.0644, beta=0.0001\n",
      "Batch 60, loss=0.0389, recon=0.0388, kl=0.8409, beta=0.0001\n",
      "Batch 80, loss=0.0352, recon=0.0351, kl=0.9284, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0531 (Recon: 0.0530, KL: 0.9689, Current Beta: 0.0001) | Avg Valid Loss: 0.0477 | Avg Valid recon Loss: 0.0476\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0511, recon=0.0511, kl=0.3951, beta=0.0001\n",
      "Batch 40, loss=0.0377, recon=0.0377, kl=0.4512, beta=0.0001\n",
      "Batch 60, loss=0.0361, recon=0.0361, kl=0.2376, beta=0.0001\n",
      "Batch 80, loss=0.0384, recon=0.0384, kl=0.3832, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0516, KL: 0.3897, Current Beta: 0.0001) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0464\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0476, recon=0.0476, kl=0.2128, beta=0.0001\n",
      "Batch 40, loss=0.0442, recon=0.0442, kl=0.1259, beta=0.0001\n",
      "Batch 60, loss=0.0508, recon=0.0508, kl=0.2338, beta=0.0001\n",
      "Batch 80, loss=0.0631, recon=0.0631, kl=0.1174, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0503 (Recon: 0.0503, KL: 0.2209, Current Beta: 0.0001) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0458\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0340, recon=0.0339, kl=0.1210, beta=0.0001\n",
      "Batch 40, loss=0.0452, recon=0.0452, kl=0.1074, beta=0.0001\n",
      "Batch 60, loss=0.0970, recon=0.0970, kl=0.1053, beta=0.0001\n",
      "Batch 80, loss=0.0435, recon=0.0435, kl=0.1507, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0492 (Recon: 0.0492, KL: 0.1419, Current Beta: 0.0001) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0247, recon=0.0247, kl=0.1339, beta=0.0001\n",
      "Batch 40, loss=0.0359, recon=0.0359, kl=0.0553, beta=0.0001\n",
      "Batch 60, loss=0.0440, recon=0.0440, kl=0.0839, beta=0.0001\n",
      "Batch 80, loss=0.0513, recon=0.0513, kl=0.0758, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 0.0725, Current Beta: 0.0001) | Avg Valid Loss: 0.0439 | Avg Valid recon Loss: 0.0439\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0359, recon=0.0359, kl=0.0877, beta=0.0001\n",
      "Batch 40, loss=0.0368, recon=0.0368, kl=0.0587, beta=0.0001\n",
      "Batch 60, loss=0.0479, recon=0.0479, kl=0.0554, beta=0.0001\n",
      "Batch 80, loss=0.0375, recon=0.0375, kl=0.0384, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0473, KL: 0.0619, Current Beta: 0.0001) | Avg Valid Loss: 0.0434 | Avg Valid recon Loss: 0.0434\n",
      "\n",
      "[VRAE Run 136/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2006, recon=0.2006, kl=37.9682, beta=0.0000\n",
      "Batch 40, loss=0.0849, recon=0.0849, kl=53.4922, beta=0.0000\n",
      "Batch 60, loss=0.0746, recon=0.0746, kl=52.1226, beta=0.0000\n",
      "Batch 80, loss=0.0676, recon=0.0676, kl=46.2381, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1622 (Recon: 0.1622, KL: 42.4400, Current Beta: 0.0000) | Avg Valid Loss: 0.0730 | Avg Valid recon Loss: 0.0730\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0517, recon=0.0517, kl=52.8560, beta=0.0000\n",
      "Batch 40, loss=0.0610, recon=0.0610, kl=59.3641, beta=0.0000\n",
      "Batch 60, loss=0.1807, recon=0.1807, kl=68.6253, beta=0.0000\n",
      "Batch 80, loss=0.0374, recon=0.0374, kl=60.3954, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0711 (Recon: 0.0711, KL: 60.2453, Current Beta: 0.0000) | Avg Valid Loss: 0.0514 | Avg Valid recon Loss: 0.0514\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0410, recon=0.0410, kl=68.0532, beta=0.0000\n",
      "Batch 40, loss=0.0667, recon=0.0667, kl=62.0979, beta=0.0000\n",
      "Batch 60, loss=0.0491, recon=0.0491, kl=70.8485, beta=0.0000\n",
      "Batch 80, loss=0.0476, recon=0.0476, kl=71.1736, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0545, KL: 67.0464, Current Beta: 0.0000) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0444, recon=0.0444, kl=72.8793, beta=0.0000\n",
      "Batch 40, loss=0.0561, recon=0.0561, kl=73.4212, beta=0.0000\n",
      "Batch 60, loss=0.0454, recon=0.0454, kl=67.3863, beta=0.0000\n",
      "Batch 80, loss=0.0394, recon=0.0394, kl=61.6041, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0483 (Recon: 0.0483, KL: 69.1363, Current Beta: 0.0000) | Avg Valid Loss: 0.0419 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0294, recon=0.0294, kl=69.9379, beta=0.0000\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=78.2102, beta=0.0000\n",
      "Batch 60, loss=0.0557, recon=0.0557, kl=55.2105, beta=0.0000\n",
      "Batch 80, loss=0.0384, recon=0.0384, kl=58.1130, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0461, KL: 65.9266, Current Beta: 0.0000) | Avg Valid Loss: 0.0419 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0832, recon=0.0832, kl=70.2793, beta=0.0000\n",
      "Batch 40, loss=0.0491, recon=0.0491, kl=72.7564, beta=0.0000\n",
      "Batch 60, loss=0.0406, recon=0.0406, kl=69.9450, beta=0.0000\n",
      "Batch 80, loss=0.0397, recon=0.0397, kl=58.9371, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0444 (Recon: 0.0444, KL: 67.5163, Current Beta: 0.0000) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0303, recon=0.0303, kl=64.4232, beta=0.0000\n",
      "Batch 40, loss=0.0280, recon=0.0280, kl=66.4641, beta=0.0000\n",
      "Batch 60, loss=0.3051, recon=0.3051, kl=66.1701, beta=0.0000\n",
      "Batch 80, loss=0.0291, recon=0.0291, kl=63.2551, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0410, KL: 64.7177, Current Beta: 0.0000) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0323, recon=0.0323, kl=64.0534, beta=0.0000\n",
      "Batch 40, loss=0.0403, recon=0.0403, kl=61.0920, beta=0.0000\n",
      "Batch 60, loss=0.0324, recon=0.0324, kl=59.8465, beta=0.0000\n",
      "Batch 80, loss=0.0515, recon=0.0515, kl=61.6121, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0419, KL: 62.1118, Current Beta: 0.0000) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0284, recon=0.0284, kl=60.3418, beta=0.0000\n",
      "Batch 40, loss=0.0329, recon=0.0329, kl=53.7521, beta=0.0000\n",
      "Batch 60, loss=0.0364, recon=0.0364, kl=53.5263, beta=0.0000\n",
      "Batch 80, loss=0.0278, recon=0.0278, kl=56.8500, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0403 (Recon: 0.0403, KL: 57.0449, Current Beta: 0.0000) | Avg Valid Loss: 0.0320 | Avg Valid recon Loss: 0.0320\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0251, recon=0.0251, kl=41.7579, beta=0.0000\n",
      "Batch 40, loss=0.0247, recon=0.0246, kl=44.1197, beta=0.0000\n",
      "Batch 60, loss=0.0363, recon=0.0362, kl=38.2950, beta=0.0000\n",
      "Batch 80, loss=0.0331, recon=0.0330, kl=48.8048, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0358, KL: 43.9842, Current Beta: 0.0000) | Avg Valid Loss: 0.0326 | Avg Valid recon Loss: 0.0325\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0319, recon=0.0318, kl=32.6554, beta=0.0000\n",
      "Batch 40, loss=0.0296, recon=0.0295, kl=28.4202, beta=0.0000\n",
      "Batch 60, loss=0.0330, recon=0.0329, kl=25.2889, beta=0.0000\n",
      "Batch 80, loss=0.0739, recon=0.0738, kl=28.9838, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0361, KL: 29.9959, Current Beta: 0.0000) | Avg Valid Loss: 0.0333 | Avg Valid recon Loss: 0.0332\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0218, recon=0.0217, kl=17.6321, beta=0.0000\n",
      "Batch 40, loss=0.0286, recon=0.0285, kl=15.0219, beta=0.0000\n",
      "Batch 60, loss=0.0332, recon=0.0331, kl=11.1433, beta=0.0000\n",
      "Batch 80, loss=0.0821, recon=0.0820, kl=18.1246, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0357, KL: 15.6967, Current Beta: 0.0000) | Avg Valid Loss: 0.0316 | Avg Valid recon Loss: 0.0315\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0347, recon=0.0345, kl=15.8234, beta=0.0000\n",
      "Batch 40, loss=0.0214, recon=0.0211, kl=19.3331, beta=0.0000\n",
      "Batch 60, loss=0.0328, recon=0.0326, kl=11.1393, beta=0.0000\n",
      "Batch 80, loss=0.0349, recon=0.0346, kl=14.4219, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0359, KL: 14.2251, Current Beta: 0.0000) | Avg Valid Loss: 0.0316 | Avg Valid recon Loss: 0.0314\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0503, recon=0.0501, kl=3.9578, beta=0.0000\n",
      "Batch 40, loss=0.0492, recon=0.0491, kl=2.6033, beta=0.0000\n",
      "Batch 60, loss=0.0325, recon=0.0324, kl=2.9743, beta=0.0000\n",
      "Batch 80, loss=0.0446, recon=0.0445, kl=2.9516, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0517, KL: 3.8046, Current Beta: 0.0000) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0416\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0363, recon=0.0362, kl=0.5646, beta=0.0001\n",
      "Batch 40, loss=0.0410, recon=0.0410, kl=0.5384, beta=0.0001\n",
      "Batch 60, loss=0.0403, recon=0.0403, kl=0.8550, beta=0.0001\n",
      "Batch 80, loss=0.0411, recon=0.0411, kl=0.6710, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0475 (Recon: 0.0475, KL: 0.8395, Current Beta: 0.0001) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0304, recon=0.0304, kl=0.1830, beta=0.0001\n",
      "Batch 40, loss=0.0462, recon=0.0462, kl=0.1504, beta=0.0001\n",
      "Batch 60, loss=0.0414, recon=0.0414, kl=0.3029, beta=0.0001\n",
      "Batch 80, loss=0.0284, recon=0.0284, kl=0.1195, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0455, KL: 0.2037, Current Beta: 0.0001) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0316, recon=0.0316, kl=0.1216, beta=0.0001\n",
      "Batch 40, loss=0.0519, recon=0.0519, kl=0.2378, beta=0.0001\n",
      "Batch 60, loss=0.0268, recon=0.0267, kl=0.3072, beta=0.0001\n",
      "Batch 80, loss=0.0587, recon=0.0587, kl=0.4357, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0434, KL: 0.2527, Current Beta: 0.0001) | Avg Valid Loss: 0.0404 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0381, recon=0.0380, kl=0.2604, beta=0.0001\n",
      "Batch 40, loss=0.0249, recon=0.0248, kl=1.3460, beta=0.0001\n",
      "Batch 60, loss=0.0420, recon=0.0419, kl=0.8563, beta=0.0001\n",
      "Batch 80, loss=0.0280, recon=0.0280, kl=0.2805, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0387, KL: 0.6528, Current Beta: 0.0001) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0306\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0248, recon=0.0247, kl=0.0822, beta=0.0001\n",
      "Batch 40, loss=0.0752, recon=0.0752, kl=0.1994, beta=0.0001\n",
      "Batch 60, loss=0.0275, recon=0.0275, kl=0.2290, beta=0.0001\n",
      "Batch 80, loss=0.0497, recon=0.0497, kl=0.1309, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0339 (Recon: 0.0339, KL: 0.1658, Current Beta: 0.0001) | Avg Valid Loss: 0.0286 | Avg Valid recon Loss: 0.0286\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0240, recon=0.0240, kl=0.1211, beta=0.0001\n",
      "Batch 40, loss=0.0193, recon=0.0193, kl=0.0986, beta=0.0001\n",
      "Batch 60, loss=0.0383, recon=0.0383, kl=0.0554, beta=0.0001\n",
      "Batch 80, loss=0.0223, recon=0.0223, kl=0.0505, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0314 (Recon: 0.0314, KL: 0.0834, Current Beta: 0.0001) | Avg Valid Loss: 0.0331 | Avg Valid recon Loss: 0.0331\n",
      "\n",
      "[VRAE Run 137/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4117, recon=0.4117, kl=1.5564, beta=0.0000\n",
      "Batch 40, loss=0.2363, recon=0.2363, kl=41.9713, beta=0.0000\n",
      "Batch 60, loss=0.1952, recon=0.1952, kl=74.6606, beta=0.0000\n",
      "Batch 80, loss=0.1984, recon=0.1984, kl=91.2195, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3954 (Recon: 0.3954, KL: 46.8873, Current Beta: 0.0000) | Avg Valid Loss: 0.1850 | Avg Valid recon Loss: 0.1850\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2096, recon=0.2096, kl=112.6696, beta=0.0000\n",
      "Batch 40, loss=0.1330, recon=0.1330, kl=124.6051, beta=0.0000\n",
      "Batch 60, loss=0.2640, recon=0.2640, kl=130.0786, beta=0.0000\n",
      "Batch 80, loss=0.1346, recon=0.1346, kl=136.8372, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1698 (Recon: 0.1698, KL: 123.9337, Current Beta: 0.0000) | Avg Valid Loss: 0.1233 | Avg Valid recon Loss: 0.1233\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0865, recon=0.0865, kl=143.1478, beta=0.0000\n",
      "Batch 40, loss=0.0943, recon=0.0943, kl=146.2341, beta=0.0000\n",
      "Batch 60, loss=0.1061, recon=0.1061, kl=151.1695, beta=0.0000\n",
      "Batch 80, loss=0.0774, recon=0.0774, kl=155.6099, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1265 (Recon: 0.1265, KL: 148.0701, Current Beta: 0.0000) | Avg Valid Loss: 0.0986 | Avg Valid recon Loss: 0.0986\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0822, recon=0.0822, kl=161.5687, beta=0.0000\n",
      "Batch 40, loss=0.0792, recon=0.0792, kl=167.2256, beta=0.0000\n",
      "Batch 60, loss=0.0657, recon=0.0657, kl=173.8137, beta=0.0000\n",
      "Batch 80, loss=0.0604, recon=0.0604, kl=178.4079, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1068 (Recon: 0.1068, KL: 168.6465, Current Beta: 0.0000) | Avg Valid Loss: 0.0855 | Avg Valid recon Loss: 0.0855\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0833, recon=0.0833, kl=183.7844, beta=0.0000\n",
      "Batch 40, loss=0.0961, recon=0.0961, kl=187.8843, beta=0.0000\n",
      "Batch 60, loss=0.0686, recon=0.0686, kl=190.5831, beta=0.0000\n",
      "Batch 80, loss=0.0609, recon=0.0609, kl=191.2068, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0942 (Recon: 0.0942, KL: 187.6816, Current Beta: 0.0000) | Avg Valid Loss: 0.0788 | Avg Valid recon Loss: 0.0788\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0705, recon=0.0705, kl=194.0176, beta=0.0000\n",
      "Batch 40, loss=0.1375, recon=0.1375, kl=195.9845, beta=0.0000\n",
      "Batch 60, loss=0.0597, recon=0.0597, kl=197.4619, beta=0.0000\n",
      "Batch 80, loss=0.2426, recon=0.2426, kl=196.8192, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0856 (Recon: 0.0856, KL: 196.0081, Current Beta: 0.0000) | Avg Valid Loss: 0.0731 | Avg Valid recon Loss: 0.0731\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0540, recon=0.0540, kl=196.1051, beta=0.0000\n",
      "Batch 40, loss=0.0595, recon=0.0595, kl=194.0498, beta=0.0000\n",
      "Batch 60, loss=0.0793, recon=0.0793, kl=191.3937, beta=0.0000\n",
      "Batch 80, loss=0.2089, recon=0.2089, kl=190.1804, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0796 (Recon: 0.0795, KL: 193.2448, Current Beta: 0.0000) | Avg Valid Loss: 0.0689 | Avg Valid recon Loss: 0.0689\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0491, recon=0.0491, kl=184.1427, beta=0.0000\n",
      "Batch 40, loss=0.3544, recon=0.3544, kl=175.1793, beta=0.0000\n",
      "Batch 60, loss=0.0616, recon=0.0616, kl=169.8608, beta=0.0000\n",
      "Batch 80, loss=0.0621, recon=0.0621, kl=161.7603, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0746 (Recon: 0.0746, KL: 174.2120, Current Beta: 0.0000) | Avg Valid Loss: 0.0647 | Avg Valid recon Loss: 0.0647\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0568, recon=0.0567, kl=139.4505, beta=0.0000\n",
      "Batch 40, loss=0.0478, recon=0.0478, kl=119.7925, beta=0.0000\n",
      "Batch 60, loss=0.0914, recon=0.0913, kl=112.7711, beta=0.0000\n",
      "Batch 80, loss=0.0531, recon=0.0530, kl=107.7445, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0706 (Recon: 0.0706, KL: 124.2890, Current Beta: 0.0000) | Avg Valid Loss: 0.0611 | Avg Valid recon Loss: 0.0611\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0513, recon=0.0512, kl=80.6635, beta=0.0000\n",
      "Batch 40, loss=0.0928, recon=0.0927, kl=66.3689, beta=0.0000\n",
      "Batch 60, loss=0.1149, recon=0.1148, kl=68.0572, beta=0.0000\n",
      "Batch 80, loss=0.0568, recon=0.0568, kl=62.9123, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0668 (Recon: 0.0667, KL: 73.2866, Current Beta: 0.0000) | Avg Valid Loss: 0.0589 | Avg Valid recon Loss: 0.0588\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0383, recon=0.0382, kl=38.0575, beta=0.0000\n",
      "Batch 40, loss=0.0624, recon=0.0623, kl=32.5228, beta=0.0000\n",
      "Batch 60, loss=0.0757, recon=0.0756, kl=30.7788, beta=0.0000\n",
      "Batch 80, loss=0.1098, recon=0.1097, kl=29.5560, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0641 (Recon: 0.0640, KL: 35.8498, Current Beta: 0.0000) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0574\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0383, recon=0.0382, kl=12.9667, beta=0.0000\n",
      "Batch 40, loss=0.0361, recon=0.0360, kl=14.1262, beta=0.0000\n",
      "Batch 60, loss=0.0399, recon=0.0398, kl=12.1221, beta=0.0000\n",
      "Batch 80, loss=0.0524, recon=0.0523, kl=11.2713, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0602 (Recon: 0.0601, KL: 14.0557, Current Beta: 0.0000) | Avg Valid Loss: 0.0545 | Avg Valid recon Loss: 0.0545\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0477, recon=0.0476, kl=5.3605, beta=0.0000\n",
      "Batch 40, loss=0.0702, recon=0.0701, kl=5.2921, beta=0.0000\n",
      "Batch 60, loss=0.0784, recon=0.0783, kl=4.6496, beta=0.0000\n",
      "Batch 80, loss=0.5439, recon=0.5438, kl=4.2094, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0595 (Recon: 0.0594, KL: 5.3659, Current Beta: 0.0000) | Avg Valid Loss: 0.0530 | Avg Valid recon Loss: 0.0530\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0526, recon=0.0525, kl=2.8205, beta=0.0000\n",
      "Batch 40, loss=0.0451, recon=0.0450, kl=4.6797, beta=0.0000\n",
      "Batch 60, loss=0.1422, recon=0.1421, kl=2.4159, beta=0.0000\n",
      "Batch 80, loss=0.1388, recon=0.1387, kl=2.2134, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0575 (Recon: 0.0573, KL: 2.8885, Current Beta: 0.0000) | Avg Valid Loss: 0.0512 | Avg Valid recon Loss: 0.0511\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0469, recon=0.0468, kl=1.1925, beta=0.0001\n",
      "Batch 40, loss=0.0487, recon=0.0486, kl=1.6637, beta=0.0001\n",
      "Batch 60, loss=0.0467, recon=0.0467, kl=1.1147, beta=0.0001\n",
      "Batch 80, loss=0.0361, recon=0.0360, kl=1.3043, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0561 (Recon: 0.0560, KL: 1.3832, Current Beta: 0.0001) | Avg Valid Loss: 0.0497 | Avg Valid recon Loss: 0.0496\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0422, recon=0.0421, kl=0.8703, beta=0.0001\n",
      "Batch 40, loss=0.0533, recon=0.0532, kl=0.8419, beta=0.0001\n",
      "Batch 60, loss=0.0464, recon=0.0464, kl=0.6239, beta=0.0001\n",
      "Batch 80, loss=0.0524, recon=0.0523, kl=0.7144, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0546 (Recon: 0.0546, KL: 0.7472, Current Beta: 0.0001) | Avg Valid Loss: 0.0492 | Avg Valid recon Loss: 0.0492\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0345, recon=0.0345, kl=0.5788, beta=0.0001\n",
      "Batch 40, loss=0.0315, recon=0.0315, kl=0.4478, beta=0.0001\n",
      "Batch 60, loss=0.0417, recon=0.0416, kl=0.5777, beta=0.0001\n",
      "Batch 80, loss=0.0358, recon=0.0357, kl=0.4078, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0532 (Recon: 0.0532, KL: 0.4908, Current Beta: 0.0001) | Avg Valid Loss: 0.0490 | Avg Valid recon Loss: 0.0490\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=0.3177, beta=0.0001\n",
      "Batch 40, loss=0.0532, recon=0.0531, kl=0.3682, beta=0.0001\n",
      "Batch 60, loss=0.0324, recon=0.0324, kl=0.2548, beta=0.0001\n",
      "Batch 80, loss=0.0365, recon=0.0365, kl=0.2942, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0522 (Recon: 0.0521, KL: 0.3116, Current Beta: 0.0001) | Avg Valid Loss: 0.0461 | Avg Valid recon Loss: 0.0460\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0489, recon=0.0488, kl=0.3002, beta=0.0001\n",
      "Batch 40, loss=0.0750, recon=0.0750, kl=0.2609, beta=0.0001\n",
      "Batch 60, loss=0.0382, recon=0.0382, kl=0.1617, beta=0.0001\n",
      "Batch 80, loss=0.0283, recon=0.0283, kl=0.1649, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0510 (Recon: 0.0510, KL: 0.2157, Current Beta: 0.0001) | Avg Valid Loss: 0.0451 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=0.1304, beta=0.0001\n",
      "Batch 40, loss=0.0379, recon=0.0379, kl=0.1301, beta=0.0001\n",
      "Batch 60, loss=0.0481, recon=0.0481, kl=0.0974, beta=0.0001\n",
      "Batch 80, loss=0.0345, recon=0.0344, kl=0.1140, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0499 (Recon: 0.0499, KL: 0.1146, Current Beta: 0.0001) | Avg Valid Loss: 0.0440 | Avg Valid recon Loss: 0.0440\n",
      "\n",
      "[VRAE Run 138/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1944, recon=0.1944, kl=62.3763, beta=0.0000\n",
      "Batch 40, loss=0.1669, recon=0.1669, kl=121.1572, beta=0.0000\n",
      "Batch 60, loss=0.0787, recon=0.0787, kl=132.1172, beta=0.0000\n",
      "Batch 80, loss=0.0886, recon=0.0886, kl=127.8005, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1694 (Recon: 0.1694, KL: 98.9602, Current Beta: 0.0000) | Avg Valid Loss: 0.0716 | Avg Valid recon Loss: 0.0716\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0739, recon=0.0739, kl=98.8727, beta=0.0000\n",
      "Batch 40, loss=0.6339, recon=0.6339, kl=115.9586, beta=0.0000\n",
      "Batch 60, loss=0.0585, recon=0.0585, kl=121.6466, beta=0.0000\n",
      "Batch 80, loss=0.0554, recon=0.0554, kl=126.9547, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0722 (Recon: 0.0722, KL: 116.7308, Current Beta: 0.0000) | Avg Valid Loss: 0.0702 | Avg Valid recon Loss: 0.0702\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0439, recon=0.0439, kl=123.7791, beta=0.0000\n",
      "Batch 40, loss=0.1267, recon=0.1267, kl=139.9637, beta=0.0000\n",
      "Batch 60, loss=0.0729, recon=0.0729, kl=143.0396, beta=0.0000\n",
      "Batch 80, loss=0.0468, recon=0.0468, kl=144.5218, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 135.5672, Current Beta: 0.0000) | Avg Valid Loss: 0.0461 | Avg Valid recon Loss: 0.0461\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0619, recon=0.0619, kl=137.0697, beta=0.0000\n",
      "Batch 40, loss=0.4047, recon=0.4047, kl=144.8931, beta=0.0000\n",
      "Batch 60, loss=0.0322, recon=0.0322, kl=123.4843, beta=0.0000\n",
      "Batch 80, loss=0.0286, recon=0.0286, kl=124.2948, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0499 (Recon: 0.0499, KL: 133.7029, Current Beta: 0.0000) | Avg Valid Loss: 0.0468 | Avg Valid recon Loss: 0.0468\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0305, recon=0.0305, kl=148.1267, beta=0.0000\n",
      "Batch 40, loss=0.0391, recon=0.0391, kl=134.0068, beta=0.0000\n",
      "Batch 60, loss=0.0454, recon=0.0454, kl=134.7938, beta=0.0000\n",
      "Batch 80, loss=0.0692, recon=0.0692, kl=147.0094, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0481 (Recon: 0.0481, KL: 140.9181, Current Beta: 0.0000) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0514, recon=0.0514, kl=135.0912, beta=0.0000\n",
      "Batch 40, loss=0.0475, recon=0.0475, kl=113.8413, beta=0.0000\n",
      "Batch 60, loss=0.0368, recon=0.0368, kl=140.3050, beta=0.0000\n",
      "Batch 80, loss=0.0435, recon=0.0435, kl=144.3494, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0424, KL: 135.1456, Current Beta: 0.0000) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0347, recon=0.0347, kl=143.8717, beta=0.0000\n",
      "Batch 40, loss=0.0293, recon=0.0293, kl=107.0551, beta=0.0000\n",
      "Batch 60, loss=0.0342, recon=0.0342, kl=123.4337, beta=0.0000\n",
      "Batch 80, loss=0.0526, recon=0.0526, kl=138.9783, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0429, KL: 130.7816, Current Beta: 0.0000) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0798, recon=0.0798, kl=135.4283, beta=0.0000\n",
      "Batch 40, loss=0.0444, recon=0.0444, kl=122.7654, beta=0.0000\n",
      "Batch 60, loss=0.0233, recon=0.0233, kl=117.2126, beta=0.0000\n",
      "Batch 80, loss=0.0314, recon=0.0314, kl=113.1756, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0430, KL: 125.0166, Current Beta: 0.0000) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0403, recon=0.0403, kl=99.8589, beta=0.0000\n",
      "Batch 40, loss=0.0411, recon=0.0410, kl=104.3795, beta=0.0000\n",
      "Batch 60, loss=0.0266, recon=0.0265, kl=102.8707, beta=0.0000\n",
      "Batch 80, loss=0.0674, recon=0.0673, kl=96.1215, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0378 (Recon: 0.0378, KL: 102.7150, Current Beta: 0.0000) | Avg Valid Loss: 0.0329 | Avg Valid recon Loss: 0.0329\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0728, recon=0.0727, kl=69.2292, beta=0.0000\n",
      "Batch 40, loss=0.0357, recon=0.0356, kl=87.9071, beta=0.0000\n",
      "Batch 60, loss=0.0341, recon=0.0340, kl=86.0639, beta=0.0000\n",
      "Batch 80, loss=0.0286, recon=0.0285, kl=76.2942, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0381, KL: 81.1384, Current Beta: 0.0000) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0409\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0321, recon=0.0319, kl=55.9933, beta=0.0000\n",
      "Batch 40, loss=0.0379, recon=0.0378, kl=52.2103, beta=0.0000\n",
      "Batch 60, loss=0.0405, recon=0.0403, kl=60.4075, beta=0.0000\n",
      "Batch 80, loss=0.0260, recon=0.0258, kl=57.9322, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0406 (Recon: 0.0405, KL: 55.2859, Current Beta: 0.0000) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0486\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0255, recon=0.0253, kl=30.2275, beta=0.0000\n",
      "Batch 40, loss=0.0248, recon=0.0245, kl=33.6319, beta=0.0000\n",
      "Batch 60, loss=0.0469, recon=0.0467, kl=31.8822, beta=0.0000\n",
      "Batch 80, loss=0.0293, recon=0.0290, kl=30.2888, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0446, KL: 33.3802, Current Beta: 0.0000) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0335\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0278, recon=0.0273, kl=26.1941, beta=0.0000\n",
      "Batch 40, loss=0.0256, recon=0.0253, kl=17.6965, beta=0.0000\n",
      "Batch 60, loss=0.0320, recon=0.0318, kl=11.8031, beta=0.0000\n",
      "Batch 80, loss=0.0431, recon=0.0429, kl=11.6613, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0399 (Recon: 0.0395, KL: 18.1364, Current Beta: 0.0000) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0288, recon=0.0284, kl=12.4860, beta=0.0000\n",
      "Batch 40, loss=0.0301, recon=0.0298, kl=9.1621, beta=0.0000\n",
      "Batch 60, loss=0.0376, recon=0.0374, kl=6.1449, beta=0.0000\n",
      "Batch 80, loss=0.0232, recon=0.0231, kl=3.0418, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0385, KL: 7.6404, Current Beta: 0.0000) | Avg Valid Loss: 0.0293 | Avg Valid recon Loss: 0.0292\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0276, recon=0.0275, kl=0.9485, beta=0.0001\n",
      "Batch 40, loss=0.0305, recon=0.0304, kl=1.7961, beta=0.0001\n",
      "Batch 60, loss=0.0328, recon=0.0322, kl=8.7338, beta=0.0001\n",
      "Batch 80, loss=0.0313, recon=0.0306, kl=11.0995, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0355, KL: 5.2553, Current Beta: 0.0001) | Avg Valid Loss: 0.0329 | Avg Valid recon Loss: 0.0323\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0268, recon=0.0261, kl=6.9331, beta=0.0001\n",
      "Batch 40, loss=0.0228, recon=0.0224, kl=3.8993, beta=0.0001\n",
      "Batch 60, loss=0.0283, recon=0.0276, kl=7.3167, beta=0.0001\n",
      "Batch 80, loss=0.0928, recon=0.0917, kl=10.4860, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0384, KL: 7.8319, Current Beta: 0.0001) | Avg Valid Loss: 0.0437 | Avg Valid recon Loss: 0.0427\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0282, recon=0.0276, kl=5.8605, beta=0.0001\n",
      "Batch 40, loss=0.0552, recon=0.0547, kl=5.3463, beta=0.0001\n",
      "Batch 60, loss=0.0229, recon=0.0225, kl=4.0009, beta=0.0001\n",
      "Batch 80, loss=0.0366, recon=0.0362, kl=3.5823, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0399 (Recon: 0.0394, KL: 4.9948, Current Beta: 0.0001) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0363, recon=0.0361, kl=2.1043, beta=0.0001\n",
      "Batch 40, loss=0.1077, recon=0.1074, kl=3.1564, beta=0.0001\n",
      "Batch 60, loss=0.0744, recon=0.0741, kl=3.1164, beta=0.0001\n",
      "Batch 80, loss=0.0408, recon=0.0405, kl=3.2600, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0493, KL: 3.1551, Current Beta: 0.0001) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0300, recon=0.0298, kl=1.8439, beta=0.0001\n",
      "Batch 40, loss=0.0452, recon=0.0442, kl=9.6908, beta=0.0001\n",
      "Batch 60, loss=0.0465, recon=0.0449, kl=16.7177, beta=0.0001\n",
      "Batch 80, loss=0.0369, recon=0.0353, kl=16.3826, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0462, KL: 11.1734, Current Beta: 0.0001) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0247, recon=0.0236, kl=11.6970, beta=0.0001\n",
      "Batch 40, loss=0.0337, recon=0.0327, kl=9.8926, beta=0.0001\n",
      "Batch 60, loss=0.0359, recon=0.0349, kl=10.0028, beta=0.0001\n",
      "Batch 80, loss=0.0426, recon=0.0419, kl=7.7107, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0475, KL: 10.4131, Current Beta: 0.0001) | Avg Valid Loss: 0.0532 | Avg Valid recon Loss: 0.0524\n",
      "\n",
      "[VRAE Run 139/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2956, recon=0.2956, kl=5.5271, beta=0.0000\n",
      "Batch 40, loss=0.2019, recon=0.2019, kl=17.8549, beta=0.0000\n",
      "Batch 60, loss=0.1694, recon=0.1694, kl=25.1198, beta=0.0000\n",
      "Batch 80, loss=0.2221, recon=0.2221, kl=33.8070, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2854 (Recon: 0.2854, KL: 18.0478, Current Beta: 0.0000) | Avg Valid Loss: 0.1172 | Avg Valid recon Loss: 0.1172\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1470, recon=0.1470, kl=51.1170, beta=0.0000\n",
      "Batch 40, loss=0.0898, recon=0.0898, kl=54.4217, beta=0.0000\n",
      "Batch 60, loss=0.0901, recon=0.0901, kl=53.9201, beta=0.0000\n",
      "Batch 80, loss=0.0809, recon=0.0809, kl=53.9675, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1249 (Recon: 0.1249, KL: 52.5893, Current Beta: 0.0000) | Avg Valid Loss: 0.0890 | Avg Valid recon Loss: 0.0890\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0828, recon=0.0828, kl=58.5063, beta=0.0000\n",
      "Batch 40, loss=0.0676, recon=0.0676, kl=62.6214, beta=0.0000\n",
      "Batch 60, loss=0.0856, recon=0.0856, kl=67.3206, beta=0.0000\n",
      "Batch 80, loss=0.0820, recon=0.0820, kl=74.6253, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0977 (Recon: 0.0977, KL: 64.9904, Current Beta: 0.0000) | Avg Valid Loss: 0.0719 | Avg Valid recon Loss: 0.0719\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0566, recon=0.0566, kl=80.8736, beta=0.0000\n",
      "Batch 40, loss=0.0575, recon=0.0575, kl=78.0280, beta=0.0000\n",
      "Batch 60, loss=0.0526, recon=0.0526, kl=84.3694, beta=0.0000\n",
      "Batch 80, loss=0.0427, recon=0.0427, kl=88.1985, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0810 (Recon: 0.0810, KL: 82.3348, Current Beta: 0.0000) | Avg Valid Loss: 0.0641 | Avg Valid recon Loss: 0.0641\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0670, recon=0.0670, kl=83.8116, beta=0.0000\n",
      "Batch 40, loss=0.0514, recon=0.0514, kl=79.9812, beta=0.0000\n",
      "Batch 60, loss=0.0622, recon=0.0622, kl=77.8037, beta=0.0000\n",
      "Batch 80, loss=0.1101, recon=0.1101, kl=82.3478, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0715 (Recon: 0.0715, KL: 81.2334, Current Beta: 0.0000) | Avg Valid Loss: 0.0572 | Avg Valid recon Loss: 0.0572\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0686, recon=0.0686, kl=77.6862, beta=0.0000\n",
      "Batch 40, loss=0.0797, recon=0.0797, kl=77.2661, beta=0.0000\n",
      "Batch 60, loss=0.0434, recon=0.0434, kl=77.1731, beta=0.0000\n",
      "Batch 80, loss=0.0518, recon=0.0518, kl=79.5983, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0649 (Recon: 0.0649, KL: 78.1521, Current Beta: 0.0000) | Avg Valid Loss: 0.0536 | Avg Valid recon Loss: 0.0536\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1496, recon=0.1496, kl=74.2087, beta=0.0000\n",
      "Batch 40, loss=0.0634, recon=0.0634, kl=70.3999, beta=0.0000\n",
      "Batch 60, loss=0.0459, recon=0.0459, kl=69.4477, beta=0.0000\n",
      "Batch 80, loss=0.0398, recon=0.0398, kl=67.1830, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0590 (Recon: 0.0590, KL: 70.8200, Current Beta: 0.0000) | Avg Valid Loss: 0.0498 | Avg Valid recon Loss: 0.0498\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0455, recon=0.0455, kl=65.8234, beta=0.0000\n",
      "Batch 40, loss=0.0508, recon=0.0508, kl=56.9820, beta=0.0000\n",
      "Batch 60, loss=0.0700, recon=0.0700, kl=52.0064, beta=0.0000\n",
      "Batch 80, loss=0.0294, recon=0.0294, kl=49.3388, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0556 (Recon: 0.0556, KL: 57.5516, Current Beta: 0.0000) | Avg Valid Loss: 0.0473 | Avg Valid recon Loss: 0.0473\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0298, recon=0.0298, kl=45.7065, beta=0.0000\n",
      "Batch 40, loss=0.0396, recon=0.0396, kl=41.5224, beta=0.0000\n",
      "Batch 60, loss=0.0409, recon=0.0409, kl=43.5336, beta=0.0000\n",
      "Batch 80, loss=0.0361, recon=0.0361, kl=37.5785, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0521 (Recon: 0.0521, KL: 43.3737, Current Beta: 0.0000) | Avg Valid Loss: 0.0445 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0324, recon=0.0323, kl=28.5207, beta=0.0000\n",
      "Batch 40, loss=0.0431, recon=0.0431, kl=23.7855, beta=0.0000\n",
      "Batch 60, loss=0.0421, recon=0.0421, kl=21.8587, beta=0.0000\n",
      "Batch 80, loss=0.0381, recon=0.0381, kl=24.1014, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0492 (Recon: 0.0491, KL: 26.0638, Current Beta: 0.0000) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0677, recon=0.0677, kl=12.2047, beta=0.0000\n",
      "Batch 40, loss=0.0526, recon=0.0526, kl=14.3008, beta=0.0000\n",
      "Batch 60, loss=0.0501, recon=0.0500, kl=11.5046, beta=0.0000\n",
      "Batch 80, loss=0.0331, recon=0.0331, kl=16.6853, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0465, KL: 14.3624, Current Beta: 0.0000) | Avg Valid Loss: 0.0405 | Avg Valid recon Loss: 0.0404\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0324, recon=0.0323, kl=7.2368, beta=0.0000\n",
      "Batch 40, loss=0.0269, recon=0.0268, kl=5.4773, beta=0.0000\n",
      "Batch 60, loss=0.0314, recon=0.0313, kl=4.6972, beta=0.0000\n",
      "Batch 80, loss=0.0347, recon=0.0347, kl=5.1071, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0447 (Recon: 0.0446, KL: 6.3497, Current Beta: 0.0000) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0703, recon=0.0703, kl=2.6440, beta=0.0000\n",
      "Batch 40, loss=0.0363, recon=0.0363, kl=2.5599, beta=0.0000\n",
      "Batch 60, loss=0.0342, recon=0.0342, kl=1.9647, beta=0.0000\n",
      "Batch 80, loss=0.0330, recon=0.0329, kl=3.2908, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0426 (Recon: 0.0425, KL: 2.7138, Current Beta: 0.0000) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.3326, recon=0.3325, kl=0.8317, beta=0.0000\n",
      "Batch 40, loss=0.0258, recon=0.0257, kl=1.0136, beta=0.0000\n",
      "Batch 60, loss=0.0429, recon=0.0428, kl=1.1327, beta=0.0000\n",
      "Batch 80, loss=0.0268, recon=0.0268, kl=0.5870, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0415, KL: 1.0287, Current Beta: 0.0000) | Avg Valid Loss: 0.0360 | Avg Valid recon Loss: 0.0360\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0244, recon=0.0244, kl=0.2740, beta=0.0001\n",
      "Batch 40, loss=0.0727, recon=0.0727, kl=0.3514, beta=0.0001\n",
      "Batch 60, loss=0.0255, recon=0.0255, kl=0.2229, beta=0.0001\n",
      "Batch 80, loss=0.0289, recon=0.0289, kl=0.3581, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0399 (Recon: 0.0399, KL: 0.4130, Current Beta: 0.0001) | Avg Valid Loss: 0.0348 | Avg Valid recon Loss: 0.0348\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0291, recon=0.0290, kl=0.1798, beta=0.0001\n",
      "Batch 40, loss=0.0247, recon=0.0247, kl=0.0842, beta=0.0001\n",
      "Batch 60, loss=0.0389, recon=0.0389, kl=0.1403, beta=0.0001\n",
      "Batch 80, loss=0.0263, recon=0.0263, kl=0.0598, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0388, KL: 0.1025, Current Beta: 0.0001) | Avg Valid Loss: 0.0337 | Avg Valid recon Loss: 0.0337\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0289, recon=0.0289, kl=0.0791, beta=0.0001\n",
      "Batch 40, loss=0.0281, recon=0.0281, kl=0.0217, beta=0.0001\n",
      "Batch 60, loss=0.0271, recon=0.0270, kl=0.1349, beta=0.0001\n",
      "Batch 80, loss=0.0224, recon=0.0224, kl=0.0445, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0376, KL: 0.0793, Current Beta: 0.0001) | Avg Valid Loss: 0.0333 | Avg Valid recon Loss: 0.0333\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0271, recon=0.0271, kl=0.0375, beta=0.0001\n",
      "Batch 40, loss=0.0216, recon=0.0216, kl=0.0358, beta=0.0001\n",
      "Batch 60, loss=0.0340, recon=0.0340, kl=0.0154, beta=0.0001\n",
      "Batch 80, loss=0.0257, recon=0.0257, kl=0.0350, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0366 (Recon: 0.0366, KL: 0.0445, Current Beta: 0.0001) | Avg Valid Loss: 0.0336 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0350, recon=0.0350, kl=0.0334, beta=0.0001\n",
      "Batch 40, loss=0.0222, recon=0.0222, kl=0.0245, beta=0.0001\n",
      "Batch 60, loss=0.0236, recon=0.0236, kl=0.0184, beta=0.0001\n",
      "Batch 80, loss=0.0379, recon=0.0379, kl=0.0275, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0362, KL: 0.0405, Current Beta: 0.0001) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0318\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0271, recon=0.0271, kl=0.0109, beta=0.0001\n",
      "Batch 40, loss=0.0223, recon=0.0223, kl=0.0163, beta=0.0001\n",
      "Batch 60, loss=0.0289, recon=0.0289, kl=0.0385, beta=0.0001\n",
      "Batch 80, loss=0.0202, recon=0.0202, kl=0.0207, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0355 (Recon: 0.0355, KL: 0.0327, Current Beta: 0.0001) | Avg Valid Loss: 0.0310 | Avg Valid recon Loss: 0.0310\n",
      "\n",
      "[VRAE Run 140/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1165, recon=0.1165, kl=17.4853, beta=0.0000\n",
      "Batch 40, loss=0.0836, recon=0.0836, kl=26.2377, beta=0.0000\n",
      "Batch 60, loss=0.0552, recon=0.0552, kl=23.5344, beta=0.0000\n",
      "Batch 80, loss=0.0607, recon=0.0607, kl=29.1228, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1340 (Recon: 0.1340, KL: 22.3827, Current Beta: 0.0000) | Avg Valid Loss: 0.0601 | Avg Valid recon Loss: 0.0601\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2243, recon=0.2243, kl=32.7523, beta=0.0000\n",
      "Batch 40, loss=0.0470, recon=0.0470, kl=33.0605, beta=0.0000\n",
      "Batch 60, loss=0.1479, recon=0.1479, kl=34.7671, beta=0.0000\n",
      "Batch 80, loss=0.0364, recon=0.0364, kl=25.0444, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0625 (Recon: 0.0625, KL: 31.1375, Current Beta: 0.0000) | Avg Valid Loss: 0.0477 | Avg Valid recon Loss: 0.0477\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0403, recon=0.0403, kl=35.6591, beta=0.0000\n",
      "Batch 40, loss=0.0273, recon=0.0273, kl=35.8529, beta=0.0000\n",
      "Batch 60, loss=0.0398, recon=0.0398, kl=31.5385, beta=0.0000\n",
      "Batch 80, loss=0.0421, recon=0.0421, kl=36.9047, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0494, KL: 34.6140, Current Beta: 0.0000) | Avg Valid Loss: 0.0453 | Avg Valid recon Loss: 0.0453\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0392, recon=0.0392, kl=37.4120, beta=0.0000\n",
      "Batch 40, loss=0.0485, recon=0.0485, kl=38.2860, beta=0.0000\n",
      "Batch 60, loss=0.0251, recon=0.0251, kl=39.2735, beta=0.0000\n",
      "Batch 80, loss=0.0300, recon=0.0300, kl=34.9445, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0484 (Recon: 0.0484, KL: 36.9232, Current Beta: 0.0000) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0238, recon=0.0238, kl=33.9374, beta=0.0000\n",
      "Batch 40, loss=0.0224, recon=0.0224, kl=32.6126, beta=0.0000\n",
      "Batch 60, loss=0.0385, recon=0.0385, kl=34.5449, beta=0.0000\n",
      "Batch 80, loss=0.0310, recon=0.0310, kl=38.6905, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0411 (Recon: 0.0411, KL: 34.0366, Current Beta: 0.0000) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0384\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0365, recon=0.0365, kl=29.1282, beta=0.0000\n",
      "Batch 40, loss=0.0277, recon=0.0277, kl=34.8372, beta=0.0000\n",
      "Batch 60, loss=0.0398, recon=0.0398, kl=36.7794, beta=0.0000\n",
      "Batch 80, loss=0.0810, recon=0.0810, kl=37.6580, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0400, KL: 36.8548, Current Beta: 0.0000) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0763, recon=0.0763, kl=38.9490, beta=0.0000\n",
      "Batch 40, loss=0.0438, recon=0.0438, kl=39.5213, beta=0.0000\n",
      "Batch 60, loss=0.0247, recon=0.0247, kl=40.0399, beta=0.0000\n",
      "Batch 80, loss=0.0221, recon=0.0221, kl=40.8469, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0392, KL: 39.7120, Current Beta: 0.0000) | Avg Valid Loss: 0.0344 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0364, recon=0.0364, kl=41.6308, beta=0.0000\n",
      "Batch 40, loss=0.0338, recon=0.0338, kl=41.8621, beta=0.0000\n",
      "Batch 60, loss=0.0448, recon=0.0448, kl=41.7189, beta=0.0000\n",
      "Batch 80, loss=0.0490, recon=0.0490, kl=42.6058, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0438, KL: 41.9203, Current Beta: 0.0000) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0306, recon=0.0305, kl=42.1997, beta=0.0000\n",
      "Batch 40, loss=0.0482, recon=0.0482, kl=41.1416, beta=0.0000\n",
      "Batch 60, loss=0.0379, recon=0.0379, kl=40.6726, beta=0.0000\n",
      "Batch 80, loss=0.0368, recon=0.0368, kl=40.4061, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0378 (Recon: 0.0378, KL: 41.2620, Current Beta: 0.0000) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0250, recon=0.0250, kl=28.9747, beta=0.0000\n",
      "Batch 40, loss=0.0445, recon=0.0445, kl=28.2075, beta=0.0000\n",
      "Batch 60, loss=0.0494, recon=0.0494, kl=28.9365, beta=0.0000\n",
      "Batch 80, loss=0.0289, recon=0.0288, kl=28.7780, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 30.2287, Current Beta: 0.0000) | Avg Valid Loss: 0.0328 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0283, recon=0.0282, kl=26.1419, beta=0.0000\n",
      "Batch 40, loss=0.0766, recon=0.0765, kl=23.7272, beta=0.0000\n",
      "Batch 60, loss=0.0376, recon=0.0376, kl=21.2859, beta=0.0000\n",
      "Batch 80, loss=0.0276, recon=0.0275, kl=21.9256, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0353, KL: 23.7711, Current Beta: 0.0000) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0545, recon=0.0544, kl=17.5852, beta=0.0000\n",
      "Batch 40, loss=0.0336, recon=0.0335, kl=17.1190, beta=0.0000\n",
      "Batch 60, loss=0.0227, recon=0.0226, kl=17.5143, beta=0.0000\n",
      "Batch 80, loss=0.0231, recon=0.0230, kl=17.4809, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0402 (Recon: 0.0401, KL: 17.9408, Current Beta: 0.0000) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0346\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0265, recon=0.0263, kl=11.3432, beta=0.0000\n",
      "Batch 40, loss=0.0367, recon=0.0365, kl=8.2198, beta=0.0000\n",
      "Batch 60, loss=0.0360, recon=0.0358, kl=10.4398, beta=0.0000\n",
      "Batch 80, loss=0.0292, recon=0.0290, kl=11.3829, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0385 (Recon: 0.0383, KL: 10.7152, Current Beta: 0.0000) | Avg Valid Loss: 0.0314 | Avg Valid recon Loss: 0.0312\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0264, recon=0.0262, kl=4.8088, beta=0.0000\n",
      "Batch 40, loss=0.0330, recon=0.0328, kl=3.8437, beta=0.0000\n",
      "Batch 60, loss=0.0277, recon=0.0276, kl=3.4185, beta=0.0000\n",
      "Batch 80, loss=0.0207, recon=0.0206, kl=2.6911, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0317 (Recon: 0.0315, KL: 4.3599, Current Beta: 0.0000) | Avg Valid Loss: 0.0283 | Avg Valid recon Loss: 0.0282\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0259, recon=0.0257, kl=2.1351, beta=0.0001\n",
      "Batch 40, loss=0.0195, recon=0.0194, kl=1.1781, beta=0.0001\n",
      "Batch 60, loss=0.0206, recon=0.0205, kl=2.2395, beta=0.0001\n",
      "Batch 80, loss=0.0346, recon=0.0344, kl=2.1661, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0308 (Recon: 0.0306, KL: 2.0211, Current Beta: 0.0001) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0306\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0202, recon=0.0201, kl=0.2209, beta=0.0001\n",
      "Batch 40, loss=0.0690, recon=0.0690, kl=0.5370, beta=0.0001\n",
      "Batch 60, loss=0.0169, recon=0.0168, kl=0.5917, beta=0.0001\n",
      "Batch 80, loss=0.0285, recon=0.0285, kl=0.2819, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0286 (Recon: 0.0285, KL: 0.4763, Current Beta: 0.0001) | Avg Valid Loss: 0.0269 | Avg Valid recon Loss: 0.0269\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0239, recon=0.0239, kl=0.3867, beta=0.0001\n",
      "Batch 40, loss=0.0176, recon=0.0176, kl=0.3985, beta=0.0001\n",
      "Batch 60, loss=0.0210, recon=0.0209, kl=0.4949, beta=0.0001\n",
      "Batch 80, loss=0.0281, recon=0.0278, kl=2.2919, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0342 (Recon: 0.0341, KL: 0.8196, Current Beta: 0.0001) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0425, recon=0.0424, kl=1.4495, beta=0.0001\n",
      "Batch 40, loss=0.0361, recon=0.0360, kl=0.5163, beta=0.0001\n",
      "Batch 60, loss=0.0226, recon=0.0226, kl=0.5438, beta=0.0001\n",
      "Batch 80, loss=0.0316, recon=0.0315, kl=0.5308, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0326 (Recon: 0.0325, KL: 1.0462, Current Beta: 0.0001) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0217, recon=0.0217, kl=0.4255, beta=0.0001\n",
      "Batch 40, loss=0.0529, recon=0.0528, kl=0.2333, beta=0.0001\n",
      "Batch 60, loss=0.0171, recon=0.0171, kl=0.1738, beta=0.0001\n",
      "Batch 80, loss=0.0300, recon=0.0300, kl=0.5010, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0310 (Recon: 0.0309, KL: 0.3673, Current Beta: 0.0001) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 141/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3771, recon=0.3771, kl=4.8140, beta=0.0000\n",
      "Batch 40, loss=0.2412, recon=0.2412, kl=39.7234, beta=0.0000\n",
      "Batch 60, loss=0.1881, recon=0.1881, kl=56.3219, beta=0.0000\n",
      "Batch 80, loss=0.1295, recon=0.1295, kl=59.5553, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2867 (Recon: 0.2867, KL: 36.4126, Current Beta: 0.0000) | Avg Valid Loss: 0.1254 | Avg Valid recon Loss: 0.1254\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0967, recon=0.0967, kl=69.4677, beta=0.0000\n",
      "Batch 40, loss=0.0962, recon=0.0962, kl=77.5695, beta=0.0000\n",
      "Batch 60, loss=0.1224, recon=0.1224, kl=83.0951, beta=0.0000\n",
      "Batch 80, loss=0.0887, recon=0.0887, kl=82.9382, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1294 (Recon: 0.1294, KL: 76.4643, Current Beta: 0.0000) | Avg Valid Loss: 0.0907 | Avg Valid recon Loss: 0.0907\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0775, recon=0.0775, kl=85.3428, beta=0.0000\n",
      "Batch 40, loss=0.0868, recon=0.0868, kl=87.6425, beta=0.0000\n",
      "Batch 60, loss=0.0600, recon=0.0600, kl=96.2865, beta=0.0000\n",
      "Batch 80, loss=0.0654, recon=0.0654, kl=96.8312, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0959 (Recon: 0.0959, KL: 90.6735, Current Beta: 0.0000) | Avg Valid Loss: 0.0698 | Avg Valid recon Loss: 0.0698\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0901, recon=0.0901, kl=105.6269, beta=0.0000\n",
      "Batch 40, loss=0.0505, recon=0.0505, kl=108.1494, beta=0.0000\n",
      "Batch 60, loss=0.0941, recon=0.0941, kl=107.3857, beta=0.0000\n",
      "Batch 80, loss=0.0528, recon=0.0528, kl=112.8460, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0781 (Recon: 0.0781, KL: 107.5009, Current Beta: 0.0000) | Avg Valid Loss: 0.0632 | Avg Valid recon Loss: 0.0632\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0594, recon=0.0594, kl=108.4218, beta=0.0000\n",
      "Batch 40, loss=0.0426, recon=0.0426, kl=107.2275, beta=0.0000\n",
      "Batch 60, loss=0.0505, recon=0.0504, kl=110.0300, beta=0.0000\n",
      "Batch 80, loss=0.0578, recon=0.0578, kl=107.0997, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0689 (Recon: 0.0688, KL: 108.4760, Current Beta: 0.0000) | Avg Valid Loss: 0.0555 | Avg Valid recon Loss: 0.0555\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0574, recon=0.0574, kl=107.4330, beta=0.0000\n",
      "Batch 40, loss=0.0371, recon=0.0371, kl=105.9831, beta=0.0000\n",
      "Batch 60, loss=0.0401, recon=0.0401, kl=104.8248, beta=0.0000\n",
      "Batch 80, loss=0.0334, recon=0.0334, kl=105.2176, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0618 (Recon: 0.0618, KL: 106.3441, Current Beta: 0.0000) | Avg Valid Loss: 0.0509 | Avg Valid recon Loss: 0.0509\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0457, recon=0.0457, kl=102.9891, beta=0.0000\n",
      "Batch 40, loss=0.1197, recon=0.1197, kl=99.6190, beta=0.0000\n",
      "Batch 60, loss=0.0279, recon=0.0279, kl=93.8968, beta=0.0000\n",
      "Batch 80, loss=0.0440, recon=0.0440, kl=91.2600, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0565 (Recon: 0.0564, KL: 98.3957, Current Beta: 0.0000) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0480\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0369, recon=0.0369, kl=77.8314, beta=0.0000\n",
      "Batch 40, loss=0.0430, recon=0.0430, kl=75.7347, beta=0.0000\n",
      "Batch 60, loss=0.0399, recon=0.0399, kl=69.7151, beta=0.0000\n",
      "Batch 80, loss=0.0382, recon=0.0382, kl=68.2284, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0523, KL: 75.4580, Current Beta: 0.0000) | Avg Valid Loss: 0.0443 | Avg Valid recon Loss: 0.0442\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0328, recon=0.0328, kl=57.4980, beta=0.0000\n",
      "Batch 40, loss=0.0422, recon=0.0422, kl=51.0422, beta=0.0000\n",
      "Batch 60, loss=0.0467, recon=0.0467, kl=54.7965, beta=0.0000\n",
      "Batch 80, loss=0.0350, recon=0.0349, kl=49.7139, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0490 (Recon: 0.0489, KL: 54.6075, Current Beta: 0.0000) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0280, recon=0.0279, kl=34.6360, beta=0.0000\n",
      "Batch 40, loss=0.0405, recon=0.0405, kl=33.5789, beta=0.0000\n",
      "Batch 60, loss=0.0283, recon=0.0283, kl=33.2797, beta=0.0000\n",
      "Batch 80, loss=0.0364, recon=0.0364, kl=29.1428, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0462, KL: 34.1642, Current Beta: 0.0000) | Avg Valid Loss: 0.0406 | Avg Valid recon Loss: 0.0406\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=16.2961, beta=0.0000\n",
      "Batch 40, loss=0.0271, recon=0.0270, kl=16.9853, beta=0.0000\n",
      "Batch 60, loss=0.0365, recon=0.0365, kl=16.1843, beta=0.0000\n",
      "Batch 80, loss=0.0352, recon=0.0351, kl=12.8794, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0444 (Recon: 0.0444, KL: 17.1191, Current Beta: 0.0000) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0319, recon=0.0319, kl=5.8096, beta=0.0000\n",
      "Batch 40, loss=0.0233, recon=0.0232, kl=7.7388, beta=0.0000\n",
      "Batch 60, loss=0.0313, recon=0.0312, kl=7.8597, beta=0.0000\n",
      "Batch 80, loss=0.0268, recon=0.0268, kl=5.4599, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0423, KL: 7.2524, Current Beta: 0.0000) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0258, recon=0.0257, kl=2.6409, beta=0.0000\n",
      "Batch 40, loss=0.0261, recon=0.0261, kl=2.8453, beta=0.0000\n",
      "Batch 60, loss=0.0301, recon=0.0301, kl=2.4921, beta=0.0000\n",
      "Batch 80, loss=0.0346, recon=0.0345, kl=3.3605, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0409, KL: 2.9466, Current Beta: 0.0000) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0269, recon=0.0269, kl=1.1555, beta=0.0000\n",
      "Batch 40, loss=0.0264, recon=0.0263, kl=1.4044, beta=0.0000\n",
      "Batch 60, loss=0.0270, recon=0.0270, kl=1.2780, beta=0.0000\n",
      "Batch 80, loss=0.0303, recon=0.0302, kl=1.4116, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0394, KL: 1.4872, Current Beta: 0.0000) | Avg Valid Loss: 0.0350 | Avg Valid recon Loss: 0.0349\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0357, recon=0.0357, kl=0.5535, beta=0.0001\n",
      "Batch 40, loss=0.0359, recon=0.0359, kl=0.5409, beta=0.0001\n",
      "Batch 60, loss=0.0368, recon=0.0367, kl=0.7771, beta=0.0001\n",
      "Batch 80, loss=0.0311, recon=0.0310, kl=0.5275, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0385, KL: 0.6358, Current Beta: 0.0001) | Avg Valid Loss: 0.0344 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0297, recon=0.0297, kl=0.2150, beta=0.0001\n",
      "Batch 40, loss=0.0364, recon=0.0364, kl=0.2805, beta=0.0001\n",
      "Batch 60, loss=0.0814, recon=0.0814, kl=0.1205, beta=0.0001\n",
      "Batch 80, loss=0.0295, recon=0.0294, kl=0.1973, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0373 (Recon: 0.0373, KL: 0.2280, Current Beta: 0.0001) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0332\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0222, recon=0.0221, kl=0.2196, beta=0.0001\n",
      "Batch 40, loss=0.0568, recon=0.0568, kl=0.1060, beta=0.0001\n",
      "Batch 60, loss=0.0490, recon=0.0489, kl=0.0826, beta=0.0001\n",
      "Batch 80, loss=0.0355, recon=0.0355, kl=0.2073, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0367 (Recon: 0.0366, KL: 0.1408, Current Beta: 0.0001) | Avg Valid Loss: 0.0325 | Avg Valid recon Loss: 0.0325\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0282, recon=0.0281, kl=0.0695, beta=0.0001\n",
      "Batch 40, loss=0.0321, recon=0.0321, kl=0.0611, beta=0.0001\n",
      "Batch 60, loss=0.0247, recon=0.0247, kl=0.0651, beta=0.0001\n",
      "Batch 80, loss=0.0415, recon=0.0415, kl=0.0810, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0358, KL: 0.0747, Current Beta: 0.0001) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0206, recon=0.0206, kl=0.0549, beta=0.0001\n",
      "Batch 40, loss=0.0388, recon=0.0388, kl=0.0429, beta=0.0001\n",
      "Batch 60, loss=0.0305, recon=0.0305, kl=0.0500, beta=0.0001\n",
      "Batch 80, loss=0.0329, recon=0.0329, kl=0.1010, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0353 (Recon: 0.0353, KL: 0.0793, Current Beta: 0.0001) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0307\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0203, recon=0.0203, kl=0.0313, beta=0.0001\n",
      "Batch 40, loss=0.0230, recon=0.0230, kl=0.0659, beta=0.0001\n",
      "Batch 60, loss=0.0244, recon=0.0244, kl=0.0269, beta=0.0001\n",
      "Batch 80, loss=0.0244, recon=0.0244, kl=0.0373, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0344 (Recon: 0.0344, KL: 0.0425, Current Beta: 0.0001) | Avg Valid Loss: 0.0308 | Avg Valid recon Loss: 0.0307\n",
      "\n",
      "[VRAE Run 142/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1636, recon=0.1636, kl=34.0115, beta=0.0000\n",
      "Batch 40, loss=0.2026, recon=0.2026, kl=47.5812, beta=0.0000\n",
      "Batch 60, loss=0.1266, recon=0.1266, kl=62.6418, beta=0.0000\n",
      "Batch 80, loss=0.0990, recon=0.0990, kl=55.8381, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1455 (Recon: 0.1455, KL: 46.2138, Current Beta: 0.0000) | Avg Valid Loss: 0.0654 | Avg Valid recon Loss: 0.0654\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0457, recon=0.0457, kl=61.3817, beta=0.0000\n",
      "Batch 40, loss=0.0480, recon=0.0480, kl=60.4956, beta=0.0000\n",
      "Batch 60, loss=0.0606, recon=0.0606, kl=61.1027, beta=0.0000\n",
      "Batch 80, loss=0.0691, recon=0.0691, kl=67.6872, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0636 (Recon: 0.0636, KL: 62.7536, Current Beta: 0.0000) | Avg Valid Loss: 0.0577 | Avg Valid recon Loss: 0.0577\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0358, recon=0.0358, kl=59.3243, beta=0.0000\n",
      "Batch 40, loss=0.0417, recon=0.0417, kl=53.1958, beta=0.0000\n",
      "Batch 60, loss=0.0285, recon=0.0285, kl=62.3093, beta=0.0000\n",
      "Batch 80, loss=0.0328, recon=0.0328, kl=64.5383, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0562 (Recon: 0.0562, KL: 60.7067, Current Beta: 0.0000) | Avg Valid Loss: 0.0468 | Avg Valid recon Loss: 0.0468\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0319, recon=0.0319, kl=74.6747, beta=0.0000\n",
      "Batch 40, loss=0.0373, recon=0.0373, kl=75.2016, beta=0.0000\n",
      "Batch 60, loss=0.0372, recon=0.0372, kl=94.7112, beta=0.0000\n",
      "Batch 80, loss=0.0249, recon=0.0249, kl=54.3364, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0469, KL: 80.0090, Current Beta: 0.0000) | Avg Valid Loss: 0.0359 | Avg Valid recon Loss: 0.0359\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0347, recon=0.0347, kl=86.2505, beta=0.0000\n",
      "Batch 40, loss=0.0270, recon=0.0270, kl=80.2667, beta=0.0000\n",
      "Batch 60, loss=0.0202, recon=0.0202, kl=81.5619, beta=0.0000\n",
      "Batch 80, loss=0.0299, recon=0.0299, kl=63.0796, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0390, KL: 78.3432, Current Beta: 0.0000) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0824, recon=0.0824, kl=80.1905, beta=0.0000\n",
      "Batch 40, loss=0.0332, recon=0.0332, kl=50.2025, beta=0.0000\n",
      "Batch 60, loss=0.0292, recon=0.0292, kl=77.5534, beta=0.0000\n",
      "Batch 80, loss=0.0403, recon=0.0403, kl=69.9583, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 70.1614, Current Beta: 0.0000) | Avg Valid Loss: 0.0315 | Avg Valid recon Loss: 0.0315\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0337, recon=0.0337, kl=75.1844, beta=0.0000\n",
      "Batch 40, loss=0.0330, recon=0.0330, kl=65.1607, beta=0.0000\n",
      "Batch 60, loss=0.0274, recon=0.0274, kl=67.6367, beta=0.0000\n",
      "Batch 80, loss=0.0216, recon=0.0216, kl=68.5626, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0380 (Recon: 0.0380, KL: 70.9535, Current Beta: 0.0000) | Avg Valid Loss: 0.0314 | Avg Valid recon Loss: 0.0314\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0256, recon=0.0256, kl=71.0196, beta=0.0000\n",
      "Batch 40, loss=0.0342, recon=0.0342, kl=62.0354, beta=0.0000\n",
      "Batch 60, loss=0.0221, recon=0.0221, kl=71.5896, beta=0.0000\n",
      "Batch 80, loss=0.0213, recon=0.0213, kl=61.9575, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0386, KL: 66.6343, Current Beta: 0.0000) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0466\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0438, recon=0.0438, kl=56.7785, beta=0.0000\n",
      "Batch 40, loss=0.0325, recon=0.0325, kl=56.9102, beta=0.0000\n",
      "Batch 60, loss=0.0252, recon=0.0252, kl=68.7767, beta=0.0000\n",
      "Batch 80, loss=0.0555, recon=0.0555, kl=74.5745, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0430, KL: 63.4895, Current Beta: 0.0000) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.3570, recon=0.3569, kl=56.8689, beta=0.0000\n",
      "Batch 40, loss=0.0557, recon=0.0557, kl=27.9602, beta=0.0000\n",
      "Batch 60, loss=0.0517, recon=0.0516, kl=56.8716, beta=0.0000\n",
      "Batch 80, loss=0.0306, recon=0.0306, kl=62.3688, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0677 (Recon: 0.0677, KL: 56.2372, Current Beta: 0.0000) | Avg Valid Loss: 0.0404 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0277, recon=0.0276, kl=52.0768, beta=0.0000\n",
      "Batch 40, loss=0.0179, recon=0.0178, kl=43.9996, beta=0.0000\n",
      "Batch 60, loss=0.0253, recon=0.0252, kl=43.3810, beta=0.0000\n",
      "Batch 80, loss=0.0384, recon=0.0383, kl=46.2542, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0412 (Recon: 0.0411, KL: 48.4302, Current Beta: 0.0000) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0400\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0603, recon=0.0600, kl=34.6592, beta=0.0000\n",
      "Batch 40, loss=0.0300, recon=0.0297, kl=40.6078, beta=0.0000\n",
      "Batch 60, loss=0.0289, recon=0.0286, kl=31.4366, beta=0.0000\n",
      "Batch 80, loss=0.0273, recon=0.0270, kl=34.3765, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0447 (Recon: 0.0444, KL: 36.8508, Current Beta: 0.0000) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0292, recon=0.0289, kl=17.6735, beta=0.0000\n",
      "Batch 40, loss=0.0329, recon=0.0325, kl=17.2609, beta=0.0000\n",
      "Batch 60, loss=0.0317, recon=0.0314, kl=16.2541, beta=0.0000\n",
      "Batch 80, loss=0.0260, recon=0.0257, kl=15.4375, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0346 (Recon: 0.0342, KL: 17.9631, Current Beta: 0.0000) | Avg Valid Loss: 0.0335 | Avg Valid recon Loss: 0.0332\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.2632, recon=0.2628, kl=9.4323, beta=0.0000\n",
      "Batch 40, loss=0.0286, recon=0.0282, kl=9.2396, beta=0.0000\n",
      "Batch 60, loss=0.0311, recon=0.0307, kl=11.1262, beta=0.0000\n",
      "Batch 80, loss=0.0237, recon=0.0232, kl=11.4917, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0426, KL: 10.5099, Current Beta: 0.0000) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0344, recon=0.0339, kl=7.6493, beta=0.0001\n",
      "Batch 40, loss=0.0366, recon=0.0342, kl=39.3235, beta=0.0001\n",
      "Batch 60, loss=0.0362, recon=0.0349, kl=20.6694, beta=0.0001\n",
      "Batch 80, loss=0.0219, recon=0.0207, kl=18.9797, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0378, KL: 16.4041, Current Beta: 0.0001) | Avg Valid Loss: 0.0453 | Avg Valid recon Loss: 0.0442\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0422, recon=0.0407, kl=14.9952, beta=0.0001\n",
      "Batch 40, loss=0.0716, recon=0.0703, kl=13.5658, beta=0.0001\n",
      "Batch 60, loss=0.0457, recon=0.0425, kl=31.8614, beta=0.0001\n",
      "Batch 80, loss=0.0409, recon=0.0388, kl=21.3891, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0443, KL: 19.4846, Current Beta: 0.0001) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0245, recon=0.0231, kl=13.7884, beta=0.0001\n",
      "Batch 40, loss=0.0238, recon=0.0228, kl=10.4252, beta=0.0001\n",
      "Batch 60, loss=0.0401, recon=0.0390, kl=11.5432, beta=0.0001\n",
      "Batch 80, loss=0.0546, recon=0.0536, kl=10.1084, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0358, KL: 12.2028, Current Beta: 0.0001) | Avg Valid Loss: 0.0328 | Avg Valid recon Loss: 0.0318\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0772, recon=0.0763, kl=8.8361, beta=0.0001\n",
      "Batch 40, loss=0.0235, recon=0.0227, kl=7.8026, beta=0.0001\n",
      "Batch 60, loss=0.0200, recon=0.0193, kl=6.6180, beta=0.0001\n",
      "Batch 80, loss=0.0294, recon=0.0284, kl=9.2542, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0338 (Recon: 0.0330, KL: 8.3336, Current Beta: 0.0001) | Avg Valid Loss: 0.0315 | Avg Valid recon Loss: 0.0305\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0279, recon=0.0268, kl=11.2255, beta=0.0001\n",
      "Batch 40, loss=0.0348, recon=0.0337, kl=10.8994, beta=0.0001\n",
      "Batch 60, loss=0.0328, recon=0.0319, kl=9.6553, beta=0.0001\n",
      "Batch 80, loss=0.0192, recon=0.0184, kl=8.4035, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0363 (Recon: 0.0353, KL: 9.8557, Current Beta: 0.0001) | Avg Valid Loss: 0.0282 | Avg Valid recon Loss: 0.0274\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0268, recon=0.0262, kl=6.7558, beta=0.0001\n",
      "Batch 40, loss=0.0269, recon=0.0263, kl=6.9636, beta=0.0001\n",
      "Batch 60, loss=0.0213, recon=0.0206, kl=6.8332, beta=0.0001\n",
      "Batch 80, loss=0.0264, recon=0.0257, kl=6.5173, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0338 (Recon: 0.0331, KL: 6.8518, Current Beta: 0.0001) | Avg Valid Loss: 0.0301 | Avg Valid recon Loss: 0.0294\n",
      "\n",
      "[VRAE Run 143/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3805, recon=0.3805, kl=13.1105, beta=0.0000\n",
      "Batch 40, loss=0.2104, recon=0.2104, kl=86.8754, beta=0.0000\n",
      "Batch 60, loss=0.1267, recon=0.1267, kl=115.6261, beta=0.0000\n",
      "Batch 80, loss=0.1250, recon=0.1250, kl=145.4246, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2944 (Recon: 0.2944, KL: 82.2235, Current Beta: 0.0000) | Avg Valid Loss: 0.1204 | Avg Valid recon Loss: 0.1204\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1002, recon=0.1002, kl=177.4647, beta=0.0000\n",
      "Batch 40, loss=0.1042, recon=0.1042, kl=173.2303, beta=0.0000\n",
      "Batch 60, loss=0.1147, recon=0.1147, kl=165.3541, beta=0.0000\n",
      "Batch 80, loss=0.0781, recon=0.0781, kl=165.2469, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1277 (Recon: 0.1277, KL: 170.2700, Current Beta: 0.0000) | Avg Valid Loss: 0.0873 | Avg Valid recon Loss: 0.0873\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0857, recon=0.0857, kl=178.6656, beta=0.0000\n",
      "Batch 40, loss=0.1461, recon=0.1461, kl=178.5786, beta=0.0000\n",
      "Batch 60, loss=0.1016, recon=0.1016, kl=180.8771, beta=0.0000\n",
      "Batch 80, loss=0.0751, recon=0.0751, kl=180.6485, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0963 (Recon: 0.0963, KL: 179.0849, Current Beta: 0.0000) | Avg Valid Loss: 0.0714 | Avg Valid recon Loss: 0.0714\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0987, recon=0.0987, kl=180.7302, beta=0.0000\n",
      "Batch 40, loss=0.0605, recon=0.0605, kl=191.6422, beta=0.0000\n",
      "Batch 60, loss=0.0547, recon=0.0547, kl=186.1960, beta=0.0000\n",
      "Batch 80, loss=0.1792, recon=0.1792, kl=188.9915, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0798 (Recon: 0.0798, KL: 186.0501, Current Beta: 0.0000) | Avg Valid Loss: 0.0628 | Avg Valid recon Loss: 0.0628\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0555, recon=0.0555, kl=192.4929, beta=0.0000\n",
      "Batch 40, loss=0.0563, recon=0.0563, kl=195.4269, beta=0.0000\n",
      "Batch 60, loss=0.0411, recon=0.0411, kl=196.0637, beta=0.0000\n",
      "Batch 80, loss=0.0566, recon=0.0566, kl=192.3670, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0703 (Recon: 0.0703, KL: 193.7799, Current Beta: 0.0000) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0574\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0580, recon=0.0580, kl=195.0653, beta=0.0000\n",
      "Batch 40, loss=0.0545, recon=0.0545, kl=191.0770, beta=0.0000\n",
      "Batch 60, loss=0.0680, recon=0.0680, kl=191.9123, beta=0.0000\n",
      "Batch 80, loss=0.0435, recon=0.0435, kl=190.5083, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0632 (Recon: 0.0632, KL: 192.4743, Current Beta: 0.0000) | Avg Valid Loss: 0.0518 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0540, recon=0.0540, kl=182.1957, beta=0.0000\n",
      "Batch 40, loss=0.0991, recon=0.0991, kl=175.7255, beta=0.0000\n",
      "Batch 60, loss=0.0572, recon=0.0572, kl=168.3102, beta=0.0000\n",
      "Batch 80, loss=0.0375, recon=0.0375, kl=170.0798, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0582 (Recon: 0.0582, KL: 176.2780, Current Beta: 0.0000) | Avg Valid Loss: 0.0492 | Avg Valid recon Loss: 0.0492\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=157.2362, beta=0.0000\n",
      "Batch 40, loss=0.0409, recon=0.0409, kl=136.8126, beta=0.0000\n",
      "Batch 60, loss=0.0318, recon=0.0318, kl=128.4986, beta=0.0000\n",
      "Batch 80, loss=0.0490, recon=0.0490, kl=132.6172, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0538 (Recon: 0.0538, KL: 141.6467, Current Beta: 0.0000) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0466\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0357, recon=0.0357, kl=97.2316, beta=0.0000\n",
      "Batch 40, loss=0.0297, recon=0.0297, kl=88.0613, beta=0.0000\n",
      "Batch 60, loss=0.0710, recon=0.0710, kl=88.8798, beta=0.0000\n",
      "Batch 80, loss=0.0553, recon=0.0552, kl=85.0200, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0503 (Recon: 0.0503, KL: 94.6200, Current Beta: 0.0000) | Avg Valid Loss: 0.0434 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0453, recon=0.0452, kl=57.4903, beta=0.0000\n",
      "Batch 40, loss=0.0343, recon=0.0342, kl=46.6469, beta=0.0000\n",
      "Batch 60, loss=0.0425, recon=0.0424, kl=44.3265, beta=0.0000\n",
      "Batch 80, loss=0.0274, recon=0.0273, kl=51.2688, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0478 (Recon: 0.0478, KL: 53.6469, Current Beta: 0.0000) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0476, recon=0.0476, kl=21.8280, beta=0.0000\n",
      "Batch 40, loss=0.0277, recon=0.0276, kl=22.2254, beta=0.0000\n",
      "Batch 60, loss=0.0399, recon=0.0398, kl=20.9187, beta=0.0000\n",
      "Batch 80, loss=0.0314, recon=0.0313, kl=20.6246, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0454, KL: 23.8659, Current Beta: 0.0000) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0339, recon=0.0338, kl=8.0443, beta=0.0000\n",
      "Batch 40, loss=0.0288, recon=0.0288, kl=8.9539, beta=0.0000\n",
      "Batch 60, loss=0.0275, recon=0.0275, kl=7.9596, beta=0.0000\n",
      "Batch 80, loss=0.0345, recon=0.0344, kl=8.6059, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0432, KL: 9.3769, Current Beta: 0.0000) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.3468, recon=0.3467, kl=4.5287, beta=0.0000\n",
      "Batch 40, loss=0.0508, recon=0.0507, kl=3.1490, beta=0.0000\n",
      "Batch 60, loss=0.0780, recon=0.0779, kl=3.2576, beta=0.0000\n",
      "Batch 80, loss=0.0368, recon=0.0368, kl=2.9532, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0420, KL: 3.7503, Current Beta: 0.0000) | Avg Valid Loss: 0.0367 | Avg Valid recon Loss: 0.0366\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0430, recon=0.0430, kl=1.2408, beta=0.0000\n",
      "Batch 40, loss=0.0390, recon=0.0389, kl=1.1654, beta=0.0000\n",
      "Batch 60, loss=0.0265, recon=0.0265, kl=1.3724, beta=0.0000\n",
      "Batch 80, loss=0.0302, recon=0.0301, kl=1.4557, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0404 (Recon: 0.0404, KL: 1.5498, Current Beta: 0.0000) | Avg Valid Loss: 0.0354 | Avg Valid recon Loss: 0.0354\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0238, recon=0.0237, kl=0.8704, beta=0.0001\n",
      "Batch 40, loss=0.0305, recon=0.0304, kl=0.7622, beta=0.0001\n",
      "Batch 60, loss=0.0314, recon=0.0313, kl=0.5833, beta=0.0001\n",
      "Batch 80, loss=0.0223, recon=0.0222, kl=0.7044, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0394 (Recon: 0.0394, KL: 0.8895, Current Beta: 0.0001) | Avg Valid Loss: 0.0343 | Avg Valid recon Loss: 0.0343\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0223, recon=0.0223, kl=0.2212, beta=0.0001\n",
      "Batch 40, loss=0.0329, recon=0.0329, kl=0.2699, beta=0.0001\n",
      "Batch 60, loss=0.0293, recon=0.0293, kl=0.2630, beta=0.0001\n",
      "Batch 80, loss=0.0396, recon=0.0396, kl=0.2121, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0382, KL: 0.3156, Current Beta: 0.0001) | Avg Valid Loss: 0.0340 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0309, recon=0.0309, kl=0.1818, beta=0.0001\n",
      "Batch 40, loss=0.0403, recon=0.0403, kl=0.1859, beta=0.0001\n",
      "Batch 60, loss=0.0243, recon=0.0242, kl=0.1436, beta=0.0001\n",
      "Batch 80, loss=0.0904, recon=0.0904, kl=0.1323, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0374 (Recon: 0.0374, KL: 0.1718, Current Beta: 0.0001) | Avg Valid Loss: 0.0333 | Avg Valid recon Loss: 0.0333\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.2678, recon=0.2678, kl=0.1011, beta=0.0001\n",
      "Batch 40, loss=0.0321, recon=0.0321, kl=0.0646, beta=0.0001\n",
      "Batch 60, loss=0.0226, recon=0.0225, kl=0.1886, beta=0.0001\n",
      "Batch 80, loss=0.0488, recon=0.0488, kl=0.0680, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0364 (Recon: 0.0364, KL: 0.0992, Current Beta: 0.0001) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0246, recon=0.0246, kl=0.0979, beta=0.0001\n",
      "Batch 40, loss=0.0253, recon=0.0253, kl=0.0789, beta=0.0001\n",
      "Batch 60, loss=0.0602, recon=0.0602, kl=0.0426, beta=0.0001\n",
      "Batch 80, loss=0.0340, recon=0.0340, kl=0.0524, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0360 (Recon: 0.0359, KL: 0.0707, Current Beta: 0.0001) | Avg Valid Loss: 0.0316 | Avg Valid recon Loss: 0.0316\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0246, recon=0.0245, kl=0.0435, beta=0.0001\n",
      "Batch 40, loss=0.0375, recon=0.0375, kl=0.0555, beta=0.0001\n",
      "Batch 60, loss=0.1304, recon=0.1304, kl=0.0610, beta=0.0001\n",
      "Batch 80, loss=0.0365, recon=0.0364, kl=0.0449, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0353 (Recon: 0.0353, KL: 0.0514, Current Beta: 0.0001) | Avg Valid Loss: 0.0314 | Avg Valid recon Loss: 0.0314\n",
      "\n",
      "[VRAE Run 144/324] Training with params: {'batch_size': 64, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1291, recon=0.1291, kl=70.6185, beta=0.0000\n",
      "Batch 40, loss=0.0639, recon=0.0639, kl=96.1268, beta=0.0000\n",
      "Batch 60, loss=0.0698, recon=0.0698, kl=121.6271, beta=0.0000\n",
      "Batch 80, loss=0.0861, recon=0.0861, kl=97.3593, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1368 (Recon: 0.1368, KL: 87.7341, Current Beta: 0.0000) | Avg Valid Loss: 0.0817 | Avg Valid recon Loss: 0.0817\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0380, recon=0.0380, kl=114.6257, beta=0.0000\n",
      "Batch 40, loss=0.0404, recon=0.0404, kl=117.8315, beta=0.0000\n",
      "Batch 60, loss=0.0272, recon=0.0272, kl=128.3959, beta=0.0000\n",
      "Batch 80, loss=0.0430, recon=0.0430, kl=71.2535, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0648 (Recon: 0.0648, KL: 109.0941, Current Beta: 0.0000) | Avg Valid Loss: 0.0540 | Avg Valid recon Loss: 0.0540\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0618, recon=0.0618, kl=137.5338, beta=0.0000\n",
      "Batch 40, loss=0.0456, recon=0.0456, kl=134.9682, beta=0.0000\n",
      "Batch 60, loss=0.0318, recon=0.0318, kl=146.6563, beta=0.0000\n",
      "Batch 80, loss=0.0472, recon=0.0472, kl=154.4341, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 141.6260, Current Beta: 0.0000) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0402, recon=0.0402, kl=164.5947, beta=0.0000\n",
      "Batch 40, loss=0.0461, recon=0.0461, kl=169.3047, beta=0.0000\n",
      "Batch 60, loss=0.1015, recon=0.1015, kl=108.6155, beta=0.0000\n",
      "Batch 80, loss=0.0566, recon=0.0566, kl=136.6167, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0487 (Recon: 0.0487, KL: 144.0673, Current Beta: 0.0000) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0303, recon=0.0303, kl=158.6959, beta=0.0000\n",
      "Batch 40, loss=0.0385, recon=0.0385, kl=156.4674, beta=0.0000\n",
      "Batch 60, loss=0.0426, recon=0.0426, kl=142.2899, beta=0.0000\n",
      "Batch 80, loss=0.0436, recon=0.0436, kl=161.0861, beta=0.0000\n",
      "  â†’ Avg Train Loss: 6770854.3940 (Recon: 6770854.3919, KL: 12235032.2029, Current Beta: 0.0000) | Avg Valid Loss: 0.0481 | Avg Valid recon Loss: 0.0481\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0538, recon=0.0538, kl=123.8342, beta=0.0000\n",
      "Batch 40, loss=0.0250, recon=0.0250, kl=95.5012, beta=0.0000\n",
      "Batch 60, loss=0.0328, recon=0.0328, kl=113.1556, beta=0.0000\n",
      "Batch 80, loss=0.0305, recon=0.0305, kl=124.4464, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0468 (Recon: 0.0468, KL: 121.3131, Current Beta: 0.0000) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=135.9140, beta=0.0000\n",
      "Batch 40, loss=0.0366, recon=0.0366, kl=135.3822, beta=0.0000\n",
      "Batch 60, loss=0.0680, recon=0.0679, kl=140.7615, beta=0.0000\n",
      "Batch 80, loss=0.0309, recon=0.0309, kl=142.4109, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0428, KL: 136.9741, Current Beta: 0.0000) | Avg Valid Loss: 0.0359 | Avg Valid recon Loss: 0.0359\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0480, recon=0.0479, kl=142.2573, beta=0.0000\n",
      "Batch 40, loss=0.0236, recon=0.0236, kl=144.9397, beta=0.0000\n",
      "Batch 60, loss=0.0329, recon=0.0329, kl=146.4412, beta=0.0000\n",
      "Batch 80, loss=0.0349, recon=0.0349, kl=150.9530, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0352 (Recon: 0.0352, KL: 145.3942, Current Beta: 0.0000) | Avg Valid Loss: 0.0313 | Avg Valid recon Loss: 0.0313\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0391, recon=0.0390, kl=149.6443, beta=0.0000\n",
      "Batch 40, loss=0.0495, recon=0.0494, kl=149.6034, beta=0.0000\n",
      "Batch 60, loss=0.0202, recon=0.0202, kl=150.1922, beta=0.0000\n",
      "Batch 80, loss=0.0251, recon=0.0250, kl=151.7901, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0364 (Recon: 0.0363, KL: 150.0517, Current Beta: 0.0000) | Avg Valid Loss: 0.0331 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0615, recon=0.0613, kl=148.1902, beta=0.0000\n",
      "Batch 40, loss=0.0539, recon=0.0537, kl=145.8197, beta=0.0000\n",
      "Batch 60, loss=0.0539, recon=0.0537, kl=139.9125, beta=0.0000\n",
      "Batch 80, loss=0.0556, recon=0.0555, kl=134.1081, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0432, KL: 141.9755, Current Beta: 0.0000) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0439\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0276, recon=0.0272, kl=129.2141, beta=0.0000\n",
      "Batch 40, loss=0.0322, recon=0.0319, kl=115.8346, beta=0.0000\n",
      "Batch 60, loss=0.0430, recon=0.0427, kl=110.3694, beta=0.0000\n",
      "Batch 80, loss=0.0239, recon=0.0236, kl=104.8974, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0397 (Recon: 0.0394, KL: 117.3408, Current Beta: 0.0000) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0280, recon=0.0273, kl=93.6237, beta=0.0000\n",
      "Batch 40, loss=0.0348, recon=0.0341, kl=83.3869, beta=0.0000\n",
      "Batch 60, loss=0.0254, recon=0.0248, kl=77.8876, beta=0.0000\n",
      "Batch 80, loss=0.0337, recon=0.0331, kl=74.8597, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0375 (Recon: 0.0369, KL: 85.2152, Current Beta: 0.0000) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0235, recon=0.0224, kl=61.3886, beta=0.0000\n",
      "Batch 40, loss=0.0461, recon=0.0451, kl=55.4473, beta=0.0000\n",
      "Batch 60, loss=0.0441, recon=0.0431, kl=52.6388, beta=0.0000\n",
      "Batch 80, loss=0.0296, recon=0.0286, kl=52.9388, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0380, KL: 57.7446, Current Beta: 0.0000) | Avg Valid Loss: 0.0365 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0212, recon=0.0200, kl=31.8527, beta=0.0000\n",
      "Batch 40, loss=0.0282, recon=0.0270, kl=30.1947, beta=0.0000\n",
      "Batch 60, loss=0.0425, recon=0.0415, kl=27.6203, beta=0.0000\n",
      "Batch 80, loss=1.8280, recon=1.8264, kl=41.6363, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 145/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6346, recon=0.6346, kl=0.3463, beta=0.0000\n",
      "Batch 40, loss=0.4809, recon=0.4809, kl=1.0323, beta=0.0000\n",
      "Batch 60, loss=0.3392, recon=0.3392, kl=6.8997, beta=0.0000\n",
      "Batch 80, loss=0.3244, recon=0.3244, kl=11.1971, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5394 (Recon: 0.5394, KL: 4.4379, Current Beta: 0.0000) | Avg Valid Loss: 0.3446 | Avg Valid recon Loss: 0.3446\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2672, recon=0.2672, kl=15.5889, beta=0.0000\n",
      "Batch 40, loss=0.2558, recon=0.2558, kl=17.6929, beta=0.0000\n",
      "Batch 60, loss=0.2698, recon=0.2698, kl=19.3981, beta=0.0000\n",
      "Batch 80, loss=0.2235, recon=0.2235, kl=21.2056, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2950 (Recon: 0.2950, KL: 18.0101, Current Beta: 0.0000) | Avg Valid Loss: 0.2253 | Avg Valid recon Loss: 0.2253\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1947, recon=0.1947, kl=23.1756, beta=0.0000\n",
      "Batch 40, loss=0.2101, recon=0.2101, kl=24.5830, beta=0.0000\n",
      "Batch 60, loss=0.1542, recon=0.1542, kl=25.8833, beta=0.0000\n",
      "Batch 80, loss=0.1865, recon=0.1865, kl=27.4291, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2257 (Recon: 0.2257, KL: 25.0116, Current Beta: 0.0000) | Avg Valid Loss: 0.1750 | Avg Valid recon Loss: 0.1750\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1413, recon=0.1413, kl=29.0526, beta=0.0000\n",
      "Batch 40, loss=0.1571, recon=0.1571, kl=29.8848, beta=0.0000\n",
      "Batch 60, loss=0.1559, recon=0.1559, kl=30.8152, beta=0.0000\n",
      "Batch 80, loss=0.1710, recon=0.1710, kl=31.6340, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1869 (Recon: 0.1869, KL: 30.0847, Current Beta: 0.0000) | Avg Valid Loss: 0.1464 | Avg Valid recon Loss: 0.1464\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1673, recon=0.1673, kl=32.4802, beta=0.0000\n",
      "Batch 40, loss=0.1598, recon=0.1598, kl=33.2770, beta=0.0000\n",
      "Batch 60, loss=0.1311, recon=0.1311, kl=34.0216, beta=0.0000\n",
      "Batch 80, loss=0.1226, recon=0.1226, kl=34.5896, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1616 (Recon: 0.1616, KL: 33.4500, Current Beta: 0.0000) | Avg Valid Loss: 0.1290 | Avg Valid recon Loss: 0.1290\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1184, recon=0.1184, kl=35.2614, beta=0.0000\n",
      "Batch 40, loss=0.1068, recon=0.1068, kl=35.2151, beta=0.0000\n",
      "Batch 60, loss=0.1391, recon=0.1390, kl=35.0423, beta=0.0000\n",
      "Batch 80, loss=0.0739, recon=0.0739, kl=34.6684, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1424 (Recon: 0.1423, KL: 35.0056, Current Beta: 0.0000) | Avg Valid Loss: 0.1154 | Avg Valid recon Loss: 0.1154\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1280, recon=0.1279, kl=33.4930, beta=0.0000\n",
      "Batch 40, loss=0.0989, recon=0.0989, kl=32.0208, beta=0.0000\n",
      "Batch 60, loss=0.1073, recon=0.1073, kl=30.5982, beta=0.0000\n",
      "Batch 80, loss=0.1918, recon=0.1918, kl=29.0679, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1284 (Recon: 0.1284, KL: 31.6165, Current Beta: 0.0000) | Avg Valid Loss: 0.1060 | Avg Valid recon Loss: 0.1060\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1015, recon=0.1015, kl=24.7063, beta=0.0000\n",
      "Batch 40, loss=0.0825, recon=0.0825, kl=21.0248, beta=0.0000\n",
      "Batch 60, loss=0.0787, recon=0.0787, kl=18.2869, beta=0.0000\n",
      "Batch 80, loss=0.0676, recon=0.0676, kl=16.8992, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1170 (Recon: 0.1169, KL: 21.1209, Current Beta: 0.0000) | Avg Valid Loss: 0.0980 | Avg Valid recon Loss: 0.0980\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0823, recon=0.0823, kl=11.8930, beta=0.0000\n",
      "Batch 40, loss=0.0931, recon=0.0931, kl=9.1527, beta=0.0000\n",
      "Batch 60, loss=0.0990, recon=0.0989, kl=8.9280, beta=0.0000\n",
      "Batch 80, loss=0.0625, recon=0.0624, kl=8.3477, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1088 (Recon: 0.1088, KL: 10.2929, Current Beta: 0.0000) | Avg Valid Loss: 0.0920 | Avg Valid recon Loss: 0.0920\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1014, recon=0.1013, kl=3.7487, beta=0.0000\n",
      "Batch 40, loss=0.1202, recon=0.1201, kl=3.4202, beta=0.0000\n",
      "Batch 60, loss=0.0758, recon=0.0757, kl=3.0454, beta=0.0000\n",
      "Batch 80, loss=0.0694, recon=0.0694, kl=3.0605, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1018 (Recon: 0.1017, KL: 3.7631, Current Beta: 0.0000) | Avg Valid Loss: 0.0875 | Avg Valid recon Loss: 0.0875\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0747, recon=0.0747, kl=0.7713, beta=0.0000\n",
      "Batch 40, loss=0.0629, recon=0.0628, kl=1.0974, beta=0.0000\n",
      "Batch 60, loss=0.0618, recon=0.0618, kl=0.7550, beta=0.0000\n",
      "Batch 80, loss=0.0849, recon=0.0848, kl=0.6921, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0961 (Recon: 0.0961, KL: 1.0018, Current Beta: 0.0000) | Avg Valid Loss: 0.0832 | Avg Valid recon Loss: 0.0832\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0852, recon=0.0851, kl=0.0961, beta=0.0001\n",
      "Batch 40, loss=0.0885, recon=0.0885, kl=0.1276, beta=0.0001\n",
      "Batch 60, loss=0.0939, recon=0.0939, kl=0.0558, beta=0.0001\n",
      "Batch 80, loss=0.0652, recon=0.0652, kl=0.0409, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0910 (Recon: 0.0910, KL: 0.1280, Current Beta: 0.0001) | Avg Valid Loss: 0.0799 | Avg Valid recon Loss: 0.0799\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0476, recon=0.0476, kl=0.0074, beta=0.0002\n",
      "Batch 40, loss=0.0639, recon=0.0639, kl=0.0089, beta=0.0002\n",
      "Batch 60, loss=0.0884, recon=0.0884, kl=0.0066, beta=0.0002\n",
      "Batch 80, loss=0.0719, recon=0.0719, kl=0.0058, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0872 (Recon: 0.0872, KL: 0.0102, Current Beta: 0.0002) | Avg Valid Loss: 0.0765 | Avg Valid recon Loss: 0.0765\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0592, recon=0.0592, kl=0.0022, beta=0.0004\n",
      "Batch 40, loss=0.1140, recon=0.1140, kl=0.0121, beta=0.0004\n",
      "Batch 60, loss=0.0663, recon=0.0663, kl=0.0017, beta=0.0004\n",
      "Batch 80, loss=0.0713, recon=0.0713, kl=0.0011, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0837 (Recon: 0.0837, KL: 0.0022, Current Beta: 0.0004) | Avg Valid Loss: 0.0739 | Avg Valid recon Loss: 0.0739\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0959, recon=0.0959, kl=0.0005, beta=0.0006\n",
      "Batch 40, loss=0.0586, recon=0.0586, kl=0.0007, beta=0.0006\n",
      "Batch 60, loss=0.0545, recon=0.0545, kl=0.0005, beta=0.0006\n",
      "Batch 80, loss=0.0637, recon=0.0637, kl=0.0006, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0808 (Recon: 0.0808, KL: 0.0009, Current Beta: 0.0006) | Avg Valid Loss: 0.0724 | Avg Valid recon Loss: 0.0724\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1693, recon=0.1693, kl=0.0005, beta=0.0010\n",
      "Batch 40, loss=0.0424, recon=0.0423, kl=0.0010, beta=0.0010\n",
      "Batch 60, loss=0.0646, recon=0.0646, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0587, recon=0.0587, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0784 (Recon: 0.0784, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0696 | Avg Valid recon Loss: 0.0696\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0757, recon=0.0757, kl=0.0005, beta=0.0010\n",
      "Batch 40, loss=0.0969, recon=0.0969, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.2315, recon=0.2315, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0455, recon=0.0455, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0758 (Recon: 0.0758, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0683 | Avg Valid recon Loss: 0.0683\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0449, recon=0.0449, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0515, recon=0.0515, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0757, recon=0.0757, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0492, recon=0.0492, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0736 (Recon: 0.0736, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0668 | Avg Valid recon Loss: 0.0668\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0413, recon=0.0413, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0956, recon=0.0956, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0469, recon=0.0469, kl=0.0008, beta=0.0010\n",
      "Batch 80, loss=0.0389, recon=0.0389, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0718 (Recon: 0.0718, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0652 | Avg Valid recon Loss: 0.0652\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0667, recon=0.0667, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0478, recon=0.0478, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0914, recon=0.0914, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0962, recon=0.0962, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0701 (Recon: 0.0701, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0638 | Avg Valid recon Loss: 0.0638\n",
      "\n",
      "[VRAE Run 146/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3427, recon=0.3427, kl=18.9780, beta=0.0000\n",
      "Batch 40, loss=0.1750, recon=0.1750, kl=25.9596, beta=0.0000\n",
      "Batch 60, loss=0.1325, recon=0.1325, kl=30.3226, beta=0.0000\n",
      "Batch 80, loss=0.0919, recon=0.0919, kl=34.5205, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2419 (Recon: 0.2419, KL: 24.1819, Current Beta: 0.0000) | Avg Valid Loss: 0.0965 | Avg Valid recon Loss: 0.0965\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0935, recon=0.0935, kl=37.2514, beta=0.0000\n",
      "Batch 40, loss=0.0871, recon=0.0871, kl=39.5453, beta=0.0000\n",
      "Batch 60, loss=0.0801, recon=0.0801, kl=38.2560, beta=0.0000\n",
      "Batch 80, loss=0.1033, recon=0.1033, kl=38.8722, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0956 (Recon: 0.0956, KL: 37.9726, Current Beta: 0.0000) | Avg Valid Loss: 0.0768 | Avg Valid recon Loss: 0.0768\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=40.9182, beta=0.0000\n",
      "Batch 40, loss=0.0772, recon=0.0772, kl=40.0373, beta=0.0000\n",
      "Batch 60, loss=0.0453, recon=0.0453, kl=40.2618, beta=0.0000\n",
      "Batch 80, loss=0.0916, recon=0.0916, kl=39.6033, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0753 (Recon: 0.0753, KL: 40.0822, Current Beta: 0.0000) | Avg Valid Loss: 0.0625 | Avg Valid recon Loss: 0.0625\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0685, recon=0.0685, kl=37.9529, beta=0.0000\n",
      "Batch 40, loss=0.0400, recon=0.0400, kl=39.8579, beta=0.0000\n",
      "Batch 60, loss=0.0475, recon=0.0475, kl=40.7875, beta=0.0000\n",
      "Batch 80, loss=0.0659, recon=0.0659, kl=39.2047, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0675 (Recon: 0.0675, KL: 38.9393, Current Beta: 0.0000) | Avg Valid Loss: 0.0568 | Avg Valid recon Loss: 0.0568\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0498, recon=0.0498, kl=37.5477, beta=0.0000\n",
      "Batch 40, loss=0.0584, recon=0.0584, kl=34.5628, beta=0.0000\n",
      "Batch 60, loss=0.1761, recon=0.1761, kl=32.5790, beta=0.0000\n",
      "Batch 80, loss=0.0488, recon=0.0488, kl=33.8230, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0623 (Recon: 0.0623, KL: 35.1466, Current Beta: 0.0000) | Avg Valid Loss: 0.0517 | Avg Valid recon Loss: 0.0517\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0533, recon=0.0533, kl=31.5875, beta=0.0000\n",
      "Batch 40, loss=0.0381, recon=0.0381, kl=29.3939, beta=0.0000\n",
      "Batch 60, loss=0.0578, recon=0.0578, kl=28.9633, beta=0.0000\n",
      "Batch 80, loss=0.0801, recon=0.0801, kl=27.6319, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0581, KL: 29.8912, Current Beta: 0.0000) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0271, recon=0.0271, kl=24.5180, beta=0.0000\n",
      "Batch 40, loss=0.0337, recon=0.0336, kl=21.3806, beta=0.0000\n",
      "Batch 60, loss=0.0359, recon=0.0359, kl=20.7606, beta=0.0000\n",
      "Batch 80, loss=0.0296, recon=0.0296, kl=21.7246, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0555, KL: 22.5832, Current Beta: 0.0000) | Avg Valid Loss: 0.0484 | Avg Valid recon Loss: 0.0484\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0394, recon=0.0394, kl=13.7353, beta=0.0000\n",
      "Batch 40, loss=0.0426, recon=0.0426, kl=14.4696, beta=0.0000\n",
      "Batch 60, loss=0.0460, recon=0.0459, kl=13.7727, beta=0.0000\n",
      "Batch 80, loss=0.0413, recon=0.0413, kl=13.0511, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0529, KL: 14.5304, Current Beta: 0.0000) | Avg Valid Loss: 0.0514 | Avg Valid recon Loss: 0.0514\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0372, recon=0.0372, kl=6.2529, beta=0.0000\n",
      "Batch 40, loss=0.0350, recon=0.0350, kl=6.7555, beta=0.0000\n",
      "Batch 60, loss=0.0543, recon=0.0543, kl=5.4571, beta=0.0000\n",
      "Batch 80, loss=0.0269, recon=0.0269, kl=4.4993, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0537 (Recon: 0.0536, KL: 6.4980, Current Beta: 0.0000) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0466\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0341, recon=0.0340, kl=2.2193, beta=0.0000\n",
      "Batch 40, loss=0.0507, recon=0.0507, kl=1.8871, beta=0.0000\n",
      "Batch 60, loss=0.0395, recon=0.0394, kl=2.0218, beta=0.0000\n",
      "Batch 80, loss=0.0487, recon=0.0487, kl=3.0257, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0469, KL: 2.5363, Current Beta: 0.0000) | Avg Valid Loss: 0.0446 | Avg Valid recon Loss: 0.0446\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0422, recon=0.0422, kl=0.4702, beta=0.0000\n",
      "Batch 40, loss=0.0364, recon=0.0364, kl=0.2742, beta=0.0000\n",
      "Batch 60, loss=0.0337, recon=0.0337, kl=0.1460, beta=0.0000\n",
      "Batch 80, loss=0.0394, recon=0.0394, kl=0.3559, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0503 (Recon: 0.0503, KL: 0.4235, Current Beta: 0.0000) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0280, recon=0.0280, kl=0.0469, beta=0.0001\n",
      "Batch 40, loss=0.0777, recon=0.0777, kl=0.0143, beta=0.0001\n",
      "Batch 60, loss=0.0428, recon=0.0428, kl=0.0199, beta=0.0001\n",
      "Batch 80, loss=0.0472, recon=0.0472, kl=0.0173, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0495, KL: 0.0495, Current Beta: 0.0001) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0291, recon=0.0291, kl=0.0230, beta=0.0002\n",
      "Batch 40, loss=0.0439, recon=0.0439, kl=0.0071, beta=0.0002\n",
      "Batch 60, loss=0.0349, recon=0.0349, kl=0.0025, beta=0.0002\n",
      "Batch 80, loss=0.0496, recon=0.0496, kl=0.0048, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0494, KL: 0.0116, Current Beta: 0.0002) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0466\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0352, recon=0.0352, kl=0.0021, beta=0.0004\n",
      "Batch 40, loss=0.0441, recon=0.0441, kl=0.0010, beta=0.0004\n",
      "Batch 60, loss=0.0412, recon=0.0412, kl=0.0017, beta=0.0004\n",
      "Batch 80, loss=0.0464, recon=0.0464, kl=0.0056, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0496, KL: 0.0025, Current Beta: 0.0004) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0288, recon=0.0288, kl=0.0030, beta=0.0006\n",
      "Batch 40, loss=0.0316, recon=0.0316, kl=0.0011, beta=0.0006\n",
      "Batch 60, loss=0.0355, recon=0.0355, kl=0.0011, beta=0.0006\n",
      "Batch 80, loss=0.0549, recon=0.0549, kl=0.0037, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0474 (Recon: 0.0474, KL: 0.0022, Current Beta: 0.0006) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0394\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0309, recon=0.0309, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0340, recon=0.0340, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0422, recon=0.0422, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0429, recon=0.0428, kl=0.0076, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0471 (Recon: 0.0471, KL: 0.0019, Current Beta: 0.0010) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0375, recon=0.0375, kl=0.0012, beta=0.0010\n",
      "Batch 40, loss=0.0305, recon=0.0305, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0358, recon=0.0358, kl=0.0006, beta=0.0010\n",
      "Batch 80, loss=0.0328, recon=0.0328, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0461, KL: 0.0014, Current Beta: 0.0010) | Avg Valid Loss: 0.0386 | Avg Valid recon Loss: 0.0386\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0368, recon=0.0368, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0346, recon=0.0346, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0434, recon=0.0434, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0415, recon=0.0415, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0457, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0396 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0275, recon=0.0275, kl=0.0091, beta=0.0010\n",
      "Batch 40, loss=0.0638, recon=0.0638, kl=0.0025, beta=0.0010\n",
      "Batch 60, loss=0.0356, recon=0.0356, kl=0.0012, beta=0.0010\n",
      "Batch 80, loss=0.0319, recon=0.0319, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0471 (Recon: 0.0471, KL: 0.0020, Current Beta: 0.0010) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0371, recon=0.0371, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0354, recon=0.0354, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0648, recon=0.0648, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0422, recon=0.0422, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0515 | Avg Valid recon Loss: 0.0515\n",
      "\n",
      "[VRAE Run 147/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5245, recon=0.5245, kl=0.5218, beta=0.0000\n",
      "Batch 40, loss=0.5602, recon=0.5602, kl=1.3241, beta=0.0000\n",
      "Batch 60, loss=0.4910, recon=0.4910, kl=8.4350, beta=0.0000\n",
      "Batch 80, loss=0.2829, recon=0.2829, kl=21.7320, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5551 (Recon: 0.5551, KL: 7.3632, Current Beta: 0.0000) | Avg Valid Loss: 0.3499 | Avg Valid recon Loss: 0.3499\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2897, recon=0.2897, kl=32.8014, beta=0.0000\n",
      "Batch 40, loss=0.2495, recon=0.2495, kl=37.0065, beta=0.0000\n",
      "Batch 60, loss=0.2704, recon=0.2704, kl=40.2334, beta=0.0000\n",
      "Batch 80, loss=0.2011, recon=0.2011, kl=42.9800, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2987 (Recon: 0.2987, KL: 37.1045, Current Beta: 0.0000) | Avg Valid Loss: 0.2326 | Avg Valid recon Loss: 0.2326\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2128, recon=0.2128, kl=46.2333, beta=0.0000\n",
      "Batch 40, loss=0.1843, recon=0.1843, kl=48.0851, beta=0.0000\n",
      "Batch 60, loss=0.1915, recon=0.1915, kl=50.1870, beta=0.0000\n",
      "Batch 80, loss=0.2062, recon=0.2062, kl=51.7913, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2302 (Recon: 0.2302, KL: 48.5843, Current Beta: 0.0000) | Avg Valid Loss: 0.1804 | Avg Valid recon Loss: 0.1804\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1799, recon=0.1799, kl=53.5441, beta=0.0000\n",
      "Batch 40, loss=0.1427, recon=0.1426, kl=54.0899, beta=0.0000\n",
      "Batch 60, loss=0.1354, recon=0.1354, kl=54.8727, beta=0.0000\n",
      "Batch 80, loss=0.1994, recon=0.1994, kl=55.8684, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1904 (Recon: 0.1904, KL: 54.4123, Current Beta: 0.0000) | Avg Valid Loss: 0.1517 | Avg Valid recon Loss: 0.1517\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1171, recon=0.1171, kl=56.7112, beta=0.0000\n",
      "Batch 40, loss=0.1152, recon=0.1152, kl=57.0374, beta=0.0000\n",
      "Batch 60, loss=0.1474, recon=0.1474, kl=57.0681, beta=0.0000\n",
      "Batch 80, loss=0.1960, recon=0.1960, kl=57.6729, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1671 (Recon: 0.1671, KL: 57.0639, Current Beta: 0.0000) | Avg Valid Loss: 0.1329 | Avg Valid recon Loss: 0.1329\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2959, recon=0.2959, kl=57.6833, beta=0.0000\n",
      "Batch 40, loss=0.0992, recon=0.0992, kl=56.3475, beta=0.0000\n",
      "Batch 60, loss=0.1316, recon=0.1316, kl=55.1531, beta=0.0000\n",
      "Batch 80, loss=0.1005, recon=0.1005, kl=53.9740, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1470 (Recon: 0.1469, KL: 56.0996, Current Beta: 0.0000) | Avg Valid Loss: 0.1172 | Avg Valid recon Loss: 0.1172\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0895, recon=0.0895, kl=50.3747, beta=0.0000\n",
      "Batch 40, loss=0.1125, recon=0.1125, kl=45.3581, beta=0.0000\n",
      "Batch 60, loss=0.0986, recon=0.0986, kl=41.5768, beta=0.0000\n",
      "Batch 80, loss=0.1664, recon=0.1664, kl=39.2764, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1301 (Recon: 0.1300, KL: 45.2386, Current Beta: 0.0000) | Avg Valid Loss: 0.1062 | Avg Valid recon Loss: 0.1061\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1443, recon=0.1442, kl=29.8886, beta=0.0000\n",
      "Batch 40, loss=0.1020, recon=0.1020, kl=23.5796, beta=0.0000\n",
      "Batch 60, loss=0.0902, recon=0.0902, kl=22.3615, beta=0.0000\n",
      "Batch 80, loss=0.1270, recon=0.1270, kl=21.4241, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1176 (Recon: 0.1176, KL: 25.8046, Current Beta: 0.0000) | Avg Valid Loss: 0.0980 | Avg Valid recon Loss: 0.0979\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1118, recon=0.1118, kl=10.1077, beta=0.0000\n",
      "Batch 40, loss=0.0653, recon=0.0652, kl=9.4126, beta=0.0000\n",
      "Batch 60, loss=0.1132, recon=0.1131, kl=9.1171, beta=0.0000\n",
      "Batch 80, loss=0.0788, recon=0.0788, kl=8.7571, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1076 (Recon: 0.1075, KL: 10.5357, Current Beta: 0.0000) | Avg Valid Loss: 0.0910 | Avg Valid recon Loss: 0.0910\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0994, recon=0.0994, kl=3.0105, beta=0.0000\n",
      "Batch 40, loss=0.0641, recon=0.0641, kl=2.7356, beta=0.0000\n",
      "Batch 60, loss=0.0753, recon=0.0753, kl=2.7499, beta=0.0000\n",
      "Batch 80, loss=0.0733, recon=0.0733, kl=1.9438, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1002 (Recon: 0.1002, KL: 3.0478, Current Beta: 0.0000) | Avg Valid Loss: 0.0855 | Avg Valid recon Loss: 0.0855\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0689, recon=0.0689, kl=0.5163, beta=0.0000\n",
      "Batch 40, loss=0.0634, recon=0.0634, kl=0.6357, beta=0.0000\n",
      "Batch 60, loss=0.0851, recon=0.0851, kl=0.4669, beta=0.0000\n",
      "Batch 80, loss=0.0549, recon=0.0549, kl=0.4170, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0939 (Recon: 0.0939, KL: 0.6429, Current Beta: 0.0000) | Avg Valid Loss: 0.0815 | Avg Valid recon Loss: 0.0815\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.7991, recon=0.7991, kl=0.0897, beta=0.0001\n",
      "Batch 40, loss=0.0699, recon=0.0699, kl=0.0766, beta=0.0001\n",
      "Batch 60, loss=0.0593, recon=0.0593, kl=0.0542, beta=0.0001\n",
      "Batch 80, loss=0.0640, recon=0.0640, kl=0.0388, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0891 (Recon: 0.0891, KL: 0.0955, Current Beta: 0.0001) | Avg Valid Loss: 0.0777 | Avg Valid recon Loss: 0.0777\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0528, recon=0.0528, kl=0.0092, beta=0.0002\n",
      "Batch 40, loss=0.1404, recon=0.1404, kl=0.0067, beta=0.0002\n",
      "Batch 60, loss=0.0843, recon=0.0843, kl=0.0060, beta=0.0002\n",
      "Batch 80, loss=0.0736, recon=0.0736, kl=0.0067, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0853 (Recon: 0.0853, KL: 0.0109, Current Beta: 0.0002) | Avg Valid Loss: 0.0750 | Avg Valid recon Loss: 0.0750\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0593, recon=0.0593, kl=0.0027, beta=0.0004\n",
      "Batch 40, loss=0.0466, recon=0.0466, kl=0.0018, beta=0.0004\n",
      "Batch 60, loss=0.0738, recon=0.0738, kl=0.0044, beta=0.0004\n",
      "Batch 80, loss=0.0653, recon=0.0653, kl=0.0020, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0820 (Recon: 0.0820, KL: 0.0024, Current Beta: 0.0004) | Avg Valid Loss: 0.0723 | Avg Valid recon Loss: 0.0722\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0598, recon=0.0598, kl=0.0009, beta=0.0006\n",
      "Batch 40, loss=0.0585, recon=0.0585, kl=0.0005, beta=0.0006\n",
      "Batch 60, loss=0.0436, recon=0.0436, kl=0.0005, beta=0.0006\n",
      "Batch 80, loss=0.0781, recon=0.0781, kl=0.0013, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0789 (Recon: 0.0789, KL: 0.0010, Current Beta: 0.0006) | Avg Valid Loss: 0.0705 | Avg Valid recon Loss: 0.0705\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0516, recon=0.0516, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0613, recon=0.0613, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0710, recon=0.0710, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0429, recon=0.0429, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0768 (Recon: 0.0768, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0681 | Avg Valid recon Loss: 0.0681\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0767, recon=0.0767, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0843, recon=0.0843, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0819, recon=0.0819, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.2174, recon=0.2174, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0742 (Recon: 0.0742, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0666 | Avg Valid recon Loss: 0.0666\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0694, recon=0.0694, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0424, recon=0.0424, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0605, recon=0.0605, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.2070, recon=0.2070, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0724 (Recon: 0.0724, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0648 | Avg Valid recon Loss: 0.0648\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0479, recon=0.0479, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0590, recon=0.0590, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0725, recon=0.0725, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0418, recon=0.0418, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0705 (Recon: 0.0705, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0636 | Avg Valid recon Loss: 0.0636\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1727, recon=0.1727, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0849, recon=0.0849, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0357, recon=0.0357, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0372, recon=0.0372, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0684 (Recon: 0.0684, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0618 | Avg Valid recon Loss: 0.0618\n",
      "\n",
      "[VRAE Run 148/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3822, recon=0.3822, kl=33.0830, beta=0.0000\n",
      "Batch 40, loss=0.1317, recon=0.1317, kl=48.6220, beta=0.0000\n",
      "Batch 60, loss=0.0932, recon=0.0932, kl=51.7962, beta=0.0000\n",
      "Batch 80, loss=0.0839, recon=0.0839, kl=52.3132, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2332 (Recon: 0.2332, KL: 41.6605, Current Beta: 0.0000) | Avg Valid Loss: 0.0958 | Avg Valid recon Loss: 0.0958\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0677, recon=0.0677, kl=61.9905, beta=0.0000\n",
      "Batch 40, loss=0.0771, recon=0.0771, kl=64.5650, beta=0.0000\n",
      "Batch 60, loss=0.0985, recon=0.0985, kl=61.2640, beta=0.0000\n",
      "Batch 80, loss=0.0614, recon=0.0614, kl=67.5120, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0923 (Recon: 0.0923, KL: 62.8166, Current Beta: 0.0000) | Avg Valid Loss: 0.0693 | Avg Valid recon Loss: 0.0693\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0835, recon=0.0835, kl=65.4884, beta=0.0000\n",
      "Batch 40, loss=0.0490, recon=0.0490, kl=60.6477, beta=0.0000\n",
      "Batch 60, loss=0.0472, recon=0.0472, kl=65.0748, beta=0.0000\n",
      "Batch 80, loss=0.0592, recon=0.0592, kl=64.8441, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0729 (Recon: 0.0729, KL: 64.1873, Current Beta: 0.0000) | Avg Valid Loss: 0.0622 | Avg Valid recon Loss: 0.0622\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0382, recon=0.0382, kl=62.5759, beta=0.0000\n",
      "Batch 40, loss=0.6323, recon=0.6323, kl=60.3582, beta=0.0000\n",
      "Batch 60, loss=0.0501, recon=0.0501, kl=63.3832, beta=0.0000\n",
      "Batch 80, loss=0.0660, recon=0.0660, kl=60.2807, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0659 (Recon: 0.0659, KL: 61.8643, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0435, recon=0.0435, kl=58.0747, beta=0.0000\n",
      "Batch 40, loss=0.1107, recon=0.1107, kl=57.2778, beta=0.0000\n",
      "Batch 60, loss=0.0432, recon=0.0432, kl=53.9060, beta=0.0000\n",
      "Batch 80, loss=0.0430, recon=0.0430, kl=61.0840, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0612 (Recon: 0.0612, KL: 57.1528, Current Beta: 0.0000) | Avg Valid Loss: 0.0548 | Avg Valid recon Loss: 0.0548\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0404, recon=0.0404, kl=52.0899, beta=0.0000\n",
      "Batch 40, loss=0.1140, recon=0.1140, kl=48.0530, beta=0.0000\n",
      "Batch 60, loss=0.0407, recon=0.0407, kl=46.3789, beta=0.0000\n",
      "Batch 80, loss=0.0318, recon=0.0318, kl=49.8231, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0594 (Recon: 0.0594, KL: 49.8868, Current Beta: 0.0000) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0541\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0412, recon=0.0411, kl=41.4225, beta=0.0000\n",
      "Batch 40, loss=0.0693, recon=0.0693, kl=36.8920, beta=0.0000\n",
      "Batch 60, loss=0.0354, recon=0.0354, kl=37.6749, beta=0.0000\n",
      "Batch 80, loss=0.0529, recon=0.0529, kl=33.5007, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0555, KL: 38.6914, Current Beta: 0.0000) | Avg Valid Loss: 0.0554 | Avg Valid recon Loss: 0.0553\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0472, recon=0.0471, kl=25.8173, beta=0.0000\n",
      "Batch 40, loss=0.0337, recon=0.0336, kl=23.2345, beta=0.0000\n",
      "Batch 60, loss=0.0834, recon=0.0834, kl=21.5103, beta=0.0000\n",
      "Batch 80, loss=0.0551, recon=0.0551, kl=27.4225, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 25.3902, Current Beta: 0.0000) | Avg Valid Loss: 0.0520 | Avg Valid recon Loss: 0.0520\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0470, recon=0.0469, kl=12.3296, beta=0.0000\n",
      "Batch 40, loss=0.0424, recon=0.0423, kl=15.8083, beta=0.0000\n",
      "Batch 60, loss=0.0434, recon=0.0433, kl=13.6301, beta=0.0000\n",
      "Batch 80, loss=0.0346, recon=0.0346, kl=10.3242, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0544, KL: 14.4448, Current Beta: 0.0000) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0492\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0449, recon=0.0449, kl=3.3370, beta=0.0000\n",
      "Batch 40, loss=0.4115, recon=0.4115, kl=3.8116, beta=0.0000\n",
      "Batch 60, loss=0.0460, recon=0.0459, kl=3.5451, beta=0.0000\n",
      "Batch 80, loss=0.0669, recon=0.0668, kl=2.8099, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0518, KL: 3.9536, Current Beta: 0.0000) | Avg Valid Loss: 0.0471 | Avg Valid recon Loss: 0.0470\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.3961, recon=0.3961, kl=0.5426, beta=0.0000\n",
      "Batch 40, loss=0.0350, recon=0.0349, kl=1.3473, beta=0.0000\n",
      "Batch 60, loss=0.0345, recon=0.0345, kl=0.5026, beta=0.0000\n",
      "Batch 80, loss=0.0385, recon=0.0385, kl=0.2878, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0499 (Recon: 0.0499, KL: 0.8774, Current Beta: 0.0000) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0475, recon=0.0475, kl=0.0832, beta=0.0001\n",
      "Batch 40, loss=0.0293, recon=0.0292, kl=0.0911, beta=0.0001\n",
      "Batch 60, loss=0.0654, recon=0.0654, kl=0.0234, beta=0.0001\n",
      "Batch 80, loss=0.0897, recon=0.0897, kl=0.0817, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 0.0889, Current Beta: 0.0001) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0371, recon=0.0371, kl=0.2461, beta=0.0002\n",
      "Batch 40, loss=0.0778, recon=0.0778, kl=0.0454, beta=0.0002\n",
      "Batch 60, loss=0.0582, recon=0.0582, kl=0.0123, beta=0.0002\n",
      "Batch 80, loss=0.0418, recon=0.0418, kl=0.0095, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 0.0508, Current Beta: 0.0002) | Avg Valid Loss: 0.0428 | Avg Valid recon Loss: 0.0428\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0331, recon=0.0331, kl=0.0039, beta=0.0004\n",
      "Batch 40, loss=0.0368, recon=0.0368, kl=0.0401, beta=0.0004\n",
      "Batch 60, loss=0.0454, recon=0.0454, kl=0.0115, beta=0.0004\n",
      "Batch 80, loss=0.0378, recon=0.0378, kl=0.0047, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0478 (Recon: 0.0478, KL: 0.0112, Current Beta: 0.0004) | Avg Valid Loss: 0.0427 | Avg Valid recon Loss: 0.0427\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0352, recon=0.0352, kl=0.0041, beta=0.0006\n",
      "Batch 40, loss=0.0275, recon=0.0275, kl=0.0014, beta=0.0006\n",
      "Batch 60, loss=0.0498, recon=0.0498, kl=0.0013, beta=0.0006\n",
      "Batch 80, loss=0.0369, recon=0.0369, kl=0.0020, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0465 (Recon: 0.0465, KL: 0.0024, Current Beta: 0.0006) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0247, recon=0.0247, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.0456, recon=0.0456, kl=0.0051, beta=0.0010\n",
      "Batch 60, loss=0.0300, recon=0.0300, kl=0.0012, beta=0.0010\n",
      "Batch 80, loss=0.0598, recon=0.0598, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0466, KL: 0.0017, Current Beta: 0.0010) | Avg Valid Loss: 0.0434 | Avg Valid recon Loss: 0.0434\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0315, recon=0.0315, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.0357, recon=0.0357, kl=0.0016, beta=0.0010\n",
      "Batch 60, loss=0.0544, recon=0.0544, kl=0.0048, beta=0.0010\n",
      "Batch 80, loss=0.0333, recon=0.0333, kl=0.0019, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0495, KL: 0.0018, Current Beta: 0.0010) | Avg Valid Loss: 0.0396 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0389, recon=0.0389, kl=0.0043, beta=0.0010\n",
      "Batch 40, loss=0.0284, recon=0.0284, kl=0.0020, beta=0.0010\n",
      "Batch 60, loss=0.0365, recon=0.0365, kl=0.0018, beta=0.0010\n",
      "Batch 80, loss=0.0559, recon=0.0559, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 0.0020, Current Beta: 0.0010) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0394\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0350, recon=0.0350, kl=0.0005, beta=0.0010\n",
      "Batch 40, loss=0.0311, recon=0.0311, kl=0.0051, beta=0.0010\n",
      "Batch 60, loss=0.0984, recon=0.0984, kl=0.0015, beta=0.0010\n",
      "Batch 80, loss=0.0354, recon=0.0354, kl=0.0012, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0448 (Recon: 0.0448, KL: 0.0015, Current Beta: 0.0010) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0418, recon=0.0418, kl=0.0008, beta=0.0010\n",
      "Batch 40, loss=0.0280, recon=0.0280, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0393, recon=0.0393, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.3285, recon=0.3285, kl=0.0081, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0447 (Recon: 0.0447, KL: 0.0012, Current Beta: 0.0010) | Avg Valid Loss: 0.0432 | Avg Valid recon Loss: 0.0432\n",
      "\n",
      "[VRAE Run 149/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7385, recon=0.7385, kl=0.7082, beta=0.0000\n",
      "Batch 40, loss=0.3404, recon=0.3404, kl=1.2477, beta=0.0000\n",
      "Batch 60, loss=0.3871, recon=0.3871, kl=9.1676, beta=0.0000\n",
      "Batch 80, loss=0.2472, recon=0.2472, kl=34.8644, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5531 (Recon: 0.5531, KL: 10.8039, Current Beta: 0.0000) | Avg Valid Loss: 0.3577 | Avg Valid recon Loss: 0.3577\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3568, recon=0.3568, kl=58.1437, beta=0.0000\n",
      "Batch 40, loss=0.2450, recon=0.2450, kl=67.1902, beta=0.0000\n",
      "Batch 60, loss=0.2653, recon=0.2653, kl=73.5736, beta=0.0000\n",
      "Batch 80, loss=0.2464, recon=0.2464, kl=80.0005, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3057 (Recon: 0.3057, KL: 67.7050, Current Beta: 0.0000) | Avg Valid Loss: 0.2379 | Avg Valid recon Loss: 0.2379\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.7560, recon=0.7560, kl=85.3785, beta=0.0000\n",
      "Batch 40, loss=0.1815, recon=0.1815, kl=90.4836, beta=0.0000\n",
      "Batch 60, loss=0.2225, recon=0.2225, kl=94.7509, beta=0.0000\n",
      "Batch 80, loss=0.2099, recon=0.2099, kl=98.8310, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2320 (Recon: 0.2320, KL: 91.4509, Current Beta: 0.0000) | Avg Valid Loss: 0.1797 | Avg Valid recon Loss: 0.1797\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1842, recon=0.1842, kl=103.0036, beta=0.0000\n",
      "Batch 40, loss=0.2076, recon=0.2076, kl=106.6645, beta=0.0000\n",
      "Batch 60, loss=0.1232, recon=0.1232, kl=108.6032, beta=0.0000\n",
      "Batch 80, loss=0.3793, recon=0.3793, kl=110.7779, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1912 (Recon: 0.1912, KL: 106.5354, Current Beta: 0.0000) | Avg Valid Loss: 0.1504 | Avg Valid recon Loss: 0.1504\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1424, recon=0.1424, kl=111.5520, beta=0.0000\n",
      "Batch 40, loss=0.1438, recon=0.1438, kl=111.8043, beta=0.0000\n",
      "Batch 60, loss=0.1193, recon=0.1193, kl=112.0730, beta=0.0000\n",
      "Batch 80, loss=0.1208, recon=0.1207, kl=111.3255, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1646 (Recon: 0.1646, KL: 111.5800, Current Beta: 0.0000) | Avg Valid Loss: 0.1305 | Avg Valid recon Loss: 0.1305\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1075, recon=0.1075, kl=108.3545, beta=0.0000\n",
      "Batch 40, loss=0.1779, recon=0.1779, kl=103.2672, beta=0.0000\n",
      "Batch 60, loss=0.1211, recon=0.1210, kl=101.0970, beta=0.0000\n",
      "Batch 80, loss=0.1360, recon=0.1360, kl=97.0910, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1452 (Recon: 0.1452, KL: 103.4371, Current Beta: 0.0000) | Avg Valid Loss: 0.1174 | Avg Valid recon Loss: 0.1174\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.9927, recon=0.9926, kl=87.6521, beta=0.0000\n",
      "Batch 40, loss=0.1204, recon=0.1203, kl=75.0383, beta=0.0000\n",
      "Batch 60, loss=0.1136, recon=0.1136, kl=65.7729, beta=0.0000\n",
      "Batch 80, loss=0.0905, recon=0.0905, kl=62.5519, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1309 (Recon: 0.1309, KL: 74.8638, Current Beta: 0.0000) | Avg Valid Loss: 0.1076 | Avg Valid recon Loss: 0.1076\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0999, recon=0.0999, kl=43.0630, beta=0.0000\n",
      "Batch 40, loss=0.1582, recon=0.1581, kl=31.7664, beta=0.0000\n",
      "Batch 60, loss=0.1556, recon=0.1555, kl=31.0886, beta=0.0000\n",
      "Batch 80, loss=0.0826, recon=0.0825, kl=27.5830, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1196 (Recon: 0.1195, KL: 36.4456, Current Beta: 0.0000) | Avg Valid Loss: 0.0985 | Avg Valid recon Loss: 0.0984\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1012, recon=0.1011, kl=11.6753, beta=0.0000\n",
      "Batch 40, loss=0.0696, recon=0.0695, kl=12.2305, beta=0.0000\n",
      "Batch 60, loss=0.0835, recon=0.0835, kl=11.0045, beta=0.0000\n",
      "Batch 80, loss=0.0701, recon=0.0700, kl=8.6524, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1103 (Recon: 0.1103, KL: 12.5732, Current Beta: 0.0000) | Avg Valid Loss: 0.0928 | Avg Valid recon Loss: 0.0927\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1090, recon=0.1090, kl=2.9991, beta=0.0000\n",
      "Batch 40, loss=0.0955, recon=0.0955, kl=3.0916, beta=0.0000\n",
      "Batch 60, loss=0.0864, recon=0.0863, kl=2.8783, beta=0.0000\n",
      "Batch 80, loss=0.0571, recon=0.0571, kl=2.3229, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1028 (Recon: 0.1027, KL: 3.3109, Current Beta: 0.0000) | Avg Valid Loss: 0.0869 | Avg Valid recon Loss: 0.0869\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0853, recon=0.0853, kl=0.7564, beta=0.0000\n",
      "Batch 40, loss=0.0706, recon=0.0705, kl=0.7414, beta=0.0000\n",
      "Batch 60, loss=0.0854, recon=0.0854, kl=0.5525, beta=0.0000\n",
      "Batch 80, loss=0.0657, recon=0.0657, kl=0.5445, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0963 (Recon: 0.0963, KL: 0.7853, Current Beta: 0.0000) | Avg Valid Loss: 0.0824 | Avg Valid recon Loss: 0.0824\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0516, recon=0.0516, kl=0.1710, beta=0.0001\n",
      "Batch 40, loss=0.0966, recon=0.0966, kl=0.1276, beta=0.0001\n",
      "Batch 60, loss=0.0525, recon=0.0525, kl=0.0885, beta=0.0001\n",
      "Batch 80, loss=0.0803, recon=0.0803, kl=0.0745, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0915 (Recon: 0.0915, KL: 0.1536, Current Beta: 0.0001) | Avg Valid Loss: 0.0787 | Avg Valid recon Loss: 0.0787\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0775, recon=0.0774, kl=0.0171, beta=0.0002\n",
      "Batch 40, loss=0.0711, recon=0.0711, kl=0.0109, beta=0.0002\n",
      "Batch 60, loss=0.0608, recon=0.0608, kl=0.0071, beta=0.0002\n",
      "Batch 80, loss=0.0713, recon=0.0713, kl=0.0073, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0874 (Recon: 0.0874, KL: 0.0172, Current Beta: 0.0002) | Avg Valid Loss: 0.0756 | Avg Valid recon Loss: 0.0756\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0904, recon=0.0904, kl=0.0011, beta=0.0004\n",
      "Batch 40, loss=0.1322, recon=0.1322, kl=0.0015, beta=0.0004\n",
      "Batch 60, loss=0.0734, recon=0.0734, kl=0.0019, beta=0.0004\n",
      "Batch 80, loss=0.0651, recon=0.0651, kl=0.0015, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0835 (Recon: 0.0835, KL: 0.0020, Current Beta: 0.0004) | Avg Valid Loss: 0.0725 | Avg Valid recon Loss: 0.0725\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0489, recon=0.0489, kl=0.0006, beta=0.0006\n",
      "Batch 40, loss=0.0714, recon=0.0714, kl=0.0005, beta=0.0006\n",
      "Batch 60, loss=0.0540, recon=0.0540, kl=0.0017, beta=0.0006\n",
      "Batch 80, loss=0.0586, recon=0.0586, kl=0.0005, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0799 (Recon: 0.0799, KL: 0.0007, Current Beta: 0.0006) | Avg Valid Loss: 0.0700 | Avg Valid recon Loss: 0.0700\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0531, recon=0.0531, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0731, recon=0.0731, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0604, recon=0.0604, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0613, recon=0.0613, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0776 (Recon: 0.0776, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0683 | Avg Valid recon Loss: 0.0683\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0571, recon=0.0571, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0422, recon=0.0422, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0496, recon=0.0496, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0601, recon=0.0601, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0753 (Recon: 0.0753, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0658 | Avg Valid recon Loss: 0.0658\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1456, recon=0.1456, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0482, recon=0.0482, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0631, recon=0.0631, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0568, recon=0.0568, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0728 (Recon: 0.0728, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.0649 | Avg Valid recon Loss: 0.0649\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0507, recon=0.0507, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0600, recon=0.0600, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0695, recon=0.0695, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0534, recon=0.0534, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0707 (Recon: 0.0707, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.0634 | Avg Valid recon Loss: 0.0634\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0442, recon=0.0442, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0581, recon=0.0581, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0651, recon=0.0651, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0810, recon=0.0810, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0693 (Recon: 0.0693, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.0615 | Avg Valid recon Loss: 0.0615\n",
      "\n",
      "[VRAE Run 150/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2781, recon=0.2781, kl=54.7164, beta=0.0000\n",
      "Batch 40, loss=0.1674, recon=0.1674, kl=85.8581, beta=0.0000\n",
      "Batch 60, loss=0.0746, recon=0.0746, kl=100.0981, beta=0.0000\n",
      "Batch 80, loss=1.1032, recon=1.1032, kl=111.5257, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2234 (Recon: 0.2234, KL: 78.4459, Current Beta: 0.0000) | Avg Valid Loss: 0.0910 | Avg Valid recon Loss: 0.0910\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0710, recon=0.0710, kl=118.2953, beta=0.0000\n",
      "Batch 40, loss=0.1968, recon=0.1968, kl=127.2305, beta=0.0000\n",
      "Batch 60, loss=0.0587, recon=0.0587, kl=115.0356, beta=0.0000\n",
      "Batch 80, loss=0.0520, recon=0.0520, kl=110.1793, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0944 (Recon: 0.0944, KL: 117.1659, Current Beta: 0.0000) | Avg Valid Loss: 0.0711 | Avg Valid recon Loss: 0.0711\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0596, recon=0.0596, kl=120.7255, beta=0.0000\n",
      "Batch 40, loss=0.0459, recon=0.0459, kl=129.5997, beta=0.0000\n",
      "Batch 60, loss=0.0586, recon=0.0586, kl=117.5034, beta=0.0000\n",
      "Batch 80, loss=0.0610, recon=0.0610, kl=125.8118, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0761 (Recon: 0.0761, KL: 122.1502, Current Beta: 0.0000) | Avg Valid Loss: 0.0628 | Avg Valid recon Loss: 0.0628\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0457, recon=0.0456, kl=115.4680, beta=0.0000\n",
      "Batch 40, loss=0.0585, recon=0.0585, kl=111.2111, beta=0.0000\n",
      "Batch 60, loss=0.1134, recon=0.1134, kl=120.9257, beta=0.0000\n",
      "Batch 80, loss=0.0444, recon=0.0444, kl=115.4866, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0663 (Recon: 0.0663, KL: 116.4214, Current Beta: 0.0000) | Avg Valid Loss: 0.0590 | Avg Valid recon Loss: 0.0590\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0410, recon=0.0410, kl=122.5741, beta=0.0000\n",
      "Batch 40, loss=0.0579, recon=0.0579, kl=99.6096, beta=0.0000\n",
      "Batch 60, loss=0.0620, recon=0.0620, kl=102.3487, beta=0.0000\n",
      "Batch 80, loss=0.0607, recon=0.0607, kl=113.4905, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0608 (Recon: 0.0608, KL: 111.2226, Current Beta: 0.0000) | Avg Valid Loss: 0.0567 | Avg Valid recon Loss: 0.0567\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0448, recon=0.0448, kl=99.1911, beta=0.0000\n",
      "Batch 40, loss=0.0474, recon=0.0474, kl=84.5678, beta=0.0000\n",
      "Batch 60, loss=0.0547, recon=0.0547, kl=83.2230, beta=0.0000\n",
      "Batch 80, loss=0.0353, recon=0.0353, kl=87.7371, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0588 (Recon: 0.0588, KL: 91.5790, Current Beta: 0.0000) | Avg Valid Loss: 0.0743 | Avg Valid recon Loss: 0.0743\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0549, recon=0.0549, kl=68.6146, beta=0.0000\n",
      "Batch 40, loss=0.0499, recon=0.0499, kl=75.0246, beta=0.0000\n",
      "Batch 60, loss=0.4671, recon=0.4671, kl=70.2346, beta=0.0000\n",
      "Batch 80, loss=0.0359, recon=0.0359, kl=68.6582, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 73.1283, Current Beta: 0.0000) | Avg Valid Loss: 0.0512 | Avg Valid recon Loss: 0.0512\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0416, recon=0.0415, kl=45.2476, beta=0.0000\n",
      "Batch 40, loss=0.0367, recon=0.0366, kl=44.7821, beta=0.0000\n",
      "Batch 60, loss=0.0479, recon=0.0478, kl=42.0597, beta=0.0000\n",
      "Batch 80, loss=0.0558, recon=0.0558, kl=40.8060, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0545, KL: 45.8706, Current Beta: 0.0000) | Avg Valid Loss: 0.0533 | Avg Valid recon Loss: 0.0532\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0474, recon=0.0474, kl=22.0132, beta=0.0000\n",
      "Batch 40, loss=0.0535, recon=0.0534, kl=26.8499, beta=0.0000\n",
      "Batch 60, loss=0.0362, recon=0.0361, kl=19.1677, beta=0.0000\n",
      "Batch 80, loss=0.0333, recon=0.0332, kl=21.1813, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0551, KL: 23.4915, Current Beta: 0.0000) | Avg Valid Loss: 0.0459 | Avg Valid recon Loss: 0.0458\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0356, recon=0.0355, kl=5.8038, beta=0.0000\n",
      "Batch 40, loss=0.0339, recon=0.0338, kl=8.6063, beta=0.0000\n",
      "Batch 60, loss=0.0366, recon=0.0365, kl=7.4019, beta=0.0000\n",
      "Batch 80, loss=0.0345, recon=0.0344, kl=4.8979, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0515, KL: 8.2696, Current Beta: 0.0000) | Avg Valid Loss: 0.0457 | Avg Valid recon Loss: 0.0456\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=1.8816, beta=0.0000\n",
      "Batch 40, loss=0.0424, recon=0.0422, kl=4.2669, beta=0.0000\n",
      "Batch 60, loss=0.0433, recon=0.0431, kl=4.9779, beta=0.0000\n",
      "Batch 80, loss=0.0363, recon=0.0362, kl=2.3075, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0522, KL: 3.5335, Current Beta: 0.0000) | Avg Valid Loss: 0.0457 | Avg Valid recon Loss: 0.0457\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0424, recon=0.0423, kl=1.1293, beta=0.0001\n",
      "Batch 40, loss=0.0341, recon=0.0333, kl=10.1976, beta=0.0001\n",
      "Batch 60, loss=0.0543, recon=0.0527, kl=20.9626, beta=0.0001\n",
      "Batch 80, loss=0.1018, recon=0.1009, kl=11.5520, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0512 (Recon: 0.0505, KL: 9.6112, Current Beta: 0.0001) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0334, recon=0.0320, kl=7.6405, beta=0.0002\n",
      "Batch 40, loss=0.0279, recon=0.0259, kl=11.0784, beta=0.0002\n",
      "Batch 60, loss=0.0646, recon=0.0631, kl=8.2901, beta=0.0002\n",
      "Batch 80, loss=0.0329, recon=0.0315, kl=7.3612, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0513, KL: 8.5076, Current Beta: 0.0002) | Avg Valid Loss: 0.0457 | Avg Valid recon Loss: 0.0445\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0371, recon=0.0353, kl=4.6348, beta=0.0004\n",
      "Batch 40, loss=0.0374, recon=0.0356, kl=4.8547, beta=0.0004\n",
      "Batch 60, loss=0.0905, recon=0.0884, kl=5.4726, beta=0.0004\n",
      "Batch 80, loss=0.0584, recon=0.0572, kl=3.1003, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0489, KL: 4.8926, Current Beta: 0.0004) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0567, recon=0.0515, kl=8.4528, beta=0.0006\n",
      "Batch 40, loss=0.0633, recon=0.0561, kl=11.6325, beta=0.0006\n",
      "Batch 60, loss=0.0597, recon=0.0534, kl=10.1926, beta=0.0006\n",
      "Batch 80, loss=0.0559, recon=0.0466, kl=14.9408, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.3251 (Recon: 0.3184, KL: 10.7466, Current Beta: 0.0006) | Avg Valid Loss: 0.0643 | Avg Valid recon Loss: 0.0552\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0600, recon=0.0490, kl=10.9736, beta=0.0010\n",
      "Batch 40, loss=0.0605, recon=0.0511, kl=9.4454, beta=0.0010\n",
      "Batch 60, loss=0.0485, recon=0.0426, kl=5.9149, beta=0.0010\n",
      "Batch 80, loss=0.0638, recon=0.0562, kl=7.5972, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0766 (Recon: 0.0672, KL: 9.4021, Current Beta: 0.0010) | Avg Valid Loss: 0.0521 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0437, recon=0.0384, kl=5.3019, beta=0.0010\n",
      "Batch 40, loss=0.0397, recon=0.0353, kl=4.4234, beta=0.0010\n",
      "Batch 60, loss=0.0529, recon=0.0466, kl=6.2467, beta=0.0010\n",
      "Batch 80, loss=0.0435, recon=0.0363, kl=7.2154, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0607 (Recon: 0.0548, KL: 5.9331, Current Beta: 0.0010) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0430, recon=0.0380, kl=4.9966, beta=0.0010\n",
      "Batch 40, loss=0.0381, recon=0.0338, kl=4.2789, beta=0.0010\n",
      "Batch 60, loss=0.0615, recon=0.0576, kl=3.8563, beta=0.0010\n",
      "Batch 80, loss=0.0600, recon=0.0563, kl=3.6696, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0543 (Recon: 0.0499, KL: 4.4449, Current Beta: 0.0010) | Avg Valid Loss: 0.0467 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0647, recon=0.0511, kl=13.6322, beta=0.0010\n",
      "Batch 40, loss=0.0520, recon=0.0374, kl=14.6467, beta=0.0010\n",
      "Batch 60, loss=0.1358, recon=0.1212, kl=14.6224, beta=0.0010\n",
      "Batch 80, loss=0.0482, recon=0.0351, kl=13.1309, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0776 (Recon: 0.0644, KL: 13.2107, Current Beta: 0.0010) | Avg Valid Loss: 0.0589 | Avg Valid recon Loss: 0.0462\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0524, recon=0.0402, kl=12.1277, beta=0.0010\n",
      "Batch 40, loss=0.0472, recon=0.0360, kl=11.1947, beta=0.0010\n",
      "Batch 60, loss=0.0411, recon=0.0307, kl=10.3668, beta=0.0010\n",
      "Batch 80, loss=0.0447, recon=0.0349, kl=9.8175, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0599 (Recon: 0.0489, KL: 10.9745, Current Beta: 0.0010) | Avg Valid Loss: 0.0515 | Avg Valid recon Loss: 0.0421\n",
      "\n",
      "[VRAE Run 151/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3791, recon=0.3791, kl=0.1911, beta=0.0000\n",
      "Batch 40, loss=0.2424, recon=0.2424, kl=2.6550, beta=0.0000\n",
      "Batch 60, loss=0.2403, recon=0.2403, kl=10.5054, beta=0.0000\n",
      "Batch 80, loss=0.6183, recon=0.6183, kl=16.1342, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4118 (Recon: 0.4118, KL: 6.8954, Current Beta: 0.0000) | Avg Valid Loss: 0.2151 | Avg Valid recon Loss: 0.2151\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2237, recon=0.2237, kl=22.7645, beta=0.0000\n",
      "Batch 40, loss=0.1551, recon=0.1551, kl=25.9708, beta=0.0000\n",
      "Batch 60, loss=0.2296, recon=0.2296, kl=26.7377, beta=0.0000\n",
      "Batch 80, loss=0.1146, recon=0.1146, kl=27.5668, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1993 (Recon: 0.1993, KL: 25.1442, Current Beta: 0.0000) | Avg Valid Loss: 0.1367 | Avg Valid recon Loss: 0.1367\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1379, recon=0.1379, kl=30.5528, beta=0.0000\n",
      "Batch 40, loss=0.1118, recon=0.1118, kl=32.3623, beta=0.0000\n",
      "Batch 60, loss=0.1225, recon=0.1225, kl=34.3003, beta=0.0000\n",
      "Batch 80, loss=0.1313, recon=0.1313, kl=35.8807, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1538 (Recon: 0.1538, KL: 32.4953, Current Beta: 0.0000) | Avg Valid Loss: 0.1109 | Avg Valid recon Loss: 0.1109\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0931, recon=0.0931, kl=36.1141, beta=0.0000\n",
      "Batch 40, loss=0.1672, recon=0.1672, kl=37.0973, beta=0.0000\n",
      "Batch 60, loss=0.0897, recon=0.0897, kl=37.9132, beta=0.0000\n",
      "Batch 80, loss=0.1172, recon=0.1172, kl=39.1047, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1274 (Recon: 0.1274, KL: 37.1042, Current Beta: 0.0000) | Avg Valid Loss: 0.0948 | Avg Valid recon Loss: 0.0948\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1866, recon=0.1866, kl=38.0435, beta=0.0000\n",
      "Batch 40, loss=0.0756, recon=0.0756, kl=38.3703, beta=0.0000\n",
      "Batch 60, loss=0.0871, recon=0.0871, kl=39.0048, beta=0.0000\n",
      "Batch 80, loss=0.0726, recon=0.0726, kl=38.6519, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1090 (Recon: 0.1090, KL: 38.5006, Current Beta: 0.0000) | Avg Valid Loss: 0.0837 | Avg Valid recon Loss: 0.0837\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2028, recon=0.2028, kl=38.1154, beta=0.0000\n",
      "Batch 40, loss=0.1100, recon=0.1100, kl=35.6404, beta=0.0000\n",
      "Batch 60, loss=0.8237, recon=0.8237, kl=34.1039, beta=0.0000\n",
      "Batch 80, loss=0.0629, recon=0.0629, kl=33.6141, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0952 (Recon: 0.0952, KL: 35.8748, Current Beta: 0.0000) | Avg Valid Loss: 0.0755 | Avg Valid recon Loss: 0.0755\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0695, recon=0.0694, kl=29.8783, beta=0.0000\n",
      "Batch 40, loss=0.0988, recon=0.0988, kl=25.6861, beta=0.0000\n",
      "Batch 60, loss=0.0684, recon=0.0684, kl=23.4738, beta=0.0000\n",
      "Batch 80, loss=0.0679, recon=0.0679, kl=23.3570, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0862 (Recon: 0.0862, KL: 26.4352, Current Beta: 0.0000) | Avg Valid Loss: 0.0703 | Avg Valid recon Loss: 0.0703\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0752, recon=0.0751, kl=16.5394, beta=0.0000\n",
      "Batch 40, loss=0.7286, recon=0.7286, kl=12.8883, beta=0.0000\n",
      "Batch 60, loss=0.0467, recon=0.0467, kl=13.2792, beta=0.0000\n",
      "Batch 80, loss=0.0941, recon=0.0941, kl=12.8247, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0795 (Recon: 0.0794, KL: 14.9501, Current Beta: 0.0000) | Avg Valid Loss: 0.0662 | Avg Valid recon Loss: 0.0662\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0439, recon=0.0439, kl=6.2680, beta=0.0000\n",
      "Batch 40, loss=0.0640, recon=0.0640, kl=5.8330, beta=0.0000\n",
      "Batch 60, loss=0.0589, recon=0.0588, kl=6.3134, beta=0.0000\n",
      "Batch 80, loss=0.0706, recon=0.0706, kl=5.0670, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0742 (Recon: 0.0742, KL: 6.6138, Current Beta: 0.0000) | Avg Valid Loss: 0.0638 | Avg Valid recon Loss: 0.0638\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0466, recon=0.0466, kl=2.0643, beta=0.0000\n",
      "Batch 40, loss=0.0583, recon=0.0583, kl=2.4318, beta=0.0000\n",
      "Batch 60, loss=0.0847, recon=0.0847, kl=2.1245, beta=0.0000\n",
      "Batch 80, loss=0.0662, recon=0.0662, kl=1.9273, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0701 (Recon: 0.0701, KL: 2.3440, Current Beta: 0.0000) | Avg Valid Loss: 0.0607 | Avg Valid recon Loss: 0.0607\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0528, recon=0.0527, kl=0.6463, beta=0.0000\n",
      "Batch 40, loss=0.0432, recon=0.0432, kl=0.7136, beta=0.0000\n",
      "Batch 60, loss=0.0499, recon=0.0498, kl=0.3606, beta=0.0000\n",
      "Batch 80, loss=0.0521, recon=0.0521, kl=0.4948, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0669 (Recon: 0.0669, KL: 0.6367, Current Beta: 0.0000) | Avg Valid Loss: 0.0585 | Avg Valid recon Loss: 0.0585\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0915, recon=0.0915, kl=0.0685, beta=0.0001\n",
      "Batch 40, loss=0.0368, recon=0.0368, kl=0.0553, beta=0.0001\n",
      "Batch 60, loss=0.0468, recon=0.0468, kl=0.0894, beta=0.0001\n",
      "Batch 80, loss=0.0437, recon=0.0437, kl=0.1023, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0637 (Recon: 0.0636, KL: 0.1103, Current Beta: 0.0001) | Avg Valid Loss: 0.0562 | Avg Valid recon Loss: 0.0562\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0509, recon=0.0509, kl=0.0236, beta=0.0002\n",
      "Batch 40, loss=0.0411, recon=0.0410, kl=0.0092, beta=0.0002\n",
      "Batch 60, loss=0.1767, recon=0.1767, kl=0.0163, beta=0.0002\n",
      "Batch 80, loss=0.0417, recon=0.0417, kl=0.0131, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0613 (Recon: 0.0613, KL: 0.0144, Current Beta: 0.0002) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0541\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=0.0023, beta=0.0004\n",
      "Batch 40, loss=0.0617, recon=0.0617, kl=0.0011, beta=0.0004\n",
      "Batch 60, loss=0.0426, recon=0.0426, kl=0.0026, beta=0.0004\n",
      "Batch 80, loss=0.0356, recon=0.0356, kl=0.0021, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0596 (Recon: 0.0596, KL: 0.0030, Current Beta: 0.0004) | Avg Valid Loss: 0.0526 | Avg Valid recon Loss: 0.0526\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0394, recon=0.0394, kl=0.0011, beta=0.0006\n",
      "Batch 40, loss=0.0570, recon=0.0570, kl=0.0008, beta=0.0006\n",
      "Batch 60, loss=0.0377, recon=0.0377, kl=0.0014, beta=0.0006\n",
      "Batch 80, loss=0.0387, recon=0.0387, kl=0.0006, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0578 (Recon: 0.0578, KL: 0.0013, Current Beta: 0.0006) | Avg Valid Loss: 0.0514 | Avg Valid recon Loss: 0.0514\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0451, recon=0.0451, kl=0.0009, beta=0.0010\n",
      "Batch 40, loss=0.0292, recon=0.0292, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0285, recon=0.0285, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0479, recon=0.0479, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0561 (Recon: 0.0561, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0498 | Avg Valid recon Loss: 0.0498\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0394, recon=0.0394, kl=0.0008, beta=0.0010\n",
      "Batch 40, loss=0.0305, recon=0.0305, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0414, recon=0.0414, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0481, recon=0.0481, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0549 (Recon: 0.0549, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0417, recon=0.0417, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.4933, recon=0.4933, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0410, recon=0.0410, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0366, recon=0.0366, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0536 (Recon: 0.0536, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0789, recon=0.0789, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0340, recon=0.0340, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0401, recon=0.0401, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0302, recon=0.0302, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0523, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0464 | Avg Valid recon Loss: 0.0464\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0487, recon=0.0487, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0455, recon=0.0455, kl=0.0010, beta=0.0010\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.1292, recon=0.1292, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0509 (Recon: 0.0509, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0454 | Avg Valid recon Loss: 0.0454\n",
      "\n",
      "[VRAE Run 152/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1765, recon=0.1765, kl=31.2461, beta=0.0000\n",
      "Batch 40, loss=0.1341, recon=0.1341, kl=30.6341, beta=0.0000\n",
      "Batch 60, loss=0.0815, recon=0.0815, kl=33.1177, beta=0.0000\n",
      "Batch 80, loss=0.1191, recon=0.1191, kl=35.6953, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1707 (Recon: 0.1707, KL: 29.8115, Current Beta: 0.0000) | Avg Valid Loss: 0.0709 | Avg Valid recon Loss: 0.0709\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0610, recon=0.0610, kl=34.9433, beta=0.0000\n",
      "Batch 40, loss=0.0712, recon=0.0712, kl=40.3300, beta=0.0000\n",
      "Batch 60, loss=0.0483, recon=0.0483, kl=36.9180, beta=0.0000\n",
      "Batch 80, loss=0.6894, recon=0.6894, kl=39.4121, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0751 (Recon: 0.0751, KL: 36.7106, Current Beta: 0.0000) | Avg Valid Loss: 0.0673 | Avg Valid recon Loss: 0.0673\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0510, recon=0.0510, kl=38.1982, beta=0.0000\n",
      "Batch 40, loss=0.0366, recon=0.0366, kl=40.0039, beta=0.0000\n",
      "Batch 60, loss=0.0499, recon=0.0499, kl=40.3206, beta=0.0000\n",
      "Batch 80, loss=0.0763, recon=0.0763, kl=39.5337, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0626 (Recon: 0.0626, KL: 39.5175, Current Beta: 0.0000) | Avg Valid Loss: 0.0528 | Avg Valid recon Loss: 0.0528\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0311, recon=0.0311, kl=37.9278, beta=0.0000\n",
      "Batch 40, loss=0.1451, recon=0.1451, kl=33.9435, beta=0.0000\n",
      "Batch 60, loss=0.0352, recon=0.0352, kl=34.0028, beta=0.0000\n",
      "Batch 80, loss=0.0414, recon=0.0414, kl=35.3775, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0556 (Recon: 0.0556, KL: 35.9466, Current Beta: 0.0000) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0465\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=35.4632, beta=0.0000\n",
      "Batch 40, loss=0.0441, recon=0.0441, kl=34.5888, beta=0.0000\n",
      "Batch 60, loss=0.0521, recon=0.0521, kl=35.2715, beta=0.0000\n",
      "Batch 80, loss=0.0353, recon=0.0353, kl=33.8740, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0506 (Recon: 0.0506, KL: 34.5059, Current Beta: 0.0000) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0344, recon=0.0344, kl=31.4149, beta=0.0000\n",
      "Batch 40, loss=0.0344, recon=0.0344, kl=29.8732, beta=0.0000\n",
      "Batch 60, loss=0.0436, recon=0.0436, kl=28.3007, beta=0.0000\n",
      "Batch 80, loss=0.0383, recon=0.0383, kl=29.3000, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0487 (Recon: 0.0487, KL: 29.8805, Current Beta: 0.0000) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0422, recon=0.0422, kl=25.2826, beta=0.0000\n",
      "Batch 40, loss=0.0409, recon=0.0409, kl=22.5799, beta=0.0000\n",
      "Batch 60, loss=0.0338, recon=0.0338, kl=20.5374, beta=0.0000\n",
      "Batch 80, loss=0.0334, recon=0.0334, kl=22.0298, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0467 (Recon: 0.0466, KL: 23.3723, Current Beta: 0.0000) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0939, recon=0.0938, kl=17.0998, beta=0.0000\n",
      "Batch 40, loss=0.0414, recon=0.0414, kl=15.1604, beta=0.0000\n",
      "Batch 60, loss=0.3523, recon=0.3523, kl=14.7298, beta=0.0000\n",
      "Batch 80, loss=0.0687, recon=0.0687, kl=14.4295, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 16.1191, Current Beta: 0.0000) | Avg Valid Loss: 0.0400 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0651, recon=0.0651, kl=5.7298, beta=0.0000\n",
      "Batch 40, loss=0.0333, recon=0.0333, kl=8.0227, beta=0.0000\n",
      "Batch 60, loss=0.0997, recon=0.0997, kl=7.8693, beta=0.0000\n",
      "Batch 80, loss=0.0457, recon=0.0456, kl=9.9099, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0445 (Recon: 0.0444, KL: 8.5910, Current Beta: 0.0000) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0849, recon=0.0849, kl=1.7377, beta=0.0000\n",
      "Batch 40, loss=0.0314, recon=0.0314, kl=2.7537, beta=0.0000\n",
      "Batch 60, loss=0.0337, recon=0.0336, kl=2.1765, beta=0.0000\n",
      "Batch 80, loss=0.0664, recon=0.0663, kl=1.8242, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0414, KL: 2.8306, Current Beta: 0.0000) | Avg Valid Loss: 0.0362 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0362, recon=0.0362, kl=0.3704, beta=0.0000\n",
      "Batch 40, loss=0.0242, recon=0.0242, kl=0.4605, beta=0.0000\n",
      "Batch 60, loss=0.0777, recon=0.0777, kl=0.3811, beta=0.0000\n",
      "Batch 80, loss=0.0585, recon=0.0585, kl=0.5442, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0450, KL: 0.5851, Current Beta: 0.0000) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0501, recon=0.0501, kl=0.1107, beta=0.0001\n",
      "Batch 40, loss=0.0274, recon=0.0274, kl=0.0652, beta=0.0001\n",
      "Batch 60, loss=0.0234, recon=0.0234, kl=0.0498, beta=0.0001\n",
      "Batch 80, loss=0.0392, recon=0.0392, kl=0.0931, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0417, KL: 0.1029, Current Beta: 0.0001) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0424\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0466, recon=0.0466, kl=0.0357, beta=0.0002\n",
      "Batch 40, loss=0.0449, recon=0.0449, kl=0.0078, beta=0.0002\n",
      "Batch 60, loss=0.0435, recon=0.0434, kl=0.0106, beta=0.0002\n",
      "Batch 80, loss=0.0275, recon=0.0275, kl=0.0457, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0451 (Recon: 0.0451, KL: 0.0305, Current Beta: 0.0002) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0448, recon=0.0448, kl=0.0045, beta=0.0004\n",
      "Batch 40, loss=0.0576, recon=0.0576, kl=0.0038, beta=0.0004\n",
      "Batch 60, loss=0.0270, recon=0.0270, kl=0.0058, beta=0.0004\n",
      "Batch 80, loss=0.0262, recon=0.0262, kl=0.0031, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0412 (Recon: 0.0412, KL: 0.0051, Current Beta: 0.0004) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0301, recon=0.0301, kl=0.0014, beta=0.0006\n",
      "Batch 40, loss=0.0274, recon=0.0274, kl=0.0027, beta=0.0006\n",
      "Batch 60, loss=0.0292, recon=0.0292, kl=0.0026, beta=0.0006\n",
      "Batch 80, loss=0.0458, recon=0.0458, kl=0.0026, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0402 (Recon: 0.0402, KL: 0.0024, Current Beta: 0.0006) | Avg Valid Loss: 0.0354 | Avg Valid recon Loss: 0.0354\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1003, recon=0.1003, kl=0.0010, beta=0.0010\n",
      "Batch 40, loss=0.0417, recon=0.0417, kl=0.0077, beta=0.0010\n",
      "Batch 60, loss=0.0313, recon=0.0313, kl=0.0008, beta=0.0010\n",
      "Batch 80, loss=0.0388, recon=0.0388, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0397 (Recon: 0.0397, KL: 0.0011, Current Beta: 0.0010) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0225, recon=0.0225, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.0408, recon=0.0408, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0302, recon=0.0302, kl=0.0012, beta=0.0010\n",
      "Batch 80, loss=0.0247, recon=0.0247, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0400, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0335 | Avg Valid recon Loss: 0.0335\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0301, recon=0.0301, kl=0.0013, beta=0.0010\n",
      "Batch 40, loss=0.0645, recon=0.0645, kl=0.0007, beta=0.0010\n",
      "Batch 60, loss=0.0278, recon=0.0278, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.0446, recon=0.0446, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0383 (Recon: 0.0383, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0385 | Avg Valid recon Loss: 0.0385\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0207, recon=0.0207, kl=0.0028, beta=0.0010\n",
      "Batch 40, loss=0.0278, recon=0.0278, kl=0.0008, beta=0.0010\n",
      "Batch 60, loss=0.0230, recon=0.0230, kl=0.0010, beta=0.0010\n",
      "Batch 80, loss=0.0323, recon=0.0323, kl=0.0010, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0378 (Recon: 0.0378, KL: 0.0011, Current Beta: 0.0010) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0274, recon=0.0274, kl=0.0012, beta=0.0010\n",
      "Batch 40, loss=0.0280, recon=0.0280, kl=0.0021, beta=0.0010\n",
      "Batch 60, loss=0.0330, recon=0.0330, kl=0.0015, beta=0.0010\n",
      "Batch 80, loss=0.0944, recon=0.0944, kl=0.0011, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0370, KL: 0.0016, Current Beta: 0.0010) | Avg Valid Loss: 0.0320 | Avg Valid recon Loss: 0.0320\n",
      "\n",
      "[VRAE Run 153/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4778, recon=0.4778, kl=0.3918, beta=0.0000\n",
      "Batch 40, loss=0.3676, recon=0.3676, kl=10.7222, beta=0.0000\n",
      "Batch 60, loss=0.2503, recon=0.2503, kl=36.1806, beta=0.0000\n",
      "Batch 80, loss=0.1626, recon=0.1626, kl=46.4991, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4271 (Recon: 0.4271, KL: 21.3387, Current Beta: 0.0000) | Avg Valid Loss: 0.2147 | Avg Valid recon Loss: 0.2147\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1737, recon=0.1737, kl=54.3020, beta=0.0000\n",
      "Batch 40, loss=0.3403, recon=0.3403, kl=55.1440, beta=0.0000\n",
      "Batch 60, loss=1.2043, recon=1.2043, kl=57.8182, beta=0.0000\n",
      "Batch 80, loss=0.1167, recon=0.1167, kl=62.3831, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1996 (Recon: 0.1996, KL: 56.6142, Current Beta: 0.0000) | Avg Valid Loss: 0.1380 | Avg Valid recon Loss: 0.1380\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1191, recon=0.1191, kl=65.8132, beta=0.0000\n",
      "Batch 40, loss=0.1172, recon=0.1172, kl=67.3043, beta=0.0000\n",
      "Batch 60, loss=0.1348, recon=0.1348, kl=70.6876, beta=0.0000\n",
      "Batch 80, loss=0.1093, recon=0.1093, kl=72.5473, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1544 (Recon: 0.1544, KL: 68.6798, Current Beta: 0.0000) | Avg Valid Loss: 0.1103 | Avg Valid recon Loss: 0.1103\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0920, recon=0.0920, kl=76.0735, beta=0.0000\n",
      "Batch 40, loss=0.0945, recon=0.0945, kl=78.0004, beta=0.0000\n",
      "Batch 60, loss=0.1141, recon=0.1141, kl=77.1846, beta=0.0000\n",
      "Batch 80, loss=0.1387, recon=0.1387, kl=77.6630, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1288 (Recon: 0.1288, KL: 76.8889, Current Beta: 0.0000) | Avg Valid Loss: 0.0952 | Avg Valid recon Loss: 0.0952\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0971, recon=0.0971, kl=76.6497, beta=0.0000\n",
      "Batch 40, loss=0.0685, recon=0.0685, kl=76.5327, beta=0.0000\n",
      "Batch 60, loss=0.0952, recon=0.0952, kl=72.9808, beta=0.0000\n",
      "Batch 80, loss=0.0826, recon=0.0826, kl=72.4370, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1106 (Recon: 0.1106, KL: 74.7187, Current Beta: 0.0000) | Avg Valid Loss: 0.0850 | Avg Valid recon Loss: 0.0850\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0761, recon=0.0761, kl=68.1147, beta=0.0000\n",
      "Batch 40, loss=0.0826, recon=0.0826, kl=62.6088, beta=0.0000\n",
      "Batch 60, loss=0.1271, recon=0.1270, kl=60.1403, beta=0.0000\n",
      "Batch 80, loss=0.0899, recon=0.0899, kl=59.2615, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0981 (Recon: 0.0980, KL: 63.3049, Current Beta: 0.0000) | Avg Valid Loss: 0.0771 | Avg Valid recon Loss: 0.0771\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0693, recon=0.0693, kl=48.5765, beta=0.0000\n",
      "Batch 40, loss=0.0596, recon=0.0596, kl=42.6790, beta=0.0000\n",
      "Batch 60, loss=0.0718, recon=0.0717, kl=37.5684, beta=0.0000\n",
      "Batch 80, loss=0.0700, recon=0.0699, kl=37.1157, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0886 (Recon: 0.0886, KL: 42.7680, Current Beta: 0.0000) | Avg Valid Loss: 0.0716 | Avg Valid recon Loss: 0.0716\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.2972, recon=0.2972, kl=24.1922, beta=0.0000\n",
      "Batch 40, loss=0.0681, recon=0.0681, kl=19.2878, beta=0.0000\n",
      "Batch 60, loss=0.1019, recon=0.1018, kl=19.5325, beta=0.0000\n",
      "Batch 80, loss=0.0909, recon=0.0909, kl=19.7710, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0818 (Recon: 0.0818, KL: 22.5590, Current Beta: 0.0000) | Avg Valid Loss: 0.0670 | Avg Valid recon Loss: 0.0670\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0501, recon=0.0500, kl=7.9802, beta=0.0000\n",
      "Batch 40, loss=0.0727, recon=0.0727, kl=7.2099, beta=0.0000\n",
      "Batch 60, loss=0.0522, recon=0.0522, kl=7.3026, beta=0.0000\n",
      "Batch 80, loss=0.0475, recon=0.0474, kl=7.4067, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0762 (Recon: 0.0762, KL: 8.5448, Current Beta: 0.0000) | Avg Valid Loss: 0.0640 | Avg Valid recon Loss: 0.0639\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0554, recon=0.0554, kl=2.2835, beta=0.0000\n",
      "Batch 40, loss=0.0461, recon=0.0461, kl=2.3578, beta=0.0000\n",
      "Batch 60, loss=0.0544, recon=0.0544, kl=2.5067, beta=0.0000\n",
      "Batch 80, loss=0.0551, recon=0.0551, kl=1.9221, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0717 (Recon: 0.0717, KL: 2.6781, Current Beta: 0.0000) | Avg Valid Loss: 0.0610 | Avg Valid recon Loss: 0.0610\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0540, recon=0.0540, kl=0.5309, beta=0.0000\n",
      "Batch 40, loss=0.0557, recon=0.0557, kl=0.6749, beta=0.0000\n",
      "Batch 60, loss=0.0540, recon=0.0539, kl=0.5410, beta=0.0000\n",
      "Batch 80, loss=0.0445, recon=0.0445, kl=0.4005, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0684 (Recon: 0.0684, KL: 0.6212, Current Beta: 0.0000) | Avg Valid Loss: 0.0590 | Avg Valid recon Loss: 0.0590\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0597, recon=0.0596, kl=0.0904, beta=0.0001\n",
      "Batch 40, loss=0.0501, recon=0.0500, kl=0.0951, beta=0.0001\n",
      "Batch 60, loss=0.0741, recon=0.0741, kl=0.0440, beta=0.0001\n",
      "Batch 80, loss=0.1148, recon=0.1148, kl=0.0520, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0652 (Recon: 0.0652, KL: 0.0995, Current Beta: 0.0001) | Avg Valid Loss: 0.0569 | Avg Valid recon Loss: 0.0569\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0614, recon=0.0614, kl=0.0106, beta=0.0002\n",
      "Batch 40, loss=0.0407, recon=0.0407, kl=0.0073, beta=0.0002\n",
      "Batch 60, loss=0.1537, recon=0.1537, kl=0.0151, beta=0.0002\n",
      "Batch 80, loss=0.1408, recon=0.1408, kl=0.0052, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0627 (Recon: 0.0627, KL: 0.0115, Current Beta: 0.0002) | Avg Valid Loss: 0.0553 | Avg Valid recon Loss: 0.0553\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0396, recon=0.0396, kl=0.0067, beta=0.0004\n",
      "Batch 40, loss=0.0580, recon=0.0580, kl=0.0019, beta=0.0004\n",
      "Batch 60, loss=0.0394, recon=0.0394, kl=0.0009, beta=0.0004\n",
      "Batch 80, loss=0.0407, recon=0.0407, kl=0.0015, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0604 (Recon: 0.0604, KL: 0.0030, Current Beta: 0.0004) | Avg Valid Loss: 0.0534 | Avg Valid recon Loss: 0.0534\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0453, recon=0.0453, kl=0.0008, beta=0.0006\n",
      "Batch 40, loss=0.0645, recon=0.0645, kl=0.0018, beta=0.0006\n",
      "Batch 60, loss=0.0579, recon=0.0579, kl=0.0008, beta=0.0006\n",
      "Batch 80, loss=0.0382, recon=0.0382, kl=0.0009, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0586 (Recon: 0.0586, KL: 0.0012, Current Beta: 0.0006) | Avg Valid Loss: 0.0518 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0446, recon=0.0446, kl=0.0005, beta=0.0010\n",
      "Batch 40, loss=0.0400, recon=0.0400, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0420, recon=0.0420, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0483, recon=0.0483, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0505 | Avg Valid recon Loss: 0.0505\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0593, recon=0.0593, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0608, recon=0.0608, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0340, recon=0.0340, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0334, recon=0.0334, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0490 | Avg Valid recon Loss: 0.0490\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0290, recon=0.0290, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0559, recon=0.0559, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0384, recon=0.0384, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.6051, recon=0.6051, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0541 (Recon: 0.0541, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0481 | Avg Valid recon Loss: 0.0481\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0449, recon=0.0449, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0301, recon=0.0301, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0322, recon=0.0322, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0535, recon=0.0535, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0528 (Recon: 0.0528, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0474\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1241, recon=0.1241, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0335, recon=0.0335, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0265, recon=0.0265, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0311, recon=0.0311, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0514 (Recon: 0.0514, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0458\n",
      "\n",
      "[VRAE Run 154/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1549, recon=0.1549, kl=41.3878, beta=0.0000\n",
      "Batch 40, loss=0.0935, recon=0.0935, kl=60.0092, beta=0.0000\n",
      "Batch 60, loss=0.0661, recon=0.0661, kl=60.6737, beta=0.0000\n",
      "Batch 80, loss=0.0496, recon=0.0496, kl=60.8602, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1800 (Recon: 0.1800, KL: 49.7170, Current Beta: 0.0000) | Avg Valid Loss: 0.0728 | Avg Valid recon Loss: 0.0728\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0877, recon=0.0877, kl=57.8911, beta=0.0000\n",
      "Batch 40, loss=0.0454, recon=0.0454, kl=60.0138, beta=0.0000\n",
      "Batch 60, loss=0.0433, recon=0.0433, kl=62.6724, beta=0.0000\n",
      "Batch 80, loss=0.0548, recon=0.0548, kl=67.6602, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0754 (Recon: 0.0754, KL: 61.2578, Current Beta: 0.0000) | Avg Valid Loss: 0.0576 | Avg Valid recon Loss: 0.0576\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0457, recon=0.0457, kl=69.1761, beta=0.0000\n",
      "Batch 40, loss=0.0606, recon=0.0606, kl=63.0829, beta=0.0000\n",
      "Batch 60, loss=0.0359, recon=0.0359, kl=57.8168, beta=0.0000\n",
      "Batch 80, loss=0.0374, recon=0.0374, kl=59.0727, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0630 (Recon: 0.0630, KL: 62.1385, Current Beta: 0.0000) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0474, recon=0.0474, kl=64.9534, beta=0.0000\n",
      "Batch 40, loss=0.0513, recon=0.0513, kl=61.4448, beta=0.0000\n",
      "Batch 60, loss=0.0650, recon=0.0650, kl=59.9500, beta=0.0000\n",
      "Batch 80, loss=0.0297, recon=0.0297, kl=62.1077, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0563 (Recon: 0.0563, KL: 62.1865, Current Beta: 0.0000) | Avg Valid Loss: 0.0471 | Avg Valid recon Loss: 0.0471\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0393, recon=0.0393, kl=63.9374, beta=0.0000\n",
      "Batch 40, loss=0.1046, recon=0.1046, kl=62.9367, beta=0.0000\n",
      "Batch 60, loss=0.0837, recon=0.0837, kl=60.3949, beta=0.0000\n",
      "Batch 80, loss=0.0353, recon=0.0353, kl=59.1052, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0523, KL: 61.8716, Current Beta: 0.0000) | Avg Valid Loss: 0.0471 | Avg Valid recon Loss: 0.0471\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0986, recon=0.0986, kl=53.2842, beta=0.0000\n",
      "Batch 40, loss=0.0313, recon=0.0312, kl=47.4665, beta=0.0000\n",
      "Batch 60, loss=0.0348, recon=0.0348, kl=49.2852, beta=0.0000\n",
      "Batch 80, loss=0.0345, recon=0.0345, kl=50.1109, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0486 (Recon: 0.0486, KL: 50.6728, Current Beta: 0.0000) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0367, recon=0.0366, kl=41.7739, beta=0.0000\n",
      "Batch 40, loss=0.0327, recon=0.0327, kl=35.4479, beta=0.0000\n",
      "Batch 60, loss=0.0556, recon=0.0556, kl=36.6106, beta=0.0000\n",
      "Batch 80, loss=0.0657, recon=0.0656, kl=33.7812, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0472, KL: 38.1578, Current Beta: 0.0000) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0448\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0326, recon=0.0326, kl=26.5255, beta=0.0000\n",
      "Batch 40, loss=0.0952, recon=0.0952, kl=28.8333, beta=0.0000\n",
      "Batch 60, loss=0.0609, recon=0.0609, kl=26.8631, beta=0.0000\n",
      "Batch 80, loss=0.0533, recon=0.0533, kl=25.4409, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0465, KL: 28.0010, Current Beta: 0.0000) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0316, recon=0.0315, kl=15.0159, beta=0.0000\n",
      "Batch 40, loss=0.0330, recon=0.0329, kl=19.0901, beta=0.0000\n",
      "Batch 60, loss=0.0429, recon=0.0427, kl=40.6345, beta=0.0000\n",
      "Batch 80, loss=0.0406, recon=0.0404, kl=40.9249, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2532 (Recon: 0.2530, KL: 30.9443, Current Beta: 0.0000) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0331, recon=0.0327, kl=38.1313, beta=0.0000\n",
      "Batch 40, loss=0.0370, recon=0.0366, kl=33.1521, beta=0.0000\n",
      "Batch 60, loss=0.0387, recon=0.0383, kl=32.1276, beta=0.0000\n",
      "Batch 80, loss=0.0484, recon=0.0481, kl=28.7841, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0445, KL: 33.4816, Current Beta: 0.0000) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0392\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0408, recon=0.0401, kl=24.2682, beta=0.0000\n",
      "Batch 40, loss=0.0434, recon=0.0428, kl=20.3296, beta=0.0000\n",
      "Batch 60, loss=0.0467, recon=0.0461, kl=18.5298, beta=0.0000\n",
      "Batch 80, loss=0.0318, recon=0.0313, kl=17.6254, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0450, KL: 21.2029, Current Beta: 0.0000) | Avg Valid Loss: 0.0416 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0328, recon=0.0318, kl=13.4222, beta=0.0001\n",
      "Batch 40, loss=0.0255, recon=0.0247, kl=10.0612, beta=0.0001\n",
      "Batch 60, loss=0.0304, recon=0.0297, kl=8.4729, beta=0.0001\n",
      "Batch 80, loss=0.0394, recon=0.0388, kl=7.7522, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0443 (Recon: 0.0435, KL: 10.6495, Current Beta: 0.0001) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0435, recon=0.0426, kl=5.3200, beta=0.0002\n",
      "Batch 40, loss=0.0300, recon=0.0293, kl=3.6271, beta=0.0002\n",
      "Batch 60, loss=0.0271, recon=0.0266, kl=3.0611, beta=0.0002\n",
      "Batch 80, loss=0.0874, recon=0.0868, kl=3.5032, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0420, KL: 4.1562, Current Beta: 0.0002) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0366\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0443, recon=0.0438, kl=1.3900, beta=0.0004\n",
      "Batch 40, loss=0.0350, recon=0.0342, kl=2.0051, beta=0.0004\n",
      "Batch 60, loss=0.0453, recon=0.0449, kl=1.0234, beta=0.0004\n",
      "Batch 80, loss=0.0348, recon=0.0346, kl=0.5842, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0412, KL: 1.3149, Current Beta: 0.0004) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0301, recon=0.0297, kl=0.6286, beta=0.0006\n",
      "Batch 40, loss=0.0230, recon=0.0226, kl=0.5871, beta=0.0006\n",
      "Batch 60, loss=0.0282, recon=0.0280, kl=0.2810, beta=0.0006\n",
      "Batch 80, loss=0.0315, recon=0.0314, kl=0.2067, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0408, KL: 0.3502, Current Beta: 0.0006) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0351, recon=0.0350, kl=0.0470, beta=0.0010\n",
      "Batch 40, loss=0.0467, recon=0.0466, kl=0.1183, beta=0.0010\n",
      "Batch 60, loss=0.0258, recon=0.0258, kl=0.0754, beta=0.0010\n",
      "Batch 80, loss=0.0306, recon=0.0306, kl=0.0572, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0389, KL: 0.0861, Current Beta: 0.0010) | Avg Valid Loss: 0.0333 | Avg Valid recon Loss: 0.0332\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=0.0332, beta=0.0010\n",
      "Batch 40, loss=0.0359, recon=0.0358, kl=0.0486, beta=0.0010\n",
      "Batch 60, loss=0.0226, recon=0.0225, kl=0.0435, beta=0.0010\n",
      "Batch 80, loss=0.0281, recon=0.0281, kl=0.0249, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0372 (Recon: 0.0371, KL: 0.0424, Current Beta: 0.0010) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0328\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0312, recon=0.0312, kl=0.0315, beta=0.0010\n",
      "Batch 40, loss=0.0317, recon=0.0317, kl=0.0145, beta=0.0010\n",
      "Batch 60, loss=0.0316, recon=0.0316, kl=0.0156, beta=0.0010\n",
      "Batch 80, loss=0.0267, recon=0.0266, kl=0.0320, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0383 (Recon: 0.0383, KL: 0.0291, Current Beta: 0.0010) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0333\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0851, recon=0.0851, kl=0.0332, beta=0.0010\n",
      "Batch 40, loss=0.0340, recon=0.0339, kl=0.0207, beta=0.0010\n",
      "Batch 60, loss=0.0224, recon=0.0223, kl=0.0299, beta=0.0010\n",
      "Batch 80, loss=0.0309, recon=0.0309, kl=0.0264, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0380 (Recon: 0.0380, KL: 0.0279, Current Beta: 0.0010) | Avg Valid Loss: 0.0331 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0340, recon=0.0339, kl=0.0162, beta=0.0010\n",
      "Batch 40, loss=0.0407, recon=0.0406, kl=0.0247, beta=0.0010\n",
      "Batch 60, loss=0.0283, recon=0.0283, kl=0.0108, beta=0.0010\n",
      "Batch 80, loss=0.0467, recon=0.0466, kl=0.0136, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0365 (Recon: 0.0365, KL: 0.0170, Current Beta: 0.0010) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0333\n",
      "\n",
      "[VRAE Run 155/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4993, recon=0.4993, kl=0.6795, beta=0.0000\n",
      "Batch 40, loss=0.4198, recon=0.4198, kl=11.6429, beta=0.0000\n",
      "Batch 60, loss=0.3416, recon=0.3416, kl=58.5415, beta=0.0000\n",
      "Batch 80, loss=0.2626, recon=0.2626, kl=85.9469, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4144 (Recon: 0.4144, KL: 35.9396, Current Beta: 0.0000) | Avg Valid Loss: 0.2122 | Avg Valid recon Loss: 0.2122\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2128, recon=0.2128, kl=104.4129, beta=0.0000\n",
      "Batch 40, loss=0.1677, recon=0.1677, kl=112.4825, beta=0.0000\n",
      "Batch 60, loss=0.2291, recon=0.2291, kl=119.3172, beta=0.0000\n",
      "Batch 80, loss=0.1509, recon=0.1509, kl=126.8927, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1973 (Recon: 0.1973, KL: 113.6401, Current Beta: 0.0000) | Avg Valid Loss: 0.1359 | Avg Valid recon Loss: 0.1359\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1625, recon=0.1625, kl=136.0841, beta=0.0000\n",
      "Batch 40, loss=0.1055, recon=0.1055, kl=139.1574, beta=0.0000\n",
      "Batch 60, loss=0.1052, recon=0.1052, kl=140.8804, beta=0.0000\n",
      "Batch 80, loss=0.1045, recon=0.1045, kl=144.0743, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1515 (Recon: 0.1515, KL: 139.0325, Current Beta: 0.0000) | Avg Valid Loss: 0.1091 | Avg Valid recon Loss: 0.1091\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1113, recon=0.1113, kl=144.5406, beta=0.0000\n",
      "Batch 40, loss=0.1413, recon=0.1413, kl=144.4799, beta=0.0000\n",
      "Batch 60, loss=0.0860, recon=0.0860, kl=144.0730, beta=0.0000\n",
      "Batch 80, loss=0.0926, recon=0.0926, kl=145.3538, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1245 (Recon: 0.1245, KL: 144.5502, Current Beta: 0.0000) | Avg Valid Loss: 0.0918 | Avg Valid recon Loss: 0.0918\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.3600, recon=0.3600, kl=141.9226, beta=0.0000\n",
      "Batch 40, loss=0.1001, recon=0.1001, kl=140.9442, beta=0.0000\n",
      "Batch 60, loss=0.1093, recon=0.1093, kl=139.3901, beta=0.0000\n",
      "Batch 80, loss=0.0670, recon=0.0669, kl=137.4037, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1066 (Recon: 0.1066, KL: 140.4299, Current Beta: 0.0000) | Avg Valid Loss: 0.0823 | Avg Valid recon Loss: 0.0823\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0764, recon=0.0764, kl=129.1006, beta=0.0000\n",
      "Batch 40, loss=0.0548, recon=0.0548, kl=119.0141, beta=0.0000\n",
      "Batch 60, loss=0.0623, recon=0.0623, kl=109.8590, beta=0.0000\n",
      "Batch 80, loss=0.0569, recon=0.0569, kl=106.9846, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0941 (Recon: 0.0940, KL: 117.8670, Current Beta: 0.0000) | Avg Valid Loss: 0.0766 | Avg Valid recon Loss: 0.0766\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0555, recon=0.0555, kl=88.0234, beta=0.0000\n",
      "Batch 40, loss=0.0705, recon=0.0704, kl=71.4222, beta=0.0000\n",
      "Batch 60, loss=0.0674, recon=0.0674, kl=66.4083, beta=0.0000\n",
      "Batch 80, loss=0.0461, recon=0.0461, kl=64.0303, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0848 (Recon: 0.0848, KL: 75.9277, Current Beta: 0.0000) | Avg Valid Loss: 0.0704 | Avg Valid recon Loss: 0.0704\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0624, recon=0.0624, kl=39.3292, beta=0.0000\n",
      "Batch 40, loss=0.0642, recon=0.0641, kl=32.6710, beta=0.0000\n",
      "Batch 60, loss=0.0501, recon=0.0500, kl=35.6770, beta=0.0000\n",
      "Batch 80, loss=0.0458, recon=0.0457, kl=29.3765, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0784 (Recon: 0.0784, KL: 37.6615, Current Beta: 0.0000) | Avg Valid Loss: 0.0666 | Avg Valid recon Loss: 0.0666\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0725, recon=0.0724, kl=13.4772, beta=0.0000\n",
      "Batch 40, loss=0.0486, recon=0.0486, kl=11.5459, beta=0.0000\n",
      "Batch 60, loss=0.0559, recon=0.0559, kl=12.2347, beta=0.0000\n",
      "Batch 80, loss=0.0505, recon=0.0505, kl=10.9480, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0735 (Recon: 0.0735, KL: 13.5909, Current Beta: 0.0000) | Avg Valid Loss: 0.0642 | Avg Valid recon Loss: 0.0641\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0484, recon=0.0483, kl=3.7963, beta=0.0000\n",
      "Batch 40, loss=0.0875, recon=0.0875, kl=3.3484, beta=0.0000\n",
      "Batch 60, loss=0.0403, recon=0.0402, kl=3.5050, beta=0.0000\n",
      "Batch 80, loss=0.0454, recon=0.0454, kl=4.2446, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0698 (Recon: 0.0697, KL: 4.0865, Current Beta: 0.0000) | Avg Valid Loss: 0.0607 | Avg Valid recon Loss: 0.0607\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0894, recon=0.0894, kl=1.1407, beta=0.0000\n",
      "Batch 40, loss=0.0735, recon=0.0735, kl=1.0695, beta=0.0000\n",
      "Batch 60, loss=0.0460, recon=0.0460, kl=1.1633, beta=0.0000\n",
      "Batch 80, loss=0.0909, recon=0.0909, kl=0.7472, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0669 (Recon: 0.0668, KL: 1.1454, Current Beta: 0.0000) | Avg Valid Loss: 0.0590 | Avg Valid recon Loss: 0.0590\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0625, recon=0.0625, kl=0.1939, beta=0.0001\n",
      "Batch 40, loss=0.0541, recon=0.0541, kl=0.1338, beta=0.0001\n",
      "Batch 60, loss=0.0477, recon=0.0477, kl=0.1372, beta=0.0001\n",
      "Batch 80, loss=0.0541, recon=0.0541, kl=0.1295, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0639 (Recon: 0.0638, KL: 0.1932, Current Beta: 0.0001) | Avg Valid Loss: 0.0562 | Avg Valid recon Loss: 0.0562\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0498, recon=0.0498, kl=0.0239, beta=0.0002\n",
      "Batch 40, loss=0.0405, recon=0.0405, kl=0.0131, beta=0.0002\n",
      "Batch 60, loss=0.0445, recon=0.0445, kl=0.0153, beta=0.0002\n",
      "Batch 80, loss=0.0413, recon=0.0413, kl=0.0177, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0617 (Recon: 0.0617, KL: 0.0291, Current Beta: 0.0002) | Avg Valid Loss: 0.0550 | Avg Valid recon Loss: 0.0550\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0401, recon=0.0401, kl=0.0055, beta=0.0004\n",
      "Batch 40, loss=0.0448, recon=0.0448, kl=0.0033, beta=0.0004\n",
      "Batch 60, loss=0.0352, recon=0.0352, kl=0.0031, beta=0.0004\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=0.0028, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0594 (Recon: 0.0594, KL: 0.0035, Current Beta: 0.0004) | Avg Valid Loss: 0.0533 | Avg Valid recon Loss: 0.0533\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0500, recon=0.0500, kl=0.0006, beta=0.0006\n",
      "Batch 40, loss=0.0421, recon=0.0421, kl=0.0008, beta=0.0006\n",
      "Batch 60, loss=0.0842, recon=0.0842, kl=0.0035, beta=0.0006\n",
      "Batch 80, loss=0.1662, recon=0.1662, kl=0.0020, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 0.0009, Current Beta: 0.0006) | Avg Valid Loss: 0.0520 | Avg Valid recon Loss: 0.0519\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0379, recon=0.0379, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0457, recon=0.0457, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0454, recon=0.0454, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.0380, recon=0.0380, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0563 (Recon: 0.0563, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0502 | Avg Valid recon Loss: 0.0502\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0371, recon=0.0371, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0567, recon=0.0567, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0495, recon=0.0495, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0380, recon=0.0380, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0548 (Recon: 0.0548, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0490 | Avg Valid recon Loss: 0.0490\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0690, recon=0.0690, kl=0.0012, beta=0.0010\n",
      "Batch 40, loss=0.0348, recon=0.0348, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0423, recon=0.0423, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0411, recon=0.0411, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0531 (Recon: 0.0531, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0301, recon=0.0301, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.1411, recon=0.1411, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0349, recon=0.0349, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0437, recon=0.0437, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0521 (Recon: 0.0521, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0466\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0487, recon=0.0487, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0657, recon=0.0657, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0376, recon=0.0376, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0508, recon=0.0508, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0511 (Recon: 0.0511, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0457\n",
      "\n",
      "[VRAE Run 156/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1758, recon=0.1758, kl=79.8697, beta=0.0000\n",
      "Batch 40, loss=0.1213, recon=0.1213, kl=107.5891, beta=0.0000\n",
      "Batch 60, loss=0.0807, recon=0.0807, kl=97.2952, beta=0.0000\n",
      "Batch 80, loss=0.0538, recon=0.0538, kl=106.0768, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1740 (Recon: 0.1740, KL: 90.1986, Current Beta: 0.0000) | Avg Valid Loss: 0.0767 | Avg Valid recon Loss: 0.0767\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0580, recon=0.0580, kl=114.2733, beta=0.0000\n",
      "Batch 40, loss=0.0672, recon=0.0672, kl=119.7155, beta=0.0000\n",
      "Batch 60, loss=0.0732, recon=0.0732, kl=111.5898, beta=0.0000\n",
      "Batch 80, loss=0.0606, recon=0.0606, kl=119.3041, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0758 (Recon: 0.0758, KL: 114.7244, Current Beta: 0.0000) | Avg Valid Loss: 0.0588 | Avg Valid recon Loss: 0.0588\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0475, recon=0.0475, kl=129.5474, beta=0.0000\n",
      "Batch 40, loss=0.0634, recon=0.0634, kl=243.1507, beta=0.0000\n",
      "Batch 60, loss=0.0486, recon=0.0486, kl=269.5642, beta=0.0000\n",
      "Batch 80, loss=0.0395, recon=0.0395, kl=263.2017, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0660 (Recon: 0.0660, KL: 213.7472, Current Beta: 0.0000) | Avg Valid Loss: 0.0549 | Avg Valid recon Loss: 0.0549\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0538, recon=0.0538, kl=256.7222, beta=0.0000\n",
      "Batch 40, loss=0.5784, recon=0.5784, kl=253.7489, beta=0.0000\n",
      "Batch 60, loss=0.0418, recon=0.0418, kl=242.9074, beta=0.0000\n",
      "Batch 80, loss=0.0324, recon=0.0324, kl=243.4464, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0563 (Recon: 0.0563, KL: 250.4779, Current Beta: 0.0000) | Avg Valid Loss: 0.0492 | Avg Valid recon Loss: 0.0492\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0778, recon=0.0778, kl=238.7621, beta=0.0000\n",
      "Batch 40, loss=0.0777, recon=0.0777, kl=242.8542, beta=0.0000\n",
      "Batch 60, loss=0.0406, recon=0.0406, kl=245.9326, beta=0.0000\n",
      "Batch 80, loss=0.0429, recon=0.0429, kl=232.7632, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0526 (Recon: 0.0526, KL: 239.9482, Current Beta: 0.0000) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0477\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0424, recon=0.0423, kl=226.1017, beta=0.0000\n",
      "Batch 40, loss=0.0457, recon=0.0457, kl=221.9389, beta=0.0000\n",
      "Batch 60, loss=0.0626, recon=0.0626, kl=217.2359, beta=0.0000\n",
      "Batch 80, loss=0.0444, recon=0.0444, kl=211.5649, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0506 (Recon: 0.0505, KL: 220.3323, Current Beta: 0.0000) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0449, recon=0.0448, kl=199.4147, beta=0.0000\n",
      "Batch 40, loss=0.0405, recon=0.0404, kl=188.7419, beta=0.0000\n",
      "Batch 60, loss=0.0391, recon=0.0390, kl=178.3480, beta=0.0000\n",
      "Batch 80, loss=0.0553, recon=0.0552, kl=170.0344, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0484, KL: 186.4717, Current Beta: 0.0000) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0555, recon=0.0553, kl=147.9995, beta=0.0000\n",
      "Batch 40, loss=0.0392, recon=0.0390, kl=132.8359, beta=0.0000\n",
      "Batch 60, loss=0.0342, recon=0.0340, kl=120.8027, beta=0.0000\n",
      "Batch 80, loss=0.0536, recon=0.0535, kl=113.3149, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0475 (Recon: 0.0473, KL: 132.4057, Current Beta: 0.0000) | Avg Valid Loss: 0.0406 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0862, recon=0.0858, kl=93.7959, beta=0.0000\n",
      "Batch 40, loss=0.0408, recon=0.0405, kl=79.1638, beta=0.0000\n",
      "Batch 60, loss=0.0443, recon=0.0440, kl=72.5423, beta=0.0000\n",
      "Batch 80, loss=0.0291, recon=0.0289, kl=65.6064, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0455, KL: 80.3177, Current Beta: 0.0000) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0328, recon=0.0322, kl=47.2264, beta=0.0000\n",
      "Batch 40, loss=0.0401, recon=0.0396, kl=41.1237, beta=0.0000\n",
      "Batch 60, loss=0.0495, recon=0.0491, kl=34.7231, beta=0.0000\n",
      "Batch 80, loss=0.0254, recon=0.0250, kl=32.4105, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0447 (Recon: 0.0443, KL: 41.2599, Current Beta: 0.0000) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0358, recon=0.0352, kl=19.6326, beta=0.0000\n",
      "Batch 40, loss=0.0329, recon=0.0325, kl=14.0216, beta=0.0000\n",
      "Batch 60, loss=0.0384, recon=0.0380, kl=12.4063, beta=0.0000\n",
      "Batch 80, loss=0.0429, recon=0.0427, kl=8.7764, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0427 (Recon: 0.0422, KL: 15.3684, Current Beta: 0.0000) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0356, recon=0.0348, kl=10.6828, beta=0.0001\n",
      "Batch 40, loss=0.0329, recon=0.0325, kl=6.0052, beta=0.0001\n",
      "Batch 60, loss=0.0829, recon=0.0826, kl=4.1489, beta=0.0001\n",
      "Batch 80, loss=0.0452, recon=0.0449, kl=4.1905, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0425, KL: 5.7469, Current Beta: 0.0001) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0464, recon=0.0344, kl=65.2980, beta=0.0002\n",
      "Batch 40, loss=0.0469, recon=0.0432, kl=20.1101, beta=0.0002\n",
      "Batch 60, loss=0.0695, recon=0.0670, kl=13.2314, beta=0.0002\n",
      "Batch 80, loss=0.0365, recon=0.0316, kl=27.2185, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0439, KL: 31.7388, Current Beta: 0.0002) | Avg Valid Loss: 0.0786 | Avg Valid recon Loss: 0.0747\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0404, recon=0.0372, kl=8.5715, beta=0.0004\n",
      "Batch 40, loss=0.0312, recon=0.0281, kl=8.2915, beta=0.0004\n",
      "Batch 60, loss=0.0429, recon=0.0415, kl=3.6060, beta=0.0004\n",
      "Batch 80, loss=0.0395, recon=0.0381, kl=3.8341, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0468 (Recon: 0.0437, KL: 8.2368, Current Beta: 0.0004) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0359\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0448, recon=0.0431, kl=2.7772, beta=0.0006\n",
      "Batch 40, loss=0.0394, recon=0.0275, kl=19.0595, beta=0.0006\n",
      "Batch 60, loss=0.0293, recon=0.0230, kl=10.0523, beta=0.0006\n",
      "Batch 80, loss=0.0296, recon=0.0269, kl=4.2246, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0408, KL: 7.8811, Current Beta: 0.0006) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0334\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0397, recon=0.0377, kl=2.0641, beta=0.0010\n",
      "Batch 40, loss=0.1441, recon=0.0917, kl=52.3828, beta=0.0010\n",
      "Batch 60, loss=0.1373, recon=0.0973, kl=39.9950, beta=0.0010\n",
      "Batch 80, loss=0.0821, recon=0.0556, kl=26.4699, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1747 (Recon: 0.1472, KL: 27.4944, Current Beta: 0.0010) | Avg Valid Loss: 0.0774 | Avg Valid recon Loss: 0.0584\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0514, recon=0.0430, kl=8.4377, beta=0.0010\n",
      "Batch 40, loss=0.0667, recon=0.0601, kl=6.5903, beta=0.0010\n",
      "Batch 60, loss=0.0420, recon=0.0364, kl=5.6113, beta=0.0010\n",
      "Batch 80, loss=0.0385, recon=0.0346, kl=3.8998, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0630 (Recon: 0.0555, KL: 7.4725, Current Beta: 0.0010) | Avg Valid Loss: 0.0515 | Avg Valid recon Loss: 0.0477\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0482, recon=0.0438, kl=4.4000, beta=0.0010\n",
      "Batch 40, loss=0.0512, recon=0.0476, kl=3.5748, beta=0.0010\n",
      "Batch 60, loss=0.0462, recon=0.0429, kl=3.3216, beta=0.0010\n",
      "Batch 80, loss=0.0809, recon=0.0543, kl=26.5676, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0785 (Recon: 0.0703, KL: 8.1914, Current Beta: 0.0010) | Avg Valid Loss: 0.1088 | Avg Valid recon Loss: 0.0811\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.2413, recon=0.2092, kl=32.1469, beta=0.0010\n",
      "Batch 40, loss=0.1514, recon=0.1055, kl=45.8179, beta=0.0010\n",
      "Batch 60, loss=0.1098, recon=0.0691, kl=40.6712, beta=0.0010\n",
      "Batch 80, loss=0.0942, recon=0.0616, kl=32.6800, beta=0.0010\n",
      "  â†’ Avg Train Loss: 2.6050 (Recon: 2.5656, KL: 39.3884, Current Beta: 0.0010) | Avg Valid Loss: 0.1019 | Avg Valid recon Loss: 0.0721\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0761, recon=0.0513, kl=24.8461, beta=0.0010\n",
      "Batch 40, loss=0.0660, recon=0.0424, kl=23.6603, beta=0.0010\n",
      "Batch 60, loss=0.0705, recon=0.0503, kl=20.2747, beta=0.0010\n",
      "Batch 80, loss=0.0783, recon=0.0596, kl=18.7030, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0908 (Recon: 0.0676, KL: 23.2014, Current Beta: 0.0010) | Avg Valid Loss: 0.0759 | Avg Valid recon Loss: 0.0579\n",
      "\n",
      "[VRAE Run 157/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4245, recon=0.4245, kl=0.2931, beta=0.0000\n",
      "Batch 40, loss=0.1913, recon=0.1913, kl=8.9440, beta=0.0000\n",
      "Batch 60, loss=0.1646, recon=0.1646, kl=23.7871, beta=0.0000\n",
      "Batch 80, loss=0.1366, recon=0.1366, kl=27.8495, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3067 (Recon: 0.3067, KL: 13.4790, Current Beta: 0.0000) | Avg Valid Loss: 0.1297 | Avg Valid recon Loss: 0.1297\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1467, recon=0.1467, kl=31.4422, beta=0.0000\n",
      "Batch 40, loss=0.1203, recon=0.1203, kl=36.4988, beta=0.0000\n",
      "Batch 60, loss=0.2062, recon=0.2062, kl=35.1593, beta=0.0000\n",
      "Batch 80, loss=0.1319, recon=0.1319, kl=37.6945, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1438 (Recon: 0.1438, KL: 34.6026, Current Beta: 0.0000) | Avg Valid Loss: 0.0937 | Avg Valid recon Loss: 0.0937\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1098, recon=0.1098, kl=42.6440, beta=0.0000\n",
      "Batch 40, loss=0.0872, recon=0.0872, kl=40.8901, beta=0.0000\n",
      "Batch 60, loss=0.0918, recon=0.0918, kl=43.9861, beta=0.0000\n",
      "Batch 80, loss=0.0952, recon=0.0952, kl=47.7439, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1128 (Recon: 0.1128, KL: 43.5078, Current Beta: 0.0000) | Avg Valid Loss: 0.0775 | Avg Valid recon Loss: 0.0775\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1923, recon=0.1923, kl=54.2625, beta=0.0000\n",
      "Batch 40, loss=0.0689, recon=0.0689, kl=60.0803, beta=0.0000\n",
      "Batch 60, loss=0.0713, recon=0.0713, kl=56.6084, beta=0.0000\n",
      "Batch 80, loss=0.1005, recon=0.1005, kl=50.0766, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0932 (Recon: 0.0932, KL: 54.5093, Current Beta: 0.0000) | Avg Valid Loss: 0.0683 | Avg Valid recon Loss: 0.0682\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0577, recon=0.0577, kl=48.1216, beta=0.0000\n",
      "Batch 40, loss=0.0514, recon=0.0514, kl=45.8552, beta=0.0000\n",
      "Batch 60, loss=0.0518, recon=0.0518, kl=40.6809, beta=0.0000\n",
      "Batch 80, loss=0.0899, recon=0.0899, kl=41.4153, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0804 (Recon: 0.0804, KL: 44.9768, Current Beta: 0.0000) | Avg Valid Loss: 0.0622 | Avg Valid recon Loss: 0.0622\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0513, recon=0.0513, kl=39.1060, beta=0.0000\n",
      "Batch 40, loss=0.0389, recon=0.0389, kl=31.2638, beta=0.0000\n",
      "Batch 60, loss=0.0517, recon=0.0517, kl=36.1683, beta=0.0000\n",
      "Batch 80, loss=0.0543, recon=0.0543, kl=32.8783, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0720 (Recon: 0.0720, KL: 36.1720, Current Beta: 0.0000) | Avg Valid Loss: 0.0573 | Avg Valid recon Loss: 0.0573\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0569, recon=0.0569, kl=25.2639, beta=0.0000\n",
      "Batch 40, loss=0.1343, recon=0.1343, kl=22.0810, beta=0.0000\n",
      "Batch 60, loss=0.0407, recon=0.0407, kl=18.9717, beta=0.0000\n",
      "Batch 80, loss=0.0453, recon=0.0453, kl=18.3037, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0661 (Recon: 0.0661, KL: 22.7021, Current Beta: 0.0000) | Avg Valid Loss: 0.0540 | Avg Valid recon Loss: 0.0540\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0539, recon=0.0539, kl=12.9248, beta=0.0000\n",
      "Batch 40, loss=0.0538, recon=0.0538, kl=9.7050, beta=0.0000\n",
      "Batch 60, loss=0.0561, recon=0.0560, kl=11.3488, beta=0.0000\n",
      "Batch 80, loss=0.0515, recon=0.0514, kl=11.8116, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0619 (Recon: 0.0618, KL: 12.3895, Current Beta: 0.0000) | Avg Valid Loss: 0.0521 | Avg Valid recon Loss: 0.0521\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0417, recon=0.0417, kl=4.5825, beta=0.0000\n",
      "Batch 40, loss=0.0436, recon=0.0435, kl=5.2389, beta=0.0000\n",
      "Batch 60, loss=0.0416, recon=0.0416, kl=4.7678, beta=0.0000\n",
      "Batch 80, loss=0.0509, recon=0.0509, kl=3.5516, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0583 (Recon: 0.0583, KL: 5.3062, Current Beta: 0.0000) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0478, recon=0.0478, kl=1.7823, beta=0.0000\n",
      "Batch 40, loss=0.0397, recon=0.0397, kl=2.0275, beta=0.0000\n",
      "Batch 60, loss=0.0514, recon=0.0514, kl=2.2851, beta=0.0000\n",
      "Batch 80, loss=0.0361, recon=0.0361, kl=1.5870, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0555, KL: 2.4038, Current Beta: 0.0000) | Avg Valid Loss: 0.0475 | Avg Valid recon Loss: 0.0475\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0473, recon=0.0472, kl=0.5391, beta=0.0000\n",
      "Batch 40, loss=0.4582, recon=0.4582, kl=0.9272, beta=0.0000\n",
      "Batch 60, loss=0.0383, recon=0.0383, kl=0.7598, beta=0.0000\n",
      "Batch 80, loss=0.0459, recon=0.0459, kl=0.6732, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0522 (Recon: 0.0522, KL: 0.7946, Current Beta: 0.0000) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0360, recon=0.0359, kl=0.1078, beta=0.0001\n",
      "Batch 40, loss=0.0364, recon=0.0364, kl=0.1503, beta=0.0001\n",
      "Batch 60, loss=0.0491, recon=0.0491, kl=0.1351, beta=0.0001\n",
      "Batch 80, loss=0.0354, recon=0.0354, kl=0.0695, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0510 (Recon: 0.0510, KL: 0.1629, Current Beta: 0.0001) | Avg Valid Loss: 0.0443 | Avg Valid recon Loss: 0.0443\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0290, recon=0.0290, kl=0.0122, beta=0.0002\n",
      "Batch 40, loss=0.0289, recon=0.0289, kl=0.0113, beta=0.0002\n",
      "Batch 60, loss=0.0418, recon=0.0418, kl=0.0094, beta=0.0002\n",
      "Batch 80, loss=0.0300, recon=0.0300, kl=0.0409, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0492 (Recon: 0.0492, KL: 0.0197, Current Beta: 0.0002) | Avg Valid Loss: 0.0424 | Avg Valid recon Loss: 0.0424\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0472, recon=0.0472, kl=0.0024, beta=0.0004\n",
      "Batch 40, loss=0.0459, recon=0.0459, kl=0.0024, beta=0.0004\n",
      "Batch 60, loss=0.0329, recon=0.0329, kl=0.0010, beta=0.0004\n",
      "Batch 80, loss=0.0404, recon=0.0404, kl=0.0010, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0478 (Recon: 0.0478, KL: 0.0028, Current Beta: 0.0004) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0339, recon=0.0339, kl=0.0006, beta=0.0006\n",
      "Batch 40, loss=0.0447, recon=0.0447, kl=0.0011, beta=0.0006\n",
      "Batch 60, loss=0.0395, recon=0.0395, kl=0.0009, beta=0.0006\n",
      "Batch 80, loss=0.0387, recon=0.0387, kl=0.0010, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0461, KL: 0.0011, Current Beta: 0.0006) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0534, recon=0.0534, kl=0.0015, beta=0.0010\n",
      "Batch 40, loss=0.0390, recon=0.0390, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.1352, recon=0.1352, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0337, recon=0.0337, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0453 (Recon: 0.0453, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0372, recon=0.0372, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0715, recon=0.0715, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0241, recon=0.0241, kl=0.0025, beta=0.0010\n",
      "Batch 80, loss=0.0266, recon=0.0266, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0441 (Recon: 0.0441, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.4092, recon=0.4092, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0371, recon=0.0371, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0429, recon=0.0429, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0306, recon=0.0306, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0431, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0378 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0300, recon=0.0300, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0331, recon=0.0331, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0280, recon=0.0280, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0297, recon=0.0297, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0324, recon=0.0324, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0258, recon=0.0258, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0428, recon=0.0428, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0265, recon=0.0265, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0417, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0361\n",
      "\n",
      "[VRAE Run 158/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1268, recon=0.1268, kl=21.7006, beta=0.0000\n",
      "Batch 40, loss=0.0802, recon=0.0802, kl=20.6920, beta=0.0000\n",
      "Batch 60, loss=0.0612, recon=0.0612, kl=28.8006, beta=0.0000\n",
      "Batch 80, loss=0.0554, recon=0.0554, kl=26.6458, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1496 (Recon: 0.1496, KL: 21.7972, Current Beta: 0.0000) | Avg Valid Loss: 0.0622 | Avg Valid recon Loss: 0.0622\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0525, recon=0.0525, kl=28.8071, beta=0.0000\n",
      "Batch 40, loss=0.1209, recon=0.1209, kl=27.1174, beta=0.0000\n",
      "Batch 60, loss=0.0521, recon=0.0521, kl=30.5257, beta=0.0000\n",
      "Batch 80, loss=0.0387, recon=0.0387, kl=33.3932, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0695 (Recon: 0.0695, KL: 28.8061, Current Beta: 0.0000) | Avg Valid Loss: 0.0516 | Avg Valid recon Loss: 0.0516\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1447, recon=0.1447, kl=34.1677, beta=0.0000\n",
      "Batch 40, loss=0.0484, recon=0.0484, kl=34.5847, beta=0.0000\n",
      "Batch 60, loss=0.0419, recon=0.0419, kl=34.4594, beta=0.0000\n",
      "Batch 80, loss=0.0400, recon=0.0400, kl=34.9577, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0538 (Recon: 0.0538, KL: 34.7384, Current Beta: 0.0000) | Avg Valid Loss: 0.0545 | Avg Valid recon Loss: 0.0545\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0432, recon=0.0432, kl=31.2782, beta=0.0000\n",
      "Batch 40, loss=0.0321, recon=0.0321, kl=28.2746, beta=0.0000\n",
      "Batch 60, loss=0.0344, recon=0.0344, kl=33.9044, beta=0.0000\n",
      "Batch 80, loss=0.0336, recon=0.0336, kl=33.5169, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0513 (Recon: 0.0513, KL: 31.7990, Current Beta: 0.0000) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0720, recon=0.0720, kl=34.8133, beta=0.0000\n",
      "Batch 40, loss=0.0336, recon=0.0336, kl=32.5017, beta=0.0000\n",
      "Batch 60, loss=0.0463, recon=0.0463, kl=31.5277, beta=0.0000\n",
      "Batch 80, loss=0.0430, recon=0.0430, kl=34.2014, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0451 (Recon: 0.0451, KL: 33.5052, Current Beta: 0.0000) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0267, recon=0.0267, kl=31.7292, beta=0.0000\n",
      "Batch 40, loss=0.0300, recon=0.0300, kl=28.3077, beta=0.0000\n",
      "Batch 60, loss=0.0356, recon=0.0356, kl=26.7658, beta=0.0000\n",
      "Batch 80, loss=0.0502, recon=0.0502, kl=30.6265, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 29.6900, Current Beta: 0.0000) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0331, recon=0.0331, kl=25.7674, beta=0.0000\n",
      "Batch 40, loss=0.0265, recon=0.0265, kl=20.5485, beta=0.0000\n",
      "Batch 60, loss=0.0596, recon=0.0596, kl=23.4855, beta=0.0000\n",
      "Batch 80, loss=0.0359, recon=0.0359, kl=25.0068, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0424, KL: 24.6418, Current Beta: 0.0000) | Avg Valid Loss: 0.0366 | Avg Valid recon Loss: 0.0366\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0342, recon=0.0342, kl=32.2160, beta=0.0000\n",
      "Batch 40, loss=0.0378, recon=0.0377, kl=37.5406, beta=0.0000\n",
      "Batch 60, loss=0.0344, recon=0.0343, kl=43.7060, beta=0.0000\n",
      "Batch 80, loss=0.0325, recon=0.0324, kl=51.9983, beta=0.0000\n",
      "  â†’ Avg Train Loss: 63832.9057 (Recon: 63832.1357, KL: 512142.4215, Current Beta: 0.0000) | Avg Valid Loss: 0.0343 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0275, recon=0.0273, kl=49.4877, beta=0.0000\n",
      "Batch 40, loss=0.0447, recon=0.0445, kl=46.9420, beta=0.0000\n",
      "Batch 60, loss=0.0269, recon=0.0267, kl=44.2123, beta=0.0000\n",
      "Batch 80, loss=0.0359, recon=0.0357, kl=45.7153, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0380, KL: 46.7700, Current Beta: 0.0000) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0455, recon=0.0451, kl=40.8340, beta=0.0000\n",
      "Batch 40, loss=0.0490, recon=0.0485, kl=37.3163, beta=0.0000\n",
      "Batch 60, loss=0.0326, recon=0.0322, kl=34.4823, beta=0.0000\n",
      "Batch 80, loss=0.0272, recon=0.0269, kl=31.7169, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0402 (Recon: 0.0398, KL: 36.8504, Current Beta: 0.0000) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0385\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0519, recon=0.0511, kl=26.9518, beta=0.0000\n",
      "Batch 40, loss=0.0590, recon=0.0583, kl=23.8284, beta=0.0000\n",
      "Batch 60, loss=0.0358, recon=0.0351, kl=21.4548, beta=0.0000\n",
      "Batch 80, loss=0.0289, recon=0.0283, kl=20.2775, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0387 (Recon: 0.0380, KL: 24.1300, Current Beta: 0.0000) | Avg Valid Loss: 0.0328 | Avg Valid recon Loss: 0.0322\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0457, recon=0.0446, kl=14.6440, beta=0.0001\n",
      "Batch 40, loss=0.0271, recon=0.0262, kl=11.7910, beta=0.0001\n",
      "Batch 60, loss=0.0221, recon=0.0213, kl=11.0506, beta=0.0001\n",
      "Batch 80, loss=0.0254, recon=0.0248, kl=8.1032, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0366 (Recon: 0.0356, KL: 12.2471, Current Beta: 0.0001) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0298\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0296, recon=0.0289, kl=4.1393, beta=0.0002\n",
      "Batch 40, loss=0.0314, recon=0.0307, kl=3.9496, beta=0.0002\n",
      "Batch 60, loss=0.0235, recon=0.0230, kl=2.6662, beta=0.0002\n",
      "Batch 80, loss=0.0261, recon=0.0258, kl=1.6773, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0345 (Recon: 0.0338, KL: 3.6271, Current Beta: 0.0002) | Avg Valid Loss: 0.0298 | Avg Valid recon Loss: 0.0294\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0381, recon=0.0378, kl=0.7504, beta=0.0004\n",
      "Batch 40, loss=0.0318, recon=0.0316, kl=0.5505, beta=0.0004\n",
      "Batch 60, loss=0.0189, recon=0.0187, kl=0.5490, beta=0.0004\n",
      "Batch 80, loss=0.0284, recon=0.0282, kl=0.4647, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0351 (Recon: 0.0348, KL: 0.7957, Current Beta: 0.0004) | Avg Valid Loss: 0.0297 | Avg Valid recon Loss: 0.0296\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0211, recon=0.0210, kl=0.1158, beta=0.0006\n",
      "Batch 40, loss=0.0762, recon=0.0759, kl=0.3730, beta=0.0006\n",
      "Batch 60, loss=0.0398, recon=0.0397, kl=0.3022, beta=0.0006\n",
      "Batch 80, loss=0.0233, recon=0.0232, kl=0.1343, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0328 (Recon: 0.0326, KL: 0.2422, Current Beta: 0.0006) | Avg Valid Loss: 0.0322 | Avg Valid recon Loss: 0.0320\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0280, recon=0.0279, kl=0.0725, beta=0.0010\n",
      "Batch 40, loss=0.0254, recon=0.0253, kl=0.0823, beta=0.0010\n",
      "Batch 60, loss=0.0287, recon=0.0286, kl=0.0914, beta=0.0010\n",
      "Batch 80, loss=0.0241, recon=0.0241, kl=0.0403, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0348 (Recon: 0.0347, KL: 0.1172, Current Beta: 0.0010) | Avg Valid Loss: 0.0295 | Avg Valid recon Loss: 0.0295\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0477, recon=0.0476, kl=0.0308, beta=0.0010\n",
      "Batch 40, loss=0.0265, recon=0.0264, kl=0.0607, beta=0.0010\n",
      "Batch 60, loss=0.0230, recon=0.0228, kl=0.1586, beta=0.0010\n",
      "Batch 80, loss=0.0214, recon=0.0214, kl=0.0336, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0313 (Recon: 0.0313, KL: 0.0694, Current Beta: 0.0010) | Avg Valid Loss: 0.0293 | Avg Valid recon Loss: 0.0293\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0151, recon=0.0151, kl=0.0562, beta=0.0010\n",
      "Batch 40, loss=0.0191, recon=0.0190, kl=0.0270, beta=0.0010\n",
      "Batch 60, loss=0.0346, recon=0.0346, kl=0.0470, beta=0.0010\n",
      "Batch 80, loss=0.0315, recon=0.0315, kl=0.0389, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0308 (Recon: 0.0308, KL: 0.0516, Current Beta: 0.0010) | Avg Valid Loss: 0.0277 | Avg Valid recon Loss: 0.0277\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0270, recon=0.0270, kl=0.0227, beta=0.0010\n",
      "Batch 40, loss=0.0386, recon=0.0385, kl=0.0262, beta=0.0010\n",
      "Batch 60, loss=0.0228, recon=0.0228, kl=0.0220, beta=0.0010\n",
      "Batch 80, loss=0.0221, recon=0.0220, kl=0.0655, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0291 (Recon: 0.0290, KL: 0.0392, Current Beta: 0.0010) | Avg Valid Loss: 0.0272 | Avg Valid recon Loss: 0.0272\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0237, recon=0.0237, kl=0.0233, beta=0.0010\n",
      "Batch 40, loss=0.0255, recon=0.0255, kl=0.0199, beta=0.0010\n",
      "Batch 60, loss=0.0202, recon=0.0201, kl=0.0263, beta=0.0010\n",
      "Batch 80, loss=0.0224, recon=0.0224, kl=0.0253, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0289 (Recon: 0.0289, KL: 0.0319, Current Beta: 0.0010) | Avg Valid Loss: 0.0271 | Avg Valid recon Loss: 0.0270\n",
      "\n",
      "[VRAE Run 159/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3859, recon=0.3859, kl=1.2909, beta=0.0000\n",
      "Batch 40, loss=1.2071, recon=1.2071, kl=31.6830, beta=0.0000\n",
      "Batch 60, loss=0.2197, recon=0.2197, kl=53.1502, beta=0.0000\n",
      "Batch 80, loss=0.1798, recon=0.1798, kl=60.0538, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3142 (Recon: 0.3142, KL: 33.2790, Current Beta: 0.0000) | Avg Valid Loss: 0.1348 | Avg Valid recon Loss: 0.1348\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1441, recon=0.1441, kl=65.3391, beta=0.0000\n",
      "Batch 40, loss=0.1495, recon=0.1495, kl=72.1119, beta=0.0000\n",
      "Batch 60, loss=0.1316, recon=0.1316, kl=75.9729, beta=0.0000\n",
      "Batch 80, loss=0.0970, recon=0.0970, kl=80.8233, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1436 (Recon: 0.1436, KL: 72.3660, Current Beta: 0.0000) | Avg Valid Loss: 0.0967 | Avg Valid recon Loss: 0.0967\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0858, recon=0.0858, kl=87.5351, beta=0.0000\n",
      "Batch 40, loss=0.0974, recon=0.0974, kl=89.6466, beta=0.0000\n",
      "Batch 60, loss=0.0935, recon=0.0935, kl=92.6711, beta=0.0000\n",
      "Batch 80, loss=0.1057, recon=0.1057, kl=89.7119, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1171 (Recon: 0.1171, KL: 89.8989, Current Beta: 0.0000) | Avg Valid Loss: 0.0815 | Avg Valid recon Loss: 0.0815\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0671, recon=0.0671, kl=83.7096, beta=0.0000\n",
      "Batch 40, loss=0.0862, recon=0.0862, kl=85.0365, beta=0.0000\n",
      "Batch 60, loss=0.0732, recon=0.0732, kl=83.0573, beta=0.0000\n",
      "Batch 80, loss=0.0628, recon=0.0628, kl=85.6183, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0967 (Recon: 0.0967, KL: 84.8335, Current Beta: 0.0000) | Avg Valid Loss: 0.0703 | Avg Valid recon Loss: 0.0703\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0692, recon=0.0692, kl=77.0691, beta=0.0000\n",
      "Batch 40, loss=0.0680, recon=0.0680, kl=77.3543, beta=0.0000\n",
      "Batch 60, loss=0.0528, recon=0.0528, kl=70.0486, beta=0.0000\n",
      "Batch 80, loss=0.0885, recon=0.0885, kl=66.4271, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0827 (Recon: 0.0826, KL: 73.9691, Current Beta: 0.0000) | Avg Valid Loss: 0.0629 | Avg Valid recon Loss: 0.0629\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0792, recon=0.0792, kl=58.1493, beta=0.0000\n",
      "Batch 40, loss=0.0461, recon=0.0461, kl=54.5187, beta=0.0000\n",
      "Batch 60, loss=0.0678, recon=0.0678, kl=48.1882, beta=0.0000\n",
      "Batch 80, loss=0.0507, recon=0.0507, kl=49.8839, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0736 (Recon: 0.0736, KL: 53.7179, Current Beta: 0.0000) | Avg Valid Loss: 0.0590 | Avg Valid recon Loss: 0.0590\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0529, recon=0.0528, kl=37.1974, beta=0.0000\n",
      "Batch 40, loss=0.0634, recon=0.0633, kl=34.1766, beta=0.0000\n",
      "Batch 60, loss=0.0491, recon=0.0491, kl=32.6357, beta=0.0000\n",
      "Batch 80, loss=0.0368, recon=0.0368, kl=34.1562, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0672 (Recon: 0.0672, KL: 36.9977, Current Beta: 0.0000) | Avg Valid Loss: 0.0552 | Avg Valid recon Loss: 0.0552\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0492, recon=0.0492, kl=19.3676, beta=0.0000\n",
      "Batch 40, loss=0.0410, recon=0.0409, kl=14.7983, beta=0.0000\n",
      "Batch 60, loss=0.1178, recon=0.1178, kl=17.0757, beta=0.0000\n",
      "Batch 80, loss=0.0652, recon=0.0651, kl=16.2807, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0622 (Recon: 0.0622, KL: 19.0055, Current Beta: 0.0000) | Avg Valid Loss: 0.0528 | Avg Valid recon Loss: 0.0528\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0508, recon=0.0507, kl=6.7843, beta=0.0000\n",
      "Batch 40, loss=0.0395, recon=0.0395, kl=7.4743, beta=0.0000\n",
      "Batch 60, loss=0.0476, recon=0.0476, kl=6.6636, beta=0.0000\n",
      "Batch 80, loss=0.1427, recon=0.1426, kl=6.0422, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0582 (Recon: 0.0582, KL: 7.3922, Current Beta: 0.0000) | Avg Valid Loss: 0.0501 | Avg Valid recon Loss: 0.0501\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0505, recon=0.0505, kl=2.0224, beta=0.0000\n",
      "Batch 40, loss=0.0406, recon=0.0406, kl=2.5792, beta=0.0000\n",
      "Batch 60, loss=0.0373, recon=0.0373, kl=2.7064, beta=0.0000\n",
      "Batch 80, loss=0.0422, recon=0.0422, kl=2.1236, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0555, KL: 2.7323, Current Beta: 0.0000) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0568, recon=0.0568, kl=0.7501, beta=0.0000\n",
      "Batch 40, loss=0.0439, recon=0.0438, kl=0.8607, beta=0.0000\n",
      "Batch 60, loss=0.0451, recon=0.0450, kl=0.7652, beta=0.0000\n",
      "Batch 80, loss=0.0629, recon=0.0629, kl=0.5696, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0531 (Recon: 0.0530, KL: 0.8495, Current Beta: 0.0000) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0432, recon=0.0432, kl=0.1531, beta=0.0001\n",
      "Batch 40, loss=0.0496, recon=0.0496, kl=0.1547, beta=0.0001\n",
      "Batch 60, loss=0.0383, recon=0.0383, kl=0.1526, beta=0.0001\n",
      "Batch 80, loss=0.0351, recon=0.0351, kl=0.1267, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0506 (Recon: 0.0506, KL: 0.1837, Current Beta: 0.0001) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0528, recon=0.0528, kl=0.0175, beta=0.0002\n",
      "Batch 40, loss=0.0288, recon=0.0288, kl=0.0124, beta=0.0002\n",
      "Batch 60, loss=0.0550, recon=0.0550, kl=0.0258, beta=0.0002\n",
      "Batch 80, loss=0.0575, recon=0.0575, kl=0.0082, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0490 (Recon: 0.0490, KL: 0.0176, Current Beta: 0.0002) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0321, recon=0.0321, kl=0.0042, beta=0.0004\n",
      "Batch 40, loss=0.0592, recon=0.0592, kl=0.0027, beta=0.0004\n",
      "Batch 60, loss=0.0400, recon=0.0400, kl=0.0035, beta=0.0004\n",
      "Batch 80, loss=0.0277, recon=0.0277, kl=0.0037, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0471 (Recon: 0.0471, KL: 0.0042, Current Beta: 0.0004) | Avg Valid Loss: 0.0414 | Avg Valid recon Loss: 0.0414\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0380, recon=0.0380, kl=0.0013, beta=0.0006\n",
      "Batch 40, loss=0.0433, recon=0.0433, kl=0.0011, beta=0.0006\n",
      "Batch 60, loss=0.1542, recon=0.1542, kl=0.0022, beta=0.0006\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=0.0008, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0459, KL: 0.0014, Current Beta: 0.0006) | Avg Valid Loss: 0.0406 | Avg Valid recon Loss: 0.0406\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0319, recon=0.0319, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0303, recon=0.0303, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0832, recon=0.0832, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0414, recon=0.0414, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0450, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0240, recon=0.0240, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0391, recon=0.0391, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0432, recon=0.0432, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0344, recon=0.0344, kl=0.0013, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0441 (Recon: 0.0441, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0318, recon=0.0318, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.0334, recon=0.0334, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0318, recon=0.0318, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0377, recon=0.0377, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0430, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0315, recon=0.0315, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0386, recon=0.0386, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0415, recon=0.0415, kl=0.0019, beta=0.0010\n",
      "Batch 80, loss=0.0277, recon=0.0277, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0439, recon=0.0439, kl=0.0008, beta=0.0010\n",
      "Batch 40, loss=0.0287, recon=0.0287, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0343, recon=0.0343, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0269, recon=0.0269, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0413 (Recon: 0.0413, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0368\n",
      "\n",
      "[VRAE Run 160/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1281, recon=0.1281, kl=54.0087, beta=0.0000\n",
      "Batch 40, loss=0.1140, recon=0.1140, kl=48.6343, beta=0.0000\n",
      "Batch 60, loss=0.0679, recon=0.0679, kl=50.2033, beta=0.0000\n",
      "Batch 80, loss=0.0986, recon=0.0986, kl=53.4675, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1486 (Recon: 0.1486, KL: 44.5171, Current Beta: 0.0000) | Avg Valid Loss: 0.0605 | Avg Valid recon Loss: 0.0605\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0457, recon=0.0457, kl=60.4337, beta=0.0000\n",
      "Batch 40, loss=0.0539, recon=0.0539, kl=63.4920, beta=0.0000\n",
      "Batch 60, loss=0.0569, recon=0.0569, kl=70.0019, beta=0.0000\n",
      "Batch 80, loss=0.0447, recon=0.0447, kl=62.4994, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0674 (Recon: 0.0674, KL: 64.2919, Current Beta: 0.0000) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0496\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0427, recon=0.0427, kl=53.3009, beta=0.0000\n",
      "Batch 40, loss=0.0501, recon=0.0501, kl=62.2004, beta=0.0000\n",
      "Batch 60, loss=0.0423, recon=0.0422, kl=65.7771, beta=0.0000\n",
      "Batch 80, loss=0.0295, recon=0.0295, kl=66.5471, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 62.1890, Current Beta: 0.0000) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0411, recon=0.0411, kl=59.2925, beta=0.0000\n",
      "Batch 40, loss=0.0413, recon=0.0413, kl=63.1059, beta=0.0000\n",
      "Batch 60, loss=0.0393, recon=0.0393, kl=58.7126, beta=0.0000\n",
      "Batch 80, loss=0.0337, recon=0.0337, kl=64.9755, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 61.4251, Current Beta: 0.0000) | Avg Valid Loss: 0.0400 | Avg Valid recon Loss: 0.0400\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0374, recon=0.0374, kl=67.3091, beta=0.0000\n",
      "Batch 40, loss=0.0276, recon=0.0276, kl=61.8180, beta=0.0000\n",
      "Batch 60, loss=0.0422, recon=0.0422, kl=56.2097, beta=0.0000\n",
      "Batch 80, loss=0.3183, recon=0.3183, kl=54.7985, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 60.8019, Current Beta: 0.0000) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=57.2055, beta=0.0000\n",
      "Batch 40, loss=0.0374, recon=0.0374, kl=49.4299, beta=0.0000\n",
      "Batch 60, loss=0.0397, recon=0.0397, kl=53.9330, beta=0.0000\n",
      "Batch 80, loss=0.0342, recon=0.0342, kl=55.6621, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0432, KL: 55.5697, Current Beta: 0.0000) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0354, recon=0.0353, kl=64.4820, beta=0.0000\n",
      "Batch 40, loss=0.0471, recon=0.0471, kl=94.7944, beta=0.0000\n",
      "Batch 60, loss=0.0370, recon=0.0369, kl=113.4428, beta=0.0000\n",
      "Batch 80, loss=0.0317, recon=0.0316, kl=106.0068, beta=0.0000\n",
      "  â†’ Avg Train Loss: 7359639643.0673 (Recon: 7359638914.8895, KL: 831703813.4850, Current Beta: 0.0000) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0448, recon=0.0446, kl=91.8475, beta=0.0000\n",
      "Batch 40, loss=0.0270, recon=0.0268, kl=89.5007, beta=0.0000\n",
      "Batch 60, loss=0.0241, recon=0.0240, kl=81.4298, beta=0.0000\n",
      "Batch 80, loss=0.0353, recon=0.0352, kl=77.1655, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0412 (Recon: 0.0411, KL: 86.4001, Current Beta: 0.0000) | Avg Valid Loss: 0.0400 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0365, recon=0.0362, kl=67.6785, beta=0.0000\n",
      "Batch 40, loss=0.0350, recon=0.0348, kl=57.5425, beta=0.0000\n",
      "Batch 60, loss=0.0355, recon=0.0353, kl=55.1984, beta=0.0000\n",
      "Batch 80, loss=0.1090, recon=0.1087, kl=75.0012, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3113 (Recon: 0.3111, KL: 66.5243, Current Beta: 0.0000) | Avg Valid Loss: 0.0904 | Avg Valid recon Loss: 0.0900\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0749, recon=0.0736, kl=117.9251, beta=0.0000\n",
      "Batch 40, loss=0.0673, recon=0.0662, kl=100.6525, beta=0.0000\n",
      "Batch 60, loss=0.0433, recon=0.0422, kl=98.7381, beta=0.0000\n",
      "Batch 80, loss=0.0492, recon=0.0481, kl=96.6828, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0650 (Recon: 0.0639, KL: 101.6482, Current Beta: 0.0000) | Avg Valid Loss: 0.0497 | Avg Valid recon Loss: 0.0487\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0442, recon=0.0416, kl=86.9680, beta=0.0000\n",
      "Batch 40, loss=0.0525, recon=0.0502, kl=79.3041, beta=0.0000\n",
      "Batch 60, loss=0.0462, recon=0.0441, kl=71.9346, beta=0.0000\n",
      "Batch 80, loss=0.0546, recon=0.0527, kl=64.4047, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0505 (Recon: 0.0483, KL: 78.0301, Current Beta: 0.0000) | Avg Valid Loss: 0.0424 | Avg Valid recon Loss: 0.0406\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0463, recon=0.0425, kl=49.9243, beta=0.0001\n",
      "Batch 40, loss=0.0527, recon=0.0498, kl=39.4906, beta=0.0001\n",
      "Batch 60, loss=0.0409, recon=0.0386, kl=30.9746, beta=0.0001\n",
      "Batch 80, loss=0.0435, recon=0.0416, kl=25.3204, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0433, KL: 38.6904, Current Beta: 0.0001) | Avg Valid Loss: 0.0405 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0342, recon=0.0303, kl=21.1729, beta=0.0002\n",
      "Batch 40, loss=0.0291, recon=0.0272, kl=10.4775, beta=0.0002\n",
      "Batch 60, loss=0.0784, recon=0.0765, kl=10.2627, beta=0.0002\n",
      "Batch 80, loss=0.0432, recon=0.0415, kl=9.4333, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0405, KL: 13.2009, Current Beta: 0.0002) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0430, recon=0.0410, kl=5.1056, beta=0.0004\n",
      "Batch 40, loss=0.0339, recon=0.0311, kl=7.3045, beta=0.0004\n",
      "Batch 60, loss=0.0375, recon=0.0353, kl=5.8616, beta=0.0004\n",
      "Batch 80, loss=0.0325, recon=0.0287, kl=9.8932, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0439 (Recon: 0.0414, KL: 6.7330, Current Beta: 0.0004) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0404, recon=0.0372, kl=5.0222, beta=0.0006\n",
      "Batch 40, loss=0.0484, recon=0.0463, kl=3.3372, beta=0.0006\n",
      "Batch 60, loss=0.0339, recon=0.0306, kl=5.2215, beta=0.0006\n",
      "Batch 80, loss=0.0541, recon=0.0516, kl=4.1064, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0413 (Recon: 0.0387, KL: 4.2429, Current Beta: 0.0006) | Avg Valid Loss: 0.0366 | Avg Valid recon Loss: 0.0348\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0648, recon=0.0294, kl=35.3436, beta=0.0010\n",
      "Batch 40, loss=0.0433, recon=0.0258, kl=17.4949, beta=0.0010\n",
      "Batch 60, loss=0.0412, recon=0.0345, kl=6.6420, beta=0.0010\n",
      "Batch 80, loss=0.0457, recon=0.0385, kl=7.2200, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0415, KL: 13.8054, Current Beta: 0.0010) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0681, recon=0.0646, kl=3.4879, beta=0.0010\n",
      "Batch 40, loss=0.0590, recon=0.0349, kl=24.1280, beta=0.0010\n",
      "Batch 60, loss=0.0670, recon=0.0515, kl=15.4877, beta=0.0010\n",
      "Batch 80, loss=0.0485, recon=0.0392, kl=9.2976, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0539 (Recon: 0.0406, KL: 13.3100, Current Beta: 0.0010) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0319, recon=0.0271, kl=4.8131, beta=0.0010\n",
      "Batch 40, loss=0.0344, recon=0.0294, kl=4.9744, beta=0.0010\n",
      "Batch 60, loss=0.0521, recon=0.0489, kl=3.1956, beta=0.0010\n",
      "Batch 80, loss=0.0489, recon=0.0462, kl=2.7561, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0382, KL: 4.0913, Current Beta: 0.0010) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0335\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0723, recon=0.0696, kl=2.7122, beta=0.0010\n",
      "Batch 40, loss=0.0577, recon=0.0555, kl=2.1917, beta=0.0010\n",
      "Batch 60, loss=0.0529, recon=0.0506, kl=2.3432, beta=0.0010\n",
      "Batch 80, loss=0.0496, recon=0.0471, kl=2.4565, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0402 (Recon: 0.0377, KL: 2.4502, Current Beta: 0.0010) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0326\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0340, recon=0.0322, kl=1.7920, beta=0.0010\n",
      "Batch 40, loss=0.0288, recon=0.0271, kl=1.7315, beta=0.0010\n",
      "Batch 60, loss=0.0271, recon=0.0252, kl=1.8966, beta=0.0010\n",
      "Batch 80, loss=0.0332, recon=0.0314, kl=1.7637, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0384 (Recon: 0.0365, KL: 1.9400, Current Beta: 0.0010) | Avg Valid Loss: 0.0348 | Avg Valid recon Loss: 0.0331\n",
      "\n",
      "[VRAE Run 161/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3039, recon=0.3039, kl=2.9956, beta=0.0000\n",
      "Batch 40, loss=0.1715, recon=0.1715, kl=72.7737, beta=0.0000\n",
      "Batch 60, loss=0.2033, recon=0.2033, kl=97.8038, beta=0.0000\n",
      "Batch 80, loss=0.1609, recon=0.1609, kl=114.2868, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3114 (Recon: 0.3114, KL: 65.8385, Current Beta: 0.0000) | Avg Valid Loss: 0.1310 | Avg Valid recon Loss: 0.1310\n",
      "Epoch 2/20\n",
      "Batch 20, loss=1.0420, recon=1.0420, kl=126.1899, beta=0.0000\n",
      "Batch 40, loss=0.4283, recon=0.4283, kl=137.5034, beta=0.0000\n",
      "Batch 60, loss=0.1451, recon=0.1451, kl=148.2178, beta=0.0000\n",
      "Batch 80, loss=0.1307, recon=0.1307, kl=163.9887, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1457 (Recon: 0.1457, KL: 141.9173, Current Beta: 0.0000) | Avg Valid Loss: 0.0963 | Avg Valid recon Loss: 0.0963\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1119, recon=0.1119, kl=155.4426, beta=0.0000\n",
      "Batch 40, loss=0.1217, recon=0.1217, kl=154.4726, beta=0.0000\n",
      "Batch 60, loss=0.1291, recon=0.1291, kl=155.9000, beta=0.0000\n",
      "Batch 80, loss=0.1296, recon=0.1296, kl=154.5638, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1174 (Recon: 0.1174, KL: 156.5604, Current Beta: 0.0000) | Avg Valid Loss: 0.0798 | Avg Valid recon Loss: 0.0798\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0827, recon=0.0827, kl=157.4761, beta=0.0000\n",
      "Batch 40, loss=0.0833, recon=0.0833, kl=159.5060, beta=0.0000\n",
      "Batch 60, loss=0.0709, recon=0.0709, kl=160.0539, beta=0.0000\n",
      "Batch 80, loss=0.0587, recon=0.0587, kl=151.9289, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0974 (Recon: 0.0974, KL: 157.5087, Current Beta: 0.0000) | Avg Valid Loss: 0.0706 | Avg Valid recon Loss: 0.0706\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0696, recon=0.0696, kl=152.4065, beta=0.0000\n",
      "Batch 40, loss=0.0792, recon=0.0791, kl=133.2074, beta=0.0000\n",
      "Batch 60, loss=0.0667, recon=0.0667, kl=128.1159, beta=0.0000\n",
      "Batch 80, loss=0.0571, recon=0.0571, kl=121.6159, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0834 (Recon: 0.0834, KL: 136.4302, Current Beta: 0.0000) | Avg Valid Loss: 0.0640 | Avg Valid recon Loss: 0.0640\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0689, recon=0.0689, kl=105.6382, beta=0.0000\n",
      "Batch 40, loss=0.0579, recon=0.0579, kl=89.7824, beta=0.0000\n",
      "Batch 60, loss=0.0687, recon=0.0687, kl=84.8261, beta=0.0000\n",
      "Batch 80, loss=0.0637, recon=0.0637, kl=87.5449, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0739 (Recon: 0.0739, KL: 94.2869, Current Beta: 0.0000) | Avg Valid Loss: 0.0594 | Avg Valid recon Loss: 0.0594\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0706, recon=0.0706, kl=57.0940, beta=0.0000\n",
      "Batch 40, loss=0.0644, recon=0.0644, kl=47.2968, beta=0.0000\n",
      "Batch 60, loss=0.0485, recon=0.0484, kl=44.6016, beta=0.0000\n",
      "Batch 80, loss=0.5754, recon=0.5753, kl=48.6484, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0682 (Recon: 0.0682, KL: 53.0467, Current Beta: 0.0000) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0559\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0576, recon=0.0576, kl=23.0651, beta=0.0000\n",
      "Batch 40, loss=0.0757, recon=0.0757, kl=22.5834, beta=0.0000\n",
      "Batch 60, loss=0.0749, recon=0.0748, kl=19.4379, beta=0.0000\n",
      "Batch 80, loss=0.1439, recon=0.1439, kl=19.4589, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0633 (Recon: 0.0633, KL: 24.3243, Current Beta: 0.0000) | Avg Valid Loss: 0.0531 | Avg Valid recon Loss: 0.0531\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0375, recon=0.0375, kl=7.7081, beta=0.0000\n",
      "Batch 40, loss=0.0402, recon=0.0401, kl=7.5734, beta=0.0000\n",
      "Batch 60, loss=0.0446, recon=0.0446, kl=6.0273, beta=0.0000\n",
      "Batch 80, loss=0.0468, recon=0.0468, kl=6.2201, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0598 (Recon: 0.0598, KL: 8.3832, Current Beta: 0.0000) | Avg Valid Loss: 0.0508 | Avg Valid recon Loss: 0.0508\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0619, recon=0.0619, kl=2.0150, beta=0.0000\n",
      "Batch 40, loss=0.0428, recon=0.0428, kl=3.2279, beta=0.0000\n",
      "Batch 60, loss=0.0479, recon=0.0479, kl=2.3197, beta=0.0000\n",
      "Batch 80, loss=0.0463, recon=0.0463, kl=2.2797, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 2.7353, Current Beta: 0.0000) | Avg Valid Loss: 0.0489 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0481, recon=0.0481, kl=0.5610, beta=0.0000\n",
      "Batch 40, loss=0.1033, recon=0.1033, kl=0.7438, beta=0.0000\n",
      "Batch 60, loss=0.0503, recon=0.0502, kl=0.6420, beta=0.0000\n",
      "Batch 80, loss=0.0436, recon=0.0435, kl=0.7598, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0544 (Recon: 0.0544, KL: 0.9091, Current Beta: 0.0000) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0471\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0479, recon=0.0479, kl=0.0976, beta=0.0001\n",
      "Batch 40, loss=0.0509, recon=0.0509, kl=0.1588, beta=0.0001\n",
      "Batch 60, loss=0.0436, recon=0.0436, kl=0.1280, beta=0.0001\n",
      "Batch 80, loss=0.0320, recon=0.0320, kl=0.1262, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0523, KL: 0.1852, Current Beta: 0.0001) | Avg Valid Loss: 0.0451 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0376, recon=0.0376, kl=0.0140, beta=0.0002\n",
      "Batch 40, loss=0.0371, recon=0.0371, kl=0.0112, beta=0.0002\n",
      "Batch 60, loss=0.0341, recon=0.0341, kl=0.0094, beta=0.0002\n",
      "Batch 80, loss=0.0326, recon=0.0326, kl=0.0115, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0504 (Recon: 0.0504, KL: 0.0180, Current Beta: 0.0002) | Avg Valid Loss: 0.0434 | Avg Valid recon Loss: 0.0434\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0935, recon=0.0935, kl=0.0055, beta=0.0004\n",
      "Batch 40, loss=0.0301, recon=0.0301, kl=0.0024, beta=0.0004\n",
      "Batch 60, loss=0.0326, recon=0.0326, kl=0.0013, beta=0.0004\n",
      "Batch 80, loss=0.0417, recon=0.0417, kl=0.0031, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0491 (Recon: 0.0491, KL: 0.0031, Current Beta: 0.0004) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0317, recon=0.0317, kl=0.0008, beta=0.0006\n",
      "Batch 40, loss=0.0425, recon=0.0425, kl=0.0008, beta=0.0006\n",
      "Batch 60, loss=0.3726, recon=0.3726, kl=0.0010, beta=0.0006\n",
      "Batch 80, loss=0.0387, recon=0.0387, kl=0.0019, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0475 (Recon: 0.0475, KL: 0.0014, Current Beta: 0.0006) | Avg Valid Loss: 0.0414 | Avg Valid recon Loss: 0.0414\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0281, recon=0.0281, kl=0.0012, beta=0.0010\n",
      "Batch 40, loss=0.0305, recon=0.0305, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0422, recon=0.0422, kl=0.0023, beta=0.0010\n",
      "Batch 80, loss=0.0396, recon=0.0396, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0461, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0397, recon=0.0397, kl=0.0008, beta=0.0010\n",
      "Batch 40, loss=0.0277, recon=0.0277, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0334, recon=0.0334, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0277, recon=0.0277, kl=0.0009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0453 (Recon: 0.0453, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0392\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=0.0010, beta=0.0010\n",
      "Batch 40, loss=0.0358, recon=0.0358, kl=0.0009, beta=0.0010\n",
      "Batch 60, loss=0.0331, recon=0.0331, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0461, recon=0.0461, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0438, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.3318, recon=0.3318, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0403, recon=0.0403, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0249, recon=0.0249, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0428, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0239, recon=0.0239, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.0254, recon=0.0254, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0275, recon=0.0275, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0289, recon=0.0289, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "\n",
      "[VRAE Run 162/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1490, recon=0.1490, kl=50.9652, beta=0.0000\n",
      "Batch 40, loss=0.1001, recon=0.1001, kl=91.8223, beta=0.0000\n",
      "Batch 60, loss=0.0764, recon=0.0764, kl=106.4100, beta=0.0000\n",
      "Batch 80, loss=0.0663, recon=0.0663, kl=122.7768, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1491 (Recon: 0.1491, KL: 84.6900, Current Beta: 0.0000) | Avg Valid Loss: 0.0648 | Avg Valid recon Loss: 0.0648\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1390, recon=0.1390, kl=95.3368, beta=0.0000\n",
      "Batch 40, loss=0.0411, recon=0.0411, kl=97.0605, beta=0.0000\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=113.4562, beta=0.0000\n",
      "Batch 80, loss=0.0726, recon=0.0726, kl=113.6649, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0675 (Recon: 0.0675, KL: 105.2213, Current Beta: 0.0000) | Avg Valid Loss: 0.0506 | Avg Valid recon Loss: 0.0506\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=125.3537, beta=0.0000\n",
      "Batch 40, loss=0.0478, recon=0.0478, kl=116.2395, beta=0.0000\n",
      "Batch 60, loss=0.0556, recon=0.0555, kl=119.6360, beta=0.0000\n",
      "Batch 80, loss=0.0950, recon=0.0950, kl=127.6146, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0547, KL: 121.1984, Current Beta: 0.0000) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0371, recon=0.0371, kl=114.2719, beta=0.0000\n",
      "Batch 40, loss=0.1197, recon=0.1197, kl=102.5036, beta=0.0000\n",
      "Batch 60, loss=0.0892, recon=0.0892, kl=109.4926, beta=0.0000\n",
      "Batch 80, loss=0.0439, recon=0.0439, kl=120.5030, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0495, KL: 113.9648, Current Beta: 0.0000) | Avg Valid Loss: 0.0414 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0471, recon=0.0471, kl=122.9467, beta=0.0000\n",
      "Batch 40, loss=0.0426, recon=0.0426, kl=117.2629, beta=0.0000\n",
      "Batch 60, loss=0.0467, recon=0.0467, kl=112.0880, beta=0.0000\n",
      "Batch 80, loss=0.0335, recon=0.0335, kl=114.0284, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0444 (Recon: 0.0444, KL: 118.2587, Current Beta: 0.0000) | Avg Valid Loss: 0.0385 | Avg Valid recon Loss: 0.0384\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0658, recon=0.0658, kl=108.6632, beta=0.0000\n",
      "Batch 40, loss=0.0263, recon=0.0263, kl=98.4179, beta=0.0000\n",
      "Batch 60, loss=0.0318, recon=0.0318, kl=100.1695, beta=0.0000\n",
      "Batch 80, loss=0.0388, recon=0.0388, kl=107.8667, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0437, KL: 105.5127, Current Beta: 0.0000) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0249, recon=0.0249, kl=86.1165, beta=0.0000\n",
      "Batch 40, loss=0.0471, recon=0.0471, kl=72.5534, beta=0.0000\n",
      "Batch 60, loss=0.0273, recon=0.0273, kl=81.8958, beta=0.0000\n",
      "Batch 80, loss=0.0868, recon=0.0868, kl=91.0297, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0407 (Recon: 0.0407, KL: 85.3029, Current Beta: 0.0000) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0494, recon=0.0493, kl=55.5114, beta=0.0000\n",
      "Batch 40, loss=0.0823, recon=0.0822, kl=64.4544, beta=0.0000\n",
      "Batch 60, loss=0.0293, recon=0.0292, kl=65.0939, beta=0.0000\n",
      "Batch 80, loss=0.0430, recon=0.0429, kl=57.4232, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0374 (Recon: 0.0373, KL: 62.8522, Current Beta: 0.0000) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0474, recon=0.0472, kl=49.0109, beta=0.0000\n",
      "Batch 40, loss=0.0316, recon=0.0315, kl=46.6299, beta=0.0000\n",
      "Batch 60, loss=0.0780, recon=0.0778, kl=39.9325, beta=0.0000\n",
      "Batch 80, loss=0.0251, recon=0.0249, kl=44.4903, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0384, KL: 45.3607, Current Beta: 0.0000) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0316\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.2122, recon=0.2119, kl=30.3287, beta=0.0000\n",
      "Batch 40, loss=0.0356, recon=0.0352, kl=32.4217, beta=0.0000\n",
      "Batch 60, loss=0.0266, recon=0.0264, kl=21.0259, beta=0.0000\n",
      "Batch 80, loss=0.0268, recon=0.0266, kl=20.5190, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0359 (Recon: 0.0356, KL: 25.3271, Current Beta: 0.0000) | Avg Valid Loss: 0.0315 | Avg Valid recon Loss: 0.0313\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0387, recon=0.0385, kl=7.1037, beta=0.0000\n",
      "Batch 40, loss=0.0303, recon=0.0296, kl=21.6553, beta=0.0000\n",
      "Batch 60, loss=0.0355, recon=0.0345, kl=31.5753, beta=0.0000\n",
      "Batch 80, loss=0.0727, recon=0.0718, kl=29.8191, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0398 (Recon: 0.0392, KL: 22.1039, Current Beta: 0.0000) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0346\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0241, recon=0.0225, kl=22.1173, beta=0.0001\n",
      "Batch 40, loss=0.0252, recon=0.0241, kl=15.2544, beta=0.0001\n",
      "Batch 60, loss=0.0386, recon=0.0371, kl=19.7357, beta=0.0001\n",
      "Batch 80, loss=0.0345, recon=0.0335, kl=13.5445, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0380, KL: 19.3395, Current Beta: 0.0001) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0416, recon=0.0401, kl=7.7185, beta=0.0002\n",
      "Batch 40, loss=0.0259, recon=0.0247, kl=6.7287, beta=0.0002\n",
      "Batch 60, loss=0.0531, recon=0.0517, kl=7.8314, beta=0.0002\n",
      "Batch 80, loss=0.0317, recon=0.0302, kl=8.0377, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0397 (Recon: 0.0382, KL: 7.9565, Current Beta: 0.0002) | Avg Valid Loss: 0.0350 | Avg Valid recon Loss: 0.0315\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1558, recon=0.1455, kl=27.3610, beta=0.0004\n",
      "Batch 40, loss=0.0657, recon=0.0562, kl=25.1675, beta=0.0004\n",
      "Batch 60, loss=0.1668, recon=0.1567, kl=26.7397, beta=0.0004\n",
      "Batch 80, loss=0.0446, recon=0.0385, kl=16.2267, beta=0.0004\n",
      "  â†’ Avg Train Loss: 2.0191 (Recon: 2.0102, KL: 23.3537, Current Beta: 0.0004) | Avg Valid Loss: 0.0681 | Avg Valid recon Loss: 0.0615\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0716, recon=0.0644, kl=11.4508, beta=0.0006\n",
      "Batch 40, loss=0.0720, recon=0.0497, kl=35.7314, beta=0.0006\n",
      "Batch 60, loss=0.0478, recon=0.0254, kl=36.0146, beta=0.0006\n",
      "Batch 80, loss=0.0641, recon=0.0436, kl=32.8184, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0779 (Recon: 0.0606, KL: 27.7763, Current Beta: 0.0006) | Avg Valid Loss: 0.0635 | Avg Valid recon Loss: 0.0462\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0893, recon=0.0746, kl=14.6839, beta=0.0010\n",
      "Batch 40, loss=0.0749, recon=0.0349, kl=40.0448, beta=0.0010\n",
      "Batch 60, loss=0.0887, recon=0.0564, kl=32.2342, beta=0.0010\n",
      "Batch 80, loss=0.1179, recon=0.0878, kl=30.1230, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0765 (Recon: 0.0476, KL: 28.8940, Current Beta: 0.0010) | Avg Valid Loss: 2.1245 | Avg Valid recon Loss: 2.0990\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0486, recon=0.0275, kl=21.1604, beta=0.0010\n",
      "Batch 40, loss=0.0456, recon=0.0297, kl=15.9875, beta=0.0010\n",
      "Batch 60, loss=0.3060, recon=0.2975, kl=8.5522, beta=0.0010\n",
      "Batch 80, loss=0.0634, recon=0.0298, kl=33.5629, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0674 (Recon: 0.0458, KL: 21.6204, Current Beta: 0.0010) | Avg Valid Loss: 2.7794 | Avg Valid recon Loss: 2.7447\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0638, recon=0.0320, kl=31.7958, beta=0.0010\n",
      "Batch 40, loss=0.0633, recon=0.0400, kl=23.2641, beta=0.0010\n",
      "Batch 60, loss=0.2703, recon=0.2511, kl=19.1779, beta=0.0010\n",
      "Batch 80, loss=0.3211, recon=0.2838, kl=37.2126, beta=0.0010\n",
      "  â†’ Avg Train Loss: 22.7128 (Recon: 22.6835, KL: 29.3349, Current Beta: 0.0010) | Avg Valid Loss: 0.4556 | Avg Valid recon Loss: 0.3935\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.2155, recon=0.1605, kl=55.0052, beta=0.0010\n",
      "Batch 40, loss=0.2047, recon=0.1545, kl=50.1943, beta=0.0010\n",
      "Batch 60, loss=0.2370, recon=0.1920, kl=45.0053, beta=0.0010\n",
      "Batch 80, loss=0.1673, recon=0.1350, kl=32.3103, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.3282 (Recon: 0.2801, KL: 48.0830, Current Beta: 0.0010) | Avg Valid Loss: 0.2757 | Avg Valid recon Loss: 0.2425\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1525, recon=0.1236, kl=28.9054, beta=0.0010\n",
      "Batch 40, loss=0.1370, recon=0.1075, kl=29.5428, beta=0.0010\n",
      "Batch 60, loss=0.1419, recon=0.1174, kl=24.5335, beta=0.0010\n",
      "Batch 80, loss=0.1400, recon=0.1180, kl=22.0254, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 163/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.9766, recon=0.9766, kl=0.4344, beta=0.0000\n",
      "Batch 40, loss=0.5533, recon=0.5533, kl=1.0148, beta=0.0000\n",
      "Batch 60, loss=0.4584, recon=0.4584, kl=5.5041, beta=0.0000\n",
      "Batch 80, loss=0.3418, recon=0.3418, kl=9.1102, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5954 (Recon: 0.5954, KL: 3.7316, Current Beta: 0.0000) | Avg Valid Loss: 0.3852 | Avg Valid recon Loss: 0.3852\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2557, recon=0.2557, kl=14.5536, beta=0.0000\n",
      "Batch 40, loss=0.2634, recon=0.2634, kl=16.7446, beta=0.0000\n",
      "Batch 60, loss=0.1913, recon=0.1913, kl=18.9977, beta=0.0000\n",
      "Batch 80, loss=0.2292, recon=0.2292, kl=21.7925, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2947 (Recon: 0.2947, KL: 17.4543, Current Beta: 0.0000) | Avg Valid Loss: 0.2203 | Avg Valid recon Loss: 0.2203\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2167, recon=0.2167, kl=25.9157, beta=0.0000\n",
      "Batch 40, loss=0.1510, recon=0.1510, kl=28.4423, beta=0.0000\n",
      "Batch 60, loss=0.1322, recon=0.1322, kl=30.2154, beta=0.0000\n",
      "Batch 80, loss=0.1747, recon=0.1747, kl=31.7543, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2000 (Recon: 0.2000, KL: 28.4845, Current Beta: 0.0000) | Avg Valid Loss: 0.1624 | Avg Valid recon Loss: 0.1624\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1286, recon=0.1286, kl=34.0092, beta=0.0000\n",
      "Batch 40, loss=0.2489, recon=0.2489, kl=35.4399, beta=0.0000\n",
      "Batch 60, loss=0.1027, recon=0.1027, kl=36.9155, beta=0.0000\n",
      "Batch 80, loss=0.1061, recon=0.1061, kl=37.1884, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1629 (Recon: 0.1629, KL: 35.6008, Current Beta: 0.0000) | Avg Valid Loss: 0.1332 | Avg Valid recon Loss: 0.1332\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1778, recon=0.1778, kl=38.4903, beta=0.0000\n",
      "Batch 40, loss=0.1361, recon=0.1361, kl=38.7235, beta=0.0000\n",
      "Batch 60, loss=0.0779, recon=0.0779, kl=39.4234, beta=0.0000\n",
      "Batch 80, loss=0.1328, recon=0.1327, kl=39.6455, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1369 (Recon: 0.1369, KL: 38.9382, Current Beta: 0.0000) | Avg Valid Loss: 0.1157 | Avg Valid recon Loss: 0.1157\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1054, recon=0.1054, kl=39.6672, beta=0.0000\n",
      "Batch 40, loss=0.1042, recon=0.1042, kl=39.3657, beta=0.0000\n",
      "Batch 60, loss=0.0867, recon=0.0867, kl=39.2520, beta=0.0000\n",
      "Batch 80, loss=0.1645, recon=0.1645, kl=39.1178, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1195 (Recon: 0.1195, KL: 39.3745, Current Beta: 0.0000) | Avg Valid Loss: 0.1033 | Avg Valid recon Loss: 0.1033\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0907, recon=0.0907, kl=37.7751, beta=0.0000\n",
      "Batch 40, loss=0.0746, recon=0.0746, kl=36.3531, beta=0.0000\n",
      "Batch 60, loss=0.1003, recon=0.1003, kl=34.8526, beta=0.0000\n",
      "Batch 80, loss=0.0943, recon=0.0942, kl=33.9468, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1077 (Recon: 0.1077, KL: 35.9871, Current Beta: 0.0000) | Avg Valid Loss: 0.0943 | Avg Valid recon Loss: 0.0943\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0797, recon=0.0797, kl=30.0692, beta=0.0000\n",
      "Batch 40, loss=0.0847, recon=0.0847, kl=27.3707, beta=0.0000\n",
      "Batch 60, loss=0.0806, recon=0.0805, kl=24.7558, beta=0.0000\n",
      "Batch 80, loss=0.0783, recon=0.0783, kl=22.9237, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0988 (Recon: 0.0988, KL: 26.9542, Current Beta: 0.0000) | Avg Valid Loss: 0.0881 | Avg Valid recon Loss: 0.0881\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0940, recon=0.0940, kl=18.2580, beta=0.0000\n",
      "Batch 40, loss=0.0762, recon=0.0761, kl=14.1946, beta=0.0000\n",
      "Batch 60, loss=0.1156, recon=0.1155, kl=12.7889, beta=0.0000\n",
      "Batch 80, loss=0.1585, recon=0.1584, kl=11.1452, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0926 (Recon: 0.0926, KL: 15.0316, Current Beta: 0.0000) | Avg Valid Loss: 0.0830 | Avg Valid recon Loss: 0.0830\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0828, recon=0.0828, kl=6.5618, beta=0.0000\n",
      "Batch 40, loss=0.0917, recon=0.0917, kl=5.2303, beta=0.0000\n",
      "Batch 60, loss=0.0960, recon=0.0960, kl=4.6317, beta=0.0000\n",
      "Batch 80, loss=0.0658, recon=0.0658, kl=3.7293, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0874 (Recon: 0.0873, KL: 5.7286, Current Beta: 0.0000) | Avg Valid Loss: 0.0790 | Avg Valid recon Loss: 0.0790\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0655, recon=0.0655, kl=1.5866, beta=0.0000\n",
      "Batch 40, loss=0.0512, recon=0.0511, kl=1.7298, beta=0.0000\n",
      "Batch 60, loss=0.0753, recon=0.0752, kl=1.3215, beta=0.0000\n",
      "Batch 80, loss=0.0531, recon=0.0531, kl=1.2016, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0838 (Recon: 0.0837, KL: 1.7314, Current Beta: 0.0000) | Avg Valid Loss: 0.0757 | Avg Valid recon Loss: 0.0756\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0738, recon=0.0738, kl=0.3558, beta=0.0001\n",
      "Batch 40, loss=0.0552, recon=0.0552, kl=0.3228, beta=0.0001\n",
      "Batch 60, loss=0.1284, recon=0.1284, kl=0.3428, beta=0.0001\n",
      "Batch 80, loss=0.0650, recon=0.0650, kl=0.2493, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0800 (Recon: 0.0800, KL: 0.4017, Current Beta: 0.0001) | Avg Valid Loss: 0.0723 | Avg Valid recon Loss: 0.0723\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0554, recon=0.0554, kl=0.1076, beta=0.0002\n",
      "Batch 40, loss=0.0470, recon=0.0470, kl=0.0448, beta=0.0002\n",
      "Batch 60, loss=0.0588, recon=0.0588, kl=0.1019, beta=0.0002\n",
      "Batch 80, loss=0.0616, recon=0.0616, kl=0.0154, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0774 (Recon: 0.0774, KL: 0.0624, Current Beta: 0.0002) | Avg Valid Loss: 0.0703 | Avg Valid recon Loss: 0.0703\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0979, recon=0.0979, kl=0.0059, beta=0.0004\n",
      "Batch 40, loss=0.0481, recon=0.0481, kl=0.0049, beta=0.0004\n",
      "Batch 60, loss=0.2576, recon=0.2576, kl=0.0031, beta=0.0004\n",
      "Batch 80, loss=0.0538, recon=0.0538, kl=0.0043, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0747 (Recon: 0.0747, KL: 0.0052, Current Beta: 0.0004) | Avg Valid Loss: 0.0675 | Avg Valid recon Loss: 0.0674\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0457, recon=0.0457, kl=0.0011, beta=0.0006\n",
      "Batch 40, loss=0.0550, recon=0.0550, kl=0.0008, beta=0.0006\n",
      "Batch 60, loss=0.0553, recon=0.0553, kl=0.0014, beta=0.0006\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=0.0029, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0725 (Recon: 0.0725, KL: 0.0013, Current Beta: 0.0006) | Avg Valid Loss: 0.0658 | Avg Valid recon Loss: 0.0658\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0558, recon=0.0558, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0474, recon=0.0474, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0436, recon=0.0436, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0447, recon=0.0447, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0704 (Recon: 0.0704, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0641 | Avg Valid recon Loss: 0.0641\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0769, recon=0.0769, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0487, recon=0.0487, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0450, recon=0.0450, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0665, recon=0.0665, kl=0.0009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0689 (Recon: 0.0689, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0629 | Avg Valid recon Loss: 0.0629\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0748, recon=0.0748, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.1211, recon=0.1211, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0446, recon=0.0446, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0421, recon=0.0421, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0660 (Recon: 0.0660, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0612 | Avg Valid recon Loss: 0.0612\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0574, recon=0.0574, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0366, recon=0.0366, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0682, recon=0.0682, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0371, recon=0.0371, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0654 (Recon: 0.0654, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0604 | Avg Valid recon Loss: 0.0604\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0481, recon=0.0481, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0487, recon=0.0487, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0415, recon=0.0415, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0423, recon=0.0423, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0644 (Recon: 0.0644, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0586 | Avg Valid recon Loss: 0.0586\n",
      "\n",
      "[VRAE Run 164/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1747, recon=0.1747, kl=15.3082, beta=0.0000\n",
      "Batch 40, loss=0.1354, recon=0.1354, kl=24.6940, beta=0.0000\n",
      "Batch 60, loss=0.0942, recon=0.0942, kl=30.0136, beta=0.0000\n",
      "Batch 80, loss=0.0757, recon=0.0757, kl=32.7127, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2331 (Recon: 0.2331, KL: 22.9191, Current Beta: 0.0000) | Avg Valid Loss: 0.0954 | Avg Valid recon Loss: 0.0954\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0689, recon=0.0689, kl=34.4717, beta=0.0000\n",
      "Batch 40, loss=0.0662, recon=0.0662, kl=37.3885, beta=0.0000\n",
      "Batch 60, loss=0.1056, recon=0.1056, kl=38.7241, beta=0.0000\n",
      "Batch 80, loss=0.0563, recon=0.0563, kl=39.6851, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0901 (Recon: 0.0901, KL: 37.1096, Current Beta: 0.0000) | Avg Valid Loss: 0.0687 | Avg Valid recon Loss: 0.0687\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0423, recon=0.0423, kl=41.0634, beta=0.0000\n",
      "Batch 40, loss=0.0845, recon=0.0845, kl=41.9758, beta=0.0000\n",
      "Batch 60, loss=0.0455, recon=0.0455, kl=42.2187, beta=0.0000\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=41.3531, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0726 (Recon: 0.0726, KL: 41.5942, Current Beta: 0.0000) | Avg Valid Loss: 0.0592 | Avg Valid recon Loss: 0.0592\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0655, recon=0.0655, kl=43.1126, beta=0.0000\n",
      "Batch 40, loss=0.0635, recon=0.0635, kl=42.5043, beta=0.0000\n",
      "Batch 60, loss=0.0465, recon=0.0465, kl=42.9762, beta=0.0000\n",
      "Batch 80, loss=0.0453, recon=0.0453, kl=42.3100, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0647 (Recon: 0.0647, KL: 42.7278, Current Beta: 0.0000) | Avg Valid Loss: 0.0545 | Avg Valid recon Loss: 0.0545\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0626, recon=0.0626, kl=40.9414, beta=0.0000\n",
      "Batch 40, loss=0.0578, recon=0.0578, kl=37.6267, beta=0.0000\n",
      "Batch 60, loss=0.0333, recon=0.0333, kl=36.5126, beta=0.0000\n",
      "Batch 80, loss=0.0558, recon=0.0558, kl=36.6774, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 38.1729, Current Beta: 0.0000) | Avg Valid Loss: 0.0548 | Avg Valid recon Loss: 0.0547\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0358, recon=0.0358, kl=36.6631, beta=0.0000\n",
      "Batch 40, loss=0.0682, recon=0.0682, kl=29.5841, beta=0.0000\n",
      "Batch 60, loss=0.0502, recon=0.0502, kl=31.4234, beta=0.0000\n",
      "Batch 80, loss=0.4558, recon=0.4558, kl=29.7522, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0561 (Recon: 0.0561, KL: 32.2945, Current Beta: 0.0000) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0537\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0444, recon=0.0444, kl=22.2661, beta=0.0000\n",
      "Batch 40, loss=0.0466, recon=0.0466, kl=25.8561, beta=0.0000\n",
      "Batch 60, loss=0.0296, recon=0.0296, kl=24.1351, beta=0.0000\n",
      "Batch 80, loss=0.0328, recon=0.0328, kl=20.1146, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0550 (Recon: 0.0550, KL: 23.2899, Current Beta: 0.0000) | Avg Valid Loss: 0.0432 | Avg Valid recon Loss: 0.0432\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0290, recon=0.0290, kl=14.1503, beta=0.0000\n",
      "Batch 40, loss=0.0341, recon=0.0340, kl=15.2117, beta=0.0000\n",
      "Batch 60, loss=0.0412, recon=0.0412, kl=16.4410, beta=0.0000\n",
      "Batch 80, loss=0.0399, recon=0.0399, kl=14.1538, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0491 (Recon: 0.0491, KL: 15.3309, Current Beta: 0.0000) | Avg Valid Loss: 0.0416 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0421, recon=0.0421, kl=8.2098, beta=0.0000\n",
      "Batch 40, loss=0.3686, recon=0.3686, kl=7.0657, beta=0.0000\n",
      "Batch 60, loss=0.0347, recon=0.0347, kl=6.5081, beta=0.0000\n",
      "Batch 80, loss=0.0415, recon=0.0414, kl=8.1188, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0468 (Recon: 0.0468, KL: 8.0136, Current Beta: 0.0000) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0358, recon=0.0358, kl=1.6430, beta=0.0000\n",
      "Batch 40, loss=0.3469, recon=0.3468, kl=3.6472, beta=0.0000\n",
      "Batch 60, loss=0.0977, recon=0.0977, kl=2.5698, beta=0.0000\n",
      "Batch 80, loss=0.0491, recon=0.0491, kl=3.2110, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0456 (Recon: 0.0456, KL: 3.3935, Current Beta: 0.0000) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0387, recon=0.0387, kl=0.3901, beta=0.0000\n",
      "Batch 40, loss=0.0463, recon=0.0463, kl=0.2942, beta=0.0000\n",
      "Batch 60, loss=0.0514, recon=0.0514, kl=0.3097, beta=0.0000\n",
      "Batch 80, loss=0.0365, recon=0.0365, kl=0.5677, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0468, KL: 0.6443, Current Beta: 0.0000) | Avg Valid Loss: 0.0397 | Avg Valid recon Loss: 0.0397\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0518, recon=0.0518, kl=0.0302, beta=0.0001\n",
      "Batch 40, loss=0.0250, recon=0.0250, kl=0.0420, beta=0.0001\n",
      "Batch 60, loss=0.0328, recon=0.0328, kl=0.0414, beta=0.0001\n",
      "Batch 80, loss=0.0740, recon=0.0740, kl=0.0231, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0426 (Recon: 0.0426, KL: 0.0499, Current Beta: 0.0001) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0400, recon=0.0400, kl=0.0050, beta=0.0002\n",
      "Batch 40, loss=0.0445, recon=0.0445, kl=0.0086, beta=0.0002\n",
      "Batch 60, loss=0.1027, recon=0.1027, kl=0.0271, beta=0.0002\n",
      "Batch 80, loss=0.0463, recon=0.0463, kl=0.0049, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0430, KL: 0.0123, Current Beta: 0.0002) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0317, recon=0.0317, kl=0.0027, beta=0.0004\n",
      "Batch 40, loss=0.0345, recon=0.0345, kl=0.0020, beta=0.0004\n",
      "Batch 60, loss=0.0412, recon=0.0412, kl=0.0047, beta=0.0004\n",
      "Batch 80, loss=0.0348, recon=0.0348, kl=0.0028, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0428, KL: 0.0027, Current Beta: 0.0004) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0378, recon=0.0378, kl=0.0031, beta=0.0006\n",
      "Batch 40, loss=0.0464, recon=0.0464, kl=0.0011, beta=0.0006\n",
      "Batch 60, loss=0.0308, recon=0.0308, kl=0.0009, beta=0.0006\n",
      "Batch 80, loss=0.0341, recon=0.0341, kl=0.0013, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0441 (Recon: 0.0441, KL: 0.0014, Current Beta: 0.0006) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0429\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0994, recon=0.0994, kl=0.0005, beta=0.0010\n",
      "Batch 40, loss=0.0692, recon=0.0692, kl=0.0008, beta=0.0010\n",
      "Batch 60, loss=0.0378, recon=0.0378, kl=0.0009, beta=0.0010\n",
      "Batch 80, loss=0.0692, recon=0.0692, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0473, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0310, recon=0.0310, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0420, recon=0.0420, kl=0.0010, beta=0.0010\n",
      "Batch 60, loss=0.0372, recon=0.0372, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0357, recon=0.0357, kl=0.0030, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0407 (Recon: 0.0407, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0405 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0787, recon=0.0787, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0468, recon=0.0468, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0653, recon=0.0653, kl=0.0011, beta=0.0010\n",
      "Batch 80, loss=0.0557, recon=0.0557, kl=0.0027, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0649 (Recon: 0.0649, KL: 0.0017, Current Beta: 0.0010) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0537\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0326, recon=0.0326, kl=0.0016, beta=0.0010\n",
      "Batch 40, loss=0.0823, recon=0.0823, kl=0.0024, beta=0.0010\n",
      "Batch 60, loss=0.0508, recon=0.0508, kl=0.0013, beta=0.0010\n",
      "Batch 80, loss=0.0582, recon=0.0582, kl=0.0011, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 0.0017, Current Beta: 0.0010) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0342, recon=0.0342, kl=0.0021, beta=0.0010\n",
      "Batch 40, loss=0.0520, recon=0.0520, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0340, recon=0.0340, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0399, recon=0.0399, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0436 (Recon: 0.0436, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0387\n",
      "\n",
      "[VRAE Run 165/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7578, recon=0.7578, kl=0.5932, beta=0.0000\n",
      "Batch 40, loss=0.5033, recon=0.5033, kl=4.0255, beta=0.0000\n",
      "Batch 60, loss=0.3741, recon=0.3741, kl=17.3117, beta=0.0000\n",
      "Batch 80, loss=0.3753, recon=0.3753, kl=27.5833, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5636 (Recon: 0.5636, KL: 11.2774, Current Beta: 0.0000) | Avg Valid Loss: 0.3625 | Avg Valid recon Loss: 0.3625\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2727, recon=0.2727, kl=37.0710, beta=0.0000\n",
      "Batch 40, loss=0.3164, recon=0.3164, kl=42.8878, beta=0.0000\n",
      "Batch 60, loss=0.2654, recon=0.2654, kl=47.2544, beta=0.0000\n",
      "Batch 80, loss=0.1765, recon=0.1765, kl=51.3988, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2824 (Recon: 0.2824, KL: 43.4401, Current Beta: 0.0000) | Avg Valid Loss: 0.2077 | Avg Valid recon Loss: 0.2077\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1622, recon=0.1622, kl=58.1399, beta=0.0000\n",
      "Batch 40, loss=0.1908, recon=0.1908, kl=61.2969, beta=0.0000\n",
      "Batch 60, loss=0.2372, recon=0.2372, kl=64.8153, beta=0.0000\n",
      "Batch 80, loss=0.1714, recon=0.1714, kl=66.0734, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1980 (Recon: 0.1980, KL: 61.6769, Current Beta: 0.0000) | Avg Valid Loss: 0.1559 | Avg Valid recon Loss: 0.1559\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1432, recon=0.1432, kl=66.1579, beta=0.0000\n",
      "Batch 40, loss=0.1157, recon=0.1157, kl=67.7610, beta=0.0000\n",
      "Batch 60, loss=0.1090, recon=0.1090, kl=70.1460, beta=0.0000\n",
      "Batch 80, loss=1.1419, recon=1.1419, kl=71.3165, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1573 (Recon: 0.1573, KL: 68.6105, Current Beta: 0.0000) | Avg Valid Loss: 0.1284 | Avg Valid recon Loss: 0.1284\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1327, recon=0.1327, kl=72.6291, beta=0.0000\n",
      "Batch 40, loss=0.1218, recon=0.1218, kl=73.3741, beta=0.0000\n",
      "Batch 60, loss=0.1038, recon=0.1038, kl=73.0322, beta=0.0000\n",
      "Batch 80, loss=0.0758, recon=0.0758, kl=72.6207, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1322 (Recon: 0.1322, KL: 72.8021, Current Beta: 0.0000) | Avg Valid Loss: 0.1125 | Avg Valid recon Loss: 0.1125\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0708, recon=0.0707, kl=72.6395, beta=0.0000\n",
      "Batch 40, loss=0.1190, recon=0.1190, kl=72.0349, beta=0.0000\n",
      "Batch 60, loss=0.1017, recon=0.1016, kl=71.6539, beta=0.0000\n",
      "Batch 80, loss=0.0686, recon=0.0686, kl=71.0326, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1158 (Recon: 0.1158, KL: 71.9262, Current Beta: 0.0000) | Avg Valid Loss: 0.1010 | Avg Valid recon Loss: 0.1010\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0710, recon=0.0710, kl=68.6181, beta=0.0000\n",
      "Batch 40, loss=0.1083, recon=0.1083, kl=65.8840, beta=0.0000\n",
      "Batch 60, loss=0.0849, recon=0.0849, kl=62.9179, beta=0.0000\n",
      "Batch 80, loss=0.1118, recon=0.1117, kl=60.4570, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1046 (Recon: 0.1045, KL: 65.1273, Current Beta: 0.0000) | Avg Valid Loss: 0.0930 | Avg Valid recon Loss: 0.0930\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0660, recon=0.0660, kl=51.8447, beta=0.0000\n",
      "Batch 40, loss=0.0968, recon=0.0968, kl=42.7899, beta=0.0000\n",
      "Batch 60, loss=0.1216, recon=0.1216, kl=38.9534, beta=0.0000\n",
      "Batch 80, loss=0.0814, recon=0.0813, kl=38.5521, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0960 (Recon: 0.0959, KL: 44.4638, Current Beta: 0.0000) | Avg Valid Loss: 0.0881 | Avg Valid recon Loss: 0.0881\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0541, recon=0.0540, kl=24.7340, beta=0.0000\n",
      "Batch 40, loss=0.0965, recon=0.0964, kl=19.9219, beta=0.0000\n",
      "Batch 60, loss=0.0994, recon=0.0993, kl=20.4742, beta=0.0000\n",
      "Batch 80, loss=0.0927, recon=0.0926, kl=17.3906, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0898 (Recon: 0.0897, KL: 22.1046, Current Beta: 0.0000) | Avg Valid Loss: 0.0824 | Avg Valid recon Loss: 0.0823\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0654, recon=0.0653, kl=7.9854, beta=0.0000\n",
      "Batch 40, loss=0.0870, recon=0.0869, kl=8.0231, beta=0.0000\n",
      "Batch 60, loss=0.0510, recon=0.0510, kl=7.7313, beta=0.0000\n",
      "Batch 80, loss=0.1528, recon=0.1527, kl=6.4331, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0848 (Recon: 0.0847, KL: 8.4032, Current Beta: 0.0000) | Avg Valid Loss: 0.0771 | Avg Valid recon Loss: 0.0770\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0796, recon=0.0795, kl=2.5272, beta=0.0000\n",
      "Batch 40, loss=0.0534, recon=0.0533, kl=2.1602, beta=0.0000\n",
      "Batch 60, loss=0.0726, recon=0.0725, kl=2.0049, beta=0.0000\n",
      "Batch 80, loss=0.0571, recon=0.0571, kl=1.7872, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0809 (Recon: 0.0809, KL: 2.4559, Current Beta: 0.0000) | Avg Valid Loss: 0.0749 | Avg Valid recon Loss: 0.0749\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0455, recon=0.0455, kl=0.5481, beta=0.0001\n",
      "Batch 40, loss=0.0457, recon=0.0457, kl=0.4684, beta=0.0001\n",
      "Batch 60, loss=0.0512, recon=0.0512, kl=0.3784, beta=0.0001\n",
      "Batch 80, loss=0.0579, recon=0.0579, kl=0.3420, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0777 (Recon: 0.0777, KL: 0.5360, Current Beta: 0.0001) | Avg Valid Loss: 0.0711 | Avg Valid recon Loss: 0.0710\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0604, recon=0.0604, kl=0.0659, beta=0.0002\n",
      "Batch 40, loss=0.0444, recon=0.0444, kl=0.0537, beta=0.0002\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=0.0361, beta=0.0002\n",
      "Batch 80, loss=0.0480, recon=0.0480, kl=0.0306, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0748 (Recon: 0.0748, KL: 0.0689, Current Beta: 0.0002) | Avg Valid Loss: 0.0695 | Avg Valid recon Loss: 0.0695\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0593, recon=0.0593, kl=0.0054, beta=0.0004\n",
      "Batch 40, loss=0.0470, recon=0.0470, kl=0.0053, beta=0.0004\n",
      "Batch 60, loss=0.0615, recon=0.0615, kl=0.0028, beta=0.0004\n",
      "Batch 80, loss=0.0467, recon=0.0467, kl=0.0023, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0723 (Recon: 0.0723, KL: 0.0048, Current Beta: 0.0004) | Avg Valid Loss: 0.0673 | Avg Valid recon Loss: 0.0673\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0453, recon=0.0453, kl=0.0008, beta=0.0006\n",
      "Batch 40, loss=0.0551, recon=0.0551, kl=0.0006, beta=0.0006\n",
      "Batch 60, loss=0.0645, recon=0.0645, kl=0.0005, beta=0.0006\n",
      "Batch 80, loss=0.0640, recon=0.0640, kl=0.0007, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0701 (Recon: 0.0701, KL: 0.0008, Current Beta: 0.0006) | Avg Valid Loss: 0.0647 | Avg Valid recon Loss: 0.0647\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0538, recon=0.0538, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0464, recon=0.0464, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0585, recon=0.0585, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0622, recon=0.0622, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0678 (Recon: 0.0678, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0635 | Avg Valid recon Loss: 0.0635\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0482, recon=0.0482, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0379, recon=0.0379, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0471, recon=0.0471, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.1323, recon=0.1323, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0667 (Recon: 0.0667, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0615 | Avg Valid recon Loss: 0.0615\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0533, recon=0.0533, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.1413, recon=0.1413, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0605, recon=0.0605, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0712, recon=0.0712, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0654 (Recon: 0.0654, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.0609 | Avg Valid recon Loss: 0.0609\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1058, recon=0.1058, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0450, recon=0.0450, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0422, recon=0.0422, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.1078, recon=0.1078, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0595 | Avg Valid recon Loss: 0.0595\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0378, recon=0.0378, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0584, recon=0.0584, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0519, recon=0.0519, kl=0.0000, beta=0.0010\n",
      "Batch 80, loss=0.0502, recon=0.0502, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0631 (Recon: 0.0631, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.0577 | Avg Valid recon Loss: 0.0577\n",
      "\n",
      "[VRAE Run 166/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2954, recon=0.2954, kl=29.3827, beta=0.0000\n",
      "Batch 40, loss=0.1001, recon=0.1001, kl=48.3020, beta=0.0000\n",
      "Batch 60, loss=0.1097, recon=0.1097, kl=57.9644, beta=0.0000\n",
      "Batch 80, loss=0.1453, recon=0.1453, kl=55.5704, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2452 (Recon: 0.2452, KL: 42.8583, Current Beta: 0.0000) | Avg Valid Loss: 0.0927 | Avg Valid recon Loss: 0.0927\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0772, recon=0.0772, kl=61.4392, beta=0.0000\n",
      "Batch 40, loss=0.1085, recon=0.1085, kl=68.3407, beta=0.0000\n",
      "Batch 60, loss=0.0877, recon=0.0877, kl=72.4801, beta=0.0000\n",
      "Batch 80, loss=0.0730, recon=0.0730, kl=70.6257, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0857 (Recon: 0.0857, KL: 67.4267, Current Beta: 0.0000) | Avg Valid Loss: 0.0657 | Avg Valid recon Loss: 0.0657\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0437, recon=0.0437, kl=72.2565, beta=0.0000\n",
      "Batch 40, loss=0.0468, recon=0.0468, kl=77.1297, beta=0.0000\n",
      "Batch 60, loss=0.0550, recon=0.0550, kl=70.2706, beta=0.0000\n",
      "Batch 80, loss=0.0611, recon=0.0611, kl=75.2471, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0655 (Recon: 0.0655, KL: 73.4389, Current Beta: 0.0000) | Avg Valid Loss: 0.0525 | Avg Valid recon Loss: 0.0525\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0494, recon=0.0494, kl=76.9544, beta=0.0000\n",
      "Batch 40, loss=0.0905, recon=0.0905, kl=76.6559, beta=0.0000\n",
      "Batch 60, loss=0.0390, recon=0.0390, kl=73.9280, beta=0.0000\n",
      "Batch 80, loss=0.0478, recon=0.0477, kl=73.4403, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0577 (Recon: 0.0577, KL: 75.2371, Current Beta: 0.0000) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0500, recon=0.0499, kl=70.1637, beta=0.0000\n",
      "Batch 40, loss=0.0300, recon=0.0300, kl=70.1771, beta=0.0000\n",
      "Batch 60, loss=0.0362, recon=0.0362, kl=65.6706, beta=0.0000\n",
      "Batch 80, loss=0.0395, recon=0.0395, kl=63.3827, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0525 (Recon: 0.0524, KL: 68.5578, Current Beta: 0.0000) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0429, recon=0.0429, kl=66.1830, beta=0.0000\n",
      "Batch 40, loss=0.0421, recon=0.0421, kl=58.0710, beta=0.0000\n",
      "Batch 60, loss=0.0884, recon=0.0884, kl=57.4599, beta=0.0000\n",
      "Batch 80, loss=0.0447, recon=0.0447, kl=57.9141, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 60.3838, Current Beta: 0.0000) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0262, recon=0.0262, kl=42.2782, beta=0.0000\n",
      "Batch 40, loss=0.0433, recon=0.0432, kl=39.8385, beta=0.0000\n",
      "Batch 60, loss=0.0404, recon=0.0404, kl=47.3394, beta=0.0000\n",
      "Batch 80, loss=0.0509, recon=0.0509, kl=45.0990, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0456 (Recon: 0.0455, KL: 44.7496, Current Beta: 0.0000) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0277, recon=0.0276, kl=27.2362, beta=0.0000\n",
      "Batch 40, loss=0.0914, recon=0.0913, kl=27.1005, beta=0.0000\n",
      "Batch 60, loss=0.0359, recon=0.0358, kl=26.6527, beta=0.0000\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=27.0087, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0441 (Recon: 0.0441, KL: 29.0495, Current Beta: 0.0000) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0325, recon=0.0325, kl=14.8890, beta=0.0000\n",
      "Batch 40, loss=0.0524, recon=0.0523, kl=12.8325, beta=0.0000\n",
      "Batch 60, loss=0.0304, recon=0.0304, kl=10.7781, beta=0.0000\n",
      "Batch 80, loss=0.0219, recon=0.0218, kl=9.1894, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0411 (Recon: 0.0410, KL: 13.7301, Current Beta: 0.0000) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0550, recon=0.0549, kl=5.0871, beta=0.0000\n",
      "Batch 40, loss=0.0340, recon=0.0339, kl=4.1914, beta=0.0000\n",
      "Batch 60, loss=0.0339, recon=0.0339, kl=6.3800, beta=0.0000\n",
      "Batch 80, loss=0.0358, recon=0.0358, kl=3.5137, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0417, KL: 6.3966, Current Beta: 0.0000) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0345\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0310, recon=0.0310, kl=0.6223, beta=0.0000\n",
      "Batch 40, loss=0.0260, recon=0.0260, kl=0.5109, beta=0.0000\n",
      "Batch 60, loss=0.0377, recon=0.0377, kl=0.6504, beta=0.0000\n",
      "Batch 80, loss=0.0365, recon=0.0365, kl=0.5334, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0416, KL: 1.0704, Current Beta: 0.0000) | Avg Valid Loss: 0.0428 | Avg Valid recon Loss: 0.0428\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0416, recon=0.0416, kl=0.0461, beta=0.0001\n",
      "Batch 40, loss=0.0320, recon=0.0320, kl=0.0497, beta=0.0001\n",
      "Batch 60, loss=0.0434, recon=0.0433, kl=0.4539, beta=0.0001\n",
      "Batch 80, loss=0.0676, recon=0.0675, kl=0.2793, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0399 (Recon: 0.0399, KL: 0.2125, Current Beta: 0.0001) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0406, recon=0.0406, kl=0.0047, beta=0.0002\n",
      "Batch 40, loss=0.0277, recon=0.0277, kl=0.0107, beta=0.0002\n",
      "Batch 60, loss=0.0322, recon=0.0322, kl=0.0041, beta=0.0002\n",
      "Batch 80, loss=0.0223, recon=0.0223, kl=0.0069, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0379 (Recon: 0.0379, KL: 0.0127, Current Beta: 0.0002) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0334\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=0.0032, beta=0.0004\n",
      "Batch 40, loss=0.0271, recon=0.0271, kl=0.0013, beta=0.0004\n",
      "Batch 60, loss=0.0209, recon=0.0208, kl=0.0024, beta=0.0004\n",
      "Batch 80, loss=0.0702, recon=0.0702, kl=0.0025, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0384 (Recon: 0.0384, KL: 0.0021, Current Beta: 0.0004) | Avg Valid Loss: 0.0453 | Avg Valid recon Loss: 0.0453\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0597, recon=0.0597, kl=0.0060, beta=0.0006\n",
      "Batch 40, loss=0.0899, recon=0.0899, kl=0.0024, beta=0.0006\n",
      "Batch 60, loss=0.0279, recon=0.0279, kl=0.0021, beta=0.0006\n",
      "Batch 80, loss=0.0677, recon=0.0677, kl=0.0015, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0495, KL: 0.0024, Current Beta: 0.0006) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0345\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0462, recon=0.0462, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0366, recon=0.0366, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0391, recon=0.0391, kl=0.0008, beta=0.0010\n",
      "Batch 80, loss=0.0760, recon=0.0760, kl=0.0017, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0435 (Recon: 0.0435, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0335, recon=0.0335, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0704, recon=0.0704, kl=0.0010, beta=0.0010\n",
      "Batch 60, loss=0.0401, recon=0.0401, kl=0.0011, beta=0.0010\n",
      "Batch 80, loss=0.0283, recon=0.0283, kl=0.0051, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0545, KL: 0.0017, Current Beta: 0.0010) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0255, recon=0.0255, kl=0.0023, beta=0.0010\n",
      "Batch 40, loss=0.0371, recon=0.0370, kl=0.0012, beta=0.0010\n",
      "Batch 60, loss=0.0276, recon=0.0276, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0460, recon=0.0460, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0416, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0443 | Avg Valid recon Loss: 0.0443\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0229, recon=0.0229, kl=0.0072, beta=0.0010\n",
      "Batch 60, loss=0.0253, recon=0.0253, kl=0.0031, beta=0.0010\n",
      "Batch 80, loss=0.0668, recon=0.0668, kl=0.0009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0433, KL: 0.0031, Current Beta: 0.0010) | Avg Valid Loss: 0.0429 | Avg Valid recon Loss: 0.0429\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0417, recon=0.0417, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.0507, recon=0.0507, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.1068, recon=0.1068, kl=0.0010, beta=0.0010\n",
      "Batch 80, loss=0.0311, recon=0.0311, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0448 (Recon: 0.0448, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "\n",
      "[VRAE Run 167/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4962, recon=0.4962, kl=1.1123, beta=0.0000\n",
      "Batch 40, loss=0.5430, recon=0.5430, kl=10.5765, beta=0.0000\n",
      "Batch 60, loss=0.3027, recon=0.3027, kl=34.7303, beta=0.0000\n",
      "Batch 80, loss=0.3184, recon=0.3184, kl=50.7109, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5524 (Recon: 0.5524, KL: 21.9883, Current Beta: 0.0000) | Avg Valid Loss: 0.3532 | Avg Valid recon Loss: 0.3532\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2680, recon=0.2680, kl=65.5076, beta=0.0000\n",
      "Batch 40, loss=0.2368, recon=0.2368, kl=74.8843, beta=0.0000\n",
      "Batch 60, loss=0.1678, recon=0.1678, kl=83.1535, beta=0.0000\n",
      "Batch 80, loss=0.1287, recon=0.1287, kl=91.7060, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2783 (Recon: 0.2783, KL: 76.7888, Current Beta: 0.0000) | Avg Valid Loss: 0.2087 | Avg Valid recon Loss: 0.2087\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1826, recon=0.1826, kl=101.6757, beta=0.0000\n",
      "Batch 40, loss=0.1702, recon=0.1702, kl=107.0275, beta=0.0000\n",
      "Batch 60, loss=0.1856, recon=0.1856, kl=112.4411, beta=0.0000\n",
      "Batch 80, loss=0.2378, recon=0.2378, kl=117.5988, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1971 (Recon: 0.1971, KL: 108.3430, Current Beta: 0.0000) | Avg Valid Loss: 0.1573 | Avg Valid recon Loss: 0.1573\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1523, recon=0.1523, kl=121.6191, beta=0.0000\n",
      "Batch 40, loss=0.1696, recon=0.1696, kl=124.6105, beta=0.0000\n",
      "Batch 60, loss=0.1446, recon=0.1446, kl=127.0048, beta=0.0000\n",
      "Batch 80, loss=0.1359, recon=0.1359, kl=130.1537, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1585 (Recon: 0.1585, KL: 125.2715, Current Beta: 0.0000) | Avg Valid Loss: 0.1309 | Avg Valid recon Loss: 0.1309\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1191, recon=0.1191, kl=132.6729, beta=0.0000\n",
      "Batch 40, loss=0.1555, recon=0.1555, kl=133.0977, beta=0.0000\n",
      "Batch 60, loss=0.1319, recon=0.1319, kl=135.6031, beta=0.0000\n",
      "Batch 80, loss=0.0928, recon=0.0928, kl=137.1805, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1354 (Recon: 0.1354, KL: 134.4526, Current Beta: 0.0000) | Avg Valid Loss: 0.1148 | Avg Valid recon Loss: 0.1148\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0841, recon=0.0841, kl=136.3221, beta=0.0000\n",
      "Batch 40, loss=0.1937, recon=0.1937, kl=134.8726, beta=0.0000\n",
      "Batch 60, loss=0.1049, recon=0.1048, kl=133.3240, beta=0.0000\n",
      "Batch 80, loss=0.0717, recon=0.0717, kl=132.4254, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1194 (Recon: 0.1194, KL: 134.6587, Current Beta: 0.0000) | Avg Valid Loss: 0.1035 | Avg Valid recon Loss: 0.1035\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0712, recon=0.0711, kl=126.7112, beta=0.0000\n",
      "Batch 40, loss=0.0675, recon=0.0674, kl=116.6007, beta=0.0000\n",
      "Batch 60, loss=0.0759, recon=0.0758, kl=108.8604, beta=0.0000\n",
      "Batch 80, loss=0.8998, recon=0.8997, kl=102.9088, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1089 (Recon: 0.1089, KL: 115.2827, Current Beta: 0.0000) | Avg Valid Loss: 0.0959 | Avg Valid recon Loss: 0.0958\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0545, recon=0.0544, kl=75.4782, beta=0.0000\n",
      "Batch 40, loss=0.0692, recon=0.0691, kl=56.8717, beta=0.0000\n",
      "Batch 60, loss=0.3018, recon=0.3017, kl=58.1227, beta=0.0000\n",
      "Batch 80, loss=0.1307, recon=0.1306, kl=54.0102, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1004 (Recon: 0.1003, KL: 65.0232, Current Beta: 0.0000) | Avg Valid Loss: 0.0889 | Avg Valid recon Loss: 0.0888\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0875, recon=0.0874, kl=28.7270, beta=0.0000\n",
      "Batch 40, loss=0.0643, recon=0.0642, kl=29.3923, beta=0.0000\n",
      "Batch 60, loss=0.0840, recon=0.0839, kl=25.0813, beta=0.0000\n",
      "Batch 80, loss=0.0798, recon=0.0797, kl=26.7548, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0943 (Recon: 0.0941, KL: 29.6759, Current Beta: 0.0000) | Avg Valid Loss: 0.0851 | Avg Valid recon Loss: 0.0850\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1010, recon=0.1009, kl=12.6744, beta=0.0000\n",
      "Batch 40, loss=0.0534, recon=0.0534, kl=8.5233, beta=0.0000\n",
      "Batch 60, loss=0.0622, recon=0.0621, kl=8.5779, beta=0.0000\n",
      "Batch 80, loss=0.0779, recon=0.0778, kl=7.1920, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0889 (Recon: 0.0888, KL: 9.8583, Current Beta: 0.0000) | Avg Valid Loss: 0.0798 | Avg Valid recon Loss: 0.0797\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1050, recon=0.1049, kl=3.2649, beta=0.0000\n",
      "Batch 40, loss=0.0773, recon=0.0773, kl=1.6443, beta=0.0000\n",
      "Batch 60, loss=0.0575, recon=0.0574, kl=1.9716, beta=0.0000\n",
      "Batch 80, loss=0.0870, recon=0.0869, kl=1.3129, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0842 (Recon: 0.0842, KL: 2.2245, Current Beta: 0.0000) | Avg Valid Loss: 0.0764 | Avg Valid recon Loss: 0.0763\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0749, recon=0.0749, kl=0.4084, beta=0.0001\n",
      "Batch 40, loss=0.1065, recon=0.1064, kl=0.4867, beta=0.0001\n",
      "Batch 60, loss=0.0547, recon=0.0547, kl=0.2818, beta=0.0001\n",
      "Batch 80, loss=0.0590, recon=0.0589, kl=0.2302, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0804 (Recon: 0.0804, KL: 0.4468, Current Beta: 0.0001) | Avg Valid Loss: 0.0732 | Avg Valid recon Loss: 0.0731\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0561, recon=0.0561, kl=0.0701, beta=0.0002\n",
      "Batch 40, loss=0.0616, recon=0.0616, kl=0.0323, beta=0.0002\n",
      "Batch 60, loss=0.0471, recon=0.0471, kl=0.0199, beta=0.0002\n",
      "Batch 80, loss=0.0405, recon=0.0405, kl=0.0154, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0773 (Recon: 0.0773, KL: 0.0512, Current Beta: 0.0002) | Avg Valid Loss: 0.0702 | Avg Valid recon Loss: 0.0702\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0650, recon=0.0650, kl=0.0032, beta=0.0004\n",
      "Batch 40, loss=0.0533, recon=0.0533, kl=0.0026, beta=0.0004\n",
      "Batch 60, loss=0.0505, recon=0.0505, kl=0.0026, beta=0.0004\n",
      "Batch 80, loss=0.0470, recon=0.0470, kl=0.0021, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0742 (Recon: 0.0742, KL: 0.0035, Current Beta: 0.0004) | Avg Valid Loss: 0.0678 | Avg Valid recon Loss: 0.0678\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0403, recon=0.0403, kl=0.0009, beta=0.0006\n",
      "Batch 40, loss=0.0575, recon=0.0575, kl=0.0006, beta=0.0006\n",
      "Batch 60, loss=0.0603, recon=0.0603, kl=0.0006, beta=0.0006\n",
      "Batch 80, loss=0.0447, recon=0.0447, kl=0.0010, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0722 (Recon: 0.0722, KL: 0.0008, Current Beta: 0.0006) | Avg Valid Loss: 0.0659 | Avg Valid recon Loss: 0.0659\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0541, recon=0.0541, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.1213, recon=0.1213, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0537, recon=0.0537, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0632, recon=0.0632, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0699 (Recon: 0.0699, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0637 | Avg Valid recon Loss: 0.0637\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0537, recon=0.0537, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0483, recon=0.0483, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0597, recon=0.0597, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0588, recon=0.0588, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0680 (Recon: 0.0680, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0616 | Avg Valid recon Loss: 0.0616\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0497, recon=0.0497, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.1911, recon=0.1911, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0379, recon=0.0378, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0462, recon=0.0462, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0662 (Recon: 0.0662, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0603 | Avg Valid recon Loss: 0.0603\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0710, recon=0.0710, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0511, recon=0.0511, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0598, recon=0.0598, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0456, recon=0.0456, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0648 (Recon: 0.0648, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0587 | Avg Valid recon Loss: 0.0587\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0386, recon=0.0386, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0469, recon=0.0469, kl=0.0001, beta=0.0010\n",
      "Batch 60, loss=0.0481, recon=0.0481, kl=0.0001, beta=0.0010\n",
      "Batch 80, loss=0.0981, recon=0.0981, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0631 (Recon: 0.0631, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0574\n",
      "\n",
      "[VRAE Run 168/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2633, recon=0.2633, kl=74.7091, beta=0.0000\n",
      "Batch 40, loss=0.1619, recon=0.1619, kl=103.4412, beta=0.0000\n",
      "Batch 60, loss=0.0767, recon=0.0767, kl=118.2919, beta=0.0000\n",
      "Batch 80, loss=0.0895, recon=0.0895, kl=131.2750, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2228 (Recon: 0.2228, KL: 94.9496, Current Beta: 0.0000) | Avg Valid Loss: 0.0950 | Avg Valid recon Loss: 0.0950\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1494, recon=0.1494, kl=129.0295, beta=0.0000\n",
      "Batch 40, loss=0.0747, recon=0.0747, kl=132.9645, beta=0.0000\n",
      "Batch 60, loss=0.0729, recon=0.0729, kl=112.6948, beta=0.0000\n",
      "Batch 80, loss=0.0627, recon=0.0627, kl=119.0616, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0897 (Recon: 0.0897, KL: 126.0367, Current Beta: 0.0000) | Avg Valid Loss: 0.0724 | Avg Valid recon Loss: 0.0724\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1256, recon=0.1256, kl=133.2231, beta=0.0000\n",
      "Batch 40, loss=0.0562, recon=0.0562, kl=138.2140, beta=0.0000\n",
      "Batch 60, loss=0.0485, recon=0.0485, kl=141.7004, beta=0.0000\n",
      "Batch 80, loss=0.0506, recon=0.0506, kl=154.7106, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0712 (Recon: 0.0712, KL: 138.5659, Current Beta: 0.0000) | Avg Valid Loss: 0.0632 | Avg Valid recon Loss: 0.0632\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0535, recon=0.0535, kl=141.8567, beta=0.0000\n",
      "Batch 40, loss=0.0440, recon=0.0440, kl=128.5466, beta=0.0000\n",
      "Batch 60, loss=0.0525, recon=0.0525, kl=127.5393, beta=0.0000\n",
      "Batch 80, loss=0.0472, recon=0.0472, kl=130.8354, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0636 (Recon: 0.0636, KL: 134.9619, Current Beta: 0.0000) | Avg Valid Loss: 0.0542 | Avg Valid recon Loss: 0.0542\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0424, recon=0.0424, kl=120.6783, beta=0.0000\n",
      "Batch 40, loss=0.0516, recon=0.0516, kl=117.3576, beta=0.0000\n",
      "Batch 60, loss=0.0372, recon=0.0372, kl=108.3610, beta=0.0000\n",
      "Batch 80, loss=0.0757, recon=0.0757, kl=117.3428, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 118.4953, Current Beta: 0.0000) | Avg Valid Loss: 0.0520 | Avg Valid recon Loss: 0.0520\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0517, recon=0.0517, kl=107.0584, beta=0.0000\n",
      "Batch 40, loss=0.0397, recon=0.0397, kl=97.1974, beta=0.0000\n",
      "Batch 60, loss=0.0336, recon=0.0336, kl=94.5386, beta=0.0000\n",
      "Batch 80, loss=0.0449, recon=0.0449, kl=107.8764, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0532 (Recon: 0.0531, KL: 101.3598, Current Beta: 0.0000) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0466\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0285, recon=0.0284, kl=68.9536, beta=0.0000\n",
      "Batch 40, loss=0.0398, recon=0.0398, kl=81.5147, beta=0.0000\n",
      "Batch 60, loss=0.0840, recon=0.0839, kl=76.5345, beta=0.0000\n",
      "Batch 80, loss=0.0343, recon=0.0342, kl=73.5521, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0501 (Recon: 0.0500, KL: 77.7742, Current Beta: 0.0000) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0346, recon=0.0345, kl=48.4156, beta=0.0000\n",
      "Batch 40, loss=0.0314, recon=0.0313, kl=47.6606, beta=0.0000\n",
      "Batch 60, loss=0.0337, recon=0.0337, kl=45.9052, beta=0.0000\n",
      "Batch 80, loss=0.0496, recon=0.0495, kl=65.2184, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0481, KL: 54.4092, Current Beta: 0.0000) | Avg Valid Loss: 0.0427 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0399, recon=0.0398, kl=26.5518, beta=0.0000\n",
      "Batch 40, loss=0.0509, recon=0.0508, kl=32.2372, beta=0.0000\n",
      "Batch 60, loss=0.0356, recon=0.0354, kl=39.9297, beta=0.0000\n",
      "Batch 80, loss=0.0436, recon=0.0435, kl=29.9968, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0461, KL: 34.4630, Current Beta: 0.0000) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0409\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0353, recon=0.0351, kl=15.8056, beta=0.0000\n",
      "Batch 40, loss=0.0658, recon=0.0657, kl=12.4114, beta=0.0000\n",
      "Batch 60, loss=0.0259, recon=0.0257, kl=11.4073, beta=0.0000\n",
      "Batch 80, loss=0.0440, recon=0.0439, kl=10.9223, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0444, KL: 13.2904, Current Beta: 0.0000) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0313, recon=0.0313, kl=1.9427, beta=0.0000\n",
      "Batch 40, loss=0.0377, recon=0.0376, kl=3.0706, beta=0.0000\n",
      "Batch 60, loss=0.0358, recon=0.0356, kl=8.1143, beta=0.0000\n",
      "Batch 80, loss=0.0296, recon=0.0295, kl=4.4666, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0501 (Recon: 0.0500, KL: 4.3456, Current Beta: 0.0000) | Avg Valid Loss: 0.0443 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0263, recon=0.0262, kl=1.3266, beta=0.0001\n",
      "Batch 40, loss=0.0244, recon=0.0244, kl=0.3288, beta=0.0001\n",
      "Batch 60, loss=0.0332, recon=0.0332, kl=0.0950, beta=0.0001\n",
      "Batch 80, loss=0.0406, recon=0.0406, kl=0.2120, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0458, KL: 0.8372, Current Beta: 0.0001) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0523\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0454, recon=0.0453, kl=0.3372, beta=0.0002\n",
      "Batch 40, loss=0.0437, recon=0.0437, kl=0.0414, beta=0.0002\n",
      "Batch 60, loss=0.0378, recon=0.0378, kl=0.1648, beta=0.0002\n",
      "Batch 80, loss=0.0540, recon=0.0540, kl=0.0813, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0453 (Recon: 0.0453, KL: 0.2489, Current Beta: 0.0002) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.2790, recon=0.2790, kl=0.0032, beta=0.0004\n",
      "Batch 40, loss=0.0266, recon=0.0266, kl=0.0027, beta=0.0004\n",
      "Batch 60, loss=0.0333, recon=0.0333, kl=0.0024, beta=0.0004\n",
      "Batch 80, loss=0.0238, recon=0.0238, kl=0.0078, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0406 (Recon: 0.0406, KL: 0.0046, Current Beta: 0.0004) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0275, recon=0.0275, kl=0.0009, beta=0.0006\n",
      "Batch 40, loss=0.0302, recon=0.0302, kl=0.0030, beta=0.0006\n",
      "Batch 60, loss=0.0587, recon=0.0587, kl=0.0032, beta=0.0006\n",
      "Batch 80, loss=0.0301, recon=0.0301, kl=0.0043, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0403 (Recon: 0.0403, KL: 0.0028, Current Beta: 0.0006) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0276, recon=0.0276, kl=0.0019, beta=0.0010\n",
      "Batch 40, loss=0.0323, recon=0.0323, kl=0.0009, beta=0.0010\n",
      "Batch 60, loss=0.0261, recon=0.0261, kl=0.0027, beta=0.0010\n",
      "Batch 80, loss=0.0353, recon=0.0353, kl=0.0009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0392, KL: 0.0022, Current Beta: 0.0010) | Avg Valid Loss: 0.0329 | Avg Valid recon Loss: 0.0329\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0301, recon=0.0301, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0275, recon=0.0275, kl=0.0008, beta=0.0010\n",
      "Batch 60, loss=0.0298, recon=0.0298, kl=0.0072, beta=0.0010\n",
      "Batch 80, loss=0.0583, recon=0.0583, kl=0.0035, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0384 (Recon: 0.0384, KL: 0.0023, Current Beta: 0.0010) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0334\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0395, recon=0.0395, kl=0.0009, beta=0.0010\n",
      "Batch 40, loss=0.0293, recon=0.0293, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0269, recon=0.0269, kl=0.0122, beta=0.0010\n",
      "Batch 80, loss=0.0341, recon=0.0340, kl=0.0049, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0387 (Recon: 0.0387, KL: 0.0054, Current Beta: 0.0010) | Avg Valid Loss: 0.0320 | Avg Valid recon Loss: 0.0320\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0232, recon=0.0232, kl=0.0011, beta=0.0010\n",
      "Batch 40, loss=0.0634, recon=0.0634, kl=0.0008, beta=0.0010\n",
      "Batch 60, loss=0.0323, recon=0.0323, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0232, recon=0.0232, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0361 (Recon: 0.0361, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0343 | Avg Valid recon Loss: 0.0343\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0529, recon=0.0529, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0870, recon=0.0869, kl=0.0861, beta=0.0010\n",
      "Batch 60, loss=0.0335, recon=0.0333, kl=0.1512, beta=0.0010\n",
      "Batch 80, loss=0.0295, recon=0.0295, kl=0.0213, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0452 (Recon: 0.0452, KL: 0.0747, Current Beta: 0.0010) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "\n",
      "[VRAE Run 169/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4099, recon=0.4099, kl=0.6724, beta=0.0000\n",
      "Batch 40, loss=0.2867, recon=0.2867, kl=12.2879, beta=0.0000\n",
      "Batch 60, loss=0.6543, recon=0.6543, kl=19.7533, beta=0.0000\n",
      "Batch 80, loss=0.4240, recon=0.4240, kl=26.2897, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4039 (Recon: 0.4039, KL: 13.3498, Current Beta: 0.0000) | Avg Valid Loss: 0.1893 | Avg Valid recon Loss: 0.1893\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2105, recon=0.2105, kl=32.0445, beta=0.0000\n",
      "Batch 40, loss=0.1421, recon=0.1421, kl=35.5998, beta=0.0000\n",
      "Batch 60, loss=0.1018, recon=0.1018, kl=40.9655, beta=0.0000\n",
      "Batch 80, loss=0.1329, recon=0.1329, kl=43.9239, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1748 (Recon: 0.1748, KL: 37.3062, Current Beta: 0.0000) | Avg Valid Loss: 0.1245 | Avg Valid recon Loss: 0.1245\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1179, recon=0.1179, kl=47.0504, beta=0.0000\n",
      "Batch 40, loss=0.1298, recon=0.1298, kl=48.2740, beta=0.0000\n",
      "Batch 60, loss=0.1163, recon=0.1163, kl=52.1057, beta=0.0000\n",
      "Batch 80, loss=0.0855, recon=0.0855, kl=51.9232, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1309 (Recon: 0.1309, KL: 49.4446, Current Beta: 0.0000) | Avg Valid Loss: 0.1016 | Avg Valid recon Loss: 0.1016\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0933, recon=0.0933, kl=52.0812, beta=0.0000\n",
      "Batch 40, loss=0.0892, recon=0.0892, kl=51.4585, beta=0.0000\n",
      "Batch 60, loss=0.0707, recon=0.0707, kl=50.7072, beta=0.0000\n",
      "Batch 80, loss=0.0832, recon=0.0832, kl=50.9634, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1073 (Recon: 0.1073, KL: 51.3040, Current Beta: 0.0000) | Avg Valid Loss: 0.0853 | Avg Valid recon Loss: 0.0853\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0747, recon=0.0747, kl=51.2366, beta=0.0000\n",
      "Batch 40, loss=0.0984, recon=0.0984, kl=50.9729, beta=0.0000\n",
      "Batch 60, loss=0.0689, recon=0.0689, kl=49.7809, beta=0.0000\n",
      "Batch 80, loss=0.0692, recon=0.0692, kl=49.8907, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0935 (Recon: 0.0935, KL: 50.5323, Current Beta: 0.0000) | Avg Valid Loss: 0.0783 | Avg Valid recon Loss: 0.0783\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0546, recon=0.0546, kl=47.6814, beta=0.0000\n",
      "Batch 40, loss=0.1793, recon=0.1793, kl=45.4448, beta=0.0000\n",
      "Batch 60, loss=0.0638, recon=0.0637, kl=44.3156, beta=0.0000\n",
      "Batch 80, loss=0.0668, recon=0.0668, kl=43.1355, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0840 (Recon: 0.0840, KL: 45.5549, Current Beta: 0.0000) | Avg Valid Loss: 0.0711 | Avg Valid recon Loss: 0.0710\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1037, recon=0.1037, kl=37.5790, beta=0.0000\n",
      "Batch 40, loss=0.0513, recon=0.0513, kl=35.0958, beta=0.0000\n",
      "Batch 60, loss=0.0898, recon=0.0898, kl=33.7061, beta=0.0000\n",
      "Batch 80, loss=0.0690, recon=0.0690, kl=32.1295, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0768 (Recon: 0.0768, KL: 35.4496, Current Beta: 0.0000) | Avg Valid Loss: 0.0657 | Avg Valid recon Loss: 0.0656\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0531, recon=0.0531, kl=25.3834, beta=0.0000\n",
      "Batch 40, loss=0.0456, recon=0.0456, kl=19.8738, beta=0.0000\n",
      "Batch 60, loss=0.0481, recon=0.0480, kl=20.8497, beta=0.0000\n",
      "Batch 80, loss=0.0567, recon=0.0567, kl=19.6945, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0718 (Recon: 0.0718, KL: 22.3642, Current Beta: 0.0000) | Avg Valid Loss: 0.0630 | Avg Valid recon Loss: 0.0629\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.6009, recon=0.6008, kl=11.7923, beta=0.0000\n",
      "Batch 40, loss=0.0511, recon=0.0511, kl=10.9751, beta=0.0000\n",
      "Batch 60, loss=0.0420, recon=0.0420, kl=11.4695, beta=0.0000\n",
      "Batch 80, loss=0.0368, recon=0.0367, kl=10.0059, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0680 (Recon: 0.0680, KL: 11.8616, Current Beta: 0.0000) | Avg Valid Loss: 0.0597 | Avg Valid recon Loss: 0.0597\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0877, recon=0.0877, kl=4.2588, beta=0.0000\n",
      "Batch 40, loss=0.0539, recon=0.0538, kl=4.7631, beta=0.0000\n",
      "Batch 60, loss=0.0432, recon=0.0432, kl=4.7983, beta=0.0000\n",
      "Batch 80, loss=0.0617, recon=0.0616, kl=3.8326, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0647 (Recon: 0.0647, KL: 4.8432, Current Beta: 0.0000) | Avg Valid Loss: 0.0575 | Avg Valid recon Loss: 0.0575\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0590, recon=0.0589, kl=1.8397, beta=0.0000\n",
      "Batch 40, loss=0.0539, recon=0.0538, kl=1.2266, beta=0.0000\n",
      "Batch 60, loss=0.0437, recon=0.0437, kl=1.1572, beta=0.0000\n",
      "Batch 80, loss=0.0633, recon=0.0632, kl=1.2826, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0624 (Recon: 0.0624, KL: 1.5217, Current Beta: 0.0000) | Avg Valid Loss: 0.0557 | Avg Valid recon Loss: 0.0557\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1487, recon=0.1487, kl=0.3205, beta=0.0001\n",
      "Batch 40, loss=0.0610, recon=0.0610, kl=0.2590, beta=0.0001\n",
      "Batch 60, loss=0.0611, recon=0.0610, kl=0.2649, beta=0.0001\n",
      "Batch 80, loss=0.0374, recon=0.0374, kl=0.2115, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0601 (Recon: 0.0601, KL: 0.3009, Current Beta: 0.0001) | Avg Valid Loss: 0.0530 | Avg Valid recon Loss: 0.0530\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0578, recon=0.0578, kl=0.0406, beta=0.0002\n",
      "Batch 40, loss=0.0370, recon=0.0370, kl=0.0186, beta=0.0002\n",
      "Batch 60, loss=0.0483, recon=0.0483, kl=0.0292, beta=0.0002\n",
      "Batch 80, loss=0.0505, recon=0.0505, kl=0.0409, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0582 (Recon: 0.0581, KL: 0.0314, Current Beta: 0.0002) | Avg Valid Loss: 0.0512 | Avg Valid recon Loss: 0.0512\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0483, recon=0.0483, kl=0.0061, beta=0.0004\n",
      "Batch 40, loss=0.0455, recon=0.0455, kl=0.0024, beta=0.0004\n",
      "Batch 60, loss=0.0367, recon=0.0367, kl=0.0028, beta=0.0004\n",
      "Batch 80, loss=0.0592, recon=0.0592, kl=0.0021, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0561 (Recon: 0.0561, KL: 0.0035, Current Beta: 0.0004) | Avg Valid Loss: 0.0497 | Avg Valid recon Loss: 0.0497\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0409, recon=0.0409, kl=0.0011, beta=0.0006\n",
      "Batch 40, loss=0.0374, recon=0.0374, kl=0.0008, beta=0.0006\n",
      "Batch 60, loss=0.0554, recon=0.0554, kl=0.0017, beta=0.0006\n",
      "Batch 80, loss=0.1495, recon=0.1495, kl=0.0008, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0547, KL: 0.0014, Current Beta: 0.0006) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0509, recon=0.0509, kl=0.0009, beta=0.0010\n",
      "Batch 40, loss=0.0411, recon=0.0411, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0476, recon=0.0476, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0526, recon=0.0526, kl=0.0010, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0532 (Recon: 0.0532, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0478\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0301, recon=0.0301, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0539, recon=0.0539, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0358, recon=0.0358, kl=0.0013, beta=0.0010\n",
      "Batch 80, loss=0.0357, recon=0.0357, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0522 (Recon: 0.0522, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0468 | Avg Valid recon Loss: 0.0468\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0408, recon=0.0408, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0358, recon=0.0358, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0276, recon=0.0276, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0407, recon=0.0407, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0501 (Recon: 0.0501, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0450\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0321, recon=0.0321, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0383, recon=0.0383, kl=0.0002, beta=0.0010\n",
      "Batch 60, loss=0.0346, recon=0.0346, kl=0.0007, beta=0.0010\n",
      "Batch 80, loss=0.0384, recon=0.0384, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0495, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0447 | Avg Valid recon Loss: 0.0447\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0365, recon=0.0365, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0292, recon=0.0292, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.1141, recon=0.1141, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0499, recon=0.0499, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0485, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0432 | Avg Valid recon Loss: 0.0432\n",
      "\n",
      "[VRAE Run 170/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1635, recon=0.1635, kl=18.5142, beta=0.0000\n",
      "Batch 40, loss=0.1055, recon=0.1055, kl=27.0003, beta=0.0000\n",
      "Batch 60, loss=0.0856, recon=0.0856, kl=32.1473, beta=0.0000\n",
      "Batch 80, loss=0.0793, recon=0.0793, kl=29.5810, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1719 (Recon: 0.1719, KL: 24.3277, Current Beta: 0.0000) | Avg Valid Loss: 0.0711 | Avg Valid recon Loss: 0.0711\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0625, recon=0.0625, kl=27.5840, beta=0.0000\n",
      "Batch 40, loss=0.0839, recon=0.0839, kl=37.6230, beta=0.0000\n",
      "Batch 60, loss=0.0572, recon=0.0572, kl=37.1973, beta=0.0000\n",
      "Batch 80, loss=0.0405, recon=0.0405, kl=35.9047, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0683 (Recon: 0.0683, KL: 34.8594, Current Beta: 0.0000) | Avg Valid Loss: 0.0589 | Avg Valid recon Loss: 0.0589\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0483, recon=0.0483, kl=35.6992, beta=0.0000\n",
      "Batch 40, loss=0.0573, recon=0.0573, kl=35.8517, beta=0.0000\n",
      "Batch 60, loss=0.1260, recon=0.1260, kl=34.7828, beta=0.0000\n",
      "Batch 80, loss=0.0427, recon=0.0427, kl=39.3235, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 35.9654, Current Beta: 0.0000) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0559\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0477, recon=0.0477, kl=31.3333, beta=0.0000\n",
      "Batch 40, loss=0.1039, recon=0.1039, kl=32.5205, beta=0.0000\n",
      "Batch 60, loss=0.0497, recon=0.0497, kl=36.0839, beta=0.0000\n",
      "Batch 80, loss=0.0325, recon=0.0325, kl=39.0914, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0518, KL: 35.2388, Current Beta: 0.0000) | Avg Valid Loss: 0.0419 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0369, recon=0.0369, kl=38.6934, beta=0.0000\n",
      "Batch 40, loss=0.0337, recon=0.0337, kl=34.0275, beta=0.0000\n",
      "Batch 60, loss=0.0229, recon=0.0229, kl=34.4117, beta=0.0000\n",
      "Batch 80, loss=0.0348, recon=0.0348, kl=35.5854, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0443 (Recon: 0.0443, KL: 36.0591, Current Beta: 0.0000) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0334, recon=0.0334, kl=31.4299, beta=0.0000\n",
      "Batch 40, loss=0.0217, recon=0.0217, kl=26.9066, beta=0.0000\n",
      "Batch 60, loss=0.0231, recon=0.0231, kl=30.9638, beta=0.0000\n",
      "Batch 80, loss=0.0545, recon=0.0545, kl=29.8420, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0415, KL: 29.9953, Current Beta: 0.0000) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0345\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0320, recon=0.0320, kl=27.5040, beta=0.0000\n",
      "Batch 40, loss=0.0314, recon=0.0314, kl=23.3185, beta=0.0000\n",
      "Batch 60, loss=0.0310, recon=0.0310, kl=26.2100, beta=0.0000\n",
      "Batch 80, loss=0.0724, recon=0.0724, kl=25.9600, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0386, KL: 26.2494, Current Beta: 0.0000) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0326\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0315, recon=0.0315, kl=14.3112, beta=0.0000\n",
      "Batch 40, loss=0.0526, recon=0.0525, kl=19.2798, beta=0.0000\n",
      "Batch 60, loss=0.0204, recon=0.0204, kl=14.9089, beta=0.0000\n",
      "Batch 80, loss=0.0220, recon=0.0219, kl=18.2492, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0370, KL: 17.9688, Current Beta: 0.0000) | Avg Valid Loss: 0.0308 | Avg Valid recon Loss: 0.0308\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0246, recon=0.0245, kl=8.5929, beta=0.0000\n",
      "Batch 40, loss=0.0263, recon=0.0263, kl=9.3603, beta=0.0000\n",
      "Batch 60, loss=0.0328, recon=0.0328, kl=7.9396, beta=0.0000\n",
      "Batch 80, loss=0.0746, recon=0.0746, kl=7.4251, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0358, KL: 9.1880, Current Beta: 0.0000) | Avg Valid Loss: 0.0329 | Avg Valid recon Loss: 0.0329\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=2.7328, beta=0.0000\n",
      "Batch 40, loss=0.0307, recon=0.0307, kl=3.1555, beta=0.0000\n",
      "Batch 60, loss=0.0240, recon=0.0240, kl=1.9821, beta=0.0000\n",
      "Batch 80, loss=0.0277, recon=0.0277, kl=3.0347, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0364 (Recon: 0.0363, KL: 3.0957, Current Beta: 0.0000) | Avg Valid Loss: 0.0325 | Avg Valid recon Loss: 0.0324\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1210, recon=0.1210, kl=0.4435, beta=0.0000\n",
      "Batch 40, loss=0.0430, recon=0.0430, kl=0.7331, beta=0.0000\n",
      "Batch 60, loss=0.0332, recon=0.0332, kl=0.7583, beta=0.0000\n",
      "Batch 80, loss=0.0233, recon=0.0233, kl=0.5753, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0510 (Recon: 0.0509, KL: 0.8233, Current Beta: 0.0000) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0218, recon=0.0218, kl=0.0947, beta=0.0001\n",
      "Batch 40, loss=0.0494, recon=0.0494, kl=0.0200, beta=0.0001\n",
      "Batch 60, loss=0.2646, recon=0.2645, kl=0.0345, beta=0.0001\n",
      "Batch 80, loss=0.0450, recon=0.0450, kl=0.1206, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0403 (Recon: 0.0403, KL: 0.1273, Current Beta: 0.0001) | Avg Valid Loss: 0.0343 | Avg Valid recon Loss: 0.0343\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0336, recon=0.0336, kl=0.0191, beta=0.0002\n",
      "Batch 40, loss=0.0304, recon=0.0304, kl=0.2190, beta=0.0002\n",
      "Batch 60, loss=0.0289, recon=0.0288, kl=0.0613, beta=0.0002\n",
      "Batch 80, loss=0.0290, recon=0.0290, kl=0.0143, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0415, KL: 0.0872, Current Beta: 0.0002) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0307\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0674, recon=0.0674, kl=0.0014, beta=0.0004\n",
      "Batch 40, loss=0.0234, recon=0.0234, kl=0.0039, beta=0.0004\n",
      "Batch 60, loss=0.0268, recon=0.0268, kl=0.0013, beta=0.0004\n",
      "Batch 80, loss=0.0864, recon=0.0864, kl=0.0036, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0369 (Recon: 0.0369, KL: 0.0027, Current Beta: 0.0004) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0310, recon=0.0310, kl=0.0023, beta=0.0006\n",
      "Batch 40, loss=0.0568, recon=0.0568, kl=0.0054, beta=0.0006\n",
      "Batch 60, loss=0.0433, recon=0.0433, kl=0.0068, beta=0.0006\n",
      "Batch 80, loss=0.0530, recon=0.0530, kl=0.0145, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 0.0055, Current Beta: 0.0006) | Avg Valid Loss: 0.0378 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0188, recon=0.0188, kl=0.0013, beta=0.0010\n",
      "Batch 40, loss=0.0280, recon=0.0280, kl=0.0013, beta=0.0010\n",
      "Batch 60, loss=0.0260, recon=0.0260, kl=0.0012, beta=0.0010\n",
      "Batch 80, loss=0.0278, recon=0.0278, kl=0.0023, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0396 (Recon: 0.0396, KL: 0.0015, Current Beta: 0.0010) | Avg Valid Loss: 0.0428 | Avg Valid recon Loss: 0.0428\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0287, recon=0.0287, kl=0.0015, beta=0.0010\n",
      "Batch 40, loss=0.0283, recon=0.0283, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0323, recon=0.0323, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0260, recon=0.0260, kl=0.0025, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0395, KL: 0.0014, Current Beta: 0.0010) | Avg Valid Loss: 0.0315 | Avg Valid recon Loss: 0.0315\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=0.0019, beta=0.0010\n",
      "Batch 40, loss=0.0314, recon=0.0314, kl=0.0024, beta=0.0010\n",
      "Batch 60, loss=0.0248, recon=0.0248, kl=0.0012, beta=0.0010\n",
      "Batch 80, loss=0.0249, recon=0.0249, kl=0.0012, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0343 (Recon: 0.0343, KL: 0.0032, Current Beta: 0.0010) | Avg Valid Loss: 0.0278 | Avg Valid recon Loss: 0.0278\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0344, recon=0.0344, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0254, recon=0.0254, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0411, recon=0.0411, kl=0.0010, beta=0.0010\n",
      "Batch 80, loss=0.0359, recon=0.0358, kl=0.0016, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0309 (Recon: 0.0309, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0279 | Avg Valid recon Loss: 0.0279\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0264, recon=0.0264, kl=0.0043, beta=0.0010\n",
      "Batch 40, loss=0.0304, recon=0.0304, kl=0.0011, beta=0.0010\n",
      "Batch 60, loss=0.0267, recon=0.0267, kl=0.0011, beta=0.0010\n",
      "Batch 80, loss=0.0333, recon=0.0333, kl=0.0022, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0334 (Recon: 0.0334, KL: 0.0027, Current Beta: 0.0010) | Avg Valid Loss: 0.0309 | Avg Valid recon Loss: 0.0309\n",
      "\n",
      "[VRAE Run 171/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4116, recon=0.4116, kl=1.7888, beta=0.0000\n",
      "Batch 40, loss=0.2842, recon=0.2842, kl=23.1295, beta=0.0000\n",
      "Batch 60, loss=0.2636, recon=0.2636, kl=42.1481, beta=0.0000\n",
      "Batch 80, loss=0.1487, recon=0.1487, kl=53.1001, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3936 (Recon: 0.3936, KL: 27.2369, Current Beta: 0.0000) | Avg Valid Loss: 0.1884 | Avg Valid recon Loss: 0.1884\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1432, recon=0.1432, kl=63.8614, beta=0.0000\n",
      "Batch 40, loss=0.2806, recon=0.2806, kl=70.1036, beta=0.0000\n",
      "Batch 60, loss=0.1403, recon=0.1403, kl=74.4315, beta=0.0000\n",
      "Batch 80, loss=0.2095, recon=0.2095, kl=77.1240, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1740 (Recon: 0.1740, KL: 70.0225, Current Beta: 0.0000) | Avg Valid Loss: 0.1233 | Avg Valid recon Loss: 0.1233\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1103, recon=0.1103, kl=79.2271, beta=0.0000\n",
      "Batch 40, loss=0.1448, recon=0.1448, kl=79.7132, beta=0.0000\n",
      "Batch 60, loss=0.1703, recon=0.1703, kl=81.8588, beta=0.0000\n",
      "Batch 80, loss=0.1003, recon=0.1003, kl=83.8494, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1300 (Recon: 0.1300, KL: 80.9076, Current Beta: 0.0000) | Avg Valid Loss: 0.0981 | Avg Valid recon Loss: 0.0981\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0667, recon=0.0667, kl=84.3130, beta=0.0000\n",
      "Batch 40, loss=0.0755, recon=0.0755, kl=85.5958, beta=0.0000\n",
      "Batch 60, loss=0.1228, recon=0.1228, kl=86.6333, beta=0.0000\n",
      "Batch 80, loss=0.0679, recon=0.0679, kl=86.6779, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0983 (Recon: 0.0983, KL: 85.3962, Current Beta: 0.0000) | Avg Valid Loss: 0.0867 | Avg Valid recon Loss: 0.0867\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0804, recon=0.0804, kl=87.5255, beta=0.0000\n",
      "Batch 40, loss=0.0758, recon=0.0757, kl=86.4185, beta=0.0000\n",
      "Batch 60, loss=0.0584, recon=0.0584, kl=85.6775, beta=0.0000\n",
      "Batch 80, loss=0.0567, recon=0.0567, kl=86.5691, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0936 (Recon: 0.0936, KL: 86.5582, Current Beta: 0.0000) | Avg Valid Loss: 0.0784 | Avg Valid recon Loss: 0.0784\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0693, recon=0.0693, kl=82.3036, beta=0.0000\n",
      "Batch 40, loss=0.0835, recon=0.0835, kl=78.4244, beta=0.0000\n",
      "Batch 60, loss=0.0679, recon=0.0679, kl=74.0103, beta=0.0000\n",
      "Batch 80, loss=0.0679, recon=0.0678, kl=72.5532, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0836 (Recon: 0.0836, KL: 77.8087, Current Beta: 0.0000) | Avg Valid Loss: 0.0721 | Avg Valid recon Loss: 0.0720\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0653, recon=0.0653, kl=64.8888, beta=0.0000\n",
      "Batch 40, loss=0.0854, recon=0.0854, kl=55.6119, beta=0.0000\n",
      "Batch 60, loss=0.0675, recon=0.0675, kl=53.4877, beta=0.0000\n",
      "Batch 80, loss=0.0944, recon=0.0944, kl=52.2873, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0766 (Recon: 0.0766, KL: 57.7446, Current Beta: 0.0000) | Avg Valid Loss: 0.0673 | Avg Valid recon Loss: 0.0673\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0578, recon=0.0578, kl=35.5923, beta=0.0000\n",
      "Batch 40, loss=0.0767, recon=0.0767, kl=32.5616, beta=0.0000\n",
      "Batch 60, loss=0.0708, recon=0.0707, kl=30.9473, beta=0.0000\n",
      "Batch 80, loss=0.1926, recon=0.1926, kl=29.4569, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0718 (Recon: 0.0718, KL: 33.9866, Current Beta: 0.0000) | Avg Valid Loss: 0.0645 | Avg Valid recon Loss: 0.0645\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0772, recon=0.0772, kl=14.6228, beta=0.0000\n",
      "Batch 40, loss=0.0361, recon=0.0360, kl=14.2584, beta=0.0000\n",
      "Batch 60, loss=0.0694, recon=0.0693, kl=14.2562, beta=0.0000\n",
      "Batch 80, loss=0.0767, recon=0.0767, kl=12.8382, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0681 (Recon: 0.0681, KL: 15.4147, Current Beta: 0.0000) | Avg Valid Loss: 0.0600 | Avg Valid recon Loss: 0.0600\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0557, recon=0.0556, kl=5.7157, beta=0.0000\n",
      "Batch 40, loss=0.0527, recon=0.0527, kl=6.2983, beta=0.0000\n",
      "Batch 60, loss=0.0698, recon=0.0697, kl=5.2617, beta=0.0000\n",
      "Batch 80, loss=0.0497, recon=0.0496, kl=4.3970, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0651 (Recon: 0.0650, KL: 5.9516, Current Beta: 0.0000) | Avg Valid Loss: 0.0572 | Avg Valid recon Loss: 0.0572\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0474, recon=0.0474, kl=1.6381, beta=0.0000\n",
      "Batch 40, loss=0.0406, recon=0.0406, kl=2.1401, beta=0.0000\n",
      "Batch 60, loss=0.0504, recon=0.0504, kl=1.7249, beta=0.0000\n",
      "Batch 80, loss=0.0354, recon=0.0353, kl=1.4785, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0623 (Recon: 0.0622, KL: 1.9177, Current Beta: 0.0000) | Avg Valid Loss: 0.0555 | Avg Valid recon Loss: 0.0555\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0640, recon=0.0639, kl=0.9486, beta=0.0001\n",
      "Batch 40, loss=0.0413, recon=0.0412, kl=0.4526, beta=0.0001\n",
      "Batch 60, loss=0.0537, recon=0.0537, kl=0.3461, beta=0.0001\n",
      "Batch 80, loss=0.0435, recon=0.0435, kl=0.4089, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0543 (Recon: 0.0542, KL: 0.5465, Current Beta: 0.0001) | Avg Valid Loss: 0.0539 | Avg Valid recon Loss: 0.0538\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0479, recon=0.0479, kl=0.0882, beta=0.0002\n",
      "Batch 40, loss=0.0344, recon=0.0344, kl=0.0424, beta=0.0002\n",
      "Batch 60, loss=0.0429, recon=0.0429, kl=0.0346, beta=0.0002\n",
      "Batch 80, loss=0.0758, recon=0.0758, kl=0.0375, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0583 (Recon: 0.0583, KL: 0.0620, Current Beta: 0.0002) | Avg Valid Loss: 0.0520 | Avg Valid recon Loss: 0.0520\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1310, recon=0.1310, kl=0.0154, beta=0.0004\n",
      "Batch 40, loss=0.0370, recon=0.0370, kl=0.0059, beta=0.0004\n",
      "Batch 60, loss=0.0467, recon=0.0467, kl=0.0067, beta=0.0004\n",
      "Batch 80, loss=0.0579, recon=0.0579, kl=0.0056, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0567 (Recon: 0.0567, KL: 0.0086, Current Beta: 0.0004) | Avg Valid Loss: 0.0505 | Avg Valid recon Loss: 0.0505\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.5099, recon=0.5099, kl=0.0028, beta=0.0006\n",
      "Batch 40, loss=0.0563, recon=0.0563, kl=0.0065, beta=0.0006\n",
      "Batch 60, loss=0.0424, recon=0.0424, kl=0.0038, beta=0.0006\n",
      "Batch 80, loss=0.0342, recon=0.0342, kl=0.0016, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0548 (Recon: 0.0548, KL: 0.0027, Current Beta: 0.0006) | Avg Valid Loss: 0.0505 | Avg Valid recon Loss: 0.0505\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0356, recon=0.0356, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0297, recon=0.0297, kl=0.0010, beta=0.0010\n",
      "Batch 60, loss=0.0431, recon=0.0431, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0715, recon=0.0715, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0537 (Recon: 0.0537, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0480\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0613, recon=0.0613, kl=0.0009, beta=0.0010\n",
      "Batch 40, loss=0.0375, recon=0.0375, kl=0.0007, beta=0.0010\n",
      "Batch 60, loss=0.0411, recon=0.0411, kl=0.0008, beta=0.0010\n",
      "Batch 80, loss=0.0561, recon=0.0561, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0525 (Recon: 0.0525, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0470 | Avg Valid recon Loss: 0.0470\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=0.0009, beta=0.0010\n",
      "Batch 40, loss=0.0360, recon=0.0360, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.4605, recon=0.4605, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0385, recon=0.0385, kl=0.0014, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0514 (Recon: 0.0514, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0461 | Avg Valid recon Loss: 0.0461\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0362, recon=0.0362, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0840, recon=0.0840, kl=0.0009, beta=0.0010\n",
      "Batch 60, loss=0.0489, recon=0.0489, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0314, recon=0.0314, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0500 (Recon: 0.0500, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0449\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0318, recon=0.0318, kl=0.0010, beta=0.0010\n",
      "Batch 40, loss=0.0380, recon=0.0380, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0344, recon=0.0344, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0420, recon=0.0420, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0493 (Recon: 0.0493, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "\n",
      "[VRAE Run 172/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2308, recon=0.2308, kl=48.9256, beta=0.0000\n",
      "Batch 40, loss=0.1257, recon=0.1257, kl=62.3103, beta=0.0000\n",
      "Batch 60, loss=0.0988, recon=0.0988, kl=69.0075, beta=0.0000\n",
      "Batch 80, loss=0.0864, recon=0.0864, kl=66.4671, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1772 (Recon: 0.1772, KL: 55.6365, Current Beta: 0.0000) | Avg Valid Loss: 0.0794 | Avg Valid recon Loss: 0.0794\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0684, recon=0.0684, kl=68.6600, beta=0.0000\n",
      "Batch 40, loss=0.0698, recon=0.0698, kl=70.0927, beta=0.0000\n",
      "Batch 60, loss=0.0419, recon=0.0419, kl=66.9745, beta=0.0000\n",
      "Batch 80, loss=0.0435, recon=0.0435, kl=69.5187, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0735 (Recon: 0.0735, KL: 67.7252, Current Beta: 0.0000) | Avg Valid Loss: 0.0549 | Avg Valid recon Loss: 0.0549\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0511, recon=0.0511, kl=68.1522, beta=0.0000\n",
      "Batch 40, loss=0.0418, recon=0.0418, kl=62.9192, beta=0.0000\n",
      "Batch 60, loss=0.0930, recon=0.0930, kl=68.2453, beta=0.0000\n",
      "Batch 80, loss=0.0342, recon=0.0342, kl=68.1582, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0580 (Recon: 0.0580, KL: 67.5735, Current Beta: 0.0000) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0456\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0352, recon=0.0352, kl=49.5667, beta=0.0000\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=65.9861, beta=0.0000\n",
      "Batch 60, loss=0.0276, recon=0.0276, kl=67.1517, beta=0.0000\n",
      "Batch 80, loss=0.0447, recon=0.0447, kl=59.2695, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0505 (Recon: 0.0505, KL: 60.0644, Current Beta: 0.0000) | Avg Valid Loss: 0.0419 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0406, recon=0.0406, kl=65.9587, beta=0.0000\n",
      "Batch 40, loss=0.0787, recon=0.0787, kl=66.0639, beta=0.0000\n",
      "Batch 60, loss=0.0375, recon=0.0375, kl=68.1042, beta=0.0000\n",
      "Batch 80, loss=0.3732, recon=0.3732, kl=61.0195, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0445 (Recon: 0.0444, KL: 65.4731, Current Beta: 0.0000) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0929, recon=0.0928, kl=54.6066, beta=0.0000\n",
      "Batch 40, loss=0.0337, recon=0.0337, kl=53.3512, beta=0.0000\n",
      "Batch 60, loss=0.0344, recon=0.0344, kl=55.6447, beta=0.0000\n",
      "Batch 80, loss=0.0438, recon=0.0438, kl=48.1144, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0432, KL: 53.7121, Current Beta: 0.0000) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0373, recon=0.0373, kl=46.7386, beta=0.0000\n",
      "Batch 40, loss=0.0225, recon=0.0225, kl=40.5907, beta=0.0000\n",
      "Batch 60, loss=0.0552, recon=0.0552, kl=51.0197, beta=0.0000\n",
      "Batch 80, loss=0.0392, recon=0.0392, kl=47.5302, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0435 (Recon: 0.0435, KL: 47.5148, Current Beta: 0.0000) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0484, recon=0.0484, kl=29.4829, beta=0.0000\n",
      "Batch 40, loss=0.0355, recon=0.0354, kl=42.5987, beta=0.0000\n",
      "Batch 60, loss=0.0326, recon=0.0326, kl=31.8374, beta=0.0000\n",
      "Batch 80, loss=0.0234, recon=0.0234, kl=33.7733, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0466, KL: 35.7993, Current Beta: 0.0000) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0412, recon=0.0411, kl=22.5223, beta=0.0000\n",
      "Batch 40, loss=0.0260, recon=0.0259, kl=21.5635, beta=0.0000\n",
      "Batch 60, loss=0.0249, recon=0.0248, kl=27.6589, beta=0.0000\n",
      "Batch 80, loss=0.0420, recon=0.0419, kl=20.6553, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0390, KL: 23.5690, Current Beta: 0.0000) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0272, recon=0.0271, kl=11.4876, beta=0.0000\n",
      "Batch 40, loss=0.0802, recon=0.0800, kl=17.2208, beta=0.0000\n",
      "Batch 60, loss=0.0411, recon=0.0410, kl=9.2528, beta=0.0000\n",
      "Batch 80, loss=0.0393, recon=0.0392, kl=9.8168, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0404 (Recon: 0.0403, KL: 11.9272, Current Beta: 0.0000) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0413, recon=0.0412, kl=2.1669, beta=0.0000\n",
      "Batch 40, loss=0.0329, recon=0.0328, kl=1.9684, beta=0.0000\n",
      "Batch 60, loss=0.0380, recon=0.0379, kl=1.8955, beta=0.0000\n",
      "Batch 80, loss=0.0836, recon=0.0836, kl=2.7497, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0436 (Recon: 0.0435, KL: 2.6445, Current Beta: 0.0000) | Avg Valid Loss: 0.0592 | Avg Valid recon Loss: 0.0591\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0335, recon=0.0334, kl=0.8014, beta=0.0001\n",
      "Batch 40, loss=0.0414, recon=0.0414, kl=0.2786, beta=0.0001\n",
      "Batch 60, loss=0.1642, recon=0.1642, kl=0.2447, beta=0.0001\n",
      "Batch 80, loss=0.0351, recon=0.0351, kl=0.7478, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0494, KL: 0.6884, Current Beta: 0.0001) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0230, recon=0.0230, kl=0.1126, beta=0.0002\n",
      "Batch 40, loss=0.0326, recon=0.0326, kl=0.0612, beta=0.0002\n",
      "Batch 60, loss=0.1253, recon=0.1253, kl=0.1453, beta=0.0002\n",
      "Batch 80, loss=0.0379, recon=0.0379, kl=0.2406, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0384 (Recon: 0.0384, KL: 0.2030, Current Beta: 0.0002) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0462, recon=0.0462, kl=0.0034, beta=0.0004\n",
      "Batch 40, loss=0.0263, recon=0.0262, kl=0.0110, beta=0.0004\n",
      "Batch 60, loss=0.0210, recon=0.0210, kl=0.0063, beta=0.0004\n",
      "Batch 80, loss=0.0210, recon=0.0210, kl=0.0110, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0355 (Recon: 0.0355, KL: 0.0196, Current Beta: 0.0004) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0551, recon=0.0551, kl=0.0038, beta=0.0006\n",
      "Batch 40, loss=0.0327, recon=0.0327, kl=0.0093, beta=0.0006\n",
      "Batch 60, loss=0.0456, recon=0.0456, kl=0.0039, beta=0.0006\n",
      "Batch 80, loss=0.0339, recon=0.0339, kl=0.0020, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0375 (Recon: 0.0375, KL: 0.0061, Current Beta: 0.0006) | Avg Valid Loss: 0.0314 | Avg Valid recon Loss: 0.0314\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0343, recon=0.0343, kl=0.0013, beta=0.0010\n",
      "Batch 40, loss=0.0200, recon=0.0200, kl=0.0009, beta=0.0010\n",
      "Batch 60, loss=0.0236, recon=0.0236, kl=0.0037, beta=0.0010\n",
      "Batch 80, loss=0.0183, recon=0.0183, kl=0.0017, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0321 (Recon: 0.0321, KL: 0.0025, Current Beta: 0.0010) | Avg Valid Loss: 0.0291 | Avg Valid recon Loss: 0.0291\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0236, recon=0.0236, kl=0.0028, beta=0.0010\n",
      "Batch 40, loss=0.0374, recon=0.0374, kl=0.0034, beta=0.0010\n",
      "Batch 60, loss=0.0286, recon=0.0286, kl=0.0052, beta=0.0010\n",
      "Batch 80, loss=0.0266, recon=0.0266, kl=0.0026, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0358, KL: 0.0034, Current Beta: 0.0010) | Avg Valid Loss: 0.0337 | Avg Valid recon Loss: 0.0337\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0746, recon=0.0746, kl=0.0032, beta=0.0010\n",
      "Batch 40, loss=0.0289, recon=0.0289, kl=0.0045, beta=0.0010\n",
      "Batch 60, loss=0.0664, recon=0.0664, kl=0.0022, beta=0.0010\n",
      "Batch 80, loss=0.0601, recon=0.0601, kl=0.0031, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0354, KL: 0.0031, Current Beta: 0.0010) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0616, recon=0.0616, kl=0.0037, beta=0.0010\n",
      "Batch 40, loss=0.0308, recon=0.0308, kl=0.0096, beta=0.0010\n",
      "Batch 60, loss=0.0275, recon=0.0275, kl=0.0028, beta=0.0010\n",
      "Batch 80, loss=0.0388, recon=0.0388, kl=0.0031, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0406 (Recon: 0.0406, KL: 0.0044, Current Beta: 0.0010) | Avg Valid Loss: 0.0298 | Avg Valid recon Loss: 0.0298\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0253, recon=0.0253, kl=0.0021, beta=0.0010\n",
      "Batch 40, loss=0.0249, recon=0.0249, kl=0.0068, beta=0.0010\n",
      "Batch 60, loss=0.0304, recon=0.0304, kl=0.0039, beta=0.0010\n",
      "Batch 80, loss=0.0397, recon=0.0397, kl=0.0026, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0354, KL: 0.0029, Current Beta: 0.0010) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0318\n",
      "\n",
      "[VRAE Run 173/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4786, recon=0.4786, kl=1.2436, beta=0.0000\n",
      "Batch 40, loss=0.2890, recon=0.2890, kl=34.3737, beta=0.0000\n",
      "Batch 60, loss=0.2990, recon=0.2990, kl=68.3536, beta=0.0000\n",
      "Batch 80, loss=0.1852, recon=0.1852, kl=87.5783, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3890 (Recon: 0.3890, KL: 43.1007, Current Beta: 0.0000) | Avg Valid Loss: 0.1863 | Avg Valid recon Loss: 0.1863\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1768, recon=0.1768, kl=106.8372, beta=0.0000\n",
      "Batch 40, loss=0.1708, recon=0.1708, kl=114.7883, beta=0.0000\n",
      "Batch 60, loss=0.1514, recon=0.1514, kl=123.3713, beta=0.0000\n",
      "Batch 80, loss=0.1612, recon=0.1612, kl=128.7313, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1693 (Recon: 0.1693, KL: 116.3998, Current Beta: 0.0000) | Avg Valid Loss: 0.1175 | Avg Valid recon Loss: 0.1175\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1147, recon=0.1147, kl=132.8956, beta=0.0000\n",
      "Batch 40, loss=0.0864, recon=0.0864, kl=136.4341, beta=0.0000\n",
      "Batch 60, loss=0.1045, recon=0.1045, kl=141.8706, beta=0.0000\n",
      "Batch 80, loss=0.3400, recon=0.3400, kl=145.6357, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1266 (Recon: 0.1266, KL: 138.7186, Current Beta: 0.0000) | Avg Valid Loss: 0.0963 | Avg Valid recon Loss: 0.0963\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1093, recon=0.1093, kl=150.8854, beta=0.0000\n",
      "Batch 40, loss=0.0793, recon=0.0793, kl=153.3207, beta=0.0000\n",
      "Batch 60, loss=0.0891, recon=0.0891, kl=155.8441, beta=0.0000\n",
      "Batch 80, loss=0.0793, recon=0.0793, kl=160.8313, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1031 (Recon: 0.1031, KL: 154.4809, Current Beta: 0.0000) | Avg Valid Loss: 0.0847 | Avg Valid recon Loss: 0.0847\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1000, recon=0.1000, kl=163.1730, beta=0.0000\n",
      "Batch 40, loss=0.0827, recon=0.0827, kl=161.5841, beta=0.0000\n",
      "Batch 60, loss=0.0585, recon=0.0584, kl=163.5045, beta=0.0000\n",
      "Batch 80, loss=0.0668, recon=0.0668, kl=159.6080, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0908 (Recon: 0.0908, KL: 162.0935, Current Beta: 0.0000) | Avg Valid Loss: 0.0758 | Avg Valid recon Loss: 0.0758\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0723, recon=0.0723, kl=151.7262, beta=0.0000\n",
      "Batch 40, loss=0.0767, recon=0.0767, kl=139.9327, beta=0.0000\n",
      "Batch 60, loss=0.0623, recon=0.0623, kl=129.8542, beta=0.0000\n",
      "Batch 80, loss=0.0678, recon=0.0678, kl=121.6080, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0812 (Recon: 0.0812, KL: 137.8475, Current Beta: 0.0000) | Avg Valid Loss: 0.0697 | Avg Valid recon Loss: 0.0697\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0445, recon=0.0444, kl=99.1018, beta=0.0000\n",
      "Batch 40, loss=0.0540, recon=0.0540, kl=83.1350, beta=0.0000\n",
      "Batch 60, loss=0.0480, recon=0.0479, kl=76.9118, beta=0.0000\n",
      "Batch 80, loss=0.0528, recon=0.0528, kl=74.3028, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0747 (Recon: 0.0747, KL: 86.2905, Current Beta: 0.0000) | Avg Valid Loss: 0.0654 | Avg Valid recon Loss: 0.0653\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1228, recon=0.1227, kl=44.3379, beta=0.0000\n",
      "Batch 40, loss=0.0372, recon=0.0372, kl=40.6911, beta=0.0000\n",
      "Batch 60, loss=0.0422, recon=0.0422, kl=37.7486, beta=0.0000\n",
      "Batch 80, loss=0.0912, recon=0.0911, kl=35.5782, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0705 (Recon: 0.0704, KL: 42.9912, Current Beta: 0.0000) | Avg Valid Loss: 0.0615 | Avg Valid recon Loss: 0.0614\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0452, recon=0.0451, kl=18.0649, beta=0.0000\n",
      "Batch 40, loss=0.0440, recon=0.0439, kl=16.8338, beta=0.0000\n",
      "Batch 60, loss=0.0610, recon=0.0609, kl=15.7383, beta=0.0000\n",
      "Batch 80, loss=0.0547, recon=0.0547, kl=16.4989, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0667 (Recon: 0.0666, KL: 17.7611, Current Beta: 0.0000) | Avg Valid Loss: 0.0582 | Avg Valid recon Loss: 0.0582\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0455, recon=0.0454, kl=8.3033, beta=0.0000\n",
      "Batch 40, loss=0.0906, recon=0.0905, kl=5.8645, beta=0.0000\n",
      "Batch 60, loss=0.0418, recon=0.0417, kl=5.9674, beta=0.0000\n",
      "Batch 80, loss=0.0436, recon=0.0436, kl=5.0591, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0635 (Recon: 0.0635, KL: 6.5604, Current Beta: 0.0000) | Avg Valid Loss: 0.0563 | Avg Valid recon Loss: 0.0562\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0575, recon=0.0575, kl=2.9024, beta=0.0000\n",
      "Batch 40, loss=0.0626, recon=0.0626, kl=2.3999, beta=0.0000\n",
      "Batch 60, loss=0.0394, recon=0.0394, kl=2.1431, beta=0.0000\n",
      "Batch 80, loss=0.0476, recon=0.0475, kl=1.8643, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0610 (Recon: 0.0609, KL: 2.4860, Current Beta: 0.0000) | Avg Valid Loss: 0.0545 | Avg Valid recon Loss: 0.0544\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0433, recon=0.0432, kl=1.4419, beta=0.0001\n",
      "Batch 40, loss=0.0672, recon=0.0671, kl=0.6533, beta=0.0001\n",
      "Batch 60, loss=0.0371, recon=0.0371, kl=0.7000, beta=0.0001\n",
      "Batch 80, loss=0.0524, recon=0.0523, kl=0.7286, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0588 (Recon: 0.0587, KL: 0.8458, Current Beta: 0.0001) | Avg Valid Loss: 0.0521 | Avg Valid recon Loss: 0.0521\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0777, recon=0.0777, kl=0.1182, beta=0.0002\n",
      "Batch 40, loss=0.0372, recon=0.0372, kl=0.1470, beta=0.0002\n",
      "Batch 60, loss=0.0427, recon=0.0427, kl=0.0856, beta=0.0002\n",
      "Batch 80, loss=0.0510, recon=0.0510, kl=0.1026, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0572 (Recon: 0.0572, KL: 0.1487, Current Beta: 0.0002) | Avg Valid Loss: 0.0511 | Avg Valid recon Loss: 0.0511\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0482, recon=0.0482, kl=0.0164, beta=0.0004\n",
      "Batch 40, loss=0.0347, recon=0.0347, kl=0.0092, beta=0.0004\n",
      "Batch 60, loss=0.0419, recon=0.0419, kl=0.0089, beta=0.0004\n",
      "Batch 80, loss=0.0614, recon=0.0614, kl=0.0054, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0553 (Recon: 0.0553, KL: 0.0154, Current Beta: 0.0004) | Avg Valid Loss: 0.0491 | Avg Valid recon Loss: 0.0491\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0336, recon=0.0336, kl=0.0039, beta=0.0006\n",
      "Batch 40, loss=0.1498, recon=0.1498, kl=0.0020, beta=0.0006\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=0.0015, beta=0.0006\n",
      "Batch 80, loss=0.0373, recon=0.0372, kl=0.0024, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0541 (Recon: 0.0541, KL: 0.0029, Current Beta: 0.0006) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0859, recon=0.0859, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=0.0008, beta=0.0010\n",
      "Batch 60, loss=0.0291, recon=0.0291, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0310, recon=0.0310, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0524, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0463 | Avg Valid recon Loss: 0.0463\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0531, recon=0.0531, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0350, recon=0.0350, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0322, recon=0.0322, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0307, recon=0.0307, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0516, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0457 | Avg Valid recon Loss: 0.0457\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0366, recon=0.0366, kl=0.0002, beta=0.0010\n",
      "Batch 40, loss=0.0530, recon=0.0530, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0259, recon=0.0259, kl=0.0003, beta=0.0010\n",
      "Batch 80, loss=0.0310, recon=0.0310, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0501 (Recon: 0.0501, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0406, recon=0.0406, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0334, recon=0.0334, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0371, recon=0.0371, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0936, recon=0.0936, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0496, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0387, recon=0.0387, kl=0.0001, beta=0.0010\n",
      "Batch 40, loss=0.0399, recon=0.0399, kl=0.0005, beta=0.0010\n",
      "Batch 60, loss=0.0301, recon=0.0301, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.1106, recon=0.1106, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0486 (Recon: 0.0486, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0431\n",
      "\n",
      "[VRAE Run 174/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1542, recon=0.1542, kl=89.4255, beta=0.0000\n",
      "Batch 40, loss=0.0875, recon=0.0875, kl=99.6848, beta=0.0000\n",
      "Batch 60, loss=0.1107, recon=0.1107, kl=108.6288, beta=0.0000\n",
      "Batch 80, loss=0.1158, recon=0.1158, kl=124.6693, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1721 (Recon: 0.1721, KL: 95.1054, Current Beta: 0.0000) | Avg Valid Loss: 0.0798 | Avg Valid recon Loss: 0.0798\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0658, recon=0.0658, kl=127.1629, beta=0.0000\n",
      "Batch 40, loss=0.0525, recon=0.0525, kl=101.8496, beta=0.0000\n",
      "Batch 60, loss=0.0516, recon=0.0516, kl=124.6095, beta=0.0000\n",
      "Batch 80, loss=0.0627, recon=0.0627, kl=137.7148, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0732 (Recon: 0.0732, KL: 123.1052, Current Beta: 0.0000) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0559\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0505, recon=0.0505, kl=142.1980, beta=0.0000\n",
      "Batch 40, loss=0.0559, recon=0.0559, kl=130.9185, beta=0.0000\n",
      "Batch 60, loss=0.0568, recon=0.0568, kl=128.0215, beta=0.0000\n",
      "Batch 80, loss=0.0325, recon=0.0325, kl=136.4052, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0573 (Recon: 0.0573, KL: 135.6217, Current Beta: 0.0000) | Avg Valid Loss: 0.0532 | Avg Valid recon Loss: 0.0532\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0441, recon=0.0441, kl=130.8919, beta=0.0000\n",
      "Batch 40, loss=0.0388, recon=0.0388, kl=134.7089, beta=0.0000\n",
      "Batch 60, loss=0.0413, recon=0.0413, kl=140.6838, beta=0.0000\n",
      "Batch 80, loss=0.0585, recon=0.0585, kl=134.4793, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0523, KL: 136.3857, Current Beta: 0.0000) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0851, recon=0.0851, kl=113.3955, beta=0.0000\n",
      "Batch 40, loss=0.0354, recon=0.0354, kl=122.9628, beta=0.0000\n",
      "Batch 60, loss=0.0415, recon=0.0415, kl=135.0094, beta=0.0000\n",
      "Batch 80, loss=0.0709, recon=0.0709, kl=123.4668, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 123.2890, Current Beta: 0.0000) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0455, recon=0.0455, kl=114.4845, beta=0.0000\n",
      "Batch 40, loss=0.0286, recon=0.0285, kl=106.7218, beta=0.0000\n",
      "Batch 60, loss=0.0247, recon=0.0247, kl=120.8519, beta=0.0000\n",
      "Batch 80, loss=0.0338, recon=0.0338, kl=105.2545, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 112.3890, Current Beta: 0.0000) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0321, recon=0.0321, kl=86.0932, beta=0.0000\n",
      "Batch 40, loss=0.0934, recon=0.0933, kl=78.8360, beta=0.0000\n",
      "Batch 60, loss=0.0293, recon=0.0292, kl=102.7227, beta=0.0000\n",
      "Batch 80, loss=0.0272, recon=0.0272, kl=91.5793, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0402 (Recon: 0.0401, KL: 93.0406, Current Beta: 0.0000) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0239, recon=0.0238, kl=65.0383, beta=0.0000\n",
      "Batch 40, loss=0.0287, recon=0.0286, kl=71.8342, beta=0.0000\n",
      "Batch 60, loss=0.0726, recon=0.0726, kl=61.1050, beta=0.0000\n",
      "Batch 80, loss=0.0264, recon=0.0262, kl=72.1631, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0380, KL: 69.7438, Current Beta: 0.0000) | Avg Valid Loss: 0.0359 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0346, recon=0.0344, kl=39.6304, beta=0.0000\n",
      "Batch 40, loss=0.0304, recon=0.0302, kl=38.4647, beta=0.0000\n",
      "Batch 60, loss=0.0270, recon=0.0268, kl=41.2731, beta=0.0000\n",
      "Batch 80, loss=0.0444, recon=0.0443, kl=38.7915, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0390, KL: 41.3234, Current Beta: 0.0000) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0379, recon=0.0375, kl=32.0816, beta=0.0000\n",
      "Batch 40, loss=0.0245, recon=0.0242, kl=29.9345, beta=0.0000\n",
      "Batch 60, loss=0.0301, recon=0.0298, kl=20.8408, beta=0.0000\n",
      "Batch 80, loss=0.0248, recon=0.0245, kl=23.7876, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0383 (Recon: 0.0380, KL: 26.2651, Current Beta: 0.0000) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0340\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0338, recon=0.0334, kl=12.7355, beta=0.0000\n",
      "Batch 40, loss=0.0271, recon=0.0269, kl=6.6535, beta=0.0000\n",
      "Batch 60, loss=0.0292, recon=0.0290, kl=5.9915, beta=0.0000\n",
      "Batch 80, loss=0.0518, recon=0.0517, kl=3.9734, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0366 (Recon: 0.0364, KL: 7.7721, Current Beta: 0.0000) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0219, recon=0.0218, kl=1.4806, beta=0.0001\n",
      "Batch 40, loss=0.0285, recon=0.0285, kl=1.0913, beta=0.0001\n",
      "Batch 60, loss=0.0417, recon=0.0417, kl=1.0263, beta=0.0001\n",
      "Batch 80, loss=0.0476, recon=0.0475, kl=0.6349, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0408 (Recon: 0.0407, KL: 1.3370, Current Beta: 0.0001) | Avg Valid Loss: 0.0527 | Avg Valid recon Loss: 0.0526\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0698, recon=0.0697, kl=0.2074, beta=0.0002\n",
      "Batch 40, loss=0.0604, recon=0.0603, kl=0.6600, beta=0.0002\n",
      "Batch 60, loss=0.0390, recon=0.0389, kl=0.6777, beta=0.0002\n",
      "Batch 80, loss=0.0425, recon=0.0424, kl=0.1762, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0538 (Recon: 0.0537, KL: 0.4343, Current Beta: 0.0002) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0361\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0327, recon=0.0327, kl=0.0189, beta=0.0004\n",
      "Batch 40, loss=0.0335, recon=0.0335, kl=0.0172, beta=0.0004\n",
      "Batch 60, loss=0.0397, recon=0.0397, kl=0.0337, beta=0.0004\n",
      "Batch 80, loss=0.0329, recon=0.0329, kl=0.0381, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0382, KL: 0.0357, Current Beta: 0.0004) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=0.0090, beta=0.0006\n",
      "Batch 40, loss=0.0335, recon=0.0335, kl=0.0535, beta=0.0006\n",
      "Batch 60, loss=0.0271, recon=0.0271, kl=0.0122, beta=0.0006\n",
      "Batch 80, loss=0.0244, recon=0.0243, kl=0.0072, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0407 (Recon: 0.0407, KL: 0.0218, Current Beta: 0.0006) | Avg Valid Loss: 0.0336 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0365, recon=0.0365, kl=0.0034, beta=0.0010\n",
      "Batch 40, loss=0.0448, recon=0.0448, kl=0.0032, beta=0.0010\n",
      "Batch 60, loss=0.0368, recon=0.0367, kl=0.0023, beta=0.0010\n",
      "Batch 80, loss=0.0281, recon=0.0281, kl=0.0059, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0404 (Recon: 0.0404, KL: 0.0040, Current Beta: 0.0010) | Avg Valid Loss: 0.0311 | Avg Valid recon Loss: 0.0311\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0297, recon=0.0297, kl=0.0040, beta=0.0010\n",
      "Batch 40, loss=0.0237, recon=0.0237, kl=0.0018, beta=0.0010\n",
      "Batch 60, loss=0.0265, recon=0.0265, kl=0.0013, beta=0.0010\n",
      "Batch 80, loss=0.0220, recon=0.0220, kl=0.0015, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0332 (Recon: 0.0332, KL: 0.0027, Current Beta: 0.0010) | Avg Valid Loss: 0.0290 | Avg Valid recon Loss: 0.0290\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0402, recon=0.0401, kl=0.0132, beta=0.0010\n",
      "Batch 40, loss=0.0261, recon=0.0261, kl=0.0070, beta=0.0010\n",
      "Batch 60, loss=0.0283, recon=0.0283, kl=0.0037, beta=0.0010\n",
      "Batch 80, loss=0.0289, recon=0.0289, kl=0.0048, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0331 (Recon: 0.0331, KL: 0.0060, Current Beta: 0.0010) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0579, recon=0.0578, kl=0.0091, beta=0.0010\n",
      "Batch 40, loss=0.0316, recon=0.0316, kl=0.0177, beta=0.0010\n",
      "Batch 60, loss=0.0473, recon=0.0473, kl=0.0046, beta=0.0010\n",
      "Batch 80, loss=0.0254, recon=0.0254, kl=0.0055, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0351 (Recon: 0.0351, KL: 0.0071, Current Beta: 0.0010) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0462, recon=0.0461, kl=0.0322, beta=0.0010\n",
      "Batch 40, loss=0.0298, recon=0.0298, kl=0.0251, beta=0.0010\n",
      "Batch 60, loss=0.0281, recon=0.0281, kl=0.0156, beta=0.0010\n",
      "Batch 80, loss=0.0389, recon=0.0389, kl=0.0064, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 0.0216, Current Beta: 0.0010) | Avg Valid Loss: 0.0322 | Avg Valid recon Loss: 0.0322\n",
      "\n",
      "[VRAE Run 175/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2201, recon=0.2201, kl=6.7665, beta=0.0000\n",
      "Batch 40, loss=0.1671, recon=0.1671, kl=22.1535, beta=0.0000\n",
      "Batch 60, loss=0.1489, recon=0.1489, kl=27.2971, beta=0.0000\n",
      "Batch 80, loss=0.1235, recon=0.1235, kl=35.9695, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2702 (Recon: 0.2702, KL: 20.9125, Current Beta: 0.0000) | Avg Valid Loss: 0.1174 | Avg Valid recon Loss: 0.1174\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0857, recon=0.0857, kl=50.9077, beta=0.0000\n",
      "Batch 40, loss=0.1174, recon=0.1174, kl=60.9438, beta=0.0000\n",
      "Batch 60, loss=0.1005, recon=0.1005, kl=60.7222, beta=0.0000\n",
      "Batch 80, loss=0.0813, recon=0.0813, kl=60.3578, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1259 (Recon: 0.1259, KL: 56.6349, Current Beta: 0.0000) | Avg Valid Loss: 0.0873 | Avg Valid recon Loss: 0.0873\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0854, recon=0.0854, kl=58.4146, beta=0.0000\n",
      "Batch 40, loss=0.0988, recon=0.0988, kl=57.8979, beta=0.0000\n",
      "Batch 60, loss=0.0532, recon=0.0532, kl=54.0949, beta=0.0000\n",
      "Batch 80, loss=0.2660, recon=0.2660, kl=61.1719, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0980 (Recon: 0.0980, KL: 58.1774, Current Beta: 0.0000) | Avg Valid Loss: 0.0709 | Avg Valid recon Loss: 0.0709\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0888, recon=0.0888, kl=56.7814, beta=0.0000\n",
      "Batch 40, loss=0.0807, recon=0.0807, kl=58.2728, beta=0.0000\n",
      "Batch 60, loss=0.0601, recon=0.0601, kl=56.6547, beta=0.0000\n",
      "Batch 80, loss=0.0643, recon=0.0643, kl=62.4854, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0803 (Recon: 0.0803, KL: 58.7635, Current Beta: 0.0000) | Avg Valid Loss: 0.0615 | Avg Valid recon Loss: 0.0615\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0842, recon=0.0842, kl=55.5738, beta=0.0000\n",
      "Batch 40, loss=0.0943, recon=0.0943, kl=53.2300, beta=0.0000\n",
      "Batch 60, loss=0.0462, recon=0.0462, kl=52.2140, beta=0.0000\n",
      "Batch 80, loss=0.0494, recon=0.0494, kl=51.4853, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0705 (Recon: 0.0705, KL: 53.9827, Current Beta: 0.0000) | Avg Valid Loss: 0.0557 | Avg Valid recon Loss: 0.0557\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0501, recon=0.0501, kl=50.0412, beta=0.0000\n",
      "Batch 40, loss=0.0690, recon=0.0690, kl=42.3573, beta=0.0000\n",
      "Batch 60, loss=0.0436, recon=0.0436, kl=41.1348, beta=0.0000\n",
      "Batch 80, loss=0.0575, recon=0.0575, kl=39.3865, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0632 (Recon: 0.0632, KL: 43.5516, Current Beta: 0.0000) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0374, recon=0.0374, kl=30.8084, beta=0.0000\n",
      "Batch 40, loss=0.1080, recon=0.1079, kl=29.5669, beta=0.0000\n",
      "Batch 60, loss=0.0686, recon=0.0686, kl=28.6019, beta=0.0000\n",
      "Batch 80, loss=0.0378, recon=0.0378, kl=29.8441, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0577 (Recon: 0.0577, KL: 30.5206, Current Beta: 0.0000) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0547, recon=0.0547, kl=18.8617, beta=0.0000\n",
      "Batch 40, loss=0.1165, recon=0.1165, kl=20.1364, beta=0.0000\n",
      "Batch 60, loss=0.0451, recon=0.0451, kl=17.2522, beta=0.0000\n",
      "Batch 80, loss=0.0469, recon=0.0468, kl=13.8992, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0538 (Recon: 0.0537, KL: 18.2540, Current Beta: 0.0000) | Avg Valid Loss: 0.0451 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0402, recon=0.0402, kl=7.4508, beta=0.0000\n",
      "Batch 40, loss=0.0673, recon=0.0673, kl=7.6770, beta=0.0000\n",
      "Batch 60, loss=0.0689, recon=0.0688, kl=9.1639, beta=0.0000\n",
      "Batch 80, loss=0.0448, recon=0.0448, kl=8.1487, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0503 (Recon: 0.0502, KL: 8.7345, Current Beta: 0.0000) | Avg Valid Loss: 0.0424 | Avg Valid recon Loss: 0.0424\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0753, recon=0.0753, kl=3.9407, beta=0.0000\n",
      "Batch 40, loss=0.0371, recon=0.0371, kl=2.8249, beta=0.0000\n",
      "Batch 60, loss=0.0976, recon=0.0976, kl=3.3718, beta=0.0000\n",
      "Batch 80, loss=0.0316, recon=0.0315, kl=2.6571, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0476 (Recon: 0.0476, KL: 3.4465, Current Beta: 0.0000) | Avg Valid Loss: 0.0409 | Avg Valid recon Loss: 0.0409\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0376, recon=0.0376, kl=1.1305, beta=0.0000\n",
      "Batch 40, loss=0.0413, recon=0.0413, kl=1.2215, beta=0.0000\n",
      "Batch 60, loss=0.0383, recon=0.0382, kl=0.7956, beta=0.0000\n",
      "Batch 80, loss=0.0329, recon=0.0329, kl=1.0218, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0451 (Recon: 0.0451, KL: 1.1509, Current Beta: 0.0000) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0392\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0315, recon=0.0314, kl=0.5495, beta=0.0001\n",
      "Batch 40, loss=0.0300, recon=0.0299, kl=0.2846, beta=0.0001\n",
      "Batch 60, loss=0.0245, recon=0.0245, kl=0.1105, beta=0.0001\n",
      "Batch 80, loss=0.0605, recon=0.0605, kl=0.1327, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0431, KL: 0.2515, Current Beta: 0.0001) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0986, recon=0.0986, kl=0.0681, beta=0.0002\n",
      "Batch 40, loss=0.0251, recon=0.0251, kl=0.0332, beta=0.0002\n",
      "Batch 60, loss=0.0342, recon=0.0342, kl=0.0081, beta=0.0002\n",
      "Batch 80, loss=0.0439, recon=0.0439, kl=0.0124, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0414, KL: 0.0251, Current Beta: 0.0002) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0259, recon=0.0259, kl=0.0112, beta=0.0004\n",
      "Batch 40, loss=0.0361, recon=0.0361, kl=0.0065, beta=0.0004\n",
      "Batch 60, loss=0.0277, recon=0.0277, kl=0.0031, beta=0.0004\n",
      "Batch 80, loss=0.0368, recon=0.0368, kl=0.0016, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0401 (Recon: 0.0401, KL: 0.0041, Current Beta: 0.0004) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0768, recon=0.0768, kl=0.0007, beta=0.0006\n",
      "Batch 40, loss=0.0262, recon=0.0262, kl=0.0008, beta=0.0006\n",
      "Batch 60, loss=0.0540, recon=0.0540, kl=0.0020, beta=0.0006\n",
      "Batch 80, loss=0.0442, recon=0.0442, kl=0.0011, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 0.0017, Current Beta: 0.0006) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0346\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0396, recon=0.0396, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0282, recon=0.0282, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0304, recon=0.0304, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0330, recon=0.0330, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0379 (Recon: 0.0379, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0335 | Avg Valid recon Loss: 0.0335\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0388, recon=0.0388, kl=0.0004, beta=0.0010\n",
      "Batch 40, loss=0.0263, recon=0.0263, kl=0.0003, beta=0.0010\n",
      "Batch 60, loss=0.0352, recon=0.0352, kl=0.0006, beta=0.0010\n",
      "Batch 80, loss=0.0436, recon=0.0436, kl=0.0009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0376 (Recon: 0.0376, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0242, recon=0.0242, kl=0.0017, beta=0.0010\n",
      "Batch 40, loss=0.0701, recon=0.0701, kl=0.0004, beta=0.0010\n",
      "Batch 60, loss=0.0279, recon=0.0279, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0885, recon=0.0885, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0364 (Recon: 0.0364, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0328 | Avg Valid recon Loss: 0.0328\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0358, recon=0.0358, kl=0.0008, beta=0.0010\n",
      "Batch 40, loss=0.0303, recon=0.0303, kl=0.0007, beta=0.0010\n",
      "Batch 60, loss=0.2469, recon=0.2469, kl=0.0006, beta=0.0010\n",
      "Batch 80, loss=0.0217, recon=0.0217, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0354, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0318\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=0.0005, beta=0.0010\n",
      "Batch 40, loss=0.0270, recon=0.0270, kl=0.0010, beta=0.0010\n",
      "Batch 60, loss=0.0266, recon=0.0266, kl=0.0004, beta=0.0010\n",
      "Batch 80, loss=0.0272, recon=0.0272, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0346 (Recon: 0.0346, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0312 | Avg Valid recon Loss: 0.0312\n",
      "\n",
      "[VRAE Run 176/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1293, recon=0.1293, kl=19.8519, beta=0.0000\n",
      "Batch 40, loss=0.0981, recon=0.0981, kl=25.4833, beta=0.0000\n",
      "Batch 60, loss=0.0668, recon=0.0668, kl=22.4868, beta=0.0000\n",
      "Batch 80, loss=0.0745, recon=0.0745, kl=26.7352, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1452 (Recon: 0.1452, KL: 21.4940, Current Beta: 0.0000) | Avg Valid Loss: 0.0626 | Avg Valid recon Loss: 0.0626\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0334, recon=0.0334, kl=30.0713, beta=0.0000\n",
      "Batch 40, loss=0.0374, recon=0.0374, kl=31.3170, beta=0.0000\n",
      "Batch 60, loss=0.0829, recon=0.0829, kl=31.9845, beta=0.0000\n",
      "Batch 80, loss=0.0437, recon=0.0437, kl=28.6032, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0636 (Recon: 0.0636, KL: 30.5277, Current Beta: 0.0000) | Avg Valid Loss: 0.0500 | Avg Valid recon Loss: 0.0500\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0389, recon=0.0389, kl=29.0450, beta=0.0000\n",
      "Batch 40, loss=0.0572, recon=0.0572, kl=31.7799, beta=0.0000\n",
      "Batch 60, loss=0.0698, recon=0.0698, kl=34.3602, beta=0.0000\n",
      "Batch 80, loss=0.0440, recon=0.0440, kl=36.6158, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0519 (Recon: 0.0519, KL: 31.9962, Current Beta: 0.0000) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0341, recon=0.0341, kl=34.2996, beta=0.0000\n",
      "Batch 40, loss=0.0264, recon=0.0264, kl=25.9255, beta=0.0000\n",
      "Batch 60, loss=0.0253, recon=0.0253, kl=37.9769, beta=0.0000\n",
      "Batch 80, loss=0.0378, recon=0.0378, kl=34.8837, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0450, KL: 32.7714, Current Beta: 0.0000) | Avg Valid Loss: 0.0543 | Avg Valid recon Loss: 0.0543\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0342, recon=0.0342, kl=29.8413, beta=0.0000\n",
      "Batch 40, loss=0.0340, recon=0.0340, kl=32.8529, beta=0.0000\n",
      "Batch 60, loss=0.0394, recon=0.0394, kl=34.5890, beta=0.0000\n",
      "Batch 80, loss=0.0467, recon=0.0467, kl=35.5218, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0475 (Recon: 0.0475, KL: 32.8927, Current Beta: 0.0000) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0236, recon=0.0235, kl=31.3209, beta=0.0000\n",
      "Batch 40, loss=0.0267, recon=0.0267, kl=32.5714, beta=0.0000\n",
      "Batch 60, loss=0.0220, recon=0.0220, kl=32.8310, beta=0.0000\n",
      "Batch 80, loss=0.0232, recon=0.0232, kl=28.0043, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0375 (Recon: 0.0375, KL: 31.6119, Current Beta: 0.0000) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0388, recon=0.0388, kl=26.4451, beta=0.0000\n",
      "Batch 40, loss=0.0264, recon=0.0264, kl=26.8004, beta=0.0000\n",
      "Batch 60, loss=0.0541, recon=0.0541, kl=27.0399, beta=0.0000\n",
      "Batch 80, loss=0.0360, recon=0.0360, kl=25.4211, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0393 (Recon: 0.0393, KL: 26.8268, Current Beta: 0.0000) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0188, recon=0.0187, kl=17.4316, beta=0.0000\n",
      "Batch 40, loss=0.0700, recon=0.0700, kl=18.1653, beta=0.0000\n",
      "Batch 60, loss=0.0339, recon=0.0339, kl=23.8773, beta=0.0000\n",
      "Batch 80, loss=0.0318, recon=0.0318, kl=23.1101, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0391, KL: 21.0776, Current Beta: 0.0000) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=12.9985, beta=0.0000\n",
      "Batch 40, loss=0.0289, recon=0.0288, kl=16.4642, beta=0.0000\n",
      "Batch 60, loss=0.0304, recon=0.0304, kl=13.4404, beta=0.0000\n",
      "Batch 80, loss=0.0303, recon=0.0302, kl=16.9755, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0381 (Recon: 0.0381, KL: 15.9368, Current Beta: 0.0000) | Avg Valid Loss: 0.0480 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0317, recon=0.0316, kl=12.3378, beta=0.0000\n",
      "Batch 40, loss=0.0469, recon=0.0468, kl=9.5961, beta=0.0000\n",
      "Batch 60, loss=0.0228, recon=0.0227, kl=10.1812, beta=0.0000\n",
      "Batch 80, loss=0.0385, recon=0.0385, kl=5.5709, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0417, KL: 9.8758, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0898, recon=0.0897, kl=3.7779, beta=0.0000\n",
      "Batch 40, loss=0.0313, recon=0.0312, kl=4.6180, beta=0.0000\n",
      "Batch 60, loss=0.0240, recon=0.0240, kl=2.9671, beta=0.0000\n",
      "Batch 80, loss=0.0367, recon=0.0365, kl=5.8863, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0507, KL: 4.8684, Current Beta: 0.0000) | Avg Valid Loss: 0.0405 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0306, recon=0.0305, kl=1.5024, beta=0.0001\n",
      "Batch 40, loss=0.0297, recon=0.0297, kl=1.0605, beta=0.0001\n",
      "Batch 60, loss=0.0222, recon=0.0221, kl=0.6551, beta=0.0001\n",
      "Batch 80, loss=0.0307, recon=0.0306, kl=0.6768, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0399, KL: 1.5837, Current Beta: 0.0001) | Avg Valid Loss: 0.0453 | Avg Valid recon Loss: 0.0453\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0514, recon=0.0514, kl=0.4066, beta=0.0002\n",
      "Batch 40, loss=0.0277, recon=0.0276, kl=0.3738, beta=0.0002\n",
      "Batch 60, loss=0.0292, recon=0.0291, kl=0.5592, beta=0.0002\n",
      "Batch 80, loss=0.0251, recon=0.0250, kl=0.4514, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0403 (Recon: 0.0402, KL: 0.4446, Current Beta: 0.0002) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0567, recon=0.0567, kl=0.1000, beta=0.0004\n",
      "Batch 40, loss=0.0432, recon=0.0430, kl=0.3491, beta=0.0004\n",
      "Batch 60, loss=0.0331, recon=0.0330, kl=0.1111, beta=0.0004\n",
      "Batch 80, loss=0.0724, recon=0.0724, kl=0.0434, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0413 (Recon: 0.0413, KL: 0.1687, Current Beta: 0.0004) | Avg Valid Loss: 0.0336 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0235, recon=0.0235, kl=0.0044, beta=0.0006\n",
      "Batch 40, loss=0.0291, recon=0.0291, kl=0.0087, beta=0.0006\n",
      "Batch 60, loss=0.0581, recon=0.0581, kl=0.0057, beta=0.0006\n",
      "Batch 80, loss=0.0752, recon=0.0752, kl=0.0369, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0394 (Recon: 0.0394, KL: 0.0170, Current Beta: 0.0006) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0472\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0217, recon=0.0217, kl=0.0074, beta=0.0010\n",
      "Batch 40, loss=0.0883, recon=0.0883, kl=0.0136, beta=0.0010\n",
      "Batch 60, loss=0.0512, recon=0.0511, kl=0.0381, beta=0.0010\n",
      "Batch 80, loss=0.0275, recon=0.0275, kl=0.0100, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0415, KL: 0.0250, Current Beta: 0.0010) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=0.0053, beta=0.0010\n",
      "Batch 40, loss=0.0294, recon=0.0294, kl=0.0038, beta=0.0010\n",
      "Batch 60, loss=0.0206, recon=0.0206, kl=0.0055, beta=0.0010\n",
      "Batch 80, loss=0.0418, recon=0.0418, kl=0.0065, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0371 (Recon: 0.0371, KL: 0.0061, Current Beta: 0.0010) | Avg Valid Loss: 0.0354 | Avg Valid recon Loss: 0.0354\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0238, recon=0.0238, kl=0.0089, beta=0.0010\n",
      "Batch 40, loss=0.0652, recon=0.0652, kl=0.0050, beta=0.0010\n",
      "Batch 60, loss=0.0269, recon=0.0269, kl=0.0457, beta=0.0010\n",
      "Batch 80, loss=0.2363, recon=0.2363, kl=0.0126, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0365 (Recon: 0.0365, KL: 0.0179, Current Beta: 0.0010) | Avg Valid Loss: 0.0495 | Avg Valid recon Loss: 0.0495\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0303, recon=0.0303, kl=0.0251, beta=0.0010\n",
      "Batch 40, loss=0.0259, recon=0.0259, kl=0.0069, beta=0.0010\n",
      "Batch 60, loss=0.0329, recon=0.0329, kl=0.0209, beta=0.0010\n",
      "Batch 80, loss=0.0267, recon=0.0267, kl=0.0284, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0409, KL: 0.0192, Current Beta: 0.0010) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0323, recon=0.0323, kl=0.0101, beta=0.0010\n",
      "Batch 40, loss=0.0421, recon=0.0421, kl=0.0270, beta=0.0010\n",
      "Batch 60, loss=0.0419, recon=0.0419, kl=0.0475, beta=0.0010\n",
      "Batch 80, loss=0.0296, recon=0.0296, kl=0.0128, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0424, KL: 0.0226, Current Beta: 0.0010) | Avg Valid Loss: 0.0356 | Avg Valid recon Loss: 0.0355\n",
      "\n",
      "[VRAE Run 177/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3076, recon=0.3076, kl=6.9399, beta=0.0000\n",
      "Batch 40, loss=0.1660, recon=0.1660, kl=41.3718, beta=0.0000\n",
      "Batch 60, loss=0.1584, recon=0.1584, kl=55.8446, beta=0.0000\n",
      "Batch 80, loss=0.1737, recon=0.1737, kl=67.1487, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2721 (Recon: 0.2721, KL: 38.8987, Current Beta: 0.0000) | Avg Valid Loss: 0.1132 | Avg Valid recon Loss: 0.1132\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0948, recon=0.0948, kl=80.5119, beta=0.0000\n",
      "Batch 40, loss=0.1358, recon=0.1358, kl=86.9820, beta=0.0000\n",
      "Batch 60, loss=0.3389, recon=0.3389, kl=90.5178, beta=0.0000\n",
      "Batch 80, loss=0.1117, recon=0.1117, kl=92.2451, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1195 (Recon: 0.1195, KL: 86.1235, Current Beta: 0.0000) | Avg Valid Loss: 0.0814 | Avg Valid recon Loss: 0.0814\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0700, recon=0.0700, kl=90.9922, beta=0.0000\n",
      "Batch 40, loss=0.1207, recon=0.1207, kl=88.5176, beta=0.0000\n",
      "Batch 60, loss=0.0635, recon=0.0635, kl=96.1181, beta=0.0000\n",
      "Batch 80, loss=0.0586, recon=0.0586, kl=96.2680, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0903 (Recon: 0.0903, KL: 92.7675, Current Beta: 0.0000) | Avg Valid Loss: 0.0679 | Avg Valid recon Loss: 0.0679\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0714, recon=0.0714, kl=99.2182, beta=0.0000\n",
      "Batch 40, loss=0.0588, recon=0.0588, kl=97.2564, beta=0.0000\n",
      "Batch 60, loss=0.0569, recon=0.0569, kl=94.3447, beta=0.0000\n",
      "Batch 80, loss=0.0527, recon=0.0527, kl=93.0142, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0755 (Recon: 0.0755, KL: 95.8726, Current Beta: 0.0000) | Avg Valid Loss: 0.0616 | Avg Valid recon Loss: 0.0616\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0494, recon=0.0493, kl=93.8186, beta=0.0000\n",
      "Batch 40, loss=0.0602, recon=0.0601, kl=93.1517, beta=0.0000\n",
      "Batch 60, loss=0.0509, recon=0.0509, kl=89.2513, beta=0.0000\n",
      "Batch 80, loss=0.0445, recon=0.0445, kl=87.0631, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0674 (Recon: 0.0674, KL: 90.9018, Current Beta: 0.0000) | Avg Valid Loss: 0.0547 | Avg Valid recon Loss: 0.0547\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0424, recon=0.0424, kl=81.7736, beta=0.0000\n",
      "Batch 40, loss=0.0368, recon=0.0368, kl=67.6001, beta=0.0000\n",
      "Batch 60, loss=0.0422, recon=0.0422, kl=68.3334, beta=0.0000\n",
      "Batch 80, loss=0.1296, recon=0.1295, kl=57.8818, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0612 (Recon: 0.0612, KL: 70.7181, Current Beta: 0.0000) | Avg Valid Loss: 0.0512 | Avg Valid recon Loss: 0.0512\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0573, recon=0.0573, kl=50.2089, beta=0.0000\n",
      "Batch 40, loss=0.0400, recon=0.0400, kl=45.8726, beta=0.0000\n",
      "Batch 60, loss=0.0365, recon=0.0365, kl=44.0214, beta=0.0000\n",
      "Batch 80, loss=0.0452, recon=0.0452, kl=44.4259, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0559 (Recon: 0.0558, KL: 48.0312, Current Beta: 0.0000) | Avg Valid Loss: 0.0469 | Avg Valid recon Loss: 0.0468\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0318, recon=0.0318, kl=29.3093, beta=0.0000\n",
      "Batch 40, loss=0.0339, recon=0.0339, kl=23.2283, beta=0.0000\n",
      "Batch 60, loss=0.0457, recon=0.0457, kl=25.9011, beta=0.0000\n",
      "Batch 80, loss=0.0343, recon=0.0343, kl=24.2770, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0520 (Recon: 0.0520, KL: 27.5556, Current Beta: 0.0000) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0459, recon=0.0458, kl=14.1003, beta=0.0000\n",
      "Batch 40, loss=0.0413, recon=0.0412, kl=10.9818, beta=0.0000\n",
      "Batch 60, loss=0.0337, recon=0.0337, kl=9.8380, beta=0.0000\n",
      "Batch 80, loss=0.0382, recon=0.0382, kl=9.0560, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0488 (Recon: 0.0487, KL: 12.4091, Current Beta: 0.0000) | Avg Valid Loss: 0.0416 | Avg Valid recon Loss: 0.0416\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0778, recon=0.0777, kl=3.2313, beta=0.0000\n",
      "Batch 40, loss=0.0277, recon=0.0277, kl=4.6589, beta=0.0000\n",
      "Batch 60, loss=0.0511, recon=0.0511, kl=3.3947, beta=0.0000\n",
      "Batch 80, loss=0.0402, recon=0.0402, kl=3.3581, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0458, KL: 4.1314, Current Beta: 0.0000) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0421, recon=0.0421, kl=1.0648, beta=0.0000\n",
      "Batch 40, loss=0.0421, recon=0.0421, kl=1.0628, beta=0.0000\n",
      "Batch 60, loss=0.0489, recon=0.0489, kl=0.9239, beta=0.0000\n",
      "Batch 80, loss=0.0293, recon=0.0293, kl=1.0275, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 1.2564, Current Beta: 0.0000) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0276, recon=0.0275, kl=0.2561, beta=0.0001\n",
      "Batch 40, loss=0.0469, recon=0.0468, kl=0.1687, beta=0.0001\n",
      "Batch 60, loss=0.0278, recon=0.0278, kl=0.1771, beta=0.0001\n",
      "Batch 80, loss=0.0503, recon=0.0503, kl=0.2398, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0418, KL: 0.2737, Current Beta: 0.0001) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=0.0676, beta=0.0002\n",
      "Batch 40, loss=0.0351, recon=0.0351, kl=0.0285, beta=0.0002\n",
      "Batch 60, loss=0.0290, recon=0.0290, kl=0.1245, beta=0.0002\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=0.0248, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0402 (Recon: 0.0402, KL: 0.0435, Current Beta: 0.0002) | Avg Valid Loss: 0.0348 | Avg Valid recon Loss: 0.0348\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0626, recon=0.0626, kl=0.0070, beta=0.0004\n",
      "Batch 40, loss=0.0439, recon=0.0439, kl=0.0123, beta=0.0004\n",
      "Batch 60, loss=0.0225, recon=0.0225, kl=0.0206, beta=0.0004\n",
      "Batch 80, loss=0.0346, recon=0.0346, kl=0.0179, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0388, KL: 0.0108, Current Beta: 0.0004) | Avg Valid Loss: 0.0337 | Avg Valid recon Loss: 0.0337\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0299, recon=0.0299, kl=0.0059, beta=0.0006\n",
      "Batch 40, loss=0.0372, recon=0.0372, kl=0.0048, beta=0.0006\n",
      "Batch 60, loss=0.0235, recon=0.0235, kl=0.0012, beta=0.0006\n",
      "Batch 80, loss=0.0226, recon=0.0226, kl=0.0017, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0378 (Recon: 0.0378, KL: 0.0045, Current Beta: 0.0006) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0334\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0416, recon=0.0416, kl=0.0061, beta=0.0010\n",
      "Batch 40, loss=0.0219, recon=0.0219, kl=0.0015, beta=0.0010\n",
      "Batch 60, loss=0.0330, recon=0.0330, kl=0.0013, beta=0.0010\n",
      "Batch 80, loss=0.0273, recon=0.0273, kl=0.0010, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0368 (Recon: 0.0368, KL: 0.0029, Current Beta: 0.0010) | Avg Valid Loss: 0.0321 | Avg Valid recon Loss: 0.0321\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0216, recon=0.0216, kl=0.0024, beta=0.0010\n",
      "Batch 40, loss=0.0383, recon=0.0383, kl=0.0018, beta=0.0010\n",
      "Batch 60, loss=0.0447, recon=0.0447, kl=0.0014, beta=0.0010\n",
      "Batch 80, loss=0.0206, recon=0.0206, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0362, KL: 0.0023, Current Beta: 0.0010) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0318\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0301, recon=0.0301, kl=0.0026, beta=0.0010\n",
      "Batch 40, loss=0.0610, recon=0.0610, kl=0.0011, beta=0.0010\n",
      "Batch 60, loss=0.0280, recon=0.0280, kl=0.0009, beta=0.0010\n",
      "Batch 80, loss=0.0246, recon=0.0246, kl=0.0010, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0355 (Recon: 0.0355, KL: 0.0015, Current Beta: 0.0010) | Avg Valid Loss: 0.0310 | Avg Valid recon Loss: 0.0310\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0196, recon=0.0196, kl=0.0007, beta=0.0010\n",
      "Batch 40, loss=0.0400, recon=0.0400, kl=0.0019, beta=0.0010\n",
      "Batch 60, loss=0.0266, recon=0.0266, kl=0.0009, beta=0.0010\n",
      "Batch 80, loss=0.0325, recon=0.0325, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0323 (Recon: 0.0323, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0305 | Avg Valid recon Loss: 0.0305\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0363, recon=0.0363, kl=0.0006, beta=0.0010\n",
      "Batch 40, loss=0.0239, recon=0.0239, kl=0.0012, beta=0.0010\n",
      "Batch 60, loss=0.0364, recon=0.0364, kl=0.0013, beta=0.0010\n",
      "Batch 80, loss=0.0323, recon=0.0323, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0341 (Recon: 0.0341, KL: 0.0013, Current Beta: 0.0010) | Avg Valid Loss: 0.0305 | Avg Valid recon Loss: 0.0305\n",
      "\n",
      "[VRAE Run 178/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1321, recon=0.1321, kl=40.6629, beta=0.0000\n",
      "Batch 40, loss=0.0682, recon=0.0682, kl=55.9885, beta=0.0000\n",
      "Batch 60, loss=0.0860, recon=0.0860, kl=62.8736, beta=0.0000\n",
      "Batch 80, loss=0.0508, recon=0.0508, kl=50.8264, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1445 (Recon: 0.1445, KL: 48.9392, Current Beta: 0.0000) | Avg Valid Loss: 0.0594 | Avg Valid recon Loss: 0.0594\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0612, recon=0.0612, kl=64.0749, beta=0.0000\n",
      "Batch 40, loss=0.0421, recon=0.0421, kl=58.4014, beta=0.0000\n",
      "Batch 60, loss=0.0991, recon=0.0991, kl=62.0871, beta=0.0000\n",
      "Batch 80, loss=0.0419, recon=0.0419, kl=64.9255, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0641 (Recon: 0.0641, KL: 61.7301, Current Beta: 0.0000) | Avg Valid Loss: 0.0503 | Avg Valid recon Loss: 0.0503\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0491, recon=0.0491, kl=83.7340, beta=0.0000\n",
      "Batch 40, loss=0.0532, recon=0.0532, kl=128.9037, beta=0.0000\n",
      "Batch 60, loss=0.1298, recon=0.1298, kl=99.1912, beta=0.0000\n",
      "Batch 80, loss=0.7757, recon=0.7757, kl=79.4322, beta=0.0000\n",
      "  â†’ Avg Train Loss: 759.5760 (Recon: 759.5758, KL: 11064.1230, Current Beta: 0.0000) | Avg Valid Loss: 102.3925 | Avg Valid recon Loss: 102.3925\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1243, recon=0.1243, kl=155.6532, beta=0.0000\n",
      "Batch 40, loss=0.0669, recon=0.0669, kl=154.4112, beta=0.0000\n",
      "Batch 60, loss=0.0651, recon=0.0651, kl=150.1332, beta=0.0000\n",
      "Batch 80, loss=0.0875, recon=0.0875, kl=147.4112, beta=0.0000\n",
      "  â†’ Avg Train Loss: 2.8881 (Recon: 2.8881, KL: 148.4383, Current Beta: 0.0000) | Avg Valid Loss: 0.0592 | Avg Valid recon Loss: 0.0592\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0341, recon=0.0341, kl=146.7744, beta=0.0000\n",
      "Batch 40, loss=0.0373, recon=0.0373, kl=146.2749, beta=0.0000\n",
      "Batch 60, loss=0.0286, recon=0.0286, kl=145.6488, beta=0.0000\n",
      "Batch 80, loss=0.0313, recon=0.0313, kl=145.1466, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0546 (Recon: 0.0546, KL: 146.2654, Current Beta: 0.0000) | Avg Valid Loss: 0.0505 | Avg Valid recon Loss: 0.0505\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0460, recon=0.0460, kl=145.2797, beta=0.0000\n",
      "Batch 40, loss=0.0562, recon=0.0561, kl=144.9846, beta=0.0000\n",
      "Batch 60, loss=0.0307, recon=0.0307, kl=144.0800, beta=0.0000\n",
      "Batch 80, loss=0.0257, recon=0.0257, kl=143.9920, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0495, KL: 144.5576, Current Beta: 0.0000) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0480, recon=0.0479, kl=143.8953, beta=0.0000\n",
      "Batch 40, loss=0.0325, recon=0.0324, kl=143.3447, beta=0.0000\n",
      "Batch 60, loss=0.0320, recon=0.0319, kl=142.9276, beta=0.0000\n",
      "Batch 80, loss=0.0791, recon=0.0790, kl=141.7281, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0429, KL: 143.0514, Current Beta: 0.0000) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0407, recon=0.0405, kl=140.0771, beta=0.0000\n",
      "Batch 40, loss=0.0509, recon=0.0507, kl=137.6173, beta=0.0000\n",
      "Batch 60, loss=0.0701, recon=0.0699, kl=135.4175, beta=0.0000\n",
      "Batch 80, loss=0.0395, recon=0.0393, kl=132.9925, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0427, KL: 136.7457, Current Beta: 0.0000) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0292, recon=0.0287, kl=126.8417, beta=0.0000\n",
      "Batch 40, loss=0.0300, recon=0.0295, kl=120.4623, beta=0.0000\n",
      "Batch 60, loss=0.0364, recon=0.0359, kl=115.1156, beta=0.0000\n",
      "Batch 80, loss=0.0281, recon=0.0276, kl=110.5152, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0395, KL: 119.7265, Current Beta: 0.0000) | Avg Valid Loss: 0.0343 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0308, recon=0.0297, kl=97.7272, beta=0.0000\n",
      "Batch 40, loss=0.0354, recon=0.0346, kl=78.1741, beta=0.0000\n",
      "Batch 60, loss=0.0180, recon=0.0173, kl=65.6838, beta=0.0000\n",
      "Batch 80, loss=0.0247, recon=0.0241, kl=59.4835, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0380, KL: 78.6230, Current Beta: 0.0000) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0333\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0755, recon=0.0742, kl=45.5618, beta=0.0000\n",
      "Batch 40, loss=0.0292, recon=0.0282, kl=33.2010, beta=0.0000\n",
      "Batch 60, loss=0.0319, recon=0.0311, kl=28.3203, beta=0.0000\n",
      "Batch 80, loss=0.0284, recon=0.0277, kl=24.3221, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0360, KL: 35.3961, Current Beta: 0.0000) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0331\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0375, recon=0.0365, kl=13.8998, beta=0.0001\n",
      "Batch 40, loss=0.0372, recon=0.0362, kl=12.6577, beta=0.0001\n",
      "Batch 60, loss=0.0275, recon=0.0266, kl=11.1171, beta=0.0001\n",
      "Batch 80, loss=0.0283, recon=0.0276, kl=9.6518, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0375 (Recon: 0.0365, KL: 12.4071, Current Beta: 0.0001) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0286, recon=0.0275, kl=5.9760, beta=0.0002\n",
      "Batch 40, loss=0.0312, recon=0.0301, kl=6.3524, beta=0.0002\n",
      "Batch 60, loss=0.0307, recon=0.0299, kl=4.1802, beta=0.0002\n",
      "Batch 80, loss=0.0263, recon=0.0255, kl=4.3407, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0366 (Recon: 0.0357, KL: 4.9299, Current Beta: 0.0002) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0411, recon=0.0399, kl=3.2314, beta=0.0004\n",
      "Batch 40, loss=0.0792, recon=0.0779, kl=3.5767, beta=0.0004\n",
      "Batch 60, loss=0.0436, recon=0.0429, kl=1.8784, beta=0.0004\n",
      "Batch 80, loss=0.0410, recon=0.0400, kl=2.6363, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0434, KL: 3.0187, Current Beta: 0.0004) | Avg Valid Loss: 0.0362 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0305, recon=0.0297, kl=1.3395, beta=0.0006\n",
      "Batch 40, loss=0.0294, recon=0.0286, kl=1.1583, beta=0.0006\n",
      "Batch 60, loss=0.0609, recon=0.0590, kl=3.1568, beta=0.0006\n",
      "Batch 80, loss=0.0351, recon=0.0341, kl=1.6709, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0363 (Recon: 0.0350, KL: 1.9648, Current Beta: 0.0006) | Avg Valid Loss: 0.0301 | Avg Valid recon Loss: 0.0291\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0302, recon=0.0295, kl=0.7434, beta=0.0010\n",
      "Batch 40, loss=0.0292, recon=0.0280, kl=1.2713, beta=0.0010\n",
      "Batch 60, loss=0.0355, recon=0.0348, kl=0.6922, beta=0.0010\n",
      "Batch 80, loss=0.0266, recon=0.0250, kl=1.5424, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0339 (Recon: 0.0328, KL: 1.0909, Current Beta: 0.0010) | Avg Valid Loss: 0.0336 | Avg Valid recon Loss: 0.0326\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0259, recon=0.0253, kl=0.6188, beta=0.0010\n",
      "Batch 40, loss=0.0315, recon=0.0308, kl=0.6448, beta=0.0010\n",
      "Batch 60, loss=0.0291, recon=0.0283, kl=0.8411, beta=0.0010\n",
      "Batch 80, loss=0.0313, recon=0.0309, kl=0.3413, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0379, KL: 0.7006, Current Beta: 0.0010) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0545, recon=0.0535, kl=0.9678, beta=0.0010\n",
      "Batch 40, loss=0.0342, recon=0.0341, kl=0.1573, beta=0.0010\n",
      "Batch 60, loss=0.0397, recon=0.0389, kl=0.7647, beta=0.0010\n",
      "Batch 80, loss=0.0226, recon=0.0223, kl=0.3791, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0411, KL: 0.6169, Current Beta: 0.0010) | Avg Valid Loss: 0.0314 | Avg Valid recon Loss: 0.0308\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0215, recon=0.0210, kl=0.4468, beta=0.0010\n",
      "Batch 40, loss=0.0250, recon=0.0247, kl=0.3590, beta=0.0010\n",
      "Batch 60, loss=0.0383, recon=0.0380, kl=0.3198, beta=0.0010\n",
      "Batch 80, loss=0.0320, recon=0.0315, kl=0.5349, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0381 (Recon: 0.0377, KL: 0.4367, Current Beta: 0.0010) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0328\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0238, recon=0.0236, kl=0.1827, beta=0.0010\n",
      "Batch 40, loss=0.0414, recon=0.0411, kl=0.2858, beta=0.0010\n",
      "Batch 60, loss=0.0221, recon=0.0219, kl=0.1983, beta=0.0010\n",
      "Batch 80, loss=0.0220, recon=0.0218, kl=0.2200, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0341 (Recon: 0.0337, KL: 0.3057, Current Beta: 0.0010) | Avg Valid Loss: 0.0306 | Avg Valid recon Loss: 0.0303\n",
      "\n",
      "[VRAE Run 179/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2421, recon=0.2421, kl=16.2656, beta=0.0000\n",
      "Batch 40, loss=0.2210, recon=0.2210, kl=89.5338, beta=0.0000\n",
      "Batch 60, loss=0.4879, recon=0.4879, kl=119.2415, beta=0.0000\n",
      "Batch 80, loss=0.2229, recon=0.2229, kl=139.2895, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2763 (Recon: 0.2763, KL: 83.0560, Current Beta: 0.0000) | Avg Valid Loss: 0.1177 | Avg Valid recon Loss: 0.1177\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1071, recon=0.1071, kl=146.6570, beta=0.0000\n",
      "Batch 40, loss=0.1140, recon=0.1140, kl=146.5693, beta=0.0000\n",
      "Batch 60, loss=0.0987, recon=0.0987, kl=142.4395, beta=0.0000\n",
      "Batch 80, loss=0.0667, recon=0.0667, kl=150.9822, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1252 (Recon: 0.1252, KL: 147.0515, Current Beta: 0.0000) | Avg Valid Loss: 0.0851 | Avg Valid recon Loss: 0.0851\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0954, recon=0.0954, kl=162.3887, beta=0.0000\n",
      "Batch 40, loss=0.0718, recon=0.0718, kl=173.4843, beta=0.0000\n",
      "Batch 60, loss=0.0647, recon=0.0647, kl=179.0003, beta=0.0000\n",
      "Batch 80, loss=0.0668, recon=0.0668, kl=181.7284, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0961 (Recon: 0.0961, KL: 172.6476, Current Beta: 0.0000) | Avg Valid Loss: 0.0709 | Avg Valid recon Loss: 0.0709\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0563, recon=0.0563, kl=182.2863, beta=0.0000\n",
      "Batch 40, loss=0.0584, recon=0.0584, kl=184.1659, beta=0.0000\n",
      "Batch 60, loss=0.0853, recon=0.0853, kl=179.8596, beta=0.0000\n",
      "Batch 80, loss=0.0503, recon=0.0503, kl=176.9146, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0798 (Recon: 0.0798, KL: 181.1499, Current Beta: 0.0000) | Avg Valid Loss: 0.0633 | Avg Valid recon Loss: 0.0633\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0496, recon=0.0496, kl=171.6718, beta=0.0000\n",
      "Batch 40, loss=0.0482, recon=0.0482, kl=163.7093, beta=0.0000\n",
      "Batch 60, loss=0.0504, recon=0.0504, kl=159.2654, beta=0.0000\n",
      "Batch 80, loss=0.1154, recon=0.1154, kl=150.2515, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0699 (Recon: 0.0699, KL: 164.0943, Current Beta: 0.0000) | Avg Valid Loss: 0.0593 | Avg Valid recon Loss: 0.0593\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0502, recon=0.0502, kl=137.1295, beta=0.0000\n",
      "Batch 40, loss=0.0570, recon=0.0570, kl=115.4673, beta=0.0000\n",
      "Batch 60, loss=0.0421, recon=0.0421, kl=104.6488, beta=0.0000\n",
      "Batch 80, loss=0.0616, recon=0.0616, kl=107.7873, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0636 (Recon: 0.0636, KL: 118.9938, Current Beta: 0.0000) | Avg Valid Loss: 0.0521 | Avg Valid recon Loss: 0.0521\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0450, recon=0.0449, kl=82.6069, beta=0.0000\n",
      "Batch 40, loss=0.0492, recon=0.0492, kl=69.3511, beta=0.0000\n",
      "Batch 60, loss=0.0598, recon=0.0598, kl=68.5088, beta=0.0000\n",
      "Batch 80, loss=0.0399, recon=0.0399, kl=66.5064, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0587 (Recon: 0.0587, KL: 74.2857, Current Beta: 0.0000) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0495\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0416, recon=0.0416, kl=40.1018, beta=0.0000\n",
      "Batch 40, loss=0.0532, recon=0.0531, kl=35.0569, beta=0.0000\n",
      "Batch 60, loss=0.0373, recon=0.0373, kl=35.1043, beta=0.0000\n",
      "Batch 80, loss=0.0578, recon=0.0577, kl=33.8302, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0543 (Recon: 0.0543, KL: 39.4341, Current Beta: 0.0000) | Avg Valid Loss: 0.0464 | Avg Valid recon Loss: 0.0463\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0542, recon=0.0542, kl=15.4328, beta=0.0000\n",
      "Batch 40, loss=0.0276, recon=0.0275, kl=13.8446, beta=0.0000\n",
      "Batch 60, loss=0.0454, recon=0.0453, kl=15.8486, beta=0.0000\n",
      "Batch 80, loss=0.0526, recon=0.0525, kl=14.0897, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0510 (Recon: 0.0510, KL: 16.5476, Current Beta: 0.0000) | Avg Valid Loss: 0.0439 | Avg Valid recon Loss: 0.0439\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0620, recon=0.0620, kl=5.3597, beta=0.0000\n",
      "Batch 40, loss=0.0322, recon=0.0321, kl=5.6408, beta=0.0000\n",
      "Batch 60, loss=0.0318, recon=0.0318, kl=6.0001, beta=0.0000\n",
      "Batch 80, loss=0.0401, recon=0.0400, kl=4.6585, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0479, KL: 6.3707, Current Beta: 0.0000) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0356, recon=0.0355, kl=2.2749, beta=0.0000\n",
      "Batch 40, loss=0.0452, recon=0.0452, kl=2.4124, beta=0.0000\n",
      "Batch 60, loss=0.0372, recon=0.0372, kl=1.8019, beta=0.0000\n",
      "Batch 80, loss=0.0327, recon=0.0327, kl=1.5593, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0454, KL: 2.2601, Current Beta: 0.0000) | Avg Valid Loss: 0.0404 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0326, recon=0.0326, kl=0.7053, beta=0.0001\n",
      "Batch 40, loss=0.0716, recon=0.0715, kl=0.6294, beta=0.0001\n",
      "Batch 60, loss=0.0279, recon=0.0278, kl=0.5779, beta=0.0001\n",
      "Batch 80, loss=0.0452, recon=0.0451, kl=0.7244, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0438, KL: 0.6766, Current Beta: 0.0001) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0243, recon=0.0243, kl=0.1105, beta=0.0002\n",
      "Batch 40, loss=0.0293, recon=0.0292, kl=0.1307, beta=0.0002\n",
      "Batch 60, loss=0.0271, recon=0.0271, kl=0.1031, beta=0.0002\n",
      "Batch 80, loss=0.0307, recon=0.0307, kl=0.0846, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0416, KL: 0.1175, Current Beta: 0.0002) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0387, recon=0.0387, kl=0.0180, beta=0.0004\n",
      "Batch 40, loss=0.0731, recon=0.0731, kl=0.0101, beta=0.0004\n",
      "Batch 60, loss=0.0240, recon=0.0240, kl=0.0078, beta=0.0004\n",
      "Batch 80, loss=0.0245, recon=0.0245, kl=0.0114, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0406 (Recon: 0.0406, KL: 0.0154, Current Beta: 0.0004) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0355\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0243, recon=0.0243, kl=0.0025, beta=0.0006\n",
      "Batch 40, loss=0.0271, recon=0.0271, kl=0.0046, beta=0.0006\n",
      "Batch 60, loss=0.0983, recon=0.0983, kl=0.0039, beta=0.0006\n",
      "Batch 80, loss=0.0233, recon=0.0233, kl=0.0032, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0391, KL: 0.0036, Current Beta: 0.0006) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0328, recon=0.0328, kl=0.0009, beta=0.0010\n",
      "Batch 40, loss=0.0855, recon=0.0855, kl=0.0009, beta=0.0010\n",
      "Batch 60, loss=0.0352, recon=0.0351, kl=0.0050, beta=0.0010\n",
      "Batch 80, loss=0.0366, recon=0.0366, kl=0.0013, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0382, KL: 0.0015, Current Beta: 0.0010) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0230, recon=0.0230, kl=0.0008, beta=0.0010\n",
      "Batch 40, loss=0.0336, recon=0.0336, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0199, recon=0.0199, kl=0.0009, beta=0.0010\n",
      "Batch 80, loss=0.0339, recon=0.0339, kl=0.0051, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0375 (Recon: 0.0375, KL: 0.0013, Current Beta: 0.0010) | Avg Valid Loss: 0.0329 | Avg Valid recon Loss: 0.0329\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0369, recon=0.0369, kl=0.0010, beta=0.0010\n",
      "Batch 40, loss=0.0309, recon=0.0309, kl=0.0009, beta=0.0010\n",
      "Batch 60, loss=0.0277, recon=0.0277, kl=0.0009, beta=0.0010\n",
      "Batch 80, loss=0.0300, recon=0.0300, kl=0.0015, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0365 (Recon: 0.0365, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0331 | Avg Valid recon Loss: 0.0331\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0302, recon=0.0302, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0355, recon=0.0355, kl=0.0011, beta=0.0010\n",
      "Batch 60, loss=0.0224, recon=0.0224, kl=0.0005, beta=0.0010\n",
      "Batch 80, loss=0.0429, recon=0.0429, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0357 (Recon: 0.0357, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0319 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0217, recon=0.0217, kl=0.0003, beta=0.0010\n",
      "Batch 40, loss=0.0302, recon=0.0302, kl=0.0006, beta=0.0010\n",
      "Batch 60, loss=0.0268, recon=0.0268, kl=0.0002, beta=0.0010\n",
      "Batch 80, loss=0.0494, recon=0.0494, kl=0.0014, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0353 (Recon: 0.0353, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0318\n",
      "\n",
      "[VRAE Run 180/324] Training with params: {'batch_size': 64, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1689, recon=0.1689, kl=104.4240, beta=0.0000\n",
      "Batch 40, loss=0.1152, recon=0.1152, kl=109.5130, beta=0.0000\n",
      "Batch 60, loss=0.0633, recon=0.0633, kl=101.2615, beta=0.0000\n",
      "Batch 80, loss=0.0690, recon=0.0690, kl=103.0208, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1500 (Recon: 0.1500, KL: 94.6525, Current Beta: 0.0000) | Avg Valid Loss: 0.0649 | Avg Valid recon Loss: 0.0649\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0800, recon=0.0800, kl=122.5922, beta=0.0000\n",
      "Batch 40, loss=0.0459, recon=0.0459, kl=127.4234, beta=0.0000\n",
      "Batch 60, loss=0.0431, recon=0.0431, kl=131.6407, beta=0.0000\n",
      "Batch 80, loss=0.0358, recon=0.0358, kl=120.5887, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0646 (Recon: 0.0646, KL: 124.5480, Current Beta: 0.0000) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0450\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0680, recon=0.0680, kl=152.1867, beta=0.0000\n",
      "Batch 40, loss=0.0328, recon=0.0328, kl=146.4389, beta=0.0000\n",
      "Batch 60, loss=0.0555, recon=0.0555, kl=138.4741, beta=0.0000\n",
      "Batch 80, loss=0.0315, recon=0.0315, kl=121.1808, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0515 (Recon: 0.0515, KL: 140.5778, Current Beta: 0.0000) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0242, recon=0.0242, kl=134.9384, beta=0.0000\n",
      "Batch 40, loss=0.0878, recon=0.0878, kl=69.1688, beta=0.0000\n",
      "Batch 60, loss=0.0949, recon=0.0949, kl=119.6037, beta=0.0000\n",
      "Batch 80, loss=0.0267, recon=0.0267, kl=135.8921, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0432, KL: 113.9747, Current Beta: 0.0000) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0419, recon=0.0419, kl=140.8701, beta=0.0000\n",
      "Batch 40, loss=0.0413, recon=0.0412, kl=144.5442, beta=0.0000\n",
      "Batch 60, loss=0.0239, recon=0.0239, kl=146.3636, beta=0.0000\n",
      "Batch 80, loss=0.2886, recon=0.2886, kl=150.5512, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0419, KL: 144.9180, Current Beta: 0.0000) | Avg Valid Loss: 0.0447 | Avg Valid recon Loss: 0.0447\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0300, recon=0.0299, kl=152.3208, beta=0.0000\n",
      "Batch 40, loss=0.0358, recon=0.0358, kl=149.7160, beta=0.0000\n",
      "Batch 60, loss=0.0325, recon=0.0325, kl=143.9745, beta=0.0000\n",
      "Batch 80, loss=0.0313, recon=0.0313, kl=137.8739, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0410, KL: 146.4996, Current Beta: 0.0000) | Avg Valid Loss: 0.0362 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0323, recon=0.0322, kl=113.4619, beta=0.0000\n",
      "Batch 40, loss=0.0367, recon=0.0366, kl=97.3928, beta=0.0000\n",
      "Batch 60, loss=0.0564, recon=0.0563, kl=114.8459, beta=0.0000\n",
      "Batch 80, loss=0.0348, recon=0.0347, kl=91.7328, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0404, KL: 109.9625, Current Beta: 0.0000) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0332\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0333, recon=0.0332, kl=83.2480, beta=0.0000\n",
      "Batch 40, loss=0.0280, recon=0.0279, kl=80.3832, beta=0.0000\n",
      "Batch 60, loss=0.0386, recon=0.0385, kl=77.3109, beta=0.0000\n",
      "Batch 80, loss=0.0188, recon=0.0187, kl=81.2226, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0367 (Recon: 0.0366, KL: 81.0882, Current Beta: 0.0000) | Avg Valid Loss: 0.0301 | Avg Valid recon Loss: 0.0300\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0269, recon=0.0267, kl=48.4805, beta=0.0000\n",
      "Batch 40, loss=0.0225, recon=0.0223, kl=43.9572, beta=0.0000\n",
      "Batch 60, loss=0.0260, recon=0.0258, kl=48.9450, beta=0.0000\n",
      "Batch 80, loss=0.0241, recon=0.0239, kl=42.9848, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0352, KL: 48.9053, Current Beta: 0.0000) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0328\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0231, recon=0.0228, kl=27.5935, beta=0.0000\n",
      "Batch 40, loss=0.0507, recon=0.0504, kl=26.4878, beta=0.0000\n",
      "Batch 60, loss=0.0287, recon=0.0284, kl=23.8754, beta=0.0000\n",
      "Batch 80, loss=0.0413, recon=0.0409, kl=37.6428, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0397 (Recon: 0.0393, KL: 30.2647, Current Beta: 0.0000) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0258, recon=0.0254, kl=12.6641, beta=0.0000\n",
      "Batch 40, loss=0.0389, recon=0.0386, kl=9.1421, beta=0.0000\n",
      "Batch 60, loss=0.0191, recon=0.0187, kl=12.1415, beta=0.0000\n",
      "Batch 80, loss=0.0225, recon=0.0221, kl=13.0624, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0339 (Recon: 0.0335, KL: 12.5925, Current Beta: 0.0000) | Avg Valid Loss: 0.0296 | Avg Valid recon Loss: 0.0293\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0333, recon=0.0330, kl=3.8355, beta=0.0001\n",
      "Batch 40, loss=0.0407, recon=0.0405, kl=2.6184, beta=0.0001\n",
      "Batch 60, loss=0.0298, recon=0.0295, kl=3.9528, beta=0.0001\n",
      "Batch 80, loss=0.0384, recon=0.0381, kl=3.0416, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0342 (Recon: 0.0339, KL: 3.7597, Current Beta: 0.0001) | Avg Valid Loss: 0.0308 | Avg Valid recon Loss: 0.0306\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0255, recon=0.0254, kl=0.4436, beta=0.0002\n",
      "Batch 40, loss=0.0272, recon=0.0272, kl=0.1905, beta=0.0002\n",
      "Batch 60, loss=0.0405, recon=0.0404, kl=0.3868, beta=0.0002\n",
      "Batch 80, loss=0.0353, recon=0.0353, kl=0.2352, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0348 (Recon: 0.0347, KL: 0.5401, Current Beta: 0.0002) | Avg Valid Loss: 0.0670 | Avg Valid recon Loss: 0.0669\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0345, recon=0.0345, kl=0.0702, beta=0.0004\n",
      "Batch 40, loss=0.0498, recon=0.0498, kl=0.1902, beta=0.0004\n",
      "Batch 60, loss=0.0270, recon=0.0269, kl=0.1355, beta=0.0004\n",
      "Batch 80, loss=0.0233, recon=0.0232, kl=0.0640, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0393 (Recon: 0.0393, KL: 0.1227, Current Beta: 0.0004) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0304\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0187, recon=0.0187, kl=0.0088, beta=0.0006\n",
      "Batch 40, loss=0.0616, recon=0.0616, kl=0.0097, beta=0.0006\n",
      "Batch 60, loss=0.0396, recon=0.0396, kl=0.0118, beta=0.0006\n",
      "Batch 80, loss=0.0273, recon=0.0273, kl=0.0280, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0333 (Recon: 0.0333, KL: 0.0153, Current Beta: 0.0006) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0369, recon=0.0369, kl=0.0048, beta=0.0010\n",
      "Batch 40, loss=0.0283, recon=0.0283, kl=0.0058, beta=0.0010\n",
      "Batch 60, loss=0.0297, recon=0.0296, kl=0.0092, beta=0.0010\n",
      "Batch 80, loss=0.0326, recon=0.0326, kl=0.0092, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0335 (Recon: 0.0335, KL: 0.0075, Current Beta: 0.0010) | Avg Valid Loss: 0.0313 | Avg Valid recon Loss: 0.0313\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0279, recon=0.0279, kl=0.0093, beta=0.0010\n",
      "Batch 40, loss=0.0494, recon=0.0494, kl=0.0047, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0010\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0010) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 181/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.8764, recon=0.8764, kl=0.2515, beta=0.0000\n",
      "Batch 40, loss=0.3788, recon=0.3788, kl=0.5818, beta=0.0000\n",
      "Batch 60, loss=0.3212, recon=0.3212, kl=4.6611, beta=0.0000\n",
      "Batch 80, loss=0.3111, recon=0.3111, kl=9.8735, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5064 (Recon: 0.5064, KL: 3.4829, Current Beta: 0.0000) | Avg Valid Loss: 0.3288 | Avg Valid recon Loss: 0.3288\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3503, recon=0.3503, kl=15.4295, beta=0.0000\n",
      "Batch 40, loss=0.2491, recon=0.2491, kl=17.7488, beta=0.0000\n",
      "Batch 60, loss=0.2421, recon=0.2421, kl=19.0741, beta=0.0000\n",
      "Batch 80, loss=0.2330, recon=0.2330, kl=20.4293, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2855 (Recon: 0.2855, KL: 17.6503, Current Beta: 0.0000) | Avg Valid Loss: 0.2185 | Avg Valid recon Loss: 0.2185\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2649, recon=0.2649, kl=22.4686, beta=0.0000\n",
      "Batch 40, loss=0.1654, recon=0.1654, kl=23.6057, beta=0.0000\n",
      "Batch 60, loss=0.1425, recon=0.1425, kl=24.4573, beta=0.0000\n",
      "Batch 80, loss=0.1796, recon=0.1796, kl=25.4083, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2201 (Recon: 0.2201, KL: 23.6810, Current Beta: 0.0000) | Avg Valid Loss: 0.1712 | Avg Valid recon Loss: 0.1712\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1299, recon=0.1299, kl=26.1866, beta=0.0000\n",
      "Batch 40, loss=0.1748, recon=0.1748, kl=25.8347, beta=0.0000\n",
      "Batch 60, loss=0.1819, recon=0.1818, kl=25.6687, beta=0.0000\n",
      "Batch 80, loss=0.1275, recon=0.1275, kl=25.9876, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1828 (Recon: 0.1827, KL: 25.8999, Current Beta: 0.0000) | Avg Valid Loss: 0.1430 | Avg Valid recon Loss: 0.1430\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2048, recon=0.2048, kl=24.2316, beta=0.0000\n",
      "Batch 40, loss=0.1406, recon=0.1406, kl=22.7811, beta=0.0000\n",
      "Batch 60, loss=0.1037, recon=0.1037, kl=21.4127, beta=0.0000\n",
      "Batch 80, loss=0.1073, recon=0.1073, kl=20.3500, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1563 (Recon: 0.1563, KL: 22.5667, Current Beta: 0.0000) | Avg Valid Loss: 0.1257 | Avg Valid recon Loss: 0.1257\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1344, recon=0.1344, kl=16.5918, beta=0.0000\n",
      "Batch 40, loss=0.1448, recon=0.1447, kl=13.1917, beta=0.0000\n",
      "Batch 60, loss=0.1217, recon=0.1217, kl=11.8663, beta=0.0000\n",
      "Batch 80, loss=0.1085, recon=0.1084, kl=11.3627, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1371 (Recon: 0.1371, KL: 13.9751, Current Beta: 0.0000) | Avg Valid Loss: 0.1121 | Avg Valid recon Loss: 0.1120\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0927, recon=0.0926, kl=6.4008, beta=0.0000\n",
      "Batch 40, loss=0.1079, recon=0.1079, kl=5.1778, beta=0.0000\n",
      "Batch 60, loss=0.1091, recon=0.1090, kl=4.1731, beta=0.0000\n",
      "Batch 80, loss=0.0971, recon=0.0971, kl=4.4308, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1234 (Recon: 0.1233, KL: 5.6289, Current Beta: 0.0000) | Avg Valid Loss: 0.1028 | Avg Valid recon Loss: 0.1028\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0790, recon=0.0790, kl=1.4280, beta=0.0000\n",
      "Batch 40, loss=0.0706, recon=0.0706, kl=1.3157, beta=0.0000\n",
      "Batch 60, loss=0.1694, recon=0.1694, kl=1.0351, beta=0.0000\n",
      "Batch 80, loss=0.0655, recon=0.0655, kl=1.0888, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1129 (Recon: 0.1129, KL: 1.4256, Current Beta: 0.0000) | Avg Valid Loss: 0.0946 | Avg Valid recon Loss: 0.0946\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1151, recon=0.1151, kl=0.2357, beta=0.0000\n",
      "Batch 40, loss=0.0657, recon=0.0656, kl=0.2054, beta=0.0000\n",
      "Batch 60, loss=0.1239, recon=0.1239, kl=0.1825, beta=0.0000\n",
      "Batch 80, loss=0.0997, recon=0.0997, kl=0.1580, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1034 (Recon: 0.1034, KL: 0.2607, Current Beta: 0.0000) | Avg Valid Loss: 0.0881 | Avg Valid recon Loss: 0.0881\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0712, recon=0.0712, kl=0.0263, beta=0.0001\n",
      "Batch 40, loss=0.0997, recon=0.0997, kl=0.0170, beta=0.0001\n",
      "Batch 60, loss=0.0893, recon=0.0893, kl=0.0187, beta=0.0001\n",
      "Batch 80, loss=0.0865, recon=0.0865, kl=0.0135, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0968 (Recon: 0.0968, KL: 0.0319, Current Beta: 0.0001) | Avg Valid Loss: 0.0833 | Avg Valid recon Loss: 0.0833\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1921, recon=0.1921, kl=0.0039, beta=0.0003\n",
      "Batch 40, loss=0.0706, recon=0.0706, kl=0.0023, beta=0.0003\n",
      "Batch 60, loss=0.0632, recon=0.0632, kl=0.0017, beta=0.0003\n",
      "Batch 80, loss=0.0672, recon=0.0672, kl=0.0017, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0909 (Recon: 0.0909, KL: 0.0032, Current Beta: 0.0003) | Avg Valid Loss: 0.0792 | Avg Valid recon Loss: 0.0792\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0594, recon=0.0594, kl=0.0007, beta=0.0008\n",
      "Batch 40, loss=0.0877, recon=0.0877, kl=0.0003, beta=0.0008\n",
      "Batch 60, loss=0.0677, recon=0.0677, kl=0.0004, beta=0.0008\n",
      "Batch 80, loss=0.0760, recon=0.0760, kl=0.0004, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0864 (Recon: 0.0864, KL: 0.0007, Current Beta: 0.0008) | Avg Valid Loss: 0.0761 | Avg Valid recon Loss: 0.0761\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0458, recon=0.0458, kl=0.0001, beta=0.0018\n",
      "Batch 40, loss=0.2453, recon=0.2453, kl=0.0005, beta=0.0018\n",
      "Batch 60, loss=0.0575, recon=0.0575, kl=0.0001, beta=0.0018\n",
      "Batch 80, loss=0.0666, recon=0.0666, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0824 (Recon: 0.0824, KL: 0.0002, Current Beta: 0.0018) | Avg Valid Loss: 0.0727 | Avg Valid recon Loss: 0.0727\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0515, recon=0.0515, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0750, recon=0.0750, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.0518, recon=0.0518, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0800, recon=0.0800, kl=0.0000, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0792 (Recon: 0.0792, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0704 | Avg Valid recon Loss: 0.0704\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0517, recon=0.0517, kl=0.0000, beta=0.0062\n",
      "Batch 40, loss=0.0524, recon=0.0524, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0522, recon=0.0522, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0613, recon=0.0613, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0764 (Recon: 0.0764, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0681 | Avg Valid recon Loss: 0.0681\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0493, recon=0.0493, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0554, recon=0.0554, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0520, recon=0.0520, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0772, recon=0.0772, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0739 (Recon: 0.0739, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0662 | Avg Valid recon Loss: 0.0662\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0543, recon=0.0543, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0621, recon=0.0621, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0479, recon=0.0479, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0547, recon=0.0547, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0713 (Recon: 0.0713, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0641 | Avg Valid recon Loss: 0.0641\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0522, recon=0.0522, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0630, recon=0.0630, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0661, recon=0.0661, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0505, recon=0.0505, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0698 (Recon: 0.0698, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0629 | Avg Valid recon Loss: 0.0629\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0380, recon=0.0380, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0659, recon=0.0659, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0484, recon=0.0484, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.1047, recon=0.1047, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0680 (Recon: 0.0680, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0611 | Avg Valid recon Loss: 0.0611\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0818, recon=0.0818, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0499, recon=0.0499, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0522, recon=0.0522, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0629, recon=0.0629, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0667 (Recon: 0.0667, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0599 | Avg Valid recon Loss: 0.0599\n",
      "\n",
      "[VRAE Run 182/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2469, recon=0.2469, kl=17.7147, beta=0.0000\n",
      "Batch 40, loss=0.1884, recon=0.1884, kl=23.4903, beta=0.0000\n",
      "Batch 60, loss=0.0974, recon=0.0974, kl=28.9384, beta=0.0000\n",
      "Batch 80, loss=0.1064, recon=0.1064, kl=29.5176, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2475 (Recon: 0.2475, KL: 21.8195, Current Beta: 0.0000) | Avg Valid Loss: 0.0970 | Avg Valid recon Loss: 0.0970\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0748, recon=0.0748, kl=29.6038, beta=0.0000\n",
      "Batch 40, loss=0.0687, recon=0.0687, kl=31.9838, beta=0.0000\n",
      "Batch 60, loss=0.0802, recon=0.0802, kl=33.5567, beta=0.0000\n",
      "Batch 80, loss=0.0777, recon=0.0777, kl=34.3091, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0986 (Recon: 0.0986, KL: 31.9856, Current Beta: 0.0000) | Avg Valid Loss: 0.0730 | Avg Valid recon Loss: 0.0730\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0509, recon=0.0509, kl=31.0443, beta=0.0000\n",
      "Batch 40, loss=0.0633, recon=0.0633, kl=30.7830, beta=0.0000\n",
      "Batch 60, loss=0.0793, recon=0.0793, kl=29.4235, beta=0.0000\n",
      "Batch 80, loss=0.0530, recon=0.0530, kl=27.5398, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0798 (Recon: 0.0798, KL: 30.4494, Current Beta: 0.0000) | Avg Valid Loss: 0.0637 | Avg Valid recon Loss: 0.0637\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0535, recon=0.0535, kl=27.3183, beta=0.0000\n",
      "Batch 40, loss=0.2715, recon=0.2715, kl=25.1428, beta=0.0000\n",
      "Batch 60, loss=0.0541, recon=0.0541, kl=25.2966, beta=0.0000\n",
      "Batch 80, loss=0.0601, recon=0.0601, kl=24.6643, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0690 (Recon: 0.0690, KL: 25.9887, Current Beta: 0.0000) | Avg Valid Loss: 0.0602 | Avg Valid recon Loss: 0.0602\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0502, recon=0.0502, kl=19.1810, beta=0.0000\n",
      "Batch 40, loss=0.0390, recon=0.0390, kl=16.5231, beta=0.0000\n",
      "Batch 60, loss=0.0533, recon=0.0533, kl=15.6882, beta=0.0000\n",
      "Batch 80, loss=0.1602, recon=0.1601, kl=17.0782, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0643 (Recon: 0.0643, KL: 17.8780, Current Beta: 0.0000) | Avg Valid Loss: 0.0538 | Avg Valid recon Loss: 0.0538\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1014, recon=0.1014, kl=13.4891, beta=0.0000\n",
      "Batch 40, loss=0.0411, recon=0.0410, kl=10.4388, beta=0.0000\n",
      "Batch 60, loss=0.0407, recon=0.0407, kl=10.7498, beta=0.0000\n",
      "Batch 80, loss=0.0400, recon=0.0399, kl=10.0351, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0611 (Recon: 0.0611, KL: 11.9691, Current Beta: 0.0000) | Avg Valid Loss: 0.0521 | Avg Valid recon Loss: 0.0521\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0443, recon=0.0442, kl=4.7461, beta=0.0000\n",
      "Batch 40, loss=0.0427, recon=0.0426, kl=4.4109, beta=0.0000\n",
      "Batch 60, loss=0.0408, recon=0.0408, kl=5.1224, beta=0.0000\n",
      "Batch 80, loss=0.0366, recon=0.0366, kl=4.3600, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0583 (Recon: 0.0583, KL: 5.1331, Current Beta: 0.0000) | Avg Valid Loss: 0.0494 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0397, recon=0.0397, kl=0.7100, beta=0.0000\n",
      "Batch 40, loss=0.0469, recon=0.0469, kl=0.9530, beta=0.0000\n",
      "Batch 60, loss=0.0372, recon=0.0372, kl=1.0115, beta=0.0000\n",
      "Batch 80, loss=0.1940, recon=0.1940, kl=0.4548, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0560 (Recon: 0.0560, KL: 0.9796, Current Beta: 0.0000) | Avg Valid Loss: 0.0492 | Avg Valid recon Loss: 0.0492\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0444, recon=0.0444, kl=0.1178, beta=0.0000\n",
      "Batch 40, loss=0.0944, recon=0.0944, kl=0.1362, beta=0.0000\n",
      "Batch 60, loss=0.0496, recon=0.0495, kl=0.0963, beta=0.0000\n",
      "Batch 80, loss=0.0417, recon=0.0417, kl=0.0949, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0539 (Recon: 0.0539, KL: 0.1313, Current Beta: 0.0000) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0499, recon=0.0499, kl=0.0140, beta=0.0001\n",
      "Batch 40, loss=0.0521, recon=0.0521, kl=0.0109, beta=0.0001\n",
      "Batch 60, loss=0.0409, recon=0.0409, kl=0.0048, beta=0.0001\n",
      "Batch 80, loss=0.0340, recon=0.0340, kl=0.0607, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0508, KL: 0.0186, Current Beta: 0.0001) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0465\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0383, recon=0.0383, kl=0.0050, beta=0.0003\n",
      "Batch 40, loss=0.0629, recon=0.0629, kl=0.0058, beta=0.0003\n",
      "Batch 60, loss=0.0406, recon=0.0406, kl=0.0056, beta=0.0003\n",
      "Batch 80, loss=0.0536, recon=0.0536, kl=0.0022, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0524, KL: 0.0060, Current Beta: 0.0003) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0775, recon=0.0775, kl=0.0008, beta=0.0008\n",
      "Batch 40, loss=0.0314, recon=0.0314, kl=0.0006, beta=0.0008\n",
      "Batch 60, loss=0.0523, recon=0.0523, kl=0.0016, beta=0.0008\n",
      "Batch 80, loss=0.3845, recon=0.3845, kl=0.0014, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0494, KL: 0.0011, Current Beta: 0.0008) | Avg Valid Loss: 0.0498 | Avg Valid recon Loss: 0.0498\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0331, recon=0.0331, kl=0.0005, beta=0.0018\n",
      "Batch 40, loss=0.0380, recon=0.0380, kl=0.0009, beta=0.0018\n",
      "Batch 60, loss=0.0366, recon=0.0366, kl=0.0004, beta=0.0018\n",
      "Batch 80, loss=0.0340, recon=0.0340, kl=0.0003, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0512 (Recon: 0.0512, KL: 0.0011, Current Beta: 0.0018) | Avg Valid Loss: 0.0467 | Avg Valid recon Loss: 0.0467\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0340, recon=0.0340, kl=0.0002, beta=0.0038\n",
      "Batch 40, loss=0.0486, recon=0.0486, kl=0.0005, beta=0.0038\n",
      "Batch 60, loss=0.0812, recon=0.0812, kl=0.0003, beta=0.0038\n",
      "Batch 80, loss=0.0337, recon=0.0337, kl=0.0003, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0483 (Recon: 0.0483, KL: 0.0008, Current Beta: 0.0038) | Avg Valid Loss: 0.0416 | Avg Valid recon Loss: 0.0416\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0549, recon=0.0549, kl=0.0000, beta=0.0062\n",
      "Batch 40, loss=0.0384, recon=0.0384, kl=0.0006, beta=0.0062\n",
      "Batch 60, loss=0.0316, recon=0.0316, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0404, recon=0.0404, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0474 (Recon: 0.0474, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0555 | Avg Valid recon Loss: 0.0555\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0442, recon=0.0442, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0349, recon=0.0349, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0503, recon=0.0503, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.3959, recon=0.3959, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0526 (Recon: 0.0526, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0497 | Avg Valid recon Loss: 0.0497\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0413, recon=0.0413, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0612, recon=0.0612, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0572, recon=0.0572, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0346, recon=0.0346, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0575 (Recon: 0.0575, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0376, recon=0.0376, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0353, recon=0.0353, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0450, recon=0.0450, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0385, recon=0.0385, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0516, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0443, recon=0.0443, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0814, recon=0.0814, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0325, recon=0.0325, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0368, recon=0.0368, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0479, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0459 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0559, recon=0.0559, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0359, recon=0.0359, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0347, recon=0.0347, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0335, recon=0.0335, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0499 (Recon: 0.0499, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0421\n",
      "\n",
      "[VRAE Run 183/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7105, recon=0.7105, kl=0.3830, beta=0.0000\n",
      "Batch 40, loss=0.5654, recon=0.5654, kl=0.7685, beta=0.0000\n",
      "Batch 60, loss=0.3641, recon=0.3641, kl=6.9783, beta=0.0000\n",
      "Batch 80, loss=0.3139, recon=0.3139, kl=22.2786, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6326 (Recon: 0.6326, KL: 7.0441, Current Beta: 0.0000) | Avg Valid Loss: 0.3944 | Avg Valid recon Loss: 0.3944\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3675, recon=0.3675, kl=36.6811, beta=0.0000\n",
      "Batch 40, loss=0.2548, recon=0.2548, kl=40.1372, beta=0.0000\n",
      "Batch 60, loss=0.2832, recon=0.2832, kl=41.9129, beta=0.0000\n",
      "Batch 80, loss=0.2726, recon=0.2726, kl=43.8549, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3222 (Recon: 0.3222, KL: 39.6583, Current Beta: 0.0000) | Avg Valid Loss: 0.2481 | Avg Valid recon Loss: 0.2481\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1869, recon=0.1869, kl=45.1980, beta=0.0000\n",
      "Batch 40, loss=0.4223, recon=0.4223, kl=45.9915, beta=0.0000\n",
      "Batch 60, loss=0.2501, recon=0.2501, kl=46.9709, beta=0.0000\n",
      "Batch 80, loss=0.1672, recon=0.1672, kl=48.6982, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2386 (Recon: 0.2386, KL: 46.5469, Current Beta: 0.0000) | Avg Valid Loss: 0.1870 | Avg Valid recon Loss: 0.1870\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1902, recon=0.1902, kl=48.0909, beta=0.0000\n",
      "Batch 40, loss=0.1992, recon=0.1992, kl=47.4202, beta=0.0000\n",
      "Batch 60, loss=0.1258, recon=0.1258, kl=46.2468, beta=0.0000\n",
      "Batch 80, loss=0.1017, recon=0.1017, kl=45.1586, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1956 (Recon: 0.1956, KL: 46.8777, Current Beta: 0.0000) | Avg Valid Loss: 0.1549 | Avg Valid recon Loss: 0.1549\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1480, recon=0.1480, kl=39.4937, beta=0.0000\n",
      "Batch 40, loss=0.1540, recon=0.1540, kl=35.0473, beta=0.0000\n",
      "Batch 60, loss=0.0882, recon=0.0882, kl=30.2598, beta=0.0000\n",
      "Batch 80, loss=0.1515, recon=0.1515, kl=28.2567, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1672 (Recon: 0.1671, KL: 34.2689, Current Beta: 0.0000) | Avg Valid Loss: 0.1342 | Avg Valid recon Loss: 0.1341\n",
      "Epoch 6/20\n",
      "Batch 20, loss=1.0824, recon=1.0824, kl=19.8020, beta=0.0000\n",
      "Batch 40, loss=0.1423, recon=0.1423, kl=16.1958, beta=0.0000\n",
      "Batch 60, loss=0.1157, recon=0.1157, kl=13.8667, beta=0.0000\n",
      "Batch 80, loss=0.1217, recon=0.1217, kl=12.3193, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1467 (Recon: 0.1467, KL: 16.7505, Current Beta: 0.0000) | Avg Valid Loss: 0.1195 | Avg Valid recon Loss: 0.1194\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1020, recon=0.1019, kl=5.2115, beta=0.0000\n",
      "Batch 40, loss=0.0959, recon=0.0958, kl=6.2613, beta=0.0000\n",
      "Batch 60, loss=0.0991, recon=0.0991, kl=4.2639, beta=0.0000\n",
      "Batch 80, loss=1.0322, recon=1.0321, kl=4.3518, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1317 (Recon: 0.1316, KL: 5.7305, Current Beta: 0.0000) | Avg Valid Loss: 0.1089 | Avg Valid recon Loss: 0.1089\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1103, recon=0.1103, kl=1.4931, beta=0.0000\n",
      "Batch 40, loss=0.1271, recon=0.1270, kl=1.7205, beta=0.0000\n",
      "Batch 60, loss=0.3739, recon=0.3738, kl=1.1057, beta=0.0000\n",
      "Batch 80, loss=0.1392, recon=0.1392, kl=1.2961, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1205 (Recon: 0.1205, KL: 1.6024, Current Beta: 0.0000) | Avg Valid Loss: 0.1013 | Avg Valid recon Loss: 0.1013\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1031, recon=0.1031, kl=0.2629, beta=0.0000\n",
      "Batch 40, loss=0.9441, recon=0.9441, kl=0.3464, beta=0.0000\n",
      "Batch 60, loss=0.0833, recon=0.0833, kl=0.2838, beta=0.0000\n",
      "Batch 80, loss=0.1092, recon=0.1092, kl=0.2905, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1120 (Recon: 0.1120, KL: 0.3729, Current Beta: 0.0000) | Avg Valid Loss: 0.0947 | Avg Valid recon Loss: 0.0947\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0720, recon=0.0720, kl=0.0493, beta=0.0001\n",
      "Batch 40, loss=0.1091, recon=0.1091, kl=0.0531, beta=0.0001\n",
      "Batch 60, loss=0.1188, recon=0.1188, kl=0.0364, beta=0.0001\n",
      "Batch 80, loss=0.0635, recon=0.0635, kl=0.0319, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1043 (Recon: 0.1043, KL: 0.0589, Current Beta: 0.0001) | Avg Valid Loss: 0.0896 | Avg Valid recon Loss: 0.0896\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0722, recon=0.0722, kl=0.0038, beta=0.0003\n",
      "Batch 40, loss=0.0933, recon=0.0933, kl=0.0056, beta=0.0003\n",
      "Batch 60, loss=0.0795, recon=0.0795, kl=0.0030, beta=0.0003\n",
      "Batch 80, loss=0.1069, recon=0.1069, kl=0.0024, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0982 (Recon: 0.0982, KL: 0.0058, Current Beta: 0.0003) | Avg Valid Loss: 0.0855 | Avg Valid recon Loss: 0.0855\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0565, recon=0.0565, kl=0.0007, beta=0.0008\n",
      "Batch 40, loss=0.1345, recon=0.1345, kl=0.0018, beta=0.0008\n",
      "Batch 60, loss=0.0822, recon=0.0822, kl=0.0005, beta=0.0008\n",
      "Batch 80, loss=0.0569, recon=0.0569, kl=0.0009, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0933 (Recon: 0.0933, KL: 0.0011, Current Beta: 0.0008) | Avg Valid Loss: 0.0816 | Avg Valid recon Loss: 0.0816\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0511, recon=0.0511, kl=0.0003, beta=0.0018\n",
      "Batch 40, loss=0.0576, recon=0.0576, kl=0.0002, beta=0.0018\n",
      "Batch 60, loss=0.0604, recon=0.0604, kl=0.0001, beta=0.0018\n",
      "Batch 80, loss=0.0727, recon=0.0727, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0890 (Recon: 0.0890, KL: 0.0004, Current Beta: 0.0018) | Avg Valid Loss: 0.0792 | Avg Valid recon Loss: 0.0792\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0761, recon=0.0761, kl=0.0002, beta=0.0038\n",
      "Batch 40, loss=0.0729, recon=0.0729, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.1276, recon=0.1276, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0749, recon=0.0749, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0852 (Recon: 0.0852, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0759 | Avg Valid recon Loss: 0.0758\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1080, recon=0.1080, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0866, recon=0.0866, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.2578, recon=0.2578, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0667, recon=0.0667, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0823 (Recon: 0.0823, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0733 | Avg Valid recon Loss: 0.0733\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1045, recon=0.1045, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0686, recon=0.0686, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0584, recon=0.0584, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0491, recon=0.0491, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0791 (Recon: 0.0791, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0703 | Avg Valid recon Loss: 0.0703\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0512, recon=0.0512, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0770, recon=0.0770, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0649, recon=0.0649, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0721, recon=0.0721, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0767 (Recon: 0.0767, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0687 | Avg Valid recon Loss: 0.0687\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0509, recon=0.0509, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0556, recon=0.0556, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0398, recon=0.0398, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.1037, recon=0.1037, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0749 (Recon: 0.0749, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0670 | Avg Valid recon Loss: 0.0670\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0675, recon=0.0675, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0637, recon=0.0637, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0666, recon=0.0666, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0718, recon=0.0718, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0728 (Recon: 0.0728, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0654 | Avg Valid recon Loss: 0.0654\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0432, recon=0.0432, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0579, recon=0.0579, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0459, recon=0.0459, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0529, recon=0.0529, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0709 (Recon: 0.0709, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0645 | Avg Valid recon Loss: 0.0645\n",
      "\n",
      "[VRAE Run 184/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2736, recon=0.2736, kl=38.3898, beta=0.0000\n",
      "Batch 40, loss=0.1499, recon=0.1499, kl=44.4728, beta=0.0000\n",
      "Batch 60, loss=0.1116, recon=0.1116, kl=52.3136, beta=0.0000\n",
      "Batch 80, loss=0.0957, recon=0.0957, kl=51.3952, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2452 (Recon: 0.2452, KL: 41.4076, Current Beta: 0.0000) | Avg Valid Loss: 0.0997 | Avg Valid recon Loss: 0.0997\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1631, recon=0.1631, kl=52.7393, beta=0.0000\n",
      "Batch 40, loss=0.0926, recon=0.0926, kl=52.0465, beta=0.0000\n",
      "Batch 60, loss=0.0781, recon=0.0781, kl=61.7409, beta=0.0000\n",
      "Batch 80, loss=0.0537, recon=0.0537, kl=62.1075, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0967 (Recon: 0.0967, KL: 56.1069, Current Beta: 0.0000) | Avg Valid Loss: 0.0723 | Avg Valid recon Loss: 0.0723\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0475, recon=0.0475, kl=57.9560, beta=0.0000\n",
      "Batch 40, loss=0.0559, recon=0.0559, kl=57.3576, beta=0.0000\n",
      "Batch 60, loss=0.0622, recon=0.0622, kl=51.0942, beta=0.0000\n",
      "Batch 80, loss=0.1339, recon=0.1339, kl=54.3194, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0758 (Recon: 0.0758, KL: 55.7006, Current Beta: 0.0000) | Avg Valid Loss: 0.0650 | Avg Valid recon Loss: 0.0650\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0553, recon=0.0553, kl=50.9482, beta=0.0000\n",
      "Batch 40, loss=0.0578, recon=0.0577, kl=47.4775, beta=0.0000\n",
      "Batch 60, loss=0.0519, recon=0.0519, kl=42.7505, beta=0.0000\n",
      "Batch 80, loss=0.0565, recon=0.0565, kl=38.8261, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0682 (Recon: 0.0682, KL: 45.6086, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0406, recon=0.0405, kl=32.4888, beta=0.0000\n",
      "Batch 40, loss=0.0426, recon=0.0426, kl=27.8888, beta=0.0000\n",
      "Batch 60, loss=0.0773, recon=0.0773, kl=26.3181, beta=0.0000\n",
      "Batch 80, loss=0.0493, recon=0.0493, kl=26.2035, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0628 (Recon: 0.0627, KL: 29.4660, Current Beta: 0.0000) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0566\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0520, recon=0.0519, kl=16.2001, beta=0.0000\n",
      "Batch 40, loss=0.0488, recon=0.0487, kl=16.0371, beta=0.0000\n",
      "Batch 60, loss=0.0585, recon=0.0585, kl=16.0977, beta=0.0000\n",
      "Batch 80, loss=0.0597, recon=0.0597, kl=16.3677, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0600 (Recon: 0.0599, KL: 17.4478, Current Beta: 0.0000) | Avg Valid Loss: 0.0533 | Avg Valid recon Loss: 0.0533\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0457, recon=0.0457, kl=6.9464, beta=0.0000\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=6.1699, beta=0.0000\n",
      "Batch 60, loss=0.0795, recon=0.0794, kl=4.9381, beta=0.0000\n",
      "Batch 80, loss=0.0851, recon=0.0850, kl=5.0430, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0575 (Recon: 0.0575, KL: 7.1028, Current Beta: 0.0000) | Avg Valid Loss: 0.0484 | Avg Valid recon Loss: 0.0484\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0383, recon=0.0383, kl=1.2526, beta=0.0000\n",
      "Batch 40, loss=0.0391, recon=0.0390, kl=1.6465, beta=0.0000\n",
      "Batch 60, loss=0.0374, recon=0.0373, kl=2.4717, beta=0.0000\n",
      "Batch 80, loss=0.0588, recon=0.0588, kl=0.8546, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0553 (Recon: 0.0553, KL: 1.7948, Current Beta: 0.0000) | Avg Valid Loss: 0.0506 | Avg Valid recon Loss: 0.0506\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0567, recon=0.0566, kl=0.1029, beta=0.0000\n",
      "Batch 40, loss=0.0532, recon=0.0531, kl=0.6888, beta=0.0000\n",
      "Batch 60, loss=0.0513, recon=0.0513, kl=0.2437, beta=0.0000\n",
      "Batch 80, loss=0.0403, recon=0.0403, kl=0.2154, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0565 (Recon: 0.0565, KL: 0.3244, Current Beta: 0.0000) | Avg Valid Loss: 0.0492 | Avg Valid recon Loss: 0.0491\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=0.0156, beta=0.0001\n",
      "Batch 40, loss=0.0406, recon=0.0406, kl=0.0211, beta=0.0001\n",
      "Batch 60, loss=0.0392, recon=0.0392, kl=0.0252, beta=0.0001\n",
      "Batch 80, loss=0.0667, recon=0.0667, kl=0.0144, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0545, KL: 0.0560, Current Beta: 0.0001) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0472\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0358, recon=0.0358, kl=0.0101, beta=0.0003\n",
      "Batch 40, loss=0.0438, recon=0.0438, kl=0.0021, beta=0.0003\n",
      "Batch 60, loss=0.0392, recon=0.0392, kl=0.0037, beta=0.0003\n",
      "Batch 80, loss=0.0452, recon=0.0452, kl=0.0026, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0518, KL: 0.0058, Current Beta: 0.0003) | Avg Valid Loss: 0.0523 | Avg Valid recon Loss: 0.0523\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0487, recon=0.0487, kl=0.0020, beta=0.0008\n",
      "Batch 40, loss=0.0452, recon=0.0452, kl=0.0016, beta=0.0008\n",
      "Batch 60, loss=0.0362, recon=0.0362, kl=0.0040, beta=0.0008\n",
      "Batch 80, loss=0.0384, recon=0.0384, kl=0.0012, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0533, KL: 0.0019, Current Beta: 0.0008) | Avg Valid Loss: 0.0503 | Avg Valid recon Loss: 0.0503\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0370, recon=0.0370, kl=0.0020, beta=0.0018\n",
      "Batch 40, loss=0.1022, recon=0.1022, kl=0.0002, beta=0.0018\n",
      "Batch 60, loss=0.0450, recon=0.0450, kl=0.0003, beta=0.0018\n",
      "Batch 80, loss=0.0392, recon=0.0392, kl=0.0010, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0520 (Recon: 0.0520, KL: 0.0006, Current Beta: 0.0018) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0456\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0429, recon=0.0429, kl=0.0004, beta=0.0038\n",
      "Batch 40, loss=0.0282, recon=0.0282, kl=0.0004, beta=0.0038\n",
      "Batch 60, loss=0.0428, recon=0.0428, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0681, recon=0.0681, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0500 (Recon: 0.0500, KL: 0.0004, Current Beta: 0.0038) | Avg Valid Loss: 0.0427 | Avg Valid recon Loss: 0.0427\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0475, recon=0.0475, kl=0.0003, beta=0.0062\n",
      "Batch 40, loss=0.0394, recon=0.0394, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0446, recon=0.0446, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0449, recon=0.0449, kl=0.0002, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0490 (Recon: 0.0490, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0883, recon=0.0883, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0977, recon=0.0977, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0376, recon=0.0376, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0331, recon=0.0331, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0475 (Recon: 0.0475, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0392, recon=0.0392, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0338, recon=0.0338, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0298, recon=0.0298, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0363, recon=0.0363, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0480, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0463 | Avg Valid recon Loss: 0.0462\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0745, recon=0.0745, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0418, recon=0.0418, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.1079, recon=0.1079, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0428, recon=0.0428, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0478 (Recon: 0.0478, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0376, recon=0.0376, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0241, recon=0.0241, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0408, recon=0.0407, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0411, recon=0.0411, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0455, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0386 | Avg Valid recon Loss: 0.0386\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0417, recon=0.0417, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0400, recon=0.0400, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0305, recon=0.0305, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0369, recon=0.0369, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0447 (Recon: 0.0447, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0419 | Avg Valid recon Loss: 0.0419\n",
      "\n",
      "[VRAE Run 185/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6617, recon=0.6617, kl=0.6391, beta=0.0000\n",
      "Batch 40, loss=0.4395, recon=0.4395, kl=1.4333, beta=0.0000\n",
      "Batch 60, loss=0.3935, recon=0.3935, kl=15.5688, beta=0.0000\n",
      "Batch 80, loss=0.2960, recon=0.2960, kl=39.4160, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5447 (Recon: 0.5447, KL: 13.0228, Current Beta: 0.0000) | Avg Valid Loss: 0.3448 | Avg Valid recon Loss: 0.3448\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2660, recon=0.2660, kl=61.9490, beta=0.0000\n",
      "Batch 40, loss=1.3764, recon=1.3764, kl=70.5473, beta=0.0000\n",
      "Batch 60, loss=0.2081, recon=0.2081, kl=76.3988, beta=0.0000\n",
      "Batch 80, loss=0.1790, recon=0.1790, kl=81.0291, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2927 (Recon: 0.2927, KL: 70.3967, Current Beta: 0.0000) | Avg Valid Loss: 0.2264 | Avg Valid recon Loss: 0.2264\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2824, recon=0.2823, kl=84.3940, beta=0.0000\n",
      "Batch 40, loss=0.2106, recon=0.2106, kl=85.1656, beta=0.0000\n",
      "Batch 60, loss=0.2432, recon=0.2432, kl=86.1049, beta=0.0000\n",
      "Batch 80, loss=0.2311, recon=0.2311, kl=87.7950, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2251 (Recon: 0.2251, KL: 85.6033, Current Beta: 0.0000) | Avg Valid Loss: 0.1740 | Avg Valid recon Loss: 0.1740\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1421, recon=0.1421, kl=85.7022, beta=0.0000\n",
      "Batch 40, loss=0.1668, recon=0.1668, kl=82.3565, beta=0.0000\n",
      "Batch 60, loss=0.2239, recon=0.2239, kl=78.1642, beta=0.0000\n",
      "Batch 80, loss=0.1781, recon=0.1781, kl=77.0735, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1878 (Recon: 0.1878, KL: 81.6005, Current Beta: 0.0000) | Avg Valid Loss: 0.1460 | Avg Valid recon Loss: 0.1460\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1611, recon=0.1611, kl=67.0560, beta=0.0000\n",
      "Batch 40, loss=0.1348, recon=0.1348, kl=54.2938, beta=0.0000\n",
      "Batch 60, loss=0.1644, recon=0.1643, kl=46.9342, beta=0.0000\n",
      "Batch 80, loss=0.1091, recon=0.1091, kl=44.3142, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1622 (Recon: 0.1621, KL: 55.6309, Current Beta: 0.0000) | Avg Valid Loss: 0.1261 | Avg Valid recon Loss: 0.1261\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1083, recon=0.1082, kl=29.6060, beta=0.0000\n",
      "Batch 40, loss=0.1259, recon=0.1258, kl=20.4921, beta=0.0000\n",
      "Batch 60, loss=0.1430, recon=0.1430, kl=18.9356, beta=0.0000\n",
      "Batch 80, loss=0.1382, recon=0.1381, kl=19.7318, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1394 (Recon: 0.1393, KL: 24.3147, Current Beta: 0.0000) | Avg Valid Loss: 0.1129 | Avg Valid recon Loss: 0.1129\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.4503, recon=0.4502, kl=8.4123, beta=0.0000\n",
      "Batch 40, loss=0.1267, recon=0.1266, kl=6.4651, beta=0.0000\n",
      "Batch 60, loss=0.0622, recon=0.0621, kl=6.9899, beta=0.0000\n",
      "Batch 80, loss=0.0970, recon=0.0970, kl=5.5576, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1280 (Recon: 0.1279, KL: 7.7240, Current Beta: 0.0000) | Avg Valid Loss: 0.1027 | Avg Valid recon Loss: 0.1027\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0665, recon=0.0664, kl=2.0453, beta=0.0000\n",
      "Batch 40, loss=0.1221, recon=0.1221, kl=1.9470, beta=0.0000\n",
      "Batch 60, loss=0.0913, recon=0.0913, kl=2.1043, beta=0.0000\n",
      "Batch 80, loss=0.0841, recon=0.0841, kl=1.6332, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1169 (Recon: 0.1169, KL: 2.1791, Current Beta: 0.0000) | Avg Valid Loss: 0.0950 | Avg Valid recon Loss: 0.0950\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0810, recon=0.0809, kl=0.6923, beta=0.0000\n",
      "Batch 40, loss=0.1168, recon=0.1168, kl=0.5966, beta=0.0000\n",
      "Batch 60, loss=0.0610, recon=0.0610, kl=0.4179, beta=0.0000\n",
      "Batch 80, loss=0.3428, recon=0.3428, kl=0.4101, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1081 (Recon: 0.1081, KL: 0.6131, Current Beta: 0.0000) | Avg Valid Loss: 0.0884 | Avg Valid recon Loss: 0.0883\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0765, recon=0.0765, kl=0.1079, beta=0.0001\n",
      "Batch 40, loss=0.1120, recon=0.1120, kl=0.1137, beta=0.0001\n",
      "Batch 60, loss=0.0740, recon=0.0739, kl=0.0590, beta=0.0001\n",
      "Batch 80, loss=0.0811, recon=0.0811, kl=0.0430, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1002 (Recon: 0.1002, KL: 0.1033, Current Beta: 0.0001) | Avg Valid Loss: 0.0839 | Avg Valid recon Loss: 0.0839\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1033, recon=0.1033, kl=0.0055, beta=0.0003\n",
      "Batch 40, loss=0.1292, recon=0.1292, kl=0.0047, beta=0.0003\n",
      "Batch 60, loss=0.0729, recon=0.0729, kl=0.0047, beta=0.0003\n",
      "Batch 80, loss=0.0493, recon=0.0493, kl=0.0040, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0949 (Recon: 0.0949, KL: 0.0087, Current Beta: 0.0003) | Avg Valid Loss: 0.0793 | Avg Valid recon Loss: 0.0793\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0828, recon=0.0828, kl=0.0011, beta=0.0008\n",
      "Batch 40, loss=0.0709, recon=0.0709, kl=0.0008, beta=0.0008\n",
      "Batch 60, loss=0.0526, recon=0.0526, kl=0.0004, beta=0.0008\n",
      "Batch 80, loss=0.2896, recon=0.2896, kl=0.0010, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0894 (Recon: 0.0894, KL: 0.0009, Current Beta: 0.0008) | Avg Valid Loss: 0.0765 | Avg Valid recon Loss: 0.0765\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0616, recon=0.0616, kl=0.0002, beta=0.0018\n",
      "Batch 40, loss=0.1065, recon=0.1065, kl=0.0001, beta=0.0018\n",
      "Batch 60, loss=0.0524, recon=0.0524, kl=0.0002, beta=0.0018\n",
      "Batch 80, loss=0.0438, recon=0.0438, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0857 (Recon: 0.0857, KL: 0.0002, Current Beta: 0.0018) | Avg Valid Loss: 0.0734 | Avg Valid recon Loss: 0.0734\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0662, recon=0.0662, kl=0.0000, beta=0.0038\n",
      "Batch 40, loss=0.0670, recon=0.0670, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.0621, recon=0.0621, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0466, recon=0.0466, kl=0.0000, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0820 (Recon: 0.0820, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0709 | Avg Valid recon Loss: 0.0709\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1170, recon=0.1170, kl=0.0006, beta=0.0062\n",
      "Batch 40, loss=0.0569, recon=0.0569, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0845, recon=0.0845, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0742, recon=0.0742, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0789 (Recon: 0.0789, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0686 | Avg Valid recon Loss: 0.0686\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0523, recon=0.0523, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0494, recon=0.0494, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0990, recon=0.0989, kl=0.0010, beta=0.0100\n",
      "Batch 80, loss=0.0567, recon=0.0567, kl=0.0004, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0758 (Recon: 0.0758, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0671 | Avg Valid recon Loss: 0.0671\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0589, recon=0.0589, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0393, recon=0.0393, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.1748, recon=0.1748, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0440, recon=0.0440, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0739 (Recon: 0.0739, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0647 | Avg Valid recon Loss: 0.0647\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0531, recon=0.0531, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0850, recon=0.0850, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0513, recon=0.0513, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0513, recon=0.0513, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0717 (Recon: 0.0717, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0634 | Avg Valid recon Loss: 0.0634\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0745, recon=0.0745, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0670, recon=0.0670, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0396, recon=0.0396, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0392, recon=0.0392, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0697 (Recon: 0.0697, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0628 | Avg Valid recon Loss: 0.0628\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0602, recon=0.0602, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0460, recon=0.0460, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0749, recon=0.0749, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0393, recon=0.0393, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0682 (Recon: 0.0682, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0606 | Avg Valid recon Loss: 0.0606\n",
      "\n",
      "[VRAE Run 186/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7935, recon=0.7935, kl=72.5581, beta=0.0000\n",
      "Batch 40, loss=0.1763, recon=0.1763, kl=82.4240, beta=0.0000\n",
      "Batch 60, loss=0.1120, recon=0.1120, kl=87.3249, beta=0.0000\n",
      "Batch 80, loss=0.1558, recon=0.1558, kl=78.9771, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2424 (Recon: 0.2424, KL: 70.8984, Current Beta: 0.0000) | Avg Valid Loss: 0.0992 | Avg Valid recon Loss: 0.0992\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1629, recon=0.1629, kl=94.4647, beta=0.0000\n",
      "Batch 40, loss=0.0854, recon=0.0854, kl=108.7648, beta=0.0000\n",
      "Batch 60, loss=0.0961, recon=0.0961, kl=104.4831, beta=0.0000\n",
      "Batch 80, loss=0.0671, recon=0.0671, kl=110.8764, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0989 (Recon: 0.0989, KL: 101.5508, Current Beta: 0.0000) | Avg Valid Loss: 0.0751 | Avg Valid recon Loss: 0.0751\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0568, recon=0.0568, kl=94.1730, beta=0.0000\n",
      "Batch 40, loss=0.0580, recon=0.0580, kl=83.9922, beta=0.0000\n",
      "Batch 60, loss=0.0760, recon=0.0760, kl=94.1836, beta=0.0000\n",
      "Batch 80, loss=0.0482, recon=0.0482, kl=92.5199, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0778 (Recon: 0.0778, KL: 93.1280, Current Beta: 0.0000) | Avg Valid Loss: 0.0644 | Avg Valid recon Loss: 0.0644\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=80.7601, beta=0.0000\n",
      "Batch 40, loss=0.0871, recon=0.0871, kl=75.1882, beta=0.0000\n",
      "Batch 60, loss=0.0544, recon=0.0544, kl=78.8867, beta=0.0000\n",
      "Batch 80, loss=0.0412, recon=0.0411, kl=89.2256, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0705 (Recon: 0.0705, KL: 81.2956, Current Beta: 0.0000) | Avg Valid Loss: 0.0576 | Avg Valid recon Loss: 0.0576\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0570, recon=0.0570, kl=56.9097, beta=0.0000\n",
      "Batch 40, loss=0.0604, recon=0.0604, kl=47.7027, beta=0.0000\n",
      "Batch 60, loss=0.5979, recon=0.5978, kl=47.6844, beta=0.0000\n",
      "Batch 80, loss=0.0505, recon=0.0504, kl=55.0110, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0642 (Recon: 0.0642, KL: 55.8944, Current Beta: 0.0000) | Avg Valid Loss: 0.0538 | Avg Valid recon Loss: 0.0538\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0399, recon=0.0399, kl=27.5492, beta=0.0000\n",
      "Batch 40, loss=0.0533, recon=0.0533, kl=28.9205, beta=0.0000\n",
      "Batch 60, loss=0.0589, recon=0.0589, kl=38.0171, beta=0.0000\n",
      "Batch 80, loss=0.0781, recon=0.0781, kl=39.8297, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0600 (Recon: 0.0599, KL: 35.5586, Current Beta: 0.0000) | Avg Valid Loss: 0.0517 | Avg Valid recon Loss: 0.0517\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0361, recon=0.0360, kl=10.3092, beta=0.0000\n",
      "Batch 40, loss=0.0449, recon=0.0448, kl=18.9175, beta=0.0000\n",
      "Batch 60, loss=0.0400, recon=0.0399, kl=17.0429, beta=0.0000\n",
      "Batch 80, loss=0.0431, recon=0.0430, kl=14.1425, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0592 (Recon: 0.0591, KL: 16.5609, Current Beta: 0.0000) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0407, recon=0.0407, kl=3.4466, beta=0.0000\n",
      "Batch 40, loss=0.0664, recon=0.0663, kl=5.2065, beta=0.0000\n",
      "Batch 60, loss=0.0439, recon=0.0438, kl=7.3645, beta=0.0000\n",
      "Batch 80, loss=0.0650, recon=0.0649, kl=6.7237, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0566 (Recon: 0.0565, KL: 6.7478, Current Beta: 0.0000) | Avg Valid Loss: 0.0578 | Avg Valid recon Loss: 0.0577\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0396, recon=0.0396, kl=0.6778, beta=0.0000\n",
      "Batch 40, loss=0.0442, recon=0.0441, kl=1.1162, beta=0.0000\n",
      "Batch 60, loss=0.0427, recon=0.0426, kl=1.9861, beta=0.0000\n",
      "Batch 80, loss=0.1011, recon=0.1010, kl=0.8726, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0583 (Recon: 0.0583, KL: 1.6390, Current Beta: 0.0000) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=0.0515, beta=0.0001\n",
      "Batch 40, loss=0.0385, recon=0.0385, kl=0.2120, beta=0.0001\n",
      "Batch 60, loss=0.0674, recon=0.0674, kl=0.0503, beta=0.0001\n",
      "Batch 80, loss=0.0747, recon=0.0746, kl=0.0516, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0539 (Recon: 0.0539, KL: 0.1186, Current Beta: 0.0001) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0472\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0333, recon=0.0333, kl=0.0121, beta=0.0003\n",
      "Batch 40, loss=0.0317, recon=0.0317, kl=0.0142, beta=0.0003\n",
      "Batch 60, loss=0.0539, recon=0.0539, kl=0.0072, beta=0.0003\n",
      "Batch 80, loss=0.0336, recon=0.0336, kl=0.0107, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 0.0188, Current Beta: 0.0003) | Avg Valid Loss: 0.0500 | Avg Valid recon Loss: 0.0500\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0703, recon=0.0703, kl=0.0037, beta=0.0008\n",
      "Batch 40, loss=0.0437, recon=0.0437, kl=0.0014, beta=0.0008\n",
      "Batch 60, loss=0.0327, recon=0.0327, kl=0.0017, beta=0.0008\n",
      "Batch 80, loss=0.0327, recon=0.0327, kl=0.0020, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0518, KL: 0.0024, Current Beta: 0.0008) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0432, recon=0.0432, kl=0.0016, beta=0.0018\n",
      "Batch 40, loss=0.0927, recon=0.0927, kl=0.0009, beta=0.0018\n",
      "Batch 60, loss=0.0914, recon=0.0914, kl=0.0010, beta=0.0018\n",
      "Batch 80, loss=0.0384, recon=0.0384, kl=0.0009, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0501 (Recon: 0.0501, KL: 0.0016, Current Beta: 0.0018) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0931, recon=0.0931, kl=0.0006, beta=0.0038\n",
      "Batch 40, loss=0.0322, recon=0.0322, kl=0.0006, beta=0.0038\n",
      "Batch 60, loss=0.0325, recon=0.0325, kl=0.0007, beta=0.0038\n",
      "Batch 80, loss=0.0397, recon=0.0397, kl=0.0003, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 0.0009, Current Beta: 0.0038) | Avg Valid Loss: 0.0446 | Avg Valid recon Loss: 0.0446\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0274, recon=0.0274, kl=0.0003, beta=0.0062\n",
      "Batch 40, loss=0.0555, recon=0.0555, kl=0.0003, beta=0.0062\n",
      "Batch 60, loss=0.0352, recon=0.0352, kl=0.0003, beta=0.0062\n",
      "Batch 80, loss=0.0419, recon=0.0419, kl=0.0002, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0498 (Recon: 0.0498, KL: 0.0007, Current Beta: 0.0062) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=0.0005, beta=0.0100\n",
      "Batch 40, loss=0.0327, recon=0.0327, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0282, recon=0.0282, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0382, recon=0.0382, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0472, KL: 0.0008, Current Beta: 0.0100) | Avg Valid Loss: 0.0459 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0387, recon=0.0387, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0341, recon=0.0341, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0440, recon=0.0440, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0316, recon=0.0316, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0476 (Recon: 0.0476, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0365, recon=0.0365, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0729, recon=0.0729, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0539, recon=0.0539, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0818, recon=0.0818, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0453 (Recon: 0.0453, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0437 | Avg Valid recon Loss: 0.0437\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0382, recon=0.0382, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0377, recon=0.0377, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0461, recon=0.0461, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0337, recon=0.0337, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0481 (Recon: 0.0481, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0386\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0547, recon=0.0547, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0670, recon=0.0670, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0341, recon=0.0341, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0300, recon=0.0300, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0457, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0394\n",
      "\n",
      "[VRAE Run 187/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6056, recon=0.6056, kl=0.2713, beta=0.0000\n",
      "Batch 40, loss=0.3210, recon=0.3210, kl=3.2510, beta=0.0000\n",
      "Batch 60, loss=0.2445, recon=0.2445, kl=14.1304, beta=0.0000\n",
      "Batch 80, loss=0.2091, recon=0.2091, kl=20.5566, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4485 (Recon: 0.4485, KL: 8.7854, Current Beta: 0.0000) | Avg Valid Loss: 0.2269 | Avg Valid recon Loss: 0.2269\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1891, recon=0.1891, kl=25.7329, beta=0.0000\n",
      "Batch 40, loss=0.1506, recon=0.1506, kl=29.4817, beta=0.0000\n",
      "Batch 60, loss=0.1452, recon=0.1452, kl=30.9623, beta=0.0000\n",
      "Batch 80, loss=0.2443, recon=0.2443, kl=32.9535, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2039 (Recon: 0.2039, KL: 28.9519, Current Beta: 0.0000) | Avg Valid Loss: 0.1451 | Avg Valid recon Loss: 0.1451\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1252, recon=0.1252, kl=33.7508, beta=0.0000\n",
      "Batch 40, loss=0.1119, recon=0.1119, kl=33.8446, beta=0.0000\n",
      "Batch 60, loss=0.1145, recon=0.1144, kl=35.8700, beta=0.0000\n",
      "Batch 80, loss=0.1052, recon=0.1052, kl=36.5888, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1574 (Recon: 0.1574, KL: 35.1073, Current Beta: 0.0000) | Avg Valid Loss: 0.1161 | Avg Valid recon Loss: 0.1161\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1049, recon=0.1049, kl=36.4660, beta=0.0000\n",
      "Batch 40, loss=0.0941, recon=0.0941, kl=30.9576, beta=0.0000\n",
      "Batch 60, loss=0.1006, recon=0.1006, kl=28.8674, beta=0.0000\n",
      "Batch 80, loss=0.1128, recon=0.1128, kl=27.7546, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1308 (Recon: 0.1308, KL: 32.0260, Current Beta: 0.0000) | Avg Valid Loss: 0.0975 | Avg Valid recon Loss: 0.0974\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1318, recon=0.1318, kl=22.8983, beta=0.0000\n",
      "Batch 40, loss=0.0822, recon=0.0822, kl=17.9565, beta=0.0000\n",
      "Batch 60, loss=0.0950, recon=0.0950, kl=17.2745, beta=0.0000\n",
      "Batch 80, loss=0.1100, recon=0.1100, kl=17.7687, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1118 (Recon: 0.1118, KL: 19.8671, Current Beta: 0.0000) | Avg Valid Loss: 0.0865 | Avg Valid recon Loss: 0.0865\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1421, recon=0.1420, kl=12.4883, beta=0.0000\n",
      "Batch 40, loss=0.1244, recon=0.1244, kl=8.6424, beta=0.0000\n",
      "Batch 60, loss=0.0876, recon=0.0876, kl=8.6678, beta=0.0000\n",
      "Batch 80, loss=0.1053, recon=0.1052, kl=9.9571, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0988 (Recon: 0.0988, KL: 10.9440, Current Beta: 0.0000) | Avg Valid Loss: 0.0794 | Avg Valid recon Loss: 0.0794\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2719, recon=0.2719, kl=3.9825, beta=0.0000\n",
      "Batch 40, loss=0.0908, recon=0.0908, kl=3.3495, beta=0.0000\n",
      "Batch 60, loss=0.1016, recon=0.1016, kl=4.2592, beta=0.0000\n",
      "Batch 80, loss=0.0783, recon=0.0783, kl=3.1232, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0899 (Recon: 0.0898, KL: 4.2531, Current Beta: 0.0000) | Avg Valid Loss: 0.0736 | Avg Valid recon Loss: 0.0736\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0517, recon=0.0517, kl=0.9707, beta=0.0000\n",
      "Batch 40, loss=0.0689, recon=0.0689, kl=1.1067, beta=0.0000\n",
      "Batch 60, loss=0.0661, recon=0.0660, kl=1.1243, beta=0.0000\n",
      "Batch 80, loss=0.0727, recon=0.0726, kl=0.9100, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0833 (Recon: 0.0833, KL: 1.3007, Current Beta: 0.0000) | Avg Valid Loss: 0.0691 | Avg Valid recon Loss: 0.0691\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0591, recon=0.0590, kl=0.2492, beta=0.0000\n",
      "Batch 40, loss=0.0597, recon=0.0597, kl=0.2721, beta=0.0000\n",
      "Batch 60, loss=0.0627, recon=0.0627, kl=0.2742, beta=0.0000\n",
      "Batch 80, loss=0.1118, recon=0.1118, kl=0.2168, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0777 (Recon: 0.0777, KL: 0.3255, Current Beta: 0.0000) | Avg Valid Loss: 0.0656 | Avg Valid recon Loss: 0.0656\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0755, recon=0.0755, kl=0.0142, beta=0.0001\n",
      "Batch 40, loss=0.0636, recon=0.0636, kl=0.0468, beta=0.0001\n",
      "Batch 60, loss=0.0473, recon=0.0472, kl=0.0249, beta=0.0001\n",
      "Batch 80, loss=0.0603, recon=0.0603, kl=0.0297, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0736 (Recon: 0.0736, KL: 0.0440, Current Beta: 0.0001) | Avg Valid Loss: 0.0634 | Avg Valid recon Loss: 0.0634\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0499, recon=0.0499, kl=0.0108, beta=0.0003\n",
      "Batch 40, loss=0.0707, recon=0.0707, kl=0.0021, beta=0.0003\n",
      "Batch 60, loss=0.0531, recon=0.0531, kl=0.0024, beta=0.0003\n",
      "Batch 80, loss=0.0498, recon=0.0498, kl=0.0050, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0698 (Recon: 0.0698, KL: 0.0064, Current Beta: 0.0003) | Avg Valid Loss: 0.0599 | Avg Valid recon Loss: 0.0599\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0575, recon=0.0575, kl=0.0004, beta=0.0008\n",
      "Batch 40, loss=0.0497, recon=0.0497, kl=0.0008, beta=0.0008\n",
      "Batch 60, loss=0.0578, recon=0.0578, kl=0.0005, beta=0.0008\n",
      "Batch 80, loss=0.0464, recon=0.0464, kl=0.0008, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0666 (Recon: 0.0666, KL: 0.0010, Current Beta: 0.0008) | Avg Valid Loss: 0.0571 | Avg Valid recon Loss: 0.0571\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0566, recon=0.0566, kl=0.0003, beta=0.0018\n",
      "Batch 40, loss=0.0709, recon=0.0709, kl=0.0002, beta=0.0018\n",
      "Batch 60, loss=0.0451, recon=0.0451, kl=0.0001, beta=0.0018\n",
      "Batch 80, loss=0.0661, recon=0.0661, kl=0.0003, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0640 (Recon: 0.0640, KL: 0.0003, Current Beta: 0.0018) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0559\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0491, recon=0.0491, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0375, recon=0.0375, kl=0.0003, beta=0.0038\n",
      "Batch 60, loss=0.0464, recon=0.0464, kl=0.0003, beta=0.0038\n",
      "Batch 80, loss=0.0499, recon=0.0499, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0613 (Recon: 0.0613, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0536 | Avg Valid recon Loss: 0.0536\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0379, recon=0.0379, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0429, recon=0.0429, kl=0.0002, beta=0.0062\n",
      "Batch 60, loss=0.0460, recon=0.0460, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0447, recon=0.0447, kl=0.0002, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0596 (Recon: 0.0596, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0536 | Avg Valid recon Loss: 0.0536\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0433, recon=0.0433, kl=0.0005, beta=0.0100\n",
      "Batch 40, loss=0.0406, recon=0.0406, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0479, recon=0.0479, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0556, recon=0.0556, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0576 (Recon: 0.0576, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0499, recon=0.0499, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0650, recon=0.0650, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0450, recon=0.0450, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.1768, recon=0.1768, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0558 (Recon: 0.0558, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0495 | Avg Valid recon Loss: 0.0495\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0357, recon=0.0357, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0544, recon=0.0544, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0321, recon=0.0321, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0412, recon=0.0412, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0544 (Recon: 0.0544, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0482 | Avg Valid recon Loss: 0.0482\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0493, recon=0.0493, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0516, recon=0.0516, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0352, recon=0.0352, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.4941, recon=0.4941, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0529, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0475 | Avg Valid recon Loss: 0.0475\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0410, recon=0.0410, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0424, recon=0.0424, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0519, recon=0.0519, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0369, recon=0.0369, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0518, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0458\n",
      "\n",
      "[VRAE Run 188/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2129, recon=0.2129, kl=22.7578, beta=0.0000\n",
      "Batch 40, loss=0.1872, recon=0.1872, kl=29.0843, beta=0.0000\n",
      "Batch 60, loss=0.0713, recon=0.0713, kl=27.5891, beta=0.0000\n",
      "Batch 80, loss=0.0760, recon=0.0760, kl=33.6076, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1844 (Recon: 0.1844, KL: 25.8641, Current Beta: 0.0000) | Avg Valid Loss: 0.0779 | Avg Valid recon Loss: 0.0779\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0682, recon=0.0682, kl=23.9126, beta=0.0000\n",
      "Batch 40, loss=0.0802, recon=0.0802, kl=26.4787, beta=0.0000\n",
      "Batch 60, loss=0.1913, recon=0.1913, kl=29.5667, beta=0.0000\n",
      "Batch 80, loss=0.0561, recon=0.0561, kl=29.5788, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0782 (Recon: 0.0782, KL: 28.0890, Current Beta: 0.0000) | Avg Valid Loss: 0.0669 | Avg Valid recon Loss: 0.0669\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0467, recon=0.0467, kl=25.9581, beta=0.0000\n",
      "Batch 40, loss=0.0882, recon=0.0882, kl=28.6066, beta=0.0000\n",
      "Batch 60, loss=0.0371, recon=0.0371, kl=30.1453, beta=0.0000\n",
      "Batch 80, loss=0.0459, recon=0.0459, kl=31.4697, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0636 (Recon: 0.0636, KL: 28.7409, Current Beta: 0.0000) | Avg Valid Loss: 0.0522 | Avg Valid recon Loss: 0.0522\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0438, recon=0.0438, kl=29.9066, beta=0.0000\n",
      "Batch 40, loss=0.0523, recon=0.0523, kl=28.0350, beta=0.0000\n",
      "Batch 60, loss=0.0340, recon=0.0340, kl=26.9692, beta=0.0000\n",
      "Batch 80, loss=0.0416, recon=0.0416, kl=24.2543, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 27.4749, Current Beta: 0.0000) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0454, recon=0.0454, kl=23.2031, beta=0.0000\n",
      "Batch 40, loss=0.0355, recon=0.0355, kl=18.9807, beta=0.0000\n",
      "Batch 60, loss=0.0375, recon=0.0375, kl=16.4764, beta=0.0000\n",
      "Batch 80, loss=0.0312, recon=0.0312, kl=16.9542, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 19.4956, Current Beta: 0.0000) | Avg Valid Loss: 0.0447 | Avg Valid recon Loss: 0.0447\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1040, recon=0.1039, kl=13.5524, beta=0.0000\n",
      "Batch 40, loss=0.0371, recon=0.0370, kl=11.8134, beta=0.0000\n",
      "Batch 60, loss=0.0538, recon=0.0538, kl=10.9530, beta=0.0000\n",
      "Batch 80, loss=0.0347, recon=0.0347, kl=11.1239, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0492 (Recon: 0.0492, KL: 12.4039, Current Beta: 0.0000) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.3958, recon=0.3958, kl=6.2199, beta=0.0000\n",
      "Batch 40, loss=0.0636, recon=0.0636, kl=6.5548, beta=0.0000\n",
      "Batch 60, loss=0.0305, recon=0.0304, kl=4.3211, beta=0.0000\n",
      "Batch 80, loss=0.0513, recon=0.0513, kl=4.6126, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0478, KL: 5.9777, Current Beta: 0.0000) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0593, recon=0.0592, kl=2.8781, beta=0.0000\n",
      "Batch 40, loss=0.0433, recon=0.0433, kl=2.4326, beta=0.0000\n",
      "Batch 60, loss=0.0356, recon=0.0356, kl=1.6834, beta=0.0000\n",
      "Batch 80, loss=0.0297, recon=0.0296, kl=1.9138, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0443 (Recon: 0.0443, KL: 2.2870, Current Beta: 0.0000) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0417, recon=0.0417, kl=0.5605, beta=0.0000\n",
      "Batch 40, loss=0.0398, recon=0.0397, kl=0.9351, beta=0.0000\n",
      "Batch 60, loss=0.0332, recon=0.0331, kl=0.4238, beta=0.0000\n",
      "Batch 80, loss=0.0295, recon=0.0295, kl=0.3005, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0426 (Recon: 0.0426, KL: 0.6389, Current Beta: 0.0000) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0312, recon=0.0312, kl=0.0366, beta=0.0001\n",
      "Batch 40, loss=0.0433, recon=0.0432, kl=0.0949, beta=0.0001\n",
      "Batch 60, loss=0.0558, recon=0.0558, kl=0.0142, beta=0.0001\n",
      "Batch 80, loss=0.0276, recon=0.0276, kl=0.0280, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0439 (Recon: 0.0439, KL: 0.0610, Current Beta: 0.0001) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0400, recon=0.0400, kl=0.0101, beta=0.0003\n",
      "Batch 40, loss=0.0340, recon=0.0340, kl=0.0055, beta=0.0003\n",
      "Batch 60, loss=0.0387, recon=0.0387, kl=0.0028, beta=0.0003\n",
      "Batch 80, loss=0.0597, recon=0.0597, kl=0.0026, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0415, KL: 0.0083, Current Beta: 0.0003) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0392\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0279, recon=0.0279, kl=0.0020, beta=0.0008\n",
      "Batch 40, loss=0.0327, recon=0.0327, kl=0.0019, beta=0.0008\n",
      "Batch 60, loss=0.0361, recon=0.0361, kl=0.0011, beta=0.0008\n",
      "Batch 80, loss=0.0351, recon=0.0351, kl=0.0007, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0423, KL: 0.0027, Current Beta: 0.0008) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0283, recon=0.0283, kl=0.0002, beta=0.0018\n",
      "Batch 40, loss=0.0450, recon=0.0450, kl=0.0013, beta=0.0018\n",
      "Batch 60, loss=0.0318, recon=0.0318, kl=0.0011, beta=0.0018\n",
      "Batch 80, loss=0.0271, recon=0.0271, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0418, KL: 0.0008, Current Beta: 0.0018) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0294, recon=0.0294, kl=0.0005, beta=0.0038\n",
      "Batch 40, loss=0.0372, recon=0.0372, kl=0.0004, beta=0.0038\n",
      "Batch 60, loss=0.0381, recon=0.0381, kl=0.0002, beta=0.0038\n",
      "Batch 80, loss=0.0456, recon=0.0456, kl=0.0010, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0397 (Recon: 0.0397, KL: 0.0006, Current Beta: 0.0038) | Avg Valid Loss: 0.0340 | Avg Valid recon Loss: 0.0340\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0288, recon=0.0288, kl=0.0002, beta=0.0062\n",
      "Batch 40, loss=0.0317, recon=0.0317, kl=0.0002, beta=0.0062\n",
      "Batch 60, loss=0.0353, recon=0.0353, kl=0.0005, beta=0.0062\n",
      "Batch 80, loss=0.0355, recon=0.0355, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 0.0004, Current Beta: 0.0062) | Avg Valid Loss: 0.0331 | Avg Valid recon Loss: 0.0331\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0342, recon=0.0342, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0385, recon=0.0385, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0230, recon=0.0230, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0307, recon=0.0307, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0380 (Recon: 0.0380, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0246, recon=0.0246, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0361, recon=0.0361, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0275, recon=0.0275, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0333, recon=0.0333, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0401 (Recon: 0.0401, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0234, recon=0.0234, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0369, recon=0.0369, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0348, recon=0.0348, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0395, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0340 | Avg Valid recon Loss: 0.0340\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0345, recon=0.0345, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0301, recon=0.0301, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0346, recon=0.0346, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0454, recon=0.0454, kl=0.0015, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0382, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0460, recon=0.0460, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0285, recon=0.0285, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0329, recon=0.0329, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0381, recon=0.0381, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0387 (Recon: 0.0387, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0344\n",
      "\n",
      "[VRAE Run 189/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=1.2308, recon=1.2308, kl=0.5067, beta=0.0000\n",
      "Batch 40, loss=0.3199, recon=0.3199, kl=9.8795, beta=0.0000\n",
      "Batch 60, loss=0.2911, recon=0.2911, kl=34.5077, beta=0.0000\n",
      "Batch 80, loss=0.1945, recon=0.1945, kl=48.1970, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4303 (Recon: 0.4303, KL: 20.9489, Current Beta: 0.0000) | Avg Valid Loss: 0.2171 | Avg Valid recon Loss: 0.2171\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1600, recon=0.1600, kl=56.1280, beta=0.0000\n",
      "Batch 40, loss=0.2351, recon=0.2351, kl=58.6902, beta=0.0000\n",
      "Batch 60, loss=0.1798, recon=0.1798, kl=60.9059, beta=0.0000\n",
      "Batch 80, loss=0.1458, recon=0.1458, kl=63.4579, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1979 (Recon: 0.1979, KL: 58.9646, Current Beta: 0.0000) | Avg Valid Loss: 0.1383 | Avg Valid recon Loss: 0.1383\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1634, recon=0.1634, kl=68.4372, beta=0.0000\n",
      "Batch 40, loss=0.1300, recon=0.1300, kl=65.9727, beta=0.0000\n",
      "Batch 60, loss=0.1067, recon=0.1067, kl=64.0779, beta=0.0000\n",
      "Batch 80, loss=0.1052, recon=0.1052, kl=62.3568, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1515 (Recon: 0.1515, KL: 65.4235, Current Beta: 0.0000) | Avg Valid Loss: 0.1102 | Avg Valid recon Loss: 0.1102\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1379, recon=0.1378, kl=57.0285, beta=0.0000\n",
      "Batch 40, loss=0.0798, recon=0.0798, kl=50.4444, beta=0.0000\n",
      "Batch 60, loss=0.1537, recon=0.1537, kl=47.5978, beta=0.0000\n",
      "Batch 80, loss=0.1064, recon=0.1064, kl=48.9876, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1253 (Recon: 0.1253, KL: 52.0016, Current Beta: 0.0000) | Avg Valid Loss: 0.0942 | Avg Valid recon Loss: 0.0942\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0954, recon=0.0954, kl=38.4575, beta=0.0000\n",
      "Batch 40, loss=0.1270, recon=0.1270, kl=30.1821, beta=0.0000\n",
      "Batch 60, loss=0.0814, recon=0.0813, kl=31.0852, beta=0.0000\n",
      "Batch 80, loss=0.1306, recon=0.1306, kl=30.9847, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1087 (Recon: 0.1087, KL: 34.2391, Current Beta: 0.0000) | Avg Valid Loss: 0.0845 | Avg Valid recon Loss: 0.0845\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0655, recon=0.0655, kl=20.8611, beta=0.0000\n",
      "Batch 40, loss=0.0654, recon=0.0654, kl=13.4371, beta=0.0000\n",
      "Batch 60, loss=0.0909, recon=0.0909, kl=14.4183, beta=0.0000\n",
      "Batch 80, loss=0.0725, recon=0.0725, kl=13.5795, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0971 (Recon: 0.0971, KL: 17.1166, Current Beta: 0.0000) | Avg Valid Loss: 0.0779 | Avg Valid recon Loss: 0.0779\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0507, recon=0.0506, kl=5.4858, beta=0.0000\n",
      "Batch 40, loss=0.0561, recon=0.0561, kl=5.0028, beta=0.0000\n",
      "Batch 60, loss=0.0516, recon=0.0516, kl=5.1343, beta=0.0000\n",
      "Batch 80, loss=0.0764, recon=0.0763, kl=4.4014, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0883 (Recon: 0.0883, KL: 5.8219, Current Beta: 0.0000) | Avg Valid Loss: 0.0725 | Avg Valid recon Loss: 0.0724\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0639, recon=0.0639, kl=1.5031, beta=0.0000\n",
      "Batch 40, loss=0.0664, recon=0.0664, kl=1.6704, beta=0.0000\n",
      "Batch 60, loss=0.0687, recon=0.0686, kl=1.8211, beta=0.0000\n",
      "Batch 80, loss=0.0754, recon=0.0754, kl=1.6621, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0816 (Recon: 0.0815, KL: 1.9750, Current Beta: 0.0000) | Avg Valid Loss: 0.0682 | Avg Valid recon Loss: 0.0682\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0531, recon=0.0530, kl=0.4816, beta=0.0000\n",
      "Batch 40, loss=0.0617, recon=0.0617, kl=0.4084, beta=0.0000\n",
      "Batch 60, loss=0.7400, recon=0.7400, kl=0.4771, beta=0.0000\n",
      "Batch 80, loss=0.0499, recon=0.0499, kl=0.3076, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0758 (Recon: 0.0758, KL: 0.5301, Current Beta: 0.0000) | Avg Valid Loss: 0.0654 | Avg Valid recon Loss: 0.0654\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0559, recon=0.0559, kl=0.0678, beta=0.0001\n",
      "Batch 40, loss=0.0638, recon=0.0638, kl=0.0723, beta=0.0001\n",
      "Batch 60, loss=0.0495, recon=0.0495, kl=0.0479, beta=0.0001\n",
      "Batch 80, loss=0.0628, recon=0.0628, kl=0.0515, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0713 (Recon: 0.0713, KL: 0.0875, Current Beta: 0.0001) | Avg Valid Loss: 0.0615 | Avg Valid recon Loss: 0.0615\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0934, recon=0.0934, kl=0.0056, beta=0.0003\n",
      "Batch 40, loss=0.0618, recon=0.0618, kl=0.0065, beta=0.0003\n",
      "Batch 60, loss=0.0412, recon=0.0412, kl=0.0035, beta=0.0003\n",
      "Batch 80, loss=0.0492, recon=0.0492, kl=0.0039, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0675 (Recon: 0.0675, KL: 0.0072, Current Beta: 0.0003) | Avg Valid Loss: 0.0586 | Avg Valid recon Loss: 0.0586\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0421, recon=0.0421, kl=0.0006, beta=0.0008\n",
      "Batch 40, loss=0.0568, recon=0.0568, kl=0.0011, beta=0.0008\n",
      "Batch 60, loss=0.0492, recon=0.0492, kl=0.0011, beta=0.0008\n",
      "Batch 80, loss=0.0597, recon=0.0597, kl=0.0005, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0645 (Recon: 0.0645, KL: 0.0009, Current Beta: 0.0008) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0566\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0493, recon=0.0493, kl=0.0002, beta=0.0018\n",
      "Batch 40, loss=0.0437, recon=0.0437, kl=0.0003, beta=0.0018\n",
      "Batch 60, loss=0.0487, recon=0.0487, kl=0.0006, beta=0.0018\n",
      "Batch 80, loss=0.0491, recon=0.0491, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0620 (Recon: 0.0620, KL: 0.0003, Current Beta: 0.0018) | Avg Valid Loss: 0.0542 | Avg Valid recon Loss: 0.0542\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1219, recon=0.1219, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.1148, recon=0.1148, kl=0.0000, beta=0.0038\n",
      "Batch 60, loss=0.0439, recon=0.0439, kl=0.0002, beta=0.0038\n",
      "Batch 80, loss=0.0397, recon=0.0397, kl=0.0000, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0598 (Recon: 0.0598, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0535 | Avg Valid recon Loss: 0.0535\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0473, recon=0.0473, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0313, recon=0.0313, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0440, recon=0.0440, kl=0.0002, beta=0.0062\n",
      "Batch 80, loss=0.0428, recon=0.0428, kl=0.0004, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0577 (Recon: 0.0577, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0340, recon=0.0340, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0460, recon=0.0460, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.1071, recon=0.1071, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0505, recon=0.0505, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0549 (Recon: 0.0549, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0495 | Avg Valid recon Loss: 0.0495\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0361, recon=0.0361, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0288, recon=0.0288, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0393, recon=0.0393, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0390, recon=0.0390, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0543 (Recon: 0.0543, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0482 | Avg Valid recon Loss: 0.0482\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0293, recon=0.0293, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0695, recon=0.0695, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0364, recon=0.0364, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0430, recon=0.0430, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0531 (Recon: 0.0531, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0469 | Avg Valid recon Loss: 0.0469\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0393, recon=0.0393, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0379, recon=0.0379, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0545, recon=0.0545, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0596, recon=0.0596, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0517, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0461 | Avg Valid recon Loss: 0.0461\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0278, recon=0.0277, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0835, recon=0.0835, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0691, recon=0.0691, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0446, recon=0.0446, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0509 (Recon: 0.0509, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0452\n",
      "\n",
      "[VRAE Run 190/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3217, recon=0.3217, kl=42.7451, beta=0.0000\n",
      "Batch 40, loss=0.1358, recon=0.1358, kl=55.5460, beta=0.0000\n",
      "Batch 60, loss=0.0945, recon=0.0945, kl=51.8896, beta=0.0000\n",
      "Batch 80, loss=0.0613, recon=0.0613, kl=51.5671, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1780 (Recon: 0.1780, KL: 45.7647, Current Beta: 0.0000) | Avg Valid Loss: 0.0766 | Avg Valid recon Loss: 0.0766\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0774, recon=0.0774, kl=56.2622, beta=0.0000\n",
      "Batch 40, loss=0.0556, recon=0.0556, kl=62.6254, beta=0.0000\n",
      "Batch 60, loss=0.0501, recon=0.0501, kl=65.5717, beta=0.0000\n",
      "Batch 80, loss=0.0678, recon=0.0678, kl=59.4278, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0765 (Recon: 0.0765, KL: 60.9251, Current Beta: 0.0000) | Avg Valid Loss: 0.0616 | Avg Valid recon Loss: 0.0616\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0433, recon=0.0433, kl=53.1069, beta=0.0000\n",
      "Batch 40, loss=0.0545, recon=0.0545, kl=53.7050, beta=0.0000\n",
      "Batch 60, loss=0.0352, recon=0.0352, kl=54.0081, beta=0.0000\n",
      "Batch 80, loss=0.0441, recon=0.0441, kl=54.6504, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0633 (Recon: 0.0632, KL: 54.6679, Current Beta: 0.0000) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0541\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0409, recon=0.0409, kl=46.4596, beta=0.0000\n",
      "Batch 40, loss=0.0291, recon=0.0291, kl=46.5122, beta=0.0000\n",
      "Batch 60, loss=0.0405, recon=0.0405, kl=44.5537, beta=0.0000\n",
      "Batch 80, loss=0.0597, recon=0.0597, kl=48.2066, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0564 (Recon: 0.0564, KL: 46.7652, Current Beta: 0.0000) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0471\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0269, recon=0.0269, kl=33.4485, beta=0.0000\n",
      "Batch 40, loss=0.0379, recon=0.0378, kl=31.3701, beta=0.0000\n",
      "Batch 60, loss=0.0375, recon=0.0375, kl=33.2935, beta=0.0000\n",
      "Batch 80, loss=0.1640, recon=0.1639, kl=40.7190, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0517 (Recon: 0.0517, KL: 35.4773, Current Beta: 0.0000) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0566, recon=0.0565, kl=46.2826, beta=0.0000\n",
      "Batch 40, loss=0.0586, recon=0.0585, kl=41.8377, beta=0.0000\n",
      "Batch 60, loss=0.0293, recon=0.0293, kl=33.8711, beta=0.0000\n",
      "Batch 80, loss=0.0958, recon=0.0957, kl=29.2923, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0496, KL: 38.0603, Current Beta: 0.0000) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0331, recon=0.0330, kl=20.6440, beta=0.0000\n",
      "Batch 40, loss=0.0401, recon=0.0400, kl=15.6870, beta=0.0000\n",
      "Batch 60, loss=0.0294, recon=0.0293, kl=14.0559, beta=0.0000\n",
      "Batch 80, loss=0.0794, recon=0.0793, kl=12.5970, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0476 (Recon: 0.0475, KL: 16.8413, Current Beta: 0.0000) | Avg Valid Loss: 0.0406 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0290, recon=0.0290, kl=5.1877, beta=0.0000\n",
      "Batch 40, loss=0.0663, recon=0.0663, kl=3.0091, beta=0.0000\n",
      "Batch 60, loss=0.0299, recon=0.0299, kl=2.9768, beta=0.0000\n",
      "Batch 80, loss=0.0380, recon=0.0380, kl=2.0539, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0461, KL: 4.0004, Current Beta: 0.0000) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0458, recon=0.0458, kl=1.0588, beta=0.0000\n",
      "Batch 40, loss=0.0587, recon=0.0587, kl=0.7701, beta=0.0000\n",
      "Batch 60, loss=0.0398, recon=0.0398, kl=0.3357, beta=0.0000\n",
      "Batch 80, loss=0.0314, recon=0.0313, kl=0.3419, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0434, KL: 0.7054, Current Beta: 0.0000) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0286, recon=0.0286, kl=0.0367, beta=0.0001\n",
      "Batch 40, loss=0.0357, recon=0.0357, kl=0.0432, beta=0.0001\n",
      "Batch 60, loss=0.0327, recon=0.0327, kl=0.0941, beta=0.0001\n",
      "Batch 80, loss=0.0344, recon=0.0344, kl=0.0558, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0423, KL: 0.0931, Current Beta: 0.0001) | Avg Valid Loss: 0.0546 | Avg Valid recon Loss: 0.0546\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0340, recon=0.0340, kl=0.0194, beta=0.0003\n",
      "Batch 40, loss=0.0297, recon=0.0297, kl=0.0091, beta=0.0003\n",
      "Batch 60, loss=0.0281, recon=0.0281, kl=0.0151, beta=0.0003\n",
      "Batch 80, loss=0.0389, recon=0.0389, kl=0.0100, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0461, KL: 0.0170, Current Beta: 0.0003) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=0.0055, beta=0.0008\n",
      "Batch 40, loss=0.0366, recon=0.0366, kl=0.0045, beta=0.0008\n",
      "Batch 60, loss=0.0290, recon=0.0290, kl=0.0085, beta=0.0008\n",
      "Batch 80, loss=0.0511, recon=0.0511, kl=0.0041, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0435 (Recon: 0.0435, KL: 0.0065, Current Beta: 0.0008) | Avg Valid Loss: 0.0360 | Avg Valid recon Loss: 0.0360\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0352, recon=0.0352, kl=0.0011, beta=0.0018\n",
      "Batch 40, loss=0.0331, recon=0.0331, kl=0.0015, beta=0.0018\n",
      "Batch 60, loss=0.0749, recon=0.0749, kl=0.0024, beta=0.0018\n",
      "Batch 80, loss=0.0442, recon=0.0442, kl=0.0020, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0429, KL: 0.0027, Current Beta: 0.0018) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0511, recon=0.0511, kl=0.0007, beta=0.0038\n",
      "Batch 40, loss=0.0291, recon=0.0290, kl=0.0235, beta=0.0038\n",
      "Batch 60, loss=0.0288, recon=0.0287, kl=0.0033, beta=0.0038\n",
      "Batch 80, loss=0.0402, recon=0.0402, kl=0.0014, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 0.0046, Current Beta: 0.0038) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0315, recon=0.0315, kl=0.0009, beta=0.0062\n",
      "Batch 40, loss=0.0305, recon=0.0305, kl=0.0003, beta=0.0062\n",
      "Batch 60, loss=0.0460, recon=0.0460, kl=0.0002, beta=0.0062\n",
      "Batch 80, loss=0.0823, recon=0.0823, kl=0.0004, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0403 (Recon: 0.0403, KL: 0.0008, Current Beta: 0.0062) | Avg Valid Loss: 0.0359 | Avg Valid recon Loss: 0.0359\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0344, recon=0.0344, kl=0.0007, beta=0.0100\n",
      "Batch 40, loss=0.0350, recon=0.0350, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.0389, recon=0.0388, kl=0.0027, beta=0.0100\n",
      "Batch 80, loss=0.0289, recon=0.0289, kl=0.0008, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0407 (Recon: 0.0406, KL: 0.0012, Current Beta: 0.0100) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0332\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0394, recon=0.0394, kl=0.0017, beta=0.0100\n",
      "Batch 40, loss=0.0357, recon=0.0357, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0371, recon=0.0371, kl=0.0003, beta=0.0100\n",
      "Batch 80, loss=0.0338, recon=0.0338, kl=0.0013, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 0.0009, Current Beta: 0.0100) | Avg Valid Loss: 0.0323 | Avg Valid recon Loss: 0.0323\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0266, recon=0.0266, kl=0.0027, beta=0.0100\n",
      "Batch 40, loss=0.0381, recon=0.0381, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0422, recon=0.0422, kl=0.0004, beta=0.0100\n",
      "Batch 80, loss=0.0530, recon=0.0530, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0397 (Recon: 0.0397, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0406 | Avg Valid recon Loss: 0.0406\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0325, recon=0.0325, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0766, recon=0.0766, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0352, recon=0.0352, kl=0.0005, beta=0.0100\n",
      "Batch 80, loss=0.0347, recon=0.0347, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0404 (Recon: 0.0404, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0310, recon=0.0310, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0293, recon=0.0293, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.0313, recon=0.0313, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0236, recon=0.0236, kl=0.0006, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0394 (Recon: 0.0394, KL: 0.0006, Current Beta: 0.0100) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0352\n",
      "\n",
      "[VRAE Run 191/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4799, recon=0.4799, kl=0.8875, beta=0.0000\n",
      "Batch 40, loss=0.3082, recon=0.3082, kl=27.5437, beta=0.0000\n",
      "Batch 60, loss=0.2871, recon=0.2871, kl=66.0122, beta=0.0000\n",
      "Batch 80, loss=0.2322, recon=0.2322, kl=86.2964, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4112 (Recon: 0.4112, KL: 40.1522, Current Beta: 0.0000) | Avg Valid Loss: 0.2061 | Avg Valid recon Loss: 0.2061\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1561, recon=0.1561, kl=103.4065, beta=0.0000\n",
      "Batch 40, loss=0.1812, recon=0.1812, kl=111.5064, beta=0.0000\n",
      "Batch 60, loss=0.1456, recon=0.1456, kl=119.5297, beta=0.0000\n",
      "Batch 80, loss=0.1433, recon=0.1433, kl=125.2621, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1930 (Recon: 0.1930, KL: 112.9074, Current Beta: 0.0000) | Avg Valid Loss: 0.1313 | Avg Valid recon Loss: 0.1313\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1156, recon=0.1156, kl=129.0997, beta=0.0000\n",
      "Batch 40, loss=0.2612, recon=0.2611, kl=125.9789, beta=0.0000\n",
      "Batch 60, loss=0.1407, recon=0.1407, kl=121.8441, beta=0.0000\n",
      "Batch 80, loss=0.4241, recon=0.4241, kl=119.0254, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1509 (Recon: 0.1509, KL: 124.6372, Current Beta: 0.0000) | Avg Valid Loss: 0.1067 | Avg Valid recon Loss: 0.1067\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0840, recon=0.0840, kl=103.5421, beta=0.0000\n",
      "Batch 40, loss=0.0973, recon=0.0973, kl=90.5425, beta=0.0000\n",
      "Batch 60, loss=0.1152, recon=0.1152, kl=79.6569, beta=0.0000\n",
      "Batch 80, loss=0.1557, recon=0.1556, kl=76.6950, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1256 (Recon: 0.1256, KL: 90.5169, Current Beta: 0.0000) | Avg Valid Loss: 0.0931 | Avg Valid recon Loss: 0.0931\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0838, recon=0.0838, kl=55.1093, beta=0.0000\n",
      "Batch 40, loss=0.1065, recon=0.1064, kl=44.4570, beta=0.0000\n",
      "Batch 60, loss=0.0864, recon=0.0864, kl=44.1783, beta=0.0000\n",
      "Batch 80, loss=0.0729, recon=0.0729, kl=43.2528, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1080 (Recon: 0.1079, KL: 49.5785, Current Beta: 0.0000) | Avg Valid Loss: 0.0818 | Avg Valid recon Loss: 0.0817\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0865, recon=0.0865, kl=20.8304, beta=0.0000\n",
      "Batch 40, loss=0.0840, recon=0.0839, kl=18.8962, beta=0.0000\n",
      "Batch 60, loss=0.0746, recon=0.0745, kl=18.8574, beta=0.0000\n",
      "Batch 80, loss=0.1246, recon=0.1246, kl=16.2481, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0959 (Recon: 0.0959, KL: 21.0520, Current Beta: 0.0000) | Avg Valid Loss: 0.0757 | Avg Valid recon Loss: 0.0757\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0929, recon=0.0929, kl=5.3098, beta=0.0000\n",
      "Batch 40, loss=0.0993, recon=0.0992, kl=6.1371, beta=0.0000\n",
      "Batch 60, loss=0.0598, recon=0.0598, kl=5.4778, beta=0.0000\n",
      "Batch 80, loss=0.0777, recon=0.0777, kl=4.3840, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0872 (Recon: 0.0871, KL: 6.5964, Current Beta: 0.0000) | Avg Valid Loss: 0.0699 | Avg Valid recon Loss: 0.0699\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0906, recon=0.0906, kl=1.8277, beta=0.0000\n",
      "Batch 40, loss=0.0584, recon=0.0584, kl=1.8316, beta=0.0000\n",
      "Batch 60, loss=0.1485, recon=0.1484, kl=1.9144, beta=0.0000\n",
      "Batch 80, loss=0.0685, recon=0.0685, kl=2.0653, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0810 (Recon: 0.0809, KL: 2.1780, Current Beta: 0.0000) | Avg Valid Loss: 0.0674 | Avg Valid recon Loss: 0.0674\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0552, recon=0.0552, kl=0.6122, beta=0.0000\n",
      "Batch 40, loss=0.0489, recon=0.0489, kl=0.6478, beta=0.0000\n",
      "Batch 60, loss=0.0543, recon=0.0543, kl=0.5095, beta=0.0000\n",
      "Batch 80, loss=0.0659, recon=0.0659, kl=0.4488, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0757 (Recon: 0.0757, KL: 0.6427, Current Beta: 0.0000) | Avg Valid Loss: 0.0642 | Avg Valid recon Loss: 0.0641\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0652, recon=0.0652, kl=0.0940, beta=0.0001\n",
      "Batch 40, loss=0.0562, recon=0.0562, kl=0.1261, beta=0.0001\n",
      "Batch 60, loss=0.0588, recon=0.0588, kl=0.0810, beta=0.0001\n",
      "Batch 80, loss=0.0393, recon=0.0393, kl=0.0541, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0716 (Recon: 0.0716, KL: 0.1228, Current Beta: 0.0001) | Avg Valid Loss: 0.0613 | Avg Valid recon Loss: 0.0613\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0535, recon=0.0535, kl=0.0068, beta=0.0003\n",
      "Batch 40, loss=0.0704, recon=0.0704, kl=0.0112, beta=0.0003\n",
      "Batch 60, loss=0.0499, recon=0.0499, kl=0.0070, beta=0.0003\n",
      "Batch 80, loss=0.0557, recon=0.0557, kl=0.0093, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0681 (Recon: 0.0681, KL: 0.0135, Current Beta: 0.0003) | Avg Valid Loss: 0.0591 | Avg Valid recon Loss: 0.0591\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0397, recon=0.0397, kl=0.0012, beta=0.0008\n",
      "Batch 40, loss=0.0619, recon=0.0619, kl=0.0009, beta=0.0008\n",
      "Batch 60, loss=0.0482, recon=0.0482, kl=0.0013, beta=0.0008\n",
      "Batch 80, loss=0.1500, recon=0.1500, kl=0.0006, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0648 (Recon: 0.0648, KL: 0.0016, Current Beta: 0.0008) | Avg Valid Loss: 0.0568 | Avg Valid recon Loss: 0.0568\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=0.0004, beta=0.0018\n",
      "Batch 40, loss=0.0832, recon=0.0832, kl=0.0002, beta=0.0018\n",
      "Batch 60, loss=0.0364, recon=0.0364, kl=0.0003, beta=0.0018\n",
      "Batch 80, loss=0.0672, recon=0.0672, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0621 (Recon: 0.0621, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0543 | Avg Valid recon Loss: 0.0543\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0516, recon=0.0515, kl=0.0004, beta=0.0038\n",
      "Batch 40, loss=0.0581, recon=0.0581, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.0399, recon=0.0399, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0492, recon=0.0492, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0597 (Recon: 0.0597, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0529 | Avg Valid recon Loss: 0.0529\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0512, recon=0.0512, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0664, recon=0.0664, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0974, recon=0.0974, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0552, recon=0.0552, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0581, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0427, recon=0.0427, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0393, recon=0.0393, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0324, recon=0.0324, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0357, recon=0.0357, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0561 (Recon: 0.0561, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0497 | Avg Valid recon Loss: 0.0497\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0340, recon=0.0340, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0625, recon=0.0625, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0315, recon=0.0315, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0332, recon=0.0332, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0550 (Recon: 0.0550, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1431, recon=0.1431, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0514, recon=0.0514, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0305, recon=0.0305, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0387, recon=0.0387, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0538 (Recon: 0.0538, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0473 | Avg Valid recon Loss: 0.0473\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0521, recon=0.0521, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0340, recon=0.0340, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0337, recon=0.0337, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.1301, recon=0.1301, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0523, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0460\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0595, recon=0.0595, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0369, recon=0.0369, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0685, recon=0.0685, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0487, recon=0.0487, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0511 (Recon: 0.0511, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0453 | Avg Valid recon Loss: 0.0453\n",
      "\n",
      "[VRAE Run 192/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1595, recon=0.1595, kl=74.5034, beta=0.0000\n",
      "Batch 40, loss=0.1416, recon=0.1416, kl=90.7709, beta=0.0000\n",
      "Batch 60, loss=0.0782, recon=0.0782, kl=113.3260, beta=0.0000\n",
      "Batch 80, loss=0.0635, recon=0.0635, kl=121.1209, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1824 (Recon: 0.1824, KL: 88.5650, Current Beta: 0.0000) | Avg Valid Loss: 0.0763 | Avg Valid recon Loss: 0.0763\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1218, recon=0.1218, kl=99.7118, beta=0.0000\n",
      "Batch 40, loss=0.0630, recon=0.0630, kl=108.6310, beta=0.0000\n",
      "Batch 60, loss=0.0409, recon=0.0409, kl=100.5937, beta=0.0000\n",
      "Batch 80, loss=0.0545, recon=0.0545, kl=109.4050, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0756 (Recon: 0.0756, KL: 104.6332, Current Beta: 0.0000) | Avg Valid Loss: 0.0572 | Avg Valid recon Loss: 0.0572\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=104.6943, beta=0.0000\n",
      "Batch 40, loss=0.0343, recon=0.0343, kl=90.0339, beta=0.0000\n",
      "Batch 60, loss=0.0393, recon=0.0392, kl=97.2852, beta=0.0000\n",
      "Batch 80, loss=0.0576, recon=0.0575, kl=93.9716, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0627 (Recon: 0.0627, KL: 98.8507, Current Beta: 0.0000) | Avg Valid Loss: 0.0563 | Avg Valid recon Loss: 0.0563\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0506, recon=0.0506, kl=86.6686, beta=0.0000\n",
      "Batch 40, loss=0.0343, recon=0.0343, kl=75.1221, beta=0.0000\n",
      "Batch 60, loss=0.0413, recon=0.0413, kl=82.3578, beta=0.0000\n",
      "Batch 80, loss=0.0335, recon=0.0335, kl=83.7256, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0576 (Recon: 0.0576, KL: 83.2538, Current Beta: 0.0000) | Avg Valid Loss: 0.0500 | Avg Valid recon Loss: 0.0500\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0716, recon=0.0716, kl=61.6660, beta=0.0000\n",
      "Batch 40, loss=0.0348, recon=0.0348, kl=54.8983, beta=0.0000\n",
      "Batch 60, loss=0.0665, recon=0.0664, kl=65.1374, beta=0.0000\n",
      "Batch 80, loss=0.0438, recon=0.0438, kl=73.6185, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0530 (Recon: 0.0530, KL: 66.0827, Current Beta: 0.0000) | Avg Valid Loss: 0.0495 | Avg Valid recon Loss: 0.0495\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0458, recon=0.0458, kl=42.4431, beta=0.0000\n",
      "Batch 40, loss=0.0580, recon=0.0579, kl=37.3724, beta=0.0000\n",
      "Batch 60, loss=0.0366, recon=0.0365, kl=49.0053, beta=0.0000\n",
      "Batch 80, loss=0.0542, recon=0.0541, kl=49.3067, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0523 (Recon: 0.0522, KL: 47.0329, Current Beta: 0.0000) | Avg Valid Loss: 0.0446 | Avg Valid recon Loss: 0.0445\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0276, recon=0.0275, kl=19.6013, beta=0.0000\n",
      "Batch 40, loss=0.0670, recon=0.0669, kl=22.8830, beta=0.0000\n",
      "Batch 60, loss=0.0300, recon=0.0299, kl=21.1796, beta=0.0000\n",
      "Batch 80, loss=0.0445, recon=0.0444, kl=16.9590, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0489 (Recon: 0.0488, KL: 22.2471, Current Beta: 0.0000) | Avg Valid Loss: 0.0468 | Avg Valid recon Loss: 0.0467\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0294, recon=0.0293, kl=9.5533, beta=0.0000\n",
      "Batch 40, loss=0.0485, recon=0.0483, kl=9.6289, beta=0.0000\n",
      "Batch 60, loss=0.0239, recon=0.0237, kl=9.9605, beta=0.0000\n",
      "Batch 80, loss=0.0439, recon=0.0437, kl=13.2568, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0471, KL: 11.9202, Current Beta: 0.0000) | Avg Valid Loss: 0.0400 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0312, recon=0.0303, kl=20.3654, beta=0.0000\n",
      "Batch 40, loss=0.0354, recon=0.0350, kl=8.9203, beta=0.0000\n",
      "Batch 60, loss=0.0292, recon=0.0289, kl=6.1428, beta=0.0000\n",
      "Batch 80, loss=0.0404, recon=0.0401, kl=6.8913, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0452 (Recon: 0.0448, KL: 9.7475, Current Beta: 0.0000) | Avg Valid Loss: 0.0418 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0335, recon=0.0332, kl=3.0316, beta=0.0001\n",
      "Batch 40, loss=0.0587, recon=0.0583, kl=3.9324, beta=0.0001\n",
      "Batch 60, loss=0.0241, recon=0.0238, kl=2.4438, beta=0.0001\n",
      "Batch 80, loss=0.0412, recon=0.0405, kl=6.6849, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0439 (Recon: 0.0434, KL: 4.3525, Current Beta: 0.0001) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0365\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0261, recon=0.0253, kl=2.9066, beta=0.0003\n",
      "Batch 40, loss=0.0346, recon=0.0327, kl=6.5857, beta=0.0003\n",
      "Batch 60, loss=0.0402, recon=0.0382, kl=6.8915, beta=0.0003\n",
      "Batch 80, loss=0.0382, recon=0.0366, kl=5.5865, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0448 (Recon: 0.0432, KL: 5.2996, Current Beta: 0.0003) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0367\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0495, recon=0.0461, kl=4.4382, beta=0.0008\n",
      "Batch 40, loss=0.0454, recon=0.0410, kl=5.8603, beta=0.0008\n",
      "Batch 60, loss=0.0428, recon=0.0384, kl=5.8029, beta=0.0008\n",
      "Batch 80, loss=0.0354, recon=0.0291, kl=8.2356, beta=0.0008\n",
      "  â†’ Avg Train Loss: 2.6472 (Recon: 2.6419, KL: 6.9507, Current Beta: 0.0008) | Avg Valid Loss: 0.0461 | Avg Valid recon Loss: 0.0386\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0509, recon=0.0360, kl=8.1884, beta=0.0018\n",
      "Batch 40, loss=0.0419, recon=0.0310, kl=5.9579, beta=0.0018\n",
      "Batch 60, loss=0.0491, recon=0.0408, kl=4.5480, beta=0.0018\n",
      "Batch 80, loss=0.0596, recon=0.0537, kl=3.2294, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0436, KL: 6.0898, Current Beta: 0.0018) | Avg Valid Loss: 0.0470 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0566, recon=0.0352, kl=5.6673, beta=0.0038\n",
      "Batch 40, loss=0.0568, recon=0.0328, kl=6.3535, beta=0.0038\n",
      "Batch 60, loss=0.0543, recon=0.0320, kl=5.8878, beta=0.0038\n",
      "Batch 80, loss=0.0517, recon=0.0351, kl=4.4063, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0662 (Recon: 0.0461, KL: 5.3123, Current Beta: 0.0038) | Avg Valid Loss: 0.0536 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1056, recon=0.0899, kl=2.5198, beta=0.0062\n",
      "Batch 40, loss=0.0517, recon=0.0388, kl=2.0792, beta=0.0062\n",
      "Batch 60, loss=0.0791, recon=0.0406, kl=6.1801, beta=0.0062\n",
      "Batch 80, loss=0.0795, recon=0.0342, kl=7.2776, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0815 (Recon: 0.0546, KL: 4.3186, Current Beta: 0.0062) | Avg Valid Loss: 0.0800 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0748, recon=0.0348, kl=4.0001, beta=0.0100\n",
      "Batch 40, loss=0.0651, recon=0.0385, kl=2.6584, beta=0.0100\n",
      "Batch 60, loss=0.0728, recon=0.0435, kl=2.9319, beta=0.0100\n",
      "Batch 80, loss=0.0911, recon=0.0320, kl=5.9112, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0954 (Recon: 0.0528, KL: 4.2613, Current Beta: 0.0100) | Avg Valid Loss: 0.0956 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0946, recon=0.0487, kl=4.5908, beta=0.0100\n",
      "Batch 40, loss=0.0599, recon=0.0250, kl=3.4919, beta=0.0100\n",
      "Batch 60, loss=0.0590, recon=0.0289, kl=3.0076, beta=0.0100\n",
      "Batch 80, loss=0.0625, recon=0.0384, kl=2.4139, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0822 (Recon: 0.0464, KL: 3.5822, Current Beta: 0.0100) | Avg Valid Loss: 0.0632 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0627, recon=0.0333, kl=2.9349, beta=0.0100\n",
      "Batch 40, loss=0.0702, recon=0.0440, kl=2.6215, beta=0.0100\n",
      "Batch 60, loss=0.0826, recon=0.0600, kl=2.2684, beta=0.0100\n",
      "Batch 80, loss=0.0481, recon=0.0297, kl=1.8384, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0701 (Recon: 0.0462, KL: 2.3876, Current Beta: 0.0100) | Avg Valid Loss: 0.0552 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0560, recon=0.0370, kl=1.9068, beta=0.0100\n",
      "Batch 40, loss=0.1028, recon=0.0589, kl=4.3929, beta=0.0100\n",
      "Batch 60, loss=0.0705, recon=0.0323, kl=3.8208, beta=0.0100\n",
      "Batch 80, loss=0.0750, recon=0.0417, kl=3.3311, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0889 (Recon: 0.0565, KL: 3.2347, Current Beta: 0.0100) | Avg Valid Loss: 0.0723 | Avg Valid recon Loss: 0.0434\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0645, recon=0.0422, kl=2.2281, beta=0.0100\n",
      "Batch 40, loss=0.0623, recon=0.0429, kl=1.9382, beta=0.0100\n",
      "Batch 60, loss=0.0530, recon=0.0363, kl=1.6690, beta=0.0100\n",
      "Batch 80, loss=0.0553, recon=0.0356, kl=1.9705, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0679 (Recon: 0.0476, KL: 2.0393, Current Beta: 0.0100) | Avg Valid Loss: 0.0588 | Avg Valid recon Loss: 0.0402\n",
      "\n",
      "[VRAE Run 193/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3929, recon=0.3929, kl=0.5345, beta=0.0000\n",
      "Batch 40, loss=0.1872, recon=0.1872, kl=14.7633, beta=0.0000\n",
      "Batch 60, loss=0.1237, recon=0.1237, kl=23.2788, beta=0.0000\n",
      "Batch 80, loss=0.1517, recon=0.1517, kl=28.5825, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3292 (Recon: 0.3292, KL: 14.7001, Current Beta: 0.0000) | Avg Valid Loss: 0.1357 | Avg Valid recon Loss: 0.1357\n",
      "Epoch 2/20\n",
      "Batch 20, loss=1.0671, recon=1.0671, kl=30.7097, beta=0.0000\n",
      "Batch 40, loss=0.1078, recon=0.1078, kl=33.4599, beta=0.0000\n",
      "Batch 60, loss=0.1182, recon=0.1182, kl=32.8280, beta=0.0000\n",
      "Batch 80, loss=0.1113, recon=0.1113, kl=38.9207, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1474 (Recon: 0.1474, KL: 33.3932, Current Beta: 0.0000) | Avg Valid Loss: 0.0968 | Avg Valid recon Loss: 0.0968\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0986, recon=0.0986, kl=45.4117, beta=0.0000\n",
      "Batch 40, loss=0.1108, recon=0.1108, kl=41.9007, beta=0.0000\n",
      "Batch 60, loss=0.9311, recon=0.9311, kl=46.8808, beta=0.0000\n",
      "Batch 80, loss=0.0731, recon=0.0731, kl=38.9958, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1159 (Recon: 0.1159, KL: 43.1017, Current Beta: 0.0000) | Avg Valid Loss: 0.0796 | Avg Valid recon Loss: 0.0796\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0888, recon=0.0888, kl=28.0441, beta=0.0000\n",
      "Batch 40, loss=0.0896, recon=0.0895, kl=27.2570, beta=0.0000\n",
      "Batch 60, loss=0.0654, recon=0.0654, kl=25.6422, beta=0.0000\n",
      "Batch 80, loss=0.0636, recon=0.0636, kl=23.1569, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0957 (Recon: 0.0957, KL: 27.0857, Current Beta: 0.0000) | Avg Valid Loss: 0.0691 | Avg Valid recon Loss: 0.0691\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0612, recon=0.0612, kl=15.9820, beta=0.0000\n",
      "Batch 40, loss=0.0548, recon=0.0548, kl=14.3509, beta=0.0000\n",
      "Batch 60, loss=0.0615, recon=0.0615, kl=15.7553, beta=0.0000\n",
      "Batch 80, loss=0.0573, recon=0.0573, kl=13.8214, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0822 (Recon: 0.0822, KL: 16.0531, Current Beta: 0.0000) | Avg Valid Loss: 0.0637 | Avg Valid recon Loss: 0.0637\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0657, recon=0.0657, kl=6.0552, beta=0.0000\n",
      "Batch 40, loss=0.0546, recon=0.0546, kl=7.2193, beta=0.0000\n",
      "Batch 60, loss=0.0987, recon=0.0987, kl=6.3325, beta=0.0000\n",
      "Batch 80, loss=0.0762, recon=0.0762, kl=5.7321, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0734 (Recon: 0.0734, KL: 6.9328, Current Beta: 0.0000) | Avg Valid Loss: 0.0595 | Avg Valid recon Loss: 0.0595\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0521, recon=0.0521, kl=2.7016, beta=0.0000\n",
      "Batch 40, loss=0.0501, recon=0.0501, kl=2.7862, beta=0.0000\n",
      "Batch 60, loss=0.0576, recon=0.0576, kl=2.4289, beta=0.0000\n",
      "Batch 80, loss=0.0699, recon=0.0699, kl=2.5781, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0672 (Recon: 0.0672, KL: 2.7691, Current Beta: 0.0000) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0559\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0777, recon=0.0777, kl=0.6179, beta=0.0000\n",
      "Batch 40, loss=0.0455, recon=0.0455, kl=0.9729, beta=0.0000\n",
      "Batch 60, loss=0.0526, recon=0.0526, kl=1.0278, beta=0.0000\n",
      "Batch 80, loss=0.0462, recon=0.0462, kl=0.7280, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0622 (Recon: 0.0622, KL: 0.9665, Current Beta: 0.0000) | Avg Valid Loss: 0.0526 | Avg Valid recon Loss: 0.0526\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0365, recon=0.0365, kl=0.1074, beta=0.0000\n",
      "Batch 40, loss=0.0452, recon=0.0452, kl=0.2692, beta=0.0000\n",
      "Batch 60, loss=0.0491, recon=0.0491, kl=0.1326, beta=0.0000\n",
      "Batch 80, loss=0.0424, recon=0.0424, kl=0.1615, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0585 (Recon: 0.0585, KL: 0.2120, Current Beta: 0.0000) | Avg Valid Loss: 0.0508 | Avg Valid recon Loss: 0.0508\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0397, recon=0.0397, kl=0.0072, beta=0.0001\n",
      "Batch 40, loss=0.0541, recon=0.0541, kl=0.0138, beta=0.0001\n",
      "Batch 60, loss=0.0317, recon=0.0317, kl=0.0194, beta=0.0001\n",
      "Batch 80, loss=0.0412, recon=0.0412, kl=0.0120, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0558 (Recon: 0.0558, KL: 0.0220, Current Beta: 0.0001) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0393, recon=0.0393, kl=0.0020, beta=0.0003\n",
      "Batch 40, loss=0.0647, recon=0.0647, kl=0.0014, beta=0.0003\n",
      "Batch 60, loss=0.0584, recon=0.0584, kl=0.0023, beta=0.0003\n",
      "Batch 80, loss=0.0527, recon=0.0527, kl=0.0015, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0532 (Recon: 0.0532, KL: 0.0024, Current Beta: 0.0003) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0465\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0436, recon=0.0436, kl=0.0008, beta=0.0008\n",
      "Batch 40, loss=0.0402, recon=0.0402, kl=0.0002, beta=0.0008\n",
      "Batch 60, loss=0.0899, recon=0.0899, kl=0.0003, beta=0.0008\n",
      "Batch 80, loss=0.0497, recon=0.0497, kl=0.0006, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0511 (Recon: 0.0511, KL: 0.0006, Current Beta: 0.0008) | Avg Valid Loss: 0.0451 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0471, recon=0.0471, kl=0.0003, beta=0.0018\n",
      "Batch 40, loss=0.0320, recon=0.0320, kl=0.0001, beta=0.0018\n",
      "Batch 60, loss=0.0617, recon=0.0617, kl=0.0002, beta=0.0018\n",
      "Batch 80, loss=0.0365, recon=0.0365, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0493 (Recon: 0.0493, KL: 0.0003, Current Beta: 0.0018) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0376, recon=0.0376, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0269, recon=0.0269, kl=0.0014, beta=0.0038\n",
      "Batch 60, loss=0.0483, recon=0.0483, kl=0.0005, beta=0.0038\n",
      "Batch 80, loss=0.0517, recon=0.0517, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0479, KL: 0.0004, Current Beta: 0.0038) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0330, recon=0.0330, kl=0.0000, beta=0.0062\n",
      "Batch 40, loss=0.0380, recon=0.0380, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0344, recon=0.0344, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0519, recon=0.0519, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0466, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0414 | Avg Valid recon Loss: 0.0414\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0412, recon=0.0412, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0323, recon=0.0323, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0312, recon=0.0312, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0325, recon=0.0325, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0452 (Recon: 0.0452, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0319, recon=0.0319, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0290, recon=0.0290, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0336, recon=0.0336, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0263, recon=0.0263, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0440, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0941, recon=0.0941, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0268, recon=0.0268, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0416, recon=0.0416, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0429, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0268, recon=0.0268, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0368, recon=0.0368, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0383, recon=0.0383, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0334, recon=0.0334, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0420, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0253, recon=0.0253, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0364, recon=0.0364, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0255, recon=0.0255, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0543, recon=0.0543, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0414, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0366 | Avg Valid recon Loss: 0.0366\n",
      "\n",
      "[VRAE Run 194/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1343, recon=0.1343, kl=27.3007, beta=0.0000\n",
      "Batch 40, loss=0.0882, recon=0.0882, kl=29.7524, beta=0.0000\n",
      "Batch 60, loss=0.1044, recon=0.1044, kl=22.8493, beta=0.0000\n",
      "Batch 80, loss=0.0710, recon=0.0710, kl=30.9152, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1436 (Recon: 0.1436, KL: 25.7060, Current Beta: 0.0000) | Avg Valid Loss: 0.0610 | Avg Valid recon Loss: 0.0610\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0523, recon=0.0523, kl=32.2302, beta=0.0000\n",
      "Batch 40, loss=0.0618, recon=0.0618, kl=29.7813, beta=0.0000\n",
      "Batch 60, loss=0.0526, recon=0.0526, kl=29.9912, beta=0.0000\n",
      "Batch 80, loss=0.0387, recon=0.0387, kl=28.5925, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0666 (Recon: 0.0666, KL: 30.8881, Current Beta: 0.0000) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0496\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=30.8866, beta=0.0000\n",
      "Batch 40, loss=0.0537, recon=0.0537, kl=29.0404, beta=0.0000\n",
      "Batch 60, loss=0.0680, recon=0.0680, kl=26.1662, beta=0.0000\n",
      "Batch 80, loss=0.0489, recon=0.0489, kl=26.8750, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 28.1023, Current Beta: 0.0000) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0466\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0415, recon=0.0415, kl=28.5693, beta=0.0000\n",
      "Batch 40, loss=0.0297, recon=0.0297, kl=26.9144, beta=0.0000\n",
      "Batch 60, loss=0.0526, recon=0.0526, kl=25.6947, beta=0.0000\n",
      "Batch 80, loss=0.0683, recon=0.0683, kl=23.5103, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0488 (Recon: 0.0488, KL: 26.8796, Current Beta: 0.0000) | Avg Valid Loss: 0.0470 | Avg Valid recon Loss: 0.0469\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0336, recon=0.0336, kl=20.8444, beta=0.0000\n",
      "Batch 40, loss=0.0662, recon=0.0662, kl=19.9158, beta=0.0000\n",
      "Batch 60, loss=0.0443, recon=0.0442, kl=19.0355, beta=0.0000\n",
      "Batch 80, loss=0.0378, recon=0.0378, kl=19.4492, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0460 (Recon: 0.0460, KL: 20.0505, Current Beta: 0.0000) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0301, recon=0.0301, kl=13.0208, beta=0.0000\n",
      "Batch 40, loss=0.0357, recon=0.0356, kl=12.9386, beta=0.0000\n",
      "Batch 60, loss=0.0336, recon=0.0336, kl=11.0816, beta=0.0000\n",
      "Batch 80, loss=0.0349, recon=0.0348, kl=14.9209, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0424, KL: 13.5921, Current Beta: 0.0000) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0299, recon=0.0299, kl=7.6569, beta=0.0000\n",
      "Batch 40, loss=0.0355, recon=0.0355, kl=8.3394, beta=0.0000\n",
      "Batch 60, loss=0.0275, recon=0.0275, kl=9.0445, beta=0.0000\n",
      "Batch 80, loss=0.0296, recon=0.0295, kl=8.3287, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0413, KL: 9.0194, Current Beta: 0.0000) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0200, recon=0.0200, kl=2.2657, beta=0.0000\n",
      "Batch 40, loss=0.0284, recon=0.0283, kl=2.9670, beta=0.0000\n",
      "Batch 60, loss=0.0356, recon=0.0356, kl=3.0974, beta=0.0000\n",
      "Batch 80, loss=0.0837, recon=0.0837, kl=2.8901, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0397 (Recon: 0.0396, KL: 3.0455, Current Beta: 0.0000) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0354\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0482, recon=0.0482, kl=0.7016, beta=0.0000\n",
      "Batch 40, loss=0.0273, recon=0.0273, kl=0.9814, beta=0.0000\n",
      "Batch 60, loss=0.0303, recon=0.0303, kl=0.7306, beta=0.0000\n",
      "Batch 80, loss=0.0408, recon=0.0407, kl=1.3792, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0387, KL: 1.1754, Current Beta: 0.0000) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0265, recon=0.0265, kl=0.1384, beta=0.0001\n",
      "Batch 40, loss=0.0226, recon=0.0226, kl=0.1721, beta=0.0001\n",
      "Batch 60, loss=0.0210, recon=0.0210, kl=0.0622, beta=0.0001\n",
      "Batch 80, loss=0.0333, recon=0.0333, kl=0.0829, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0369 (Recon: 0.0368, KL: 0.2582, Current Beta: 0.0001) | Avg Valid Loss: 0.0328 | Avg Valid recon Loss: 0.0328\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0260, recon=0.0260, kl=0.0185, beta=0.0003\n",
      "Batch 40, loss=0.0267, recon=0.0267, kl=0.0128, beta=0.0003\n",
      "Batch 60, loss=0.0344, recon=0.0344, kl=0.0217, beta=0.0003\n",
      "Batch 80, loss=0.0244, recon=0.0244, kl=0.0187, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0351 (Recon: 0.0351, KL: 0.0248, Current Beta: 0.0003) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0386, recon=0.0386, kl=0.0059, beta=0.0008\n",
      "Batch 40, loss=0.0436, recon=0.0436, kl=0.0062, beta=0.0008\n",
      "Batch 60, loss=0.0222, recon=0.0222, kl=0.0051, beta=0.0008\n",
      "Batch 80, loss=0.0555, recon=0.0555, kl=0.0023, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0356 (Recon: 0.0356, KL: 0.0056, Current Beta: 0.0008) | Avg Valid Loss: 0.0285 | Avg Valid recon Loss: 0.0284\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0187, recon=0.0187, kl=0.0014, beta=0.0018\n",
      "Batch 40, loss=0.0176, recon=0.0176, kl=0.0009, beta=0.0018\n",
      "Batch 60, loss=0.0310, recon=0.0310, kl=0.0011, beta=0.0018\n",
      "Batch 80, loss=0.0236, recon=0.0236, kl=0.0013, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0318 (Recon: 0.0318, KL: 0.0021, Current Beta: 0.0018) | Avg Valid Loss: 0.0278 | Avg Valid recon Loss: 0.0278\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0212, recon=0.0211, kl=0.0010, beta=0.0038\n",
      "Batch 40, loss=0.0300, recon=0.0300, kl=0.0003, beta=0.0038\n",
      "Batch 60, loss=0.0291, recon=0.0291, kl=0.0002, beta=0.0038\n",
      "Batch 80, loss=0.0207, recon=0.0207, kl=0.0005, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0311 (Recon: 0.0311, KL: 0.0010, Current Beta: 0.0038) | Avg Valid Loss: 0.0265 | Avg Valid recon Loss: 0.0265\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0378, recon=0.0378, kl=0.0006, beta=0.0062\n",
      "Batch 40, loss=0.0225, recon=0.0225, kl=0.0004, beta=0.0062\n",
      "Batch 60, loss=0.0225, recon=0.0225, kl=0.0002, beta=0.0062\n",
      "Batch 80, loss=0.0186, recon=0.0186, kl=0.0003, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0299 (Recon: 0.0299, KL: 0.0008, Current Beta: 0.0062) | Avg Valid Loss: 0.0259 | Avg Valid recon Loss: 0.0258\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0238, recon=0.0237, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0202, recon=0.0202, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0205, recon=0.0205, kl=0.0006, beta=0.0100\n",
      "Batch 80, loss=0.0210, recon=0.0210, kl=0.0005, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0287 (Recon: 0.0287, KL: 0.0007, Current Beta: 0.0100) | Avg Valid Loss: 0.0255 | Avg Valid recon Loss: 0.0255\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0274, recon=0.0274, kl=0.0005, beta=0.0100\n",
      "Batch 40, loss=0.0192, recon=0.0192, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0214, recon=0.0214, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0281, recon=0.0281, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0286 (Recon: 0.0286, KL: 0.0007, Current Beta: 0.0100) | Avg Valid Loss: 0.0269 | Avg Valid recon Loss: 0.0269\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0214, recon=0.0214, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0384, recon=0.0384, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0198, recon=0.0198, kl=0.0005, beta=0.0100\n",
      "Batch 80, loss=0.0357, recon=0.0356, kl=0.0033, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0285 (Recon: 0.0285, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0248 | Avg Valid recon Loss: 0.0248\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0321, recon=0.0321, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0356, recon=0.0356, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0191, recon=0.0191, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0260, recon=0.0260, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0302 (Recon: 0.0302, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0246 | Avg Valid recon Loss: 0.0245\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0224, recon=0.0224, kl=0.0038, beta=0.0100\n",
      "Batch 40, loss=0.0184, recon=0.0183, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0224, recon=0.0224, kl=0.0004, beta=0.0100\n",
      "Batch 80, loss=0.0186, recon=0.0186, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0302 (Recon: 0.0302, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0267 | Avg Valid recon Loss: 0.0266\n",
      "\n",
      "[VRAE Run 195/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3671, recon=0.3671, kl=0.8731, beta=0.0000\n",
      "Batch 40, loss=0.2342, recon=0.2342, kl=36.4300, beta=0.0000\n",
      "Batch 60, loss=0.1661, recon=0.1661, kl=48.7791, beta=0.0000\n",
      "Batch 80, loss=0.1647, recon=0.1647, kl=53.6411, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3129 (Recon: 0.3129, KL: 31.3909, Current Beta: 0.0000) | Avg Valid Loss: 0.1347 | Avg Valid recon Loss: 0.1347\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1140, recon=0.1140, kl=56.5875, beta=0.0000\n",
      "Batch 40, loss=0.2350, recon=0.2350, kl=57.0391, beta=0.0000\n",
      "Batch 60, loss=0.1293, recon=0.1293, kl=60.8909, beta=0.0000\n",
      "Batch 80, loss=0.0959, recon=0.0959, kl=65.5648, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1462 (Recon: 0.1462, KL: 60.1383, Current Beta: 0.0000) | Avg Valid Loss: 0.0955 | Avg Valid recon Loss: 0.0955\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0817, recon=0.0817, kl=71.4682, beta=0.0000\n",
      "Batch 40, loss=0.0922, recon=0.0922, kl=67.7867, beta=0.0000\n",
      "Batch 60, loss=0.0782, recon=0.0782, kl=57.0381, beta=0.0000\n",
      "Batch 80, loss=0.1123, recon=0.1122, kl=54.9947, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1153 (Recon: 0.1153, KL: 63.4120, Current Beta: 0.0000) | Avg Valid Loss: 0.0800 | Avg Valid recon Loss: 0.0800\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0875, recon=0.0874, kl=47.6947, beta=0.0000\n",
      "Batch 40, loss=0.0854, recon=0.0854, kl=43.9675, beta=0.0000\n",
      "Batch 60, loss=0.0644, recon=0.0644, kl=40.5963, beta=0.0000\n",
      "Batch 80, loss=0.0669, recon=0.0669, kl=38.9489, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0952 (Recon: 0.0952, KL: 44.3370, Current Beta: 0.0000) | Avg Valid Loss: 0.0689 | Avg Valid recon Loss: 0.0688\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0854, recon=0.0854, kl=27.6407, beta=0.0000\n",
      "Batch 40, loss=0.0584, recon=0.0584, kl=18.0779, beta=0.0000\n",
      "Batch 60, loss=0.0632, recon=0.0632, kl=20.9540, beta=0.0000\n",
      "Batch 80, loss=0.0601, recon=0.0601, kl=20.7964, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0826 (Recon: 0.0826, KL: 23.0555, Current Beta: 0.0000) | Avg Valid Loss: 0.0635 | Avg Valid recon Loss: 0.0635\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0762, recon=0.0762, kl=9.6617, beta=0.0000\n",
      "Batch 40, loss=0.0488, recon=0.0488, kl=7.7494, beta=0.0000\n",
      "Batch 60, loss=0.0690, recon=0.0690, kl=9.8429, beta=0.0000\n",
      "Batch 80, loss=0.1187, recon=0.1186, kl=7.2034, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0733 (Recon: 0.0733, KL: 9.6912, Current Beta: 0.0000) | Avg Valid Loss: 0.0595 | Avg Valid recon Loss: 0.0595\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0621, recon=0.0620, kl=2.9095, beta=0.0000\n",
      "Batch 40, loss=0.0779, recon=0.0778, kl=2.9680, beta=0.0000\n",
      "Batch 60, loss=0.0385, recon=0.0385, kl=3.8848, beta=0.0000\n",
      "Batch 80, loss=0.0414, recon=0.0414, kl=2.1586, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0675 (Recon: 0.0675, KL: 3.5139, Current Beta: 0.0000) | Avg Valid Loss: 0.0560 | Avg Valid recon Loss: 0.0560\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0583, recon=0.0582, kl=1.0408, beta=0.0000\n",
      "Batch 40, loss=0.0451, recon=0.0451, kl=1.6808, beta=0.0000\n",
      "Batch 60, loss=0.0474, recon=0.0474, kl=0.6022, beta=0.0000\n",
      "Batch 80, loss=0.0525, recon=0.0525, kl=1.3204, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0627 (Recon: 0.0627, KL: 1.3713, Current Beta: 0.0000) | Avg Valid Loss: 0.0528 | Avg Valid recon Loss: 0.0528\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0496, recon=0.0496, kl=0.2844, beta=0.0000\n",
      "Batch 40, loss=0.0431, recon=0.0431, kl=0.3269, beta=0.0000\n",
      "Batch 60, loss=0.1503, recon=0.1503, kl=0.2638, beta=0.0000\n",
      "Batch 80, loss=0.0373, recon=0.0373, kl=0.1688, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0591 (Recon: 0.0591, KL: 0.3097, Current Beta: 0.0000) | Avg Valid Loss: 0.0505 | Avg Valid recon Loss: 0.0505\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0517, recon=0.0517, kl=0.0359, beta=0.0001\n",
      "Batch 40, loss=0.0545, recon=0.0544, kl=0.0345, beta=0.0001\n",
      "Batch 60, loss=0.0438, recon=0.0438, kl=0.0273, beta=0.0001\n",
      "Batch 80, loss=0.0664, recon=0.0664, kl=0.0192, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0560 (Recon: 0.0560, KL: 0.0425, Current Beta: 0.0001) | Avg Valid Loss: 0.0483 | Avg Valid recon Loss: 0.0483\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0422, recon=0.0422, kl=0.0027, beta=0.0003\n",
      "Batch 40, loss=0.0308, recon=0.0308, kl=0.0050, beta=0.0003\n",
      "Batch 60, loss=0.0419, recon=0.0419, kl=0.0027, beta=0.0003\n",
      "Batch 80, loss=0.0424, recon=0.0424, kl=0.0032, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0533, KL: 0.0044, Current Beta: 0.0003) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0466\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=0.0010, beta=0.0008\n",
      "Batch 40, loss=0.0352, recon=0.0352, kl=0.0007, beta=0.0008\n",
      "Batch 60, loss=0.0464, recon=0.0464, kl=0.0011, beta=0.0008\n",
      "Batch 80, loss=0.0305, recon=0.0305, kl=0.0006, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0513 (Recon: 0.0513, KL: 0.0011, Current Beta: 0.0008) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0372, recon=0.0372, kl=0.0003, beta=0.0018\n",
      "Batch 40, loss=0.0409, recon=0.0409, kl=0.0005, beta=0.0018\n",
      "Batch 60, loss=0.4282, recon=0.4282, kl=0.0042, beta=0.0018\n",
      "Batch 80, loss=0.0290, recon=0.0290, kl=0.0005, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0491 (Recon: 0.0491, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0309, recon=0.0309, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0269, recon=0.0269, kl=0.0003, beta=0.0038\n",
      "Batch 60, loss=0.0325, recon=0.0325, kl=0.0003, beta=0.0038\n",
      "Batch 80, loss=0.0270, recon=0.0270, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0478 (Recon: 0.0478, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=0.0002, beta=0.0062\n",
      "Batch 40, loss=0.0316, recon=0.0316, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0348, recon=0.0348, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0318, recon=0.0318, kl=0.0006, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0463, KL: 0.0003, Current Beta: 0.0062) | Avg Valid Loss: 0.0405 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0330, recon=0.0330, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0394, recon=0.0394, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0278, recon=0.0278, kl=0.0003, beta=0.0100\n",
      "Batch 80, loss=0.0375, recon=0.0375, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0450, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0393\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0379, recon=0.0379, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0501, recon=0.0501, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0585, recon=0.0585, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0317, recon=0.0317, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0439 (Recon: 0.0439, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0386 | Avg Valid recon Loss: 0.0386\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0374, recon=0.0374, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0435, recon=0.0435, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0300, recon=0.0300, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0295, recon=0.0295, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0321, recon=0.0321, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0394, recon=0.0394, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0448, recon=0.0448, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0290, recon=0.0290, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0419, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0235, recon=0.0235, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0326, recon=0.0326, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0292, recon=0.0292, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0307, recon=0.0307, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0411 (Recon: 0.0411, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0371\n",
      "\n",
      "[VRAE Run 196/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1352, recon=0.1352, kl=32.1402, beta=0.0000\n",
      "Batch 40, loss=0.0861, recon=0.0861, kl=54.4157, beta=0.0000\n",
      "Batch 60, loss=0.0528, recon=0.0528, kl=62.7810, beta=0.0000\n",
      "Batch 80, loss=0.2156, recon=0.2156, kl=60.1160, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1440 (Recon: 0.1440, KL: 47.9765, Current Beta: 0.0000) | Avg Valid Loss: 0.0617 | Avg Valid recon Loss: 0.0617\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0555, recon=0.0555, kl=54.6661, beta=0.0000\n",
      "Batch 40, loss=0.0544, recon=0.0544, kl=59.8830, beta=0.0000\n",
      "Batch 60, loss=0.0426, recon=0.0426, kl=55.1073, beta=0.0000\n",
      "Batch 80, loss=0.0469, recon=0.0469, kl=61.9028, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0665 (Recon: 0.0665, KL: 57.2530, Current Beta: 0.0000) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0361, recon=0.0361, kl=51.6091, beta=0.0000\n",
      "Batch 40, loss=0.0509, recon=0.0509, kl=56.2498, beta=0.0000\n",
      "Batch 60, loss=0.0966, recon=0.0966, kl=49.9147, beta=0.0000\n",
      "Batch 80, loss=0.0594, recon=0.0594, kl=52.4997, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0548 (Recon: 0.0548, KL: 53.5659, Current Beta: 0.0000) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0387, recon=0.0387, kl=42.6002, beta=0.0000\n",
      "Batch 40, loss=0.1013, recon=0.1013, kl=43.3021, beta=0.0000\n",
      "Batch 60, loss=0.0329, recon=0.0329, kl=42.0241, beta=0.0000\n",
      "Batch 80, loss=0.0477, recon=0.0477, kl=44.8274, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0484 (Recon: 0.0484, KL: 44.8254, Current Beta: 0.0000) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0325, recon=0.0325, kl=33.7264, beta=0.0000\n",
      "Batch 40, loss=0.0308, recon=0.0308, kl=34.3035, beta=0.0000\n",
      "Batch 60, loss=0.0351, recon=0.0351, kl=37.2923, beta=0.0000\n",
      "Batch 80, loss=0.0324, recon=0.0324, kl=37.8160, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0444 (Recon: 0.0444, KL: 36.1619, Current Beta: 0.0000) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0334, recon=0.0333, kl=27.4541, beta=0.0000\n",
      "Batch 40, loss=0.0302, recon=0.0302, kl=25.2119, beta=0.0000\n",
      "Batch 60, loss=0.0324, recon=0.0324, kl=31.7746, beta=0.0000\n",
      "Batch 80, loss=0.0367, recon=0.0367, kl=28.4978, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0445, KL: 28.5531, Current Beta: 0.0000) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=12.1811, beta=0.0000\n",
      "Batch 40, loss=0.0650, recon=0.0649, kl=14.1135, beta=0.0000\n",
      "Batch 60, loss=0.0292, recon=0.0291, kl=15.1232, beta=0.0000\n",
      "Batch 80, loss=0.0319, recon=0.0318, kl=12.9710, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0404, KL: 14.8778, Current Beta: 0.0000) | Avg Valid Loss: 0.0360 | Avg Valid recon Loss: 0.0359\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0336, recon=0.0335, kl=5.3755, beta=0.0000\n",
      "Batch 40, loss=0.0280, recon=0.0279, kl=4.4414, beta=0.0000\n",
      "Batch 60, loss=0.0341, recon=0.0340, kl=6.0254, beta=0.0000\n",
      "Batch 80, loss=0.0245, recon=0.0244, kl=3.5359, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0385, KL: 5.1182, Current Beta: 0.0000) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0621, recon=0.0620, kl=1.1617, beta=0.0000\n",
      "Batch 40, loss=0.0337, recon=0.0337, kl=1.0044, beta=0.0000\n",
      "Batch 60, loss=0.0397, recon=0.0396, kl=1.5981, beta=0.0000\n",
      "Batch 80, loss=0.0340, recon=0.0340, kl=1.2197, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0399 (Recon: 0.0399, KL: 1.4878, Current Beta: 0.0000) | Avg Valid Loss: 0.0337 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0312, recon=0.0312, kl=0.2447, beta=0.0001\n",
      "Batch 40, loss=0.0423, recon=0.0423, kl=0.4634, beta=0.0001\n",
      "Batch 60, loss=0.0318, recon=0.0318, kl=0.1437, beta=0.0001\n",
      "Batch 80, loss=0.0316, recon=0.0316, kl=0.1270, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0380 (Recon: 0.0379, KL: 0.4709, Current Beta: 0.0001) | Avg Valid Loss: 0.0324 | Avg Valid recon Loss: 0.0324\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0311, recon=0.0311, kl=0.0135, beta=0.0003\n",
      "Batch 40, loss=0.0287, recon=0.0287, kl=0.0088, beta=0.0003\n",
      "Batch 60, loss=0.0283, recon=0.0283, kl=0.0266, beta=0.0003\n",
      "Batch 80, loss=0.0321, recon=0.0321, kl=0.0298, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0361, KL: 0.0258, Current Beta: 0.0003) | Avg Valid Loss: 0.0323 | Avg Valid recon Loss: 0.0323\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0386, recon=0.0386, kl=0.0058, beta=0.0008\n",
      "Batch 40, loss=0.0309, recon=0.0309, kl=0.0055, beta=0.0008\n",
      "Batch 60, loss=0.0375, recon=0.0375, kl=0.0758, beta=0.0008\n",
      "Batch 80, loss=0.0544, recon=0.0544, kl=0.0069, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0369 (Recon: 0.0369, KL: 0.0070, Current Beta: 0.0008) | Avg Valid Loss: 0.0306 | Avg Valid recon Loss: 0.0306\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0361, recon=0.0361, kl=0.0011, beta=0.0018\n",
      "Batch 40, loss=0.0232, recon=0.0232, kl=0.0015, beta=0.0018\n",
      "Batch 60, loss=0.0369, recon=0.0369, kl=0.0012, beta=0.0018\n",
      "Batch 80, loss=0.1842, recon=0.1841, kl=0.0012, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0330 (Recon: 0.0330, KL: 0.0017, Current Beta: 0.0018) | Avg Valid Loss: 0.0315 | Avg Valid recon Loss: 0.0315\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0196, recon=0.0196, kl=0.0007, beta=0.0038\n",
      "Batch 40, loss=0.0282, recon=0.0282, kl=0.0007, beta=0.0038\n",
      "Batch 60, loss=0.0346, recon=0.0346, kl=0.0016, beta=0.0038\n",
      "Batch 80, loss=0.0416, recon=0.0416, kl=0.0011, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0342 (Recon: 0.0342, KL: 0.0019, Current Beta: 0.0038) | Avg Valid Loss: 0.0296 | Avg Valid recon Loss: 0.0296\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=0.0011, beta=0.0062\n",
      "Batch 40, loss=0.0229, recon=0.0229, kl=0.0004, beta=0.0062\n",
      "Batch 60, loss=0.0250, recon=0.0250, kl=0.0005, beta=0.0062\n",
      "Batch 80, loss=0.0246, recon=0.0246, kl=0.0011, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0328 (Recon: 0.0328, KL: 0.0022, Current Beta: 0.0062) | Avg Valid Loss: 0.0281 | Avg Valid recon Loss: 0.0281\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0206, recon=0.0206, kl=0.0005, beta=0.0100\n",
      "Batch 40, loss=0.0271, recon=0.0270, kl=0.0047, beta=0.0100\n",
      "Batch 60, loss=0.1625, recon=0.1625, kl=0.0003, beta=0.0100\n",
      "Batch 80, loss=0.0258, recon=0.0258, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0313 (Recon: 0.0313, KL: 0.0016, Current Beta: 0.0100) | Avg Valid Loss: 0.0274 | Avg Valid recon Loss: 0.0273\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0644, recon=0.0644, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0239, recon=0.0239, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0199, recon=0.0199, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0189, recon=0.0189, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0293 (Recon: 0.0293, KL: 0.0006, Current Beta: 0.0100) | Avg Valid Loss: 0.0285 | Avg Valid recon Loss: 0.0284\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0205, recon=0.0205, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0295, recon=0.0295, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0265, recon=0.0265, kl=0.0003, beta=0.0100\n",
      "Batch 80, loss=0.0208, recon=0.0208, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0303 (Recon: 0.0303, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0275 | Avg Valid recon Loss: 0.0275\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0637, recon=0.0637, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0294, recon=0.0294, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0267, recon=0.0267, kl=0.0004, beta=0.0100\n",
      "Batch 80, loss=0.0187, recon=0.0187, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0302 (Recon: 0.0302, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0262 | Avg Valid recon Loss: 0.0262\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0368, recon=0.0368, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0242, recon=0.0241, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0234, recon=0.0233, kl=0.0118, beta=0.0100\n",
      "Batch 80, loss=0.0179, recon=0.0179, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0296 (Recon: 0.0296, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0258 | Avg Valid recon Loss: 0.0258\n",
      "\n",
      "[VRAE Run 197/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7761, recon=0.7761, kl=1.2670, beta=0.0000\n",
      "Batch 40, loss=0.1755, recon=0.1755, kl=63.6101, beta=0.0000\n",
      "Batch 60, loss=0.1483, recon=0.1483, kl=85.0806, beta=0.0000\n",
      "Batch 80, loss=0.1989, recon=0.1989, kl=96.0021, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3027 (Recon: 0.3027, KL: 55.3397, Current Beta: 0.0000) | Avg Valid Loss: 0.1284 | Avg Valid recon Loss: 0.1284\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1049, recon=0.1049, kl=101.7902, beta=0.0000\n",
      "Batch 40, loss=0.0904, recon=0.0904, kl=101.9051, beta=0.0000\n",
      "Batch 60, loss=0.1756, recon=0.1756, kl=106.1764, beta=0.0000\n",
      "Batch 80, loss=0.0857, recon=0.0857, kl=115.1252, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1440 (Recon: 0.1440, KL: 105.8330, Current Beta: 0.0000) | Avg Valid Loss: 0.0947 | Avg Valid recon Loss: 0.0947\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1098, recon=0.1098, kl=109.0331, beta=0.0000\n",
      "Batch 40, loss=0.0712, recon=0.0712, kl=103.1215, beta=0.0000\n",
      "Batch 60, loss=0.0969, recon=0.0969, kl=102.5446, beta=0.0000\n",
      "Batch 80, loss=0.1043, recon=0.1043, kl=103.9107, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1145 (Recon: 0.1145, KL: 105.1107, Current Beta: 0.0000) | Avg Valid Loss: 0.0779 | Avg Valid recon Loss: 0.0779\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0792, recon=0.0791, kl=70.1716, beta=0.0000\n",
      "Batch 40, loss=0.0743, recon=0.0743, kl=63.0248, beta=0.0000\n",
      "Batch 60, loss=0.0777, recon=0.0777, kl=67.0257, beta=0.0000\n",
      "Batch 80, loss=0.0684, recon=0.0683, kl=65.0346, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0947 (Recon: 0.0947, KL: 69.2192, Current Beta: 0.0000) | Avg Valid Loss: 0.0701 | Avg Valid recon Loss: 0.0701\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0662, recon=0.0662, kl=42.6244, beta=0.0000\n",
      "Batch 40, loss=0.0595, recon=0.0595, kl=26.9805, beta=0.0000\n",
      "Batch 60, loss=0.0713, recon=0.0713, kl=27.0793, beta=0.0000\n",
      "Batch 80, loss=0.0621, recon=0.0621, kl=32.1733, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0816 (Recon: 0.0816, KL: 34.8685, Current Beta: 0.0000) | Avg Valid Loss: 0.0624 | Avg Valid recon Loss: 0.0624\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0501, recon=0.0501, kl=11.6616, beta=0.0000\n",
      "Batch 40, loss=0.0519, recon=0.0519, kl=12.3584, beta=0.0000\n",
      "Batch 60, loss=0.0822, recon=0.0822, kl=10.8355, beta=0.0000\n",
      "Batch 80, loss=0.0443, recon=0.0443, kl=9.8743, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0727 (Recon: 0.0727, KL: 13.1740, Current Beta: 0.0000) | Avg Valid Loss: 0.0578 | Avg Valid recon Loss: 0.0578\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0464, recon=0.0464, kl=3.5534, beta=0.0000\n",
      "Batch 40, loss=0.0635, recon=0.0635, kl=4.1772, beta=0.0000\n",
      "Batch 60, loss=0.0481, recon=0.0481, kl=4.4198, beta=0.0000\n",
      "Batch 80, loss=0.0855, recon=0.0855, kl=3.4561, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0664 (Recon: 0.0664, KL: 4.4149, Current Beta: 0.0000) | Avg Valid Loss: 0.0548 | Avg Valid recon Loss: 0.0548\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0684, recon=0.0684, kl=1.4846, beta=0.0000\n",
      "Batch 40, loss=0.0606, recon=0.0606, kl=1.7481, beta=0.0000\n",
      "Batch 60, loss=0.0435, recon=0.0435, kl=1.4271, beta=0.0000\n",
      "Batch 80, loss=0.0444, recon=0.0444, kl=1.2063, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0616 (Recon: 0.0616, KL: 1.6868, Current Beta: 0.0000) | Avg Valid Loss: 0.0517 | Avg Valid recon Loss: 0.0517\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0495, recon=0.0495, kl=0.8067, beta=0.0000\n",
      "Batch 40, loss=0.0405, recon=0.0404, kl=0.5131, beta=0.0000\n",
      "Batch 60, loss=0.0495, recon=0.0495, kl=0.3212, beta=0.0000\n",
      "Batch 80, loss=0.0316, recon=0.0315, kl=0.5637, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0582 (Recon: 0.0581, KL: 0.5452, Current Beta: 0.0000) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0884, recon=0.0884, kl=0.0805, beta=0.0001\n",
      "Batch 40, loss=0.0611, recon=0.0611, kl=0.0641, beta=0.0001\n",
      "Batch 60, loss=0.0289, recon=0.0289, kl=0.0546, beta=0.0001\n",
      "Batch 80, loss=0.0569, recon=0.0569, kl=0.0575, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0551, KL: 0.0846, Current Beta: 0.0001) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0478\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=0.0063, beta=0.0003\n",
      "Batch 40, loss=0.0355, recon=0.0355, kl=0.0044, beta=0.0003\n",
      "Batch 60, loss=0.0398, recon=0.0398, kl=0.0044, beta=0.0003\n",
      "Batch 80, loss=0.0619, recon=0.0619, kl=0.0187, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0524, KL: 0.0077, Current Beta: 0.0003) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0366, recon=0.0366, kl=0.0007, beta=0.0008\n",
      "Batch 40, loss=0.0417, recon=0.0417, kl=0.0010, beta=0.0008\n",
      "Batch 60, loss=0.0442, recon=0.0442, kl=0.0008, beta=0.0008\n",
      "Batch 80, loss=0.0331, recon=0.0331, kl=0.0007, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0501 (Recon: 0.0501, KL: 0.0011, Current Beta: 0.0008) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0408, recon=0.0408, kl=0.0008, beta=0.0018\n",
      "Batch 40, loss=0.0417, recon=0.0417, kl=0.0006, beta=0.0018\n",
      "Batch 60, loss=0.0925, recon=0.0925, kl=0.0015, beta=0.0018\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=0.0003, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0483 (Recon: 0.0483, KL: 0.0004, Current Beta: 0.0018) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0418, recon=0.0418, kl=0.0006, beta=0.0038\n",
      "Batch 40, loss=0.0319, recon=0.0319, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.1016, recon=0.1016, kl=0.0006, beta=0.0038\n",
      "Batch 80, loss=0.0301, recon=0.0301, kl=0.0002, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0366, recon=0.0366, kl=0.0002, beta=0.0062\n",
      "Batch 40, loss=0.0330, recon=0.0330, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0354, recon=0.0354, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0318, recon=0.0318, kl=0.0006, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0450, KL: 0.0003, Current Beta: 0.0062) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0411, recon=0.0411, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0347, recon=0.0347, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.0359, recon=0.0359, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0527, recon=0.0527, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0446, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0391 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0406, recon=0.0406, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0367, recon=0.0367, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0320, recon=0.0320, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0338, recon=0.0338, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0434, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0351, recon=0.0351, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0241, recon=0.0241, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0282, recon=0.0282, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0425, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0239, recon=0.0239, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0362, recon=0.0362, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0311, recon=0.0311, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0371, recon=0.0371, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0416, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0438, recon=0.0438, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0269, recon=0.0269, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0263, recon=0.0263, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0356, recon=0.0356, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0409, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0360 | Avg Valid recon Loss: 0.0360\n",
      "\n",
      "[VRAE Run 198/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1665, recon=0.1665, kl=74.4410, beta=0.0000\n",
      "Batch 40, loss=0.1280, recon=0.1280, kl=94.7369, beta=0.0000\n",
      "Batch 60, loss=0.0812, recon=0.0811, kl=113.9939, beta=0.0000\n",
      "Batch 80, loss=0.0518, recon=0.0518, kl=97.1334, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1465 (Recon: 0.1465, KL: 84.8644, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0491, recon=0.0491, kl=105.0276, beta=0.0000\n",
      "Batch 40, loss=0.0586, recon=0.0586, kl=96.5439, beta=0.0000\n",
      "Batch 60, loss=0.0669, recon=0.0669, kl=96.4326, beta=0.0000\n",
      "Batch 80, loss=0.0491, recon=0.0491, kl=85.5386, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0688 (Recon: 0.0688, KL: 96.8437, Current Beta: 0.0000) | Avg Valid Loss: 0.0523 | Avg Valid recon Loss: 0.0523\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1200, recon=0.1200, kl=104.5357, beta=0.0000\n",
      "Batch 40, loss=0.0438, recon=0.0438, kl=108.1144, beta=0.0000\n",
      "Batch 60, loss=0.0503, recon=0.0503, kl=90.2456, beta=0.0000\n",
      "Batch 80, loss=0.0428, recon=0.0428, kl=100.6693, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0567 (Recon: 0.0567, KL: 100.3061, Current Beta: 0.0000) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0523\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0542, recon=0.0542, kl=89.1119, beta=0.0000\n",
      "Batch 40, loss=0.0515, recon=0.0514, kl=85.6203, beta=0.0000\n",
      "Batch 60, loss=0.0319, recon=0.0319, kl=86.5466, beta=0.0000\n",
      "Batch 80, loss=0.0355, recon=0.0355, kl=82.9523, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0486 (Recon: 0.0486, KL: 86.4504, Current Beta: 0.0000) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0414, recon=0.0413, kl=72.0975, beta=0.0000\n",
      "Batch 40, loss=0.0370, recon=0.0370, kl=70.1109, beta=0.0000\n",
      "Batch 60, loss=0.0273, recon=0.0273, kl=77.0836, beta=0.0000\n",
      "Batch 80, loss=0.0289, recon=0.0289, kl=73.9680, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0444 (Recon: 0.0444, KL: 75.6782, Current Beta: 0.0000) | Avg Valid Loss: 0.0356 | Avg Valid recon Loss: 0.0355\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0455, recon=0.0454, kl=46.4134, beta=0.0000\n",
      "Batch 40, loss=0.0236, recon=0.0235, kl=72.4248, beta=0.0000\n",
      "Batch 60, loss=0.0352, recon=0.0350, kl=67.6364, beta=0.0000\n",
      "Batch 80, loss=0.0597, recon=0.0595, kl=57.6912, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0426 (Recon: 0.0425, KL: 60.6369, Current Beta: 0.0000) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0346, recon=0.0344, kl=37.7415, beta=0.0000\n",
      "Batch 40, loss=0.0299, recon=0.0297, kl=33.8874, beta=0.0000\n",
      "Batch 60, loss=0.0398, recon=0.0395, kl=41.2713, beta=0.0000\n",
      "Batch 80, loss=0.0449, recon=0.0447, kl=32.6758, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0407, KL: 37.7493, Current Beta: 0.0000) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0340\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0356, recon=0.0353, kl=16.1678, beta=0.0000\n",
      "Batch 40, loss=0.0490, recon=0.0488, kl=14.9753, beta=0.0000\n",
      "Batch 60, loss=0.0245, recon=0.0244, kl=9.0469, beta=0.0000\n",
      "Batch 80, loss=0.0318, recon=0.0317, kl=6.5470, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0376 (Recon: 0.0374, KL: 13.0595, Current Beta: 0.0000) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0424, recon=0.0422, kl=4.8574, beta=0.0000\n",
      "Batch 40, loss=0.0301, recon=0.0299, kl=4.7373, beta=0.0000\n",
      "Batch 60, loss=0.0309, recon=0.0308, kl=3.4325, beta=0.0000\n",
      "Batch 80, loss=0.0334, recon=0.0330, kl=10.0180, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0378 (Recon: 0.0376, KL: 5.6815, Current Beta: 0.0000) | Avg Valid Loss: 0.0310 | Avg Valid recon Loss: 0.0307\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0369, recon=0.0359, kl=8.7252, beta=0.0001\n",
      "Batch 40, loss=0.0277, recon=0.0270, kl=5.7866, beta=0.0001\n",
      "Batch 60, loss=0.0398, recon=0.0393, kl=5.2046, beta=0.0001\n",
      "Batch 80, loss=0.0319, recon=0.0313, kl=5.2074, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0360 (Recon: 0.0352, KL: 7.1468, Current Beta: 0.0001) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.2032, recon=0.1980, kl=17.9137, beta=0.0003\n",
      "Batch 40, loss=0.0618, recon=0.0570, kl=16.6489, beta=0.0003\n",
      "Batch 60, loss=0.0472, recon=0.0435, kl=12.5804, beta=0.0003\n",
      "Batch 80, loss=0.0843, recon=0.0731, kl=38.0320, beta=0.0003\n",
      "  â†’ Avg Train Loss: 11707.8105 (Recon: 11706.2388, KL: 5360.0574, Current Beta: 0.0003) | Avg Valid Loss: 0.0587 | Avg Valid recon Loss: 0.0467\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0958, recon=0.0808, kl=19.7340, beta=0.0008\n",
      "Batch 40, loss=0.0484, recon=0.0391, kl=12.3141, beta=0.0008\n",
      "Batch 60, loss=0.0509, recon=0.0384, kl=16.5468, beta=0.0008\n",
      "Batch 80, loss=0.0919, recon=0.0804, kl=15.1956, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.1159 (Recon: 0.0997, KL: 21.3980, Current Beta: 0.0008) | Avg Valid Loss: 0.0821 | Avg Valid recon Loss: 0.0550\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0833, recon=0.0336, kl=27.2442, beta=0.0018\n",
      "Batch 40, loss=0.0605, recon=0.0336, kl=14.7679, beta=0.0018\n",
      "Batch 60, loss=0.0420, recon=0.0297, kl=6.7145, beta=0.0018\n",
      "Batch 80, loss=0.0822, recon=0.0356, kl=25.5596, beta=0.0018\n",
      "  â†’ Avg Train Loss: 72.2723 (Recon: 72.1769, KL: 52.2535, Current Beta: 0.0018) | Avg Valid Loss: 0.0960 | Avg Valid recon Loss: 0.0497\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0926, recon=0.0406, kl=13.7511, beta=0.0038\n",
      "Batch 40, loss=0.0727, recon=0.0498, kl=6.0881, beta=0.0038\n",
      "Batch 60, loss=0.1608, recon=0.0996, kl=16.2028, beta=0.0038\n",
      "Batch 80, loss=0.0833, recon=0.0294, kl=14.2907, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1252 (Recon: 0.0736, KL: 13.6739, Current Beta: 0.0038) | Avg Valid Loss: 0.0871 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0957, recon=0.0559, kl=6.3923, beta=0.0062\n",
      "Batch 40, loss=0.1752, recon=0.0675, kl=17.3079, beta=0.0062\n",
      "Batch 60, loss=0.1615, recon=0.0516, kl=17.6537, beta=0.0062\n",
      "Batch 80, loss=0.2028, recon=0.1158, kl=13.9774, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.2468 (Recon: 0.1654, KL: 13.0822, Current Beta: 0.0062) | Avg Valid Loss: 0.1775 | Avg Valid recon Loss: 0.0792\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.2663, recon=0.1769, kl=8.9428, beta=0.0100\n",
      "Batch 40, loss=0.1731, recon=0.0733, kl=9.9710, beta=0.0100\n",
      "Batch 60, loss=0.1843, recon=0.0669, kl=11.7469, beta=0.0100\n",
      "Batch 80, loss=0.1367, recon=0.0547, kl=8.1988, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.2206 (Recon: 0.1224, KL: 9.8270, Current Beta: 0.0100) | Avg Valid Loss: 4.8861 | Avg Valid recon Loss: 4.8007\n",
      "Epoch 17/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 199/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5585, recon=0.5585, kl=0.1851, beta=0.0000\n",
      "Batch 40, loss=0.3654, recon=0.3654, kl=0.9844, beta=0.0000\n",
      "Batch 60, loss=0.8257, recon=0.8257, kl=7.7677, beta=0.0000\n",
      "Batch 80, loss=0.3387, recon=0.3387, kl=14.3088, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5651 (Recon: 0.5651, KL: 5.2746, Current Beta: 0.0000) | Avg Valid Loss: 0.3571 | Avg Valid recon Loss: 0.3571\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3358, recon=0.3358, kl=20.6174, beta=0.0000\n",
      "Batch 40, loss=0.2443, recon=0.2443, kl=22.9121, beta=0.0000\n",
      "Batch 60, loss=0.1895, recon=0.1895, kl=25.5927, beta=0.0000\n",
      "Batch 80, loss=0.1877, recon=0.1877, kl=27.8178, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2838 (Recon: 0.2838, KL: 23.6534, Current Beta: 0.0000) | Avg Valid Loss: 0.2126 | Avg Valid recon Loss: 0.2126\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2645, recon=0.2645, kl=30.3986, beta=0.0000\n",
      "Batch 40, loss=0.2490, recon=0.2490, kl=31.9004, beta=0.0000\n",
      "Batch 60, loss=0.1608, recon=0.1608, kl=33.2337, beta=0.0000\n",
      "Batch 80, loss=0.1603, recon=0.1603, kl=34.2272, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2020 (Recon: 0.2020, KL: 32.1003, Current Beta: 0.0000) | Avg Valid Loss: 0.1595 | Avg Valid recon Loss: 0.1595\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1995, recon=0.1995, kl=34.5659, beta=0.0000\n",
      "Batch 40, loss=0.1969, recon=0.1969, kl=35.0844, beta=0.0000\n",
      "Batch 60, loss=0.1356, recon=0.1355, kl=35.3810, beta=0.0000\n",
      "Batch 80, loss=0.1713, recon=0.1713, kl=34.9724, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1599 (Recon: 0.1599, KL: 34.9843, Current Beta: 0.0000) | Avg Valid Loss: 0.1300 | Avg Valid recon Loss: 0.1300\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1131, recon=0.1131, kl=33.7599, beta=0.0000\n",
      "Batch 40, loss=0.1268, recon=0.1267, kl=31.7552, beta=0.0000\n",
      "Batch 60, loss=0.1104, recon=0.1104, kl=30.2450, beta=0.0000\n",
      "Batch 80, loss=0.0678, recon=0.0678, kl=28.9598, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1343 (Recon: 0.1343, KL: 31.5413, Current Beta: 0.0000) | Avg Valid Loss: 0.1132 | Avg Valid recon Loss: 0.1132\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0979, recon=0.0978, kl=24.5473, beta=0.0000\n",
      "Batch 40, loss=0.1057, recon=0.1057, kl=20.6593, beta=0.0000\n",
      "Batch 60, loss=0.0873, recon=0.0872, kl=18.4675, beta=0.0000\n",
      "Batch 80, loss=0.1056, recon=0.1055, kl=17.8516, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1178 (Recon: 0.1178, KL: 21.1996, Current Beta: 0.0000) | Avg Valid Loss: 0.1016 | Avg Valid recon Loss: 0.1015\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0962, recon=0.0961, kl=13.6664, beta=0.0000\n",
      "Batch 40, loss=0.1405, recon=0.1405, kl=10.6191, beta=0.0000\n",
      "Batch 60, loss=0.0966, recon=0.0966, kl=9.7372, beta=0.0000\n",
      "Batch 80, loss=0.1080, recon=0.1079, kl=9.3999, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1062 (Recon: 0.1061, KL: 11.5084, Current Beta: 0.0000) | Avg Valid Loss: 0.0950 | Avg Valid recon Loss: 0.0949\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1961, recon=0.1961, kl=4.5662, beta=0.0000\n",
      "Batch 40, loss=0.0763, recon=0.0762, kl=3.6671, beta=0.0000\n",
      "Batch 60, loss=0.0709, recon=0.0709, kl=3.6683, beta=0.0000\n",
      "Batch 80, loss=0.0686, recon=0.0686, kl=3.0032, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0985 (Recon: 0.0985, KL: 4.2536, Current Beta: 0.0000) | Avg Valid Loss: 0.0883 | Avg Valid recon Loss: 0.0883\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0867, recon=0.0866, kl=0.8739, beta=0.0000\n",
      "Batch 40, loss=0.0688, recon=0.0688, kl=0.8592, beta=0.0000\n",
      "Batch 60, loss=0.1031, recon=0.1030, kl=0.6625, beta=0.0000\n",
      "Batch 80, loss=0.0739, recon=0.0739, kl=0.6502, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0918 (Recon: 0.0918, KL: 0.9613, Current Beta: 0.0000) | Avg Valid Loss: 0.0828 | Avg Valid recon Loss: 0.0828\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.2738, recon=0.2737, kl=0.1191, beta=0.0001\n",
      "Batch 40, loss=0.0478, recon=0.0478, kl=0.0961, beta=0.0001\n",
      "Batch 60, loss=0.0490, recon=0.0490, kl=0.0788, beta=0.0001\n",
      "Batch 80, loss=0.0875, recon=0.0875, kl=0.0772, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0869 (Recon: 0.0868, KL: 0.1297, Current Beta: 0.0001) | Avg Valid Loss: 0.0793 | Avg Valid recon Loss: 0.0793\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1940, recon=0.1940, kl=0.0075, beta=0.0003\n",
      "Batch 40, loss=0.2712, recon=0.2712, kl=0.0099, beta=0.0003\n",
      "Batch 60, loss=0.0596, recon=0.0596, kl=0.0079, beta=0.0003\n",
      "Batch 80, loss=0.0540, recon=0.0540, kl=0.0061, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0827 (Recon: 0.0827, KL: 0.0105, Current Beta: 0.0003) | Avg Valid Loss: 0.0756 | Avg Valid recon Loss: 0.0756\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0626, recon=0.0626, kl=0.0029, beta=0.0008\n",
      "Batch 40, loss=0.0575, recon=0.0575, kl=0.0018, beta=0.0008\n",
      "Batch 60, loss=0.0647, recon=0.0647, kl=0.0012, beta=0.0008\n",
      "Batch 80, loss=0.0454, recon=0.0454, kl=0.0012, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0790 (Recon: 0.0790, KL: 0.0019, Current Beta: 0.0008) | Avg Valid Loss: 0.0724 | Avg Valid recon Loss: 0.0724\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1292, recon=0.1292, kl=0.0003, beta=0.0018\n",
      "Batch 40, loss=0.0540, recon=0.0540, kl=0.0001, beta=0.0018\n",
      "Batch 60, loss=0.0449, recon=0.0449, kl=0.0004, beta=0.0018\n",
      "Batch 80, loss=0.0490, recon=0.0490, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0763 (Recon: 0.0763, KL: 0.0003, Current Beta: 0.0018) | Avg Valid Loss: 0.0696 | Avg Valid recon Loss: 0.0696\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0840, recon=0.0840, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0634, recon=0.0634, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.0672, recon=0.0672, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0513, recon=0.0513, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0738 (Recon: 0.0738, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0687 | Avg Valid recon Loss: 0.0687\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0733, recon=0.0733, kl=0.0000, beta=0.0062\n",
      "Batch 40, loss=0.0692, recon=0.0692, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0474, recon=0.0474, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0464, recon=0.0464, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0719 (Recon: 0.0719, KL: 0.0000, Current Beta: 0.0062) | Avg Valid Loss: 0.0661 | Avg Valid recon Loss: 0.0661\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0614, recon=0.0614, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0881, recon=0.0881, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0436, recon=0.0436, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0700, recon=0.0700, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0698 (Recon: 0.0698, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0634 | Avg Valid recon Loss: 0.0634\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0649, recon=0.0649, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0493, recon=0.0493, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0465, recon=0.0465, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0524, recon=0.0524, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0681 (Recon: 0.0681, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0621 | Avg Valid recon Loss: 0.0621\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0497, recon=0.0497, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0555, recon=0.0555, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0742, recon=0.0742, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0487, recon=0.0487, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0667 (Recon: 0.0667, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0603 | Avg Valid recon Loss: 0.0603\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0639, recon=0.0639, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0715, recon=0.0715, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0470, recon=0.0470, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0698, recon=0.0698, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0651 (Recon: 0.0651, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0593 | Avg Valid recon Loss: 0.0593\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0585, recon=0.0585, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0416, recon=0.0416, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0643, recon=0.0643, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0656, recon=0.0656, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0637 (Recon: 0.0637, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0578 | Avg Valid recon Loss: 0.0578\n",
      "\n",
      "[VRAE Run 200/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2378, recon=0.2378, kl=15.6357, beta=0.0000\n",
      "Batch 40, loss=0.1989, recon=0.1989, kl=28.6092, beta=0.0000\n",
      "Batch 60, loss=0.3740, recon=0.3740, kl=33.9037, beta=0.0000\n",
      "Batch 80, loss=0.0983, recon=0.0983, kl=36.5534, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2269 (Recon: 0.2269, KL: 25.4561, Current Beta: 0.0000) | Avg Valid Loss: 0.0961 | Avg Valid recon Loss: 0.0961\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0963, recon=0.0963, kl=34.5380, beta=0.0000\n",
      "Batch 40, loss=0.0577, recon=0.0577, kl=36.5411, beta=0.0000\n",
      "Batch 60, loss=0.0564, recon=0.0564, kl=38.8762, beta=0.0000\n",
      "Batch 80, loss=0.0588, recon=0.0588, kl=40.2150, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0885 (Recon: 0.0885, KL: 37.2187, Current Beta: 0.0000) | Avg Valid Loss: 0.0680 | Avg Valid recon Loss: 0.0680\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0539, recon=0.0539, kl=40.7795, beta=0.0000\n",
      "Batch 40, loss=0.0395, recon=0.0395, kl=39.7070, beta=0.0000\n",
      "Batch 60, loss=0.0481, recon=0.0481, kl=39.1826, beta=0.0000\n",
      "Batch 80, loss=0.0380, recon=0.0380, kl=37.8850, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0695 (Recon: 0.0695, KL: 39.3005, Current Beta: 0.0000) | Avg Valid Loss: 0.0593 | Avg Valid recon Loss: 0.0593\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0406, recon=0.0406, kl=32.8020, beta=0.0000\n",
      "Batch 40, loss=0.0388, recon=0.0388, kl=32.8127, beta=0.0000\n",
      "Batch 60, loss=0.0426, recon=0.0426, kl=30.9758, beta=0.0000\n",
      "Batch 80, loss=0.0597, recon=0.0596, kl=27.8376, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0618 (Recon: 0.0618, KL: 31.4357, Current Beta: 0.0000) | Avg Valid Loss: 0.0528 | Avg Valid recon Loss: 0.0528\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0630, recon=0.0629, kl=24.7679, beta=0.0000\n",
      "Batch 40, loss=0.0404, recon=0.0404, kl=24.5322, beta=0.0000\n",
      "Batch 60, loss=0.0791, recon=0.0790, kl=21.9984, beta=0.0000\n",
      "Batch 80, loss=0.0407, recon=0.0407, kl=21.1540, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0566 (Recon: 0.0566, KL: 23.4108, Current Beta: 0.0000) | Avg Valid Loss: 0.0490 | Avg Valid recon Loss: 0.0490\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0452, recon=0.0452, kl=13.5844, beta=0.0000\n",
      "Batch 40, loss=0.0749, recon=0.0749, kl=12.4510, beta=0.0000\n",
      "Batch 60, loss=0.0399, recon=0.0398, kl=11.2540, beta=0.0000\n",
      "Batch 80, loss=0.0551, recon=0.0551, kl=11.9786, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0534, KL: 12.8251, Current Beta: 0.0000) | Avg Valid Loss: 0.0467 | Avg Valid recon Loss: 0.0467\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0554, recon=0.0553, kl=5.1943, beta=0.0000\n",
      "Batch 40, loss=0.0462, recon=0.0462, kl=4.9384, beta=0.0000\n",
      "Batch 60, loss=0.0304, recon=0.0304, kl=3.9009, beta=0.0000\n",
      "Batch 80, loss=0.0880, recon=0.0880, kl=2.4835, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0538 (Recon: 0.0538, KL: 4.9609, Current Beta: 0.0000) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0456\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0348, recon=0.0348, kl=0.4864, beta=0.0000\n",
      "Batch 40, loss=0.0967, recon=0.0966, kl=0.6397, beta=0.0000\n",
      "Batch 60, loss=0.1326, recon=0.1326, kl=1.1640, beta=0.0000\n",
      "Batch 80, loss=0.0617, recon=0.0617, kl=0.2862, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0497, KL: 0.8357, Current Beta: 0.0000) | Avg Valid Loss: 0.0503 | Avg Valid recon Loss: 0.0503\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=0.1095, beta=0.0000\n",
      "Batch 40, loss=0.0261, recon=0.0261, kl=0.1827, beta=0.0000\n",
      "Batch 60, loss=0.0480, recon=0.0480, kl=0.0381, beta=0.0000\n",
      "Batch 80, loss=0.0411, recon=0.0411, kl=0.3640, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0496, KL: 0.1606, Current Beta: 0.0000) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0570, recon=0.0570, kl=0.0068, beta=0.0001\n",
      "Batch 40, loss=0.0334, recon=0.0334, kl=0.0136, beta=0.0001\n",
      "Batch 60, loss=0.0328, recon=0.0328, kl=0.0119, beta=0.0001\n",
      "Batch 80, loss=0.0281, recon=0.0281, kl=0.0226, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 0.0279, Current Beta: 0.0001) | Avg Valid Loss: 0.0400 | Avg Valid recon Loss: 0.0400\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0282, recon=0.0282, kl=0.0030, beta=0.0003\n",
      "Batch 40, loss=0.0275, recon=0.0275, kl=0.0015, beta=0.0003\n",
      "Batch 60, loss=0.0740, recon=0.0740, kl=0.0015, beta=0.0003\n",
      "Batch 80, loss=0.0388, recon=0.0388, kl=0.0068, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0422 (Recon: 0.0422, KL: 0.0059, Current Beta: 0.0003) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0773, recon=0.0773, kl=0.0005, beta=0.0008\n",
      "Batch 40, loss=0.0332, recon=0.0332, kl=0.0013, beta=0.0008\n",
      "Batch 60, loss=0.0295, recon=0.0295, kl=0.0007, beta=0.0008\n",
      "Batch 80, loss=0.0362, recon=0.0362, kl=0.0005, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0430, KL: 0.0009, Current Beta: 0.0008) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0304, recon=0.0304, kl=0.0001, beta=0.0018\n",
      "Batch 40, loss=0.0360, recon=0.0360, kl=0.0003, beta=0.0018\n",
      "Batch 60, loss=0.0321, recon=0.0321, kl=0.0001, beta=0.0018\n",
      "Batch 80, loss=0.0474, recon=0.0474, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0446, KL: 0.0001, Current Beta: 0.0018) | Avg Valid Loss: 0.0492 | Avg Valid recon Loss: 0.0492\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0391, recon=0.0391, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0274, recon=0.0274, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.0251, recon=0.0251, kl=0.0002, beta=0.0038\n",
      "Batch 80, loss=0.0586, recon=0.0586, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0506 (Recon: 0.0506, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0386 | Avg Valid recon Loss: 0.0386\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0963, recon=0.0963, kl=0.0000, beta=0.0062\n",
      "Batch 40, loss=0.0507, recon=0.0507, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0248, recon=0.0248, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0428, recon=0.0428, kl=0.0004, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0446, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0260, recon=0.0260, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0358, recon=0.0358, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0375, recon=0.0375, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0566, recon=0.0566, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0395, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0240, recon=0.0240, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0283, recon=0.0283, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0272, recon=0.0272, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0312, recon=0.0312, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0381 (Recon: 0.0381, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0313 | Avg Valid recon Loss: 0.0313\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0235, recon=0.0235, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0245, recon=0.0245, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0281, recon=0.0281, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0270, recon=0.0270, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0365 (Recon: 0.0365, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0307\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0271, recon=0.0271, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0304, recon=0.0304, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0330, recon=0.0330, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.2316, recon=0.2316, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0352 (Recon: 0.0352, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0315 | Avg Valid recon Loss: 0.0315\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0223, recon=0.0223, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0453, recon=0.0453, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0329, recon=0.0329, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0271, recon=0.0271, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0350 (Recon: 0.0350, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0298 | Avg Valid recon Loss: 0.0298\n",
      "\n",
      "[VRAE Run 201/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=1.0811, recon=1.0811, kl=0.4217, beta=0.0000\n",
      "Batch 40, loss=0.5613, recon=0.5613, kl=2.0497, beta=0.0000\n",
      "Batch 60, loss=0.2708, recon=0.2708, kl=13.6273, beta=0.0000\n",
      "Batch 80, loss=0.3810, recon=0.3810, kl=20.0022, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5832 (Recon: 0.5832, KL: 8.2370, Current Beta: 0.0000) | Avg Valid Loss: 0.3781 | Avg Valid recon Loss: 0.3781\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.4950, recon=0.4950, kl=29.9570, beta=0.0000\n",
      "Batch 40, loss=0.1849, recon=0.1849, kl=35.4983, beta=0.0000\n",
      "Batch 60, loss=0.2423, recon=0.2423, kl=41.6242, beta=0.0000\n",
      "Batch 80, loss=0.3559, recon=0.3559, kl=47.4325, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2897 (Recon: 0.2897, KL: 37.3287, Current Beta: 0.0000) | Avg Valid Loss: 0.2170 | Avg Valid recon Loss: 0.2170\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1623, recon=0.1623, kl=53.5257, beta=0.0000\n",
      "Batch 40, loss=0.2016, recon=0.2016, kl=54.0785, beta=0.0000\n",
      "Batch 60, loss=0.1131, recon=0.1131, kl=55.7163, beta=0.0000\n",
      "Batch 80, loss=0.1223, recon=0.1223, kl=56.4795, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2030 (Recon: 0.2030, KL: 54.4029, Current Beta: 0.0000) | Avg Valid Loss: 0.1613 | Avg Valid recon Loss: 0.1612\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1559, recon=0.1559, kl=55.5082, beta=0.0000\n",
      "Batch 40, loss=0.1359, recon=0.1359, kl=55.5939, beta=0.0000\n",
      "Batch 60, loss=0.1270, recon=0.1270, kl=52.8130, beta=0.0000\n",
      "Batch 80, loss=0.1421, recon=0.1421, kl=52.9330, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1613 (Recon: 0.1613, KL: 54.4862, Current Beta: 0.0000) | Avg Valid Loss: 0.1334 | Avg Valid recon Loss: 0.1333\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0885, recon=0.0885, kl=50.4926, beta=0.0000\n",
      "Batch 40, loss=0.1220, recon=0.1220, kl=47.6143, beta=0.0000\n",
      "Batch 60, loss=0.1317, recon=0.1316, kl=44.9645, beta=0.0000\n",
      "Batch 80, loss=0.1009, recon=0.1008, kl=43.6270, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1353 (Recon: 0.1353, KL: 47.2669, Current Beta: 0.0000) | Avg Valid Loss: 0.1172 | Avg Valid recon Loss: 0.1172\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1050, recon=0.1049, kl=36.8581, beta=0.0000\n",
      "Batch 40, loss=0.0871, recon=0.0870, kl=29.0489, beta=0.0000\n",
      "Batch 60, loss=0.0712, recon=0.0711, kl=26.5796, beta=0.0000\n",
      "Batch 80, loss=0.1010, recon=0.1010, kl=25.8283, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1190 (Recon: 0.1190, KL: 30.9815, Current Beta: 0.0000) | Avg Valid Loss: 0.1055 | Avg Valid recon Loss: 0.1054\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2178, recon=0.2177, kl=15.1204, beta=0.0000\n",
      "Batch 40, loss=0.0930, recon=0.0929, kl=13.8204, beta=0.0000\n",
      "Batch 60, loss=0.0867, recon=0.0866, kl=12.4550, beta=0.0000\n",
      "Batch 80, loss=0.2199, recon=0.2199, kl=11.6055, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1078 (Recon: 0.1077, KL: 14.5823, Current Beta: 0.0000) | Avg Valid Loss: 0.0967 | Avg Valid recon Loss: 0.0966\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0749, recon=0.0748, kl=5.7852, beta=0.0000\n",
      "Batch 40, loss=0.0861, recon=0.0861, kl=3.9311, beta=0.0000\n",
      "Batch 60, loss=0.0631, recon=0.0630, kl=3.4337, beta=0.0000\n",
      "Batch 80, loss=0.0504, recon=0.0504, kl=3.3719, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0997 (Recon: 0.0996, KL: 4.5766, Current Beta: 0.0000) | Avg Valid Loss: 0.0900 | Avg Valid recon Loss: 0.0900\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1880, recon=0.1880, kl=1.0309, beta=0.0000\n",
      "Batch 40, loss=0.1629, recon=0.1629, kl=0.9306, beta=0.0000\n",
      "Batch 60, loss=0.0639, recon=0.0638, kl=0.9723, beta=0.0000\n",
      "Batch 80, loss=0.0736, recon=0.0736, kl=0.7875, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0933 (Recon: 0.0933, KL: 1.0634, Current Beta: 0.0000) | Avg Valid Loss: 0.0846 | Avg Valid recon Loss: 0.0846\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0649, recon=0.0648, kl=0.2041, beta=0.0001\n",
      "Batch 40, loss=0.0643, recon=0.0643, kl=0.1923, beta=0.0001\n",
      "Batch 60, loss=0.2650, recon=0.2650, kl=0.1324, beta=0.0001\n",
      "Batch 80, loss=0.0612, recon=0.0611, kl=0.0941, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0880 (Recon: 0.0880, KL: 0.1862, Current Beta: 0.0001) | Avg Valid Loss: 0.0803 | Avg Valid recon Loss: 0.0803\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1054, recon=0.1054, kl=0.0097, beta=0.0003\n",
      "Batch 40, loss=0.1059, recon=0.1059, kl=0.0131, beta=0.0003\n",
      "Batch 60, loss=0.0706, recon=0.0706, kl=0.0076, beta=0.0003\n",
      "Batch 80, loss=0.0712, recon=0.0712, kl=0.0068, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0835 (Recon: 0.0835, KL: 0.0149, Current Beta: 0.0003) | Avg Valid Loss: 0.0767 | Avg Valid recon Loss: 0.0767\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0612, recon=0.0612, kl=0.0014, beta=0.0008\n",
      "Batch 40, loss=0.0696, recon=0.0695, kl=0.0014, beta=0.0008\n",
      "Batch 60, loss=0.0891, recon=0.0891, kl=0.0008, beta=0.0008\n",
      "Batch 80, loss=0.0652, recon=0.0652, kl=0.0004, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0801 (Recon: 0.0801, KL: 0.0012, Current Beta: 0.0008) | Avg Valid Loss: 0.0743 | Avg Valid recon Loss: 0.0743\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0587, recon=0.0587, kl=0.0002, beta=0.0018\n",
      "Batch 40, loss=0.0550, recon=0.0550, kl=0.0004, beta=0.0018\n",
      "Batch 60, loss=0.0685, recon=0.0685, kl=0.0002, beta=0.0018\n",
      "Batch 80, loss=0.0522, recon=0.0522, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0773 (Recon: 0.0773, KL: 0.0002, Current Beta: 0.0018) | Avg Valid Loss: 0.0715 | Avg Valid recon Loss: 0.0715\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0469, recon=0.0469, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0492, recon=0.0492, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.0820, recon=0.0820, kl=0.0000, beta=0.0038\n",
      "Batch 80, loss=0.0727, recon=0.0727, kl=0.0000, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0746 (Recon: 0.0746, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0687 | Avg Valid recon Loss: 0.0687\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1404, recon=0.1404, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0433, recon=0.0433, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0394, recon=0.0394, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0547, recon=0.0547, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0718 (Recon: 0.0718, KL: 0.0000, Current Beta: 0.0062) | Avg Valid Loss: 0.0673 | Avg Valid recon Loss: 0.0673\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0917, recon=0.0917, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0495, recon=0.0495, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0548, recon=0.0548, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0386, recon=0.0386, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0702 (Recon: 0.0702, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0648 | Avg Valid recon Loss: 0.0648\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0615, recon=0.0615, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0607, recon=0.0607, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0498, recon=0.0498, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0444, recon=0.0444, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0682 (Recon: 0.0682, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0631 | Avg Valid recon Loss: 0.0631\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0382, recon=0.0382, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0731, recon=0.0731, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.1206, recon=0.1206, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0605, recon=0.0605, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0665 (Recon: 0.0665, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0617 | Avg Valid recon Loss: 0.0617\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0422, recon=0.0422, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0744, recon=0.0744, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0345, recon=0.0345, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0783, recon=0.0783, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0648 (Recon: 0.0648, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0607 | Avg Valid recon Loss: 0.0607\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1008, recon=0.1008, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0500, recon=0.0500, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0416, recon=0.0416, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0642, recon=0.0642, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0635 (Recon: 0.0635, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0593 | Avg Valid recon Loss: 0.0593\n",
      "\n",
      "[VRAE Run 202/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2808, recon=0.2808, kl=25.0725, beta=0.0000\n",
      "Batch 40, loss=0.1828, recon=0.1828, kl=45.6080, beta=0.0000\n",
      "Batch 60, loss=0.1723, recon=0.1723, kl=58.4717, beta=0.0000\n",
      "Batch 80, loss=0.0661, recon=0.0661, kl=63.6334, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2317 (Recon: 0.2317, KL: 43.7889, Current Beta: 0.0000) | Avg Valid Loss: 0.0988 | Avg Valid recon Loss: 0.0988\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1197, recon=0.1197, kl=68.3197, beta=0.0000\n",
      "Batch 40, loss=0.0672, recon=0.0672, kl=67.9398, beta=0.0000\n",
      "Batch 60, loss=0.0554, recon=0.0554, kl=68.6060, beta=0.0000\n",
      "Batch 80, loss=0.0683, recon=0.0683, kl=71.0097, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0825 (Recon: 0.0825, KL: 68.5361, Current Beta: 0.0000) | Avg Valid Loss: 0.0732 | Avg Valid recon Loss: 0.0732\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0554, recon=0.0554, kl=67.8593, beta=0.0000\n",
      "Batch 40, loss=0.0576, recon=0.0576, kl=67.1683, beta=0.0000\n",
      "Batch 60, loss=0.0661, recon=0.0661, kl=66.8731, beta=0.0000\n",
      "Batch 80, loss=0.0746, recon=0.0746, kl=65.9088, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0741 (Recon: 0.0740, KL: 67.3356, Current Beta: 0.0000) | Avg Valid Loss: 0.0795 | Avg Valid recon Loss: 0.0795\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0363, recon=0.0363, kl=46.2482, beta=0.0000\n",
      "Batch 40, loss=0.1771, recon=0.1771, kl=50.6884, beta=0.0000\n",
      "Batch 60, loss=0.0316, recon=0.0316, kl=53.1368, beta=0.0000\n",
      "Batch 80, loss=0.0484, recon=0.0484, kl=57.1749, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0647 (Recon: 0.0647, KL: 53.2156, Current Beta: 0.0000) | Avg Valid Loss: 0.0542 | Avg Valid recon Loss: 0.0542\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0342, recon=0.0342, kl=37.7758, beta=0.0000\n",
      "Batch 40, loss=0.0414, recon=0.0414, kl=35.0483, beta=0.0000\n",
      "Batch 60, loss=0.0310, recon=0.0310, kl=39.0770, beta=0.0000\n",
      "Batch 80, loss=0.5259, recon=0.5258, kl=35.4285, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 38.5719, Current Beta: 0.0000) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0537\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0474, recon=0.0474, kl=26.3247, beta=0.0000\n",
      "Batch 40, loss=0.0433, recon=0.0432, kl=24.8302, beta=0.0000\n",
      "Batch 60, loss=0.0422, recon=0.0421, kl=23.7629, beta=0.0000\n",
      "Batch 80, loss=0.0343, recon=0.0343, kl=24.0118, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0572 (Recon: 0.0571, KL: 25.7129, Current Beta: 0.0000) | Avg Valid Loss: 0.0477 | Avg Valid recon Loss: 0.0476\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0355, recon=0.0354, kl=13.5184, beta=0.0000\n",
      "Batch 40, loss=0.0343, recon=0.0343, kl=9.7202, beta=0.0000\n",
      "Batch 60, loss=0.0545, recon=0.0544, kl=14.7995, beta=0.0000\n",
      "Batch 80, loss=0.0649, recon=0.0649, kl=9.5932, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0532, KL: 12.4108, Current Beta: 0.0000) | Avg Valid Loss: 0.0482 | Avg Valid recon Loss: 0.0481\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0822, recon=0.0822, kl=2.6532, beta=0.0000\n",
      "Batch 40, loss=0.0347, recon=0.0347, kl=2.9298, beta=0.0000\n",
      "Batch 60, loss=0.0320, recon=0.0320, kl=6.0795, beta=0.0000\n",
      "Batch 80, loss=0.0586, recon=0.0585, kl=4.3075, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0499 (Recon: 0.0498, KL: 4.0034, Current Beta: 0.0000) | Avg Valid Loss: 0.0487 | Avg Valid recon Loss: 0.0487\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0356, recon=0.0356, kl=0.8608, beta=0.0000\n",
      "Batch 40, loss=0.0406, recon=0.0406, kl=0.9247, beta=0.0000\n",
      "Batch 60, loss=0.0498, recon=0.0498, kl=0.4443, beta=0.0000\n",
      "Batch 80, loss=0.0324, recon=0.0324, kl=0.3034, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0508, KL: 0.8002, Current Beta: 0.0000) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0329, recon=0.0329, kl=0.0251, beta=0.0001\n",
      "Batch 40, loss=0.0394, recon=0.0394, kl=0.0752, beta=0.0001\n",
      "Batch 60, loss=0.0333, recon=0.0333, kl=0.0709, beta=0.0001\n",
      "Batch 80, loss=0.0389, recon=0.0389, kl=0.0393, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0462, KL: 0.0648, Current Beta: 0.0001) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0953, recon=0.0953, kl=0.0040, beta=0.0003\n",
      "Batch 40, loss=0.0378, recon=0.0378, kl=0.0026, beta=0.0003\n",
      "Batch 60, loss=0.0326, recon=0.0326, kl=0.0130, beta=0.0003\n",
      "Batch 80, loss=0.0301, recon=0.0301, kl=0.0038, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0447 (Recon: 0.0447, KL: 0.0078, Current Beta: 0.0003) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=0.0028, beta=0.0008\n",
      "Batch 40, loss=0.0309, recon=0.0309, kl=0.0013, beta=0.0008\n",
      "Batch 60, loss=0.0299, recon=0.0299, kl=0.0022, beta=0.0008\n",
      "Batch 80, loss=0.0354, recon=0.0354, kl=0.0012, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0443 (Recon: 0.0443, KL: 0.0016, Current Beta: 0.0008) | Avg Valid Loss: 0.0589 | Avg Valid recon Loss: 0.0589\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0617, recon=0.0617, kl=0.0010, beta=0.0018\n",
      "Batch 40, loss=0.0549, recon=0.0549, kl=0.0007, beta=0.0018\n",
      "Batch 60, loss=0.0606, recon=0.0606, kl=0.0006, beta=0.0018\n",
      "Batch 80, loss=0.0364, recon=0.0364, kl=0.0020, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0594 (Recon: 0.0594, KL: 0.0010, Current Beta: 0.0018) | Avg Valid Loss: 0.0427 | Avg Valid recon Loss: 0.0427\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0334, recon=0.0334, kl=0.0002, beta=0.0038\n",
      "Batch 40, loss=0.0342, recon=0.0342, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.0280, recon=0.0280, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0643, recon=0.0643, kl=0.0005, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0447 (Recon: 0.0447, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.0394 | Avg Valid recon Loss: 0.0394\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0255, recon=0.0255, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0315, recon=0.0315, kl=0.0002, beta=0.0062\n",
      "Batch 60, loss=0.0382, recon=0.0382, kl=0.0002, beta=0.0062\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0424, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0414 | Avg Valid recon Loss: 0.0414\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0409, recon=0.0409, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0296, recon=0.0296, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0318, recon=0.0318, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0459 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0405, recon=0.0405, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0369, recon=0.0369, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.1290, recon=0.1290, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0451, recon=0.0451, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0364, recon=0.0364, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0391, recon=0.0391, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0338, recon=0.0338, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0358, recon=0.0358, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0427 (Recon: 0.0427, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0516 | Avg Valid recon Loss: 0.0516\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0334, recon=0.0334, kl=0.0007, beta=0.0100\n",
      "Batch 40, loss=0.0368, recon=0.0368, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0336, recon=0.0336, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0324, recon=0.0324, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0457, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0544 | Avg Valid recon Loss: 0.0544\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0614, recon=0.0614, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0571, recon=0.0571, kl=0.0007, beta=0.0100\n",
      "Batch 60, loss=0.0396, recon=0.0396, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0498, recon=0.0498, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0533, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0407\n",
      "\n",
      "[VRAE Run 203/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6625, recon=0.6625, kl=1.0010, beta=0.0000\n",
      "Batch 40, loss=0.4680, recon=0.4680, kl=3.9262, beta=0.0000\n",
      "Batch 60, loss=0.4559, recon=0.4559, kl=28.0531, beta=0.0000\n",
      "Batch 80, loss=0.3364, recon=0.3364, kl=53.8236, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5921 (Recon: 0.5921, KL: 19.9767, Current Beta: 0.0000) | Avg Valid Loss: 0.3784 | Avg Valid recon Loss: 0.3784\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3346, recon=0.3346, kl=71.2361, beta=0.0000\n",
      "Batch 40, loss=0.2636, recon=0.2636, kl=77.4288, beta=0.0000\n",
      "Batch 60, loss=0.3268, recon=0.3268, kl=83.1107, beta=0.0000\n",
      "Batch 80, loss=0.2536, recon=0.2536, kl=87.6169, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2967 (Recon: 0.2967, KL: 78.1199, Current Beta: 0.0000) | Avg Valid Loss: 0.2247 | Avg Valid recon Loss: 0.2247\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2341, recon=0.2341, kl=92.6995, beta=0.0000\n",
      "Batch 40, loss=0.4713, recon=0.4713, kl=95.1192, beta=0.0000\n",
      "Batch 60, loss=0.1438, recon=0.1438, kl=96.5011, beta=0.0000\n",
      "Batch 80, loss=0.1454, recon=0.1453, kl=97.9589, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2076 (Recon: 0.2076, KL: 95.1410, Current Beta: 0.0000) | Avg Valid Loss: 0.1646 | Avg Valid recon Loss: 0.1646\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1816, recon=0.1815, kl=96.3231, beta=0.0000\n",
      "Batch 40, loss=0.1458, recon=0.1458, kl=93.5299, beta=0.0000\n",
      "Batch 60, loss=0.1158, recon=0.1158, kl=92.9693, beta=0.0000\n",
      "Batch 80, loss=0.1073, recon=0.1073, kl=93.0923, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1637 (Recon: 0.1637, KL: 94.3671, Current Beta: 0.0000) | Avg Valid Loss: 0.1361 | Avg Valid recon Loss: 0.1360\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1227, recon=0.1226, kl=86.5652, beta=0.0000\n",
      "Batch 40, loss=0.0843, recon=0.0842, kl=79.1967, beta=0.0000\n",
      "Batch 60, loss=0.1533, recon=0.1533, kl=75.0156, beta=0.0000\n",
      "Batch 80, loss=0.0914, recon=0.0914, kl=71.7417, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1381 (Recon: 0.1380, KL: 79.4761, Current Beta: 0.0000) | Avg Valid Loss: 0.1187 | Avg Valid recon Loss: 0.1186\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0723, recon=0.0722, kl=49.5624, beta=0.0000\n",
      "Batch 40, loss=0.3621, recon=0.3620, kl=41.5794, beta=0.0000\n",
      "Batch 60, loss=0.1095, recon=0.1094, kl=37.0132, beta=0.0000\n",
      "Batch 80, loss=0.1654, recon=0.1654, kl=34.5085, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1208 (Recon: 0.1207, KL: 43.2820, Current Beta: 0.0000) | Avg Valid Loss: 0.1057 | Avg Valid recon Loss: 0.1056\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0793, recon=0.0792, kl=18.3480, beta=0.0000\n",
      "Batch 40, loss=0.1196, recon=0.1196, kl=15.6853, beta=0.0000\n",
      "Batch 60, loss=0.1126, recon=0.1125, kl=14.6565, beta=0.0000\n",
      "Batch 80, loss=0.0930, recon=0.0929, kl=12.2213, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1088 (Recon: 0.1087, KL: 16.6693, Current Beta: 0.0000) | Avg Valid Loss: 0.0980 | Avg Valid recon Loss: 0.0979\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0822, recon=0.0821, kl=5.5705, beta=0.0000\n",
      "Batch 40, loss=0.0689, recon=0.0688, kl=4.1260, beta=0.0000\n",
      "Batch 60, loss=0.0827, recon=0.0826, kl=4.0285, beta=0.0000\n",
      "Batch 80, loss=0.0551, recon=0.0551, kl=4.0306, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0998 (Recon: 0.0997, KL: 4.9504, Current Beta: 0.0000) | Avg Valid Loss: 0.0896 | Avg Valid recon Loss: 0.0895\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0613, recon=0.0612, kl=1.6037, beta=0.0000\n",
      "Batch 40, loss=0.0763, recon=0.0762, kl=1.2597, beta=0.0000\n",
      "Batch 60, loss=0.0681, recon=0.0680, kl=1.0962, beta=0.0000\n",
      "Batch 80, loss=0.0887, recon=0.0886, kl=1.4654, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0926 (Recon: 0.0926, KL: 1.4643, Current Beta: 0.0000) | Avg Valid Loss: 0.0839 | Avg Valid recon Loss: 0.0838\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0605, recon=0.0604, kl=0.4007, beta=0.0001\n",
      "Batch 40, loss=0.1129, recon=0.1129, kl=0.4026, beta=0.0001\n",
      "Batch 60, loss=0.1157, recon=0.1156, kl=0.2742, beta=0.0001\n",
      "Batch 80, loss=0.0806, recon=0.0805, kl=0.2237, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0870 (Recon: 0.0870, KL: 0.3484, Current Beta: 0.0001) | Avg Valid Loss: 0.0804 | Avg Valid recon Loss: 0.0803\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0806, recon=0.0806, kl=0.0463, beta=0.0003\n",
      "Batch 40, loss=0.0492, recon=0.0492, kl=0.0248, beta=0.0003\n",
      "Batch 60, loss=0.0583, recon=0.0583, kl=0.0163, beta=0.0003\n",
      "Batch 80, loss=0.0692, recon=0.0692, kl=0.0194, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0822 (Recon: 0.0821, KL: 0.0380, Current Beta: 0.0003) | Avg Valid Loss: 0.0758 | Avg Valid recon Loss: 0.0758\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0708, recon=0.0708, kl=0.0021, beta=0.0008\n",
      "Batch 40, loss=0.0514, recon=0.0514, kl=0.0021, beta=0.0008\n",
      "Batch 60, loss=0.0929, recon=0.0929, kl=0.0008, beta=0.0008\n",
      "Batch 80, loss=0.0842, recon=0.0842, kl=0.0026, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0786 (Recon: 0.0786, KL: 0.0026, Current Beta: 0.0008) | Avg Valid Loss: 0.0731 | Avg Valid recon Loss: 0.0731\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.2550, recon=0.2550, kl=0.0007, beta=0.0018\n",
      "Batch 40, loss=0.0592, recon=0.0592, kl=0.0002, beta=0.0018\n",
      "Batch 60, loss=0.0490, recon=0.0490, kl=0.0004, beta=0.0018\n",
      "Batch 80, loss=0.0596, recon=0.0596, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0758 (Recon: 0.0758, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0696 | Avg Valid recon Loss: 0.0696\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1847, recon=0.1847, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0396, recon=0.0396, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.0670, recon=0.0670, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0495, recon=0.0495, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0731 (Recon: 0.0731, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0677 | Avg Valid recon Loss: 0.0677\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0556, recon=0.0556, kl=0.0000, beta=0.0062\n",
      "Batch 40, loss=0.0406, recon=0.0406, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0565, recon=0.0565, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0633, recon=0.0633, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0709 (Recon: 0.0709, KL: 0.0000, Current Beta: 0.0062) | Avg Valid Loss: 0.0653 | Avg Valid recon Loss: 0.0653\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0524, recon=0.0524, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0382, recon=0.0382, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0665, recon=0.0665, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0381, recon=0.0381, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0687 (Recon: 0.0687, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0636 | Avg Valid recon Loss: 0.0636\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0740, recon=0.0740, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0516, recon=0.0516, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0490, recon=0.0490, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0381, recon=0.0381, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0668 (Recon: 0.0668, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0621 | Avg Valid recon Loss: 0.0621\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0605, recon=0.0605, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0518, recon=0.0518, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0574, recon=0.0574, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0794, recon=0.0794, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0653 (Recon: 0.0653, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0600 | Avg Valid recon Loss: 0.0600\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0460, recon=0.0460, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0625, recon=0.0625, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0381, recon=0.0381, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0423, recon=0.0423, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0637 (Recon: 0.0637, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0590 | Avg Valid recon Loss: 0.0590\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1378, recon=0.1378, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0596, recon=0.0596, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0641, recon=0.0641, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0396, recon=0.0396, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0622 (Recon: 0.0622, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0575 | Avg Valid recon Loss: 0.0575\n",
      "\n",
      "[VRAE Run 204/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4161, recon=0.4161, kl=39.3742, beta=0.0000\n",
      "Batch 40, loss=0.2030, recon=0.2030, kl=67.1067, beta=0.0000\n",
      "Batch 60, loss=0.1510, recon=0.1510, kl=101.9175, beta=0.0000\n",
      "Batch 80, loss=0.1053, recon=0.1053, kl=107.8031, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2282 (Recon: 0.2282, KL: 70.8841, Current Beta: 0.0000) | Avg Valid Loss: 0.0945 | Avg Valid recon Loss: 0.0945\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0778, recon=0.0778, kl=110.7798, beta=0.0000\n",
      "Batch 40, loss=0.1550, recon=0.1550, kl=120.5253, beta=0.0000\n",
      "Batch 60, loss=0.0415, recon=0.0415, kl=122.5513, beta=0.0000\n",
      "Batch 80, loss=0.0758, recon=0.0758, kl=124.1767, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0931 (Recon: 0.0931, KL: 117.3082, Current Beta: 0.0000) | Avg Valid Loss: 0.0741 | Avg Valid recon Loss: 0.0741\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0500, recon=0.0500, kl=111.8425, beta=0.0000\n",
      "Batch 40, loss=0.0504, recon=0.0504, kl=105.6797, beta=0.0000\n",
      "Batch 60, loss=0.0948, recon=0.0948, kl=108.7106, beta=0.0000\n",
      "Batch 80, loss=0.0504, recon=0.0504, kl=104.8217, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0734 (Recon: 0.0734, KL: 109.0166, Current Beta: 0.0000) | Avg Valid Loss: 0.0594 | Avg Valid recon Loss: 0.0594\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0437, recon=0.0437, kl=90.4555, beta=0.0000\n",
      "Batch 40, loss=0.0957, recon=0.0957, kl=83.2462, beta=0.0000\n",
      "Batch 60, loss=0.0397, recon=0.0397, kl=82.2104, beta=0.0000\n",
      "Batch 80, loss=0.0540, recon=0.0540, kl=81.3238, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0624 (Recon: 0.0624, KL: 85.2898, Current Beta: 0.0000) | Avg Valid Loss: 0.0542 | Avg Valid recon Loss: 0.0542\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0497, recon=0.0497, kl=72.4701, beta=0.0000\n",
      "Batch 40, loss=0.0315, recon=0.0315, kl=61.1549, beta=0.0000\n",
      "Batch 60, loss=0.0519, recon=0.0519, kl=70.1666, beta=0.0000\n",
      "Batch 80, loss=0.0413, recon=0.0412, kl=61.4923, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 68.0490, Current Beta: 0.0000) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0495\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0362, recon=0.0361, kl=36.7600, beta=0.0000\n",
      "Batch 40, loss=0.0350, recon=0.0350, kl=42.2259, beta=0.0000\n",
      "Batch 60, loss=0.0691, recon=0.0690, kl=45.9523, beta=0.0000\n",
      "Batch 80, loss=0.0381, recon=0.0380, kl=43.4462, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0526 (Recon: 0.0525, KL: 44.3679, Current Beta: 0.0000) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0465\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0633, recon=0.0632, kl=20.9971, beta=0.0000\n",
      "Batch 40, loss=0.0443, recon=0.0442, kl=17.3342, beta=0.0000\n",
      "Batch 60, loss=0.0385, recon=0.0384, kl=16.1979, beta=0.0000\n",
      "Batch 80, loss=0.1051, recon=0.1049, kl=37.4317, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0501, KL: 23.2449, Current Beta: 0.0000) | Avg Valid Loss: 0.0445 | Avg Valid recon Loss: 0.0443\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0458, recon=0.0457, kl=6.9887, beta=0.0000\n",
      "Batch 40, loss=0.0535, recon=0.0533, kl=15.2140, beta=0.0000\n",
      "Batch 60, loss=0.0523, recon=0.0521, kl=15.4578, beta=0.0000\n",
      "Batch 80, loss=0.0379, recon=0.0378, kl=5.7392, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0525, KL: 12.7156, Current Beta: 0.0000) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0299, recon=0.0299, kl=2.0029, beta=0.0000\n",
      "Batch 40, loss=0.0535, recon=0.0534, kl=1.8262, beta=0.0000\n",
      "Batch 60, loss=0.0296, recon=0.0296, kl=0.8493, beta=0.0000\n",
      "Batch 80, loss=0.0330, recon=0.0330, kl=0.5424, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0477 (Recon: 0.0477, KL: 1.5019, Current Beta: 0.0000) | Avg Valid Loss: 0.0473 | Avg Valid recon Loss: 0.0472\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=0.1116, beta=0.0001\n",
      "Batch 40, loss=0.0348, recon=0.0347, kl=0.3578, beta=0.0001\n",
      "Batch 60, loss=0.0401, recon=0.0400, kl=0.1261, beta=0.0001\n",
      "Batch 80, loss=0.0323, recon=0.0323, kl=0.0573, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0486 (Recon: 0.0486, KL: 0.1896, Current Beta: 0.0001) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0444, recon=0.0444, kl=0.0037, beta=0.0003\n",
      "Batch 40, loss=0.0448, recon=0.0448, kl=0.0115, beta=0.0003\n",
      "Batch 60, loss=0.0340, recon=0.0340, kl=0.0653, beta=0.0003\n",
      "Batch 80, loss=0.0462, recon=0.0461, kl=0.0310, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0463, KL: 0.0247, Current Beta: 0.0003) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0461, recon=0.0461, kl=0.0015, beta=0.0008\n",
      "Batch 40, loss=0.0379, recon=0.0379, kl=0.0026, beta=0.0008\n",
      "Batch 60, loss=0.0324, recon=0.0324, kl=0.0014, beta=0.0008\n",
      "Batch 80, loss=0.0401, recon=0.0401, kl=0.0033, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0436 (Recon: 0.0436, KL: 0.0033, Current Beta: 0.0008) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0304, recon=0.0304, kl=0.0004, beta=0.0018\n",
      "Batch 40, loss=0.0209, recon=0.0209, kl=0.0007, beta=0.0018\n",
      "Batch 60, loss=0.0710, recon=0.0710, kl=0.0004, beta=0.0018\n",
      "Batch 80, loss=0.0338, recon=0.0338, kl=0.0003, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0451 (Recon: 0.0451, KL: 0.0006, Current Beta: 0.0018) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0359, recon=0.0359, kl=0.0009, beta=0.0038\n",
      "Batch 40, loss=0.0276, recon=0.0275, kl=0.0093, beta=0.0038\n",
      "Batch 60, loss=0.0292, recon=0.0286, kl=0.1704, beta=0.0038\n",
      "Batch 80, loss=0.0788, recon=0.0784, kl=0.0971, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0436, KL: 0.0515, Current Beta: 0.0038) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0479, recon=0.0478, kl=0.0033, beta=0.0062\n",
      "Batch 40, loss=0.0360, recon=0.0360, kl=0.0005, beta=0.0062\n",
      "Batch 60, loss=0.0291, recon=0.0291, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0416, recon=0.0416, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0416, KL: 0.0023, Current Beta: 0.0062) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0899, recon=0.0899, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0826, recon=0.0826, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0327, recon=0.0327, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0283, recon=0.0283, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0345\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0437, recon=0.0437, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0290, recon=0.0290, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0402, recon=0.0402, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0319, recon=0.0319, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0400, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0356 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0867, recon=0.0867, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0276, recon=0.0276, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0410, recon=0.0410, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0306, recon=0.0306, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0391, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0418 | Avg Valid recon Loss: 0.0418\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0301, recon=0.0301, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0354, recon=0.0354, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0306, recon=0.0306, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0344, recon=0.0344, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0419, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0606 | Avg Valid recon Loss: 0.0606\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0983, recon=0.0983, kl=0.0008, beta=0.0100\n",
      "Batch 40, loss=0.1024, recon=0.1024, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0616, recon=0.0616, kl=0.0021, beta=0.0100\n",
      "Batch 80, loss=0.0465, recon=0.0464, kl=0.0005, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0664 (Recon: 0.0664, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0455\n",
      "\n",
      "[VRAE Run 205/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3788, recon=0.3788, kl=0.4378, beta=0.0000\n",
      "Batch 40, loss=0.2466, recon=0.2466, kl=8.5550, beta=0.0000\n",
      "Batch 60, loss=0.2561, recon=0.2561, kl=17.1161, beta=0.0000\n",
      "Batch 80, loss=0.1601, recon=0.1601, kl=23.2744, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3823 (Recon: 0.3823, KL: 11.1270, Current Beta: 0.0000) | Avg Valid Loss: 0.1799 | Avg Valid recon Loss: 0.1799\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1187, recon=0.1187, kl=32.0053, beta=0.0000\n",
      "Batch 40, loss=0.1189, recon=0.1189, kl=36.1182, beta=0.0000\n",
      "Batch 60, loss=0.1234, recon=0.1234, kl=39.9828, beta=0.0000\n",
      "Batch 80, loss=0.2058, recon=0.2058, kl=40.2403, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1671 (Recon: 0.1671, KL: 36.1501, Current Beta: 0.0000) | Avg Valid Loss: 0.1192 | Avg Valid recon Loss: 0.1192\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0957, recon=0.0957, kl=41.9259, beta=0.0000\n",
      "Batch 40, loss=0.1220, recon=0.1220, kl=41.0907, beta=0.0000\n",
      "Batch 60, loss=0.0957, recon=0.0957, kl=42.3968, beta=0.0000\n",
      "Batch 80, loss=0.1096, recon=0.1096, kl=41.5540, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1270 (Recon: 0.1270, KL: 42.0236, Current Beta: 0.0000) | Avg Valid Loss: 0.0976 | Avg Valid recon Loss: 0.0976\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1003, recon=0.1003, kl=39.5958, beta=0.0000\n",
      "Batch 40, loss=0.0894, recon=0.0894, kl=38.7265, beta=0.0000\n",
      "Batch 60, loss=0.0718, recon=0.0718, kl=37.1931, beta=0.0000\n",
      "Batch 80, loss=0.0908, recon=0.0908, kl=38.1362, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1068 (Recon: 0.1068, KL: 38.9231, Current Beta: 0.0000) | Avg Valid Loss: 0.0861 | Avg Valid recon Loss: 0.0861\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0718, recon=0.0718, kl=34.5140, beta=0.0000\n",
      "Batch 40, loss=0.0621, recon=0.0621, kl=29.1717, beta=0.0000\n",
      "Batch 60, loss=0.0569, recon=0.0569, kl=26.9006, beta=0.0000\n",
      "Batch 80, loss=0.0680, recon=0.0679, kl=25.4084, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0940 (Recon: 0.0940, KL: 29.7585, Current Beta: 0.0000) | Avg Valid Loss: 0.0784 | Avg Valid recon Loss: 0.0784\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0757, recon=0.0756, kl=19.2478, beta=0.0000\n",
      "Batch 40, loss=0.0680, recon=0.0679, kl=16.1735, beta=0.0000\n",
      "Batch 60, loss=0.0762, recon=0.0762, kl=16.4327, beta=0.0000\n",
      "Batch 80, loss=0.0637, recon=0.0637, kl=14.8158, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0855 (Recon: 0.0855, KL: 17.6084, Current Beta: 0.0000) | Avg Valid Loss: 0.0710 | Avg Valid recon Loss: 0.0709\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0836, recon=0.0835, kl=8.4856, beta=0.0000\n",
      "Batch 40, loss=0.0564, recon=0.0563, kl=7.1635, beta=0.0000\n",
      "Batch 60, loss=0.0622, recon=0.0621, kl=7.0457, beta=0.0000\n",
      "Batch 80, loss=0.2093, recon=0.2093, kl=6.6888, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0788 (Recon: 0.0788, KL: 8.0655, Current Beta: 0.0000) | Avg Valid Loss: 0.0680 | Avg Valid recon Loss: 0.0680\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0655, recon=0.0655, kl=2.8582, beta=0.0000\n",
      "Batch 40, loss=0.0897, recon=0.0896, kl=3.0224, beta=0.0000\n",
      "Batch 60, loss=0.0607, recon=0.0606, kl=2.6811, beta=0.0000\n",
      "Batch 80, loss=0.0915, recon=0.0915, kl=1.8300, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0738 (Recon: 0.0737, KL: 2.9360, Current Beta: 0.0000) | Avg Valid Loss: 0.0631 | Avg Valid recon Loss: 0.0631\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0452, recon=0.0452, kl=0.6464, beta=0.0000\n",
      "Batch 40, loss=0.0523, recon=0.0522, kl=0.7571, beta=0.0000\n",
      "Batch 60, loss=0.0413, recon=0.0412, kl=0.6696, beta=0.0000\n",
      "Batch 80, loss=0.0644, recon=0.0644, kl=0.6098, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0697 (Recon: 0.0697, KL: 0.7955, Current Beta: 0.0000) | Avg Valid Loss: 0.0605 | Avg Valid recon Loss: 0.0605\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0808, recon=0.0808, kl=0.1791, beta=0.0001\n",
      "Batch 40, loss=0.0612, recon=0.0612, kl=0.1009, beta=0.0001\n",
      "Batch 60, loss=0.0633, recon=0.0633, kl=0.0710, beta=0.0001\n",
      "Batch 80, loss=0.0557, recon=0.0557, kl=0.0632, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0663 (Recon: 0.0663, KL: 0.1169, Current Beta: 0.0001) | Avg Valid Loss: 0.0577 | Avg Valid recon Loss: 0.0577\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0472, recon=0.0472, kl=0.0217, beta=0.0003\n",
      "Batch 40, loss=0.0483, recon=0.0483, kl=0.0186, beta=0.0003\n",
      "Batch 60, loss=0.0615, recon=0.0615, kl=0.0091, beta=0.0003\n",
      "Batch 80, loss=0.0607, recon=0.0607, kl=0.0104, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0637 (Recon: 0.0637, KL: 0.0117, Current Beta: 0.0003) | Avg Valid Loss: 0.0558 | Avg Valid recon Loss: 0.0558\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0612, recon=0.0612, kl=0.0015, beta=0.0008\n",
      "Batch 40, loss=0.0474, recon=0.0474, kl=0.0016, beta=0.0008\n",
      "Batch 60, loss=0.0566, recon=0.0566, kl=0.0006, beta=0.0008\n",
      "Batch 80, loss=0.0406, recon=0.0406, kl=0.0012, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0613 (Recon: 0.0613, KL: 0.0015, Current Beta: 0.0008) | Avg Valid Loss: 0.0538 | Avg Valid recon Loss: 0.0538\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0435, recon=0.0435, kl=0.0005, beta=0.0018\n",
      "Batch 40, loss=0.0443, recon=0.0443, kl=0.0005, beta=0.0018\n",
      "Batch 60, loss=0.0530, recon=0.0530, kl=0.0006, beta=0.0018\n",
      "Batch 80, loss=0.0933, recon=0.0933, kl=0.0003, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0592 (Recon: 0.0592, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0475, recon=0.0475, kl=0.0002, beta=0.0038\n",
      "Batch 40, loss=0.0514, recon=0.0514, kl=0.0003, beta=0.0038\n",
      "Batch 60, loss=0.0383, recon=0.0383, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0498, recon=0.0498, kl=0.0003, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0576 (Recon: 0.0576, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0583, recon=0.0583, kl=0.0002, beta=0.0062\n",
      "Batch 40, loss=0.0460, recon=0.0460, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0491, recon=0.0491, kl=0.0003, beta=0.0062\n",
      "Batch 80, loss=0.0406, recon=0.0406, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0560 (Recon: 0.0560, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0496\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0444, recon=0.0443, kl=0.0008, beta=0.0100\n",
      "Batch 40, loss=0.0403, recon=0.0403, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0640, recon=0.0640, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0564, recon=0.0564, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0547, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0463, recon=0.0463, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0371, recon=0.0371, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0602, recon=0.0602, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0366, recon=0.0366, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0536 (Recon: 0.0536, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0468 | Avg Valid recon Loss: 0.0468\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0606, recon=0.0606, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0575, recon=0.0575, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0316, recon=0.0316, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0317, recon=0.0317, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0526 (Recon: 0.0526, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0460\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0340, recon=0.0340, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0439, recon=0.0439, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0450, recon=0.0450, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0529, recon=0.0529, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0512 (Recon: 0.0512, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0449\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1239, recon=0.1239, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0326, recon=0.0326, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0273, recon=0.0273, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0297, recon=0.0297, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0505 (Recon: 0.0505, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0443 | Avg Valid recon Loss: 0.0443\n",
      "\n",
      "[VRAE Run 206/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1525, recon=0.1525, kl=29.9926, beta=0.0000\n",
      "Batch 40, loss=0.1001, recon=0.1001, kl=38.8323, beta=0.0000\n",
      "Batch 60, loss=0.0854, recon=0.0854, kl=40.6323, beta=0.0000\n",
      "Batch 80, loss=0.0673, recon=0.0673, kl=38.1854, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1664 (Recon: 0.1664, KL: 33.3179, Current Beta: 0.0000) | Avg Valid Loss: 0.0833 | Avg Valid recon Loss: 0.0833\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0590, recon=0.0590, kl=37.8169, beta=0.0000\n",
      "Batch 40, loss=0.0494, recon=0.0494, kl=37.4334, beta=0.0000\n",
      "Batch 60, loss=0.1821, recon=0.1821, kl=40.7351, beta=0.0000\n",
      "Batch 80, loss=0.1556, recon=0.1556, kl=35.0385, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0749 (Recon: 0.0749, KL: 37.5773, Current Beta: 0.0000) | Avg Valid Loss: 0.0579 | Avg Valid recon Loss: 0.0579\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0365, recon=0.0365, kl=34.4375, beta=0.0000\n",
      "Batch 40, loss=0.1349, recon=0.1349, kl=33.4588, beta=0.0000\n",
      "Batch 60, loss=0.0409, recon=0.0409, kl=34.8931, beta=0.0000\n",
      "Batch 80, loss=0.0451, recon=0.0451, kl=34.2292, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0561 (Recon: 0.0561, KL: 34.4790, Current Beta: 0.0000) | Avg Valid Loss: 0.0489 | Avg Valid recon Loss: 0.0489\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0342, recon=0.0342, kl=29.9767, beta=0.0000\n",
      "Batch 40, loss=0.0383, recon=0.0383, kl=27.8654, beta=0.0000\n",
      "Batch 60, loss=0.0380, recon=0.0380, kl=28.4272, beta=0.0000\n",
      "Batch 80, loss=0.0248, recon=0.0248, kl=27.9504, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0493 (Recon: 0.0493, KL: 28.9873, Current Beta: 0.0000) | Avg Valid Loss: 0.0414 | Avg Valid recon Loss: 0.0414\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0333, recon=0.0333, kl=22.2044, beta=0.0000\n",
      "Batch 40, loss=0.0272, recon=0.0272, kl=21.8748, beta=0.0000\n",
      "Batch 60, loss=0.0327, recon=0.0327, kl=24.9323, beta=0.0000\n",
      "Batch 80, loss=0.0576, recon=0.0576, kl=22.6659, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0463, KL: 23.3229, Current Beta: 0.0000) | Avg Valid Loss: 0.0427 | Avg Valid recon Loss: 0.0427\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0335, recon=0.0335, kl=13.4643, beta=0.0000\n",
      "Batch 40, loss=0.0408, recon=0.0407, kl=16.6824, beta=0.0000\n",
      "Batch 60, loss=0.0354, recon=0.0354, kl=14.3368, beta=0.0000\n",
      "Batch 80, loss=0.0341, recon=0.0341, kl=15.5237, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0428, KL: 15.0762, Current Beta: 0.0000) | Avg Valid Loss: 0.0366 | Avg Valid recon Loss: 0.0366\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0314, recon=0.0314, kl=8.1752, beta=0.0000\n",
      "Batch 40, loss=0.0466, recon=0.0466, kl=9.8138, beta=0.0000\n",
      "Batch 60, loss=0.0280, recon=0.0280, kl=8.6539, beta=0.0000\n",
      "Batch 80, loss=0.0407, recon=0.0407, kl=8.8007, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0407 (Recon: 0.0407, KL: 8.8309, Current Beta: 0.0000) | Avg Valid Loss: 0.0356 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0244, recon=0.0243, kl=2.0702, beta=0.0000\n",
      "Batch 40, loss=0.0226, recon=0.0226, kl=2.1030, beta=0.0000\n",
      "Batch 60, loss=0.0234, recon=0.0233, kl=2.8813, beta=0.0000\n",
      "Batch 80, loss=0.0877, recon=0.0876, kl=1.7253, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 2.6904, Current Beta: 0.0000) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0413\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0368, recon=0.0368, kl=0.5889, beta=0.0000\n",
      "Batch 40, loss=0.0255, recon=0.0254, kl=0.4042, beta=0.0000\n",
      "Batch 60, loss=0.0317, recon=0.0316, kl=0.5274, beta=0.0000\n",
      "Batch 80, loss=0.0356, recon=0.0355, kl=0.4658, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0405, KL: 0.6588, Current Beta: 0.0000) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0320, recon=0.0320, kl=0.0326, beta=0.0001\n",
      "Batch 40, loss=0.0346, recon=0.0346, kl=0.0823, beta=0.0001\n",
      "Batch 60, loss=0.0395, recon=0.0395, kl=0.0459, beta=0.0001\n",
      "Batch 80, loss=0.0273, recon=0.0273, kl=0.0128, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0404 (Recon: 0.0403, KL: 0.0732, Current Beta: 0.0001) | Avg Valid Loss: 0.0325 | Avg Valid recon Loss: 0.0325\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0256, recon=0.0256, kl=0.0021, beta=0.0003\n",
      "Batch 40, loss=0.0226, recon=0.0226, kl=0.0052, beta=0.0003\n",
      "Batch 60, loss=0.0391, recon=0.0391, kl=0.0279, beta=0.0003\n",
      "Batch 80, loss=0.0726, recon=0.0726, kl=0.0030, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0386, KL: 0.0098, Current Beta: 0.0003) | Avg Valid Loss: 0.0457 | Avg Valid recon Loss: 0.0457\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.2368, recon=0.2368, kl=0.0022, beta=0.0008\n",
      "Batch 40, loss=0.0549, recon=0.0549, kl=0.0008, beta=0.0008\n",
      "Batch 60, loss=0.0308, recon=0.0308, kl=0.0010, beta=0.0008\n",
      "Batch 80, loss=0.0411, recon=0.0411, kl=0.0073, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0423, KL: 0.0031, Current Beta: 0.0008) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0257, recon=0.0257, kl=0.0011, beta=0.0018\n",
      "Batch 40, loss=0.0244, recon=0.0244, kl=0.0003, beta=0.0018\n",
      "Batch 60, loss=0.0228, recon=0.0228, kl=0.0002, beta=0.0018\n",
      "Batch 80, loss=0.0293, recon=0.0293, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0350 (Recon: 0.0350, KL: 0.0006, Current Beta: 0.0018) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0606, recon=0.0606, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0302, recon=0.0302, kl=0.0008, beta=0.0038\n",
      "Batch 60, loss=0.0232, recon=0.0232, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0328, recon=0.0328, kl=0.0000, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0354, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.0531 | Avg Valid recon Loss: 0.0530\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0511, recon=0.0511, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0487, recon=0.0487, kl=0.0002, beta=0.0062\n",
      "Batch 60, loss=0.0495, recon=0.0495, kl=0.0002, beta=0.0062\n",
      "Batch 80, loss=0.0271, recon=0.0271, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0543 (Recon: 0.0543, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0350 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0462, recon=0.0462, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0337, recon=0.0337, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0518, recon=0.0518, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0342, recon=0.0342, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0396 (Recon: 0.0396, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0319 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0224, recon=0.0224, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0220, recon=0.0220, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0212, recon=0.0212, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0660, recon=0.0660, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0336 (Recon: 0.0336, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0301 | Avg Valid recon Loss: 0.0301\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0458, recon=0.0458, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0494, recon=0.0494, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0253, recon=0.0253, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0350, recon=0.0350, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0366 (Recon: 0.0366, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0304\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0258, recon=0.0258, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0219, recon=0.0219, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0286, recon=0.0286, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0323, recon=0.0323, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0322 (Recon: 0.0322, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0295 | Avg Valid recon Loss: 0.0295\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0792, recon=0.0792, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0304, recon=0.0304, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0232, recon=0.0232, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0259, recon=0.0259, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0390, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "\n",
      "[VRAE Run 207/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=1.6374, recon=1.6374, kl=0.5532, beta=0.0000\n",
      "Batch 40, loss=0.3574, recon=0.3574, kl=14.1444, beta=0.0000\n",
      "Batch 60, loss=0.2129, recon=0.2129, kl=31.6919, beta=0.0000\n",
      "Batch 80, loss=0.1890, recon=0.1890, kl=45.1541, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4147 (Recon: 0.4147, KL: 20.7967, Current Beta: 0.0000) | Avg Valid Loss: 0.1989 | Avg Valid recon Loss: 0.1989\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1703, recon=0.1703, kl=62.8315, beta=0.0000\n",
      "Batch 40, loss=0.1412, recon=0.1412, kl=70.1937, beta=0.0000\n",
      "Batch 60, loss=0.1692, recon=0.1692, kl=72.5871, beta=0.0000\n",
      "Batch 80, loss=0.1051, recon=0.1051, kl=75.7680, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1756 (Recon: 0.1756, KL: 68.8206, Current Beta: 0.0000) | Avg Valid Loss: 0.1233 | Avg Valid recon Loss: 0.1233\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0723, recon=0.0722, kl=74.8020, beta=0.0000\n",
      "Batch 40, loss=0.1143, recon=0.1143, kl=73.3170, beta=0.0000\n",
      "Batch 60, loss=0.3632, recon=0.3632, kl=73.6621, beta=0.0000\n",
      "Batch 80, loss=0.1167, recon=0.1167, kl=73.8192, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1299 (Recon: 0.1299, KL: 73.9991, Current Beta: 0.0000) | Avg Valid Loss: 0.0992 | Avg Valid recon Loss: 0.0992\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0801, recon=0.0801, kl=71.9975, beta=0.0000\n",
      "Batch 40, loss=0.0874, recon=0.0874, kl=68.3225, beta=0.0000\n",
      "Batch 60, loss=0.8777, recon=0.8777, kl=66.7751, beta=0.0000\n",
      "Batch 80, loss=0.0647, recon=0.0647, kl=65.7715, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1074 (Recon: 0.1074, KL: 68.9837, Current Beta: 0.0000) | Avg Valid Loss: 0.0867 | Avg Valid recon Loss: 0.0867\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0603, recon=0.0603, kl=58.0041, beta=0.0000\n",
      "Batch 40, loss=0.0680, recon=0.0679, kl=51.5818, beta=0.0000\n",
      "Batch 60, loss=0.0552, recon=0.0552, kl=49.9018, beta=0.0000\n",
      "Batch 80, loss=0.0916, recon=0.0916, kl=47.6300, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0937 (Recon: 0.0936, KL: 53.2746, Current Beta: 0.0000) | Avg Valid Loss: 0.0800 | Avg Valid recon Loss: 0.0799\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0731, recon=0.0730, kl=32.5853, beta=0.0000\n",
      "Batch 40, loss=0.0550, recon=0.0550, kl=26.6874, beta=0.0000\n",
      "Batch 60, loss=0.0635, recon=0.0635, kl=24.8836, beta=0.0000\n",
      "Batch 80, loss=0.0520, recon=0.0519, kl=25.4039, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0847 (Recon: 0.0846, KL: 29.2738, Current Beta: 0.0000) | Avg Valid Loss: 0.0724 | Avg Valid recon Loss: 0.0724\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0587, recon=0.0586, kl=10.1171, beta=0.0000\n",
      "Batch 40, loss=0.0644, recon=0.0643, kl=10.2916, beta=0.0000\n",
      "Batch 60, loss=0.0602, recon=0.0602, kl=10.0827, beta=0.0000\n",
      "Batch 80, loss=0.0838, recon=0.0838, kl=10.2418, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0776 (Recon: 0.0775, KL: 11.4952, Current Beta: 0.0000) | Avg Valid Loss: 0.0677 | Avg Valid recon Loss: 0.0676\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0545, recon=0.0545, kl=3.0768, beta=0.0000\n",
      "Batch 40, loss=0.0685, recon=0.0685, kl=3.7737, beta=0.0000\n",
      "Batch 60, loss=0.0480, recon=0.0480, kl=2.8292, beta=0.0000\n",
      "Batch 80, loss=0.0408, recon=0.0407, kl=2.5623, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0721 (Recon: 0.0721, KL: 3.5574, Current Beta: 0.0000) | Avg Valid Loss: 0.0642 | Avg Valid recon Loss: 0.0642\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0480, recon=0.0480, kl=0.7778, beta=0.0000\n",
      "Batch 40, loss=0.0601, recon=0.0601, kl=0.8362, beta=0.0000\n",
      "Batch 60, loss=0.0542, recon=0.0541, kl=0.7951, beta=0.0000\n",
      "Batch 80, loss=0.0338, recon=0.0338, kl=0.5623, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0684 (Recon: 0.0683, KL: 0.9071, Current Beta: 0.0000) | Avg Valid Loss: 0.0597 | Avg Valid recon Loss: 0.0597\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0556, recon=0.0555, kl=0.1497, beta=0.0001\n",
      "Batch 40, loss=0.0557, recon=0.0557, kl=0.1120, beta=0.0001\n",
      "Batch 60, loss=0.0561, recon=0.0561, kl=0.1090, beta=0.0001\n",
      "Batch 80, loss=0.0470, recon=0.0470, kl=0.0720, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0648 (Recon: 0.0648, KL: 0.1429, Current Beta: 0.0001) | Avg Valid Loss: 0.0573 | Avg Valid recon Loss: 0.0573\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0732, recon=0.0732, kl=0.0144, beta=0.0003\n",
      "Batch 40, loss=0.0444, recon=0.0444, kl=0.0096, beta=0.0003\n",
      "Batch 60, loss=0.0733, recon=0.0733, kl=0.0067, beta=0.0003\n",
      "Batch 80, loss=0.0522, recon=0.0522, kl=0.0055, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0618 (Recon: 0.0618, KL: 0.0105, Current Beta: 0.0003) | Avg Valid Loss: 0.0553 | Avg Valid recon Loss: 0.0553\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0387, recon=0.0387, kl=0.0019, beta=0.0008\n",
      "Batch 40, loss=0.0385, recon=0.0385, kl=0.0011, beta=0.0008\n",
      "Batch 60, loss=0.0510, recon=0.0510, kl=0.0008, beta=0.0008\n",
      "Batch 80, loss=0.0391, recon=0.0391, kl=0.0009, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0597 (Recon: 0.0597, KL: 0.0013, Current Beta: 0.0008) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0540\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0489, recon=0.0489, kl=0.0007, beta=0.0018\n",
      "Batch 40, loss=0.0517, recon=0.0517, kl=0.0003, beta=0.0018\n",
      "Batch 60, loss=0.0529, recon=0.0529, kl=0.0007, beta=0.0018\n",
      "Batch 80, loss=0.0328, recon=0.0328, kl=0.0003, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0572 (Recon: 0.0572, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0518 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0536, recon=0.0536, kl=0.0002, beta=0.0038\n",
      "Batch 40, loss=0.0521, recon=0.0521, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.0660, recon=0.0660, kl=0.0002, beta=0.0038\n",
      "Batch 80, loss=0.0569, recon=0.0569, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0560 (Recon: 0.0560, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0501 | Avg Valid recon Loss: 0.0501\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0549, recon=0.0549, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0394, recon=0.0394, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0405, recon=0.0405, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0442, recon=0.0442, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0545, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0520, recon=0.0520, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0737, recon=0.0737, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0321, recon=0.0321, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0430, recon=0.0430, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0532 (Recon: 0.0532, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0474\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0259, recon=0.0259, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0480, recon=0.0480, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0401, recon=0.0401, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0442, recon=0.0442, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0516, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0467 | Avg Valid recon Loss: 0.0467\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0485, recon=0.0485, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0396, recon=0.0396, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0422, recon=0.0422, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0330, recon=0.0330, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0505 (Recon: 0.0505, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0448 | Avg Valid recon Loss: 0.0448\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0376, recon=0.0376, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0343, recon=0.0343, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0400, recon=0.0400, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0277, recon=0.0277, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0494, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0341, recon=0.0341, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0973, recon=0.0973, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0654, recon=0.0653, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0446, recon=0.0446, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0485, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "\n",
      "[VRAE Run 208/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1566, recon=0.1566, kl=42.2976, beta=0.0000\n",
      "Batch 40, loss=0.1336, recon=0.1336, kl=52.0432, beta=0.0000\n",
      "Batch 60, loss=0.0733, recon=0.0733, kl=59.2643, beta=0.0000\n",
      "Batch 80, loss=0.0682, recon=0.0682, kl=57.2574, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1754 (Recon: 0.1754, KL: 47.1312, Current Beta: 0.0000) | Avg Valid Loss: 0.0745 | Avg Valid recon Loss: 0.0745\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2169, recon=0.2169, kl=63.3259, beta=0.0000\n",
      "Batch 40, loss=0.0418, recon=0.0418, kl=62.9842, beta=0.0000\n",
      "Batch 60, loss=0.1215, recon=0.1214, kl=56.5004, beta=0.0000\n",
      "Batch 80, loss=0.0421, recon=0.0421, kl=56.7403, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0694 (Recon: 0.0694, KL: 59.9528, Current Beta: 0.0000) | Avg Valid Loss: 0.0658 | Avg Valid recon Loss: 0.0658\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0461, recon=0.0461, kl=61.7387, beta=0.0000\n",
      "Batch 40, loss=0.0368, recon=0.0368, kl=64.0058, beta=0.0000\n",
      "Batch 60, loss=0.0574, recon=0.0574, kl=58.8391, beta=0.0000\n",
      "Batch 80, loss=0.0425, recon=0.0425, kl=61.3872, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0605 (Recon: 0.0605, KL: 61.4052, Current Beta: 0.0000) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0465\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=51.5155, beta=0.0000\n",
      "Batch 40, loss=0.0413, recon=0.0413, kl=48.7820, beta=0.0000\n",
      "Batch 60, loss=0.0578, recon=0.0578, kl=33.0529, beta=0.0000\n",
      "Batch 80, loss=0.0283, recon=0.0283, kl=52.9648, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0492 (Recon: 0.0492, KL: 49.6317, Current Beta: 0.0000) | Avg Valid Loss: 0.0428 | Avg Valid recon Loss: 0.0428\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0376, recon=0.0375, kl=42.2785, beta=0.0000\n",
      "Batch 40, loss=0.0375, recon=0.0375, kl=34.9916, beta=0.0000\n",
      "Batch 60, loss=0.0752, recon=0.0752, kl=38.8167, beta=0.0000\n",
      "Batch 80, loss=0.0782, recon=0.0781, kl=43.6499, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0438, KL: 41.1982, Current Beta: 0.0000) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0355\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0294, recon=0.0294, kl=19.8122, beta=0.0000\n",
      "Batch 40, loss=0.0521, recon=0.0521, kl=32.4501, beta=0.0000\n",
      "Batch 60, loss=0.0259, recon=0.0258, kl=25.0321, beta=0.0000\n",
      "Batch 80, loss=0.0349, recon=0.0349, kl=23.0360, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0405, KL: 27.1101, Current Beta: 0.0000) | Avg Valid Loss: 0.0367 | Avg Valid recon Loss: 0.0367\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0341, recon=0.0340, kl=18.7738, beta=0.0000\n",
      "Batch 40, loss=0.0267, recon=0.0267, kl=14.0353, beta=0.0000\n",
      "Batch 60, loss=0.0343, recon=0.0342, kl=13.8580, beta=0.0000\n",
      "Batch 80, loss=0.0423, recon=0.0422, kl=12.7502, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0401 (Recon: 0.0400, KL: 15.0065, Current Beta: 0.0000) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0468, recon=0.0467, kl=9.7190, beta=0.0000\n",
      "Batch 40, loss=0.0490, recon=0.0489, kl=6.4593, beta=0.0000\n",
      "Batch 60, loss=0.0399, recon=0.0398, kl=5.6644, beta=0.0000\n",
      "Batch 80, loss=0.0241, recon=0.0240, kl=3.3715, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0467 (Recon: 0.0466, KL: 6.6469, Current Beta: 0.0000) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0315, recon=0.0315, kl=0.7307, beta=0.0000\n",
      "Batch 40, loss=0.0238, recon=0.0237, kl=0.7311, beta=0.0000\n",
      "Batch 60, loss=0.0358, recon=0.0358, kl=0.6333, beta=0.0000\n",
      "Batch 80, loss=0.0622, recon=0.0622, kl=0.7516, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0389, KL: 0.9166, Current Beta: 0.0000) | Avg Valid Loss: 0.0464 | Avg Valid recon Loss: 0.0464\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0300, recon=0.0300, kl=0.5354, beta=0.0001\n",
      "Batch 40, loss=0.0297, recon=0.0297, kl=0.1066, beta=0.0001\n",
      "Batch 60, loss=0.0273, recon=0.0273, kl=0.0428, beta=0.0001\n",
      "Batch 80, loss=0.3026, recon=0.3026, kl=0.0389, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0417, KL: 0.3038, Current Beta: 0.0001) | Avg Valid Loss: 0.0419 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0316, recon=0.0316, kl=0.0213, beta=0.0003\n",
      "Batch 40, loss=0.0332, recon=0.0332, kl=0.0531, beta=0.0003\n",
      "Batch 60, loss=0.0267, recon=0.0267, kl=0.0394, beta=0.0003\n",
      "Batch 80, loss=0.0251, recon=0.0251, kl=0.0093, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 0.0368, Current Beta: 0.0003) | Avg Valid Loss: 0.0313 | Avg Valid recon Loss: 0.0313\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0418, recon=0.0418, kl=0.0015, beta=0.0008\n",
      "Batch 40, loss=0.0225, recon=0.0225, kl=0.0331, beta=0.0008\n",
      "Batch 60, loss=0.0263, recon=0.0263, kl=0.0073, beta=0.0008\n",
      "Batch 80, loss=0.0408, recon=0.0408, kl=0.0037, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0377, KL: 0.0134, Current Beta: 0.0008) | Avg Valid Loss: 0.0343 | Avg Valid recon Loss: 0.0343\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0691, recon=0.0691, kl=0.0011, beta=0.0018\n",
      "Batch 40, loss=0.0284, recon=0.0284, kl=0.0006, beta=0.0018\n",
      "Batch 60, loss=0.0221, recon=0.0221, kl=0.0002, beta=0.0018\n",
      "Batch 80, loss=0.0453, recon=0.0453, kl=0.0003, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0344 (Recon: 0.0344, KL: 0.0013, Current Beta: 0.0018) | Avg Valid Loss: 0.0349 | Avg Valid recon Loss: 0.0348\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=0.0007, beta=0.0038\n",
      "Batch 40, loss=0.0633, recon=0.0633, kl=0.0043, beta=0.0038\n",
      "Batch 60, loss=0.0260, recon=0.0260, kl=0.0010, beta=0.0038\n",
      "Batch 80, loss=0.0184, recon=0.0184, kl=0.0003, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0353 (Recon: 0.0353, KL: 0.0015, Current Beta: 0.0038) | Avg Valid Loss: 0.0290 | Avg Valid recon Loss: 0.0290\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0218, recon=0.0218, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0203, recon=0.0203, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0243, recon=0.0243, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0720, recon=0.0720, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0336 (Recon: 0.0336, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0208, recon=0.0208, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0227, recon=0.0227, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0300, recon=0.0300, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0203, recon=0.0203, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0327 (Recon: 0.0327, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0279 | Avg Valid recon Loss: 0.0279\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0168, recon=0.0168, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0224, recon=0.0224, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0318, recon=0.0318, kl=0.0003, beta=0.0100\n",
      "Batch 80, loss=0.0865, recon=0.0865, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0316 (Recon: 0.0316, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0318\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0245, recon=0.0245, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0597, recon=0.0597, kl=0.0005, beta=0.0100\n",
      "Batch 60, loss=0.0891, recon=0.0891, kl=0.0003, beta=0.0100\n",
      "Batch 80, loss=0.0540, recon=0.0540, kl=0.0009, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 0.0007, Current Beta: 0.0100) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0652, recon=0.0652, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0391, recon=0.0391, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.0626, recon=0.0626, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0365, recon=0.0364, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0485 (Recon: 0.0485, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0324, recon=0.0324, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0386, recon=0.0386, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0314, recon=0.0314, kl=0.0003, beta=0.0100\n",
      "Batch 80, loss=0.0264, recon=0.0264, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0368 (Recon: 0.0368, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0292 | Avg Valid recon Loss: 0.0292\n",
      "\n",
      "[VRAE Run 209/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3851, recon=0.3851, kl=2.5507, beta=0.0000\n",
      "Batch 40, loss=0.4254, recon=0.4254, kl=37.4298, beta=0.0000\n",
      "Batch 60, loss=0.4432, recon=0.4432, kl=66.2876, beta=0.0000\n",
      "Batch 80, loss=0.2221, recon=0.2221, kl=83.6625, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4007 (Recon: 0.4007, KL: 43.3116, Current Beta: 0.0000) | Avg Valid Loss: 0.1899 | Avg Valid recon Loss: 0.1899\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1247, recon=0.1247, kl=104.3131, beta=0.0000\n",
      "Batch 40, loss=0.1685, recon=0.1685, kl=113.1034, beta=0.0000\n",
      "Batch 60, loss=0.1825, recon=0.1825, kl=117.1986, beta=0.0000\n",
      "Batch 80, loss=0.1553, recon=0.1553, kl=119.4394, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1728 (Recon: 0.1728, KL: 111.4979, Current Beta: 0.0000) | Avg Valid Loss: 0.1228 | Avg Valid recon Loss: 0.1228\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1090, recon=0.1090, kl=122.4505, beta=0.0000\n",
      "Batch 40, loss=0.1125, recon=0.1125, kl=122.8222, beta=0.0000\n",
      "Batch 60, loss=0.1207, recon=0.1207, kl=122.1260, beta=0.0000\n",
      "Batch 80, loss=0.1198, recon=0.1198, kl=123.7102, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1285 (Recon: 0.1285, KL: 122.8763, Current Beta: 0.0000) | Avg Valid Loss: 0.0984 | Avg Valid recon Loss: 0.0984\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0727, recon=0.0727, kl=122.6636, beta=0.0000\n",
      "Batch 40, loss=0.1010, recon=0.1010, kl=120.0735, beta=0.0000\n",
      "Batch 60, loss=0.1217, recon=0.1217, kl=113.8120, beta=0.0000\n",
      "Batch 80, loss=0.0922, recon=0.0922, kl=108.9500, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1071 (Recon: 0.1071, KL: 117.2495, Current Beta: 0.0000) | Avg Valid Loss: 0.0848 | Avg Valid recon Loss: 0.0848\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0842, recon=0.0841, kl=91.6990, beta=0.0000\n",
      "Batch 40, loss=0.0812, recon=0.0811, kl=72.2235, beta=0.0000\n",
      "Batch 60, loss=0.0898, recon=0.0897, kl=66.5607, beta=0.0000\n",
      "Batch 80, loss=0.0767, recon=0.0767, kl=66.5614, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0928 (Recon: 0.0927, KL: 77.8858, Current Beta: 0.0000) | Avg Valid Loss: 0.0766 | Avg Valid recon Loss: 0.0766\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0707, recon=0.0706, kl=34.9235, beta=0.0000\n",
      "Batch 40, loss=0.0568, recon=0.0568, kl=33.8039, beta=0.0000\n",
      "Batch 60, loss=0.0523, recon=0.0522, kl=29.7785, beta=0.0000\n",
      "Batch 80, loss=0.0522, recon=0.0521, kl=29.5988, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0833 (Recon: 0.0832, KL: 35.6886, Current Beta: 0.0000) | Avg Valid Loss: 0.0721 | Avg Valid recon Loss: 0.0720\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0926, recon=0.0925, kl=13.5514, beta=0.0000\n",
      "Batch 40, loss=0.0994, recon=0.0993, kl=14.0908, beta=0.0000\n",
      "Batch 60, loss=0.0690, recon=0.0689, kl=11.4435, beta=0.0000\n",
      "Batch 80, loss=0.0606, recon=0.0606, kl=11.6583, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0759 (Recon: 0.0758, KL: 13.8886, Current Beta: 0.0000) | Avg Valid Loss: 0.0662 | Avg Valid recon Loss: 0.0661\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0516, recon=0.0515, kl=5.2870, beta=0.0000\n",
      "Batch 40, loss=0.0613, recon=0.0612, kl=4.1504, beta=0.0000\n",
      "Batch 60, loss=0.0511, recon=0.0510, kl=4.0649, beta=0.0000\n",
      "Batch 80, loss=0.0906, recon=0.0905, kl=3.6450, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0710 (Recon: 0.0709, KL: 4.5785, Current Beta: 0.0000) | Avg Valid Loss: 0.0623 | Avg Valid recon Loss: 0.0623\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0603, recon=0.0603, kl=1.7245, beta=0.0000\n",
      "Batch 40, loss=0.0388, recon=0.0387, kl=1.6974, beta=0.0000\n",
      "Batch 60, loss=0.0761, recon=0.0761, kl=1.2763, beta=0.0000\n",
      "Batch 80, loss=0.0387, recon=0.0387, kl=1.0873, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0673 (Recon: 0.0672, KL: 1.4926, Current Beta: 0.0000) | Avg Valid Loss: 0.0588 | Avg Valid recon Loss: 0.0587\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0860, recon=0.0859, kl=0.4629, beta=0.0001\n",
      "Batch 40, loss=0.0548, recon=0.0548, kl=0.2566, beta=0.0001\n",
      "Batch 60, loss=0.0589, recon=0.0589, kl=0.2005, beta=0.0001\n",
      "Batch 80, loss=0.0440, recon=0.0439, kl=0.1801, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0636 (Recon: 0.0636, KL: 0.3161, Current Beta: 0.0001) | Avg Valid Loss: 0.0568 | Avg Valid recon Loss: 0.0568\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0516, recon=0.0516, kl=0.0327, beta=0.0003\n",
      "Batch 40, loss=0.0466, recon=0.0466, kl=0.0284, beta=0.0003\n",
      "Batch 60, loss=0.0385, recon=0.0385, kl=0.0140, beta=0.0003\n",
      "Batch 80, loss=0.0533, recon=0.0533, kl=0.0135, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0613 (Recon: 0.0613, KL: 0.0293, Current Beta: 0.0003) | Avg Valid Loss: 0.0546 | Avg Valid recon Loss: 0.0546\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0359, recon=0.0359, kl=0.0023, beta=0.0008\n",
      "Batch 40, loss=0.0484, recon=0.0484, kl=0.0026, beta=0.0008\n",
      "Batch 60, loss=0.0602, recon=0.0602, kl=0.0016, beta=0.0008\n",
      "Batch 80, loss=0.0679, recon=0.0679, kl=0.0014, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0591 (Recon: 0.0591, KL: 0.0022, Current Beta: 0.0008) | Avg Valid Loss: 0.0525 | Avg Valid recon Loss: 0.0525\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0374, recon=0.0374, kl=0.0003, beta=0.0018\n",
      "Batch 40, loss=0.0523, recon=0.0523, kl=0.0004, beta=0.0018\n",
      "Batch 60, loss=0.0538, recon=0.0538, kl=0.0003, beta=0.0018\n",
      "Batch 80, loss=0.0374, recon=0.0374, kl=0.0004, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0571 (Recon: 0.0571, KL: 0.0004, Current Beta: 0.0018) | Avg Valid Loss: 0.0513 | Avg Valid recon Loss: 0.0513\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0443, recon=0.0443, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0394, recon=0.0394, kl=0.0001, beta=0.0038\n",
      "Batch 60, loss=0.0335, recon=0.0335, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0310, recon=0.0310, kl=0.0003, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0553 (Recon: 0.0553, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0495 | Avg Valid recon Loss: 0.0495\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0428, recon=0.0428, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0336, recon=0.0336, kl=0.0000, beta=0.0062\n",
      "Batch 60, loss=0.0319, recon=0.0319, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0420, recon=0.0420, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0541 (Recon: 0.0541, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0326, recon=0.0326, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.1439, recon=0.1439, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0369, recon=0.0369, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0404, recon=0.0404, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0528 (Recon: 0.0528, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0474\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0428, recon=0.0428, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0672, recon=0.0672, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0281, recon=0.0281, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0398, recon=0.0398, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0514 (Recon: 0.0514, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0462 | Avg Valid recon Loss: 0.0462\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0482, recon=0.0482, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0428, recon=0.0428, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0858, recon=0.0858, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0313, recon=0.0313, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0502, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0437, recon=0.0437, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0450, recon=0.0450, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0280, recon=0.0280, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0263, recon=0.0263, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0495, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0439 | Avg Valid recon Loss: 0.0439\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1229, recon=0.1229, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0296, recon=0.0296, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0547, recon=0.0547, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0387, recon=0.0387, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0488 (Recon: 0.0488, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0439 | Avg Valid recon Loss: 0.0439\n",
      "\n",
      "[VRAE Run 210/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1570, recon=0.1570, kl=95.1707, beta=0.0000\n",
      "Batch 40, loss=0.0822, recon=0.0822, kl=101.8264, beta=0.0000\n",
      "Batch 60, loss=0.0797, recon=0.0797, kl=114.3042, beta=0.0000\n",
      "Batch 80, loss=0.0759, recon=0.0759, kl=138.8102, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1725 (Recon: 0.1725, KL: 100.2826, Current Beta: 0.0000) | Avg Valid Loss: 0.0699 | Avg Valid recon Loss: 0.0699\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0697, recon=0.0697, kl=127.5323, beta=0.0000\n",
      "Batch 40, loss=0.0474, recon=0.0474, kl=121.9799, beta=0.0000\n",
      "Batch 60, loss=0.1131, recon=0.1131, kl=119.1274, beta=0.0000\n",
      "Batch 80, loss=0.0413, recon=0.0413, kl=105.0199, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0722 (Recon: 0.0722, KL: 120.5709, Current Beta: 0.0000) | Avg Valid Loss: 0.0536 | Avg Valid recon Loss: 0.0536\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0655, recon=0.0655, kl=118.6258, beta=0.0000\n",
      "Batch 40, loss=0.1419, recon=0.1419, kl=122.4264, beta=0.0000\n",
      "Batch 60, loss=0.0396, recon=0.0396, kl=127.0778, beta=0.0000\n",
      "Batch 80, loss=0.0437, recon=0.0437, kl=124.0292, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0555, KL: 121.1413, Current Beta: 0.0000) | Avg Valid Loss: 0.0468 | Avg Valid recon Loss: 0.0468\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0346, recon=0.0346, kl=93.6713, beta=0.0000\n",
      "Batch 40, loss=0.0389, recon=0.0389, kl=96.8932, beta=0.0000\n",
      "Batch 60, loss=0.0378, recon=0.0378, kl=107.8353, beta=0.0000\n",
      "Batch 80, loss=0.0267, recon=0.0267, kl=106.3239, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0480, KL: 103.4007, Current Beta: 0.0000) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0406\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0639, recon=0.0638, kl=66.6321, beta=0.0000\n",
      "Batch 40, loss=0.0225, recon=0.0224, kl=85.6961, beta=0.0000\n",
      "Batch 60, loss=0.0440, recon=0.0440, kl=74.7570, beta=0.0000\n",
      "Batch 80, loss=0.0544, recon=0.0543, kl=76.3940, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0446, KL: 79.1950, Current Beta: 0.0000) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0325, recon=0.0324, kl=47.7605, beta=0.0000\n",
      "Batch 40, loss=0.0341, recon=0.0340, kl=45.9086, beta=0.0000\n",
      "Batch 60, loss=0.0299, recon=0.0298, kl=55.1077, beta=0.0000\n",
      "Batch 80, loss=0.0269, recon=0.0268, kl=55.0357, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0413, KL: 51.2615, Current Beta: 0.0000) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0354\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0291, recon=0.0289, kl=26.0085, beta=0.0000\n",
      "Batch 40, loss=0.0238, recon=0.0236, kl=25.5828, beta=0.0000\n",
      "Batch 60, loss=0.0459, recon=0.0457, kl=34.8415, beta=0.0000\n",
      "Batch 80, loss=0.0435, recon=0.0433, kl=30.7569, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0430, KL: 29.6919, Current Beta: 0.0000) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0400\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0413, recon=0.0411, kl=11.5994, beta=0.0000\n",
      "Batch 40, loss=0.0538, recon=0.0536, kl=12.9742, beta=0.0000\n",
      "Batch 60, loss=0.0349, recon=0.0346, kl=18.7905, beta=0.0000\n",
      "Batch 80, loss=0.0309, recon=0.0307, kl=14.4531, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0535 (Recon: 0.0533, KL: 13.6103, Current Beta: 0.0000) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0381\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0416, recon=0.0415, kl=1.9660, beta=0.0000\n",
      "Batch 40, loss=0.1511, recon=0.1510, kl=3.3569, beta=0.0000\n",
      "Batch 60, loss=0.0715, recon=0.0714, kl=4.0738, beta=0.0000\n",
      "Batch 80, loss=0.0258, recon=0.0255, kl=6.4566, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0435 (Recon: 0.0433, KL: 4.2001, Current Beta: 0.0000) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0422, recon=0.0416, kl=5.4096, beta=0.0001\n",
      "Batch 40, loss=0.0301, recon=0.0298, kl=3.0009, beta=0.0001\n",
      "Batch 60, loss=0.0358, recon=0.0357, kl=0.4802, beta=0.0001\n",
      "Batch 80, loss=0.0307, recon=0.0306, kl=0.2228, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0419, KL: 2.9560, Current Beta: 0.0001) | Avg Valid Loss: 0.0367 | Avg Valid recon Loss: 0.0366\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1176, recon=0.1176, kl=0.0463, beta=0.0003\n",
      "Batch 40, loss=0.0297, recon=0.0296, kl=0.0386, beta=0.0003\n",
      "Batch 60, loss=0.0245, recon=0.0244, kl=0.0249, beta=0.0003\n",
      "Batch 80, loss=0.0243, recon=0.0243, kl=0.0225, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0463, KL: 0.0536, Current Beta: 0.0003) | Avg Valid Loss: 0.0333 | Avg Valid recon Loss: 0.0333\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0238, recon=0.0238, kl=0.0143, beta=0.0008\n",
      "Batch 40, loss=0.0488, recon=0.0488, kl=0.0130, beta=0.0008\n",
      "Batch 60, loss=0.0430, recon=0.0430, kl=0.0472, beta=0.0008\n",
      "Batch 80, loss=0.0380, recon=0.0380, kl=0.0201, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0388, KL: 0.0190, Current Beta: 0.0008) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0355\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=0.0058, beta=0.0018\n",
      "Batch 40, loss=0.0326, recon=0.0326, kl=0.0019, beta=0.0018\n",
      "Batch 60, loss=0.0277, recon=0.0277, kl=0.0004, beta=0.0018\n",
      "Batch 80, loss=0.0475, recon=0.0475, kl=0.0010, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0367 (Recon: 0.0367, KL: 0.0022, Current Beta: 0.0018) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0277, recon=0.0277, kl=0.0001, beta=0.0038\n",
      "Batch 40, loss=0.0473, recon=0.0473, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.0746, recon=0.0746, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0276, recon=0.0276, kl=0.0003, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0362, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0342, recon=0.0342, kl=0.0013, beta=0.0062\n",
      "Batch 40, loss=0.0517, recon=0.0517, kl=0.0026, beta=0.0062\n",
      "Batch 60, loss=0.0341, recon=0.0341, kl=0.0002, beta=0.0062\n",
      "Batch 80, loss=0.0415, recon=0.0415, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0398 (Recon: 0.0398, KL: 0.0004, Current Beta: 0.0062) | Avg Valid Loss: 0.0320 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0710, recon=0.0710, kl=0.0006, beta=0.0100\n",
      "Batch 40, loss=0.0270, recon=0.0270, kl=0.0005, beta=0.0100\n",
      "Batch 60, loss=0.0255, recon=0.0255, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0328, recon=0.0328, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0336 (Recon: 0.0336, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0306\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0332, recon=0.0332, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0250, recon=0.0250, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0224, recon=0.0224, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0237, recon=0.0237, kl=0.0005, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0333 (Recon: 0.0333, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0247, recon=0.0247, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0204, recon=0.0204, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0270, recon=0.0270, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0350 (Recon: 0.0350, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0442 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0472, recon=0.0471, kl=0.0009, beta=0.0100\n",
      "Batch 40, loss=0.0263, recon=0.0263, kl=0.0010, beta=0.0100\n",
      "Batch 60, loss=0.0436, recon=0.0436, kl=0.0006, beta=0.0100\n",
      "Batch 80, loss=0.0543, recon=0.0543, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0409, KL: 0.0007, Current Beta: 0.0100) | Avg Valid Loss: 0.0313 | Avg Valid recon Loss: 0.0312\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0253, recon=0.0253, kl=0.0011, beta=0.0100\n",
      "Batch 40, loss=0.0947, recon=0.0947, kl=0.0015, beta=0.0100\n",
      "Batch 60, loss=0.0298, recon=0.0298, kl=0.0006, beta=0.0100\n",
      "Batch 80, loss=0.0198, recon=0.0198, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0335 (Recon: 0.0334, KL: 0.0008, Current Beta: 0.0100) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0333\n",
      "\n",
      "[VRAE Run 211/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2853, recon=0.2853, kl=5.5247, beta=0.0000\n",
      "Batch 40, loss=0.2143, recon=0.2143, kl=15.4732, beta=0.0000\n",
      "Batch 60, loss=0.2296, recon=0.2296, kl=23.5558, beta=0.0000\n",
      "Batch 80, loss=0.1189, recon=0.1189, kl=28.5602, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2750 (Recon: 0.2750, KL: 16.3662, Current Beta: 0.0000) | Avg Valid Loss: 0.1167 | Avg Valid recon Loss: 0.1167\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1409, recon=0.1409, kl=41.3009, beta=0.0000\n",
      "Batch 40, loss=0.0914, recon=0.0913, kl=49.6816, beta=0.0000\n",
      "Batch 60, loss=0.0961, recon=0.0961, kl=48.9593, beta=0.0000\n",
      "Batch 80, loss=0.0934, recon=0.0934, kl=49.3831, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1241 (Recon: 0.1241, KL: 46.0626, Current Beta: 0.0000) | Avg Valid Loss: 0.0848 | Avg Valid recon Loss: 0.0848\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0666, recon=0.0666, kl=43.7888, beta=0.0000\n",
      "Batch 40, loss=0.2392, recon=0.2392, kl=42.9947, beta=0.0000\n",
      "Batch 60, loss=0.0603, recon=0.0602, kl=45.6979, beta=0.0000\n",
      "Batch 80, loss=0.0730, recon=0.0730, kl=48.0108, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0940 (Recon: 0.0940, KL: 44.8231, Current Beta: 0.0000) | Avg Valid Loss: 0.0696 | Avg Valid recon Loss: 0.0696\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0479, recon=0.0479, kl=44.1024, beta=0.0000\n",
      "Batch 40, loss=0.0465, recon=0.0465, kl=44.1011, beta=0.0000\n",
      "Batch 60, loss=0.0555, recon=0.0555, kl=45.0635, beta=0.0000\n",
      "Batch 80, loss=0.0954, recon=0.0953, kl=50.1458, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0786 (Recon: 0.0786, KL: 45.5892, Current Beta: 0.0000) | Avg Valid Loss: 0.0607 | Avg Valid recon Loss: 0.0607\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0509, recon=0.0508, kl=36.1648, beta=0.0000\n",
      "Batch 40, loss=0.1328, recon=0.1327, kl=30.7883, beta=0.0000\n",
      "Batch 60, loss=0.0525, recon=0.0525, kl=35.5209, beta=0.0000\n",
      "Batch 80, loss=0.0477, recon=0.0477, kl=29.0396, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0694 (Recon: 0.0694, KL: 34.5849, Current Beta: 0.0000) | Avg Valid Loss: 0.0552 | Avg Valid recon Loss: 0.0552\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1421, recon=0.1420, kl=16.4013, beta=0.0000\n",
      "Batch 40, loss=0.0504, recon=0.0504, kl=13.9148, beta=0.0000\n",
      "Batch 60, loss=0.6246, recon=0.6245, kl=10.8243, beta=0.0000\n",
      "Batch 80, loss=0.0576, recon=0.0576, kl=14.7639, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0629 (Recon: 0.0629, KL: 15.3401, Current Beta: 0.0000) | Avg Valid Loss: 0.0506 | Avg Valid recon Loss: 0.0506\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0338, recon=0.0338, kl=4.1546, beta=0.0000\n",
      "Batch 40, loss=0.0533, recon=0.0533, kl=4.4673, beta=0.0000\n",
      "Batch 60, loss=0.1056, recon=0.1056, kl=5.3570, beta=0.0000\n",
      "Batch 80, loss=0.0438, recon=0.0438, kl=4.0653, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0574 (Recon: 0.0574, KL: 5.3045, Current Beta: 0.0000) | Avg Valid Loss: 0.0482 | Avg Valid recon Loss: 0.0482\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0526, recon=0.0526, kl=1.2288, beta=0.0000\n",
      "Batch 40, loss=0.0389, recon=0.0388, kl=2.0298, beta=0.0000\n",
      "Batch 60, loss=0.0746, recon=0.0746, kl=1.5198, beta=0.0000\n",
      "Batch 80, loss=0.0401, recon=0.0401, kl=1.1756, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0532, KL: 1.7775, Current Beta: 0.0000) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0454\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0681, recon=0.0681, kl=0.1481, beta=0.0000\n",
      "Batch 40, loss=0.1295, recon=0.1295, kl=0.3191, beta=0.0000\n",
      "Batch 60, loss=0.0401, recon=0.0401, kl=0.4089, beta=0.0000\n",
      "Batch 80, loss=0.0476, recon=0.0476, kl=0.3824, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0499 (Recon: 0.0499, KL: 0.4611, Current Beta: 0.0000) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0577, recon=0.0577, kl=0.0390, beta=0.0001\n",
      "Batch 40, loss=0.0423, recon=0.0423, kl=0.0866, beta=0.0001\n",
      "Batch 60, loss=0.0348, recon=0.0348, kl=0.0158, beta=0.0001\n",
      "Batch 80, loss=0.0287, recon=0.0287, kl=0.1044, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0475 (Recon: 0.0475, KL: 0.0591, Current Beta: 0.0001) | Avg Valid Loss: 0.0405 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0268, recon=0.0268, kl=0.0100, beta=0.0003\n",
      "Batch 40, loss=0.0452, recon=0.0452, kl=0.0115, beta=0.0003\n",
      "Batch 60, loss=0.0354, recon=0.0354, kl=0.0075, beta=0.0003\n",
      "Batch 80, loss=0.0259, recon=0.0259, kl=0.0038, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0449, KL: 0.0089, Current Beta: 0.0003) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0336, recon=0.0336, kl=0.0018, beta=0.0008\n",
      "Batch 40, loss=0.0280, recon=0.0280, kl=0.0012, beta=0.0008\n",
      "Batch 60, loss=0.0263, recon=0.0263, kl=0.0008, beta=0.0008\n",
      "Batch 80, loss=0.0352, recon=0.0352, kl=0.0024, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0431, KL: 0.0017, Current Beta: 0.0008) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0265, recon=0.0265, kl=0.0009, beta=0.0018\n",
      "Batch 40, loss=0.0268, recon=0.0268, kl=0.0003, beta=0.0018\n",
      "Batch 60, loss=0.0272, recon=0.0272, kl=0.0007, beta=0.0018\n",
      "Batch 80, loss=0.0284, recon=0.0284, kl=0.0016, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0412 (Recon: 0.0412, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0247, recon=0.0247, kl=0.0002, beta=0.0038\n",
      "Batch 40, loss=0.0379, recon=0.0379, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.0522, recon=0.0522, kl=0.0002, beta=0.0038\n",
      "Batch 80, loss=0.0419, recon=0.0419, kl=0.0004, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0398 (Recon: 0.0398, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0345\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0314, recon=0.0314, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0419, recon=0.0419, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0231, recon=0.0231, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.2917, recon=0.2917, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0388, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0349 | Avg Valid recon Loss: 0.0349\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0238, recon=0.0238, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0229, recon=0.0229, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0756, recon=0.0755, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0215, recon=0.0215, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0375 (Recon: 0.0375, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0221, recon=0.0221, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0290, recon=0.0290, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0280, recon=0.0280, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0368, recon=0.0368, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0365 (Recon: 0.0365, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0321 | Avg Valid recon Loss: 0.0321\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0256, recon=0.0256, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0294, recon=0.0294, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0210, recon=0.0210, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0264, recon=0.0264, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0359 (Recon: 0.0359, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0316 | Avg Valid recon Loss: 0.0316\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0403, recon=0.0403, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0272, recon=0.0272, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0323, recon=0.0323, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0273, recon=0.0273, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0352 (Recon: 0.0352, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0306 | Avg Valid recon Loss: 0.0306\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0246, recon=0.0246, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0480, recon=0.0480, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0303, recon=0.0303, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0436, recon=0.0436, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0339 (Recon: 0.0339, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0304\n",
      "\n",
      "[VRAE Run 212/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1938, recon=0.1938, kl=21.6252, beta=0.0000\n",
      "Batch 40, loss=0.0918, recon=0.0918, kl=24.8101, beta=0.0000\n",
      "Batch 60, loss=0.0529, recon=0.0529, kl=26.9031, beta=0.0000\n",
      "Batch 80, loss=0.0871, recon=0.0871, kl=33.2179, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1497 (Recon: 0.1497, KL: 24.4609, Current Beta: 0.0000) | Avg Valid Loss: 0.0637 | Avg Valid recon Loss: 0.0637\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0382, recon=0.0382, kl=30.6414, beta=0.0000\n",
      "Batch 40, loss=0.0930, recon=0.0930, kl=33.5441, beta=0.0000\n",
      "Batch 60, loss=0.0547, recon=0.0547, kl=37.4671, beta=0.0000\n",
      "Batch 80, loss=0.0497, recon=0.0497, kl=35.1548, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0601 (Recon: 0.0601, KL: 33.5564, Current Beta: 0.0000) | Avg Valid Loss: 0.0552 | Avg Valid recon Loss: 0.0552\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0333, recon=0.0333, kl=27.5925, beta=0.0000\n",
      "Batch 40, loss=0.1308, recon=0.1307, kl=35.5903, beta=0.0000\n",
      "Batch 60, loss=0.0390, recon=0.0389, kl=34.7081, beta=0.0000\n",
      "Batch 80, loss=0.0305, recon=0.0305, kl=33.0756, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0556 (Recon: 0.0556, KL: 32.5811, Current Beta: 0.0000) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0821, recon=0.0821, kl=30.3492, beta=0.0000\n",
      "Batch 40, loss=0.0249, recon=0.0249, kl=24.9682, beta=0.0000\n",
      "Batch 60, loss=0.0479, recon=0.0479, kl=26.5396, beta=0.0000\n",
      "Batch 80, loss=0.0243, recon=0.0243, kl=26.8571, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 27.3750, Current Beta: 0.0000) | Avg Valid Loss: 0.0435 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0402, recon=0.0402, kl=21.0851, beta=0.0000\n",
      "Batch 40, loss=0.0383, recon=0.0382, kl=20.5267, beta=0.0000\n",
      "Batch 60, loss=0.0454, recon=0.0454, kl=26.8327, beta=0.0000\n",
      "Batch 80, loss=0.0274, recon=0.0274, kl=22.0726, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0420 (Recon: 0.0420, KL: 22.9095, Current Beta: 0.0000) | Avg Valid Loss: 0.0375 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0259, recon=0.0259, kl=13.0129, beta=0.0000\n",
      "Batch 40, loss=0.0598, recon=0.0598, kl=14.9716, beta=0.0000\n",
      "Batch 60, loss=0.0328, recon=0.0327, kl=13.1695, beta=0.0000\n",
      "Batch 80, loss=0.0523, recon=0.0523, kl=15.9033, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0417, KL: 14.9197, Current Beta: 0.0000) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0661, recon=0.0660, kl=6.4263, beta=0.0000\n",
      "Batch 40, loss=0.1029, recon=0.1029, kl=9.5407, beta=0.0000\n",
      "Batch 60, loss=0.0424, recon=0.0423, kl=12.3764, beta=0.0000\n",
      "Batch 80, loss=0.0333, recon=0.0332, kl=11.5059, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0491 (Recon: 0.0491, KL: 10.1453, Current Beta: 0.0000) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0271, recon=0.0270, kl=3.4061, beta=0.0000\n",
      "Batch 40, loss=0.0379, recon=0.0379, kl=4.6631, beta=0.0000\n",
      "Batch 60, loss=0.0267, recon=0.0266, kl=6.2454, beta=0.0000\n",
      "Batch 80, loss=0.0407, recon=0.0407, kl=3.0605, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0403 (Recon: 0.0403, KL: 4.6779, Current Beta: 0.0000) | Avg Valid Loss: 0.0320 | Avg Valid recon Loss: 0.0320\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0261, recon=0.0261, kl=0.5283, beta=0.0000\n",
      "Batch 40, loss=0.0190, recon=0.0190, kl=0.7493, beta=0.0000\n",
      "Batch 60, loss=0.0342, recon=0.0342, kl=1.0424, beta=0.0000\n",
      "Batch 80, loss=0.0227, recon=0.0227, kl=1.4918, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0340 (Recon: 0.0339, KL: 1.0032, Current Beta: 0.0000) | Avg Valid Loss: 0.0320 | Avg Valid recon Loss: 0.0320\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0216, recon=0.0216, kl=0.3785, beta=0.0001\n",
      "Batch 40, loss=0.0275, recon=0.0274, kl=0.1135, beta=0.0001\n",
      "Batch 60, loss=0.0282, recon=0.0282, kl=0.1589, beta=0.0001\n",
      "Batch 80, loss=0.0479, recon=0.0479, kl=0.2888, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0345 (Recon: 0.0345, KL: 0.3477, Current Beta: 0.0001) | Avg Valid Loss: 0.0348 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0567, recon=0.0567, kl=0.0417, beta=0.0003\n",
      "Batch 40, loss=0.0354, recon=0.0354, kl=0.0150, beta=0.0003\n",
      "Batch 60, loss=0.0339, recon=0.0339, kl=0.0245, beta=0.0003\n",
      "Batch 80, loss=0.4193, recon=0.4192, kl=0.1624, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.1049 (Recon: 0.1049, KL: 0.0839, Current Beta: 0.0003) | Avg Valid Loss: 0.1254 | Avg Valid recon Loss: 0.1252\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1109, recon=0.1100, kl=1.1894, beta=0.0008\n",
      "Batch 40, loss=0.1949, recon=0.1947, kl=0.3611, beta=0.0008\n",
      "Batch 60, loss=0.0417, recon=0.0416, kl=0.0846, beta=0.0008\n",
      "Batch 80, loss=0.1397, recon=0.1396, kl=0.0461, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0826 (Recon: 0.0822, KL: 0.4784, Current Beta: 0.0008) | Avg Valid Loss: 0.0504 | Avg Valid recon Loss: 0.0504\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0551, recon=0.0551, kl=0.0029, beta=0.0018\n",
      "Batch 40, loss=0.0296, recon=0.0296, kl=0.0014, beta=0.0018\n",
      "Batch 60, loss=0.0325, recon=0.0325, kl=0.0012, beta=0.0018\n",
      "Batch 80, loss=0.0826, recon=0.0826, kl=0.0060, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0469, KL: 0.0056, Current Beta: 0.0018) | Avg Valid Loss: 0.0498 | Avg Valid recon Loss: 0.0498\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0374, recon=0.0374, kl=0.0021, beta=0.0038\n",
      "Batch 40, loss=0.0287, recon=0.0287, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.0438, recon=0.0438, kl=0.0004, beta=0.0038\n",
      "Batch 80, loss=0.0276, recon=0.0276, kl=0.0004, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 0.0009, Current Beta: 0.0038) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=0.0002, beta=0.0062\n",
      "Batch 40, loss=0.0252, recon=0.0252, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0395, recon=0.0395, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0301, recon=0.0301, kl=0.0002, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0385 (Recon: 0.0385, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0460, recon=0.0460, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0292, recon=0.0292, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0207, recon=0.0207, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0307, recon=0.0307, kl=0.0008, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0464 (Recon: 0.0464, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0559\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0440, recon=0.0440, kl=0.0003, beta=0.0100\n",
      "Batch 40, loss=0.0833, recon=0.0833, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0260, recon=0.0260, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0665, recon=0.0665, kl=0.0081, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0567 (Recon: 0.0566, KL: 0.0049, Current Beta: 0.0100) | Avg Valid Loss: 0.0659 | Avg Valid recon Loss: 0.0655\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1772, recon=0.1736, kl=0.3675, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 20, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 40, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 60, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "Batch 80, loss=nan, recon=nan, kl=nan, beta=0.0100\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0100) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "[VRAE Run 213/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2825, recon=0.2825, kl=7.1601, beta=0.0000\n",
      "Batch 40, loss=0.1536, recon=0.1536, kl=45.8684, beta=0.0000\n",
      "Batch 60, loss=0.4900, recon=0.4900, kl=60.0829, beta=0.0000\n",
      "Batch 80, loss=0.1433, recon=0.1433, kl=70.4478, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2711 (Recon: 0.2711, KL: 42.0394, Current Beta: 0.0000) | Avg Valid Loss: 0.1139 | Avg Valid recon Loss: 0.1139\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0936, recon=0.0936, kl=77.0684, beta=0.0000\n",
      "Batch 40, loss=0.1067, recon=0.1067, kl=76.9387, beta=0.0000\n",
      "Batch 60, loss=0.0879, recon=0.0879, kl=74.0901, beta=0.0000\n",
      "Batch 80, loss=0.0760, recon=0.0760, kl=76.4894, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1197 (Recon: 0.1197, KL: 76.3658, Current Beta: 0.0000) | Avg Valid Loss: 0.0827 | Avg Valid recon Loss: 0.0827\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0513, recon=0.0513, kl=75.5899, beta=0.0000\n",
      "Batch 40, loss=0.1119, recon=0.1119, kl=76.9720, beta=0.0000\n",
      "Batch 60, loss=0.0833, recon=0.0833, kl=82.9637, beta=0.0000\n",
      "Batch 80, loss=0.7745, recon=0.7745, kl=80.3950, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0906 (Recon: 0.0905, KL: 78.6299, Current Beta: 0.0000) | Avg Valid Loss: 0.0699 | Avg Valid recon Loss: 0.0699\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0685, recon=0.0685, kl=80.9512, beta=0.0000\n",
      "Batch 40, loss=0.0634, recon=0.0634, kl=67.4202, beta=0.0000\n",
      "Batch 60, loss=0.0848, recon=0.0847, kl=64.0820, beta=0.0000\n",
      "Batch 80, loss=0.0633, recon=0.0633, kl=60.3713, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0770 (Recon: 0.0770, KL: 69.4372, Current Beta: 0.0000) | Avg Valid Loss: 0.0592 | Avg Valid recon Loss: 0.0592\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0522, recon=0.0521, kl=43.3815, beta=0.0000\n",
      "Batch 40, loss=0.1701, recon=0.1701, kl=36.1791, beta=0.0000\n",
      "Batch 60, loss=0.0726, recon=0.0726, kl=37.9047, beta=0.0000\n",
      "Batch 80, loss=0.0565, recon=0.0565, kl=36.2299, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0685 (Recon: 0.0685, KL: 40.5366, Current Beta: 0.0000) | Avg Valid Loss: 0.0551 | Avg Valid recon Loss: 0.0551\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0426, recon=0.0426, kl=18.4118, beta=0.0000\n",
      "Batch 40, loss=0.0479, recon=0.0479, kl=21.7510, beta=0.0000\n",
      "Batch 60, loss=0.0524, recon=0.0524, kl=17.5731, beta=0.0000\n",
      "Batch 80, loss=0.0660, recon=0.0660, kl=15.2572, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0619 (Recon: 0.0619, KL: 20.3486, Current Beta: 0.0000) | Avg Valid Loss: 0.0512 | Avg Valid recon Loss: 0.0512\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.5837, recon=0.5837, kl=8.2444, beta=0.0000\n",
      "Batch 40, loss=0.0456, recon=0.0455, kl=6.9184, beta=0.0000\n",
      "Batch 60, loss=0.0388, recon=0.0388, kl=7.0357, beta=0.0000\n",
      "Batch 80, loss=0.0558, recon=0.0557, kl=6.8706, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0573 (Recon: 0.0572, KL: 8.2741, Current Beta: 0.0000) | Avg Valid Loss: 0.0475 | Avg Valid recon Loss: 0.0474\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0425, recon=0.0424, kl=2.1953, beta=0.0000\n",
      "Batch 40, loss=0.0443, recon=0.0443, kl=2.6430, beta=0.0000\n",
      "Batch 60, loss=0.0961, recon=0.0961, kl=2.3843, beta=0.0000\n",
      "Batch 80, loss=0.0561, recon=0.0561, kl=2.0613, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0533, KL: 2.7414, Current Beta: 0.0000) | Avg Valid Loss: 0.0448 | Avg Valid recon Loss: 0.0447\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0354, recon=0.0354, kl=0.4765, beta=0.0000\n",
      "Batch 40, loss=0.0863, recon=0.0862, kl=0.6006, beta=0.0000\n",
      "Batch 60, loss=0.0410, recon=0.0409, kl=0.6562, beta=0.0000\n",
      "Batch 80, loss=0.0304, recon=0.0304, kl=0.4093, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0496, KL: 0.7056, Current Beta: 0.0000) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=0.0671, beta=0.0001\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=0.0792, beta=0.0001\n",
      "Batch 60, loss=0.0390, recon=0.0390, kl=0.0669, beta=0.0001\n",
      "Batch 80, loss=0.0423, recon=0.0423, kl=0.0725, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0468 (Recon: 0.0468, KL: 0.1001, Current Beta: 0.0001) | Avg Valid Loss: 0.0409 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0474, recon=0.0474, kl=0.0328, beta=0.0003\n",
      "Batch 40, loss=0.0259, recon=0.0259, kl=0.0118, beta=0.0003\n",
      "Batch 60, loss=0.0302, recon=0.0302, kl=0.0078, beta=0.0003\n",
      "Batch 80, loss=0.0534, recon=0.0534, kl=0.0087, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0443 (Recon: 0.0443, KL: 0.0140, Current Beta: 0.0003) | Avg Valid Loss: 0.0386 | Avg Valid recon Loss: 0.0386\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0321, recon=0.0321, kl=0.0018, beta=0.0008\n",
      "Batch 40, loss=0.0524, recon=0.0524, kl=0.0016, beta=0.0008\n",
      "Batch 60, loss=0.0427, recon=0.0427, kl=0.0015, beta=0.0008\n",
      "Batch 80, loss=0.0306, recon=0.0306, kl=0.0047, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0423, KL: 0.0032, Current Beta: 0.0008) | Avg Valid Loss: 0.0362 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.3232, recon=0.3232, kl=0.0006, beta=0.0018\n",
      "Batch 40, loss=0.0279, recon=0.0279, kl=0.0016, beta=0.0018\n",
      "Batch 60, loss=0.0216, recon=0.0216, kl=0.0011, beta=0.0018\n",
      "Batch 80, loss=0.1194, recon=0.1194, kl=0.0014, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0406 (Recon: 0.0405, KL: 0.0013, Current Beta: 0.0018) | Avg Valid Loss: 0.0354 | Avg Valid recon Loss: 0.0354\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0402, recon=0.0402, kl=0.0003, beta=0.0038\n",
      "Batch 40, loss=0.0254, recon=0.0254, kl=0.0004, beta=0.0038\n",
      "Batch 60, loss=0.0335, recon=0.0335, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0320, recon=0.0320, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0394 (Recon: 0.0394, KL: 0.0004, Current Beta: 0.0038) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0346\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0222, recon=0.0222, kl=0.0002, beta=0.0062\n",
      "Batch 40, loss=0.0930, recon=0.0930, kl=0.0001, beta=0.0062\n",
      "Batch 60, loss=0.0383, recon=0.0383, kl=0.0001, beta=0.0062\n",
      "Batch 80, loss=0.0300, recon=0.0300, kl=0.0003, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0380 (Recon: 0.0380, KL: 0.0003, Current Beta: 0.0062) | Avg Valid Loss: 0.0335 | Avg Valid recon Loss: 0.0335\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0323, recon=0.0323, kl=0.0002, beta=0.0100\n",
      "Batch 40, loss=0.0474, recon=0.0474, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.0209, recon=0.0209, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0268, recon=0.0268, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0373 (Recon: 0.0373, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0325 | Avg Valid recon Loss: 0.0325\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0393, recon=0.0393, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0474, recon=0.0474, kl=0.0002, beta=0.0100\n",
      "Batch 60, loss=0.0303, recon=0.0303, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0332, recon=0.0332, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0364 (Recon: 0.0364, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0321 | Avg Valid recon Loss: 0.0321\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0327, recon=0.0327, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0311, recon=0.0311, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0233, recon=0.0233, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0291, recon=0.0291, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0356 (Recon: 0.0356, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0313 | Avg Valid recon Loss: 0.0313\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0269, recon=0.0269, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0265, recon=0.0265, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.2557, recon=0.2557, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.0229, recon=0.0229, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0350 (Recon: 0.0350, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0318\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0198, recon=0.0198, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0348, recon=0.0348, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0291, recon=0.0291, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0216, recon=0.0216, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0344 (Recon: 0.0344, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0304\n",
      "\n",
      "[VRAE Run 214/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1039, recon=0.1039, kl=44.8012, beta=0.0000\n",
      "Batch 40, loss=0.0794, recon=0.0794, kl=57.6654, beta=0.0000\n",
      "Batch 60, loss=0.0667, recon=0.0667, kl=47.0530, beta=0.0000\n",
      "Batch 80, loss=0.0601, recon=0.0601, kl=60.9316, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1457 (Recon: 0.1457, KL: 45.5448, Current Beta: 0.0000) | Avg Valid Loss: 0.0609 | Avg Valid recon Loss: 0.0609\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0775, recon=0.0775, kl=57.7814, beta=0.0000\n",
      "Batch 40, loss=0.1020, recon=0.1020, kl=60.4133, beta=0.0000\n",
      "Batch 60, loss=0.0634, recon=0.0634, kl=53.0127, beta=0.0000\n",
      "Batch 80, loss=0.0572, recon=0.0572, kl=58.0847, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0610 (Recon: 0.0610, KL: 58.0341, Current Beta: 0.0000) | Avg Valid Loss: 0.0509 | Avg Valid recon Loss: 0.0509\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0291, recon=0.0291, kl=61.1704, beta=0.0000\n",
      "Batch 40, loss=0.0721, recon=0.0721, kl=55.2530, beta=0.0000\n",
      "Batch 60, loss=0.0311, recon=0.0311, kl=57.3735, beta=0.0000\n",
      "Batch 80, loss=0.0436, recon=0.0436, kl=46.5843, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0497, KL: 56.1678, Current Beta: 0.0000) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0352, recon=0.0351, kl=49.5103, beta=0.0000\n",
      "Batch 40, loss=0.0466, recon=0.0465, kl=51.0453, beta=0.0000\n",
      "Batch 60, loss=0.0716, recon=0.0716, kl=63.1134, beta=0.0000\n",
      "Batch 80, loss=0.0440, recon=0.0440, kl=41.5616, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0532 (Recon: 0.0531, KL: 51.0580, Current Beta: 0.0000) | Avg Valid Loss: 0.0451 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0348, recon=0.0348, kl=41.0114, beta=0.0000\n",
      "Batch 40, loss=0.0502, recon=0.0502, kl=35.4123, beta=0.0000\n",
      "Batch 60, loss=0.0434, recon=0.0433, kl=49.5917, beta=0.0000\n",
      "Batch 80, loss=0.0310, recon=0.0309, kl=45.9067, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0495, KL: 45.0763, Current Beta: 0.0000) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0385, recon=0.0384, kl=27.6044, beta=0.0000\n",
      "Batch 40, loss=0.0345, recon=0.0345, kl=32.5778, beta=0.0000\n",
      "Batch 60, loss=0.0321, recon=0.0320, kl=29.9515, beta=0.0000\n",
      "Batch 80, loss=0.0303, recon=0.0302, kl=29.9133, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0403 (Recon: 0.0403, KL: 32.1810, Current Beta: 0.0000) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0277, recon=0.0275, kl=24.8108, beta=0.0000\n",
      "Batch 40, loss=0.0303, recon=0.0302, kl=18.4162, beta=0.0000\n",
      "Batch 60, loss=0.0240, recon=0.0239, kl=19.0940, beta=0.0000\n",
      "Batch 80, loss=0.0299, recon=0.0298, kl=19.3627, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0369 (Recon: 0.0368, KL: 21.2659, Current Beta: 0.0000) | Avg Valid Loss: 0.0354 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0327, recon=0.0326, kl=12.3553, beta=0.0000\n",
      "Batch 40, loss=0.0278, recon=0.0277, kl=9.0066, beta=0.0000\n",
      "Batch 60, loss=0.0352, recon=0.0350, kl=9.4383, beta=0.0000\n",
      "Batch 80, loss=0.0385, recon=0.0383, kl=9.8996, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0389, KL: 11.8542, Current Beta: 0.0000) | Avg Valid Loss: 0.0281 | Avg Valid recon Loss: 0.0279\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0265, recon=0.0264, kl=2.6617, beta=0.0000\n",
      "Batch 40, loss=0.0303, recon=0.0302, kl=2.3460, beta=0.0000\n",
      "Batch 60, loss=0.0261, recon=0.0260, kl=1.9238, beta=0.0000\n",
      "Batch 80, loss=0.0248, recon=0.0247, kl=1.9837, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0324 (Recon: 0.0323, KL: 2.7365, Current Beta: 0.0000) | Avg Valid Loss: 0.0261 | Avg Valid recon Loss: 0.0260\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0207, recon=0.0206, kl=0.6301, beta=0.0001\n",
      "Batch 40, loss=0.0312, recon=0.0312, kl=0.6988, beta=0.0001\n",
      "Batch 60, loss=0.0304, recon=0.0304, kl=0.5298, beta=0.0001\n",
      "Batch 80, loss=0.0295, recon=0.0294, kl=0.2967, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0298 (Recon: 0.0298, KL: 0.7133, Current Beta: 0.0001) | Avg Valid Loss: 0.0266 | Avg Valid recon Loss: 0.0265\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0239, recon=0.0238, kl=0.0871, beta=0.0003\n",
      "Batch 40, loss=0.0298, recon=0.0298, kl=0.0291, beta=0.0003\n",
      "Batch 60, loss=0.0388, recon=0.0388, kl=0.0917, beta=0.0003\n",
      "Batch 80, loss=0.0255, recon=0.0255, kl=0.0996, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0361 (Recon: 0.0361, KL: 0.1163, Current Beta: 0.0003) | Avg Valid Loss: 0.0302 | Avg Valid recon Loss: 0.0301\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0270, recon=0.0270, kl=0.0086, beta=0.0008\n",
      "Batch 40, loss=0.0237, recon=0.0237, kl=0.0039, beta=0.0008\n",
      "Batch 60, loss=0.0406, recon=0.0406, kl=0.0103, beta=0.0008\n",
      "Batch 80, loss=0.0337, recon=0.0337, kl=0.0089, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0382, KL: 0.0104, Current Beta: 0.0008) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0363, recon=0.0363, kl=0.0030, beta=0.0018\n",
      "Batch 40, loss=0.0289, recon=0.0289, kl=0.0022, beta=0.0018\n",
      "Batch 60, loss=0.1202, recon=0.1202, kl=0.0024, beta=0.0018\n",
      "Batch 80, loss=0.0272, recon=0.0272, kl=0.0020, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0367 (Recon: 0.0367, KL: 0.0023, Current Beta: 0.0018) | Avg Valid Loss: 0.0462 | Avg Valid recon Loss: 0.0462\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0458, recon=0.0458, kl=0.0076, beta=0.0038\n",
      "Batch 40, loss=0.0552, recon=0.0551, kl=0.0062, beta=0.0038\n",
      "Batch 60, loss=0.0306, recon=0.0306, kl=0.0034, beta=0.0038\n",
      "Batch 80, loss=0.0405, recon=0.0405, kl=0.0014, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0503 (Recon: 0.0503, KL: 0.0042, Current Beta: 0.0038) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0384\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0295, recon=0.0295, kl=0.0003, beta=0.0062\n",
      "Batch 40, loss=0.0274, recon=0.0274, kl=0.0002, beta=0.0062\n",
      "Batch 60, loss=0.0570, recon=0.0570, kl=0.0028, beta=0.0062\n",
      "Batch 80, loss=0.0385, recon=0.0384, kl=0.0060, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0503 (Recon: 0.0503, KL: 0.0028, Current Beta: 0.0062) | Avg Valid Loss: 0.0447 | Avg Valid recon Loss: 0.0447\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0240, recon=0.0240, kl=0.0011, beta=0.0100\n",
      "Batch 40, loss=0.0601, recon=0.0600, kl=0.0012, beta=0.0100\n",
      "Batch 60, loss=0.0360, recon=0.0360, kl=0.0009, beta=0.0100\n",
      "Batch 80, loss=0.0275, recon=0.0275, kl=0.0008, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0481 (Recon: 0.0480, KL: 0.0010, Current Beta: 0.0100) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0300, recon=0.0300, kl=0.0009, beta=0.0100\n",
      "Batch 40, loss=0.0235, recon=0.0235, kl=0.0022, beta=0.0100\n",
      "Batch 60, loss=0.0279, recon=0.0279, kl=0.0005, beta=0.0100\n",
      "Batch 80, loss=0.0199, recon=0.0199, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0385 (Recon: 0.0385, KL: 0.0010, Current Beta: 0.0100) | Avg Valid Loss: 0.0329 | Avg Valid recon Loss: 0.0329\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0303, recon=0.0303, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0273, recon=0.0273, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0280, recon=0.0280, kl=0.0003, beta=0.0100\n",
      "Batch 80, loss=0.0224, recon=0.0224, kl=0.0010, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0351 (Recon: 0.0351, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0497 | Avg Valid recon Loss: 0.0497\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0366, recon=0.0366, kl=0.0027, beta=0.0100\n",
      "Batch 40, loss=0.0373, recon=0.0373, kl=0.0013, beta=0.0100\n",
      "Batch 60, loss=0.0221, recon=0.0221, kl=0.0003, beta=0.0100\n",
      "Batch 80, loss=0.0225, recon=0.0225, kl=0.0005, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0406 (Recon: 0.0406, KL: 0.0010, Current Beta: 0.0100) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0682, recon=0.0681, kl=0.0007, beta=0.0100\n",
      "Batch 40, loss=0.0343, recon=0.0343, kl=0.0013, beta=0.0100\n",
      "Batch 60, loss=0.1062, recon=0.1061, kl=0.0112, beta=0.0100\n",
      "Batch 80, loss=0.0641, recon=0.0639, kl=0.0208, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0511 (Recon: 0.0510, KL: 0.0059, Current Beta: 0.0100) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0429\n",
      "\n",
      "[VRAE Run 215/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3508, recon=0.3508, kl=20.3335, beta=0.0000\n",
      "Batch 40, loss=0.5966, recon=0.5966, kl=91.8424, beta=0.0000\n",
      "Batch 60, loss=0.2229, recon=0.2229, kl=122.1179, beta=0.0000\n",
      "Batch 80, loss=0.1476, recon=0.1476, kl=136.1409, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2761 (Recon: 0.2761, KL: 83.4582, Current Beta: 0.0000) | Avg Valid Loss: 0.1149 | Avg Valid recon Loss: 0.1149\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1244, recon=0.1243, kl=147.1988, beta=0.0000\n",
      "Batch 40, loss=0.1154, recon=0.1154, kl=145.1879, beta=0.0000\n",
      "Batch 60, loss=0.1724, recon=0.1724, kl=141.9996, beta=0.0000\n",
      "Batch 80, loss=0.0910, recon=0.0909, kl=143.6283, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1245 (Recon: 0.1245, KL: 144.5301, Current Beta: 0.0000) | Avg Valid Loss: 0.0860 | Avg Valid recon Loss: 0.0860\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0899, recon=0.0898, kl=142.1810, beta=0.0000\n",
      "Batch 40, loss=0.0777, recon=0.0777, kl=138.0708, beta=0.0000\n",
      "Batch 60, loss=0.0780, recon=0.0780, kl=139.7779, beta=0.0000\n",
      "Batch 80, loss=0.0779, recon=0.0779, kl=143.7716, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0973 (Recon: 0.0973, KL: 141.2648, Current Beta: 0.0000) | Avg Valid Loss: 0.0723 | Avg Valid recon Loss: 0.0723\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0912, recon=0.0912, kl=120.8013, beta=0.0000\n",
      "Batch 40, loss=0.2215, recon=0.2214, kl=102.9401, beta=0.0000\n",
      "Batch 60, loss=0.1007, recon=0.1006, kl=95.6216, beta=0.0000\n",
      "Batch 80, loss=0.0533, recon=0.0533, kl=93.9240, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0807 (Recon: 0.0806, KL: 107.0267, Current Beta: 0.0000) | Avg Valid Loss: 0.0637 | Avg Valid recon Loss: 0.0637\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0663, recon=0.0662, kl=68.9946, beta=0.0000\n",
      "Batch 40, loss=0.0757, recon=0.0756, kl=56.5069, beta=0.0000\n",
      "Batch 60, loss=0.0417, recon=0.0416, kl=57.4835, beta=0.0000\n",
      "Batch 80, loss=0.1102, recon=0.1102, kl=57.7500, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0702 (Recon: 0.0702, KL: 64.4937, Current Beta: 0.0000) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0573\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0641, recon=0.0641, kl=28.2098, beta=0.0000\n",
      "Batch 40, loss=0.0694, recon=0.0694, kl=25.1334, beta=0.0000\n",
      "Batch 60, loss=0.0652, recon=0.0651, kl=28.8663, beta=0.0000\n",
      "Batch 80, loss=0.0453, recon=0.0452, kl=25.7351, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0643 (Recon: 0.0643, KL: 29.2675, Current Beta: 0.0000) | Avg Valid Loss: 0.0547 | Avg Valid recon Loss: 0.0546\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0893, recon=0.0893, kl=8.3416, beta=0.0000\n",
      "Batch 40, loss=0.1050, recon=0.1049, kl=9.3127, beta=0.0000\n",
      "Batch 60, loss=0.0482, recon=0.0481, kl=10.2003, beta=0.0000\n",
      "Batch 80, loss=0.0477, recon=0.0476, kl=8.4798, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0590 (Recon: 0.0590, KL: 10.5884, Current Beta: 0.0000) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0509\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0441, recon=0.0440, kl=3.3255, beta=0.0000\n",
      "Batch 40, loss=0.0566, recon=0.0565, kl=3.4456, beta=0.0000\n",
      "Batch 60, loss=0.0548, recon=0.0547, kl=4.1483, beta=0.0000\n",
      "Batch 80, loss=0.0904, recon=0.0904, kl=3.1506, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 3.8548, Current Beta: 0.0000) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0465\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0423, recon=0.0422, kl=1.4798, beta=0.0000\n",
      "Batch 40, loss=0.0283, recon=0.0283, kl=0.9301, beta=0.0000\n",
      "Batch 60, loss=0.0546, recon=0.0546, kl=1.0204, beta=0.0000\n",
      "Batch 80, loss=0.0568, recon=0.0567, kl=0.9639, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0519 (Recon: 0.0518, KL: 1.1669, Current Beta: 0.0000) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0392, recon=0.0391, kl=0.2442, beta=0.0001\n",
      "Batch 40, loss=0.0283, recon=0.0283, kl=0.1118, beta=0.0001\n",
      "Batch 60, loss=0.0414, recon=0.0414, kl=0.1351, beta=0.0001\n",
      "Batch 80, loss=0.0579, recon=0.0579, kl=0.0822, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0488 (Recon: 0.0488, KL: 0.1927, Current Beta: 0.0001) | Avg Valid Loss: 0.0424 | Avg Valid recon Loss: 0.0424\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0401, recon=0.0401, kl=0.0167, beta=0.0003\n",
      "Batch 40, loss=0.1095, recon=0.1095, kl=0.0241, beta=0.0003\n",
      "Batch 60, loss=0.0311, recon=0.0311, kl=0.0159, beta=0.0003\n",
      "Batch 80, loss=0.0604, recon=0.0604, kl=0.0308, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0466, KL: 0.0239, Current Beta: 0.0003) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0307, recon=0.0307, kl=0.0048, beta=0.0008\n",
      "Batch 40, loss=0.0960, recon=0.0960, kl=0.0022, beta=0.0008\n",
      "Batch 60, loss=0.0247, recon=0.0247, kl=0.0032, beta=0.0008\n",
      "Batch 80, loss=0.0445, recon=0.0445, kl=0.0024, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0449, KL: 0.0042, Current Beta: 0.0008) | Avg Valid Loss: 0.0396 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0256, recon=0.0256, kl=0.0008, beta=0.0018\n",
      "Batch 40, loss=0.0297, recon=0.0297, kl=0.0003, beta=0.0018\n",
      "Batch 60, loss=0.0347, recon=0.0346, kl=0.0017, beta=0.0018\n",
      "Batch 80, loss=0.0332, recon=0.0332, kl=0.0008, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0428 (Recon: 0.0428, KL: 0.0008, Current Beta: 0.0018) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0256, recon=0.0256, kl=0.0002, beta=0.0038\n",
      "Batch 40, loss=0.0353, recon=0.0353, kl=0.0002, beta=0.0038\n",
      "Batch 60, loss=0.0913, recon=0.0913, kl=0.0001, beta=0.0038\n",
      "Batch 80, loss=0.0517, recon=0.0517, kl=0.0003, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0418, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0884, recon=0.0884, kl=0.0001, beta=0.0062\n",
      "Batch 40, loss=0.0257, recon=0.0257, kl=0.0002, beta=0.0062\n",
      "Batch 60, loss=0.0321, recon=0.0321, kl=0.0000, beta=0.0062\n",
      "Batch 80, loss=0.0386, recon=0.0386, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0402 (Recon: 0.0402, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0297, recon=0.0297, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0204, recon=0.0204, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0197, recon=0.0197, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0220, recon=0.0220, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0391, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0345\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0455, recon=0.0455, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0315, recon=0.0315, kl=0.0001, beta=0.0100\n",
      "Batch 60, loss=0.0776, recon=0.0776, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0690, recon=0.0690, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0386, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0411, recon=0.0411, kl=0.0001, beta=0.0100\n",
      "Batch 40, loss=0.0255, recon=0.0255, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0276, recon=0.0276, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0320, recon=0.0320, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0373 (Recon: 0.0372, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0329 | Avg Valid recon Loss: 0.0329\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0278, recon=0.0278, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0319, recon=0.0319, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0258, recon=0.0258, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0433, recon=0.0433, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0364 (Recon: 0.0364, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0333 | Avg Valid recon Loss: 0.0333\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0218, recon=0.0218, kl=0.0000, beta=0.0100\n",
      "Batch 40, loss=0.0242, recon=0.0242, kl=0.0000, beta=0.0100\n",
      "Batch 60, loss=0.0361, recon=0.0361, kl=0.0000, beta=0.0100\n",
      "Batch 80, loss=0.0213, recon=0.0213, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0360 (Recon: 0.0360, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0319 | Avg Valid recon Loss: 0.0319\n",
      "\n",
      "[VRAE Run 216/324] Training with params: {'batch_size': 64, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1597, recon=0.1597, kl=70.1540, beta=0.0000\n",
      "Batch 40, loss=0.9001, recon=0.9001, kl=205.2786, beta=0.0000\n",
      "Batch 60, loss=0.0684, recon=0.0684, kl=280.3367, beta=0.0000\n",
      "Batch 80, loss=0.0667, recon=0.0667, kl=272.2788, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1389 (Recon: 0.1389, KL: 187.7505, Current Beta: 0.0000) | Avg Valid Loss: 0.0578 | Avg Valid recon Loss: 0.0578\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0449, recon=0.0449, kl=272.0731, beta=0.0000\n",
      "Batch 40, loss=0.0424, recon=0.0423, kl=267.5233, beta=0.0000\n",
      "Batch 60, loss=0.0418, recon=0.0418, kl=264.1567, beta=0.0000\n",
      "Batch 80, loss=0.0481, recon=0.0481, kl=260.9244, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0611 (Recon: 0.0610, KL: 266.7555, Current Beta: 0.0000) | Avg Valid Loss: 0.0495 | Avg Valid recon Loss: 0.0495\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=246.3613, beta=0.0000\n",
      "Batch 40, loss=0.1283, recon=0.1283, kl=233.5468, beta=0.0000\n",
      "Batch 60, loss=0.0428, recon=0.0428, kl=221.2821, beta=0.0000\n",
      "Batch 80, loss=0.0282, recon=0.0282, kl=215.1604, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0493 (Recon: 0.0493, KL: 232.4365, Current Beta: 0.0000) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0430, recon=0.0430, kl=194.2278, beta=0.0000\n",
      "Batch 40, loss=0.0235, recon=0.0235, kl=177.2563, beta=0.0000\n",
      "Batch 60, loss=0.0296, recon=0.0296, kl=171.3743, beta=0.0000\n",
      "Batch 80, loss=0.4192, recon=0.4191, kl=160.8531, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0465 (Recon: 0.0465, KL: 179.4181, Current Beta: 0.0000) | Avg Valid Loss: 0.0709 | Avg Valid recon Loss: 0.0709\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0385, recon=0.0384, kl=124.8229, beta=0.0000\n",
      "Batch 40, loss=0.0423, recon=0.0422, kl=109.7687, beta=0.0000\n",
      "Batch 60, loss=0.0648, recon=0.0647, kl=105.5829, beta=0.0000\n",
      "Batch 80, loss=0.0326, recon=0.0325, kl=105.7079, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0528 (Recon: 0.0527, KL: 114.7882, Current Beta: 0.0000) | Avg Valid Loss: 0.0400 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0343, recon=0.0341, kl=63.5536, beta=0.0000\n",
      "Batch 40, loss=0.0283, recon=0.0282, kl=59.6333, beta=0.0000\n",
      "Batch 60, loss=0.0583, recon=0.0582, kl=52.1639, beta=0.0000\n",
      "Batch 80, loss=0.0362, recon=0.0361, kl=48.8956, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0421, KL: 60.3202, Current Beta: 0.0000) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0360\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0570, recon=0.0568, kl=35.1246, beta=0.0000\n",
      "Batch 40, loss=0.0301, recon=0.0299, kl=36.8668, beta=0.0000\n",
      "Batch 60, loss=0.0276, recon=0.0274, kl=25.7075, beta=0.0000\n",
      "Batch 80, loss=0.0400, recon=0.0399, kl=23.6878, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0376 (Recon: 0.0374, KL: 28.9369, Current Beta: 0.0000) | Avg Valid Loss: 0.0323 | Avg Valid recon Loss: 0.0322\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0438, recon=0.0436, kl=13.8060, beta=0.0000\n",
      "Batch 40, loss=0.0316, recon=0.0314, kl=11.6990, beta=0.0000\n",
      "Batch 60, loss=0.0429, recon=0.0428, kl=7.1632, beta=0.0000\n",
      "Batch 80, loss=0.0277, recon=0.0276, kl=7.7384, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0387, KL: 10.3727, Current Beta: 0.0000) | Avg Valid Loss: 0.0298 | Avg Valid recon Loss: 0.0297\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0214, recon=0.0213, kl=1.7482, beta=0.0000\n",
      "Batch 40, loss=0.0325, recon=0.0325, kl=1.5367, beta=0.0000\n",
      "Batch 60, loss=0.0409, recon=0.0408, kl=1.2086, beta=0.0000\n",
      "Batch 80, loss=0.0371, recon=0.0370, kl=1.7130, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0381 (Recon: 0.0381, KL: 1.8451, Current Beta: 0.0000) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0241, recon=0.0241, kl=0.2402, beta=0.0001\n",
      "Batch 40, loss=0.0277, recon=0.0276, kl=0.8959, beta=0.0001\n",
      "Batch 60, loss=0.0253, recon=0.0252, kl=1.1571, beta=0.0001\n",
      "Batch 80, loss=0.0269, recon=0.0266, kl=2.0147, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0383 (Recon: 0.0382, KL: 0.9659, Current Beta: 0.0001) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0343\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0256, recon=0.0256, kl=0.1408, beta=0.0003\n",
      "Batch 40, loss=0.0544, recon=0.0544, kl=0.0833, beta=0.0003\n",
      "Batch 60, loss=0.0464, recon=0.0463, kl=0.4102, beta=0.0003\n",
      "Batch 80, loss=0.1376, recon=0.1375, kl=0.3570, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0441 (Recon: 0.0440, KL: 0.3402, Current Beta: 0.0003) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0349, recon=0.0349, kl=0.0287, beta=0.0008\n",
      "Batch 40, loss=0.0344, recon=0.0344, kl=0.0193, beta=0.0008\n",
      "Batch 60, loss=0.0239, recon=0.0239, kl=0.0135, beta=0.0008\n",
      "Batch 80, loss=0.0252, recon=0.0252, kl=0.0048, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0358, KL: 0.0345, Current Beta: 0.0008) | Avg Valid Loss: 0.0331 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=0.0125, beta=0.0018\n",
      "Batch 40, loss=0.0289, recon=0.0288, kl=0.0149, beta=0.0018\n",
      "Batch 60, loss=0.0378, recon=0.0378, kl=0.0036, beta=0.0018\n",
      "Batch 80, loss=0.0466, recon=0.0466, kl=0.0016, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0329 (Recon: 0.0329, KL: 0.0064, Current Beta: 0.0018) | Avg Valid Loss: 0.0274 | Avg Valid recon Loss: 0.0272\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0377, recon=0.0377, kl=0.0005, beta=0.0038\n",
      "Batch 40, loss=0.0260, recon=0.0260, kl=0.0007, beta=0.0038\n",
      "Batch 60, loss=0.0247, recon=0.0247, kl=0.0007, beta=0.0038\n",
      "Batch 80, loss=0.0181, recon=0.0181, kl=0.0007, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0345 (Recon: 0.0345, KL: 0.0009, Current Beta: 0.0038) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0275, recon=0.0275, kl=0.0003, beta=0.0062\n",
      "Batch 40, loss=0.0356, recon=0.0356, kl=0.0007, beta=0.0062\n",
      "Batch 60, loss=0.0390, recon=0.0390, kl=0.0010, beta=0.0062\n",
      "Batch 80, loss=0.0426, recon=0.0426, kl=0.0018, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0435 (Recon: 0.0435, KL: 0.0013, Current Beta: 0.0062) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0195, recon=0.0195, kl=0.0020, beta=0.0100\n",
      "Batch 40, loss=0.0243, recon=0.0242, kl=0.0045, beta=0.0100\n",
      "Batch 60, loss=0.0221, recon=0.0221, kl=0.0010, beta=0.0100\n",
      "Batch 80, loss=0.0732, recon=0.0732, kl=0.0008, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0395, KL: 0.0024, Current Beta: 0.0100) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1301, recon=0.1300, kl=0.0047, beta=0.0100\n",
      "Batch 40, loss=0.0480, recon=0.0477, kl=0.0281, beta=0.0100\n",
      "Batch 60, loss=0.0400, recon=0.0398, kl=0.0155, beta=0.0100\n",
      "Batch 80, loss=0.0468, recon=0.0467, kl=0.0067, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0673 (Recon: 0.0672, KL: 0.0128, Current Beta: 0.0100) | Avg Valid Loss: 0.0429 | Avg Valid recon Loss: 0.0418\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0787, recon=0.0786, kl=0.0053, beta=0.0100\n",
      "Batch 40, loss=0.0348, recon=0.0348, kl=0.0018, beta=0.0100\n",
      "Batch 60, loss=0.0296, recon=0.0296, kl=0.0007, beta=0.0100\n",
      "Batch 80, loss=0.0275, recon=0.0275, kl=0.0004, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0444 (Recon: 0.0444, KL: 0.0015, Current Beta: 0.0100) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0251, recon=0.0250, kl=0.0025, beta=0.0100\n",
      "Batch 40, loss=0.0292, recon=0.0292, kl=0.0005, beta=0.0100\n",
      "Batch 60, loss=0.0213, recon=0.0213, kl=0.0002, beta=0.0100\n",
      "Batch 80, loss=0.3695, recon=0.3695, kl=0.0006, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0350 (Recon: 0.0350, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0385 | Avg Valid recon Loss: 0.0375\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0272, recon=0.0272, kl=0.0006, beta=0.0100\n",
      "Batch 40, loss=0.0214, recon=0.0214, kl=0.0003, beta=0.0100\n",
      "Batch 60, loss=0.0229, recon=0.0229, kl=0.0001, beta=0.0100\n",
      "Batch 80, loss=0.0365, recon=0.0365, kl=0.0011, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0391, KL: 0.0007, Current Beta: 0.0100) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0422\n",
      "\n",
      "[VRAE Run 217/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7646, recon=0.7646, kl=0.2218, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.8709 (Recon: 0.8709, KL: 0.2204, Current Beta: 0.0000) | Avg Valid Loss: 0.7301 | Avg Valid recon Loss: 0.7301\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.6528, recon=0.6528, kl=0.5093, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5976 (Recon: 0.5976, KL: 0.3525, Current Beta: 0.0000) | Avg Valid Loss: 0.5298 | Avg Valid recon Loss: 0.5298\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.4045, recon=0.4045, kl=4.7042, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4625 (Recon: 0.4625, KL: 2.3932, Current Beta: 0.0000) | Avg Valid Loss: 0.4355 | Avg Valid recon Loss: 0.4355\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.3287, recon=0.3287, kl=11.0354, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3982 (Recon: 0.3982, KL: 8.7994, Current Beta: 0.0000) | Avg Valid Loss: 0.3731 | Avg Valid recon Loss: 0.3731\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2887, recon=0.2887, kl=14.6751, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3517 (Recon: 0.3517, KL: 13.3856, Current Beta: 0.0000) | Avg Valid Loss: 0.3267 | Avg Valid recon Loss: 0.3267\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.3072, recon=0.3072, kl=16.9673, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3157 (Recon: 0.3157, KL: 16.2307, Current Beta: 0.0000) | Avg Valid Loss: 0.2903 | Avg Valid recon Loss: 0.2903\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2614, recon=0.2614, kl=19.1033, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2865 (Recon: 0.2865, KL: 18.2391, Current Beta: 0.0000) | Avg Valid Loss: 0.2614 | Avg Valid recon Loss: 0.2614\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1987, recon=0.1987, kl=20.3969, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2657 (Recon: 0.2657, KL: 19.8101, Current Beta: 0.0000) | Avg Valid Loss: 0.2389 | Avg Valid recon Loss: 0.2389\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.2008, recon=0.2008, kl=20.4049, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2465 (Recon: 0.2465, KL: 20.3939, Current Beta: 0.0000) | Avg Valid Loss: 0.2209 | Avg Valid recon Loss: 0.2209\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.2241, recon=0.2241, kl=17.5002, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2336 (Recon: 0.2336, KL: 18.6737, Current Beta: 0.0000) | Avg Valid Loss: 0.2060 | Avg Valid recon Loss: 0.2060\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1940, recon=0.1940, kl=10.5204, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2210 (Recon: 0.2209, KL: 13.4676, Current Beta: 0.0000) | Avg Valid Loss: 0.1937 | Avg Valid recon Loss: 0.1937\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1805, recon=0.1805, kl=3.5498, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2093 (Recon: 0.2092, KL: 5.8907, Current Beta: 0.0000) | Avg Valid Loss: 0.1829 | Avg Valid recon Loss: 0.1829\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1634, recon=0.1634, kl=1.0340, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2005 (Recon: 0.2005, KL: 1.7945, Current Beta: 0.0000) | Avg Valid Loss: 0.1741 | Avg Valid recon Loss: 0.1741\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1602, recon=0.1602, kl=0.3338, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1913 (Recon: 0.1913, KL: 0.5756, Current Beta: 0.0000) | Avg Valid Loss: 0.1655 | Avg Valid recon Loss: 0.1654\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1263, recon=0.1263, kl=0.0969, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1806 (Recon: 0.1806, KL: 0.1671, Current Beta: 0.0001) | Avg Valid Loss: 0.1584 | Avg Valid recon Loss: 0.1584\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1333, recon=0.1333, kl=0.0151, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1761 (Recon: 0.1761, KL: 0.0393, Current Beta: 0.0001) | Avg Valid Loss: 0.1520 | Avg Valid recon Loss: 0.1520\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1398, recon=0.1398, kl=0.0086, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1686 (Recon: 0.1686, KL: 0.0114, Current Beta: 0.0001) | Avg Valid Loss: 0.1463 | Avg Valid recon Loss: 0.1463\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1493, recon=0.1493, kl=0.0065, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1628 (Recon: 0.1628, KL: 0.0073, Current Beta: 0.0001) | Avg Valid Loss: 0.1408 | Avg Valid recon Loss: 0.1408\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1262, recon=0.1262, kl=0.0073, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1561 (Recon: 0.1561, KL: 0.0057, Current Beta: 0.0001) | Avg Valid Loss: 0.1359 | Avg Valid recon Loss: 0.1359\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1351, recon=0.1351, kl=0.0070, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1478 (Recon: 0.1478, KL: 0.0044, Current Beta: 0.0001) | Avg Valid Loss: 0.1318 | Avg Valid recon Loss: 0.1318\n",
      "\n",
      "[VRAE Run 218/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2491, recon=0.2491, kl=11.9844, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5063 (Recon: 0.5063, KL: 6.2441, Current Beta: 0.0000) | Avg Valid Loss: 0.2725 | Avg Valid recon Loss: 0.2725\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1867, recon=0.1867, kl=24.4897, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2397 (Recon: 0.2397, KL: 20.9709, Current Beta: 0.0000) | Avg Valid Loss: 0.1627 | Avg Valid recon Loss: 0.1627\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1354, recon=0.1354, kl=30.2382, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1603 (Recon: 0.1603, KL: 28.5017, Current Beta: 0.0000) | Avg Valid Loss: 0.1217 | Avg Valid recon Loss: 0.1217\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0886, recon=0.0886, kl=31.3880, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1159 (Recon: 0.1159, KL: 30.8358, Current Beta: 0.0000) | Avg Valid Loss: 0.1044 | Avg Valid recon Loss: 0.1044\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0994, recon=0.0994, kl=35.4193, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1087 (Recon: 0.1087, KL: 34.3804, Current Beta: 0.0000) | Avg Valid Loss: 0.0918 | Avg Valid recon Loss: 0.0918\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0690, recon=0.0690, kl=34.8002, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0975 (Recon: 0.0975, KL: 34.8929, Current Beta: 0.0000) | Avg Valid Loss: 0.0846 | Avg Valid recon Loss: 0.0846\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0641, recon=0.0641, kl=35.2281, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0882 (Recon: 0.0882, KL: 35.1974, Current Beta: 0.0000) | Avg Valid Loss: 0.0798 | Avg Valid recon Loss: 0.0798\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0649, recon=0.0649, kl=33.2617, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0831 (Recon: 0.0831, KL: 34.2064, Current Beta: 0.0000) | Avg Valid Loss: 0.0757 | Avg Valid recon Loss: 0.0757\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1118, recon=0.1117, kl=24.6268, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0789 (Recon: 0.0789, KL: 28.5745, Current Beta: 0.0000) | Avg Valid Loss: 0.0720 | Avg Valid recon Loss: 0.0720\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0957, recon=0.0957, kl=13.6156, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0750 (Recon: 0.0750, KL: 17.8041, Current Beta: 0.0000) | Avg Valid Loss: 0.0688 | Avg Valid recon Loss: 0.0688\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0553, recon=0.0553, kl=6.9156, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0717 (Recon: 0.0716, KL: 9.5880, Current Beta: 0.0000) | Avg Valid Loss: 0.0662 | Avg Valid recon Loss: 0.0662\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0723, recon=0.0723, kl=2.7029, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0705 (Recon: 0.0705, KL: 3.8625, Current Beta: 0.0000) | Avg Valid Loss: 0.0655 | Avg Valid recon Loss: 0.0655\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0545, recon=0.0545, kl=0.5901, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0674 (Recon: 0.0674, KL: 0.9808, Current Beta: 0.0000) | Avg Valid Loss: 0.0621 | Avg Valid recon Loss: 0.0621\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0593, recon=0.0593, kl=0.0615, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0654 (Recon: 0.0654, KL: 0.1632, Current Beta: 0.0000) | Avg Valid Loss: 0.0616 | Avg Valid recon Loss: 0.0615\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0454, recon=0.0454, kl=0.0227, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0637 (Recon: 0.0637, KL: 0.0350, Current Beta: 0.0001) | Avg Valid Loss: 0.0596 | Avg Valid recon Loss: 0.0596\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1864, recon=0.1864, kl=0.0105, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0623 (Recon: 0.0623, KL: 0.0130, Current Beta: 0.0001) | Avg Valid Loss: 0.0578 | Avg Valid recon Loss: 0.0578\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0583, recon=0.0583, kl=0.0149, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0607 (Recon: 0.0607, KL: 0.0093, Current Beta: 0.0001) | Avg Valid Loss: 0.0571 | Avg Valid recon Loss: 0.0571\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0713, recon=0.0713, kl=0.0088, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0593 (Recon: 0.0593, KL: 0.0085, Current Beta: 0.0001) | Avg Valid Loss: 0.0564 | Avg Valid recon Loss: 0.0564\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0863, recon=0.0863, kl=0.0048, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0580 (Recon: 0.0580, KL: 0.0049, Current Beta: 0.0001) | Avg Valid Loss: 0.0551 | Avg Valid recon Loss: 0.0551\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0535, recon=0.0535, kl=0.0043, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0574 (Recon: 0.0574, KL: 0.0050, Current Beta: 0.0001) | Avg Valid Loss: 0.0533 | Avg Valid recon Loss: 0.0533\n",
      "\n",
      "[VRAE Run 219/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6332, recon=0.6332, kl=0.4518, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.7971 (Recon: 0.7971, KL: 0.3410, Current Beta: 0.0000) | Avg Valid Loss: 0.6528 | Avg Valid recon Loss: 0.6528\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.4668, recon=0.4668, kl=4.0347, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5467 (Recon: 0.5467, KL: 1.8842, Current Beta: 0.0000) | Avg Valid Loss: 0.4913 | Avg Valid recon Loss: 0.4913\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.4773, recon=0.4773, kl=22.1130, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4369 (Recon: 0.4369, KL: 15.3912, Current Beta: 0.0000) | Avg Valid Loss: 0.4085 | Avg Valid recon Loss: 0.4085\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.3217, recon=0.3217, kl=32.9399, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3778 (Recon: 0.3778, KL: 29.0846, Current Beta: 0.0000) | Avg Valid Loss: 0.3516 | Avg Valid recon Loss: 0.3516\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.3430, recon=0.3430, kl=40.5295, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3349 (Recon: 0.3349, KL: 37.8091, Current Beta: 0.0000) | Avg Valid Loss: 0.3096 | Avg Valid recon Loss: 0.3096\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.4165, recon=0.4165, kl=45.8670, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3049 (Recon: 0.3048, KL: 43.9448, Current Beta: 0.0000) | Avg Valid Loss: 0.2776 | Avg Valid recon Loss: 0.2776\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.3082, recon=0.3082, kl=49.0325, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2812 (Recon: 0.2812, KL: 48.0145, Current Beta: 0.0000) | Avg Valid Loss: 0.2522 | Avg Valid recon Loss: 0.2522\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.2295, recon=0.2295, kl=49.4460, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2619 (Recon: 0.2619, KL: 49.5959, Current Beta: 0.0000) | Avg Valid Loss: 0.2310 | Avg Valid recon Loss: 0.2310\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1949, recon=0.1949, kl=45.0216, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2440 (Recon: 0.2440, KL: 47.0834, Current Beta: 0.0000) | Avg Valid Loss: 0.2134 | Avg Valid recon Loss: 0.2134\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1805, recon=0.1805, kl=32.6895, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2298 (Recon: 0.2297, KL: 38.1516, Current Beta: 0.0000) | Avg Valid Loss: 0.1991 | Avg Valid recon Loss: 0.1991\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1539, recon=0.1539, kl=15.3749, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2179 (Recon: 0.2178, KL: 22.2138, Current Beta: 0.0000) | Avg Valid Loss: 0.1871 | Avg Valid recon Loss: 0.1870\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1717, recon=0.1717, kl=4.4586, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2049 (Recon: 0.2048, KL: 7.8324, Current Beta: 0.0000) | Avg Valid Loss: 0.1772 | Avg Valid recon Loss: 0.1772\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1834, recon=0.1834, kl=1.1503, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1860 (Recon: 0.1859, KL: 2.1201, Current Beta: 0.0000) | Avg Valid Loss: 0.1680 | Avg Valid recon Loss: 0.1680\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.4377, recon=0.4377, kl=0.3495, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1885 (Recon: 0.1885, KL: 0.6526, Current Beta: 0.0000) | Avg Valid Loss: 0.1604 | Avg Valid recon Loss: 0.1604\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1384, recon=0.1384, kl=0.1182, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1805 (Recon: 0.1805, KL: 0.2061, Current Beta: 0.0001) | Avg Valid Loss: 0.1533 | Avg Valid recon Loss: 0.1533\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.4147, recon=0.4147, kl=0.0317, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1718 (Recon: 0.1718, KL: 0.0582, Current Beta: 0.0001) | Avg Valid Loss: 0.1472 | Avg Valid recon Loss: 0.1472\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.2043, recon=0.2043, kl=0.0204, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1661 (Recon: 0.1661, KL: 0.0261, Current Beta: 0.0001) | Avg Valid Loss: 0.1411 | Avg Valid recon Loss: 0.1411\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.2166, recon=0.2166, kl=0.0143, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1586 (Recon: 0.1586, KL: 0.0155, Current Beta: 0.0001) | Avg Valid Loss: 0.1363 | Avg Valid recon Loss: 0.1363\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1108, recon=0.1108, kl=0.0107, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1517 (Recon: 0.1517, KL: 0.0127, Current Beta: 0.0001) | Avg Valid Loss: 0.1312 | Avg Valid recon Loss: 0.1312\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1073, recon=0.1073, kl=0.0104, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1469 (Recon: 0.1469, KL: 0.0103, Current Beta: 0.0001) | Avg Valid Loss: 0.1261 | Avg Valid recon Loss: 0.1261\n",
      "\n",
      "[VRAE Run 220/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3561, recon=0.3561, kl=40.0282, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4988 (Recon: 0.4988, KL: 18.2694, Current Beta: 0.0000) | Avg Valid Loss: 0.2551 | Avg Valid recon Loss: 0.2551\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1676, recon=0.1676, kl=62.8497, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2114 (Recon: 0.2114, KL: 55.6536, Current Beta: 0.0000) | Avg Valid Loss: 0.1521 | Avg Valid recon Loss: 0.1521\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1294, recon=0.1294, kl=70.9254, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1538 (Recon: 0.1538, KL: 68.2059, Current Beta: 0.0000) | Avg Valid Loss: 0.1152 | Avg Valid recon Loss: 0.1152\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0969, recon=0.0969, kl=71.7755, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1227 (Recon: 0.1227, KL: 72.1567, Current Beta: 0.0000) | Avg Valid Loss: 0.0978 | Avg Valid recon Loss: 0.0978\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0771, recon=0.0771, kl=71.3328, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1033 (Recon: 0.1033, KL: 71.6651, Current Beta: 0.0000) | Avg Valid Loss: 0.0878 | Avg Valid recon Loss: 0.0878\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0545, recon=0.0545, kl=72.3453, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0905 (Recon: 0.0905, KL: 72.2500, Current Beta: 0.0000) | Avg Valid Loss: 0.0810 | Avg Valid recon Loss: 0.0810\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0688, recon=0.0688, kl=63.3183, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0855 (Recon: 0.0855, KL: 66.8943, Current Beta: 0.0000) | Avg Valid Loss: 0.0756 | Avg Valid recon Loss: 0.0756\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0680, recon=0.0680, kl=56.2334, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0803 (Recon: 0.0803, KL: 59.9126, Current Beta: 0.0000) | Avg Valid Loss: 0.0717 | Avg Valid recon Loss: 0.0717\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0934, recon=0.0934, kl=35.7562, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0755 (Recon: 0.0755, KL: 43.1186, Current Beta: 0.0000) | Avg Valid Loss: 0.0687 | Avg Valid recon Loss: 0.0687\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0667, recon=0.0667, kl=20.3232, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0718 (Recon: 0.0718, KL: 25.5400, Current Beta: 0.0000) | Avg Valid Loss: 0.0664 | Avg Valid recon Loss: 0.0664\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0681, recon=0.0680, kl=9.5453, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0693 (Recon: 0.0693, KL: 13.6376, Current Beta: 0.0000) | Avg Valid Loss: 0.0634 | Avg Valid recon Loss: 0.0633\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.2162, recon=0.2162, kl=2.3834, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0651 (Recon: 0.0651, KL: 4.5962, Current Beta: 0.0000) | Avg Valid Loss: 0.0619 | Avg Valid recon Loss: 0.0618\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0433, recon=0.0433, kl=0.4346, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0641 (Recon: 0.0641, KL: 0.9424, Current Beta: 0.0000) | Avg Valid Loss: 0.0596 | Avg Valid recon Loss: 0.0596\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0533, recon=0.0533, kl=0.1340, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0624 (Recon: 0.0624, KL: 0.1927, Current Beta: 0.0000) | Avg Valid Loss: 0.0603 | Avg Valid recon Loss: 0.0603\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0423, recon=0.0423, kl=0.0323, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0611 (Recon: 0.0611, KL: 0.0673, Current Beta: 0.0001) | Avg Valid Loss: 0.0564 | Avg Valid recon Loss: 0.0564\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0447, recon=0.0447, kl=0.0129, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0580 (Recon: 0.0580, KL: 0.0169, Current Beta: 0.0001) | Avg Valid Loss: 0.0555 | Avg Valid recon Loss: 0.0555\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0815, recon=0.0815, kl=0.0111, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0584 (Recon: 0.0584, KL: 0.0138, Current Beta: 0.0001) | Avg Valid Loss: 0.0545 | Avg Valid recon Loss: 0.0545\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0406, recon=0.0406, kl=0.0074, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0578 (Recon: 0.0578, KL: 0.0098, Current Beta: 0.0001) | Avg Valid Loss: 0.0548 | Avg Valid recon Loss: 0.0548\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0359, recon=0.0359, kl=0.0100, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0568 (Recon: 0.0568, KL: 0.0108, Current Beta: 0.0001) | Avg Valid Loss: 0.0532 | Avg Valid recon Loss: 0.0532\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0356, recon=0.0356, kl=0.0067, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0562 (Recon: 0.0562, KL: 0.0071, Current Beta: 0.0001) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "\n",
      "[VRAE Run 221/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7680, recon=0.7680, kl=0.9000, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.8886 (Recon: 0.8886, KL: 0.7617, Current Beta: 0.0000) | Avg Valid Loss: 0.7449 | Avg Valid recon Loss: 0.7449\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.4948, recon=0.4948, kl=3.4735, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6040 (Recon: 0.6040, KL: 2.0391, Current Beta: 0.0000) | Avg Valid Loss: 0.5359 | Avg Valid recon Loss: 0.5359\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.5689, recon=0.5689, kl=27.9223, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4699 (Recon: 0.4699, KL: 16.4569, Current Beta: 0.0000) | Avg Valid Loss: 0.4370 | Avg Valid recon Loss: 0.4370\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.3358, recon=0.3358, kl=54.1471, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3995 (Recon: 0.3995, KL: 44.9354, Current Beta: 0.0000) | Avg Valid Loss: 0.3752 | Avg Valid recon Loss: 0.3752\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.5690, recon=0.5690, kl=67.6952, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3539 (Recon: 0.3539, KL: 63.0878, Current Beta: 0.0000) | Avg Valid Loss: 0.3304 | Avg Valid recon Loss: 0.3304\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2595, recon=0.2595, kl=76.2211, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3132 (Recon: 0.3132, KL: 73.2310, Current Beta: 0.0000) | Avg Valid Loss: 0.2961 | Avg Valid recon Loss: 0.2961\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.3239, recon=0.3239, kl=81.5751, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2929 (Recon: 0.2928, KL: 79.6925, Current Beta: 0.0000) | Avg Valid Loss: 0.2672 | Avg Valid recon Loss: 0.2672\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.2571, recon=0.2571, kl=82.0758, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2705 (Recon: 0.2705, KL: 82.4009, Current Beta: 0.0000) | Avg Valid Loss: 0.2439 | Avg Valid recon Loss: 0.2439\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.2550, recon=0.2549, kl=72.5697, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2517 (Recon: 0.2517, KL: 77.2830, Current Beta: 0.0000) | Avg Valid Loss: 0.2249 | Avg Valid recon Loss: 0.2249\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.2077, recon=0.2077, kl=47.5427, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2362 (Recon: 0.2362, KL: 58.4166, Current Beta: 0.0000) | Avg Valid Loss: 0.2090 | Avg Valid recon Loss: 0.2090\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1970, recon=0.1969, kl=17.3681, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2235 (Recon: 0.2234, KL: 28.6184, Current Beta: 0.0000) | Avg Valid Loss: 0.1951 | Avg Valid recon Loss: 0.1950\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1583, recon=0.1583, kl=4.3717, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2120 (Recon: 0.2119, KL: 8.3161, Current Beta: 0.0000) | Avg Valid Loss: 0.1840 | Avg Valid recon Loss: 0.1840\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.4314, recon=0.4314, kl=1.0846, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2001 (Recon: 0.2000, KL: 2.0621, Current Beta: 0.0000) | Avg Valid Loss: 0.1743 | Avg Valid recon Loss: 0.1742\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1921, recon=0.1921, kl=0.2377, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1904 (Recon: 0.1903, KL: 0.5161, Current Beta: 0.0000) | Avg Valid Loss: 0.1653 | Avg Valid recon Loss: 0.1653\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1808, recon=0.1808, kl=0.0615, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1811 (Recon: 0.1811, KL: 0.1249, Current Beta: 0.0001) | Avg Valid Loss: 0.1577 | Avg Valid recon Loss: 0.1577\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1435, recon=0.1435, kl=0.0200, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1734 (Recon: 0.1734, KL: 0.0284, Current Beta: 0.0001) | Avg Valid Loss: 0.1512 | Avg Valid recon Loss: 0.1512\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1156, recon=0.1156, kl=0.0150, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1661 (Recon: 0.1661, KL: 0.0158, Current Beta: 0.0001) | Avg Valid Loss: 0.1450 | Avg Valid recon Loss: 0.1450\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1136, recon=0.1136, kl=0.0082, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1601 (Recon: 0.1600, KL: 0.0105, Current Beta: 0.0001) | Avg Valid Loss: 0.1395 | Avg Valid recon Loss: 0.1395\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1284, recon=0.1284, kl=0.0045, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1541 (Recon: 0.1541, KL: 0.0070, Current Beta: 0.0001) | Avg Valid Loss: 0.1350 | Avg Valid recon Loss: 0.1350\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1355, recon=0.1355, kl=0.0044, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1488 (Recon: 0.1488, KL: 0.0047, Current Beta: 0.0001) | Avg Valid Loss: 0.1307 | Avg Valid recon Loss: 0.1307\n",
      "\n",
      "[VRAE Run 222/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2580, recon=0.2580, kl=68.1296, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4804 (Recon: 0.4804, KL: 26.8131, Current Beta: 0.0000) | Avg Valid Loss: 0.2547 | Avg Valid recon Loss: 0.2547\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2038, recon=0.2038, kl=104.1877, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2262 (Recon: 0.2262, KL: 94.3216, Current Beta: 0.0000) | Avg Valid Loss: 0.1487 | Avg Valid recon Loss: 0.1487\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1296, recon=0.1296, kl=115.2301, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1539 (Recon: 0.1539, KL: 111.8249, Current Beta: 0.0000) | Avg Valid Loss: 0.1130 | Avg Valid recon Loss: 0.1130\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1008, recon=0.1008, kl=119.3048, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1209 (Recon: 0.1209, KL: 116.0685, Current Beta: 0.0000) | Avg Valid Loss: 0.0973 | Avg Valid recon Loss: 0.0973\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0812, recon=0.0812, kl=126.0954, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1030 (Recon: 0.1030, KL: 124.1027, Current Beta: 0.0000) | Avg Valid Loss: 0.0861 | Avg Valid recon Loss: 0.0861\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0722, recon=0.0722, kl=125.6379, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0877 (Recon: 0.0877, KL: 124.9407, Current Beta: 0.0000) | Avg Valid Loss: 0.0770 | Avg Valid recon Loss: 0.0770\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0897, recon=0.0897, kl=115.3854, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0821 (Recon: 0.0821, KL: 122.9070, Current Beta: 0.0000) | Avg Valid Loss: 0.0726 | Avg Valid recon Loss: 0.0726\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0566, recon=0.0566, kl=77.4723, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0771 (Recon: 0.0771, KL: 94.1036, Current Beta: 0.0000) | Avg Valid Loss: 0.0688 | Avg Valid recon Loss: 0.0687\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0650, recon=0.0650, kl=54.5019, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0733 (Recon: 0.0733, KL: 63.2609, Current Beta: 0.0000) | Avg Valid Loss: 0.0665 | Avg Valid recon Loss: 0.0665\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0871, recon=0.0871, kl=31.1903, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0638 (Recon: 0.0638, KL: 39.6967, Current Beta: 0.0000) | Avg Valid Loss: 0.0633 | Avg Valid recon Loss: 0.0633\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.2144, recon=0.2143, kl=10.6143, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0657 (Recon: 0.0656, KL: 17.6285, Current Beta: 0.0000) | Avg Valid Loss: 0.0626 | Avg Valid recon Loss: 0.0626\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0548, recon=0.0548, kl=3.3147, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0647 (Recon: 0.0647, KL: 6.4015, Current Beta: 0.0000) | Avg Valid Loss: 0.0604 | Avg Valid recon Loss: 0.0604\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0590, recon=0.0589, kl=3.0628, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0643 (Recon: 0.0643, KL: 2.6493, Current Beta: 0.0000) | Avg Valid Loss: 0.0591 | Avg Valid recon Loss: 0.0590\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0474, recon=0.0474, kl=0.3116, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0621 (Recon: 0.0621, KL: 0.9551, Current Beta: 0.0000) | Avg Valid Loss: 0.0571 | Avg Valid recon Loss: 0.0571\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0437, recon=0.0437, kl=0.0572, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0606 (Recon: 0.0606, KL: 0.1194, Current Beta: 0.0001) | Avg Valid Loss: 0.0567 | Avg Valid recon Loss: 0.0567\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0471, recon=0.0471, kl=0.0261, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0588 (Recon: 0.0588, KL: 0.0371, Current Beta: 0.0001) | Avg Valid Loss: 0.0544 | Avg Valid recon Loss: 0.0544\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0629, recon=0.0629, kl=0.0141, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0578 (Recon: 0.0578, KL: 0.0163, Current Beta: 0.0001) | Avg Valid Loss: 0.0530 | Avg Valid recon Loss: 0.0530\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0451, recon=0.0451, kl=0.0101, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0568 (Recon: 0.0568, KL: 0.0124, Current Beta: 0.0001) | Avg Valid Loss: 0.0539 | Avg Valid recon Loss: 0.0539\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0467, recon=0.0467, kl=0.0084, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0546 (Recon: 0.0546, KL: 0.0120, Current Beta: 0.0001) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=0.0095, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0551 (Recon: 0.0551, KL: 0.0139, Current Beta: 0.0001) | Avg Valid Loss: 0.0532 | Avg Valid recon Loss: 0.0532\n",
      "\n",
      "[VRAE Run 223/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4089, recon=0.4089, kl=0.2605, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6134 (Recon: 0.6134, KL: 0.1856, Current Beta: 0.0000) | Avg Valid Loss: 0.4404 | Avg Valid recon Loss: 0.4404\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3119, recon=0.3119, kl=6.0617, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3614 (Recon: 0.3614, KL: 2.6219, Current Beta: 0.0000) | Avg Valid Loss: 0.3110 | Avg Valid recon Loss: 0.3110\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2232, recon=0.2232, kl=18.6986, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2875 (Recon: 0.2875, KL: 13.9067, Current Beta: 0.0000) | Avg Valid Loss: 0.2412 | Avg Valid recon Loss: 0.2412\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1898, recon=0.1898, kl=23.1022, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2421 (Recon: 0.2421, KL: 21.8625, Current Beta: 0.0000) | Avg Valid Loss: 0.1978 | Avg Valid recon Loss: 0.1978\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1671, recon=0.1671, kl=26.9365, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2116 (Recon: 0.2116, KL: 25.4640, Current Beta: 0.0000) | Avg Valid Loss: 0.1702 | Avg Valid recon Loss: 0.1702\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1914, recon=0.1914, kl=30.9061, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1909 (Recon: 0.1909, KL: 29.3065, Current Beta: 0.0000) | Avg Valid Loss: 0.1521 | Avg Valid recon Loss: 0.1521\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.4780, recon=0.4780, kl=32.9559, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1760 (Recon: 0.1760, KL: 32.3537, Current Beta: 0.0000) | Avg Valid Loss: 0.1398 | Avg Valid recon Loss: 0.1398\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1283, recon=0.1282, kl=32.7754, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1508 (Recon: 0.1508, KL: 32.9776, Current Beta: 0.0000) | Avg Valid Loss: 0.1306 | Avg Valid recon Loss: 0.1306\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1154, recon=0.1154, kl=28.4061, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1532 (Recon: 0.1532, KL: 30.4891, Current Beta: 0.0000) | Avg Valid Loss: 0.1212 | Avg Valid recon Loss: 0.1212\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1264, recon=0.1263, kl=16.8245, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1452 (Recon: 0.1452, KL: 21.7442, Current Beta: 0.0000) | Avg Valid Loss: 0.1153 | Avg Valid recon Loss: 0.1153\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1860, recon=0.1860, kl=5.4296, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1374 (Recon: 0.1374, KL: 9.0517, Current Beta: 0.0000) | Avg Valid Loss: 0.1097 | Avg Valid recon Loss: 0.1097\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1102, recon=0.1102, kl=1.8911, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1308 (Recon: 0.1308, KL: 3.0928, Current Beta: 0.0000) | Avg Valid Loss: 0.1051 | Avg Valid recon Loss: 0.1051\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1053, recon=0.1053, kl=0.4715, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1244 (Recon: 0.1244, KL: 0.8603, Current Beta: 0.0000) | Avg Valid Loss: 0.1001 | Avg Valid recon Loss: 0.1001\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1012, recon=0.1012, kl=0.0658, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1180 (Recon: 0.1180, KL: 0.1726, Current Beta: 0.0000) | Avg Valid Loss: 0.0958 | Avg Valid recon Loss: 0.0958\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0963, recon=0.0963, kl=0.0228, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1125 (Recon: 0.1125, KL: 0.0381, Current Beta: 0.0001) | Avg Valid Loss: 0.0933 | Avg Valid recon Loss: 0.0933\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0824, recon=0.0824, kl=0.0066, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1082 (Recon: 0.1082, KL: 0.0113, Current Beta: 0.0001) | Avg Valid Loss: 0.0898 | Avg Valid recon Loss: 0.0898\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0883, recon=0.0883, kl=0.0044, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1042 (Recon: 0.1042, KL: 0.0073, Current Beta: 0.0001) | Avg Valid Loss: 0.0868 | Avg Valid recon Loss: 0.0868\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0974, recon=0.0974, kl=0.0070, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1007 (Recon: 0.1007, KL: 0.0072, Current Beta: 0.0001) | Avg Valid Loss: 0.0852 | Avg Valid recon Loss: 0.0852\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0850, recon=0.0850, kl=0.0060, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0968 (Recon: 0.0968, KL: 0.0064, Current Beta: 0.0001) | Avg Valid Loss: 0.0831 | Avg Valid recon Loss: 0.0831\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1325, recon=0.1325, kl=0.0050, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0933 (Recon: 0.0933, KL: 0.0055, Current Beta: 0.0001) | Avg Valid Loss: 0.0809 | Avg Valid recon Loss: 0.0809\n",
      "\n",
      "[VRAE Run 224/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1704, recon=0.1704, kl=27.5281, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3398 (Recon: 0.3398, KL: 16.5219, Current Beta: 0.0000) | Avg Valid Loss: 0.1468 | Avg Valid recon Loss: 0.1468\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0995, recon=0.0995, kl=31.9304, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1520 (Recon: 0.1520, KL: 32.6994, Current Beta: 0.0000) | Avg Valid Loss: 0.1010 | Avg Valid recon Loss: 0.1010\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0816, recon=0.0816, kl=33.8861, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1057 (Recon: 0.1057, KL: 32.7340, Current Beta: 0.0000) | Avg Valid Loss: 0.0813 | Avg Valid recon Loss: 0.0813\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.2384, recon=0.2384, kl=36.8895, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0879 (Recon: 0.0879, KL: 35.6049, Current Beta: 0.0000) | Avg Valid Loss: 0.0713 | Avg Valid recon Loss: 0.0713\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0710, recon=0.0710, kl=40.7232, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0775 (Recon: 0.0775, KL: 39.0883, Current Beta: 0.0000) | Avg Valid Loss: 0.0684 | Avg Valid recon Loss: 0.0684\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0563, recon=0.0563, kl=38.2635, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0707 (Recon: 0.0707, KL: 39.1712, Current Beta: 0.0000) | Avg Valid Loss: 0.0620 | Avg Valid recon Loss: 0.0620\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0580, recon=0.0580, kl=37.1538, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0659 (Recon: 0.0659, KL: 38.2641, Current Beta: 0.0000) | Avg Valid Loss: 0.0599 | Avg Valid recon Loss: 0.0599\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0567, recon=0.0567, kl=31.1487, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0622 (Recon: 0.0622, KL: 34.1725, Current Beta: 0.0000) | Avg Valid Loss: 0.0563 | Avg Valid recon Loss: 0.0563\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0467, recon=0.0467, kl=24.5462, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0584 (Recon: 0.0584, KL: 27.0217, Current Beta: 0.0000) | Avg Valid Loss: 0.0545 | Avg Valid recon Loss: 0.0544\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0669, recon=0.0668, kl=14.4586, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0573 (Recon: 0.0573, KL: 19.1613, Current Beta: 0.0000) | Avg Valid Loss: 0.0529 | Avg Valid recon Loss: 0.0529\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0429, recon=0.0428, kl=7.3517, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0547, KL: 9.0866, Current Beta: 0.0000) | Avg Valid Loss: 0.0544 | Avg Valid recon Loss: 0.0544\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0853, recon=0.0852, kl=3.2006, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0538 (Recon: 0.0537, KL: 4.0474, Current Beta: 0.0000) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1445, recon=0.1445, kl=0.9213, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0498 (Recon: 0.0497, KL: 1.1238, Current Beta: 0.0000) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0464\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0391, recon=0.0391, kl=0.1705, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0452 (Recon: 0.0452, KL: 0.2316, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0348, recon=0.0348, kl=0.0354, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0487 (Recon: 0.0487, KL: 0.0445, Current Beta: 0.0001) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0450\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0408, recon=0.0408, kl=0.0240, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0481 (Recon: 0.0481, KL: 0.0158, Current Beta: 0.0001) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0506, recon=0.0506, kl=0.0170, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0459, KL: 0.0123, Current Beta: 0.0001) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0489, recon=0.0489, kl=0.0157, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0459, KL: 0.0086, Current Beta: 0.0001) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0514, recon=0.0514, kl=0.0097, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0456 (Recon: 0.0456, KL: 0.0082, Current Beta: 0.0001) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0366, recon=0.0366, kl=0.0118, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0447 (Recon: 0.0447, KL: 0.0083, Current Beta: 0.0001) | Avg Valid Loss: 0.0406 | Avg Valid recon Loss: 0.0406\n",
      "\n",
      "[VRAE Run 225/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5405, recon=0.5405, kl=0.2863, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6976 (Recon: 0.6976, KL: 0.2077, Current Beta: 0.0000) | Avg Valid Loss: 0.4842 | Avg Valid recon Loss: 0.4842\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3319, recon=0.3319, kl=11.4831, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3758 (Recon: 0.3758, KL: 4.0054, Current Beta: 0.0000) | Avg Valid Loss: 0.3274 | Avg Valid recon Loss: 0.3274\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.5221, recon=0.5221, kl=36.2575, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2946 (Recon: 0.2946, KL: 26.9925, Current Beta: 0.0000) | Avg Valid Loss: 0.2533 | Avg Valid recon Loss: 0.2533\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.2128, recon=0.2128, kl=52.6339, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2476 (Recon: 0.2476, KL: 47.0484, Current Beta: 0.0000) | Avg Valid Loss: 0.2090 | Avg Valid recon Loss: 0.2090\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2063, recon=0.2063, kl=62.4331, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2179 (Recon: 0.2179, KL: 58.8862, Current Beta: 0.0000) | Avg Valid Loss: 0.1802 | Avg Valid recon Loss: 0.1802\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1659, recon=0.1659, kl=67.5701, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1955 (Recon: 0.1955, KL: 65.9008, Current Beta: 0.0000) | Avg Valid Loss: 0.1606 | Avg Valid recon Loss: 0.1606\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1755, recon=0.1755, kl=71.4427, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1792 (Recon: 0.1792, KL: 70.3675, Current Beta: 0.0000) | Avg Valid Loss: 0.1473 | Avg Valid recon Loss: 0.1473\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1495, recon=0.1495, kl=70.1206, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1668 (Recon: 0.1668, KL: 71.2669, Current Beta: 0.0000) | Avg Valid Loss: 0.1362 | Avg Valid recon Loss: 0.1362\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1327, recon=0.1327, kl=54.3714, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1562 (Recon: 0.1561, KL: 62.0178, Current Beta: 0.0000) | Avg Valid Loss: 0.1271 | Avg Valid recon Loss: 0.1271\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1196, recon=0.1196, kl=24.2601, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1484 (Recon: 0.1484, KL: 36.6136, Current Beta: 0.0000) | Avg Valid Loss: 0.1206 | Avg Valid recon Loss: 0.1206\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1927, recon=0.1927, kl=7.1299, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1407 (Recon: 0.1406, KL: 12.2719, Current Beta: 0.0000) | Avg Valid Loss: 0.1142 | Avg Valid recon Loss: 0.1142\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0989, recon=0.0989, kl=2.1855, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1331 (Recon: 0.1331, KL: 3.8502, Current Beta: 0.0000) | Avg Valid Loss: 0.1093 | Avg Valid recon Loss: 0.1093\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1074, recon=0.1074, kl=0.4906, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1264 (Recon: 0.1264, KL: 0.9891, Current Beta: 0.0000) | Avg Valid Loss: 0.1044 | Avg Valid recon Loss: 0.1044\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0904, recon=0.0904, kl=0.1554, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1225 (Recon: 0.1224, KL: 0.2244, Current Beta: 0.0000) | Avg Valid Loss: 0.1006 | Avg Valid recon Loss: 0.1006\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1069, recon=0.1069, kl=0.0643, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1167 (Recon: 0.1167, KL: 0.0637, Current Beta: 0.0001) | Avg Valid Loss: 0.0966 | Avg Valid recon Loss: 0.0966\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0960, recon=0.0960, kl=0.0167, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1122 (Recon: 0.1122, KL: 0.0210, Current Beta: 0.0001) | Avg Valid Loss: 0.0932 | Avg Valid recon Loss: 0.0932\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0932, recon=0.0932, kl=0.0130, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1076 (Recon: 0.1076, KL: 0.0137, Current Beta: 0.0001) | Avg Valid Loss: 0.0903 | Avg Valid recon Loss: 0.0903\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1291, recon=0.1291, kl=0.0104, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1036 (Recon: 0.1036, KL: 0.0102, Current Beta: 0.0001) | Avg Valid Loss: 0.0881 | Avg Valid recon Loss: 0.0881\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0841, recon=0.0841, kl=0.0080, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1006 (Recon: 0.1006, KL: 0.0084, Current Beta: 0.0001) | Avg Valid Loss: 0.0850 | Avg Valid recon Loss: 0.0850\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0762, recon=0.0762, kl=0.0062, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0968 (Recon: 0.0968, KL: 0.0072, Current Beta: 0.0001) | Avg Valid Loss: 0.0834 | Avg Valid recon Loss: 0.0834\n",
      "\n",
      "[VRAE Run 226/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2954, recon=0.2954, kl=47.0945, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3647 (Recon: 0.3647, KL: 24.9659, Current Beta: 0.0000) | Avg Valid Loss: 0.1527 | Avg Valid recon Loss: 0.1527\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1498, recon=0.1498, kl=66.7404, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1592 (Recon: 0.1592, KL: 61.7781, Current Beta: 0.0000) | Avg Valid Loss: 0.1066 | Avg Valid recon Loss: 0.1066\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0857, recon=0.0857, kl=71.8385, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1091 (Recon: 0.1091, KL: 70.7028, Current Beta: 0.0000) | Avg Valid Loss: 0.0816 | Avg Valid recon Loss: 0.0816\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0640, recon=0.0640, kl=69.6984, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0914 (Recon: 0.0914, KL: 70.0296, Current Beta: 0.0000) | Avg Valid Loss: 0.0718 | Avg Valid recon Loss: 0.0718\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1324, recon=0.1324, kl=69.2897, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0802 (Recon: 0.0802, KL: 68.7352, Current Beta: 0.0000) | Avg Valid Loss: 0.0663 | Avg Valid recon Loss: 0.0663\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0571, recon=0.0571, kl=73.2959, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0725 (Recon: 0.0725, KL: 69.9579, Current Beta: 0.0000) | Avg Valid Loss: 0.0625 | Avg Valid recon Loss: 0.0625\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1131, recon=0.1131, kl=65.4577, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0685 (Recon: 0.0685, KL: 69.4090, Current Beta: 0.0000) | Avg Valid Loss: 0.0627 | Avg Valid recon Loss: 0.0627\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0651, recon=0.0651, kl=46.9287, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0642 (Recon: 0.0642, KL: 55.8212, Current Beta: 0.0000) | Avg Valid Loss: 0.0564 | Avg Valid recon Loss: 0.0564\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0686, recon=0.0686, kl=33.1431, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0610 (Recon: 0.0609, KL: 39.6597, Current Beta: 0.0000) | Avg Valid Loss: 0.0543 | Avg Valid recon Loss: 0.0542\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0456, recon=0.0456, kl=21.2674, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0568 (Recon: 0.0568, KL: 25.2070, Current Beta: 0.0000) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0537\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0472, recon=0.0471, kl=12.4897, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0559 (Recon: 0.0558, KL: 13.6975, Current Beta: 0.0000) | Avg Valid Loss: 0.0517 | Avg Valid recon Loss: 0.0516\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0548, recon=0.0547, kl=4.3147, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0533, KL: 5.2123, Current Beta: 0.0000) | Avg Valid Loss: 0.0491 | Avg Valid recon Loss: 0.0490\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0373, recon=0.0373, kl=1.0635, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0513 (Recon: 0.0513, KL: 1.2821, Current Beta: 0.0000) | Avg Valid Loss: 0.0476 | Avg Valid recon Loss: 0.0476\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0407, recon=0.0407, kl=0.2666, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0504 (Recon: 0.0504, KL: 0.3055, Current Beta: 0.0000) | Avg Valid Loss: 0.0459 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0491, recon=0.0491, kl=0.0561, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0486 (Recon: 0.0486, KL: 0.0801, Current Beta: 0.0001) | Avg Valid Loss: 0.0445 | Avg Valid recon Loss: 0.0445\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0403, recon=0.0403, kl=0.0196, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0474 (Recon: 0.0474, KL: 0.0285, Current Beta: 0.0001) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0450\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1222, recon=0.1222, kl=0.0090, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0462, KL: 0.0140, Current Beta: 0.0001) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0507, recon=0.0507, kl=0.0114, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0455, KL: 0.0182, Current Beta: 0.0001) | Avg Valid Loss: 0.0418 | Avg Valid recon Loss: 0.0418\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0374, recon=0.0374, kl=0.0200, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0440, KL: 0.0181, Current Beta: 0.0001) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0343, recon=0.0343, kl=0.0094, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0441 (Recon: 0.0441, KL: 0.0092, Current Beta: 0.0001) | Avg Valid Loss: 0.0418 | Avg Valid recon Loss: 0.0418\n",
      "\n",
      "[VRAE Run 227/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5049, recon=0.5049, kl=1.0486, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.7420 (Recon: 0.7420, KL: 0.6556, Current Beta: 0.0000) | Avg Valid Loss: 0.5000 | Avg Valid recon Loss: 0.5000\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.6174, recon=0.6174, kl=46.1994, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4028 (Recon: 0.4028, KL: 21.5077, Current Beta: 0.0000) | Avg Valid Loss: 0.3439 | Avg Valid recon Loss: 0.3439\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.6662, recon=0.6662, kl=86.1388, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3042 (Recon: 0.3042, KL: 73.4559, Current Beta: 0.0000) | Avg Valid Loss: 0.2607 | Avg Valid recon Loss: 0.2607\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.2264, recon=0.2264, kl=105.3314, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2549 (Recon: 0.2549, KL: 99.0809, Current Beta: 0.0000) | Avg Valid Loss: 0.2153 | Avg Valid recon Loss: 0.2153\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2110, recon=0.2110, kl=117.7853, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2231 (Recon: 0.2231, KL: 113.3463, Current Beta: 0.0000) | Avg Valid Loss: 0.1848 | Avg Valid recon Loss: 0.1848\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2846, recon=0.2846, kl=126.2250, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2012 (Recon: 0.2012, KL: 123.2696, Current Beta: 0.0000) | Avg Valid Loss: 0.1638 | Avg Valid recon Loss: 0.1638\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1660, recon=0.1660, kl=126.7597, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1727 (Recon: 0.1727, KL: 126.9671, Current Beta: 0.0000) | Avg Valid Loss: 0.1489 | Avg Valid recon Loss: 0.1489\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1960, recon=0.1960, kl=116.3655, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1709 (Recon: 0.1709, KL: 121.6233, Current Beta: 0.0000) | Avg Valid Loss: 0.1377 | Avg Valid recon Loss: 0.1377\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1336, recon=0.1336, kl=83.2265, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1607 (Recon: 0.1607, KL: 97.9259, Current Beta: 0.0000) | Avg Valid Loss: 0.1282 | Avg Valid recon Loss: 0.1282\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1262, recon=0.1262, kl=31.4995, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1501 (Recon: 0.1500, KL: 51.0175, Current Beta: 0.0000) | Avg Valid Loss: 0.1206 | Avg Valid recon Loss: 0.1205\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1189, recon=0.1189, kl=9.6836, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1417 (Recon: 0.1416, KL: 15.6562, Current Beta: 0.0000) | Avg Valid Loss: 0.1143 | Avg Valid recon Loss: 0.1142\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1117, recon=0.1117, kl=2.4787, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1348 (Recon: 0.1347, KL: 4.8658, Current Beta: 0.0000) | Avg Valid Loss: 0.1090 | Avg Valid recon Loss: 0.1090\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1034, recon=0.1034, kl=0.5582, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1279 (Recon: 0.1278, KL: 1.1665, Current Beta: 0.0000) | Avg Valid Loss: 0.1044 | Avg Valid recon Loss: 0.1044\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0936, recon=0.0936, kl=0.1665, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1219 (Recon: 0.1219, KL: 0.3180, Current Beta: 0.0000) | Avg Valid Loss: 0.1000 | Avg Valid recon Loss: 0.1000\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1014, recon=0.1014, kl=0.0706, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1155 (Recon: 0.1155, KL: 0.1076, Current Beta: 0.0001) | Avg Valid Loss: 0.0965 | Avg Valid recon Loss: 0.0965\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0977, recon=0.0977, kl=0.0214, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1110 (Recon: 0.1109, KL: 0.0300, Current Beta: 0.0001) | Avg Valid Loss: 0.0932 | Avg Valid recon Loss: 0.0932\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0907, recon=0.0907, kl=0.0166, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1043 (Recon: 0.1043, KL: 0.0183, Current Beta: 0.0001) | Avg Valid Loss: 0.0901 | Avg Valid recon Loss: 0.0901\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0829, recon=0.0829, kl=0.0143, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1028 (Recon: 0.1028, KL: 0.0144, Current Beta: 0.0001) | Avg Valid Loss: 0.0866 | Avg Valid recon Loss: 0.0866\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0808, recon=0.0808, kl=0.0098, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0994 (Recon: 0.0994, KL: 0.0113, Current Beta: 0.0001) | Avg Valid Loss: 0.0851 | Avg Valid recon Loss: 0.0851\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0743, recon=0.0743, kl=0.0090, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0954 (Recon: 0.0953, KL: 0.0110, Current Beta: 0.0001) | Avg Valid Loss: 0.0821 | Avg Valid recon Loss: 0.0821\n",
      "\n",
      "[VRAE Run 228/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2204, recon=0.2204, kl=73.8649, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3536 (Recon: 0.3536, KL: 45.8584, Current Beta: 0.0000) | Avg Valid Loss: 0.1498 | Avg Valid recon Loss: 0.1498\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1158, recon=0.1158, kl=128.6533, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1537 (Recon: 0.1537, KL: 109.2614, Current Beta: 0.0000) | Avg Valid Loss: 0.1074 | Avg Valid recon Loss: 0.1074\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0702, recon=0.0702, kl=142.4507, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1100 (Recon: 0.1100, KL: 135.0179, Current Beta: 0.0000) | Avg Valid Loss: 0.0824 | Avg Valid recon Loss: 0.0824\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0702, recon=0.0702, kl=121.5190, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0903 (Recon: 0.0903, KL: 131.7119, Current Beta: 0.0000) | Avg Valid Loss: 0.0726 | Avg Valid recon Loss: 0.0726\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0614, recon=0.0614, kl=123.5260, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0792 (Recon: 0.0792, KL: 123.2434, Current Beta: 0.0000) | Avg Valid Loss: 0.0670 | Avg Valid recon Loss: 0.0670\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0490, recon=0.0490, kl=123.2306, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0720 (Recon: 0.0720, KL: 123.9371, Current Beta: 0.0000) | Avg Valid Loss: 0.0635 | Avg Valid recon Loss: 0.0635\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1025, recon=0.1025, kl=111.6592, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0669 (Recon: 0.0669, KL: 116.8584, Current Beta: 0.0000) | Avg Valid Loss: 0.0602 | Avg Valid recon Loss: 0.0602\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0629, recon=0.0628, kl=88.0678, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0620 (Recon: 0.0620, KL: 97.6255, Current Beta: 0.0000) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0559\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0837, recon=0.0837, kl=66.5139, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0592 (Recon: 0.0592, KL: 75.4761, Current Beta: 0.0000) | Avg Valid Loss: 0.0544 | Avg Valid recon Loss: 0.0544\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0503, recon=0.0502, kl=39.4298, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0575 (Recon: 0.0575, KL: 46.3843, Current Beta: 0.0000) | Avg Valid Loss: 0.0529 | Avg Valid recon Loss: 0.0528\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0716, recon=0.0715, kl=20.3025, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0573 (Recon: 0.0572, KL: 24.5027, Current Beta: 0.0000) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0463, recon=0.0463, kl=5.9233, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0540, KL: 8.3422, Current Beta: 0.0000) | Avg Valid Loss: 0.0482 | Avg Valid recon Loss: 0.0481\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0421, recon=0.0421, kl=2.0678, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0518, KL: 2.2478, Current Beta: 0.0000) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0474\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0364, recon=0.0364, kl=0.4332, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0506 (Recon: 0.0506, KL: 0.6906, Current Beta: 0.0000) | Avg Valid Loss: 0.0463 | Avg Valid recon Loss: 0.0463\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0366, recon=0.0365, kl=0.0917, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0497, KL: 0.1567, Current Beta: 0.0001) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0491, recon=0.0491, kl=0.0377, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0488 (Recon: 0.0488, KL: 0.0605, Current Beta: 0.0001) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0662, recon=0.0662, kl=0.0369, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0472, KL: 0.0236, Current Beta: 0.0001) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0371, recon=0.0371, kl=0.0197, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0467 (Recon: 0.0467, KL: 0.0250, Current Beta: 0.0001) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1135, recon=0.1135, kl=0.0155, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0450 (Recon: 0.0450, KL: 0.0152, Current Beta: 0.0001) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0350, recon=0.0350, kl=0.0182, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0452 (Recon: 0.0452, KL: 0.0174, Current Beta: 0.0001) | Avg Valid Loss: 0.0429 | Avg Valid recon Loss: 0.0429\n",
      "\n",
      "[VRAE Run 229/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2813, recon=0.2813, kl=0.8596, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5610 (Recon: 0.5610, KL: 0.3465, Current Beta: 0.0000) | Avg Valid Loss: 0.3401 | Avg Valid recon Loss: 0.3401\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3044, recon=0.3044, kl=12.9915, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2661 (Recon: 0.2661, KL: 8.1877, Current Beta: 0.0000) | Avg Valid Loss: 0.1961 | Avg Valid recon Loss: 0.1961\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.4960, recon=0.4960, kl=19.2767, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2017 (Recon: 0.2017, KL: 17.0768, Current Beta: 0.0000) | Avg Valid Loss: 0.1530 | Avg Valid recon Loss: 0.1530\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1570, recon=0.1570, kl=27.0275, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1681 (Recon: 0.1681, KL: 23.9338, Current Beta: 0.0000) | Avg Valid Loss: 0.1308 | Avg Valid recon Loss: 0.1308\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1310, recon=0.1310, kl=34.1586, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1555 (Recon: 0.1555, KL: 30.9023, Current Beta: 0.0000) | Avg Valid Loss: 0.1171 | Avg Valid recon Loss: 0.1171\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.3387, recon=0.3387, kl=36.6415, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1423 (Recon: 0.1423, KL: 35.5337, Current Beta: 0.0000) | Avg Valid Loss: 0.1077 | Avg Valid recon Loss: 0.1077\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1386, recon=0.1386, kl=38.9871, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1286 (Recon: 0.1286, KL: 38.0828, Current Beta: 0.0000) | Avg Valid Loss: 0.0991 | Avg Valid recon Loss: 0.0991\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0995, recon=0.0995, kl=37.8707, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1235 (Recon: 0.1235, KL: 38.6534, Current Beta: 0.0000) | Avg Valid Loss: 0.0937 | Avg Valid recon Loss: 0.0937\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0924, recon=0.0924, kl=19.2550, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1157 (Recon: 0.1157, KL: 25.5855, Current Beta: 0.0000) | Avg Valid Loss: 0.0889 | Avg Valid recon Loss: 0.0889\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0790, recon=0.0790, kl=8.1780, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1082 (Recon: 0.1082, KL: 9.8956, Current Beta: 0.0000) | Avg Valid Loss: 0.0845 | Avg Valid recon Loss: 0.0845\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0793, recon=0.0793, kl=2.6226, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1023 (Recon: 0.1022, KL: 4.1425, Current Beta: 0.0000) | Avg Valid Loss: 0.0810 | Avg Valid recon Loss: 0.0810\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0757, recon=0.0757, kl=1.5673, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0888 (Recon: 0.0888, KL: 1.5372, Current Beta: 0.0000) | Avg Valid Loss: 0.0769 | Avg Valid recon Loss: 0.0768\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1040, recon=0.1040, kl=0.2954, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0926 (Recon: 0.0926, KL: 0.4320, Current Beta: 0.0000) | Avg Valid Loss: 0.0740 | Avg Valid recon Loss: 0.0740\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0636, recon=0.0636, kl=0.0768, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0882 (Recon: 0.0882, KL: 0.1821, Current Beta: 0.0000) | Avg Valid Loss: 0.0724 | Avg Valid recon Loss: 0.0724\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0703, recon=0.0703, kl=0.0232, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0841 (Recon: 0.0841, KL: 0.0398, Current Beta: 0.0001) | Avg Valid Loss: 0.0699 | Avg Valid recon Loss: 0.0698\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0716, recon=0.0716, kl=0.0119, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0796 (Recon: 0.0796, KL: 0.0164, Current Beta: 0.0001) | Avg Valid Loss: 0.0683 | Avg Valid recon Loss: 0.0683\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0652, recon=0.0652, kl=0.0100, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0778 (Recon: 0.0778, KL: 0.0105, Current Beta: 0.0001) | Avg Valid Loss: 0.0661 | Avg Valid recon Loss: 0.0661\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0911, recon=0.0911, kl=0.0074, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0750 (Recon: 0.0750, KL: 0.0082, Current Beta: 0.0001) | Avg Valid Loss: 0.0650 | Avg Valid recon Loss: 0.0650\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0514, recon=0.0514, kl=0.0052, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0712 (Recon: 0.0712, KL: 0.0061, Current Beta: 0.0001) | Avg Valid Loss: 0.0635 | Avg Valid recon Loss: 0.0635\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0589, recon=0.0589, kl=0.0039, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0703 (Recon: 0.0703, KL: 0.0049, Current Beta: 0.0001) | Avg Valid Loss: 0.0630 | Avg Valid recon Loss: 0.0630\n",
      "\n",
      "[VRAE Run 230/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1371, recon=0.1371, kl=31.3362, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2716 (Recon: 0.2716, KL: 19.5853, Current Beta: 0.0000) | Avg Valid Loss: 0.1140 | Avg Valid recon Loss: 0.1140\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0831, recon=0.0831, kl=30.7009, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1200 (Recon: 0.1200, KL: 30.4864, Current Beta: 0.0000) | Avg Valid Loss: 0.0842 | Avg Valid recon Loss: 0.0842\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0551, recon=0.0551, kl=34.2735, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0874 (Recon: 0.0874, KL: 34.0409, Current Beta: 0.0000) | Avg Valid Loss: 0.0684 | Avg Valid recon Loss: 0.0684\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0491, recon=0.0491, kl=39.8046, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0727 (Recon: 0.0727, KL: 37.7894, Current Beta: 0.0000) | Avg Valid Loss: 0.0594 | Avg Valid recon Loss: 0.0594\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0641, recon=0.0641, kl=39.1541, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0668 (Recon: 0.0668, KL: 39.9464, Current Beta: 0.0000) | Avg Valid Loss: 0.0555 | Avg Valid recon Loss: 0.0555\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0455, recon=0.0455, kl=42.6736, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0586 (Recon: 0.0586, KL: 52.2119, Current Beta: 0.0000) | Avg Valid Loss: 0.0518 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0476, recon=0.0476, kl=39.4916, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0560 (Recon: 0.0560, KL: 39.5061, Current Beta: 0.0000) | Avg Valid Loss: 0.0494 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=41.0206, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0524, KL: 39.8010, Current Beta: 0.0000) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0626, recon=0.0625, kl=37.2850, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0490 (Recon: 0.0490, KL: 39.3755, Current Beta: 0.0000) | Avg Valid Loss: 0.0432 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0385, recon=0.0385, kl=27.2652, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 31.6707, Current Beta: 0.0000) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0432, recon=0.0432, kl=15.5227, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0454, KL: 19.6930, Current Beta: 0.0000) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0404\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0374, recon=0.0373, kl=10.0431, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0431 (Recon: 0.0431, KL: 11.5523, Current Beta: 0.0000) | Avg Valid Loss: 0.0400 | Avg Valid recon Loss: 0.0397\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1172, recon=0.1171, kl=4.8424, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0416 (Recon: 0.0415, KL: 5.7891, Current Beta: 0.0000) | Avg Valid Loss: 0.0378 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0423, recon=0.0422, kl=1.5045, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0414, KL: 2.0394, Current Beta: 0.0000) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=0.4476, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0399 (Recon: 0.0399, KL: 0.7156, Current Beta: 0.0001) | Avg Valid Loss: 0.0381 | Avg Valid recon Loss: 0.0365\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0375, recon=0.0375, kl=0.0947, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 0.1907, Current Beta: 0.0001) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0361, recon=0.0361, kl=0.0665, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0381 (Recon: 0.0381, KL: 0.0915, Current Beta: 0.0001) | Avg Valid Loss: 0.0365 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0278, recon=0.0278, kl=0.0758, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0377, KL: 0.0827, Current Beta: 0.0001) | Avg Valid Loss: 0.0348 | Avg Valid recon Loss: 0.0343\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0602, recon=0.0602, kl=0.0283, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0367 (Recon: 0.0367, KL: 0.0496, Current Beta: 0.0001) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0288, recon=0.0288, kl=0.0224, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0358, KL: 0.0315, Current Beta: 0.0001) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0334\n",
      "\n",
      "[VRAE Run 231/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3712, recon=0.3712, kl=3.4272, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5550 (Recon: 0.5550, KL: 1.1573, Current Beta: 0.0000) | Avg Valid Loss: 0.3410 | Avg Valid recon Loss: 0.3410\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1918, recon=0.1918, kl=38.0004, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2668 (Recon: 0.2668, KL: 21.8859, Current Beta: 0.0000) | Avg Valid Loss: 0.1961 | Avg Valid recon Loss: 0.1961\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1632, recon=0.1632, kl=65.7262, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2016 (Recon: 0.2016, KL: 56.8442, Current Beta: 0.0000) | Avg Valid Loss: 0.1535 | Avg Valid recon Loss: 0.1535\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1618, recon=0.1618, kl=74.6380, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1714 (Recon: 0.1714, KL: 71.6159, Current Beta: 0.0000) | Avg Valid Loss: 0.1302 | Avg Valid recon Loss: 0.1302\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1317, recon=0.1317, kl=85.5060, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1508 (Recon: 0.1508, KL: 80.7540, Current Beta: 0.0000) | Avg Valid Loss: 0.1148 | Avg Valid recon Loss: 0.1148\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2086, recon=0.2086, kl=97.3286, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1427 (Recon: 0.1427, KL: 92.6956, Current Beta: 0.0000) | Avg Valid Loss: 0.1076 | Avg Valid recon Loss: 0.1076\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0940, recon=0.0940, kl=105.6127, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1323 (Recon: 0.1323, KL: 103.6232, Current Beta: 0.0000) | Avg Valid Loss: 0.0979 | Avg Valid recon Loss: 0.0979\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1250, recon=0.1250, kl=87.4521, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1195 (Recon: 0.1194, KL: 97.1947, Current Beta: 0.0000) | Avg Valid Loss: 0.0934 | Avg Valid recon Loss: 0.0934\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0803, recon=0.0803, kl=42.9881, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1150 (Recon: 0.1150, KL: 61.3016, Current Beta: 0.0000) | Avg Valid Loss: 0.0878 | Avg Valid recon Loss: 0.0878\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0771, recon=0.0771, kl=13.6237, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1063 (Recon: 0.1063, KL: 23.0656, Current Beta: 0.0000) | Avg Valid Loss: 0.0839 | Avg Valid recon Loss: 0.0839\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0966, recon=0.0966, kl=4.3274, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1019 (Recon: 0.1019, KL: 7.0294, Current Beta: 0.0000) | Avg Valid Loss: 0.0811 | Avg Valid recon Loss: 0.0811\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1268, recon=0.1268, kl=1.4186, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0960 (Recon: 0.0960, KL: 2.1156, Current Beta: 0.0000) | Avg Valid Loss: 0.0774 | Avg Valid recon Loss: 0.0774\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0694, recon=0.0694, kl=0.4861, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0919 (Recon: 0.0919, KL: 0.5552, Current Beta: 0.0000) | Avg Valid Loss: 0.0741 | Avg Valid recon Loss: 0.0741\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0757, recon=0.0757, kl=0.0630, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0879 (Recon: 0.0879, KL: 0.1548, Current Beta: 0.0000) | Avg Valid Loss: 0.0717 | Avg Valid recon Loss: 0.0717\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1034, recon=0.1034, kl=0.0292, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0846 (Recon: 0.0846, KL: 0.0419, Current Beta: 0.0001) | Avg Valid Loss: 0.0695 | Avg Valid recon Loss: 0.0695\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0804, recon=0.0804, kl=0.0116, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0813 (Recon: 0.0813, KL: 0.0148, Current Beta: 0.0001) | Avg Valid Loss: 0.0680 | Avg Valid recon Loss: 0.0680\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1162, recon=0.1162, kl=0.0087, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0786 (Recon: 0.0786, KL: 0.0125, Current Beta: 0.0001) | Avg Valid Loss: 0.0665 | Avg Valid recon Loss: 0.0665\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0754, recon=0.0754, kl=0.0063, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0760 (Recon: 0.0760, KL: 0.0107, Current Beta: 0.0001) | Avg Valid Loss: 0.0652 | Avg Valid recon Loss: 0.0652\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0524, recon=0.0524, kl=0.0096, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0739 (Recon: 0.0739, KL: 0.0088, Current Beta: 0.0001) | Avg Valid Loss: 0.0643 | Avg Valid recon Loss: 0.0643\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0583, recon=0.0583, kl=0.0088, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0720 (Recon: 0.0720, KL: 0.0080, Current Beta: 0.0001) | Avg Valid Loss: 0.0622 | Avg Valid recon Loss: 0.0622\n",
      "\n",
      "[VRAE Run 232/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1333, recon=0.1333, kl=54.3655, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2733 (Recon: 0.2733, KL: 28.3387, Current Beta: 0.0000) | Avg Valid Loss: 0.1124 | Avg Valid recon Loss: 0.1124\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0975, recon=0.0975, kl=67.1114, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1221 (Recon: 0.1221, KL: 63.1137, Current Beta: 0.0000) | Avg Valid Loss: 0.0882 | Avg Valid recon Loss: 0.0882\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1168, recon=0.1168, kl=69.3887, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0885 (Recon: 0.0885, KL: 71.2225, Current Beta: 0.0000) | Avg Valid Loss: 0.0693 | Avg Valid recon Loss: 0.0693\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0554, recon=0.0554, kl=66.5293, beta=0.0000\n",
      "  â†’ Avg Train Loss: 2.0100 (Recon: 2.0100, KL: 107.7991, Current Beta: 0.0000) | Avg Valid Loss: 0.0602 | Avg Valid recon Loss: 0.0602\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0655, recon=0.0655, kl=105.3590, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0678 (Recon: 0.0678, KL: 100.0329, Current Beta: 0.0000) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0566\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1651, recon=0.1651, kl=98.2456, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0601 (Recon: 0.0601, KL: 99.7532, Current Beta: 0.0000) | Avg Valid Loss: 0.0506 | Avg Valid recon Loss: 0.0506\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0728, recon=0.0728, kl=97.0901, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0590 (Recon: 0.0590, KL: 98.2845, Current Beta: 0.0000) | Avg Valid Loss: 0.0490 | Avg Valid recon Loss: 0.0489\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0488, recon=0.0488, kl=95.9102, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0530 (Recon: 0.0530, KL: 96.9818, Current Beta: 0.0000) | Avg Valid Loss: 0.0462 | Avg Valid recon Loss: 0.0462\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0375, recon=0.0374, kl=91.6709, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0497, KL: 93.4656, Current Beta: 0.0000) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0332, recon=0.0331, kl=80.4203, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0478 (Recon: 0.0478, KL: 84.6760, Current Beta: 0.0000) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0412\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0379, recon=0.0378, kl=52.4887, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0457, KL: 63.3981, Current Beta: 0.0000) | Avg Valid Loss: 0.0427 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0378, recon=0.0376, kl=20.3241, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0452, KL: 31.0203, Current Beta: 0.0000) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0397\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0365, recon=0.0364, kl=6.6904, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0430, KL: 11.2337, Current Beta: 0.0000) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0369, recon=0.0368, kl=3.8126, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0436 (Recon: 0.0435, KL: 4.2711, Current Beta: 0.0000) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0400\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0351, recon=0.0350, kl=1.5301, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0423, KL: 2.3115, Current Beta: 0.0001) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0529, recon=0.0528, kl=0.9815, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0403, KL: 1.2787, Current Beta: 0.0001) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0281, recon=0.0281, kl=0.5941, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0391, KL: 0.7848, Current Beta: 0.0001) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0354\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=0.4651, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0388, KL: 0.5369, Current Beta: 0.0001) | Avg Valid Loss: 0.0343 | Avg Valid recon Loss: 0.0343\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0272, recon=0.0271, kl=0.4191, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0372 (Recon: 0.0372, KL: 0.4319, Current Beta: 0.0001) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0331\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0311, recon=0.0311, kl=0.1909, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0365 (Recon: 0.0365, KL: 0.2828, Current Beta: 0.0001) | Avg Valid Loss: 0.0336 | Avg Valid recon Loss: 0.0335\n",
      "\n",
      "[VRAE Run 233/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3321, recon=0.3321, kl=5.6721, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5751 (Recon: 0.5751, KL: 1.9664, Current Beta: 0.0000) | Avg Valid Loss: 0.3385 | Avg Valid recon Loss: 0.3385\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2034, recon=0.2034, kl=85.2659, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2655 (Recon: 0.2655, KL: 58.9828, Current Beta: 0.0000) | Avg Valid Loss: 0.1951 | Avg Valid recon Loss: 0.1951\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1498, recon=0.1498, kl=124.1877, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2001 (Recon: 0.2001, KL: 110.9443, Current Beta: 0.0000) | Avg Valid Loss: 0.1512 | Avg Valid recon Loss: 0.1512\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1513, recon=0.1513, kl=141.3609, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1709 (Recon: 0.1709, KL: 135.6325, Current Beta: 0.0000) | Avg Valid Loss: 0.1293 | Avg Valid recon Loss: 0.1293\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1753, recon=0.1753, kl=158.1615, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1546 (Recon: 0.1546, KL: 150.8938, Current Beta: 0.0000) | Avg Valid Loss: 0.1146 | Avg Valid recon Loss: 0.1146\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.3342, recon=0.3342, kl=172.7794, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1421 (Recon: 0.1421, KL: 168.0921, Current Beta: 0.0000) | Avg Valid Loss: 0.1062 | Avg Valid recon Loss: 0.1062\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1811, recon=0.1811, kl=157.5611, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1326 (Recon: 0.1326, KL: 167.3428, Current Beta: 0.0000) | Avg Valid Loss: 0.0983 | Avg Valid recon Loss: 0.0983\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1058, recon=0.1058, kl=115.2852, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1233 (Recon: 0.1233, KL: 136.0574, Current Beta: 0.0000) | Avg Valid Loss: 0.0933 | Avg Valid recon Loss: 0.0933\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0998, recon=0.0998, kl=55.8213, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1168 (Recon: 0.1168, KL: 77.0076, Current Beta: 0.0000) | Avg Valid Loss: 0.0884 | Avg Valid recon Loss: 0.0884\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1342, recon=0.1342, kl=20.9853, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1092 (Recon: 0.1091, KL: 32.8207, Current Beta: 0.0000) | Avg Valid Loss: 0.0848 | Avg Valid recon Loss: 0.0848\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0842, recon=0.0842, kl=7.6523, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1034 (Recon: 0.1034, KL: 11.4109, Current Beta: 0.0000) | Avg Valid Loss: 0.0799 | Avg Valid recon Loss: 0.0799\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0835, recon=0.0834, kl=1.8744, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0978 (Recon: 0.0978, KL: 3.3123, Current Beta: 0.0000) | Avg Valid Loss: 0.0770 | Avg Valid recon Loss: 0.0770\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0864, recon=0.0864, kl=0.4454, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0925 (Recon: 0.0925, KL: 0.8817, Current Beta: 0.0000) | Avg Valid Loss: 0.0750 | Avg Valid recon Loss: 0.0750\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0716, recon=0.0716, kl=0.1617, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0888 (Recon: 0.0888, KL: 0.2394, Current Beta: 0.0000) | Avg Valid Loss: 0.0715 | Avg Valid recon Loss: 0.0715\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0710, recon=0.0710, kl=0.0534, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0834 (Recon: 0.0834, KL: 0.0946, Current Beta: 0.0001) | Avg Valid Loss: 0.0692 | Avg Valid recon Loss: 0.0692\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0887, recon=0.0887, kl=0.0262, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0804 (Recon: 0.0804, KL: 0.0352, Current Beta: 0.0001) | Avg Valid Loss: 0.0678 | Avg Valid recon Loss: 0.0678\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0732, recon=0.0732, kl=0.0265, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0779 (Recon: 0.0779, KL: 0.0299, Current Beta: 0.0001) | Avg Valid Loss: 0.0662 | Avg Valid recon Loss: 0.0662\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0713, recon=0.0713, kl=0.0203, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0754 (Recon: 0.0753, KL: 0.0214, Current Beta: 0.0001) | Avg Valid Loss: 0.0650 | Avg Valid recon Loss: 0.0650\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0525, recon=0.0525, kl=0.0185, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0728 (Recon: 0.0728, KL: 0.0206, Current Beta: 0.0001) | Avg Valid Loss: 0.0633 | Avg Valid recon Loss: 0.0633\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0497, recon=0.0497, kl=0.0119, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0708 (Recon: 0.0708, KL: 0.0172, Current Beta: 0.0001) | Avg Valid Loss: 0.0615 | Avg Valid recon Loss: 0.0615\n",
      "\n",
      "[VRAE Run 234/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1220, recon=0.1220, kl=71.2585, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2714 (Recon: 0.2714, KL: 40.8297, Current Beta: 0.0000) | Avg Valid Loss: 0.1157 | Avg Valid recon Loss: 0.1157\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0888, recon=0.0888, kl=143.6102, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1175 (Recon: 0.1175, KL: 120.1777, Current Beta: 0.0000) | Avg Valid Loss: 0.0798 | Avg Valid recon Loss: 0.0798\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0705, recon=0.0705, kl=138.4370, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0868 (Recon: 0.0868, KL: 143.7914, Current Beta: 0.0000) | Avg Valid Loss: 0.0660 | Avg Valid recon Loss: 0.0660\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0548, recon=0.0548, kl=133.0098, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0741 (Recon: 0.0741, KL: 134.9196, Current Beta: 0.0000) | Avg Valid Loss: 0.0602 | Avg Valid recon Loss: 0.0602\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0524, recon=0.0524, kl=144.0472, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0651 (Recon: 0.0651, KL: 139.0563, Current Beta: 0.0000) | Avg Valid Loss: 0.0544 | Avg Valid recon Loss: 0.0544\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0484, recon=0.0484, kl=132.1373, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0583 (Recon: 0.0583, KL: 140.7225, Current Beta: 0.0000) | Avg Valid Loss: 0.0513 | Avg Valid recon Loss: 0.0513\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0567, recon=0.0567, kl=120.2390, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0594 (Recon: 0.0594, KL: 123.5587, Current Beta: 0.0000) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0462, recon=0.0461, kl=98.1779, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0520 (Recon: 0.0520, KL: 110.1081, Current Beta: 0.0000) | Avg Valid Loss: 0.0473 | Avg Valid recon Loss: 0.0473\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0439, recon=0.0439, kl=63.2261, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0479, KL: 77.1408, Current Beta: 0.0000) | Avg Valid Loss: 0.0452 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0337, recon=0.0337, kl=37.1691, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0459 (Recon: 0.0459, KL: 45.2446, Current Beta: 0.0000) | Avg Valid Loss: 0.0432 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0345, recon=0.0345, kl=20.9593, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0445, KL: 24.4049, Current Beta: 0.0000) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0410\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0362, recon=0.0362, kl=6.8540, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0438, KL: 9.8822, Current Beta: 0.0000) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0400\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0319, recon=0.0319, kl=2.3075, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0418, KL: 2.8569, Current Beta: 0.0000) | Avg Valid Loss: 0.0385 | Avg Valid recon Loss: 0.0385\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0469, recon=0.0468, kl=1.0459, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0413 (Recon: 0.0413, KL: 1.0822, Current Beta: 0.0000) | Avg Valid Loss: 0.0386 | Avg Valid recon Loss: 0.0386\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=0.3326, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0400, KL: 0.4855, Current Beta: 0.0001) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0426, recon=0.0426, kl=0.1614, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0401 (Recon: 0.0400, KL: 0.1940, Current Beta: 0.0001) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0341, recon=0.0340, kl=0.1230, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0388, KL: 0.1471, Current Beta: 0.0001) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0355\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0327, recon=0.0327, kl=0.0625, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0374 (Recon: 0.0374, KL: 0.0861, Current Beta: 0.0001) | Avg Valid Loss: 0.0349 | Avg Valid recon Loss: 0.0349\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0269, recon=0.0269, kl=0.0625, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0378 (Recon: 0.0378, KL: 0.0546, Current Beta: 0.0001) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0346\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=0.0244, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0362, KL: 0.0275, Current Beta: 0.0001) | Avg Valid Loss: 0.0333 | Avg Valid recon Loss: 0.0333\n",
      "\n",
      "[VRAE Run 235/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6236, recon=0.6236, kl=0.6188, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.7915 (Recon: 0.7915, KL: 0.4251, Current Beta: 0.0000) | Avg Valid Loss: 0.6635 | Avg Valid recon Loss: 0.6635\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.5073, recon=0.5073, kl=5.3181, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5616 (Recon: 0.5616, KL: 2.7919, Current Beta: 0.0000) | Avg Valid Loss: 0.5287 | Avg Valid recon Loss: 0.5287\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.3912, recon=0.3912, kl=12.9943, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4562 (Recon: 0.4562, KL: 10.4113, Current Beta: 0.0000) | Avg Valid Loss: 0.4315 | Avg Valid recon Loss: 0.4315\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.3775, recon=0.3775, kl=16.3393, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3826 (Recon: 0.3826, KL: 15.1314, Current Beta: 0.0000) | Avg Valid Loss: 0.3593 | Avg Valid recon Loss: 0.3593\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.3279, recon=0.3279, kl=18.8435, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3238 (Recon: 0.3238, KL: 17.8186, Current Beta: 0.0000) | Avg Valid Loss: 0.3013 | Avg Valid recon Loss: 0.3013\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2561, recon=0.2561, kl=21.8026, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2876 (Recon: 0.2876, KL: 20.7059, Current Beta: 0.0000) | Avg Valid Loss: 0.2604 | Avg Valid recon Loss: 0.2604\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2233, recon=0.2233, kl=24.8815, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2558 (Recon: 0.2558, KL: 23.6700, Current Beta: 0.0000) | Avg Valid Loss: 0.2312 | Avg Valid recon Loss: 0.2312\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1925, recon=0.1925, kl=27.4890, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2345 (Recon: 0.2345, KL: 26.5235, Current Beta: 0.0000) | Avg Valid Loss: 0.2095 | Avg Valid recon Loss: 0.2095\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1967, recon=0.1967, kl=29.2563, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2156 (Recon: 0.2155, KL: 28.7584, Current Beta: 0.0000) | Avg Valid Loss: 0.1938 | Avg Valid recon Loss: 0.1938\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1722, recon=0.1722, kl=26.7991, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1986 (Recon: 0.1985, KL: 28.1802, Current Beta: 0.0000) | Avg Valid Loss: 0.1796 | Avg Valid recon Loss: 0.1796\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1592, recon=0.1591, kl=18.8264, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1860 (Recon: 0.1859, KL: 22.2797, Current Beta: 0.0000) | Avg Valid Loss: 0.1681 | Avg Valid recon Loss: 0.1681\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.4053, recon=0.4052, kl=8.0964, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1742 (Recon: 0.1741, KL: 12.3264, Current Beta: 0.0000) | Avg Valid Loss: 0.1580 | Avg Valid recon Loss: 0.1580\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1264, recon=0.1263, kl=2.3586, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1639 (Recon: 0.1638, KL: 3.8881, Current Beta: 0.0000) | Avg Valid Loss: 0.1496 | Avg Valid recon Loss: 0.1496\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1432, recon=0.1431, kl=0.8815, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1555 (Recon: 0.1554, KL: 1.3273, Current Beta: 0.0000) | Avg Valid Loss: 0.1427 | Avg Valid recon Loss: 0.1426\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1278, recon=0.1278, kl=0.3620, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1450 (Recon: 0.1450, KL: 0.5062, Current Beta: 0.0001) | Avg Valid Loss: 0.1370 | Avg Valid recon Loss: 0.1369\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1071, recon=0.1071, kl=0.1286, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1413 (Recon: 0.1413, KL: 0.1909, Current Beta: 0.0001) | Avg Valid Loss: 0.1314 | Avg Valid recon Loss: 0.1314\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1074, recon=0.1074, kl=0.0873, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1355 (Recon: 0.1355, KL: 0.1075, Current Beta: 0.0001) | Avg Valid Loss: 0.1263 | Avg Valid recon Loss: 0.1263\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1133, recon=0.1133, kl=0.0699, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1263 (Recon: 0.1263, KL: 0.0665, Current Beta: 0.0001) | Avg Valid Loss: 0.1225 | Avg Valid recon Loss: 0.1225\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1057, recon=0.1057, kl=0.0296, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1258 (Recon: 0.1258, KL: 0.0427, Current Beta: 0.0001) | Avg Valid Loss: 0.1195 | Avg Valid recon Loss: 0.1195\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1071, recon=0.1071, kl=0.0231, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1214 (Recon: 0.1214, KL: 0.0290, Current Beta: 0.0001) | Avg Valid Loss: 0.1156 | Avg Valid recon Loss: 0.1156\n",
      "\n",
      "[VRAE Run 236/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2482, recon=0.2482, kl=22.5572, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4728 (Recon: 0.4728, KL: 11.5602, Current Beta: 0.0000) | Avg Valid Loss: 0.2361 | Avg Valid recon Loss: 0.2361\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2177, recon=0.2177, kl=33.7024, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1949 (Recon: 0.1949, KL: 30.5570, Current Beta: 0.0000) | Avg Valid Loss: 0.1396 | Avg Valid recon Loss: 0.1396\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1060, recon=0.1060, kl=39.4538, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1334 (Recon: 0.1334, KL: 37.4996, Current Beta: 0.0000) | Avg Valid Loss: 0.1185 | Avg Valid recon Loss: 0.1185\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0904, recon=0.0904, kl=43.3368, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1098 (Recon: 0.1098, KL: 41.6479, Current Beta: 0.0000) | Avg Valid Loss: 0.0958 | Avg Valid recon Loss: 0.0958\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1017, recon=0.1017, kl=45.5231, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0967 (Recon: 0.0967, KL: 44.6964, Current Beta: 0.0000) | Avg Valid Loss: 0.0882 | Avg Valid recon Loss: 0.0882\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0674, recon=0.0674, kl=47.1628, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0877 (Recon: 0.0877, KL: 45.9712, Current Beta: 0.0000) | Avg Valid Loss: 0.0797 | Avg Valid recon Loss: 0.0797\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0687, recon=0.0687, kl=46.6136, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0830 (Recon: 0.0830, KL: 46.8450, Current Beta: 0.0000) | Avg Valid Loss: 0.0760 | Avg Valid recon Loss: 0.0760\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0545, recon=0.0545, kl=43.1789, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0763 (Recon: 0.0763, KL: 45.0313, Current Beta: 0.0000) | Avg Valid Loss: 0.0715 | Avg Valid recon Loss: 0.0714\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0557, recon=0.0557, kl=29.8120, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0727 (Recon: 0.0726, KL: 35.6838, Current Beta: 0.0000) | Avg Valid Loss: 0.0697 | Avg Valid recon Loss: 0.0696\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0520, recon=0.0520, kl=16.1950, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0699 (Recon: 0.0698, KL: 20.5514, Current Beta: 0.0000) | Avg Valid Loss: 0.0645 | Avg Valid recon Loss: 0.0645\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0536, recon=0.0536, kl=9.4533, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0659 (Recon: 0.0658, KL: 11.8731, Current Beta: 0.0000) | Avg Valid Loss: 0.0619 | Avg Valid recon Loss: 0.0618\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0527, recon=0.0527, kl=4.1056, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0646 (Recon: 0.0645, KL: 5.0208, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0557, recon=0.0557, kl=0.9928, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0623 (Recon: 0.0623, KL: 1.6118, Current Beta: 0.0000) | Avg Valid Loss: 0.0585 | Avg Valid recon Loss: 0.0585\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0655, recon=0.0655, kl=0.1794, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0611 (Recon: 0.0610, KL: 0.2924, Current Beta: 0.0000) | Avg Valid Loss: 0.0560 | Avg Valid recon Loss: 0.0560\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0472, recon=0.0472, kl=0.0326, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0583 (Recon: 0.0583, KL: 0.0625, Current Beta: 0.0001) | Avg Valid Loss: 0.0558 | Avg Valid recon Loss: 0.0558\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0653, recon=0.0653, kl=0.0120, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0581, KL: 0.0181, Current Beta: 0.0001) | Avg Valid Loss: 0.0562 | Avg Valid recon Loss: 0.0562\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0679, recon=0.0679, kl=0.0090, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0558 (Recon: 0.0558, KL: 0.0083, Current Beta: 0.0001) | Avg Valid Loss: 0.0517 | Avg Valid recon Loss: 0.0517\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0555, recon=0.0555, kl=0.0045, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0545, KL: 0.0064, Current Beta: 0.0001) | Avg Valid Loss: 0.0504 | Avg Valid recon Loss: 0.0504\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0487, recon=0.0487, kl=0.0037, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0534, KL: 0.0047, Current Beta: 0.0001) | Avg Valid Loss: 0.0500 | Avg Valid recon Loss: 0.0500\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0650, recon=0.0650, kl=0.0034, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0534, KL: 0.0037, Current Beta: 0.0001) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "\n",
      "[VRAE Run 237/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7880, recon=0.7880, kl=0.9388, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.9028 (Recon: 0.9028, KL: 0.6040, Current Beta: 0.0000) | Avg Valid Loss: 0.7821 | Avg Valid recon Loss: 0.7821\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.6664, recon=0.6664, kl=8.4069, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6489 (Recon: 0.6489, KL: 4.6010, Current Beta: 0.0000) | Avg Valid Loss: 0.5989 | Avg Valid recon Loss: 0.5989\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.4509, recon=0.4509, kl=21.1386, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5127 (Recon: 0.5127, KL: 16.1215, Current Beta: 0.0000) | Avg Valid Loss: 0.4841 | Avg Valid recon Loss: 0.4841\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.4011, recon=0.4011, kl=33.1518, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4255 (Recon: 0.4255, KL: 28.8955, Current Beta: 0.0000) | Avg Valid Loss: 0.3988 | Avg Valid recon Loss: 0.3988\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.3414, recon=0.3414, kl=41.0197, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3604 (Recon: 0.3604, KL: 38.0091, Current Beta: 0.0000) | Avg Valid Loss: 0.3340 | Avg Valid recon Loss: 0.3340\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2653, recon=0.2653, kl=48.1875, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3128 (Recon: 0.3128, KL: 45.6593, Current Beta: 0.0000) | Avg Valid Loss: 0.2871 | Avg Valid recon Loss: 0.2871\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2307, recon=0.2307, kl=53.3299, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2748 (Recon: 0.2748, KL: 51.4834, Current Beta: 0.0000) | Avg Valid Loss: 0.2511 | Avg Valid recon Loss: 0.2511\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.3228, recon=0.3228, kl=56.5400, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2503 (Recon: 0.2503, KL: 55.4782, Current Beta: 0.0000) | Avg Valid Loss: 0.2262 | Avg Valid recon Loss: 0.2262\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.2270, recon=0.2269, kl=55.5500, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2290 (Recon: 0.2289, KL: 56.2793, Current Beta: 0.0000) | Avg Valid Loss: 0.2047 | Avg Valid recon Loss: 0.2047\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1984, recon=0.1983, kl=46.4429, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2105 (Recon: 0.2105, KL: 50.7068, Current Beta: 0.0000) | Avg Valid Loss: 0.1899 | Avg Valid recon Loss: 0.1898\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.2153, recon=0.2152, kl=28.4731, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1959 (Recon: 0.1958, KL: 36.2434, Current Beta: 0.0000) | Avg Valid Loss: 0.1758 | Avg Valid recon Loss: 0.1757\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1619, recon=0.1618, kl=11.4357, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1809 (Recon: 0.1808, KL: 17.5940, Current Beta: 0.0000) | Avg Valid Loss: 0.1657 | Avg Valid recon Loss: 0.1657\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1431, recon=0.1431, kl=3.2897, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1682 (Recon: 0.1681, KL: 5.7511, Current Beta: 0.0000) | Avg Valid Loss: 0.1559 | Avg Valid recon Loss: 0.1558\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.2062, recon=0.2061, kl=1.2248, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1600 (Recon: 0.1599, KL: 1.8246, Current Beta: 0.0000) | Avg Valid Loss: 0.1487 | Avg Valid recon Loss: 0.1487\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1332, recon=0.1332, kl=0.5246, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1529 (Recon: 0.1529, KL: 0.6923, Current Beta: 0.0001) | Avg Valid Loss: 0.1416 | Avg Valid recon Loss: 0.1416\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1275, recon=0.1275, kl=0.1978, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1464 (Recon: 0.1464, KL: 0.2623, Current Beta: 0.0001) | Avg Valid Loss: 0.1355 | Avg Valid recon Loss: 0.1355\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1271, recon=0.1271, kl=0.1620, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1396 (Recon: 0.1396, KL: 0.1673, Current Beta: 0.0001) | Avg Valid Loss: 0.1299 | Avg Valid recon Loss: 0.1299\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.3227, recon=0.3227, kl=0.1006, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1343 (Recon: 0.1343, KL: 0.1088, Current Beta: 0.0001) | Avg Valid Loss: 0.1254 | Avg Valid recon Loss: 0.1254\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0906, recon=0.0906, kl=0.0870, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1281 (Recon: 0.1281, KL: 0.0807, Current Beta: 0.0001) | Avg Valid Loss: 0.1204 | Avg Valid recon Loss: 0.1204\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0955, recon=0.0955, kl=0.0594, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1242 (Recon: 0.1242, KL: 0.0689, Current Beta: 0.0001) | Avg Valid Loss: 0.1167 | Avg Valid recon Loss: 0.1167\n",
      "\n",
      "[VRAE Run 238/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2459, recon=0.2459, kl=36.5046, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4434 (Recon: 0.4434, KL: 19.0325, Current Beta: 0.0000) | Avg Valid Loss: 0.2269 | Avg Valid recon Loss: 0.2269\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1226, recon=0.1226, kl=55.0346, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1926 (Recon: 0.1926, KL: 48.9385, Current Beta: 0.0000) | Avg Valid Loss: 0.1363 | Avg Valid recon Loss: 0.1363\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1150, recon=0.1150, kl=65.2915, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1263 (Recon: 0.1263, KL: 61.4405, Current Beta: 0.0000) | Avg Valid Loss: 0.1081 | Avg Valid recon Loss: 0.1081\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0829, recon=0.0829, kl=72.1733, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1106 (Recon: 0.1106, KL: 69.5658, Current Beta: 0.0000) | Avg Valid Loss: 0.1104 | Avg Valid recon Loss: 0.1104\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0785, recon=0.0785, kl=75.8779, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0991 (Recon: 0.0991, KL: 74.6838, Current Beta: 0.0000) | Avg Valid Loss: 0.0868 | Avg Valid recon Loss: 0.0868\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0807, recon=0.0807, kl=77.5403, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0875 (Recon: 0.0875, KL: 76.5728, Current Beta: 0.0000) | Avg Valid Loss: 0.0791 | Avg Valid recon Loss: 0.0791\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0724, recon=0.0724, kl=80.4331, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0810 (Recon: 0.0809, KL: 80.3206, Current Beta: 0.0000) | Avg Valid Loss: 0.0776 | Avg Valid recon Loss: 0.0776\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1051, recon=0.1050, kl=73.9833, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0787 (Recon: 0.0787, KL: 76.6264, Current Beta: 0.0000) | Avg Valid Loss: 0.0708 | Avg Valid recon Loss: 0.0707\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0619, recon=0.0618, kl=51.1516, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0711 (Recon: 0.0711, KL: 60.0824, Current Beta: 0.0000) | Avg Valid Loss: 0.0673 | Avg Valid recon Loss: 0.0673\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0504, recon=0.0504, kl=27.2154, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0672 (Recon: 0.0672, KL: 35.1915, Current Beta: 0.0000) | Avg Valid Loss: 0.0639 | Avg Valid recon Loss: 0.0639\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0458, recon=0.0458, kl=15.4456, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0638 (Recon: 0.0638, KL: 19.2670, Current Beta: 0.0000) | Avg Valid Loss: 0.0601 | Avg Valid recon Loss: 0.0601\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0485, recon=0.0485, kl=4.9269, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0644 (Recon: 0.0643, KL: 6.9151, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0597\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0695, recon=0.0695, kl=1.4688, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0605 (Recon: 0.0605, KL: 1.8017, Current Beta: 0.0000) | Avg Valid Loss: 0.0569 | Avg Valid recon Loss: 0.0569\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0816, recon=0.0816, kl=0.1619, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0607 (Recon: 0.0607, KL: 0.4222, Current Beta: 0.0000) | Avg Valid Loss: 0.0618 | Avg Valid recon Loss: 0.0618\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0478, recon=0.0478, kl=0.0270, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0577 (Recon: 0.0577, KL: 0.0971, Current Beta: 0.0001) | Avg Valid Loss: 0.0547 | Avg Valid recon Loss: 0.0547\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0655, recon=0.0655, kl=0.0052, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0550 (Recon: 0.0550, KL: 0.0123, Current Beta: 0.0001) | Avg Valid Loss: 0.0517 | Avg Valid recon Loss: 0.0517\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0552, recon=0.0552, kl=0.0054, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0533, KL: 0.0096, Current Beta: 0.0001) | Avg Valid Loss: 0.0508 | Avg Valid recon Loss: 0.0508\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0467, recon=0.0467, kl=0.0085, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0528 (Recon: 0.0528, KL: 0.0090, Current Beta: 0.0001) | Avg Valid Loss: 0.0503 | Avg Valid recon Loss: 0.0503\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0691, recon=0.0691, kl=0.0183, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0520 (Recon: 0.0520, KL: 0.0117, Current Beta: 0.0001) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0778, recon=0.0778, kl=0.0075, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0502, KL: 0.0136, Current Beta: 0.0001) | Avg Valid Loss: 0.0477 | Avg Valid recon Loss: 0.0477\n",
      "\n",
      "[VRAE Run 239/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=1.0178, recon=1.0178, kl=1.2667, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.8809 (Recon: 0.8809, KL: 0.9760, Current Beta: 0.0000) | Avg Valid Loss: 0.7546 | Avg Valid recon Loss: 0.7546\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.6424, recon=0.6424, kl=15.7703, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6183 (Recon: 0.6183, KL: 7.1544, Current Beta: 0.0000) | Avg Valid Loss: 0.5691 | Avg Valid recon Loss: 0.5691\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.3942, recon=0.3942, kl=46.1648, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4820 (Recon: 0.4820, KL: 35.0944, Current Beta: 0.0000) | Avg Valid Loss: 0.4525 | Avg Valid recon Loss: 0.4525\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.2920, recon=0.2920, kl=68.2322, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3983 (Recon: 0.3983, KL: 60.5538, Current Beta: 0.0000) | Avg Valid Loss: 0.3664 | Avg Valid recon Loss: 0.3664\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2954, recon=0.2954, kl=83.5517, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3336 (Recon: 0.3336, KL: 78.0897, Current Beta: 0.0000) | Avg Valid Loss: 0.3039 | Avg Valid recon Loss: 0.3039\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.3642, recon=0.3642, kl=94.0425, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2748 (Recon: 0.2748, KL: 90.3554, Current Beta: 0.0000) | Avg Valid Loss: 0.2603 | Avg Valid recon Loss: 0.2603\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2257, recon=0.2257, kl=100.4272, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2568 (Recon: 0.2567, KL: 98.2177, Current Beta: 0.0000) | Avg Valid Loss: 0.2311 | Avg Valid recon Loss: 0.2311\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1602, recon=0.1602, kl=102.8350, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2299 (Recon: 0.2299, KL: 102.3366, Current Beta: 0.0000) | Avg Valid Loss: 0.2088 | Avg Valid recon Loss: 0.2088\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1679, recon=0.1679, kl=96.2451, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2136 (Recon: 0.2135, KL: 99.6632, Current Beta: 0.0000) | Avg Valid Loss: 0.1915 | Avg Valid recon Loss: 0.1915\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.2212, recon=0.2211, kl=74.4014, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1972 (Recon: 0.1971, KL: 84.3556, Current Beta: 0.0000) | Avg Valid Loss: 0.1773 | Avg Valid recon Loss: 0.1772\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1379, recon=0.1378, kl=35.8354, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1819 (Recon: 0.1818, KL: 51.4049, Current Beta: 0.0000) | Avg Valid Loss: 0.1654 | Avg Valid recon Loss: 0.1653\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.2158, recon=0.2157, kl=10.7519, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1720 (Recon: 0.1718, KL: 18.2678, Current Beta: 0.0000) | Avg Valid Loss: 0.1552 | Avg Valid recon Loss: 0.1551\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1695, recon=0.1694, kl=3.6083, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1615 (Recon: 0.1614, KL: 5.8900, Current Beta: 0.0000) | Avg Valid Loss: 0.1471 | Avg Valid recon Loss: 0.1470\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1484, recon=0.1484, kl=1.3841, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1532 (Recon: 0.1531, KL: 2.0661, Current Beta: 0.0000) | Avg Valid Loss: 0.1402 | Avg Valid recon Loss: 0.1401\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1207, recon=0.1206, kl=0.5954, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1440 (Recon: 0.1440, KL: 0.8291, Current Beta: 0.0001) | Avg Valid Loss: 0.1336 | Avg Valid recon Loss: 0.1335\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1073, recon=0.1072, kl=0.2422, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1396 (Recon: 0.1396, KL: 0.3279, Current Beta: 0.0001) | Avg Valid Loss: 0.1289 | Avg Valid recon Loss: 0.1289\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1021, recon=0.1021, kl=0.1501, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1334 (Recon: 0.1333, KL: 0.1668, Current Beta: 0.0001) | Avg Valid Loss: 0.1239 | Avg Valid recon Loss: 0.1239\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1087, recon=0.1087, kl=0.0708, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1291 (Recon: 0.1291, KL: 0.0987, Current Beta: 0.0001) | Avg Valid Loss: 0.1198 | Avg Valid recon Loss: 0.1198\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1062, recon=0.1062, kl=0.0562, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1245 (Recon: 0.1245, KL: 0.0635, Current Beta: 0.0001) | Avg Valid Loss: 0.1161 | Avg Valid recon Loss: 0.1161\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0931, recon=0.0931, kl=0.0383, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1199 (Recon: 0.1199, KL: 0.0436, Current Beta: 0.0001) | Avg Valid Loss: 0.1132 | Avg Valid recon Loss: 0.1132\n",
      "\n",
      "[VRAE Run 240/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3901, recon=0.3901, kl=86.1552, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4462 (Recon: 0.4462, KL: 46.8606, Current Beta: 0.0000) | Avg Valid Loss: 0.2230 | Avg Valid recon Loss: 0.2230\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1204, recon=0.1204, kl=118.6653, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1849 (Recon: 0.1849, KL: 112.8296, Current Beta: 0.0000) | Avg Valid Loss: 0.1364 | Avg Valid recon Loss: 0.1364\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0865, recon=0.0865, kl=133.2449, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1287 (Recon: 0.1287, KL: 125.0267, Current Beta: 0.0000) | Avg Valid Loss: 0.1039 | Avg Valid recon Loss: 0.1039\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0909, recon=0.0909, kl=141.1568, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1067 (Recon: 0.1067, KL: 138.8247, Current Beta: 0.0000) | Avg Valid Loss: 0.0944 | Avg Valid recon Loss: 0.0944\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0718, recon=0.0717, kl=147.2706, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0937 (Recon: 0.0937, KL: 147.7199, Current Beta: 0.0000) | Avg Valid Loss: 0.0837 | Avg Valid recon Loss: 0.0837\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0967, recon=0.0967, kl=153.8448, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0853 (Recon: 0.0853, KL: 150.2811, Current Beta: 0.0000) | Avg Valid Loss: 0.0761 | Avg Valid recon Loss: 0.0761\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0642, recon=0.0642, kl=134.1216, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0794 (Recon: 0.0794, KL: 143.9079, Current Beta: 0.0000) | Avg Valid Loss: 0.0704 | Avg Valid recon Loss: 0.0703\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0532, recon=0.0531, kl=98.4056, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0737 (Recon: 0.0737, KL: 115.7423, Current Beta: 0.0000) | Avg Valid Loss: 0.0749 | Avg Valid recon Loss: 0.0749\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0960, recon=0.0960, kl=67.1721, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0694 (Recon: 0.0694, KL: 80.7812, Current Beta: 0.0000) | Avg Valid Loss: 0.0628 | Avg Valid recon Loss: 0.0628\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0499, recon=0.0499, kl=50.0551, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0662 (Recon: 0.0662, KL: 52.8080, Current Beta: 0.0000) | Avg Valid Loss: 0.0607 | Avg Valid recon Loss: 0.0607\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0507, recon=0.0506, kl=23.3819, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0629 (Recon: 0.0628, KL: 28.8547, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0597\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0442, recon=0.0441, kl=7.4850, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0636 (Recon: 0.0635, KL: 9.5768, Current Beta: 0.0000) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0574\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0592, recon=0.0592, kl=2.0895, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0595 (Recon: 0.0594, KL: 2.3443, Current Beta: 0.0000) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0565\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0403, recon=0.0403, kl=0.3829, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0570 (Recon: 0.0570, KL: 0.6538, Current Beta: 0.0000) | Avg Valid Loss: 0.0523 | Avg Valid recon Loss: 0.0523\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0502, recon=0.0502, kl=0.0894, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0543 (Recon: 0.0543, KL: 0.2471, Current Beta: 0.0001) | Avg Valid Loss: 0.0508 | Avg Valid recon Loss: 0.0508\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0863, recon=0.0863, kl=0.0249, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0544 (Recon: 0.0544, KL: 0.0390, Current Beta: 0.0001) | Avg Valid Loss: 0.0509 | Avg Valid recon Loss: 0.0509\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0363, recon=0.0363, kl=0.0399, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0542 (Recon: 0.0542, KL: 0.0356, Current Beta: 0.0001) | Avg Valid Loss: 0.0484 | Avg Valid recon Loss: 0.0484\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0473, recon=0.0473, kl=0.0488, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0520 (Recon: 0.0520, KL: 0.0376, Current Beta: 0.0001) | Avg Valid Loss: 0.0471 | Avg Valid recon Loss: 0.0471\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0368, recon=0.0368, kl=0.0092, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0507 (Recon: 0.0507, KL: 0.0233, Current Beta: 0.0001) | Avg Valid Loss: 0.0524 | Avg Valid recon Loss: 0.0524\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0474, recon=0.0474, kl=0.0244, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0513 (Recon: 0.0513, KL: 0.0269, Current Beta: 0.0001) | Avg Valid Loss: 0.0467 | Avg Valid recon Loss: 0.0467\n",
      "\n",
      "[VRAE Run 241/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4753, recon=0.4753, kl=0.9511, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6718 (Recon: 0.6718, KL: 0.3643, Current Beta: 0.0000) | Avg Valid Loss: 0.5068 | Avg Valid recon Loss: 0.5068\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2993, recon=0.2993, kl=13.7578, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3942 (Recon: 0.3942, KL: 8.9663, Current Beta: 0.0000) | Avg Valid Loss: 0.3386 | Avg Valid recon Loss: 0.3386\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2950, recon=0.2950, kl=21.4955, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2934 (Recon: 0.2934, KL: 18.9836, Current Beta: 0.0000) | Avg Valid Loss: 0.2490 | Avg Valid recon Loss: 0.2490\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1762, recon=0.1762, kl=27.3291, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2341 (Recon: 0.2341, KL: 25.1348, Current Beta: 0.0000) | Avg Valid Loss: 0.1984 | Avg Valid recon Loss: 0.1984\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1798, recon=0.1798, kl=32.1379, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1983 (Recon: 0.1983, KL: 30.1528, Current Beta: 0.0000) | Avg Valid Loss: 0.1685 | Avg Valid recon Loss: 0.1685\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1372, recon=0.1372, kl=37.0707, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1762 (Recon: 0.1762, KL: 35.2716, Current Beta: 0.0000) | Avg Valid Loss: 0.1477 | Avg Valid recon Loss: 0.1477\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1416, recon=0.1416, kl=42.9288, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1588 (Recon: 0.1588, KL: 40.6944, Current Beta: 0.0000) | Avg Valid Loss: 0.1325 | Avg Valid recon Loss: 0.1325\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0986, recon=0.0986, kl=45.6839, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1450 (Recon: 0.1450, KL: 45.1363, Current Beta: 0.0000) | Avg Valid Loss: 0.1229 | Avg Valid recon Loss: 0.1228\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1178, recon=0.1178, kl=41.4152, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1346 (Recon: 0.1345, KL: 43.7606, Current Beta: 0.0000) | Avg Valid Loss: 0.1165 | Avg Valid recon Loss: 0.1165\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1186, recon=0.1186, kl=26.0539, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1255 (Recon: 0.1254, KL: 32.7126, Current Beta: 0.0000) | Avg Valid Loss: 0.1080 | Avg Valid recon Loss: 0.1080\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1175, recon=0.1175, kl=10.7850, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1180 (Recon: 0.1180, KL: 16.1701, Current Beta: 0.0000) | Avg Valid Loss: 0.1020 | Avg Valid recon Loss: 0.1020\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.2810, recon=0.2810, kl=4.5713, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1114 (Recon: 0.1114, KL: 6.4589, Current Beta: 0.0000) | Avg Valid Loss: 0.0975 | Avg Valid recon Loss: 0.0975\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0871, recon=0.0870, kl=1.3865, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1069 (Recon: 0.1069, KL: 2.2222, Current Beta: 0.0000) | Avg Valid Loss: 0.0928 | Avg Valid recon Loss: 0.0928\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0926, recon=0.0925, kl=0.6503, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1009 (Recon: 0.1008, KL: 0.7556, Current Beta: 0.0000) | Avg Valid Loss: 0.0893 | Avg Valid recon Loss: 0.0893\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0762, recon=0.0762, kl=0.2061, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0965 (Recon: 0.0965, KL: 0.2622, Current Beta: 0.0001) | Avg Valid Loss: 0.0866 | Avg Valid recon Loss: 0.0866\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0704, recon=0.0704, kl=0.0559, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0941 (Recon: 0.0941, KL: 0.0801, Current Beta: 0.0001) | Avg Valid Loss: 0.0843 | Avg Valid recon Loss: 0.0843\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0999, recon=0.0999, kl=0.0303, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0878 (Recon: 0.0878, KL: 0.0511, Current Beta: 0.0001) | Avg Valid Loss: 0.0809 | Avg Valid recon Loss: 0.0809\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0751, recon=0.0751, kl=0.0336, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0868 (Recon: 0.0868, KL: 0.0324, Current Beta: 0.0001) | Avg Valid Loss: 0.0789 | Avg Valid recon Loss: 0.0789\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0728, recon=0.0728, kl=0.0210, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0845 (Recon: 0.0845, KL: 0.0252, Current Beta: 0.0001) | Avg Valid Loss: 0.0777 | Avg Valid recon Loss: 0.0777\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0613, recon=0.0613, kl=0.0237, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0811 (Recon: 0.0811, KL: 0.0231, Current Beta: 0.0001) | Avg Valid Loss: 0.0751 | Avg Valid recon Loss: 0.0751\n",
      "\n",
      "[VRAE Run 242/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2167, recon=0.2167, kl=29.2564, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3156 (Recon: 0.3156, KL: 16.2281, Current Beta: 0.0000) | Avg Valid Loss: 0.1450 | Avg Valid recon Loss: 0.1450\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0837, recon=0.0837, kl=35.0706, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1229 (Recon: 0.1229, KL: 32.8279, Current Beta: 0.0000) | Avg Valid Loss: 0.0919 | Avg Valid recon Loss: 0.0919\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0762, recon=0.0762, kl=39.0935, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0966 (Recon: 0.0966, KL: 37.5883, Current Beta: 0.0000) | Avg Valid Loss: 0.0751 | Avg Valid recon Loss: 0.0751\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0587, recon=0.0587, kl=41.7024, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0789 (Recon: 0.0789, KL: 41.1325, Current Beta: 0.0000) | Avg Valid Loss: 0.0674 | Avg Valid recon Loss: 0.0674\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0618, recon=0.0618, kl=44.3135, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0709 (Recon: 0.0709, KL: 44.8207, Current Beta: 0.0000) | Avg Valid Loss: 0.0623 | Avg Valid recon Loss: 0.0623\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1773, recon=0.1773, kl=45.2910, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0627 (Recon: 0.0627, KL: 44.9892, Current Beta: 0.0000) | Avg Valid Loss: 0.0548 | Avg Valid recon Loss: 0.0548\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0445, recon=0.0445, kl=44.2314, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0580 (Recon: 0.0580, KL: 44.8192, Current Beta: 0.0000) | Avg Valid Loss: 0.0503 | Avg Valid recon Loss: 0.0503\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0453, recon=0.0453, kl=37.0203, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0534, KL: 40.1065, Current Beta: 0.0000) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0499\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0632, recon=0.0632, kl=26.4611, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0512 (Recon: 0.0512, KL: 30.2055, Current Beta: 0.0000) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0450\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0524, recon=0.0524, kl=14.4191, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0477 (Recon: 0.0476, KL: 19.0816, Current Beta: 0.0000) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1175, recon=0.1174, kl=8.5168, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0446, KL: 11.0890, Current Beta: 0.0000) | Avg Valid Loss: 0.0416 | Avg Valid recon Loss: 0.0416\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0301, recon=0.0301, kl=4.4989, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0432, KL: 5.4382, Current Beta: 0.0000) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0397\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0342, recon=0.0342, kl=1.0048, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 1.4199, Current Beta: 0.0000) | Avg Valid Loss: 0.0396 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0350, recon=0.0350, kl=0.1316, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0413 (Recon: 0.0413, KL: 0.2288, Current Beta: 0.0000) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0366, recon=0.0366, kl=0.0603, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0418, KL: 0.0665, Current Beta: 0.0001) | Avg Valid Loss: 0.0382 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0508, recon=0.0508, kl=0.0143, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0399 (Recon: 0.0399, KL: 0.0181, Current Beta: 0.0001) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0402, recon=0.0402, kl=0.0051, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0390, KL: 0.0153, Current Beta: 0.0001) | Avg Valid Loss: 0.0350 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0357, recon=0.0357, kl=0.0133, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0373 (Recon: 0.0373, KL: 0.0090, Current Beta: 0.0001) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0345\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0327, recon=0.0327, kl=0.0090, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0371 (Recon: 0.0371, KL: 0.0093, Current Beta: 0.0001) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0332\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0264, recon=0.0264, kl=0.0050, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0366 (Recon: 0.0366, KL: 0.0104, Current Beta: 0.0001) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0345\n",
      "\n",
      "[VRAE Run 243/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5988, recon=0.5988, kl=2.8422, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6791 (Recon: 0.6791, KL: 1.0727, Current Beta: 0.0000) | Avg Valid Loss: 0.5030 | Avg Valid recon Loss: 0.5030\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3235, recon=0.3235, kl=29.7260, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3955 (Recon: 0.3955, KL: 18.6797, Current Beta: 0.0000) | Avg Valid Loss: 0.3306 | Avg Valid recon Loss: 0.3306\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1976, recon=0.1976, kl=55.0605, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2834 (Recon: 0.2834, KL: 46.1831, Current Beta: 0.0000) | Avg Valid Loss: 0.2373 | Avg Valid recon Loss: 0.2373\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1995, recon=0.1995, kl=71.1971, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2283 (Recon: 0.2283, KL: 65.2570, Current Beta: 0.0000) | Avg Valid Loss: 0.1886 | Avg Valid recon Loss: 0.1886\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1968, recon=0.1967, kl=84.4984, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1947 (Recon: 0.1947, KL: 79.8140, Current Beta: 0.0000) | Avg Valid Loss: 0.1608 | Avg Valid recon Loss: 0.1608\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1606, recon=0.1606, kl=92.2792, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1717 (Recon: 0.1717, KL: 90.1299, Current Beta: 0.0000) | Avg Valid Loss: 0.1426 | Avg Valid recon Loss: 0.1426\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1167, recon=0.1167, kl=94.1861, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1561 (Recon: 0.1561, KL: 93.7982, Current Beta: 0.0000) | Avg Valid Loss: 0.1285 | Avg Valid recon Loss: 0.1285\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1208, recon=0.1208, kl=91.6154, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1395 (Recon: 0.1395, KL: 93.1543, Current Beta: 0.0000) | Avg Valid Loss: 0.1204 | Avg Valid recon Loss: 0.1204\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1187, recon=0.1186, kl=77.4329, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1339 (Recon: 0.1339, KL: 84.3174, Current Beta: 0.0000) | Avg Valid Loss: 0.1128 | Avg Valid recon Loss: 0.1128\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1094, recon=0.1093, kl=43.2898, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1254 (Recon: 0.1253, KL: 57.7966, Current Beta: 0.0000) | Avg Valid Loss: 0.1071 | Avg Valid recon Loss: 0.1071\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1044, recon=0.1043, kl=18.9524, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1184 (Recon: 0.1184, KL: 26.5546, Current Beta: 0.0000) | Avg Valid Loss: 0.1012 | Avg Valid recon Loss: 0.1011\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0935, recon=0.0935, kl=8.2865, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1128 (Recon: 0.1127, KL: 11.5084, Current Beta: 0.0000) | Avg Valid Loss: 0.0984 | Avg Valid recon Loss: 0.0983\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.2720, recon=0.2719, kl=2.6329, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1082 (Recon: 0.1081, KL: 4.1213, Current Beta: 0.0000) | Avg Valid Loss: 0.0949 | Avg Valid recon Loss: 0.0948\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0764, recon=0.0764, kl=0.8618, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1028 (Recon: 0.1028, KL: 1.3109, Current Beta: 0.0000) | Avg Valid Loss: 0.0901 | Avg Valid recon Loss: 0.0901\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0924, recon=0.0924, kl=0.3719, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0992 (Recon: 0.0992, KL: 0.4743, Current Beta: 0.0001) | Avg Valid Loss: 0.0874 | Avg Valid recon Loss: 0.0874\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1229, recon=0.1229, kl=0.1190, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0954 (Recon: 0.0953, KL: 0.1688, Current Beta: 0.0001) | Avg Valid Loss: 0.0850 | Avg Valid recon Loss: 0.0850\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0739, recon=0.0739, kl=0.0729, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0918 (Recon: 0.0918, KL: 0.0878, Current Beta: 0.0001) | Avg Valid Loss: 0.0823 | Avg Valid recon Loss: 0.0823\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0687, recon=0.0687, kl=0.0607, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0887 (Recon: 0.0887, KL: 0.0596, Current Beta: 0.0001) | Avg Valid Loss: 0.0804 | Avg Valid recon Loss: 0.0804\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0683, recon=0.0683, kl=0.0351, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0839 (Recon: 0.0839, KL: 0.0412, Current Beta: 0.0001) | Avg Valid Loss: 0.0774 | Avg Valid recon Loss: 0.0774\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0703, recon=0.0703, kl=0.0229, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0850 (Recon: 0.0850, KL: 0.0286, Current Beta: 0.0001) | Avg Valid Loss: 0.0762 | Avg Valid recon Loss: 0.0762\n",
      "\n",
      "[VRAE Run 244/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1685, recon=0.1685, kl=63.8069, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3367 (Recon: 0.3367, KL: 35.3289, Current Beta: 0.0000) | Avg Valid Loss: 0.1446 | Avg Valid recon Loss: 0.1446\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1073, recon=0.1073, kl=83.1308, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1335 (Recon: 0.1335, KL: 77.5920, Current Beta: 0.0000) | Avg Valid Loss: 0.0955 | Avg Valid recon Loss: 0.0955\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2504, recon=0.2504, kl=85.3279, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1006 (Recon: 0.1006, KL: 84.2539, Current Beta: 0.0000) | Avg Valid Loss: 0.0793 | Avg Valid recon Loss: 0.0793\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0828, recon=0.0828, kl=85.1838, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0826 (Recon: 0.0826, KL: 84.6602, Current Beta: 0.0000) | Avg Valid Loss: 0.0676 | Avg Valid recon Loss: 0.0676\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0470, recon=0.0470, kl=90.5481, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0703 (Recon: 0.0703, KL: 88.6107, Current Beta: 0.0000) | Avg Valid Loss: 0.0608 | Avg Valid recon Loss: 0.0608\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0490, recon=0.0490, kl=86.6752, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0648 (Recon: 0.0648, KL: 89.0535, Current Beta: 0.0000) | Avg Valid Loss: 0.0558 | Avg Valid recon Loss: 0.0558\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0461, recon=0.0461, kl=86.4964, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0587 (Recon: 0.0587, KL: 84.6742, Current Beta: 0.0000) | Avg Valid Loss: 0.0538 | Avg Valid recon Loss: 0.0538\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0537, recon=0.0537, kl=70.7244, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0559 (Recon: 0.0559, KL: 78.3092, Current Beta: 0.0000) | Avg Valid Loss: 0.0498 | Avg Valid recon Loss: 0.0498\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0641, recon=0.0641, kl=49.1057, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0514 (Recon: 0.0514, KL: 57.0775, Current Beta: 0.0000) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0460\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=33.7662, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0500 (Recon: 0.0499, KL: 36.7733, Current Beta: 0.0000) | Avg Valid Loss: 0.0445 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0341, recon=0.0341, kl=18.7480, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0478 (Recon: 0.0477, KL: 21.7919, Current Beta: 0.0000) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0413, recon=0.0412, kl=6.3941, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0480, KL: 8.3162, Current Beta: 0.0000) | Avg Valid Loss: 0.0410 | Avg Valid recon Loss: 0.0409\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0334, recon=0.0333, kl=1.6299, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0432, KL: 2.1140, Current Beta: 0.0000) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0314, recon=0.0314, kl=0.2250, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0429, KL: 0.4712, Current Beta: 0.0000) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0392\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0316, recon=0.0316, kl=0.0720, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0413 (Recon: 0.0413, KL: 0.1708, Current Beta: 0.0001) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0340, recon=0.0340, kl=0.0200, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0400, KL: 0.0415, Current Beta: 0.0001) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0292, recon=0.0292, kl=0.0119, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0390, KL: 0.0134, Current Beta: 0.0001) | Avg Valid Loss: 0.0366 | Avg Valid recon Loss: 0.0366\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0303, recon=0.0303, kl=0.0057, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0389 (Recon: 0.0389, KL: 0.0113, Current Beta: 0.0001) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0497, recon=0.0497, kl=0.0116, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0370, KL: 0.0109, Current Beta: 0.0001) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0246, recon=0.0246, kl=0.0065, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0370, KL: 0.0104, Current Beta: 0.0001) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0338\n",
      "\n",
      "[VRAE Run 245/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4984, recon=0.4984, kl=2.4094, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.7184 (Recon: 0.7184, KL: 1.0140, Current Beta: 0.0000) | Avg Valid Loss: 0.5388 | Avg Valid recon Loss: 0.5388\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3585, recon=0.3585, kl=52.4503, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4165 (Recon: 0.4165, KL: 31.2268, Current Beta: 0.0000) | Avg Valid Loss: 0.3479 | Avg Valid recon Loss: 0.3479\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2562, recon=0.2562, kl=94.6270, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2960 (Recon: 0.2960, KL: 79.9375, Current Beta: 0.0000) | Avg Valid Loss: 0.2472 | Avg Valid recon Loss: 0.2472\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1673, recon=0.1673, kl=119.1678, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2343 (Recon: 0.2343, KL: 110.5213, Current Beta: 0.0000) | Avg Valid Loss: 0.1924 | Avg Valid recon Loss: 0.1924\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1580, recon=0.1580, kl=134.5143, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1971 (Recon: 0.1971, KL: 128.9984, Current Beta: 0.0000) | Avg Valid Loss: 0.1632 | Avg Valid recon Loss: 0.1632\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1381, recon=0.1380, kl=143.2033, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1742 (Recon: 0.1742, KL: 140.8510, Current Beta: 0.0000) | Avg Valid Loss: 0.1440 | Avg Valid recon Loss: 0.1440\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1223, recon=0.1223, kl=140.0216, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1573 (Recon: 0.1573, KL: 140.8937, Current Beta: 0.0000) | Avg Valid Loss: 0.1308 | Avg Valid recon Loss: 0.1308\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1367, recon=0.1367, kl=132.7514, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1329 (Recon: 0.1329, KL: 136.3297, Current Beta: 0.0000) | Avg Valid Loss: 0.1212 | Avg Valid recon Loss: 0.1212\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1080, recon=0.1079, kl=106.9861, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1298 (Recon: 0.1298, KL: 118.5845, Current Beta: 0.0000) | Avg Valid Loss: 0.1134 | Avg Valid recon Loss: 0.1134\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1001, recon=0.1001, kl=58.2604, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1250 (Recon: 0.1249, KL: 78.3161, Current Beta: 0.0000) | Avg Valid Loss: 0.1080 | Avg Valid recon Loss: 0.1079\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0920, recon=0.0919, kl=21.7400, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1174 (Recon: 0.1173, KL: 32.6289, Current Beta: 0.0000) | Avg Valid Loss: 0.1028 | Avg Valid recon Loss: 0.1027\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0808, recon=0.0807, kl=8.4185, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1115 (Recon: 0.1114, KL: 12.1549, Current Beta: 0.0000) | Avg Valid Loss: 0.0987 | Avg Valid recon Loss: 0.0986\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0736, recon=0.0735, kl=3.3549, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1066 (Recon: 0.1065, KL: 4.4190, Current Beta: 0.0000) | Avg Valid Loss: 0.0954 | Avg Valid recon Loss: 0.0953\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0911, recon=0.0911, kl=1.3148, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1025 (Recon: 0.1025, KL: 1.5930, Current Beta: 0.0000) | Avg Valid Loss: 0.0909 | Avg Valid recon Loss: 0.0909\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0855, recon=0.0854, kl=0.6147, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0981 (Recon: 0.0980, KL: 0.6883, Current Beta: 0.0001) | Avg Valid Loss: 0.0878 | Avg Valid recon Loss: 0.0878\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0743, recon=0.0743, kl=0.1924, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0940 (Recon: 0.0940, KL: 0.2652, Current Beta: 0.0001) | Avg Valid Loss: 0.0855 | Avg Valid recon Loss: 0.0854\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0582, recon=0.0582, kl=0.1253, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0903 (Recon: 0.0903, KL: 0.1426, Current Beta: 0.0001) | Avg Valid Loss: 0.0824 | Avg Valid recon Loss: 0.0824\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0798, recon=0.0798, kl=0.0817, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0890 (Recon: 0.0890, KL: 0.0850, Current Beta: 0.0001) | Avg Valid Loss: 0.0815 | Avg Valid recon Loss: 0.0815\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0560, recon=0.0560, kl=0.0430, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0774 (Recon: 0.0774, KL: 0.0628, Current Beta: 0.0001) | Avg Valid Loss: 0.0783 | Avg Valid recon Loss: 0.0783\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0690, recon=0.0690, kl=0.0433, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0834 (Recon: 0.0834, KL: 0.0406, Current Beta: 0.0001) | Avg Valid Loss: 0.0770 | Avg Valid recon Loss: 0.0770\n",
      "\n",
      "[VRAE Run 246/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1458, recon=0.1458, kl=119.5075, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3284 (Recon: 0.3284, KL: 61.9639, Current Beta: 0.0000) | Avg Valid Loss: 0.1414 | Avg Valid recon Loss: 0.1414\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1060, recon=0.1060, kl=149.4991, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1322 (Recon: 0.1322, KL: 140.5162, Current Beta: 0.0000) | Avg Valid Loss: 0.0965 | Avg Valid recon Loss: 0.0965\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0752, recon=0.0752, kl=153.6169, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0972 (Recon: 0.0972, KL: 151.4243, Current Beta: 0.0000) | Avg Valid Loss: 0.0776 | Avg Valid recon Loss: 0.0776\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1187, recon=0.1187, kl=151.6715, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0803 (Recon: 0.0803, KL: 152.3144, Current Beta: 0.0000) | Avg Valid Loss: 0.0772 | Avg Valid recon Loss: 0.0772\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0717, recon=0.0717, kl=161.3858, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0714 (Recon: 0.0714, KL: 156.9032, Current Beta: 0.0000) | Avg Valid Loss: 0.0634 | Avg Valid recon Loss: 0.0634\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0479, recon=0.0479, kl=155.6978, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0638 (Recon: 0.0638, KL: 158.3598, Current Beta: 0.0000) | Avg Valid Loss: 0.0562 | Avg Valid recon Loss: 0.0562\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0494, recon=0.0494, kl=139.5573, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0534, KL: 146.5970, Current Beta: 0.0000) | Avg Valid Loss: 0.0527 | Avg Valid recon Loss: 0.0527\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0715, recon=0.0715, kl=103.4291, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0563 (Recon: 0.0563, KL: 117.9394, Current Beta: 0.0000) | Avg Valid Loss: 0.0543 | Avg Valid recon Loss: 0.0543\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0417, recon=0.0417, kl=71.7037, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0529, KL: 84.9675, Current Beta: 0.0000) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0368, recon=0.0368, kl=59.9932, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0501 (Recon: 0.0500, KL: 56.5448, Current Beta: 0.0000) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0372, recon=0.0371, kl=25.6979, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0479, KL: 33.9723, Current Beta: 0.0000) | Avg Valid Loss: 0.0442 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0367, recon=0.0366, kl=11.6965, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0469, KL: 14.1039, Current Beta: 0.0000) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0357, recon=0.0357, kl=3.1631, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0444 (Recon: 0.0444, KL: 3.6447, Current Beta: 0.0000) | Avg Valid Loss: 0.0397 | Avg Valid recon Loss: 0.0397\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0510, recon=0.0510, kl=0.8335, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0439 (Recon: 0.0439, KL: 1.0304, Current Beta: 0.0000) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0360, recon=0.0360, kl=0.2373, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0427 (Recon: 0.0427, KL: 0.3359, Current Beta: 0.0001) | Avg Valid Loss: 0.0396 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0455, recon=0.0455, kl=0.0552, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0412 (Recon: 0.0412, KL: 0.1188, Current Beta: 0.0001) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=0.0430, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0407 (Recon: 0.0407, KL: 0.0627, Current Beta: 0.0001) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0389, recon=0.0389, kl=0.0426, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0399 (Recon: 0.0399, KL: 0.0428, Current Beta: 0.0001) | Avg Valid Loss: 0.0362 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0496, recon=0.0496, kl=0.0546, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0385 (Recon: 0.0385, KL: 0.0407, Current Beta: 0.0001) | Avg Valid Loss: 0.0344 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0346, recon=0.0346, kl=0.0264, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0379 (Recon: 0.0379, KL: 0.0523, Current Beta: 0.0001) | Avg Valid Loss: 0.0348 | Avg Valid recon Loss: 0.0348\n",
      "\n",
      "[VRAE Run 247/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3035, recon=0.3035, kl=5.3134, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5192 (Recon: 0.5192, KL: 1.6871, Current Beta: 0.0000) | Avg Valid Loss: 0.2934 | Avg Valid recon Loss: 0.2934\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1977, recon=0.1977, kl=28.3427, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2381 (Recon: 0.2381, KL: 20.9655, Current Beta: 0.0000) | Avg Valid Loss: 0.1695 | Avg Valid recon Loss: 0.1695\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1476, recon=0.1476, kl=37.2989, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1793 (Recon: 0.1793, KL: 33.6159, Current Beta: 0.0000) | Avg Valid Loss: 0.1337 | Avg Valid recon Loss: 0.1337\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1761, recon=0.1761, kl=53.8183, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1520 (Recon: 0.1520, KL: 46.7777, Current Beta: 0.0000) | Avg Valid Loss: 0.1152 | Avg Valid recon Loss: 0.1152\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0896, recon=0.0896, kl=67.9577, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1343 (Recon: 0.1343, KL: 63.2817, Current Beta: 0.0000) | Avg Valid Loss: 0.1053 | Avg Valid recon Loss: 0.1053\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0944, recon=0.0944, kl=64.2747, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1211 (Recon: 0.1211, KL: 65.7327, Current Beta: 0.0000) | Avg Valid Loss: 0.0935 | Avg Valid recon Loss: 0.0935\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0803, recon=0.0803, kl=56.1135, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1109 (Recon: 0.1109, KL: 58.2425, Current Beta: 0.0000) | Avg Valid Loss: 0.0870 | Avg Valid recon Loss: 0.0870\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0752, recon=0.0752, kl=50.8192, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1020 (Recon: 0.1020, KL: 52.9223, Current Beta: 0.0000) | Avg Valid Loss: 0.0817 | Avg Valid recon Loss: 0.0816\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0938, recon=0.0938, kl=40.1051, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0943 (Recon: 0.0943, KL: 44.6955, Current Beta: 0.0000) | Avg Valid Loss: 0.0778 | Avg Valid recon Loss: 0.0777\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0710, recon=0.0709, kl=22.3441, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0895 (Recon: 0.0895, KL: 29.0631, Current Beta: 0.0000) | Avg Valid Loss: 0.0743 | Avg Valid recon Loss: 0.0742\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0635, recon=0.0635, kl=9.9032, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0835 (Recon: 0.0835, KL: 13.2290, Current Beta: 0.0000) | Avg Valid Loss: 0.0706 | Avg Valid recon Loss: 0.0706\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0637, recon=0.0636, kl=4.5860, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0793 (Recon: 0.0792, KL: 5.2845, Current Beta: 0.0000) | Avg Valid Loss: 0.0683 | Avg Valid recon Loss: 0.0682\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0523, recon=0.0523, kl=1.5342, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0756 (Recon: 0.0756, KL: 1.9804, Current Beta: 0.0000) | Avg Valid Loss: 0.0653 | Avg Valid recon Loss: 0.0653\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0575, recon=0.0574, kl=0.6758, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0728 (Recon: 0.0727, KL: 0.7985, Current Beta: 0.0000) | Avg Valid Loss: 0.0651 | Avg Valid recon Loss: 0.0650\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0589, recon=0.0589, kl=0.2989, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0705 (Recon: 0.0704, KL: 0.3320, Current Beta: 0.0001) | Avg Valid Loss: 0.0610 | Avg Valid recon Loss: 0.0610\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0492, recon=0.0492, kl=0.1142, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0680 (Recon: 0.0680, KL: 0.1408, Current Beta: 0.0001) | Avg Valid Loss: 0.0594 | Avg Valid recon Loss: 0.0594\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0757, recon=0.0757, kl=0.0538, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0679 (Recon: 0.0678, KL: 0.0974, Current Beta: 0.0001) | Avg Valid Loss: 0.0579 | Avg Valid recon Loss: 0.0579\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0650, recon=0.0650, kl=0.0599, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0637 (Recon: 0.0637, KL: 0.0662, Current Beta: 0.0001) | Avg Valid Loss: 0.0567 | Avg Valid recon Loss: 0.0567\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0764, recon=0.0763, kl=0.0791, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0620 (Recon: 0.0620, KL: 0.0615, Current Beta: 0.0001) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0558\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0409, recon=0.0409, kl=0.0546, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0603 (Recon: 0.0603, KL: 0.0534, Current Beta: 0.0001) | Avg Valid Loss: 0.0538 | Avg Valid recon Loss: 0.0538\n",
      "\n",
      "[VRAE Run 248/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1420, recon=0.1420, kl=26.6802, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2748 (Recon: 0.2748, KL: 17.4603, Current Beta: 0.0000) | Avg Valid Loss: 0.1194 | Avg Valid recon Loss: 0.1194\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0964, recon=0.0964, kl=29.0963, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1063 (Recon: 0.1063, KL: 27.4290, Current Beta: 0.0000) | Avg Valid Loss: 0.0819 | Avg Valid recon Loss: 0.0819\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0661, recon=0.0661, kl=35.7680, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0786 (Recon: 0.0786, KL: 33.1586, Current Beta: 0.0000) | Avg Valid Loss: 0.0599 | Avg Valid recon Loss: 0.0599\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0539, recon=0.0539, kl=35.4150, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0663 (Recon: 0.0663, KL: 36.1899, Current Beta: 0.0000) | Avg Valid Loss: 0.0533 | Avg Valid recon Loss: 0.0533\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0630, recon=0.0630, kl=37.9795, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0580 (Recon: 0.0580, KL: 37.3929, Current Beta: 0.0000) | Avg Valid Loss: 0.0494 | Avg Valid recon Loss: 0.0494\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0460, recon=0.0460, kl=38.7960, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0521 (Recon: 0.0521, KL: 38.8459, Current Beta: 0.0000) | Avg Valid Loss: 0.0453 | Avg Valid recon Loss: 0.0453\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0454, recon=0.0454, kl=37.1884, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 38.7727, Current Beta: 0.0000) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0410, recon=0.0410, kl=30.4614, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0444 (Recon: 0.0444, KL: 33.6668, Current Beta: 0.0000) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0332, recon=0.0332, kl=23.3075, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0418, KL: 26.3051, Current Beta: 0.0000) | Avg Valid Loss: 0.0362 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0518, recon=0.0518, kl=64.9742, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0622 (Recon: 0.0621, KL: 38.4699, Current Beta: 0.0000) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0394\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0525, recon=0.0523, kl=61.1317, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0465, KL: 59.5246, Current Beta: 0.0000) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0414, recon=0.0410, kl=50.8809, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0391, KL: 55.7723, Current Beta: 0.0000) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0373, recon=0.0367, kl=35.1341, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0364 (Recon: 0.0356, KL: 41.7931, Current Beta: 0.0000) | Avg Valid Loss: 0.0336 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0259, recon=0.0251, kl=20.4718, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0352, KL: 25.5814, Current Beta: 0.0000) | Avg Valid Loss: 0.0325 | Avg Valid recon Loss: 0.0318\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0268, recon=0.0263, kl=7.8626, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0351 (Recon: 0.0343, KL: 11.8055, Current Beta: 0.0001) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0314\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0285, recon=0.0282, kl=3.1388, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0348 (Recon: 0.0343, KL: 4.6038, Current Beta: 0.0001) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0397, recon=0.0396, kl=1.6587, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0355 (Recon: 0.0353, KL: 2.0282, Current Beta: 0.0001) | Avg Valid Loss: 0.0333 | Avg Valid recon Loss: 0.0331\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0649, recon=0.0648, kl=1.2224, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0342 (Recon: 0.0340, KL: 1.3627, Current Beta: 0.0001) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0306\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0384, recon=0.0383, kl=0.6861, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0342 (Recon: 0.0341, KL: 0.8248, Current Beta: 0.0001) | Avg Valid Loss: 0.0325 | Avg Valid recon Loss: 0.0324\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0591, recon=0.0591, kl=0.5906, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0328 (Recon: 0.0327, KL: 0.6702, Current Beta: 0.0001) | Avg Valid Loss: 0.0301 | Avg Valid recon Loss: 0.0300\n",
      "\n",
      "[VRAE Run 249/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2690, recon=0.2690, kl=10.6138, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5092 (Recon: 0.5092, KL: 3.5078, Current Beta: 0.0000) | Avg Valid Loss: 0.2931 | Avg Valid recon Loss: 0.2931\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1806, recon=0.1806, kl=51.9007, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2413 (Recon: 0.2413, KL: 36.1375, Current Beta: 0.0000) | Avg Valid Loss: 0.1722 | Avg Valid recon Loss: 0.1722\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1785, recon=0.1785, kl=78.4688, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1754 (Recon: 0.1754, KL: 69.2109, Current Beta: 0.0000) | Avg Valid Loss: 0.1347 | Avg Valid recon Loss: 0.1347\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1128, recon=0.1128, kl=95.4754, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1528 (Recon: 0.1528, KL: 89.0772, Current Beta: 0.0000) | Avg Valid Loss: 0.1164 | Avg Valid recon Loss: 0.1164\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1126, recon=0.1126, kl=105.4272, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1356 (Recon: 0.1356, KL: 101.9306, Current Beta: 0.0000) | Avg Valid Loss: 0.1044 | Avg Valid recon Loss: 0.1044\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1238, recon=0.1238, kl=104.5562, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1223 (Recon: 0.1223, KL: 105.1140, Current Beta: 0.0000) | Avg Valid Loss: 0.0943 | Avg Valid recon Loss: 0.0942\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0800, recon=0.0799, kl=101.8821, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1129 (Recon: 0.1129, KL: 103.1698, Current Beta: 0.0000) | Avg Valid Loss: 0.0898 | Avg Valid recon Loss: 0.0898\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0977, recon=0.0977, kl=88.5773, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1034 (Recon: 0.1034, KL: 94.3444, Current Beta: 0.0000) | Avg Valid Loss: 0.0843 | Avg Valid recon Loss: 0.0842\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0852, recon=0.0851, kl=57.5390, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0953 (Recon: 0.0952, KL: 72.4004, Current Beta: 0.0000) | Avg Valid Loss: 0.0778 | Avg Valid recon Loss: 0.0778\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0786, recon=0.0786, kl=26.0209, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0924 (Recon: 0.0924, KL: 38.0522, Current Beta: 0.0000) | Avg Valid Loss: 0.0761 | Avg Valid recon Loss: 0.0761\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0725, recon=0.0724, kl=10.2599, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0865 (Recon: 0.0865, KL: 14.9454, Current Beta: 0.0000) | Avg Valid Loss: 0.0716 | Avg Valid recon Loss: 0.0716\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0592, recon=0.0591, kl=3.9474, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0805 (Recon: 0.0804, KL: 5.6079, Current Beta: 0.0000) | Avg Valid Loss: 0.0692 | Avg Valid recon Loss: 0.0692\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0656, recon=0.0655, kl=1.3667, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0775 (Recon: 0.0775, KL: 1.8099, Current Beta: 0.0000) | Avg Valid Loss: 0.0670 | Avg Valid recon Loss: 0.0670\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0981, recon=0.0981, kl=0.4617, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0750 (Recon: 0.0750, KL: 0.6231, Current Beta: 0.0000) | Avg Valid Loss: 0.0646 | Avg Valid recon Loss: 0.0646\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0552, recon=0.0552, kl=0.1516, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0717 (Recon: 0.0717, KL: 0.1714, Current Beta: 0.0001) | Avg Valid Loss: 0.0624 | Avg Valid recon Loss: 0.0624\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0616, recon=0.0616, kl=0.0600, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0689 (Recon: 0.0689, KL: 0.0682, Current Beta: 0.0001) | Avg Valid Loss: 0.0612 | Avg Valid recon Loss: 0.0612\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0598, recon=0.0598, kl=0.0444, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0654 (Recon: 0.0654, KL: 0.0414, Current Beta: 0.0001) | Avg Valid Loss: 0.0590 | Avg Valid recon Loss: 0.0590\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0431, recon=0.0431, kl=0.0335, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0657 (Recon: 0.0657, KL: 0.0307, Current Beta: 0.0001) | Avg Valid Loss: 0.0582 | Avg Valid recon Loss: 0.0582\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0642, recon=0.0642, kl=0.0452, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0634 (Recon: 0.0634, KL: 0.0295, Current Beta: 0.0001) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0566\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0450, recon=0.0450, kl=0.0301, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0616 (Recon: 0.0616, KL: 0.0278, Current Beta: 0.0001) | Avg Valid Loss: 0.0553 | Avg Valid recon Loss: 0.0553\n",
      "\n",
      "[VRAE Run 250/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1416, recon=0.1416, kl=45.0852, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2981 (Recon: 0.2981, KL: 21.8925, Current Beta: 0.0000) | Avg Valid Loss: 0.1306 | Avg Valid recon Loss: 0.1306\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0731, recon=0.0731, kl=59.0604, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1148 (Recon: 0.1148, KL: 59.6124, Current Beta: 0.0000) | Avg Valid Loss: 0.0790 | Avg Valid recon Loss: 0.0790\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0588, recon=0.0588, kl=67.2645, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0809 (Recon: 0.0809, KL: 63.7404, Current Beta: 0.0000) | Avg Valid Loss: 0.0648 | Avg Valid recon Loss: 0.0648\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0668, recon=0.0668, kl=72.5249, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0661 (Recon: 0.0661, KL: 69.7399, Current Beta: 0.0000) | Avg Valid Loss: 0.0559 | Avg Valid recon Loss: 0.0559\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0474, recon=0.0474, kl=72.3412, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0574 (Recon: 0.0574, KL: 71.9966, Current Beta: 0.0000) | Avg Valid Loss: 0.0473 | Avg Valid recon Loss: 0.0473\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0432, recon=0.0432, kl=72.3872, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0513 (Recon: 0.0513, KL: 70.3623, Current Beta: 0.0000) | Avg Valid Loss: 0.0448 | Avg Valid recon Loss: 0.0448\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0300, recon=0.0300, kl=107.1711, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0470 (Recon: 0.0470, KL: 105.0313, Current Beta: 0.0000) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0426\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0328, recon=0.0327, kl=61.9771, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0449, KL: 73.6358, Current Beta: 0.0000) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=44.2843, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0419 (Recon: 0.0419, KL: 46.9134, Current Beta: 0.0000) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0318, recon=0.0317, kl=25.0699, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0388 (Recon: 0.0388, KL: 28.7500, Current Beta: 0.0000) | Avg Valid Loss: 0.0367 | Avg Valid recon Loss: 0.0367\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0251, recon=0.0251, kl=12.5667, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0369 (Recon: 0.0369, KL: 15.4935, Current Beta: 0.0000) | Avg Valid Loss: 0.0331 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0277, recon=0.0277, kl=5.5881, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0362, KL: 7.0774, Current Beta: 0.0000) | Avg Valid Loss: 0.0331 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0756, recon=0.0756, kl=1.4189, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0342 (Recon: 0.0342, KL: 2.0973, Current Beta: 0.0000) | Avg Valid Loss: 0.0322 | Avg Valid recon Loss: 0.0322\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=0.4316, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0342 (Recon: 0.0342, KL: 0.5511, Current Beta: 0.0000) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0330\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0288, recon=0.0288, kl=0.1054, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0333 (Recon: 0.0333, KL: 0.1256, Current Beta: 0.0001) | Avg Valid Loss: 0.0312 | Avg Valid recon Loss: 0.0311\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0228, recon=0.0228, kl=0.0276, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0347 (Recon: 0.0347, KL: 0.0473, Current Beta: 0.0001) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0428, recon=0.0428, kl=0.0261, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0350 (Recon: 0.0350, KL: 0.0461, Current Beta: 0.0001) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0307, recon=0.0307, kl=0.0152, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0345 (Recon: 0.0344, KL: 0.0134, Current Beta: 0.0001) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0304\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0339, recon=0.0339, kl=0.0928, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0314 (Recon: 0.0314, KL: 0.0634, Current Beta: 0.0001) | Avg Valid Loss: 0.0310 | Avg Valid recon Loss: 0.0310\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0243, recon=0.0243, kl=0.0295, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0326 (Recon: 0.0326, KL: 0.0564, Current Beta: 0.0001) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0306\n",
      "\n",
      "[VRAE Run 251/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3373, recon=0.3373, kl=15.4683, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5085 (Recon: 0.5085, KL: 4.3625, Current Beta: 0.0000) | Avg Valid Loss: 0.2912 | Avg Valid recon Loss: 0.2912\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1662, recon=0.1662, kl=95.8665, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2388 (Recon: 0.2388, KL: 71.0513, Current Beta: 0.0000) | Avg Valid Loss: 0.1711 | Avg Valid recon Loss: 0.1711\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1304, recon=0.1304, kl=128.5459, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1789 (Recon: 0.1789, KL: 118.6523, Current Beta: 0.0000) | Avg Valid Loss: 0.1337 | Avg Valid recon Loss: 0.1337\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1295, recon=0.1295, kl=151.3456, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1523 (Recon: 0.1523, KL: 142.0935, Current Beta: 0.0000) | Avg Valid Loss: 0.1166 | Avg Valid recon Loss: 0.1166\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0932, recon=0.0932, kl=175.7545, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1350 (Recon: 0.1350, KL: 166.4082, Current Beta: 0.0000) | Avg Valid Loss: 0.1028 | Avg Valid recon Loss: 0.1028\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0860, recon=0.0860, kl=183.0148, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1221 (Recon: 0.1221, KL: 183.1433, Current Beta: 0.0000) | Avg Valid Loss: 0.0943 | Avg Valid recon Loss: 0.0943\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0869, recon=0.0869, kl=173.1505, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1112 (Recon: 0.1112, KL: 177.6774, Current Beta: 0.0000) | Avg Valid Loss: 0.0860 | Avg Valid recon Loss: 0.0860\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0790, recon=0.0790, kl=155.2801, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1004 (Recon: 0.1004, KL: 162.4883, Current Beta: 0.0000) | Avg Valid Loss: 0.0832 | Avg Valid recon Loss: 0.0832\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0728, recon=0.0728, kl=108.5798, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0938 (Recon: 0.0938, KL: 129.4466, Current Beta: 0.0000) | Avg Valid Loss: 0.0774 | Avg Valid recon Loss: 0.0774\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0756, recon=0.0755, kl=46.4537, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0876 (Recon: 0.0875, KL: 68.4392, Current Beta: 0.0000) | Avg Valid Loss: 0.0734 | Avg Valid recon Loss: 0.0733\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0683, recon=0.0683, kl=18.3738, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0824 (Recon: 0.0823, KL: 27.8135, Current Beta: 0.0000) | Avg Valid Loss: 0.0692 | Avg Valid recon Loss: 0.0692\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0771, recon=0.0771, kl=6.3110, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0785 (Recon: 0.0784, KL: 9.3154, Current Beta: 0.0000) | Avg Valid Loss: 0.0669 | Avg Valid recon Loss: 0.0668\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0635, recon=0.0635, kl=2.0005, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0757 (Recon: 0.0757, KL: 2.7974, Current Beta: 0.0000) | Avg Valid Loss: 0.0650 | Avg Valid recon Loss: 0.0649\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0604, recon=0.0604, kl=0.5295, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0723 (Recon: 0.0723, KL: 0.8198, Current Beta: 0.0000) | Avg Valid Loss: 0.0624 | Avg Valid recon Loss: 0.0624\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0675, recon=0.0675, kl=0.2154, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0694 (Recon: 0.0694, KL: 0.2733, Current Beta: 0.0001) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0717, recon=0.0717, kl=0.0868, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0671 (Recon: 0.0671, KL: 0.1081, Current Beta: 0.0001) | Avg Valid Loss: 0.0591 | Avg Valid recon Loss: 0.0590\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0828, recon=0.0828, kl=0.0634, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0653 (Recon: 0.0653, KL: 0.0610, Current Beta: 0.0001) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0566\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0843, recon=0.0843, kl=0.0387, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0634 (Recon: 0.0634, KL: 0.0556, Current Beta: 0.0001) | Avg Valid Loss: 0.0556 | Avg Valid recon Loss: 0.0556\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0534, recon=0.0534, kl=0.0441, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0567 (Recon: 0.0567, KL: 0.0448, Current Beta: 0.0001) | Avg Valid Loss: 0.0550 | Avg Valid recon Loss: 0.0550\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0412, recon=0.0412, kl=0.0296, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0600 (Recon: 0.0600, KL: 0.0429, Current Beta: 0.0001) | Avg Valid Loss: 0.0533 | Avg Valid recon Loss: 0.0533\n",
      "\n",
      "[VRAE Run 252/324] Training with params: {'batch_size': 256, 'beta': 0.0001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1424, recon=0.1424, kl=95.1220, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2915 (Recon: 0.2915, KL: 48.3611, Current Beta: 0.0000) | Avg Valid Loss: 0.1205 | Avg Valid recon Loss: 0.1205\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0818, recon=0.0818, kl=121.8361, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1111 (Recon: 0.1111, KL: 108.9655, Current Beta: 0.0000) | Avg Valid Loss: 0.0859 | Avg Valid recon Loss: 0.0859\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0596, recon=0.0596, kl=128.4479, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0831 (Recon: 0.0831, KL: 124.7947, Current Beta: 0.0000) | Avg Valid Loss: 0.0639 | Avg Valid recon Loss: 0.0639\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0625, recon=0.0625, kl=151.2406, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0658 (Recon: 0.0658, KL: 141.1380, Current Beta: 0.0000) | Avg Valid Loss: 0.0619 | Avg Valid recon Loss: 0.0619\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0428, recon=0.0428, kl=137.7746, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0600 (Recon: 0.0600, KL: 146.7381, Current Beta: 0.0000) | Avg Valid Loss: 0.0491 | Avg Valid recon Loss: 0.0491\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0454, recon=0.0454, kl=116.8862, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0539 (Recon: 0.0539, KL: 122.3142, Current Beta: 0.0000) | Avg Valid Loss: 0.0451 | Avg Valid recon Loss: 0.0451\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0335, recon=0.0335, kl=119.7354, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0472, KL: 116.9954, Current Beta: 0.0000) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0430, recon=0.0430, kl=94.6239, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0449, KL: 110.3967, Current Beta: 0.0000) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0297, recon=0.0297, kl=69.5719, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0425, KL: 72.0281, Current Beta: 0.0000) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0402, recon=0.0402, kl=46.8267, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0406 (Recon: 0.0405, KL: 51.7439, Current Beta: 0.0000) | Avg Valid Loss: 0.0366 | Avg Valid recon Loss: 0.0366\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0260, recon=0.0259, kl=30.2512, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0396 (Recon: 0.0395, KL: 29.9283, Current Beta: 0.0000) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0411, recon=0.0410, kl=13.9507, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0383 (Recon: 0.0382, KL: 13.7055, Current Beta: 0.0000) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0303, recon=0.0302, kl=3.7168, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0371 (Recon: 0.0370, KL: 5.0523, Current Beta: 0.0000) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0327\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0267, recon=0.0266, kl=1.6389, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0353, KL: 1.6076, Current Beta: 0.0000) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0404, recon=0.0404, kl=0.3400, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0342 (Recon: 0.0342, KL: 0.5221, Current Beta: 0.0001) | Avg Valid Loss: 0.0319 | Avg Valid recon Loss: 0.0319\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=0.1144, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0347 (Recon: 0.0347, KL: 0.2207, Current Beta: 0.0001) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0316\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0283, recon=0.0283, kl=0.1390, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0348 (Recon: 0.0348, KL: 0.1214, Current Beta: 0.0001) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0358, recon=0.0358, kl=0.0617, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0334 (Recon: 0.0334, KL: 0.0774, Current Beta: 0.0001) | Avg Valid Loss: 0.0298 | Avg Valid recon Loss: 0.0298\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0236, recon=0.0236, kl=0.0478, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0325 (Recon: 0.0325, KL: 0.0503, Current Beta: 0.0001) | Avg Valid Loss: 0.0301 | Avg Valid recon Loss: 0.0301\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0272, recon=0.0272, kl=0.0280, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0327 (Recon: 0.0327, KL: 0.0311, Current Beta: 0.0001) | Avg Valid Loss: 0.0312 | Avg Valid recon Loss: 0.0311\n",
      "\n",
      "[VRAE Run 253/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.8891, recon=0.8891, kl=0.2400, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.9886 (Recon: 0.9886, KL: 0.2080, Current Beta: 0.0000) | Avg Valid Loss: 0.8349 | Avg Valid recon Loss: 0.8349\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.6103, recon=0.6103, kl=0.6210, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6702 (Recon: 0.6702, KL: 0.4134, Current Beta: 0.0000) | Avg Valid Loss: 0.5834 | Avg Valid recon Loss: 0.5834\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.4356, recon=0.4356, kl=4.1249, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5039 (Recon: 0.5039, KL: 2.4036, Current Beta: 0.0000) | Avg Valid Loss: 0.4631 | Avg Valid recon Loss: 0.4631\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.3882, recon=0.3882, kl=9.9127, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4201 (Recon: 0.4201, KL: 7.4687, Current Beta: 0.0000) | Avg Valid Loss: 0.3952 | Avg Valid recon Loss: 0.3952\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.3238, recon=0.3238, kl=15.4587, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3707 (Recon: 0.3707, KL: 13.2747, Current Beta: 0.0000) | Avg Valid Loss: 0.3479 | Avg Valid recon Loss: 0.3479\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2945, recon=0.2945, kl=18.2660, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3354 (Recon: 0.3354, KL: 17.3953, Current Beta: 0.0000) | Avg Valid Loss: 0.3112 | Avg Valid recon Loss: 0.3112\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2948, recon=0.2948, kl=17.6375, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3078 (Recon: 0.3078, KL: 18.1552, Current Beta: 0.0000) | Avg Valid Loss: 0.2823 | Avg Valid recon Loss: 0.2823\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.4134, recon=0.4133, kl=12.8428, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2855 (Recon: 0.2855, KL: 14.9079, Current Beta: 0.0000) | Avg Valid Loss: 0.2586 | Avg Valid recon Loss: 0.2586\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.2562, recon=0.2562, kl=6.1012, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2676 (Recon: 0.2676, KL: 8.6998, Current Beta: 0.0000) | Avg Valid Loss: 0.2390 | Avg Valid recon Loss: 0.2390\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1887, recon=0.1886, kl=1.4705, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2517 (Recon: 0.2517, KL: 2.8051, Current Beta: 0.0000) | Avg Valid Loss: 0.2226 | Avg Valid recon Loss: 0.2225\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.2166, recon=0.2166, kl=0.2892, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2378 (Recon: 0.2378, KL: 0.6503, Current Beta: 0.0000) | Avg Valid Loss: 0.2094 | Avg Valid recon Loss: 0.2094\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.2290, recon=0.2290, kl=0.0629, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.2242 (Recon: 0.2242, KL: 0.1470, Current Beta: 0.0001) | Avg Valid Loss: 0.1974 | Avg Valid recon Loss: 0.1974\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1733, recon=0.1733, kl=0.0085, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.2149 (Recon: 0.2149, KL: 0.0230, Current Beta: 0.0002) | Avg Valid Loss: 0.1872 | Avg Valid recon Loss: 0.1872\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.2062, recon=0.2062, kl=0.0028, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.2044 (Recon: 0.2044, KL: 0.0040, Current Beta: 0.0004) | Avg Valid Loss: 0.1776 | Avg Valid recon Loss: 0.1776\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.2280, recon=0.2280, kl=0.0027, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.1943 (Recon: 0.1943, KL: 0.0014, Current Beta: 0.0006) | Avg Valid Loss: 0.1694 | Avg Valid recon Loss: 0.1694\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1568, recon=0.1568, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1858 (Recon: 0.1858, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.1616 | Avg Valid recon Loss: 0.1616\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1761, recon=0.1761, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1779 (Recon: 0.1779, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.1558 | Avg Valid recon Loss: 0.1558\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1369, recon=0.1369, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1698 (Recon: 0.1698, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.1499 | Avg Valid recon Loss: 0.1499\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1730, recon=0.1730, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1635 (Recon: 0.1635, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.1445 | Avg Valid recon Loss: 0.1445\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.2118, recon=0.2118, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1573 (Recon: 0.1573, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.1392 | Avg Valid recon Loss: 0.1392\n",
      "\n",
      "[VRAE Run 254/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3073, recon=0.3073, kl=17.4640, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4761 (Recon: 0.4761, KL: 7.7776, Current Beta: 0.0000) | Avg Valid Loss: 0.2543 | Avg Valid recon Loss: 0.2543\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2543, recon=0.2543, kl=29.7751, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2261 (Recon: 0.2261, KL: 26.4731, Current Beta: 0.0000) | Avg Valid Loss: 0.1504 | Avg Valid recon Loss: 0.1504\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1128, recon=0.1128, kl=31.3828, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1548 (Recon: 0.1548, KL: 31.1455, Current Beta: 0.0000) | Avg Valid Loss: 0.1155 | Avg Valid recon Loss: 0.1155\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1280, recon=0.1280, kl=33.0930, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1229 (Recon: 0.1229, KL: 32.2428, Current Beta: 0.0000) | Avg Valid Loss: 0.0977 | Avg Valid recon Loss: 0.0977\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0874, recon=0.0874, kl=32.6778, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1057 (Recon: 0.1057, KL: 32.9314, Current Beta: 0.0000) | Avg Valid Loss: 0.0880 | Avg Valid recon Loss: 0.0880\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0891, recon=0.0891, kl=28.5076, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0950 (Recon: 0.0950, KL: 30.4431, Current Beta: 0.0000) | Avg Valid Loss: 0.0802 | Avg Valid recon Loss: 0.0802\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0610, recon=0.0610, kl=17.3890, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0861 (Recon: 0.0861, KL: 21.1905, Current Beta: 0.0000) | Avg Valid Loss: 0.0750 | Avg Valid recon Loss: 0.0750\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0611, recon=0.0611, kl=10.1705, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0801 (Recon: 0.0801, KL: 12.6769, Current Beta: 0.0000) | Avg Valid Loss: 0.0700 | Avg Valid recon Loss: 0.0700\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0624, recon=0.0624, kl=3.7399, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0756 (Recon: 0.0756, KL: 6.1333, Current Beta: 0.0000) | Avg Valid Loss: 0.0669 | Avg Valid recon Loss: 0.0669\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0555, recon=0.0555, kl=0.6662, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0715 (Recon: 0.0715, KL: 1.7729, Current Beta: 0.0000) | Avg Valid Loss: 0.0650 | Avg Valid recon Loss: 0.0650\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0576, recon=0.0576, kl=0.0910, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0689 (Recon: 0.0689, KL: 0.2410, Current Beta: 0.0000) | Avg Valid Loss: 0.0626 | Avg Valid recon Loss: 0.0626\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0543, recon=0.0543, kl=0.0249, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0655 (Recon: 0.0655, KL: 0.0356, Current Beta: 0.0001) | Avg Valid Loss: 0.0601 | Avg Valid recon Loss: 0.0601\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0497, recon=0.0497, kl=0.0029, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 0.0067, Current Beta: 0.0002) | Avg Valid Loss: 0.0590 | Avg Valid recon Loss: 0.0590\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0428, recon=0.0428, kl=0.0014, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0620 (Recon: 0.0620, KL: 0.0018, Current Beta: 0.0004) | Avg Valid Loss: 0.0584 | Avg Valid recon Loss: 0.0584\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0444, recon=0.0444, kl=0.0005, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0608 (Recon: 0.0608, KL: 0.0007, Current Beta: 0.0006) | Avg Valid Loss: 0.0556 | Avg Valid recon Loss: 0.0556\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0457, recon=0.0457, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0584 (Recon: 0.0584, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0547 | Avg Valid recon Loss: 0.0547\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0420, recon=0.0420, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0576 (Recon: 0.0576, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0537\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1591, recon=0.1591, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0555 (Recon: 0.0555, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0517 | Avg Valid recon Loss: 0.0517\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0409, recon=0.0409, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0551 (Recon: 0.0551, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0648, recon=0.0648, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0549 (Recon: 0.0549, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0499 | Avg Valid recon Loss: 0.0499\n",
      "\n",
      "[VRAE Run 255/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6472, recon=0.6472, kl=0.8096, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.8580 (Recon: 0.8580, KL: 0.5854, Current Beta: 0.0000) | Avg Valid Loss: 0.7148 | Avg Valid recon Loss: 0.7148\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.6024, recon=0.6024, kl=3.5201, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5941 (Recon: 0.5941, KL: 2.1279, Current Beta: 0.0000) | Avg Valid Loss: 0.5184 | Avg Valid recon Loss: 0.5184\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.3805, recon=0.3805, kl=15.7269, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4541 (Recon: 0.4541, KL: 10.0310, Current Beta: 0.0000) | Avg Valid Loss: 0.4146 | Avg Valid recon Loss: 0.4146\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.2828, recon=0.2828, kl=32.0735, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3818 (Recon: 0.3818, KL: 25.6916, Current Beta: 0.0000) | Avg Valid Loss: 0.3543 | Avg Valid recon Loss: 0.3543\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2880, recon=0.2880, kl=40.2255, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3375 (Recon: 0.3375, KL: 37.7215, Current Beta: 0.0000) | Avg Valid Loss: 0.3113 | Avg Valid recon Loss: 0.3113\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2548, recon=0.2548, kl=41.4335, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3066 (Recon: 0.3066, KL: 41.6629, Current Beta: 0.0000) | Avg Valid Loss: 0.2794 | Avg Valid recon Loss: 0.2794\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2598, recon=0.2598, kl=35.6818, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2802 (Recon: 0.2802, KL: 38.6881, Current Beta: 0.0000) | Avg Valid Loss: 0.2541 | Avg Valid recon Loss: 0.2541\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.2374, recon=0.2374, kl=21.3214, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2594 (Recon: 0.2594, KL: 27.3085, Current Beta: 0.0000) | Avg Valid Loss: 0.2330 | Avg Valid recon Loss: 0.2330\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.2317, recon=0.2317, kl=7.9409, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2465 (Recon: 0.2464, KL: 12.4239, Current Beta: 0.0000) | Avg Valid Loss: 0.2156 | Avg Valid recon Loss: 0.2155\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.2182, recon=0.2182, kl=2.1045, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2256 (Recon: 0.2256, KL: 3.8482, Current Beta: 0.0000) | Avg Valid Loss: 0.2010 | Avg Valid recon Loss: 0.2010\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1803, recon=0.1803, kl=0.6053, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2187 (Recon: 0.2186, KL: 1.1085, Current Beta: 0.0000) | Avg Valid Loss: 0.1884 | Avg Valid recon Loss: 0.1884\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.2065, recon=0.2065, kl=0.1604, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.2077 (Recon: 0.2077, KL: 0.3111, Current Beta: 0.0001) | Avg Valid Loss: 0.1786 | Avg Valid recon Loss: 0.1786\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1763, recon=0.1763, kl=0.0166, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.1956 (Recon: 0.1956, KL: 0.0574, Current Beta: 0.0002) | Avg Valid Loss: 0.1696 | Avg Valid recon Loss: 0.1696\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.2083, recon=0.2083, kl=0.0036, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.1881 (Recon: 0.1881, KL: 0.0048, Current Beta: 0.0004) | Avg Valid Loss: 0.1613 | Avg Valid recon Loss: 0.1613\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1587, recon=0.1587, kl=0.0009, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.1797 (Recon: 0.1797, KL: 0.0011, Current Beta: 0.0006) | Avg Valid Loss: 0.1543 | Avg Valid recon Loss: 0.1543\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1654, recon=0.1654, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1717 (Recon: 0.1717, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.1482 | Avg Valid recon Loss: 0.1482\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1278, recon=0.1278, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1653 (Recon: 0.1653, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.1427 | Avg Valid recon Loss: 0.1427\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1200, recon=0.1200, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1576 (Recon: 0.1576, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.1373 | Avg Valid recon Loss: 0.1373\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1266, recon=0.1266, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1538 (Recon: 0.1538, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.1333 | Avg Valid recon Loss: 0.1333\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.3548, recon=0.3548, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1474 (Recon: 0.1474, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.1288 | Avg Valid recon Loss: 0.1288\n",
      "\n",
      "[VRAE Run 256/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2661, recon=0.2661, kl=36.4163, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4387 (Recon: 0.4387, KL: 16.8335, Current Beta: 0.0000) | Avg Valid Loss: 0.2349 | Avg Valid recon Loss: 0.2349\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1765, recon=0.1765, kl=48.3201, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2160 (Recon: 0.2160, KL: 46.3195, Current Beta: 0.0000) | Avg Valid Loss: 0.1470 | Avg Valid recon Loss: 0.1470\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1096, recon=0.1096, kl=55.6194, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1509 (Recon: 0.1509, KL: 53.1690, Current Beta: 0.0000) | Avg Valid Loss: 0.1145 | Avg Valid recon Loss: 0.1145\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0990, recon=0.0990, kl=57.8975, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1219 (Recon: 0.1219, KL: 57.0322, Current Beta: 0.0000) | Avg Valid Loss: 0.0949 | Avg Valid recon Loss: 0.0949\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0771, recon=0.0771, kl=54.2784, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1042 (Recon: 0.1042, KL: 57.7865, Current Beta: 0.0000) | Avg Valid Loss: 0.0867 | Avg Valid recon Loss: 0.0867\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0939, recon=0.0939, kl=46.6071, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0922 (Recon: 0.0922, KL: 49.8012, Current Beta: 0.0000) | Avg Valid Loss: 0.0795 | Avg Valid recon Loss: 0.0795\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0677, recon=0.0677, kl=26.9545, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0839 (Recon: 0.0838, KL: 34.5040, Current Beta: 0.0000) | Avg Valid Loss: 0.0740 | Avg Valid recon Loss: 0.0739\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0715, recon=0.0715, kl=15.0811, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0786 (Recon: 0.0786, KL: 19.0708, Current Beta: 0.0000) | Avg Valid Loss: 0.0690 | Avg Valid recon Loss: 0.0690\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0604, recon=0.0604, kl=4.8761, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0720 (Recon: 0.0719, KL: 8.2827, Current Beta: 0.0000) | Avg Valid Loss: 0.0663 | Avg Valid recon Loss: 0.0663\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0513, recon=0.0513, kl=1.1189, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0690 (Recon: 0.0690, KL: 2.0977, Current Beta: 0.0000) | Avg Valid Loss: 0.0636 | Avg Valid recon Loss: 0.0636\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0610, recon=0.0609, kl=0.3540, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0678 (Recon: 0.0678, KL: 0.4802, Current Beta: 0.0000) | Avg Valid Loss: 0.0612 | Avg Valid recon Loss: 0.0612\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1169, recon=0.1169, kl=0.0639, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0652 (Recon: 0.0652, KL: 0.0838, Current Beta: 0.0001) | Avg Valid Loss: 0.0596 | Avg Valid recon Loss: 0.0596\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0484, recon=0.0484, kl=0.0082, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0626 (Recon: 0.0626, KL: 0.0120, Current Beta: 0.0002) | Avg Valid Loss: 0.0572 | Avg Valid recon Loss: 0.0572\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0755, recon=0.0755, kl=0.0040, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0616 (Recon: 0.0616, KL: 0.0049, Current Beta: 0.0004) | Avg Valid Loss: 0.0564 | Avg Valid recon Loss: 0.0564\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0470, recon=0.0470, kl=0.0008, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0595 (Recon: 0.0595, KL: 0.0012, Current Beta: 0.0006) | Avg Valid Loss: 0.0549 | Avg Valid recon Loss: 0.0549\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0448, recon=0.0448, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0584 (Recon: 0.0584, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0537\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0935, recon=0.0935, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0571 (Recon: 0.0571, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0525 | Avg Valid recon Loss: 0.0525\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0461, recon=0.0461, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1575, recon=0.1575, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0547, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0507 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0389, recon=0.0389, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0548 (Recon: 0.0548, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0496\n",
      "\n",
      "[VRAE Run 257/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7396, recon=0.7396, kl=1.0725, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.9127 (Recon: 0.9127, KL: 0.9097, Current Beta: 0.0000) | Avg Valid Loss: 0.7628 | Avg Valid recon Loss: 0.7628\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.5283, recon=0.5283, kl=4.5057, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6156 (Recon: 0.6156, KL: 2.5581, Current Beta: 0.0000) | Avg Valid Loss: 0.5426 | Avg Valid recon Loss: 0.5426\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.4143, recon=0.4143, kl=31.4649, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4724 (Recon: 0.4724, KL: 19.4906, Current Beta: 0.0000) | Avg Valid Loss: 0.4383 | Avg Valid recon Loss: 0.4383\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.3172, recon=0.3172, kl=59.1965, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3960 (Recon: 0.3960, KL: 49.0424, Current Beta: 0.0000) | Avg Valid Loss: 0.3742 | Avg Valid recon Loss: 0.3742\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.3482, recon=0.3482, kl=73.9322, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3497 (Recon: 0.3497, KL: 69.1491, Current Beta: 0.0000) | Avg Valid Loss: 0.3266 | Avg Valid recon Loss: 0.3266\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2958, recon=0.2958, kl=76.2182, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3146 (Recon: 0.3146, KL: 76.3443, Current Beta: 0.0000) | Avg Valid Loss: 0.2889 | Avg Valid recon Loss: 0.2889\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2730, recon=0.2730, kl=61.5481, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2880 (Recon: 0.2879, KL: 68.5259, Current Beta: 0.0000) | Avg Valid Loss: 0.2595 | Avg Valid recon Loss: 0.2595\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.2109, recon=0.2109, kl=32.0156, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2656 (Recon: 0.2655, KL: 44.0174, Current Beta: 0.0000) | Avg Valid Loss: 0.2358 | Avg Valid recon Loss: 0.2358\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1708, recon=0.1707, kl=10.1965, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2472 (Recon: 0.2472, KL: 17.5804, Current Beta: 0.0000) | Avg Valid Loss: 0.2171 | Avg Valid recon Loss: 0.2171\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.2581, recon=0.2580, kl=2.4789, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2314 (Recon: 0.2313, KL: 4.8089, Current Beta: 0.0000) | Avg Valid Loss: 0.2023 | Avg Valid recon Loss: 0.2023\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1845, recon=0.1845, kl=0.5091, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2195 (Recon: 0.2195, KL: 1.0773, Current Beta: 0.0000) | Avg Valid Loss: 0.1900 | Avg Valid recon Loss: 0.1900\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1548, recon=0.1548, kl=0.0797, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.2085 (Recon: 0.2084, KL: 0.2155, Current Beta: 0.0001) | Avg Valid Loss: 0.1793 | Avg Valid recon Loss: 0.1793\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1584, recon=0.1584, kl=0.0061, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.1985 (Recon: 0.1985, KL: 0.0253, Current Beta: 0.0002) | Avg Valid Loss: 0.1704 | Avg Valid recon Loss: 0.1704\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.2309, recon=0.2309, kl=0.0037, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.1891 (Recon: 0.1891, KL: 0.0040, Current Beta: 0.0004) | Avg Valid Loss: 0.1627 | Avg Valid recon Loss: 0.1627\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.2335, recon=0.2335, kl=0.0008, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.1815 (Recon: 0.1815, KL: 0.0012, Current Beta: 0.0006) | Avg Valid Loss: 0.1555 | Avg Valid recon Loss: 0.1555\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1517, recon=0.1517, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1611 (Recon: 0.1611, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.1501 | Avg Valid recon Loss: 0.1501\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1365, recon=0.1365, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1658 (Recon: 0.1658, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.1443 | Avg Valid recon Loss: 0.1443\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1389, recon=0.1389, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1567 (Recon: 0.1567, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.1387 | Avg Valid recon Loss: 0.1387\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1205, recon=0.1205, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1524 (Recon: 0.1524, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.1343 | Avg Valid recon Loss: 0.1343\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1464, recon=0.1464, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1449 (Recon: 0.1449, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.1299 | Avg Valid recon Loss: 0.1299\n",
      "\n",
      "[VRAE Run 258/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2644, recon=0.2644, kl=36.7565, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4232 (Recon: 0.4232, KL: 19.6124, Current Beta: 0.0000) | Avg Valid Loss: 0.2216 | Avg Valid recon Loss: 0.2216\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1393, recon=0.1393, kl=73.2219, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2093 (Recon: 0.2093, KL: 53.1737, Current Beta: 0.0000) | Avg Valid Loss: 0.1392 | Avg Valid recon Loss: 0.1392\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1032, recon=0.1032, kl=109.4469, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1446 (Recon: 0.1446, KL: 104.1254, Current Beta: 0.0000) | Avg Valid Loss: 0.1106 | Avg Valid recon Loss: 0.1106\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0752, recon=0.0752, kl=102.7401, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1163 (Recon: 0.1163, KL: 105.7577, Current Beta: 0.0000) | Avg Valid Loss: 0.0936 | Avg Valid recon Loss: 0.0936\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1306, recon=0.1306, kl=98.8768, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0997 (Recon: 0.0997, KL: 100.7651, Current Beta: 0.0000) | Avg Valid Loss: 0.0852 | Avg Valid recon Loss: 0.0852\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0713, recon=0.0713, kl=71.4085, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0917 (Recon: 0.0917, KL: 83.7141, Current Beta: 0.0000) | Avg Valid Loss: 0.0782 | Avg Valid recon Loss: 0.0782\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0871, recon=0.0870, kl=43.3627, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0755 (Recon: 0.0755, KL: 51.8478, Current Beta: 0.0000) | Avg Valid Loss: 0.0729 | Avg Valid recon Loss: 0.0729\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0522, recon=0.0522, kl=21.3187, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0791 (Recon: 0.0791, KL: 29.2202, Current Beta: 0.0000) | Avg Valid Loss: 0.0704 | Avg Valid recon Loss: 0.0704\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0561, recon=0.0560, kl=7.1664, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0757 (Recon: 0.0757, KL: 10.0975, Current Beta: 0.0000) | Avg Valid Loss: 0.0660 | Avg Valid recon Loss: 0.0660\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0729, recon=0.0729, kl=1.1540, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0725 (Recon: 0.0724, KL: 2.7423, Current Beta: 0.0000) | Avg Valid Loss: 0.0655 | Avg Valid recon Loss: 0.0655\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0645, recon=0.0645, kl=0.2399, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0687 (Recon: 0.0687, KL: 0.5265, Current Beta: 0.0000) | Avg Valid Loss: 0.0620 | Avg Valid recon Loss: 0.0620\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0576, recon=0.0576, kl=0.0619, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0669 (Recon: 0.0669, KL: 0.0794, Current Beta: 0.0001) | Avg Valid Loss: 0.0596 | Avg Valid recon Loss: 0.0596\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0573, recon=0.0573, kl=0.0043, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0653 (Recon: 0.0653, KL: 0.0108, Current Beta: 0.0002) | Avg Valid Loss: 0.0590 | Avg Valid recon Loss: 0.0590\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0569, recon=0.0569, kl=0.0037, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0634 (Recon: 0.0634, KL: 0.0046, Current Beta: 0.0004) | Avg Valid Loss: 0.0576 | Avg Valid recon Loss: 0.0576\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1740, recon=0.1740, kl=0.0014, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0613 (Recon: 0.0613, KL: 0.0015, Current Beta: 0.0006) | Avg Valid Loss: 0.0563 | Avg Valid recon Loss: 0.0563\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0439, recon=0.0439, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0605 (Recon: 0.0605, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0553 | Avg Valid recon Loss: 0.0553\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0602, recon=0.0602, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0594 (Recon: 0.0594, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0529 | Avg Valid recon Loss: 0.0529\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1657, recon=0.1657, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0548 (Recon: 0.0548, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0525 | Avg Valid recon Loss: 0.0525\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0657, recon=0.0657, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0512 | Avg Valid recon Loss: 0.0512\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0402, recon=0.0402, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0556 (Recon: 0.0556, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0504 | Avg Valid recon Loss: 0.0504\n",
      "\n",
      "[VRAE Run 259/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4797, recon=0.4797, kl=0.5178, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.7455 (Recon: 0.7455, KL: 0.2755, Current Beta: 0.0000) | Avg Valid Loss: 0.5250 | Avg Valid recon Loss: 0.5250\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3538, recon=0.3538, kl=9.2830, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4235 (Recon: 0.4235, KL: 4.7512, Current Beta: 0.0000) | Avg Valid Loss: 0.3584 | Avg Valid recon Loss: 0.3584\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2806, recon=0.2806, kl=19.6352, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3164 (Recon: 0.3164, KL: 15.8326, Current Beta: 0.0000) | Avg Valid Loss: 0.2712 | Avg Valid recon Loss: 0.2712\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1988, recon=0.1988, kl=28.4445, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2627 (Recon: 0.2627, KL: 24.9391, Current Beta: 0.0000) | Avg Valid Loss: 0.2209 | Avg Valid recon Loss: 0.2209\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2090, recon=0.2090, kl=32.6703, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2292 (Recon: 0.2292, KL: 31.3681, Current Beta: 0.0000) | Avg Valid Loss: 0.1897 | Avg Valid recon Loss: 0.1897\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1573, recon=0.1573, kl=32.6298, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2042 (Recon: 0.2042, KL: 33.6881, Current Beta: 0.0000) | Avg Valid Loss: 0.1680 | Avg Valid recon Loss: 0.1680\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1435, recon=0.1435, kl=25.8459, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1875 (Recon: 0.1875, KL: 28.8012, Current Beta: 0.0000) | Avg Valid Loss: 0.1522 | Avg Valid recon Loss: 0.1522\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1605, recon=0.1605, kl=12.4249, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1740 (Recon: 0.1740, KL: 18.0279, Current Beta: 0.0000) | Avg Valid Loss: 0.1409 | Avg Valid recon Loss: 0.1409\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.2317, recon=0.2317, kl=3.8533, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1614 (Recon: 0.1614, KL: 6.7432, Current Beta: 0.0000) | Avg Valid Loss: 0.1315 | Avg Valid recon Loss: 0.1314\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1317, recon=0.1317, kl=1.1375, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1509 (Recon: 0.1509, KL: 2.0039, Current Beta: 0.0000) | Avg Valid Loss: 0.1237 | Avg Valid recon Loss: 0.1237\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1246, recon=0.1246, kl=0.2584, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1427 (Recon: 0.1427, KL: 0.4281, Current Beta: 0.0000) | Avg Valid Loss: 0.1173 | Avg Valid recon Loss: 0.1173\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1352, recon=0.1352, kl=0.0326, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1352 (Recon: 0.1352, KL: 0.0903, Current Beta: 0.0001) | Avg Valid Loss: 0.1119 | Avg Valid recon Loss: 0.1119\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0969, recon=0.0969, kl=0.0029, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.1281 (Recon: 0.1281, KL: 0.0105, Current Beta: 0.0002) | Avg Valid Loss: 0.1060 | Avg Valid recon Loss: 0.1060\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1080, recon=0.1079, kl=0.0015, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.1210 (Recon: 0.1210, KL: 0.0023, Current Beta: 0.0004) | Avg Valid Loss: 0.1021 | Avg Valid recon Loss: 0.1021\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1661, recon=0.1661, kl=0.0004, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.1157 (Recon: 0.1157, KL: 0.0008, Current Beta: 0.0006) | Avg Valid Loss: 0.0978 | Avg Valid recon Loss: 0.0978\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0833, recon=0.0833, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1115 (Recon: 0.1115, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0943 | Avg Valid recon Loss: 0.0943\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0862, recon=0.0862, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1071 (Recon: 0.1071, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0912 | Avg Valid recon Loss: 0.0912\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0978, recon=0.0978, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1027 (Recon: 0.1027, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0885 | Avg Valid recon Loss: 0.0885\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0916, recon=0.0916, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0977 (Recon: 0.0977, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0858 | Avg Valid recon Loss: 0.0858\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0785, recon=0.0785, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0968 (Recon: 0.0968, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0840 | Avg Valid recon Loss: 0.0840\n",
      "\n",
      "[VRAE Run 260/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2143, recon=0.2143, kl=31.5765, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3483 (Recon: 0.3483, KL: 18.1066, Current Beta: 0.0000) | Avg Valid Loss: 0.1484 | Avg Valid recon Loss: 0.1484\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1997, recon=0.1997, kl=34.1286, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1521 (Recon: 0.1521, KL: 34.0244, Current Beta: 0.0000) | Avg Valid Loss: 0.1010 | Avg Valid recon Loss: 0.1010\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0888, recon=0.0888, kl=35.7078, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1066 (Recon: 0.1066, KL: 34.8531, Current Beta: 0.0000) | Avg Valid Loss: 0.0816 | Avg Valid recon Loss: 0.0816\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0621, recon=0.0621, kl=37.5615, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0886 (Recon: 0.0886, KL: 37.3105, Current Beta: 0.0000) | Avg Valid Loss: 0.0720 | Avg Valid recon Loss: 0.0720\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0503, recon=0.0503, kl=34.7253, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0772 (Recon: 0.0772, KL: 36.1860, Current Beta: 0.0000) | Avg Valid Loss: 0.0663 | Avg Valid recon Loss: 0.0663\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0525, recon=0.0525, kl=26.6385, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0712 (Recon: 0.0711, KL: 29.5565, Current Beta: 0.0000) | Avg Valid Loss: 0.0624 | Avg Valid recon Loss: 0.0624\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1189, recon=0.1189, kl=16.0876, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0659 (Recon: 0.0659, KL: 20.2740, Current Beta: 0.0000) | Avg Valid Loss: 0.0595 | Avg Valid recon Loss: 0.0595\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1110, recon=0.1110, kl=10.7237, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0633 (Recon: 0.0633, KL: 12.0909, Current Beta: 0.0000) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0460, recon=0.0460, kl=4.5339, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0593 (Recon: 0.0593, KL: 6.0362, Current Beta: 0.0000) | Avg Valid Loss: 0.0522 | Avg Valid recon Loss: 0.0522\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0396, recon=0.0396, kl=1.3912, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0566 (Recon: 0.0566, KL: 1.9581, Current Beta: 0.0000) | Avg Valid Loss: 0.0597 | Avg Valid recon Loss: 0.0596\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0425, recon=0.0425, kl=0.3134, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0563 (Recon: 0.0563, KL: 0.3953, Current Beta: 0.0000) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0492\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=0.0542, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 0.0632, Current Beta: 0.0001) | Avg Valid Loss: 0.0476 | Avg Valid recon Loss: 0.0476\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0456, recon=0.0456, kl=0.0076, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0508 (Recon: 0.0508, KL: 0.0105, Current Beta: 0.0002) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0458\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0628, recon=0.0628, kl=0.0028, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0492 (Recon: 0.0492, KL: 0.0035, Current Beta: 0.0004) | Avg Valid Loss: 0.0445 | Avg Valid recon Loss: 0.0445\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0309, recon=0.0309, kl=0.0012, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0483 (Recon: 0.0483, KL: 0.0013, Current Beta: 0.0006) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0582, recon=0.0582, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0473, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0428 | Avg Valid recon Loss: 0.0428\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0328, recon=0.0328, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0461 (Recon: 0.0461, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0430\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0365, recon=0.0365, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0449 (Recon: 0.0449, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0561, recon=0.0561, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0443 (Recon: 0.0442, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0405 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0461, recon=0.0461, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0438, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0399\n",
      "\n",
      "[VRAE Run 261/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5817, recon=0.5817, kl=0.7300, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.7284 (Recon: 0.7284, KL: 0.4280, Current Beta: 0.0000) | Avg Valid Loss: 0.4903 | Avg Valid recon Loss: 0.4903\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3321, recon=0.3321, kl=23.4615, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3958 (Recon: 0.3958, KL: 10.7063, Current Beta: 0.0000) | Avg Valid Loss: 0.3401 | Avg Valid recon Loss: 0.3401\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.3193, recon=0.3193, kl=41.7087, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3018 (Recon: 0.3018, KL: 36.5172, Current Beta: 0.0000) | Avg Valid Loss: 0.2615 | Avg Valid recon Loss: 0.2615\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.2364, recon=0.2364, kl=51.9090, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2546 (Recon: 0.2546, KL: 48.1191, Current Beta: 0.0000) | Avg Valid Loss: 0.2177 | Avg Valid recon Loss: 0.2177\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2696, recon=0.2696, kl=55.9588, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2233 (Recon: 0.2233, KL: 55.0468, Current Beta: 0.0000) | Avg Valid Loss: 0.1877 | Avg Valid recon Loss: 0.1877\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1525, recon=0.1524, kl=53.4632, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2014 (Recon: 0.2013, KL: 54.9770, Current Beta: 0.0000) | Avg Valid Loss: 0.1672 | Avg Valid recon Loss: 0.1672\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1568, recon=0.1567, kl=38.2826, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1847 (Recon: 0.1846, KL: 45.0334, Current Beta: 0.0000) | Avg Valid Loss: 0.1516 | Avg Valid recon Loss: 0.1516\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1408, recon=0.1408, kl=16.8197, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1709 (Recon: 0.1709, KL: 25.0614, Current Beta: 0.0000) | Avg Valid Loss: 0.1397 | Avg Valid recon Loss: 0.1397\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1486, recon=0.1485, kl=5.5754, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1593 (Recon: 0.1593, KL: 9.0260, Current Beta: 0.0000) | Avg Valid Loss: 0.1309 | Avg Valid recon Loss: 0.1309\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1371, recon=0.1371, kl=1.2728, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1505 (Recon: 0.1505, KL: 2.5097, Current Beta: 0.0000) | Avg Valid Loss: 0.1233 | Avg Valid recon Loss: 0.1233\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1088, recon=0.1088, kl=0.2242, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1438 (Recon: 0.1437, KL: 0.5885, Current Beta: 0.0000) | Avg Valid Loss: 0.1173 | Avg Valid recon Loss: 0.1173\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1284, recon=0.1284, kl=0.0347, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1253 (Recon: 0.1253, KL: 0.0848, Current Beta: 0.0001) | Avg Valid Loss: 0.1111 | Avg Valid recon Loss: 0.1111\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1246, recon=0.1246, kl=0.0158, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.1200 (Recon: 0.1200, KL: 0.0127, Current Beta: 0.0002) | Avg Valid Loss: 0.1070 | Avg Valid recon Loss: 0.1070\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1034, recon=0.1034, kl=0.0023, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.1231 (Recon: 0.1231, KL: 0.0034, Current Beta: 0.0004) | Avg Valid Loss: 0.1025 | Avg Valid recon Loss: 0.1025\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1591, recon=0.1591, kl=0.0011, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.1170 (Recon: 0.1170, KL: 0.0012, Current Beta: 0.0006) | Avg Valid Loss: 0.0984 | Avg Valid recon Loss: 0.0984\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0797, recon=0.0797, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1123 (Recon: 0.1123, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0945 | Avg Valid recon Loss: 0.0945\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0950, recon=0.0950, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1083 (Recon: 0.1083, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0923 | Avg Valid recon Loss: 0.0923\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0844, recon=0.0844, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1044 (Recon: 0.1044, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0893 | Avg Valid recon Loss: 0.0893\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1077, recon=0.1077, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1005 (Recon: 0.1005, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0860 | Avg Valid recon Loss: 0.0860\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0850, recon=0.0850, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0959 (Recon: 0.0959, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0843 | Avg Valid recon Loss: 0.0843\n",
      "\n",
      "[VRAE Run 262/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1727, recon=0.1727, kl=34.6054, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3588 (Recon: 0.3588, KL: 19.5496, Current Beta: 0.0000) | Avg Valid Loss: 0.1530 | Avg Valid recon Loss: 0.1530\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1487, recon=0.1487, kl=63.4495, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1585 (Recon: 0.1585, KL: 50.6889, Current Beta: 0.0000) | Avg Valid Loss: 0.1082 | Avg Valid recon Loss: 0.1082\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0893, recon=0.0893, kl=70.5105, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1109 (Recon: 0.1109, KL: 70.6873, Current Beta: 0.0000) | Avg Valid Loss: 0.0837 | Avg Valid recon Loss: 0.0837\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0764, recon=0.0764, kl=67.3856, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0915 (Recon: 0.0915, KL: 68.8984, Current Beta: 0.0000) | Avg Valid Loss: 0.0737 | Avg Valid recon Loss: 0.0737\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0627, recon=0.0627, kl=69.6392, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0799 (Recon: 0.0799, KL: 68.3482, Current Beta: 0.0000) | Avg Valid Loss: 0.0702 | Avg Valid recon Loss: 0.0702\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0518, recon=0.0517, kl=53.2907, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0734 (Recon: 0.0734, KL: 60.3388, Current Beta: 0.0000) | Avg Valid Loss: 0.0635 | Avg Valid recon Loss: 0.0635\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0487, recon=0.0487, kl=34.5441, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0673 (Recon: 0.0673, KL: 41.9217, Current Beta: 0.0000) | Avg Valid Loss: 0.0626 | Avg Valid recon Loss: 0.0625\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0501, recon=0.0501, kl=19.1898, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0649 (Recon: 0.0649, KL: 23.1482, Current Beta: 0.0000) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0574\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0393, recon=0.0393, kl=8.5870, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0601 (Recon: 0.0601, KL: 11.3684, Current Beta: 0.0000) | Avg Valid Loss: 0.0555 | Avg Valid recon Loss: 0.0554\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0490, recon=0.0490, kl=3.2829, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0585 (Recon: 0.0585, KL: 4.0104, Current Beta: 0.0000) | Avg Valid Loss: 0.0531 | Avg Valid recon Loss: 0.0531\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0624, recon=0.0624, kl=0.7576, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0563 (Recon: 0.0563, KL: 1.0429, Current Beta: 0.0000) | Avg Valid Loss: 0.0508 | Avg Valid recon Loss: 0.0507\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0425, recon=0.0425, kl=0.0903, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0539 (Recon: 0.0539, KL: 0.1924, Current Beta: 0.0001) | Avg Valid Loss: 0.0557 | Avg Valid recon Loss: 0.0556\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0427, recon=0.0427, kl=0.0149, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0533 (Recon: 0.0533, KL: 0.0276, Current Beta: 0.0002) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0478\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0440, recon=0.0440, kl=0.0043, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0502, KL: 0.0065, Current Beta: 0.0004) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0375, recon=0.0375, kl=0.0021, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0494, KL: 0.0025, Current Beta: 0.0006) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0456\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0456, recon=0.0456, kl=0.0009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0466, KL: 0.0013, Current Beta: 0.0010) | Avg Valid Loss: 0.0446 | Avg Valid recon Loss: 0.0446\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0354, recon=0.0354, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0437 | Avg Valid recon Loss: 0.0437\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0371, recon=0.0371, kl=0.0010, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0466, KL: 0.0015, Current Beta: 0.0010) | Avg Valid Loss: 0.0448 | Avg Valid recon Loss: 0.0448\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0383, recon=0.0383, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 0.0012, Current Beta: 0.0010) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0343, recon=0.0343, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0457, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0412\n",
      "\n",
      "[VRAE Run 263/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5061, recon=0.5061, kl=1.1835, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.7461 (Recon: 0.7461, KL: 0.6928, Current Beta: 0.0000) | Avg Valid Loss: 0.5086 | Avg Valid recon Loss: 0.5086\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.4104, recon=0.4104, kl=42.6497, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4053 (Recon: 0.4053, KL: 21.0503, Current Beta: 0.0000) | Avg Valid Loss: 0.3435 | Avg Valid recon Loss: 0.3435\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2010, recon=0.2010, kl=80.3978, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3065 (Recon: 0.3065, KL: 67.8132, Current Beta: 0.0000) | Avg Valid Loss: 0.2600 | Avg Valid recon Loss: 0.2600\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.2016, recon=0.2015, kl=96.7744, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2554 (Recon: 0.2554, KL: 91.1645, Current Beta: 0.0000) | Avg Valid Loss: 0.2141 | Avg Valid recon Loss: 0.2141\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1785, recon=0.1785, kl=104.4207, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2212 (Recon: 0.2212, KL: 102.1132, Current Beta: 0.0000) | Avg Valid Loss: 0.1831 | Avg Valid recon Loss: 0.1831\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1600, recon=0.1599, kl=98.6765, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1987 (Recon: 0.1987, KL: 102.4616, Current Beta: 0.0000) | Avg Valid Loss: 0.1625 | Avg Valid recon Loss: 0.1625\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1478, recon=0.1478, kl=65.7893, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1822 (Recon: 0.1821, KL: 80.6009, Current Beta: 0.0000) | Avg Valid Loss: 0.1463 | Avg Valid recon Loss: 0.1463\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1527, recon=0.1527, kl=22.7597, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1694 (Recon: 0.1693, KL: 38.1721, Current Beta: 0.0000) | Avg Valid Loss: 0.1357 | Avg Valid recon Loss: 0.1356\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1374, recon=0.1373, kl=6.7603, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1575 (Recon: 0.1575, KL: 11.4663, Current Beta: 0.0000) | Avg Valid Loss: 0.1266 | Avg Valid recon Loss: 0.1266\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1136, recon=0.1136, kl=1.3260, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1489 (Recon: 0.1488, KL: 2.7619, Current Beta: 0.0000) | Avg Valid Loss: 0.1196 | Avg Valid recon Loss: 0.1196\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1454, recon=0.1454, kl=0.2567, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1406 (Recon: 0.1406, KL: 0.4996, Current Beta: 0.0000) | Avg Valid Loss: 0.1140 | Avg Valid recon Loss: 0.1140\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1295, recon=0.1295, kl=0.0450, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1343 (Recon: 0.1343, KL: 0.0870, Current Beta: 0.0001) | Avg Valid Loss: 0.1085 | Avg Valid recon Loss: 0.1085\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1666, recon=0.1666, kl=0.0107, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.1274 (Recon: 0.1274, KL: 0.0145, Current Beta: 0.0002) | Avg Valid Loss: 0.1040 | Avg Valid recon Loss: 0.1040\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1064, recon=0.1064, kl=0.0021, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.1216 (Recon: 0.1216, KL: 0.0031, Current Beta: 0.0004) | Avg Valid Loss: 0.0998 | Avg Valid recon Loss: 0.0998\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1100, recon=0.1100, kl=0.0007, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.1163 (Recon: 0.1163, KL: 0.0010, Current Beta: 0.0006) | Avg Valid Loss: 0.0962 | Avg Valid recon Loss: 0.0962\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1042, recon=0.1042, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1119 (Recon: 0.1119, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0929 | Avg Valid recon Loss: 0.0929\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1029, recon=0.1029, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1078 (Recon: 0.1078, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0899 | Avg Valid recon Loss: 0.0899\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0769, recon=0.0769, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1027 (Recon: 0.1027, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0874 | Avg Valid recon Loss: 0.0874\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0908, recon=0.0908, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0999 (Recon: 0.0999, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0855 | Avg Valid recon Loss: 0.0855\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0828, recon=0.0828, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0966 (Recon: 0.0966, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0827 | Avg Valid recon Loss: 0.0827\n",
      "\n",
      "[VRAE Run 264/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1835, recon=0.1835, kl=90.2786, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3614 (Recon: 0.3614, KL: 49.3764, Current Beta: 0.0000) | Avg Valid Loss: 0.1533 | Avg Valid recon Loss: 0.1533\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3988, recon=0.3988, kl=120.3373, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1571 (Recon: 0.1571, KL: 119.5681, Current Beta: 0.0000) | Avg Valid Loss: 0.1097 | Avg Valid recon Loss: 0.1097\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0755, recon=0.0755, kl=126.0885, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1090 (Recon: 0.1090, KL: 123.6519, Current Beta: 0.0000) | Avg Valid Loss: 0.0828 | Avg Valid recon Loss: 0.0828\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0646, recon=0.0646, kl=125.9651, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0883 (Recon: 0.0883, KL: 126.0438, Current Beta: 0.0000) | Avg Valid Loss: 0.0724 | Avg Valid recon Loss: 0.0724\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0521, recon=0.0521, kl=112.8013, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0772 (Recon: 0.0772, KL: 118.1682, Current Beta: 0.0000) | Avg Valid Loss: 0.0663 | Avg Valid recon Loss: 0.0663\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0518, recon=0.0517, kl=78.9662, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0702 (Recon: 0.0702, KL: 89.3056, Current Beta: 0.0000) | Avg Valid Loss: 0.0627 | Avg Valid recon Loss: 0.0626\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0585, recon=0.0585, kl=49.4515, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0668 (Recon: 0.0667, KL: 58.6302, Current Beta: 0.0000) | Avg Valid Loss: 0.0576 | Avg Valid recon Loss: 0.0576\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0473, recon=0.0472, kl=32.3247, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0628 (Recon: 0.0627, KL: 35.8656, Current Beta: 0.0000) | Avg Valid Loss: 0.0553 | Avg Valid recon Loss: 0.0552\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0496, recon=0.0496, kl=13.3895, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0578 (Recon: 0.0577, KL: 15.3198, Current Beta: 0.0000) | Avg Valid Loss: 0.0528 | Avg Valid recon Loss: 0.0528\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0857, recon=0.0857, kl=4.1376, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0561 (Recon: 0.0561, KL: 4.5085, Current Beta: 0.0000) | Avg Valid Loss: 0.0514 | Avg Valid recon Loss: 0.0513\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0569, recon=0.0569, kl=0.8733, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0546 (Recon: 0.0546, KL: 1.1673, Current Beta: 0.0000) | Avg Valid Loss: 0.0492 | Avg Valid recon Loss: 0.0492\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0555, recon=0.0555, kl=0.1009, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0551 (Recon: 0.0551, KL: 0.2785, Current Beta: 0.0001) | Avg Valid Loss: 0.0490 | Avg Valid recon Loss: 0.0490\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0775, recon=0.0775, kl=0.0188, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0516, KL: 0.0299, Current Beta: 0.0002) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0465\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0339, recon=0.0339, kl=0.0022, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0491 (Recon: 0.0491, KL: 0.0042, Current Beta: 0.0004) | Avg Valid Loss: 0.0447 | Avg Valid recon Loss: 0.0447\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0456, recon=0.0456, kl=0.0017, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0496, KL: 0.0017, Current Beta: 0.0006) | Avg Valid Loss: 0.0439 | Avg Valid recon Loss: 0.0439\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0332, recon=0.0332, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0472, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0436\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0591, recon=0.0591, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0468 (Recon: 0.0468, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0358, recon=0.0358, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0451 (Recon: 0.0451, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0463, recon=0.0463, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0440 (Recon: 0.0440, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0427 | Avg Valid recon Loss: 0.0427\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0394, recon=0.0394, kl=0.0010, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0453 (Recon: 0.0453, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0409 | Avg Valid recon Loss: 0.0409\n",
      "\n",
      "[VRAE Run 265/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3549, recon=0.3549, kl=1.2889, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5650 (Recon: 0.5650, KL: 0.4669, Current Beta: 0.0000) | Avg Valid Loss: 0.3503 | Avg Valid recon Loss: 0.3503\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2036, recon=0.2036, kl=23.2989, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2735 (Recon: 0.2735, KL: 16.2012, Current Beta: 0.0000) | Avg Valid Loss: 0.2035 | Avg Valid recon Loss: 0.2035\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1666, recon=0.1666, kl=36.0543, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2025 (Recon: 0.2025, KL: 31.9765, Current Beta: 0.0000) | Avg Valid Loss: 0.1553 | Avg Valid recon Loss: 0.1553\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1318, recon=0.1318, kl=41.9368, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1715 (Recon: 0.1715, KL: 39.7126, Current Beta: 0.0000) | Avg Valid Loss: 0.1327 | Avg Valid recon Loss: 0.1327\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.3551, recon=0.3551, kl=42.2526, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1571 (Recon: 0.1571, KL: 42.0654, Current Beta: 0.0000) | Avg Valid Loss: 0.1174 | Avg Valid recon Loss: 0.1174\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.3409, recon=0.3409, kl=34.7805, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1437 (Recon: 0.1436, KL: 38.4861, Current Beta: 0.0000) | Avg Valid Loss: 0.1093 | Avg Valid recon Loss: 0.1093\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1398, recon=0.1398, kl=17.4723, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1333 (Recon: 0.1333, KL: 25.1209, Current Beta: 0.0000) | Avg Valid Loss: 0.1004 | Avg Valid recon Loss: 0.1004\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1290, recon=0.1290, kl=5.7697, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1245 (Recon: 0.1245, KL: 9.1775, Current Beta: 0.0000) | Avg Valid Loss: 0.0945 | Avg Valid recon Loss: 0.0945\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1557, recon=0.1557, kl=1.2884, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1163 (Recon: 0.1163, KL: 2.8147, Current Beta: 0.0000) | Avg Valid Loss: 0.0896 | Avg Valid recon Loss: 0.0896\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0870, recon=0.0870, kl=0.1926, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1099 (Recon: 0.1099, KL: 0.5296, Current Beta: 0.0000) | Avg Valid Loss: 0.0854 | Avg Valid recon Loss: 0.0854\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0896, recon=0.0896, kl=0.0443, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1038 (Recon: 0.1038, KL: 0.0832, Current Beta: 0.0000) | Avg Valid Loss: 0.0820 | Avg Valid recon Loss: 0.0820\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0718, recon=0.0718, kl=0.0109, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0977 (Recon: 0.0977, KL: 0.0166, Current Beta: 0.0001) | Avg Valid Loss: 0.0777 | Avg Valid recon Loss: 0.0777\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1767, recon=0.1767, kl=0.0051, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0931 (Recon: 0.0931, KL: 0.0042, Current Beta: 0.0002) | Avg Valid Loss: 0.0746 | Avg Valid recon Loss: 0.0746\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0685, recon=0.0685, kl=0.0004, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0885 (Recon: 0.0885, KL: 0.0012, Current Beta: 0.0004) | Avg Valid Loss: 0.0725 | Avg Valid recon Loss: 0.0725\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0698, recon=0.0698, kl=0.0003, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0849 (Recon: 0.0849, KL: 0.0006, Current Beta: 0.0006) | Avg Valid Loss: 0.0700 | Avg Valid recon Loss: 0.0700\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0585, recon=0.0585, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0749 (Recon: 0.0749, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0692 | Avg Valid recon Loss: 0.0692\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0634, recon=0.0634, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0793 (Recon: 0.0793, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0673 | Avg Valid recon Loss: 0.0673\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0641, recon=0.0641, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0744 (Recon: 0.0744, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0652 | Avg Valid recon Loss: 0.0652\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0856, recon=0.0856, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0743 (Recon: 0.0743, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.0636 | Avg Valid recon Loss: 0.0636\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0555, recon=0.0555, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0717 (Recon: 0.0717, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.0630 | Avg Valid recon Loss: 0.0630\n",
      "\n",
      "[VRAE Run 266/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1463, recon=0.1463, kl=23.7622, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2590 (Recon: 0.2590, KL: 14.3146, Current Beta: 0.0000) | Avg Valid Loss: 0.1085 | Avg Valid recon Loss: 0.1085\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1249, recon=0.1249, kl=30.8384, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1168 (Recon: 0.1168, KL: 28.5685, Current Beta: 0.0000) | Avg Valid Loss: 0.0856 | Avg Valid recon Loss: 0.0856\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2340, recon=0.2340, kl=35.3590, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0863 (Recon: 0.0863, KL: 34.2113, Current Beta: 0.0000) | Avg Valid Loss: 0.0657 | Avg Valid recon Loss: 0.0657\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0521, recon=0.0521, kl=33.4884, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0714 (Recon: 0.0714, KL: 36.3629, Current Beta: 0.0000) | Avg Valid Loss: 0.0603 | Avg Valid recon Loss: 0.0603\n",
      "Epoch 5/20\n",
      "Batch 20, loss=29421.7715, recon=29421.6582, kl=1518972.2500, beta=0.0000\n",
      "  â†’ Avg Train Loss: 1541.0218 (Recon: 1541.0158, KL: 79675.9419, Current Beta: 0.0000) | Avg Valid Loss: 0.0756 | Avg Valid recon Loss: 0.0745\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0574, recon=0.0574, kl=49.2589, beta=0.0000\n",
      "  â†’ Avg Train Loss: 14.8756 (Recon: 14.8754, KL: 1016.8701, Current Beta: 0.0000) | Avg Valid Loss: 0.0607 | Avg Valid recon Loss: 0.0607\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0450, recon=0.0450, kl=39.8435, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0622 (Recon: 0.0622, KL: 41.6715, Current Beta: 0.0000) | Avg Valid Loss: 0.0533 | Avg Valid recon Loss: 0.0533\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0519, recon=0.0518, kl=37.2651, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0565 (Recon: 0.0564, KL: 37.6614, Current Beta: 0.0000) | Avg Valid Loss: 0.0506 | Avg Valid recon Loss: 0.0506\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0469, recon=0.0467, kl=34.2121, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0543, KL: 35.4868, Current Beta: 0.0000) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0509\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0417, recon=0.0414, kl=28.2917, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0535 (Recon: 0.0532, KL: 30.6643, Current Beta: 0.0000) | Avg Valid Loss: 0.0470 | Avg Valid recon Loss: 0.0467\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0445, recon=0.0439, kl=21.6073, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0502 (Recon: 0.0495, KL: 24.1997, Current Beta: 0.0000) | Avg Valid Loss: 0.0451 | Avg Valid recon Loss: 0.0445\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0407, recon=0.0397, kl=12.8885, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0486 (Recon: 0.0474, KL: 16.3481, Current Beta: 0.0001) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0435\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0386, recon=0.0376, kl=5.8062, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0516 (Recon: 0.0500, KL: 8.2636, Current Beta: 0.0002) | Avg Valid Loss: 0.0476 | Avg Valid recon Loss: 0.0467\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0381, recon=0.0371, kl=2.4473, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0494 (Recon: 0.0480, KL: 3.7920, Current Beta: 0.0004) | Avg Valid Loss: 0.0425 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0371, recon=0.0360, kl=1.7971, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0471 (Recon: 0.0458, KL: 2.0959, Current Beta: 0.0006) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0364, recon=0.0355, kl=0.8960, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0444, KL: 1.1842, Current Beta: 0.0010) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0394\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0371, recon=0.0365, kl=0.6729, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0426, KL: 0.7516, Current Beta: 0.0010) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0381, recon=0.0377, kl=0.3447, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0425 (Recon: 0.0419, KL: 0.5245, Current Beta: 0.0010) | Avg Valid Loss: 0.0385 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0285, recon=0.0283, kl=0.2009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0413, KL: 0.3493, Current Beta: 0.0010) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0593, recon=0.0591, kl=0.2207, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0438 (Recon: 0.0436, KL: 0.2636, Current Beta: 0.0010) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0381\n",
      "\n",
      "[VRAE Run 267/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3193, recon=0.3193, kl=1.6136, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5303 (Recon: 0.5303, KL: 0.6403, Current Beta: 0.0000) | Avg Valid Loss: 0.3251 | Avg Valid recon Loss: 0.3251\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1942, recon=0.1942, kl=39.3458, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2567 (Recon: 0.2567, KL: 24.8644, Current Beta: 0.0000) | Avg Valid Loss: 0.1944 | Avg Valid recon Loss: 0.1944\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1686, recon=0.1686, kl=58.5180, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2004 (Recon: 0.2004, KL: 51.9085, Current Beta: 0.0000) | Avg Valid Loss: 0.1505 | Avg Valid recon Loss: 0.1505\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1280, recon=0.1280, kl=68.0246, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1707 (Recon: 0.1707, KL: 65.0318, Current Beta: 0.0000) | Avg Valid Loss: 0.1286 | Avg Valid recon Loss: 0.1286\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1363, recon=0.1363, kl=71.3203, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1521 (Recon: 0.1520, KL: 70.7117, Current Beta: 0.0000) | Avg Valid Loss: 0.1148 | Avg Valid recon Loss: 0.1147\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1202, recon=0.1202, kl=58.2884, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1403 (Recon: 0.1403, KL: 66.5457, Current Beta: 0.0000) | Avg Valid Loss: 0.1062 | Avg Valid recon Loss: 0.1062\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1100, recon=0.1100, kl=23.8685, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1305 (Recon: 0.1305, KL: 36.3211, Current Beta: 0.0000) | Avg Valid Loss: 0.0992 | Avg Valid recon Loss: 0.0992\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0889, recon=0.0889, kl=7.4682, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1218 (Recon: 0.1218, KL: 13.0915, Current Beta: 0.0000) | Avg Valid Loss: 0.0922 | Avg Valid recon Loss: 0.0922\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0773, recon=0.0773, kl=2.9646, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1132 (Recon: 0.1132, KL: 4.0482, Current Beta: 0.0000) | Avg Valid Loss: 0.0880 | Avg Valid recon Loss: 0.0880\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.2865, recon=0.2865, kl=1.0232, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1064 (Recon: 0.1064, KL: 1.1774, Current Beta: 0.0000) | Avg Valid Loss: 0.0843 | Avg Valid recon Loss: 0.0843\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1332, recon=0.1332, kl=0.1346, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0972 (Recon: 0.0972, KL: 0.2908, Current Beta: 0.0000) | Avg Valid Loss: 0.0802 | Avg Valid recon Loss: 0.0802\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.2514, recon=0.2514, kl=0.0122, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0951 (Recon: 0.0951, KL: 0.0567, Current Beta: 0.0001) | Avg Valid Loss: 0.0764 | Avg Valid recon Loss: 0.0764\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1463, recon=0.1463, kl=0.0082, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0906 (Recon: 0.0906, KL: 0.0071, Current Beta: 0.0002) | Avg Valid Loss: 0.0742 | Avg Valid recon Loss: 0.0742\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0813, recon=0.0813, kl=0.0010, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0862 (Recon: 0.0862, KL: 0.0021, Current Beta: 0.0004) | Avg Valid Loss: 0.0712 | Avg Valid recon Loss: 0.0712\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1093, recon=0.1093, kl=0.0005, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0827 (Recon: 0.0827, KL: 0.0007, Current Beta: 0.0006) | Avg Valid Loss: 0.0696 | Avg Valid recon Loss: 0.0696\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0998, recon=0.0998, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0795 (Recon: 0.0795, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0677 | Avg Valid recon Loss: 0.0677\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0562, recon=0.0562, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0769 (Recon: 0.0769, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0660 | Avg Valid recon Loss: 0.0659\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0775, recon=0.0775, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0742 (Recon: 0.0742, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0649 | Avg Valid recon Loss: 0.0649\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0596, recon=0.0596, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0722 (Recon: 0.0722, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0633 | Avg Valid recon Loss: 0.0633\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1028, recon=0.1028, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0700 (Recon: 0.0700, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0617 | Avg Valid recon Loss: 0.0617\n",
      "\n",
      "[VRAE Run 268/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1263, recon=0.1263, kl=47.2551, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2860 (Recon: 0.2860, KL: 22.9923, Current Beta: 0.0000) | Avg Valid Loss: 0.1173 | Avg Valid recon Loss: 0.1173\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1358, recon=0.1358, kl=75.0059, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1176 (Recon: 0.1176, KL: 67.2556, Current Beta: 0.0000) | Avg Valid Loss: 0.0787 | Avg Valid recon Loss: 0.0787\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0961, recon=0.0961, kl=68.7733, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0869 (Recon: 0.0869, KL: 71.6785, Current Beta: 0.0000) | Avg Valid Loss: 0.0664 | Avg Valid recon Loss: 0.0664\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0509, recon=0.0509, kl=66.8951, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0708 (Recon: 0.0708, KL: 68.1414, Current Beta: 0.0000) | Avg Valid Loss: 0.0592 | Avg Valid recon Loss: 0.0592\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0483, recon=0.0483, kl=61.2341, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0662 (Recon: 0.0662, KL: 66.2850, Current Beta: 0.0000) | Avg Valid Loss: 0.0565 | Avg Valid recon Loss: 0.0565\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0596, recon=0.0595, kl=47.8172, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0604 (Recon: 0.0604, KL: 54.2806, Current Beta: 0.0000) | Avg Valid Loss: 0.0528 | Avg Valid recon Loss: 0.0528\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0723, recon=0.0723, kl=27.3453, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0553 (Recon: 0.0553, KL: 35.5839, Current Beta: 0.0000) | Avg Valid Loss: 0.0487 | Avg Valid recon Loss: 0.0486\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0585, recon=0.0585, kl=16.3204, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0529, KL: 19.9155, Current Beta: 0.0000) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0472\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0392, recon=0.0391, kl=7.7377, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0489 (Recon: 0.0489, KL: 10.3890, Current Beta: 0.0000) | Avg Valid Loss: 0.0438 | Avg Valid recon Loss: 0.0438\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0415, recon=0.0414, kl=2.7180, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0469 (Recon: 0.0469, KL: 3.1177, Current Beta: 0.0000) | Avg Valid Loss: 0.0426 | Avg Valid recon Loss: 0.0425\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0400, recon=0.0400, kl=0.7560, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0467 (Recon: 0.0467, KL: 0.9589, Current Beta: 0.0000) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0347, recon=0.0347, kl=0.1330, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0434, KL: 0.2286, Current Beta: 0.0001) | Avg Valid Loss: 0.0393 | Avg Valid recon Loss: 0.0393\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0929, recon=0.0929, kl=0.0210, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0424, KL: 0.0434, Current Beta: 0.0002) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0319, recon=0.0319, kl=0.0090, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0424, KL: 0.0093, Current Beta: 0.0004) | Avg Valid Loss: 0.0378 | Avg Valid recon Loss: 0.0378\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0358, recon=0.0358, kl=0.0047, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0405, KL: 0.0059, Current Beta: 0.0006) | Avg Valid Loss: 0.0367 | Avg Valid recon Loss: 0.0367\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0375, recon=0.0375, kl=0.0018, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0395, KL: 0.0024, Current Beta: 0.0010) | Avg Valid Loss: 0.0350 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0345, recon=0.0345, kl=0.0010, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0398 (Recon: 0.0398, KL: 0.0022, Current Beta: 0.0010) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0355\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0289, recon=0.0289, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0382, KL: 0.0014, Current Beta: 0.0010) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0283, recon=0.0283, kl=0.0012, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0374 (Recon: 0.0374, KL: 0.0013, Current Beta: 0.0010) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0299, recon=0.0299, kl=0.0009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0369 (Recon: 0.0369, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "\n",
      "[VRAE Run 269/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3337, recon=0.3337, kl=2.1371, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5297 (Recon: 0.5297, KL: 0.9104, Current Beta: 0.0000) | Avg Valid Loss: 0.3381 | Avg Valid recon Loss: 0.3381\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3102, recon=0.3102, kl=79.2773, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2671 (Recon: 0.2671, KL: 51.1161, Current Beta: 0.0000) | Avg Valid Loss: 0.1985 | Avg Valid recon Loss: 0.1985\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1679, recon=0.1679, kl=121.6706, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2037 (Recon: 0.2037, KL: 106.3018, Current Beta: 0.0000) | Avg Valid Loss: 0.1542 | Avg Valid recon Loss: 0.1542\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1235, recon=0.1235, kl=132.0427, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1732 (Recon: 0.1732, KL: 130.5361, Current Beta: 0.0000) | Avg Valid Loss: 0.1309 | Avg Valid recon Loss: 0.1309\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1126, recon=0.1126, kl=126.8658, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1561 (Recon: 0.1561, KL: 130.7030, Current Beta: 0.0000) | Avg Valid Loss: 0.1174 | Avg Valid recon Loss: 0.1174\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1208, recon=0.1208, kl=87.0442, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1436 (Recon: 0.1436, KL: 104.5628, Current Beta: 0.0000) | Avg Valid Loss: 0.1079 | Avg Valid recon Loss: 0.1079\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1183, recon=0.1182, kl=36.7101, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1339 (Recon: 0.1339, KL: 55.2517, Current Beta: 0.0000) | Avg Valid Loss: 0.1008 | Avg Valid recon Loss: 0.1007\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1214, recon=0.1214, kl=12.7807, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1255 (Recon: 0.1255, KL: 20.8692, Current Beta: 0.0000) | Avg Valid Loss: 0.0939 | Avg Valid recon Loss: 0.0939\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1158, recon=0.1158, kl=4.2595, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1156 (Recon: 0.1156, KL: 5.9301, Current Beta: 0.0000) | Avg Valid Loss: 0.0894 | Avg Valid recon Loss: 0.0894\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0854, recon=0.0854, kl=0.8229, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1100 (Recon: 0.1100, KL: 1.4937, Current Beta: 0.0000) | Avg Valid Loss: 0.0848 | Avg Valid recon Loss: 0.0848\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.2598, recon=0.2598, kl=0.0867, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1043 (Recon: 0.1043, KL: 0.3523, Current Beta: 0.0000) | Avg Valid Loss: 0.0813 | Avg Valid recon Loss: 0.0813\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0874, recon=0.0874, kl=0.0164, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0984 (Recon: 0.0984, KL: 0.0437, Current Beta: 0.0001) | Avg Valid Loss: 0.0780 | Avg Valid recon Loss: 0.0780\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0755, recon=0.0755, kl=0.0054, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0928 (Recon: 0.0928, KL: 0.0094, Current Beta: 0.0002) | Avg Valid Loss: 0.0752 | Avg Valid recon Loss: 0.0752\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0751, recon=0.0751, kl=0.0012, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0887 (Recon: 0.0887, KL: 0.0028, Current Beta: 0.0004) | Avg Valid Loss: 0.0722 | Avg Valid recon Loss: 0.0722\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.2189, recon=0.2189, kl=0.0009, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0850 (Recon: 0.0850, KL: 0.0013, Current Beta: 0.0006) | Avg Valid Loss: 0.0701 | Avg Valid recon Loss: 0.0701\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0725, recon=0.0725, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0744 (Recon: 0.0744, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0687 | Avg Valid recon Loss: 0.0687\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.2178, recon=0.2178, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0787 (Recon: 0.0787, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0674 | Avg Valid recon Loss: 0.0674\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0649, recon=0.0649, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0766 (Recon: 0.0766, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0652 | Avg Valid recon Loss: 0.0652\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0595, recon=0.0595, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0737 (Recon: 0.0737, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0639 | Avg Valid recon Loss: 0.0639\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0721, recon=0.0721, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0719 (Recon: 0.0719, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0628 | Avg Valid recon Loss: 0.0628\n",
      "\n",
      "[VRAE Run 270/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1394, recon=0.1394, kl=120.4893, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2711 (Recon: 0.2711, KL: 53.8295, Current Beta: 0.0000) | Avg Valid Loss: 0.1120 | Avg Valid recon Loss: 0.1120\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0720, recon=0.0720, kl=132.8952, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1200 (Recon: 0.1200, KL: 128.1346, Current Beta: 0.0000) | Avg Valid Loss: 0.0815 | Avg Valid recon Loss: 0.0815\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0624, recon=0.0624, kl=120.2962, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0861 (Recon: 0.0861, KL: 124.4103, Current Beta: 0.0000) | Avg Valid Loss: 0.0657 | Avg Valid recon Loss: 0.0657\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0612, recon=0.0612, kl=122.3712, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0719 (Recon: 0.0719, KL: 123.4573, Current Beta: 0.0000) | Avg Valid Loss: 0.0640 | Avg Valid recon Loss: 0.0640\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0498, recon=0.0498, kl=100.8796, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0650 (Recon: 0.0650, KL: 109.9876, Current Beta: 0.0000) | Avg Valid Loss: 0.0543 | Avg Valid recon Loss: 0.0543\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0481, recon=0.0481, kl=82.2192, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0586 (Recon: 0.0585, KL: 88.8768, Current Beta: 0.0000) | Avg Valid Loss: 0.0514 | Avg Valid recon Loss: 0.0514\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0485, recon=0.0485, kl=49.7051, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0576 (Recon: 0.0576, KL: 60.6525, Current Beta: 0.0000) | Avg Valid Loss: 0.0543 | Avg Valid recon Loss: 0.0543\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0536, recon=0.0536, kl=30.3320, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0542 (Recon: 0.0541, KL: 33.6826, Current Beta: 0.0000) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0477\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0462, recon=0.0462, kl=16.0146, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0496, KL: 15.8735, Current Beta: 0.0000) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0440\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0515, recon=0.0515, kl=4.8973, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0471 (Recon: 0.0470, KL: 6.4041, Current Beta: 0.0000) | Avg Valid Loss: 0.0416 | Avg Valid recon Loss: 0.0416\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0335, recon=0.0334, kl=2.0726, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0444 (Recon: 0.0444, KL: 2.0831, Current Beta: 0.0000) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0397\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0378, recon=0.0378, kl=0.2786, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0436 (Recon: 0.0435, KL: 0.4296, Current Beta: 0.0001) | Avg Valid Loss: 0.0386 | Avg Valid recon Loss: 0.0386\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0381, recon=0.0380, kl=0.0388, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0421, KL: 0.0770, Current Beta: 0.0002) | Avg Valid Loss: 0.0374 | Avg Valid recon Loss: 0.0374\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0303, recon=0.0303, kl=0.0075, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0401 (Recon: 0.0401, KL: 0.0110, Current Beta: 0.0004) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0369\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0295, recon=0.0295, kl=0.0028, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0393 (Recon: 0.0393, KL: 0.0048, Current Beta: 0.0006) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0392, recon=0.0392, kl=0.0016, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0391, KL: 0.0021, Current Beta: 0.0010) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0355\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0303, recon=0.0303, kl=0.0023, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0385 (Recon: 0.0385, KL: 0.0021, Current Beta: 0.0010) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0325, recon=0.0325, kl=0.0024, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0371 (Recon: 0.0371, KL: 0.0025, Current Beta: 0.0010) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0340\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0411, recon=0.0411, kl=0.0014, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0365 (Recon: 0.0365, KL: 0.0023, Current Beta: 0.0010) | Avg Valid Loss: 0.0338 | Avg Valid recon Loss: 0.0338\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0331, recon=0.0331, kl=0.0018, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0339 (Recon: 0.0338, KL: 0.0015, Current Beta: 0.0010) | Avg Valid Loss: 0.0327 | Avg Valid recon Loss: 0.0327\n",
      "\n",
      "[VRAE Run 271/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6539, recon=0.6539, kl=0.4658, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.7762 (Recon: 0.7762, KL: 0.2838, Current Beta: 0.0000) | Avg Valid Loss: 0.6460 | Avg Valid recon Loss: 0.6460\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.4631, recon=0.4631, kl=6.2669, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5397 (Recon: 0.5397, KL: 3.0133, Current Beta: 0.0000) | Avg Valid Loss: 0.4974 | Avg Valid recon Loss: 0.4974\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.3705, recon=0.3705, kl=14.4512, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4272 (Recon: 0.4272, KL: 11.2589, Current Beta: 0.0000) | Avg Valid Loss: 0.3962 | Avg Valid recon Loss: 0.3962\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.2817, recon=0.2817, kl=19.1708, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3527 (Recon: 0.3527, KL: 17.7737, Current Beta: 0.0000) | Avg Valid Loss: 0.3249 | Avg Valid recon Loss: 0.3249\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.3036, recon=0.3036, kl=23.2417, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3034 (Recon: 0.3034, KL: 21.7468, Current Beta: 0.0000) | Avg Valid Loss: 0.2746 | Avg Valid recon Loss: 0.2746\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2575, recon=0.2575, kl=26.0754, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2680 (Recon: 0.2680, KL: 25.0858, Current Beta: 0.0000) | Avg Valid Loss: 0.2392 | Avg Valid recon Loss: 0.2392\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2284, recon=0.2284, kl=27.2113, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2389 (Recon: 0.2389, KL: 27.0194, Current Beta: 0.0000) | Avg Valid Loss: 0.2132 | Avg Valid recon Loss: 0.2131\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1842, recon=0.1842, kl=23.7247, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2176 (Recon: 0.2175, KL: 25.5148, Current Beta: 0.0000) | Avg Valid Loss: 0.1937 | Avg Valid recon Loss: 0.1937\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1856, recon=0.1856, kl=14.3322, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2015 (Recon: 0.2014, KL: 18.2518, Current Beta: 0.0000) | Avg Valid Loss: 0.1782 | Avg Valid recon Loss: 0.1781\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1769, recon=0.1769, kl=5.3240, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1874 (Recon: 0.1873, KL: 8.5343, Current Beta: 0.0000) | Avg Valid Loss: 0.1653 | Avg Valid recon Loss: 0.1653\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1436, recon=0.1435, kl=1.4846, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1745 (Recon: 0.1744, KL: 2.5974, Current Beta: 0.0000) | Avg Valid Loss: 0.1553 | Avg Valid recon Loss: 0.1553\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1154, recon=0.1154, kl=0.3567, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1635 (Recon: 0.1635, KL: 0.6670, Current Beta: 0.0001) | Avg Valid Loss: 0.1465 | Avg Valid recon Loss: 0.1465\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1153, recon=0.1153, kl=0.0533, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.1541 (Recon: 0.1541, KL: 0.1520, Current Beta: 0.0002) | Avg Valid Loss: 0.1389 | Avg Valid recon Loss: 0.1389\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1990, recon=0.1990, kl=0.0092, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.1474 (Recon: 0.1474, KL: 0.0259, Current Beta: 0.0004) | Avg Valid Loss: 0.1332 | Avg Valid recon Loss: 0.1332\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1449, recon=0.1449, kl=0.0025, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.1406 (Recon: 0.1406, KL: 0.0042, Current Beta: 0.0006) | Avg Valid Loss: 0.1277 | Avg Valid recon Loss: 0.1277\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1287, recon=0.1287, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1343 (Recon: 0.1343, KL: 0.0013, Current Beta: 0.0010) | Avg Valid Loss: 0.1232 | Avg Valid recon Loss: 0.1232\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1461, recon=0.1461, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1264 (Recon: 0.1264, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.1186 | Avg Valid recon Loss: 0.1186\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1708, recon=0.1708, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1242 (Recon: 0.1242, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.1150 | Avg Valid recon Loss: 0.1150\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0902, recon=0.0902, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1205 (Recon: 0.1205, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.1109 | Avg Valid recon Loss: 0.1109\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1557, recon=0.1557, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1170 (Recon: 0.1170, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.1082 | Avg Valid recon Loss: 0.1082\n",
      "\n",
      "[VRAE Run 272/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2402, recon=0.2402, kl=18.0254, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4610 (Recon: 0.4610, KL: 10.5240, Current Beta: 0.0000) | Avg Valid Loss: 0.2312 | Avg Valid recon Loss: 0.2312\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1471, recon=0.1471, kl=29.7092, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1945 (Recon: 0.1945, KL: 26.2515, Current Beta: 0.0000) | Avg Valid Loss: 0.1416 | Avg Valid recon Loss: 0.1416\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0981, recon=0.0981, kl=36.1013, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1357 (Recon: 0.1357, KL: 33.6185, Current Beta: 0.0000) | Avg Valid Loss: 0.1071 | Avg Valid recon Loss: 0.1071\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0811, recon=0.0811, kl=37.5854, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1138 (Recon: 0.1138, KL: 37.5416, Current Beta: 0.0000) | Avg Valid Loss: 0.0921 | Avg Valid recon Loss: 0.0921\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0818, recon=0.0818, kl=38.7288, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0952 (Recon: 0.0952, KL: 38.2488, Current Beta: 0.0000) | Avg Valid Loss: 0.0840 | Avg Valid recon Loss: 0.0840\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0590, recon=0.0590, kl=33.2528, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0865 (Recon: 0.0865, KL: 35.7477, Current Beta: 0.0000) | Avg Valid Loss: 0.0814 | Avg Valid recon Loss: 0.0814\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0621, recon=0.0620, kl=21.9362, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0809 (Recon: 0.0808, KL: 27.3470, Current Beta: 0.0000) | Avg Valid Loss: 0.0730 | Avg Valid recon Loss: 0.0730\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.2334, recon=0.2334, kl=14.3859, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0745 (Recon: 0.0744, KL: 15.6950, Current Beta: 0.0000) | Avg Valid Loss: 0.0689 | Avg Valid recon Loss: 0.0689\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0533, recon=0.0533, kl=8.1886, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0731 (Recon: 0.0731, KL: 8.6095, Current Beta: 0.0000) | Avg Valid Loss: 0.0650 | Avg Valid recon Loss: 0.0650\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0887, recon=0.0887, kl=2.2863, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0680 (Recon: 0.0680, KL: 3.4654, Current Beta: 0.0000) | Avg Valid Loss: 0.0618 | Avg Valid recon Loss: 0.0618\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0395, recon=0.0395, kl=0.2623, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0648 (Recon: 0.0647, KL: 0.7417, Current Beta: 0.0000) | Avg Valid Loss: 0.0619 | Avg Valid recon Loss: 0.0619\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0585, recon=0.0585, kl=0.0491, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0639 (Recon: 0.0639, KL: 0.0949, Current Beta: 0.0001) | Avg Valid Loss: 0.0565 | Avg Valid recon Loss: 0.0565\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0468, recon=0.0468, kl=0.0064, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0601 (Recon: 0.0601, KL: 0.0143, Current Beta: 0.0002) | Avg Valid Loss: 0.0563 | Avg Valid recon Loss: 0.0563\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0619, recon=0.0619, kl=0.0010, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0585 (Recon: 0.0585, KL: 0.0029, Current Beta: 0.0004) | Avg Valid Loss: 0.0545 | Avg Valid recon Loss: 0.0545\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0766, recon=0.0766, kl=0.0004, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0563 (Recon: 0.0563, KL: 0.0009, Current Beta: 0.0006) | Avg Valid Loss: 0.0519 | Avg Valid recon Loss: 0.0519\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0669, recon=0.0669, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0576 (Recon: 0.0576, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0518 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0474, recon=0.0474, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0545, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0501 | Avg Valid recon Loss: 0.0501\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0608, recon=0.0608, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0521 (Recon: 0.0521, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0476 | Avg Valid recon Loss: 0.0476\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0555, recon=0.0555, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0517 (Recon: 0.0517, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0910, recon=0.0910, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0504 (Recon: 0.0504, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0461 | Avg Valid recon Loss: 0.0461\n",
      "\n",
      "[VRAE Run 273/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7298, recon=0.7298, kl=0.6584, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.8444 (Recon: 0.8444, KL: 0.5031, Current Beta: 0.0000) | Avg Valid Loss: 0.7277 | Avg Valid recon Loss: 0.7277\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.4661, recon=0.4661, kl=13.2491, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6085 (Recon: 0.6085, KL: 5.8605, Current Beta: 0.0000) | Avg Valid Loss: 0.5677 | Avg Valid recon Loss: 0.5677\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.5375, recon=0.5375, kl=29.1513, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4893 (Recon: 0.4893, KL: 23.8447, Current Beta: 0.0000) | Avg Valid Loss: 0.4718 | Avg Valid recon Loss: 0.4718\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.3618, recon=0.3618, kl=38.6162, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4146 (Recon: 0.4146, KL: 35.2977, Current Beta: 0.0000) | Avg Valid Loss: 0.3964 | Avg Valid recon Loss: 0.3964\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2849, recon=0.2849, kl=44.7385, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3598 (Recon: 0.3598, KL: 42.5596, Current Beta: 0.0000) | Avg Valid Loss: 0.3336 | Avg Valid recon Loss: 0.3336\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2667, recon=0.2667, kl=49.0723, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3133 (Recon: 0.3133, KL: 47.5689, Current Beta: 0.0000) | Avg Valid Loss: 0.2871 | Avg Valid recon Loss: 0.2871\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2304, recon=0.2303, kl=48.3476, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2777 (Recon: 0.2777, KL: 49.1682, Current Beta: 0.0000) | Avg Valid Loss: 0.2518 | Avg Valid recon Loss: 0.2518\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.2687, recon=0.2687, kl=38.0979, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2500 (Recon: 0.2500, KL: 42.9344, Current Beta: 0.0000) | Avg Valid Loss: 0.2270 | Avg Valid recon Loss: 0.2270\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1802, recon=0.1801, kl=19.2456, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2272 (Recon: 0.2270, KL: 26.8839, Current Beta: 0.0000) | Avg Valid Loss: 0.2055 | Avg Valid recon Loss: 0.2054\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.2281, recon=0.2280, kl=5.5081, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2103 (Recon: 0.2102, KL: 10.0337, Current Beta: 0.0000) | Avg Valid Loss: 0.1899 | Avg Valid recon Loss: 0.1898\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1628, recon=0.1628, kl=1.6204, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1951 (Recon: 0.1950, KL: 2.7357, Current Beta: 0.0000) | Avg Valid Loss: 0.1764 | Avg Valid recon Loss: 0.1764\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1676, recon=0.1675, kl=0.3837, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1822 (Recon: 0.1821, KL: 0.6915, Current Beta: 0.0001) | Avg Valid Loss: 0.1645 | Avg Valid recon Loss: 0.1645\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1809, recon=0.1809, kl=0.0691, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.1710 (Recon: 0.1710, KL: 0.1410, Current Beta: 0.0002) | Avg Valid Loss: 0.1559 | Avg Valid recon Loss: 0.1559\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1599, recon=0.1599, kl=0.0133, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.1612 (Recon: 0.1612, KL: 0.0199, Current Beta: 0.0004) | Avg Valid Loss: 0.1472 | Avg Valid recon Loss: 0.1472\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1186, recon=0.1186, kl=0.0028, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.1497 (Recon: 0.1497, KL: 0.0037, Current Beta: 0.0006) | Avg Valid Loss: 0.1399 | Avg Valid recon Loss: 0.1399\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1481, recon=0.1481, kl=0.0010, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1456 (Recon: 0.1456, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.1333 | Avg Valid recon Loss: 0.1333\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1249, recon=0.1249, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1395 (Recon: 0.1395, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.1280 | Avg Valid recon Loss: 0.1280\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1187, recon=0.1187, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1330 (Recon: 0.1330, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.1238 | Avg Valid recon Loss: 0.1238\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0988, recon=0.0988, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1285 (Recon: 0.1285, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.1186 | Avg Valid recon Loss: 0.1186\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0778, recon=0.0778, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1240 (Recon: 0.1240, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.1148 | Avg Valid recon Loss: 0.1148\n",
      "\n",
      "[VRAE Run 274/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2647, recon=0.2647, kl=48.6780, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4810 (Recon: 0.4810, KL: 26.4543, Current Beta: 0.0000) | Avg Valid Loss: 0.2283 | Avg Valid recon Loss: 0.2283\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1479, recon=0.1479, kl=72.8690, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1915 (Recon: 0.1915, KL: 65.3261, Current Beta: 0.0000) | Avg Valid Loss: 0.1595 | Avg Valid recon Loss: 0.1595\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1016, recon=0.1016, kl=79.5979, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1362 (Recon: 0.1362, KL: 77.7955, Current Beta: 0.0000) | Avg Valid Loss: 0.1069 | Avg Valid recon Loss: 0.1069\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0800, recon=0.0800, kl=82.2097, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1080 (Recon: 0.1080, KL: 80.6275, Current Beta: 0.0000) | Avg Valid Loss: 0.0920 | Avg Valid recon Loss: 0.0920\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0815, recon=0.0814, kl=79.4163, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0957 (Recon: 0.0957, KL: 81.4074, Current Beta: 0.0000) | Avg Valid Loss: 0.0839 | Avg Valid recon Loss: 0.0839\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0710, recon=0.0709, kl=64.9282, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0873 (Recon: 0.0873, KL: 71.3849, Current Beta: 0.0000) | Avg Valid Loss: 0.0787 | Avg Valid recon Loss: 0.0787\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0596, recon=0.0596, kl=35.8176, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0797 (Recon: 0.0797, KL: 47.3503, Current Beta: 0.0000) | Avg Valid Loss: 0.0757 | Avg Valid recon Loss: 0.0757\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0667, recon=0.0667, kl=22.7637, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0749 (Recon: 0.0749, KL: 25.9864, Current Beta: 0.0000) | Avg Valid Loss: 0.0712 | Avg Valid recon Loss: 0.0712\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0575, recon=0.0575, kl=9.9001, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0703 (Recon: 0.0702, KL: 12.5926, Current Beta: 0.0000) | Avg Valid Loss: 0.0671 | Avg Valid recon Loss: 0.0671\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0651, recon=0.0650, kl=2.1198, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0695 (Recon: 0.0695, KL: 3.5970, Current Beta: 0.0000) | Avg Valid Loss: 0.0641 | Avg Valid recon Loss: 0.0641\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0517, recon=0.0517, kl=0.1607, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0668 (Recon: 0.0668, KL: 0.5838, Current Beta: 0.0000) | Avg Valid Loss: 0.0620 | Avg Valid recon Loss: 0.0620\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0649, recon=0.0649, kl=0.0156, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0629 (Recon: 0.0629, KL: 0.0500, Current Beta: 0.0001) | Avg Valid Loss: 0.0582 | Avg Valid recon Loss: 0.0582\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0716, recon=0.0716, kl=0.0032, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0607 (Recon: 0.0607, KL: 0.0071, Current Beta: 0.0002) | Avg Valid Loss: 0.0569 | Avg Valid recon Loss: 0.0569\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0440, recon=0.0440, kl=0.0017, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0600 (Recon: 0.0600, KL: 0.0017, Current Beta: 0.0004) | Avg Valid Loss: 0.0539 | Avg Valid recon Loss: 0.0539\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0878, recon=0.0878, kl=0.0010, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0577 (Recon: 0.0577, KL: 0.0008, Current Beta: 0.0006) | Avg Valid Loss: 0.0534 | Avg Valid recon Loss: 0.0534\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0590, recon=0.0590, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0587 (Recon: 0.0587, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0527 | Avg Valid recon Loss: 0.0527\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0652, recon=0.0652, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0552 (Recon: 0.0552, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0503 | Avg Valid recon Loss: 0.0503\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0382, recon=0.0382, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0536 (Recon: 0.0536, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0504 | Avg Valid recon Loss: 0.0504\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0572, recon=0.0572, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0526 (Recon: 0.0526, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0485 | Avg Valid recon Loss: 0.0485\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0398, recon=0.0398, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0520 (Recon: 0.0520, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0484 | Avg Valid recon Loss: 0.0484\n",
      "\n",
      "[VRAE Run 275/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7069, recon=0.7069, kl=1.4732, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.8110 (Recon: 0.8110, KL: 1.0847, Current Beta: 0.0000) | Avg Valid Loss: 0.6861 | Avg Valid recon Loss: 0.6861\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.7436, recon=0.7436, kl=14.3428, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5677 (Recon: 0.5677, KL: 7.2425, Current Beta: 0.0000) | Avg Valid Loss: 0.5314 | Avg Valid recon Loss: 0.5314\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.3956, recon=0.3956, kl=41.0637, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4558 (Recon: 0.4558, KL: 30.2821, Current Beta: 0.0000) | Avg Valid Loss: 0.4295 | Avg Valid recon Loss: 0.4295\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.3396, recon=0.3396, kl=60.9257, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3801 (Recon: 0.3801, KL: 54.3642, Current Beta: 0.0000) | Avg Valid Loss: 0.3533 | Avg Valid recon Loss: 0.3533\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2648, recon=0.2648, kl=71.6505, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3239 (Recon: 0.3239, KL: 67.9795, Current Beta: 0.0000) | Avg Valid Loss: 0.2959 | Avg Valid recon Loss: 0.2959\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2725, recon=0.2724, kl=77.8807, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2674 (Recon: 0.2674, KL: 75.9593, Current Beta: 0.0000) | Avg Valid Loss: 0.2537 | Avg Valid recon Loss: 0.2537\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1945, recon=0.1945, kl=75.5395, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2503 (Recon: 0.2503, KL: 77.3824, Current Beta: 0.0000) | Avg Valid Loss: 0.2247 | Avg Valid recon Loss: 0.2247\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.4443, recon=0.4442, kl=55.4495, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2277 (Recon: 0.2276, KL: 64.9679, Current Beta: 0.0000) | Avg Valid Loss: 0.2033 | Avg Valid recon Loss: 0.2033\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1984, recon=0.1984, kl=22.1808, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2061 (Recon: 0.2060, KL: 34.8065, Current Beta: 0.0000) | Avg Valid Loss: 0.1862 | Avg Valid recon Loss: 0.1861\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.2855, recon=0.2854, kl=5.8144, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1926 (Recon: 0.1924, KL: 10.5295, Current Beta: 0.0000) | Avg Valid Loss: 0.1726 | Avg Valid recon Loss: 0.1725\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1958, recon=0.1957, kl=1.9192, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1791 (Recon: 0.1790, KL: 2.8906, Current Beta: 0.0000) | Avg Valid Loss: 0.1610 | Avg Valid recon Loss: 0.1609\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1246, recon=0.1246, kl=0.5717, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1676 (Recon: 0.1675, KL: 0.8454, Current Beta: 0.0001) | Avg Valid Loss: 0.1515 | Avg Valid recon Loss: 0.1515\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1249, recon=0.1249, kl=0.1220, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.1473 (Recon: 0.1472, KL: 0.2171, Current Beta: 0.0002) | Avg Valid Loss: 0.1441 | Avg Valid recon Loss: 0.1441\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1361, recon=0.1361, kl=0.0222, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.1477 (Recon: 0.1477, KL: 0.0405, Current Beta: 0.0004) | Avg Valid Loss: 0.1374 | Avg Valid recon Loss: 0.1374\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1091, recon=0.1091, kl=0.0038, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.1435 (Recon: 0.1435, KL: 0.0070, Current Beta: 0.0006) | Avg Valid Loss: 0.1320 | Avg Valid recon Loss: 0.1320\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1115, recon=0.1115, kl=0.0010, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1365 (Recon: 0.1365, KL: 0.0015, Current Beta: 0.0010) | Avg Valid Loss: 0.1262 | Avg Valid recon Loss: 0.1262\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1090, recon=0.1090, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1297 (Recon: 0.1297, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.1212 | Avg Valid recon Loss: 0.1212\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0963, recon=0.0963, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1246 (Recon: 0.1246, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.1178 | Avg Valid recon Loss: 0.1178\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1018, recon=0.1018, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1194 (Recon: 0.1194, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.1127 | Avg Valid recon Loss: 0.1127\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1237, recon=0.1237, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.1152 (Recon: 0.1152, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.1098 | Avg Valid recon Loss: 0.1098\n",
      "\n",
      "[VRAE Run 276/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5606, recon=0.5606, kl=68.4507, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4632 (Recon: 0.4632, KL: 37.0463, Current Beta: 0.0000) | Avg Valid Loss: 0.2279 | Avg Valid recon Loss: 0.2279\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1421, recon=0.1421, kl=117.4702, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1909 (Recon: 0.1909, KL: 99.7515, Current Beta: 0.0000) | Avg Valid Loss: 0.1360 | Avg Valid recon Loss: 0.1360\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1112, recon=0.1112, kl=132.7904, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1311 (Recon: 0.1311, KL: 127.5304, Current Beta: 0.0000) | Avg Valid Loss: 0.1048 | Avg Valid recon Loss: 0.1048\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0875, recon=0.0875, kl=140.2957, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1074 (Recon: 0.1074, KL: 139.0348, Current Beta: 0.0000) | Avg Valid Loss: 0.0901 | Avg Valid recon Loss: 0.0901\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0641, recon=0.0641, kl=135.9334, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0915 (Recon: 0.0915, KL: 139.2984, Current Beta: 0.0000) | Avg Valid Loss: 0.0800 | Avg Valid recon Loss: 0.0800\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0652, recon=0.0652, kl=99.5071, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0816 (Recon: 0.0816, KL: 114.6359, Current Beta: 0.0000) | Avg Valid Loss: 0.0746 | Avg Valid recon Loss: 0.0746\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0544, recon=0.0544, kl=56.7545, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0753 (Recon: 0.0752, KL: 70.3640, Current Beta: 0.0000) | Avg Valid Loss: 0.0679 | Avg Valid recon Loss: 0.0679\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0446, recon=0.0445, kl=37.5130, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0707 (Recon: 0.0706, KL: 43.3099, Current Beta: 0.0000) | Avg Valid Loss: 0.0650 | Avg Valid recon Loss: 0.0649\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0629, recon=0.0628, kl=15.6155, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0659 (Recon: 0.0658, KL: 19.6147, Current Beta: 0.0000) | Avg Valid Loss: 0.0615 | Avg Valid recon Loss: 0.0614\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0701, recon=0.0700, kl=3.0549, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0637 (Recon: 0.0637, KL: 4.5742, Current Beta: 0.0000) | Avg Valid Loss: 0.0582 | Avg Valid recon Loss: 0.0582\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0524, recon=0.0524, kl=0.2565, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0608 (Recon: 0.0608, KL: 0.8385, Current Beta: 0.0000) | Avg Valid Loss: 0.0575 | Avg Valid recon Loss: 0.0575\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0525, recon=0.0525, kl=0.0515, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0596 (Recon: 0.0596, KL: 0.1394, Current Beta: 0.0001) | Avg Valid Loss: 0.0562 | Avg Valid recon Loss: 0.0562\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1598, recon=0.1597, kl=0.0077, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0569 (Recon: 0.0569, KL: 0.0179, Current Beta: 0.0002) | Avg Valid Loss: 0.0526 | Avg Valid recon Loss: 0.0526\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=0.0043, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0542 (Recon: 0.0542, KL: 0.0044, Current Beta: 0.0004) | Avg Valid Loss: 0.0515 | Avg Valid recon Loss: 0.0515\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0405, recon=0.0405, kl=0.0020, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0534, KL: 0.0021, Current Beta: 0.0006) | Avg Valid Loss: 0.0489 | Avg Valid recon Loss: 0.0489\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0401, recon=0.0401, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0482, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0501 | Avg Valid recon Loss: 0.0501\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1518, recon=0.1518, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0505 (Recon: 0.0505, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0469 | Avg Valid recon Loss: 0.0469\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0558, recon=0.0558, kl=0.0010, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0492 (Recon: 0.0492, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0463 | Avg Valid recon Loss: 0.0463\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0369, recon=0.0369, kl=0.0009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0491 (Recon: 0.0491, KL: 0.0017, Current Beta: 0.0010) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0597, recon=0.0597, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0473 (Recon: 0.0473, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0433\n",
      "\n",
      "[VRAE Run 277/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4449, recon=0.4449, kl=1.2390, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6455 (Recon: 0.6455, KL: 0.4977, Current Beta: 0.0000) | Avg Valid Loss: 0.4926 | Avg Valid recon Loss: 0.4926\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3682, recon=0.3682, kl=12.0235, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3833 (Recon: 0.3833, KL: 7.6421, Current Beta: 0.0000) | Avg Valid Loss: 0.3198 | Avg Valid recon Loss: 0.3198\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2074, recon=0.2074, kl=21.9628, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2795 (Recon: 0.2795, KL: 18.3097, Current Beta: 0.0000) | Avg Valid Loss: 0.2337 | Avg Valid recon Loss: 0.2337\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1835, recon=0.1835, kl=29.5708, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2254 (Recon: 0.2254, KL: 26.8995, Current Beta: 0.0000) | Avg Valid Loss: 0.1851 | Avg Valid recon Loss: 0.1851\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2397, recon=0.2397, kl=35.4397, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1914 (Recon: 0.1914, KL: 33.1964, Current Beta: 0.0000) | Avg Valid Loss: 0.1589 | Avg Valid recon Loss: 0.1589\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1541, recon=0.1541, kl=39.1803, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1697 (Recon: 0.1697, KL: 38.0993, Current Beta: 0.0000) | Avg Valid Loss: 0.1419 | Avg Valid recon Loss: 0.1419\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1149, recon=0.1149, kl=33.3682, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1520 (Recon: 0.1520, KL: 36.2259, Current Beta: 0.0000) | Avg Valid Loss: 0.1282 | Avg Valid recon Loss: 0.1282\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1124, recon=0.1124, kl=19.0099, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1411 (Recon: 0.1411, KL: 24.7180, Current Beta: 0.0000) | Avg Valid Loss: 0.1189 | Avg Valid recon Loss: 0.1189\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1075, recon=0.1074, kl=7.3798, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1311 (Recon: 0.1311, KL: 11.2015, Current Beta: 0.0000) | Avg Valid Loss: 0.1116 | Avg Valid recon Loss: 0.1115\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1035, recon=0.1035, kl=2.2865, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1229 (Recon: 0.1229, KL: 3.7760, Current Beta: 0.0000) | Avg Valid Loss: 0.1057 | Avg Valid recon Loss: 0.1056\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0959, recon=0.0959, kl=0.7867, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1167 (Recon: 0.1167, KL: 1.0470, Current Beta: 0.0000) | Avg Valid Loss: 0.1004 | Avg Valid recon Loss: 0.1004\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1724, recon=0.1724, kl=0.1887, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1106 (Recon: 0.1106, KL: 0.2396, Current Beta: 0.0001) | Avg Valid Loss: 0.0965 | Avg Valid recon Loss: 0.0965\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1085, recon=0.1085, kl=0.0370, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.1068 (Recon: 0.1068, KL: 0.0424, Current Beta: 0.0002) | Avg Valid Loss: 0.0934 | Avg Valid recon Loss: 0.0934\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0859, recon=0.0859, kl=0.0026, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.1005 (Recon: 0.1005, KL: 0.0049, Current Beta: 0.0004) | Avg Valid Loss: 0.0897 | Avg Valid recon Loss: 0.0897\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0869, recon=0.0869, kl=0.0009, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0970 (Recon: 0.0970, KL: 0.0014, Current Beta: 0.0006) | Avg Valid Loss: 0.0876 | Avg Valid recon Loss: 0.0876\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0837, recon=0.0837, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0944 (Recon: 0.0944, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0847 | Avg Valid recon Loss: 0.0847\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0730, recon=0.0730, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0901 (Recon: 0.0901, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0822 | Avg Valid recon Loss: 0.0822\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0713, recon=0.0713, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0877 (Recon: 0.0877, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0799 | Avg Valid recon Loss: 0.0799\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0858, recon=0.0858, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0844 (Recon: 0.0844, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0802 | Avg Valid recon Loss: 0.0802\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0671, recon=0.0671, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0832 (Recon: 0.0832, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0758 | Avg Valid recon Loss: 0.0758\n",
      "\n",
      "[VRAE Run 278/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2214, recon=0.2214, kl=30.4824, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3429 (Recon: 0.3429, KL: 19.1400, Current Beta: 0.0000) | Avg Valid Loss: 0.1513 | Avg Valid recon Loss: 0.1513\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1157, recon=0.1157, kl=37.2373, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1275 (Recon: 0.1275, KL: 34.5471, Current Beta: 0.0000) | Avg Valid Loss: 0.0992 | Avg Valid recon Loss: 0.0992\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0707, recon=0.0707, kl=40.2849, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1006 (Recon: 0.1006, KL: 39.5676, Current Beta: 0.0000) | Avg Valid Loss: 0.0777 | Avg Valid recon Loss: 0.0777\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0649, recon=0.0649, kl=42.8200, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0820 (Recon: 0.0820, KL: 41.3237, Current Beta: 0.0000) | Avg Valid Loss: 0.0790 | Avg Valid recon Loss: 0.0790\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0502, recon=0.0502, kl=39.3427, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0721 (Recon: 0.0721, KL: 40.3335, Current Beta: 0.0000) | Avg Valid Loss: 0.0616 | Avg Valid recon Loss: 0.0616\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0458, recon=0.0458, kl=30.2607, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0631 (Recon: 0.0631, KL: 33.3700, Current Beta: 0.0000) | Avg Valid Loss: 0.0569 | Avg Valid recon Loss: 0.0569\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0555, recon=0.0554, kl=21.6934, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0590 (Recon: 0.0590, KL: 23.2057, Current Beta: 0.0000) | Avg Valid Loss: 0.0560 | Avg Valid recon Loss: 0.0560\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0497, recon=0.0497, kl=13.3308, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0556 (Recon: 0.0556, KL: 17.0320, Current Beta: 0.0000) | Avg Valid Loss: 0.0484 | Avg Valid recon Loss: 0.0484\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0383, recon=0.0383, kl=6.8418, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0517 (Recon: 0.0517, KL: 7.4424, Current Beta: 0.0000) | Avg Valid Loss: 0.0473 | Avg Valid recon Loss: 0.0473\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0401, recon=0.0401, kl=2.6811, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0495, KL: 3.0003, Current Beta: 0.0000) | Avg Valid Loss: 0.0530 | Avg Valid recon Loss: 0.0530\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0504, recon=0.0504, kl=0.2627, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0479, KL: 0.6901, Current Beta: 0.0000) | Avg Valid Loss: 0.0440 | Avg Valid recon Loss: 0.0440\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0334, recon=0.0334, kl=0.0240, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0455, KL: 0.0806, Current Beta: 0.0001) | Avg Valid Loss: 0.0409 | Avg Valid recon Loss: 0.0409\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1052, recon=0.1052, kl=0.0051, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0429 (Recon: 0.0429, KL: 0.0080, Current Beta: 0.0002) | Avg Valid Loss: 0.0400 | Avg Valid recon Loss: 0.0400\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0550, recon=0.0550, kl=0.0024, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 0.0029, Current Beta: 0.0004) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0562, recon=0.0562, kl=0.0007, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0410 (Recon: 0.0410, KL: 0.0008, Current Beta: 0.0006) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0420, recon=0.0420, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0409, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0276, recon=0.0276, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0394 (Recon: 0.0394, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0355 | Avg Valid recon Loss: 0.0355\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0339, recon=0.0339, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0377, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0328, recon=0.0328, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0377, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0337 | Avg Valid recon Loss: 0.0337\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0622, recon=0.0622, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0366 (Recon: 0.0366, KL: 0.0001, Current Beta: 0.0010) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0347\n",
      "\n",
      "[VRAE Run 279/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4044, recon=0.4044, kl=1.9372, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6530 (Recon: 0.6530, KL: 0.7997, Current Beta: 0.0000) | Avg Valid Loss: 0.4812 | Avg Valid recon Loss: 0.4812\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3642, recon=0.3642, kl=27.2366, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3770 (Recon: 0.3770, KL: 17.2130, Current Beta: 0.0000) | Avg Valid Loss: 0.3112 | Avg Valid recon Loss: 0.3112\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2709, recon=0.2709, kl=48.7034, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2760 (Recon: 0.2760, KL: 41.4230, Current Beta: 0.0000) | Avg Valid Loss: 0.2284 | Avg Valid recon Loss: 0.2284\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1875, recon=0.1875, kl=64.8903, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2223 (Recon: 0.2223, KL: 58.7265, Current Beta: 0.0000) | Avg Valid Loss: 0.1835 | Avg Valid recon Loss: 0.1835\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1630, recon=0.1630, kl=75.3305, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1779 (Recon: 0.1779, KL: 72.3367, Current Beta: 0.0000) | Avg Valid Loss: 0.1566 | Avg Valid recon Loss: 0.1566\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1466, recon=0.1466, kl=68.6816, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1698 (Recon: 0.1698, KL: 72.3958, Current Beta: 0.0000) | Avg Valid Loss: 0.1395 | Avg Valid recon Loss: 0.1395\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1260, recon=0.1260, kl=53.0742, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1529 (Recon: 0.1528, KL: 59.9385, Current Beta: 0.0000) | Avg Valid Loss: 0.1262 | Avg Valid recon Loss: 0.1262\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1187, recon=0.1186, kl=29.4486, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1395 (Recon: 0.1395, KL: 38.8408, Current Beta: 0.0000) | Avg Valid Loss: 0.1172 | Avg Valid recon Loss: 0.1172\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1207, recon=0.1207, kl=11.1493, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1294 (Recon: 0.1293, KL: 17.1556, Current Beta: 0.0000) | Avg Valid Loss: 0.1115 | Avg Valid recon Loss: 0.1114\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1564, recon=0.1564, kl=4.0303, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1187 (Recon: 0.1186, KL: 5.8879, Current Beta: 0.0000) | Avg Valid Loss: 0.1038 | Avg Valid recon Loss: 0.1038\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.2723, recon=0.2723, kl=1.1625, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1145 (Recon: 0.1145, KL: 1.6993, Current Beta: 0.0000) | Avg Valid Loss: 0.1001 | Avg Valid recon Loss: 0.1000\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1015, recon=0.1015, kl=0.2500, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1093 (Recon: 0.1093, KL: 0.3978, Current Beta: 0.0001) | Avg Valid Loss: 0.0961 | Avg Valid recon Loss: 0.0961\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0977, recon=0.0977, kl=0.0496, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.1040 (Recon: 0.1040, KL: 0.0715, Current Beta: 0.0002) | Avg Valid Loss: 0.0916 | Avg Valid recon Loss: 0.0916\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0703, recon=0.0703, kl=0.0031, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0999 (Recon: 0.0999, KL: 0.0095, Current Beta: 0.0004) | Avg Valid Loss: 0.0891 | Avg Valid recon Loss: 0.0891\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0743, recon=0.0743, kl=0.0034, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0967 (Recon: 0.0967, KL: 0.0028, Current Beta: 0.0006) | Avg Valid Loss: 0.0860 | Avg Valid recon Loss: 0.0860\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0669, recon=0.0669, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0931 (Recon: 0.0931, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0834 | Avg Valid recon Loss: 0.0834\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0624, recon=0.0624, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0905 (Recon: 0.0905, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0807 | Avg Valid recon Loss: 0.0807\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0623, recon=0.0623, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0871 (Recon: 0.0871, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0789 | Avg Valid recon Loss: 0.0789\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0674, recon=0.0674, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0849 (Recon: 0.0849, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0767 | Avg Valid recon Loss: 0.0767\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1071, recon=0.1071, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0818 (Recon: 0.0818, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0750 | Avg Valid recon Loss: 0.0750\n",
      "\n",
      "[VRAE Run 280/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1572, recon=0.1572, kl=48.5197, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3435 (Recon: 0.3435, KL: 25.8098, Current Beta: 0.0000) | Avg Valid Loss: 0.1488 | Avg Valid recon Loss: 0.1488\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1458, recon=0.1458, kl=74.9162, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1315 (Recon: 0.1315, KL: 66.9736, Current Beta: 0.0000) | Avg Valid Loss: 0.0960 | Avg Valid recon Loss: 0.0960\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0643, recon=0.0643, kl=77.0911, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0960 (Recon: 0.0960, KL: 75.8189, Current Beta: 0.0000) | Avg Valid Loss: 0.0774 | Avg Valid recon Loss: 0.0774\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.2180, recon=0.2180, kl=80.2063, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0771 (Recon: 0.0771, KL: 79.5194, Current Beta: 0.0000) | Avg Valid Loss: 0.0655 | Avg Valid recon Loss: 0.0655\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0564, recon=0.0564, kl=71.2271, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0695 (Recon: 0.0695, KL: 76.5536, Current Beta: 0.0000) | Avg Valid Loss: 0.0670 | Avg Valid recon Loss: 0.0670\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0758, recon=0.0757, kl=54.9577, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0636 (Recon: 0.0636, KL: 62.0874, Current Beta: 0.0000) | Avg Valid Loss: 0.0576 | Avg Valid recon Loss: 0.0576\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0561, recon=0.0561, kl=40.5031, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0579 (Recon: 0.0579, KL: 45.8849, Current Beta: 0.0000) | Avg Valid Loss: 0.0504 | Avg Valid recon Loss: 0.0504\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0470, recon=0.0470, kl=24.5428, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0532 (Recon: 0.0531, KL: 26.4268, Current Beta: 0.0000) | Avg Valid Loss: 0.0494 | Avg Valid recon Loss: 0.0494\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0401, recon=0.0400, kl=13.0469, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0517, KL: 15.1275, Current Beta: 0.0000) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0456\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0453, recon=0.0453, kl=3.5867, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0484 (Recon: 0.0483, KL: 4.7869, Current Beta: 0.0000) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0454\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0382, recon=0.0382, kl=0.5685, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0423, KL: 0.8562, Current Beta: 0.0000) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0373, recon=0.0373, kl=0.0653, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0451 (Recon: 0.0451, KL: 0.1191, Current Beta: 0.0001) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0275, recon=0.0275, kl=0.0058, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0423, KL: 0.0170, Current Beta: 0.0002) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0518, recon=0.0518, kl=0.0030, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0415, KL: 0.0029, Current Beta: 0.0004) | Avg Valid Loss: 0.0387 | Avg Valid recon Loss: 0.0387\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0407, recon=0.0407, kl=0.0007, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0414, KL: 0.0009, Current Beta: 0.0006) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0313, recon=0.0313, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0392, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0309, recon=0.0309, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0384 (Recon: 0.0384, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0350 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0261, recon=0.0261, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0382, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0297, recon=0.0297, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0368 (Recon: 0.0368, KL: 0.0004, Current Beta: 0.0010) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0334\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0258, recon=0.0258, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0354 (Recon: 0.0354, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0352\n",
      "\n",
      "[VRAE Run 281/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4598, recon=0.4598, kl=4.0153, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6861 (Recon: 0.6861, KL: 1.6210, Current Beta: 0.0000) | Avg Valid Loss: 0.5052 | Avg Valid recon Loss: 0.5052\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3259, recon=0.3259, kl=59.1681, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3922 (Recon: 0.3922, KL: 36.4398, Current Beta: 0.0000) | Avg Valid Loss: 0.3240 | Avg Valid recon Loss: 0.3240\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2932, recon=0.2932, kl=99.8456, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2795 (Recon: 0.2795, KL: 84.7809, Current Beta: 0.0000) | Avg Valid Loss: 0.2304 | Avg Valid recon Loss: 0.2304\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.2210, recon=0.2210, kl=128.3746, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2253 (Recon: 0.2253, KL: 118.1216, Current Beta: 0.0000) | Avg Valid Loss: 0.1832 | Avg Valid recon Loss: 0.1832\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2245, recon=0.2245, kl=145.8424, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1933 (Recon: 0.1933, KL: 140.9172, Current Beta: 0.0000) | Avg Valid Loss: 0.1575 | Avg Valid recon Loss: 0.1575\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1737, recon=0.1736, kl=135.9996, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1700 (Recon: 0.1699, KL: 141.9708, Current Beta: 0.0000) | Avg Valid Loss: 0.1400 | Avg Valid recon Loss: 0.1400\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1420, recon=0.1420, kl=101.6644, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1542 (Recon: 0.1541, KL: 116.9999, Current Beta: 0.0000) | Avg Valid Loss: 0.1273 | Avg Valid recon Loss: 0.1272\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1168, recon=0.1167, kl=51.5963, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1414 (Recon: 0.1413, KL: 70.8107, Current Beta: 0.0000) | Avg Valid Loss: 0.1180 | Avg Valid recon Loss: 0.1180\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.3313, recon=0.3312, kl=19.4237, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1318 (Recon: 0.1317, KL: 29.0526, Current Beta: 0.0000) | Avg Valid Loss: 0.1101 | Avg Valid recon Loss: 0.1101\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1282, recon=0.1281, kl=6.0080, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1142 (Recon: 0.1140, KL: 9.9503, Current Beta: 0.0000) | Avg Valid Loss: 0.1048 | Avg Valid recon Loss: 0.1048\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0981, recon=0.0980, kl=2.0370, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1176 (Recon: 0.1175, KL: 2.8005, Current Beta: 0.0000) | Avg Valid Loss: 0.0995 | Avg Valid recon Loss: 0.0995\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1569, recon=0.1568, kl=0.5847, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1109 (Recon: 0.1108, KL: 0.7667, Current Beta: 0.0001) | Avg Valid Loss: 0.0964 | Avg Valid recon Loss: 0.0964\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1382, recon=0.1382, kl=0.1000, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.1054 (Recon: 0.1053, KL: 0.1543, Current Beta: 0.0002) | Avg Valid Loss: 0.0925 | Avg Valid recon Loss: 0.0925\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0852, recon=0.0852, kl=0.0192, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.1012 (Recon: 0.1012, KL: 0.0220, Current Beta: 0.0004) | Avg Valid Loss: 0.0892 | Avg Valid recon Loss: 0.0892\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1319, recon=0.1319, kl=0.0030, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0972 (Recon: 0.0972, KL: 0.0041, Current Beta: 0.0006) | Avg Valid Loss: 0.0860 | Avg Valid recon Loss: 0.0860\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0752, recon=0.0752, kl=0.0010, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0926 (Recon: 0.0926, KL: 0.0012, Current Beta: 0.0010) | Avg Valid Loss: 0.0831 | Avg Valid recon Loss: 0.0831\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0586, recon=0.0586, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0904 (Recon: 0.0904, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0805 | Avg Valid recon Loss: 0.0805\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0745, recon=0.0745, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0882 (Recon: 0.0882, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0797 | Avg Valid recon Loss: 0.0797\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0869, recon=0.0869, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0852 (Recon: 0.0852, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0775 | Avg Valid recon Loss: 0.0775\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.2250, recon=0.2250, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0834 (Recon: 0.0834, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0756 | Avg Valid recon Loss: 0.0756\n",
      "\n",
      "[VRAE Run 282/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1747, recon=0.1747, kl=95.1694, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3498 (Recon: 0.3498, KL: 61.3096, Current Beta: 0.0000) | Avg Valid Loss: 0.1486 | Avg Valid recon Loss: 0.1486\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1023, recon=0.1023, kl=137.7973, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1347 (Recon: 0.1347, KL: 122.4802, Current Beta: 0.0000) | Avg Valid Loss: 0.0983 | Avg Valid recon Loss: 0.0983\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0758, recon=0.0758, kl=157.0641, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0976 (Recon: 0.0976, KL: 149.4076, Current Beta: 0.0000) | Avg Valid Loss: 0.0789 | Avg Valid recon Loss: 0.0789\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0628, recon=0.0628, kl=157.7646, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0811 (Recon: 0.0811, KL: 162.1343, Current Beta: 0.0000) | Avg Valid Loss: 0.0703 | Avg Valid recon Loss: 0.0703\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0489, recon=0.0489, kl=123.8243, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0695 (Recon: 0.0695, KL: 137.3394, Current Beta: 0.0000) | Avg Valid Loss: 0.0631 | Avg Valid recon Loss: 0.0631\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1773, recon=0.1773, kl=94.8607, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0662 (Recon: 0.0662, KL: 100.8742, Current Beta: 0.0000) | Avg Valid Loss: 0.0586 | Avg Valid recon Loss: 0.0586\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0437, recon=0.0437, kl=76.0058, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0592 (Recon: 0.0591, KL: 73.2366, Current Beta: 0.0000) | Avg Valid Loss: 0.0528 | Avg Valid recon Loss: 0.0527\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0402, recon=0.0402, kl=41.9883, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0574 (Recon: 0.0574, KL: 46.5885, Current Beta: 0.0000) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0509\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0389, recon=0.0388, kl=21.5494, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0530 (Recon: 0.0529, KL: 24.1002, Current Beta: 0.0000) | Avg Valid Loss: 0.0491 | Avg Valid recon Loss: 0.0490\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0387, recon=0.0386, kl=6.0055, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 6.8717, Current Beta: 0.0000) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0459\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0494, recon=0.0494, kl=0.4889, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0497 (Recon: 0.0497, KL: 1.6055, Current Beta: 0.0000) | Avg Valid Loss: 0.0439 | Avg Valid recon Loss: 0.0439\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0375, recon=0.0375, kl=0.1060, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0471, KL: 0.2447, Current Beta: 0.0001) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0597, recon=0.0597, kl=0.0115, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0455, KL: 0.0293, Current Beta: 0.0002) | Avg Valid Loss: 0.0411 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0290, recon=0.0290, kl=0.0058, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0430 (Recon: 0.0430, KL: 0.0053, Current Beta: 0.0004) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0442, recon=0.0442, kl=0.0011, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 0.0016, Current Beta: 0.0006) | Avg Valid Loss: 0.0399 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0410, recon=0.0410, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0427 (Recon: 0.0427, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0276, recon=0.0276, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0409 (Recon: 0.0409, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0372 | Avg Valid recon Loss: 0.0372\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0397 (Recon: 0.0397, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0361\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0423, recon=0.0423, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0392, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0294, recon=0.0294, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0393 (Recon: 0.0393, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0358\n",
      "\n",
      "[VRAE Run 283/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3914, recon=0.3914, kl=6.9272, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4920 (Recon: 0.4920, KL: 2.0382, Current Beta: 0.0000) | Avg Valid Loss: 0.2863 | Avg Valid recon Loss: 0.2863\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2820, recon=0.2820, kl=23.2199, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2375 (Recon: 0.2375, KL: 17.2744, Current Beta: 0.0000) | Avg Valid Loss: 0.1725 | Avg Valid recon Loss: 0.1725\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1328, recon=0.1328, kl=32.4871, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1773 (Recon: 0.1773, KL: 29.2235, Current Beta: 0.0000) | Avg Valid Loss: 0.1332 | Avg Valid recon Loss: 0.1332\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1260, recon=0.1260, kl=42.6674, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1502 (Recon: 0.1502, KL: 38.8681, Current Beta: 0.0000) | Avg Valid Loss: 0.1148 | Avg Valid recon Loss: 0.1148\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1651, recon=0.1651, kl=51.6643, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1323 (Recon: 0.1323, KL: 49.6151, Current Beta: 0.0000) | Avg Valid Loss: 0.1019 | Avg Valid recon Loss: 0.1019\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0944, recon=0.0944, kl=47.1986, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1192 (Recon: 0.1192, KL: 53.5543, Current Beta: 0.0000) | Avg Valid Loss: 0.0937 | Avg Valid recon Loss: 0.0937\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0943, recon=0.0943, kl=24.5648, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1081 (Recon: 0.1080, KL: 32.3602, Current Beta: 0.0000) | Avg Valid Loss: 0.0867 | Avg Valid recon Loss: 0.0866\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0708, recon=0.0708, kl=11.5756, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0970 (Recon: 0.0970, KL: 16.0626, Current Beta: 0.0000) | Avg Valid Loss: 0.0831 | Avg Valid recon Loss: 0.0830\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0684, recon=0.0684, kl=3.8113, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0928 (Recon: 0.0928, KL: 5.6547, Current Beta: 0.0000) | Avg Valid Loss: 0.0771 | Avg Valid recon Loss: 0.0770\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0654, recon=0.0653, kl=1.6105, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0800 (Recon: 0.0800, KL: 1.8306, Current Beta: 0.0000) | Avg Valid Loss: 0.0739 | Avg Valid recon Loss: 0.0739\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0698, recon=0.0698, kl=0.3135, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0829 (Recon: 0.0829, KL: 0.4401, Current Beta: 0.0000) | Avg Valid Loss: 0.0713 | Avg Valid recon Loss: 0.0713\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0730, recon=0.0730, kl=0.0468, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0793 (Recon: 0.0793, KL: 0.1115, Current Beta: 0.0001) | Avg Valid Loss: 0.0683 | Avg Valid recon Loss: 0.0682\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0548, recon=0.0548, kl=0.0075, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0757 (Recon: 0.0757, KL: 0.0207, Current Beta: 0.0002) | Avg Valid Loss: 0.0649 | Avg Valid recon Loss: 0.0649\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0549, recon=0.0549, kl=0.0022, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0709 (Recon: 0.0709, KL: 0.0038, Current Beta: 0.0004) | Avg Valid Loss: 0.0633 | Avg Valid recon Loss: 0.0633\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0557, recon=0.0557, kl=0.0008, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0704 (Recon: 0.0704, KL: 0.0010, Current Beta: 0.0006) | Avg Valid Loss: 0.0610 | Avg Valid recon Loss: 0.0610\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0769, recon=0.0769, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0664 (Recon: 0.0664, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0595 | Avg Valid recon Loss: 0.0595\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0460, recon=0.0460, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0654 (Recon: 0.0654, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0588 | Avg Valid recon Loss: 0.0588\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0740, recon=0.0740, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0640 (Recon: 0.0640, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0568 | Avg Valid recon Loss: 0.0568\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1765, recon=0.1765, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0619 (Recon: 0.0619, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0560 | Avg Valid recon Loss: 0.0560\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0430, recon=0.0430, kl=0.0001, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0594 (Recon: 0.0594, KL: 0.0002, Current Beta: 0.0010) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0541\n",
      "\n",
      "[VRAE Run 284/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1628, recon=0.1628, kl=25.5009, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2652 (Recon: 0.2652, KL: 14.1889, Current Beta: 0.0000) | Avg Valid Loss: 0.1108 | Avg Valid recon Loss: 0.1108\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0884, recon=0.0884, kl=42.0713, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1060 (Recon: 0.1060, KL: 35.3144, Current Beta: 0.0000) | Avg Valid Loss: 0.0740 | Avg Valid recon Loss: 0.0740\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0552, recon=0.0552, kl=47.6317, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0810 (Recon: 0.0810, KL: 42.7807, Current Beta: 0.0000) | Avg Valid Loss: 0.0620 | Avg Valid recon Loss: 0.0620\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0443, recon=0.0443, kl=35.9900, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0660 (Recon: 0.0660, KL: 43.1664, Current Beta: 0.0000) | Avg Valid Loss: 0.0534 | Avg Valid recon Loss: 0.0534\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0366, recon=0.0366, kl=40.4129, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0574 (Recon: 0.0574, KL: 39.4103, Current Beta: 0.0000) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0479, recon=0.0479, kl=35.7198, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0513 (Recon: 0.0513, KL: 37.2130, Current Beta: 0.0000) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0332, recon=0.0332, kl=24.7523, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0474 (Recon: 0.0474, KL: 29.6613, Current Beta: 0.0000) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0378, recon=0.0377, kl=20.6263, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0443 (Recon: 0.0442, KL: 19.9604, Current Beta: 0.0000) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0391\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0323, recon=0.0322, kl=13.0544, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0418 (Recon: 0.0417, KL: 13.0855, Current Beta: 0.0000) | Avg Valid Loss: 0.0366 | Avg Valid recon Loss: 0.0366\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0366, recon=0.0366, kl=4.6357, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0361, KL: 5.5598, Current Beta: 0.0000) | Avg Valid Loss: 0.0359 | Avg Valid recon Loss: 0.0359\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0338, recon=0.0337, kl=1.2857, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0379 (Recon: 0.0378, KL: 1.5737, Current Beta: 0.0000) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0258, recon=0.0258, kl=0.1310, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0371 (Recon: 0.0371, KL: 0.2893, Current Beta: 0.0001) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0297, recon=0.0297, kl=0.0164, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0363 (Recon: 0.0363, KL: 0.0411, Current Beta: 0.0002) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=0.0049, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0352 (Recon: 0.0352, KL: 0.0061, Current Beta: 0.0004) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0332\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0532, recon=0.0532, kl=0.0011, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0342 (Recon: 0.0342, KL: 0.0021, Current Beta: 0.0006) | Avg Valid Loss: 0.0301 | Avg Valid recon Loss: 0.0301\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0438, recon=0.0438, kl=0.0006, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0329 (Recon: 0.0329, KL: 0.0006, Current Beta: 0.0010) | Avg Valid Loss: 0.0302 | Avg Valid recon Loss: 0.0302\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0318, recon=0.0318, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0330 (Recon: 0.0330, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0316, recon=0.0316, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0338 (Recon: 0.0338, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0292 | Avg Valid recon Loss: 0.0292\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0234, recon=0.0234, kl=0.0003, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0310 (Recon: 0.0310, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0284 | Avg Valid recon Loss: 0.0284\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0307, recon=0.0307, kl=0.0002, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0307 (Recon: 0.0307, KL: 0.0003, Current Beta: 0.0010) | Avg Valid Loss: 0.0271 | Avg Valid recon Loss: 0.0271\n",
      "\n",
      "[VRAE Run 285/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3119, recon=0.3119, kl=14.3987, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5231 (Recon: 0.5231, KL: 4.1384, Current Beta: 0.0000) | Avg Valid Loss: 0.2960 | Avg Valid recon Loss: 0.2960\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2710, recon=0.2710, kl=59.1612, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2408 (Recon: 0.2408, KL: 45.8289, Current Beta: 0.0000) | Avg Valid Loss: 0.1710 | Avg Valid recon Loss: 0.1710\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1460, recon=0.1460, kl=73.2905, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1746 (Recon: 0.1746, KL: 67.9557, Current Beta: 0.0000) | Avg Valid Loss: 0.1347 | Avg Valid recon Loss: 0.1347\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1119, recon=0.1119, kl=86.2273, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1501 (Recon: 0.1500, KL: 81.4911, Current Beta: 0.0000) | Avg Valid Loss: 0.1140 | Avg Valid recon Loss: 0.1140\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1069, recon=0.1069, kl=91.4213, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1205 (Recon: 0.1205, KL: 90.2904, Current Beta: 0.0000) | Avg Valid Loss: 0.1025 | Avg Valid recon Loss: 0.1025\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1298, recon=0.1298, kl=72.4701, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1190 (Recon: 0.1190, KL: 81.1640, Current Beta: 0.0000) | Avg Valid Loss: 0.0935 | Avg Valid recon Loss: 0.0935\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1007, recon=0.1007, kl=42.0690, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1080 (Recon: 0.1079, KL: 54.3731, Current Beta: 0.0000) | Avg Valid Loss: 0.0901 | Avg Valid recon Loss: 0.0901\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0835, recon=0.0835, kl=18.4303, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1000 (Recon: 0.1000, KL: 25.8515, Current Beta: 0.0000) | Avg Valid Loss: 0.0815 | Avg Valid recon Loss: 0.0815\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0903, recon=0.0902, kl=5.6841, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0908 (Recon: 0.0908, KL: 9.8855, Current Beta: 0.0000) | Avg Valid Loss: 0.0769 | Avg Valid recon Loss: 0.0769\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0772, recon=0.0772, kl=1.9974, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0877 (Recon: 0.0877, KL: 2.7644, Current Beta: 0.0000) | Avg Valid Loss: 0.0739 | Avg Valid recon Loss: 0.0739\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0804, recon=0.0804, kl=0.5790, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0768 (Recon: 0.0768, KL: 0.6847, Current Beta: 0.0000) | Avg Valid Loss: 0.0707 | Avg Valid recon Loss: 0.0706\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0718, recon=0.0718, kl=0.1020, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0797 (Recon: 0.0797, KL: 0.1340, Current Beta: 0.0001) | Avg Valid Loss: 0.0685 | Avg Valid recon Loss: 0.0685\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0863, recon=0.0863, kl=0.0171, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0764 (Recon: 0.0764, KL: 0.0204, Current Beta: 0.0002) | Avg Valid Loss: 0.0661 | Avg Valid recon Loss: 0.0661\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0579, recon=0.0579, kl=0.0045, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0741 (Recon: 0.0741, KL: 0.0053, Current Beta: 0.0004) | Avg Valid Loss: 0.0640 | Avg Valid recon Loss: 0.0640\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0545, recon=0.0545, kl=0.0015, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0711 (Recon: 0.0711, KL: 0.0029, Current Beta: 0.0006) | Avg Valid Loss: 0.0621 | Avg Valid recon Loss: 0.0621\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0753, recon=0.0753, kl=0.0011, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0684 (Recon: 0.0684, KL: 0.0013, Current Beta: 0.0010) | Avg Valid Loss: 0.0600 | Avg Valid recon Loss: 0.0600\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0556, recon=0.0556, kl=0.0017, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0671 (Recon: 0.0671, KL: 0.0011, Current Beta: 0.0010) | Avg Valid Loss: 0.0590 | Avg Valid recon Loss: 0.0590\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0624, recon=0.0624, kl=0.0007, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0647 (Recon: 0.0647, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0567 | Avg Valid recon Loss: 0.0567\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0555, recon=0.0555, kl=0.0013, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0621 (Recon: 0.0621, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0563 | Avg Valid recon Loss: 0.0563\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0476, recon=0.0476, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0599 (Recon: 0.0599, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0546 | Avg Valid recon Loss: 0.0546\n",
      "\n",
      "[VRAE Run 286/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3672, recon=0.3672, kl=53.1910, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2792 (Recon: 0.2792, KL: 29.7391, Current Beta: 0.0000) | Avg Valid Loss: 0.1123 | Avg Valid recon Loss: 0.1123\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0843, recon=0.0843, kl=65.0964, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1125 (Recon: 0.1125, KL: 60.1187, Current Beta: 0.0000) | Avg Valid Loss: 0.0811 | Avg Valid recon Loss: 0.0811\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0491, recon=0.0491, kl=61.1203, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0794 (Recon: 0.0794, KL: 62.1130, Current Beta: 0.0000) | Avg Valid Loss: 0.0596 | Avg Valid recon Loss: 0.0596\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=63.4425, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0635 (Recon: 0.0635, KL: 61.4635, Current Beta: 0.0000) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0537\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1599, recon=0.1599, kl=70.2274, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0570 (Recon: 0.0570, KL: 70.1391, Current Beta: 0.0000) | Avg Valid Loss: 0.0486 | Avg Valid recon Loss: 0.0486\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0342, recon=0.0341, kl=60.1808, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0522 (Recon: 0.0522, KL: 65.8186, Current Beta: 0.0000) | Avg Valid Loss: 0.0437 | Avg Valid recon Loss: 0.0437\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0512, recon=0.0512, kl=41.1891, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0457, KL: 47.7686, Current Beta: 0.0000) | Avg Valid Loss: 0.0397 | Avg Valid recon Loss: 0.0396\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0353, recon=0.0353, kl=23.0828, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 29.4673, Current Beta: 0.0000) | Avg Valid Loss: 0.0386 | Avg Valid recon Loss: 0.0386\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0329, recon=0.0328, kl=14.0169, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0421 (Recon: 0.0420, KL: 16.2641, Current Beta: 0.0000) | Avg Valid Loss: 0.0369 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0385, recon=0.0385, kl=6.0501, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0401 (Recon: 0.0400, KL: 7.3580, Current Beta: 0.0000) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0357\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0297, recon=0.0297, kl=1.3264, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0374 (Recon: 0.0374, KL: 1.9985, Current Beta: 0.0000) | Avg Valid Loss: 0.0336 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0435, recon=0.0435, kl=0.1748, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0364 (Recon: 0.0364, KL: 0.2943, Current Beta: 0.0001) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0317\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0354, recon=0.0354, kl=0.0123, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0343 (Recon: 0.0342, KL: 0.0339, Current Beta: 0.0002) | Avg Valid Loss: 0.0309 | Avg Valid recon Loss: 0.0309\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0506, recon=0.0506, kl=0.0041, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0342 (Recon: 0.0342, KL: 0.0067, Current Beta: 0.0004) | Avg Valid Loss: 0.0306 | Avg Valid recon Loss: 0.0306\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0255, recon=0.0255, kl=0.0029, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0334 (Recon: 0.0334, KL: 0.0019, Current Beta: 0.0006) | Avg Valid Loss: 0.0295 | Avg Valid recon Loss: 0.0295\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0350, recon=0.0350, kl=0.0011, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0326 (Recon: 0.0326, KL: 0.0010, Current Beta: 0.0010) | Avg Valid Loss: 0.0310 | Avg Valid recon Loss: 0.0310\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0284, recon=0.0284, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0315 (Recon: 0.0315, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0301 | Avg Valid recon Loss: 0.0301\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0320, recon=0.0320, kl=0.0004, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0325 (Recon: 0.0325, KL: 0.0005, Current Beta: 0.0010) | Avg Valid Loss: 0.0309 | Avg Valid recon Loss: 0.0309\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0256, recon=0.0256, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0324 (Recon: 0.0324, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0295 | Avg Valid recon Loss: 0.0295\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0250, recon=0.0250, kl=0.0009, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0321 (Recon: 0.0321, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0286 | Avg Valid recon Loss: 0.0286\n",
      "\n",
      "[VRAE Run 287/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3296, recon=0.3296, kl=24.0477, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5093 (Recon: 0.5093, KL: 6.7092, Current Beta: 0.0000) | Avg Valid Loss: 0.2969 | Avg Valid recon Loss: 0.2969\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1609, recon=0.1609, kl=132.4652, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2450 (Recon: 0.2450, KL: 99.5453, Current Beta: 0.0000) | Avg Valid Loss: 0.1751 | Avg Valid recon Loss: 0.1751\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1373, recon=0.1373, kl=172.0590, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1809 (Recon: 0.1809, KL: 157.8942, Current Beta: 0.0000) | Avg Valid Loss: 0.1358 | Avg Valid recon Loss: 0.1358\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1366, recon=0.1366, kl=191.4885, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1496 (Recon: 0.1496, KL: 186.1554, Current Beta: 0.0000) | Avg Valid Loss: 0.1160 | Avg Valid recon Loss: 0.1160\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1897, recon=0.1897, kl=172.1802, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1346 (Recon: 0.1346, KL: 182.1990, Current Beta: 0.0000) | Avg Valid Loss: 0.1052 | Avg Valid recon Loss: 0.1052\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0982, recon=0.0982, kl=129.3782, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1225 (Recon: 0.1225, KL: 147.2328, Current Beta: 0.0000) | Avg Valid Loss: 0.0962 | Avg Valid recon Loss: 0.0962\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1039, recon=0.1039, kl=72.9811, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1097 (Recon: 0.1096, KL: 94.1896, Current Beta: 0.0000) | Avg Valid Loss: 0.0883 | Avg Valid recon Loss: 0.0883\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0801, recon=0.0801, kl=30.3853, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1035 (Recon: 0.1034, KL: 43.5052, Current Beta: 0.0000) | Avg Valid Loss: 0.0845 | Avg Valid recon Loss: 0.0845\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0682, recon=0.0682, kl=9.7926, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0974 (Recon: 0.0974, KL: 15.3579, Current Beta: 0.0000) | Avg Valid Loss: 0.0816 | Avg Valid recon Loss: 0.0815\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0801, recon=0.0800, kl=3.1156, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0913 (Recon: 0.0913, KL: 4.5770, Current Beta: 0.0000) | Avg Valid Loss: 0.0760 | Avg Valid recon Loss: 0.0759\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0737, recon=0.0737, kl=1.1642, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0868 (Recon: 0.0867, KL: 1.2701, Current Beta: 0.0000) | Avg Valid Loss: 0.0742 | Avg Valid recon Loss: 0.0742\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0646, recon=0.0646, kl=0.2362, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0822 (Recon: 0.0822, KL: 0.2906, Current Beta: 0.0001) | Avg Valid Loss: 0.0695 | Avg Valid recon Loss: 0.0695\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0967, recon=0.0967, kl=0.0343, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0771 (Recon: 0.0771, KL: 0.0524, Current Beta: 0.0002) | Avg Valid Loss: 0.0669 | Avg Valid recon Loss: 0.0669\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0656, recon=0.0656, kl=0.0046, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0752 (Recon: 0.0752, KL: 0.0092, Current Beta: 0.0004) | Avg Valid Loss: 0.0662 | Avg Valid recon Loss: 0.0662\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0618, recon=0.0618, kl=0.0035, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0726 (Recon: 0.0726, KL: 0.0036, Current Beta: 0.0006) | Avg Valid Loss: 0.0628 | Avg Valid recon Loss: 0.0628\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0526, recon=0.0526, kl=0.0027, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0704 (Recon: 0.0704, KL: 0.0016, Current Beta: 0.0010) | Avg Valid Loss: 0.0613 | Avg Valid recon Loss: 0.0613\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0511, recon=0.0511, kl=0.0017, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0687 (Recon: 0.0687, KL: 0.0016, Current Beta: 0.0010) | Avg Valid Loss: 0.0597 | Avg Valid recon Loss: 0.0597\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0539, recon=0.0539, kl=0.0012, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0659 (Recon: 0.0659, KL: 0.0016, Current Beta: 0.0010) | Avg Valid Loss: 0.0588 | Avg Valid recon Loss: 0.0588\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0538, recon=0.0538, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0644 (Recon: 0.0644, KL: 0.0012, Current Beta: 0.0010) | Avg Valid Loss: 0.0603 | Avg Valid recon Loss: 0.0603\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0490, recon=0.0490, kl=0.0013, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0635 (Recon: 0.0635, KL: 0.0011, Current Beta: 0.0010) | Avg Valid Loss: 0.0561 | Avg Valid recon Loss: 0.0561\n",
      "\n",
      "[VRAE Run 288/324] Training with params: {'batch_size': 256, 'beta': 0.001, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1273, recon=0.1273, kl=65.4159, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2697 (Recon: 0.2697, KL: 30.3402, Current Beta: 0.0000) | Avg Valid Loss: 0.1135 | Avg Valid recon Loss: 0.1135\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0739, recon=0.0739, kl=121.7570, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1088 (Recon: 0.1088, KL: 111.5145, Current Beta: 0.0000) | Avg Valid Loss: 0.0780 | Avg Valid recon Loss: 0.0780\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0541, recon=0.0541, kl=132.6953, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0807 (Recon: 0.0807, KL: 128.9693, Current Beta: 0.0000) | Avg Valid Loss: 0.0645 | Avg Valid recon Loss: 0.0645\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0787, recon=0.0787, kl=131.3226, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0657 (Recon: 0.0657, KL: 135.1651, Current Beta: 0.0000) | Avg Valid Loss: 0.0599 | Avg Valid recon Loss: 0.0599\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0362, recon=0.0362, kl=123.3008, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0604 (Recon: 0.0604, KL: 88.3984, Current Beta: 0.0000) | Avg Valid Loss: 0.0483 | Avg Valid recon Loss: 0.0483\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0507, recon=0.0507, kl=148.4489, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0534 (Recon: 0.0534, KL: 144.0851, Current Beta: 0.0000) | Avg Valid Loss: 0.0475 | Avg Valid recon Loss: 0.0474\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0341, recon=0.0340, kl=119.3647, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0476 (Recon: 0.0475, KL: 133.5021, Current Beta: 0.0000) | Avg Valid Loss: 0.0412 | Avg Valid recon Loss: 0.0411\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0424, recon=0.0423, kl=74.3234, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0445, KL: 90.1004, Current Beta: 0.0000) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0400\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0355, recon=0.0353, kl=46.6873, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0446 (Recon: 0.0444, KL: 56.2152, Current Beta: 0.0000) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0382\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0516, recon=0.0513, kl=22.3230, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0408 (Recon: 0.0405, KL: 28.0063, Current Beta: 0.0000) | Avg Valid Loss: 0.0365 | Avg Valid recon Loss: 0.0362\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0841, recon=0.0839, kl=4.8136, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0387, KL: 8.1234, Current Beta: 0.0000) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0346\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0424, recon=0.0424, kl=0.6641, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0374 (Recon: 0.0373, KL: 1.2780, Current Beta: 0.0001) | Avg Valid Loss: 0.0356 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0304, recon=0.0304, kl=0.1278, beta=0.0002\n",
      "  â†’ Avg Train Loss: 0.0371 (Recon: 0.0370, KL: 0.2450, Current Beta: 0.0002) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0340\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0302, recon=0.0302, kl=0.0104, beta=0.0004\n",
      "  â†’ Avg Train Loss: 0.0353 (Recon: 0.0353, KL: 0.0301, Current Beta: 0.0004) | Avg Valid Loss: 0.0309 | Avg Valid recon Loss: 0.0309\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0684, recon=0.0684, kl=0.0029, beta=0.0006\n",
      "  â†’ Avg Train Loss: 0.0345 (Recon: 0.0345, KL: 0.0035, Current Beta: 0.0006) | Avg Valid Loss: 0.0303 | Avg Valid recon Loss: 0.0303\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0388, recon=0.0388, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0343 (Recon: 0.0343, KL: 0.0017, Current Beta: 0.0010) | Avg Valid Loss: 0.0333 | Avg Valid recon Loss: 0.0333\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0336, recon=0.0336, kl=0.0010, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0358 (Recon: 0.0358, KL: 0.0014, Current Beta: 0.0010) | Avg Valid Loss: 0.0324 | Avg Valid recon Loss: 0.0324\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0289, recon=0.0289, kl=0.0008, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0341 (Recon: 0.0341, KL: 0.0007, Current Beta: 0.0010) | Avg Valid Loss: 0.0321 | Avg Valid recon Loss: 0.0321\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0292, recon=0.0292, kl=0.0015, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0336 (Recon: 0.0336, KL: 0.0009, Current Beta: 0.0010) | Avg Valid Loss: 0.0351 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0277, recon=0.0277, kl=0.0005, beta=0.0010\n",
      "  â†’ Avg Train Loss: 0.0341 (Recon: 0.0341, KL: 0.0008, Current Beta: 0.0010) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0304\n",
      "\n",
      "[VRAE Run 289/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.8224, recon=0.8224, kl=0.2673, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.9289 (Recon: 0.9289, KL: 0.2119, Current Beta: 0.0000) | Avg Valid Loss: 0.7809 | Avg Valid recon Loss: 0.7809\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.5644, recon=0.5644, kl=1.9646, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6365 (Recon: 0.6365, KL: 1.0036, Current Beta: 0.0000) | Avg Valid Loss: 0.5551 | Avg Valid recon Loss: 0.5551\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.5063, recon=0.5063, kl=8.2910, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4883 (Recon: 0.4883, KL: 5.9570, Current Beta: 0.0000) | Avg Valid Loss: 0.4502 | Avg Valid recon Loss: 0.4502\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.3492, recon=0.3492, kl=13.4546, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4122 (Recon: 0.4122, KL: 11.3487, Current Beta: 0.0000) | Avg Valid Loss: 0.3887 | Avg Valid recon Loss: 0.3887\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.3049, recon=0.3049, kl=14.5435, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3655 (Recon: 0.3655, KL: 14.6176, Current Beta: 0.0000) | Avg Valid Loss: 0.3408 | Avg Valid recon Loss: 0.3408\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.3073, recon=0.3072, kl=9.8238, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3302 (Recon: 0.3301, KL: 11.9259, Current Beta: 0.0000) | Avg Valid Loss: 0.3035 | Avg Valid recon Loss: 0.3034\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.3114, recon=0.3114, kl=4.2987, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3041 (Recon: 0.3041, KL: 6.3197, Current Beta: 0.0000) | Avg Valid Loss: 0.2739 | Avg Valid recon Loss: 0.2739\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.3292, recon=0.3292, kl=1.0331, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2793 (Recon: 0.2793, KL: 2.0348, Current Beta: 0.0000) | Avg Valid Loss: 0.2495 | Avg Valid recon Loss: 0.2495\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.2636, recon=0.2636, kl=0.2395, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2605 (Recon: 0.2605, KL: 0.4728, Current Beta: 0.0000) | Avg Valid Loss: 0.2297 | Avg Valid recon Loss: 0.2297\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1907, recon=0.1907, kl=0.0449, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.2433 (Recon: 0.2433, KL: 0.1203, Current Beta: 0.0001) | Avg Valid Loss: 0.2128 | Avg Valid recon Loss: 0.2128\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1944, recon=0.1944, kl=0.0042, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.2306 (Recon: 0.2306, KL: 0.0138, Current Beta: 0.0003) | Avg Valid Loss: 0.1993 | Avg Valid recon Loss: 0.1993\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.2254, recon=0.2254, kl=0.0010, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.2161 (Recon: 0.2161, KL: 0.0020, Current Beta: 0.0008) | Avg Valid Loss: 0.1878 | Avg Valid recon Loss: 0.1878\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1606, recon=0.1606, kl=0.0003, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.2052 (Recon: 0.2052, KL: 0.0006, Current Beta: 0.0018) | Avg Valid Loss: 0.1773 | Avg Valid recon Loss: 0.1773\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.2775, recon=0.2775, kl=0.0003, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1965 (Recon: 0.1965, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.1686 | Avg Valid recon Loss: 0.1686\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1926, recon=0.1926, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.1879 (Recon: 0.1879, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.1610 | Avg Valid recon Loss: 0.1610\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1447, recon=0.1447, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1797 (Recon: 0.1797, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.1545 | Avg Valid recon Loss: 0.1545\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1492, recon=0.1492, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1721 (Recon: 0.1721, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.1479 | Avg Valid recon Loss: 0.1479\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1335, recon=0.1335, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1643 (Recon: 0.1643, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1429 | Avg Valid recon Loss: 0.1429\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1293, recon=0.1293, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1594 (Recon: 0.1594, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1383 | Avg Valid recon Loss: 0.1383\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1500, recon=0.1500, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1521 (Recon: 0.1521, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1333 | Avg Valid recon Loss: 0.1333\n",
      "\n",
      "[VRAE Run 290/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2890, recon=0.2890, kl=15.0192, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4899 (Recon: 0.4899, KL: 7.1892, Current Beta: 0.0000) | Avg Valid Loss: 0.2496 | Avg Valid recon Loss: 0.2496\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1543, recon=0.1543, kl=23.9975, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2287 (Recon: 0.2287, KL: 21.5941, Current Beta: 0.0000) | Avg Valid Loss: 0.1540 | Avg Valid recon Loss: 0.1540\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1078, recon=0.1078, kl=27.6582, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1535 (Recon: 0.1535, KL: 26.6974, Current Beta: 0.0000) | Avg Valid Loss: 0.1167 | Avg Valid recon Loss: 0.1167\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0916, recon=0.0916, kl=21.0373, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1200 (Recon: 0.1200, KL: 23.4308, Current Beta: 0.0000) | Avg Valid Loss: 0.0972 | Avg Valid recon Loss: 0.0971\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1468, recon=0.1467, kl=13.7344, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1027 (Recon: 0.1027, KL: 15.7179, Current Beta: 0.0000) | Avg Valid Loss: 0.0875 | Avg Valid recon Loss: 0.0875\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0781, recon=0.0781, kl=5.9368, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0921 (Recon: 0.0921, KL: 8.8839, Current Beta: 0.0000) | Avg Valid Loss: 0.0794 | Avg Valid recon Loss: 0.0794\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0566, recon=0.0566, kl=2.1389, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0838 (Recon: 0.0838, KL: 3.4010, Current Beta: 0.0000) | Avg Valid Loss: 0.0762 | Avg Valid recon Loss: 0.0762\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0613, recon=0.0613, kl=0.5371, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0798 (Recon: 0.0798, KL: 0.8005, Current Beta: 0.0000) | Avg Valid Loss: 0.0713 | Avg Valid recon Loss: 0.0713\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0609, recon=0.0609, kl=0.0752, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0760 (Recon: 0.0760, KL: 0.1609, Current Beta: 0.0000) | Avg Valid Loss: 0.0692 | Avg Valid recon Loss: 0.0692\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0492, recon=0.0492, kl=0.0101, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0701 (Recon: 0.0701, KL: 0.0207, Current Beta: 0.0001) | Avg Valid Loss: 0.0664 | Avg Valid recon Loss: 0.0664\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0529, recon=0.0529, kl=0.0017, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0696 (Recon: 0.0696, KL: 0.0036, Current Beta: 0.0003) | Avg Valid Loss: 0.0641 | Avg Valid recon Loss: 0.0641\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0521, recon=0.0521, kl=0.0010, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0679 (Recon: 0.0679, KL: 0.0013, Current Beta: 0.0008) | Avg Valid Loss: 0.0620 | Avg Valid recon Loss: 0.0620\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0898, recon=0.0898, kl=0.0003, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0631 (Recon: 0.0631, KL: 0.0004, Current Beta: 0.0018) | Avg Valid Loss: 0.0612 | Avg Valid recon Loss: 0.0612\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0475, recon=0.0475, kl=0.0004, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0641 (Recon: 0.0641, KL: 0.0005, Current Beta: 0.0038) | Avg Valid Loss: 0.0594 | Avg Valid recon Loss: 0.0594\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0568, recon=0.0568, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0625 (Recon: 0.0625, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0574\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0404, recon=0.0404, kl=0.0005, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0608 (Recon: 0.0608, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0574\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0591, recon=0.0591, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0604 (Recon: 0.0604, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0558 | Avg Valid recon Loss: 0.0558\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0685, recon=0.0685, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0581, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0547 | Avg Valid recon Loss: 0.0547\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0356, recon=0.0356, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0583 (Recon: 0.0583, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0531 | Avg Valid recon Loss: 0.0531\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0699, recon=0.0699, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0570 (Recon: 0.0570, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0536 | Avg Valid recon Loss: 0.0536\n",
      "\n",
      "[VRAE Run 291/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.8313, recon=0.8313, kl=0.6044, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.9239 (Recon: 0.9239, KL: 0.5306, Current Beta: 0.0000) | Avg Valid Loss: 0.7462 | Avg Valid recon Loss: 0.7462\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.5537, recon=0.5537, kl=2.1900, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6023 (Recon: 0.6023, KL: 1.2682, Current Beta: 0.0000) | Avg Valid Loss: 0.5232 | Avg Valid recon Loss: 0.5232\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.4135, recon=0.4135, kl=15.1664, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4572 (Recon: 0.4572, KL: 9.9954, Current Beta: 0.0000) | Avg Valid Loss: 0.4258 | Avg Valid recon Loss: 0.4258\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.3951, recon=0.3951, kl=24.8485, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3892 (Recon: 0.3892, KL: 21.5063, Current Beta: 0.0000) | Avg Valid Loss: 0.3648 | Avg Valid recon Loss: 0.3648\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.3667, recon=0.3667, kl=26.3386, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3455 (Recon: 0.3454, KL: 26.5484, Current Beta: 0.0000) | Avg Valid Loss: 0.3211 | Avg Valid recon Loss: 0.3210\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2258, recon=0.2258, kl=17.1055, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3138 (Recon: 0.3137, KL: 21.3747, Current Beta: 0.0000) | Avg Valid Loss: 0.2878 | Avg Valid recon Loss: 0.2877\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2366, recon=0.2366, kl=6.0475, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2888 (Recon: 0.2888, KL: 10.1253, Current Beta: 0.0000) | Avg Valid Loss: 0.2609 | Avg Valid recon Loss: 0.2609\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.2162, recon=0.2162, kl=1.1921, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2665 (Recon: 0.2664, KL: 2.5621, Current Beta: 0.0000) | Avg Valid Loss: 0.2395 | Avg Valid recon Loss: 0.2394\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.2366, recon=0.2365, kl=0.3650, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2491 (Recon: 0.2491, KL: 0.6403, Current Beta: 0.0000) | Avg Valid Loss: 0.2207 | Avg Valid recon Loss: 0.2207\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1748, recon=0.1748, kl=0.0676, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.2358 (Recon: 0.2357, KL: 0.1634, Current Beta: 0.0001) | Avg Valid Loss: 0.2062 | Avg Valid recon Loss: 0.2062\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1814, recon=0.1814, kl=0.0041, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.2214 (Recon: 0.2213, KL: 0.0204, Current Beta: 0.0003) | Avg Valid Loss: 0.1933 | Avg Valid recon Loss: 0.1933\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1670, recon=0.1670, kl=0.0015, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.2115 (Recon: 0.2115, KL: 0.0029, Current Beta: 0.0008) | Avg Valid Loss: 0.1831 | Avg Valid recon Loss: 0.1831\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1659, recon=0.1659, kl=0.0005, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.1997 (Recon: 0.1997, KL: 0.0008, Current Beta: 0.0018) | Avg Valid Loss: 0.1742 | Avg Valid recon Loss: 0.1742\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.4359, recon=0.4359, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1908 (Recon: 0.1908, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.1662 | Avg Valid recon Loss: 0.1662\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1513, recon=0.1513, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.1814 (Recon: 0.1814, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.1586 | Avg Valid recon Loss: 0.1586\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1424, recon=0.1424, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1771 (Recon: 0.1771, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.1527 | Avg Valid recon Loss: 0.1527\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1518, recon=0.1518, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1715 (Recon: 0.1715, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1470 | Avg Valid recon Loss: 0.1470\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1438, recon=0.1438, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1651 (Recon: 0.1651, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1416 | Avg Valid recon Loss: 0.1416\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1194, recon=0.1194, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1598 (Recon: 0.1598, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1361 | Avg Valid recon Loss: 0.1361\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.3754, recon=0.3754, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1532 (Recon: 0.1532, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1321 | Avg Valid recon Loss: 0.1321\n",
      "\n",
      "[VRAE Run 292/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5645, recon=0.5645, kl=36.3951, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4744 (Recon: 0.4744, KL: 15.2151, Current Beta: 0.0000) | Avg Valid Loss: 0.2331 | Avg Valid recon Loss: 0.2331\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1317, recon=0.1317, kl=55.2711, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2193 (Recon: 0.2193, KL: 49.3412, Current Beta: 0.0000) | Avg Valid Loss: 0.1472 | Avg Valid recon Loss: 0.1472\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1075, recon=0.1075, kl=54.1391, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1482 (Recon: 0.1482, KL: 55.7898, Current Beta: 0.0000) | Avg Valid Loss: 0.1117 | Avg Valid recon Loss: 0.1117\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1043, recon=0.1043, kl=40.1630, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1138 (Recon: 0.1138, KL: 45.5916, Current Beta: 0.0000) | Avg Valid Loss: 0.0951 | Avg Valid recon Loss: 0.0951\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0615, recon=0.0615, kl=22.4230, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1005 (Recon: 0.1004, KL: 29.6952, Current Beta: 0.0000) | Avg Valid Loss: 0.0856 | Avg Valid recon Loss: 0.0855\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0677, recon=0.0676, kl=12.7436, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0900 (Recon: 0.0900, KL: 16.7099, Current Beta: 0.0000) | Avg Valid Loss: 0.0784 | Avg Valid recon Loss: 0.0783\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0614, recon=0.0614, kl=3.4058, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0828 (Recon: 0.0828, KL: 5.9481, Current Beta: 0.0000) | Avg Valid Loss: 0.0743 | Avg Valid recon Loss: 0.0742\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1036, recon=0.1036, kl=0.7424, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0784 (Recon: 0.0783, KL: 1.4561, Current Beta: 0.0000) | Avg Valid Loss: 0.0712 | Avg Valid recon Loss: 0.0712\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0674, recon=0.0674, kl=0.1004, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0737 (Recon: 0.0737, KL: 0.2174, Current Beta: 0.0000) | Avg Valid Loss: 0.0678 | Avg Valid recon Loss: 0.0678\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0535, recon=0.0535, kl=0.0242, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0704 (Recon: 0.0704, KL: 0.0329, Current Beta: 0.0001) | Avg Valid Loss: 0.0654 | Avg Valid recon Loss: 0.0654\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0560, recon=0.0560, kl=0.0028, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0682 (Recon: 0.0682, KL: 0.0059, Current Beta: 0.0003) | Avg Valid Loss: 0.0635 | Avg Valid recon Loss: 0.0635\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.2230, recon=0.2230, kl=0.0013, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0660 (Recon: 0.0660, KL: 0.0019, Current Beta: 0.0008) | Avg Valid Loss: 0.0611 | Avg Valid recon Loss: 0.0611\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0479, recon=0.0479, kl=0.0031, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0653 (Recon: 0.0653, KL: 0.0007, Current Beta: 0.0018) | Avg Valid Loss: 0.0615 | Avg Valid recon Loss: 0.0615\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0673, recon=0.0673, kl=0.0006, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0626 (Recon: 0.0626, KL: 0.0009, Current Beta: 0.0038) | Avg Valid Loss: 0.0602 | Avg Valid recon Loss: 0.0601\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0420, recon=0.0420, kl=0.0008, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0615 (Recon: 0.0615, KL: 0.0009, Current Beta: 0.0062) | Avg Valid Loss: 0.0571 | Avg Valid recon Loss: 0.0571\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0451, recon=0.0451, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0592 (Recon: 0.0592, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0555 | Avg Valid recon Loss: 0.0555\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0386, recon=0.0385, kl=0.0005, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0565 (Recon: 0.0565, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0548 | Avg Valid recon Loss: 0.0548\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0433, recon=0.0433, kl=0.0032, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0566 (Recon: 0.0566, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0534 | Avg Valid recon Loss: 0.0534\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0462, recon=0.0462, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0550 (Recon: 0.0550, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0527 | Avg Valid recon Loss: 0.0527\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0454, recon=0.0454, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0549 (Recon: 0.0549, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0517 | Avg Valid recon Loss: 0.0517\n",
      "\n",
      "[VRAE Run 293/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7842, recon=0.7842, kl=1.2057, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.9036 (Recon: 0.9036, KL: 0.9897, Current Beta: 0.0000) | Avg Valid Loss: 0.7658 | Avg Valid recon Loss: 0.7658\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.6714, recon=0.6714, kl=7.8145, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6271 (Recon: 0.6271, KL: 3.7970, Current Beta: 0.0000) | Avg Valid Loss: 0.5512 | Avg Valid recon Loss: 0.5512\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.4362, recon=0.4362, kl=43.2974, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4792 (Recon: 0.4792, KL: 29.7687, Current Beta: 0.0000) | Avg Valid Loss: 0.4422 | Avg Valid recon Loss: 0.4421\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.3598, recon=0.3598, kl=59.6155, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4024 (Recon: 0.4024, KL: 56.0229, Current Beta: 0.0000) | Avg Valid Loss: 0.3795 | Avg Valid recon Loss: 0.3795\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.3040, recon=0.3039, kl=46.5391, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3553 (Recon: 0.3553, KL: 53.5427, Current Beta: 0.0000) | Avg Valid Loss: 0.3340 | Avg Valid recon Loss: 0.3339\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2699, recon=0.2699, kl=21.2635, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3223 (Recon: 0.3223, KL: 30.9996, Current Beta: 0.0000) | Avg Valid Loss: 0.3000 | Avg Valid recon Loss: 0.3000\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2872, recon=0.2872, kl=6.0107, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2975 (Recon: 0.2975, KL: 10.9975, Current Beta: 0.0000) | Avg Valid Loss: 0.2719 | Avg Valid recon Loss: 0.2719\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.2483, recon=0.2483, kl=1.4369, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2754 (Recon: 0.2754, KL: 2.7733, Current Beta: 0.0000) | Avg Valid Loss: 0.2485 | Avg Valid recon Loss: 0.2485\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.2139, recon=0.2139, kl=0.3404, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2565 (Recon: 0.2565, KL: 0.6876, Current Beta: 0.0000) | Avg Valid Loss: 0.2289 | Avg Valid recon Loss: 0.2289\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1912, recon=0.1912, kl=0.0383, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.2398 (Recon: 0.2398, KL: 0.1371, Current Beta: 0.0001) | Avg Valid Loss: 0.2129 | Avg Valid recon Loss: 0.2129\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.2128, recon=0.2128, kl=0.0134, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.2269 (Recon: 0.2269, KL: 0.0118, Current Beta: 0.0003) | Avg Valid Loss: 0.1996 | Avg Valid recon Loss: 0.1996\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1822, recon=0.1822, kl=0.0011, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.2125 (Recon: 0.2125, KL: 0.0026, Current Beta: 0.0008) | Avg Valid Loss: 0.1877 | Avg Valid recon Loss: 0.1877\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1489, recon=0.1489, kl=0.0006, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.2039 (Recon: 0.2039, KL: 0.0007, Current Beta: 0.0018) | Avg Valid Loss: 0.1777 | Avg Valid recon Loss: 0.1777\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1595, recon=0.1595, kl=0.0002, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1950 (Recon: 0.1950, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.1695 | Avg Valid recon Loss: 0.1695\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1577, recon=0.1577, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.1867 (Recon: 0.1867, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.1620 | Avg Valid recon Loss: 0.1620\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1275, recon=0.1275, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1780 (Recon: 0.1780, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.1552 | Avg Valid recon Loss: 0.1552\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1496, recon=0.1496, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1706 (Recon: 0.1706, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.1491 | Avg Valid recon Loss: 0.1491\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1332, recon=0.1332, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1658 (Recon: 0.1658, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1439 | Avg Valid recon Loss: 0.1439\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1358, recon=0.1358, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1597 (Recon: 0.1597, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1384 | Avg Valid recon Loss: 0.1384\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1226, recon=0.1226, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1531 (Recon: 0.1531, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1342 | Avg Valid recon Loss: 0.1342\n",
      "\n",
      "[VRAE Run 294/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3513, recon=0.3513, kl=83.7078, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4558 (Recon: 0.4558, KL: 40.8716, Current Beta: 0.0000) | Avg Valid Loss: 0.2360 | Avg Valid recon Loss: 0.2360\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1529, recon=0.1529, kl=96.3211, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2179 (Recon: 0.2179, KL: 96.6456, Current Beta: 0.0000) | Avg Valid Loss: 0.1483 | Avg Valid recon Loss: 0.1483\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1584, recon=0.1584, kl=84.7020, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1532 (Recon: 0.1532, KL: 89.0837, Current Beta: 0.0000) | Avg Valid Loss: 0.1127 | Avg Valid recon Loss: 0.1127\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0902, recon=0.0902, kl=57.0780, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1200 (Recon: 0.1200, KL: 68.4849, Current Beta: 0.0000) | Avg Valid Loss: 0.0969 | Avg Valid recon Loss: 0.0969\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0840, recon=0.0839, kl=34.2112, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1033 (Recon: 0.1033, KL: 39.3921, Current Beta: 0.0000) | Avg Valid Loss: 0.0887 | Avg Valid recon Loss: 0.0887\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0577, recon=0.0577, kl=13.0381, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0926 (Recon: 0.0925, KL: 20.8869, Current Beta: 0.0000) | Avg Valid Loss: 0.0793 | Avg Valid recon Loss: 0.0793\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0619, recon=0.0619, kl=4.4153, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0847 (Recon: 0.0847, KL: 6.9636, Current Beta: 0.0000) | Avg Valid Loss: 0.0750 | Avg Valid recon Loss: 0.0750\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0606, recon=0.0605, kl=1.1171, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0798 (Recon: 0.0798, KL: 1.7139, Current Beta: 0.0000) | Avg Valid Loss: 0.0704 | Avg Valid recon Loss: 0.0704\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0625, recon=0.0625, kl=0.2487, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0749 (Recon: 0.0749, KL: 0.4951, Current Beta: 0.0000) | Avg Valid Loss: 0.0675 | Avg Valid recon Loss: 0.0675\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0539, recon=0.0539, kl=0.0161, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0698 (Recon: 0.0698, KL: 0.0514, Current Beta: 0.0001) | Avg Valid Loss: 0.0657 | Avg Valid recon Loss: 0.0657\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0541, recon=0.0541, kl=0.0035, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0700 (Recon: 0.0700, KL: 0.0057, Current Beta: 0.0003) | Avg Valid Loss: 0.0634 | Avg Valid recon Loss: 0.0634\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0516, recon=0.0516, kl=0.0008, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0602 (Recon: 0.0602, KL: 0.0016, Current Beta: 0.0008) | Avg Valid Loss: 0.0617 | Avg Valid recon Loss: 0.0617\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0456, recon=0.0456, kl=0.0003, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0643 (Recon: 0.0643, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0604 | Avg Valid recon Loss: 0.0604\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0688, recon=0.0688, kl=0.0004, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0623 (Recon: 0.0623, KL: 0.0005, Current Beta: 0.0038) | Avg Valid Loss: 0.0585 | Avg Valid recon Loss: 0.0585\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0564, recon=0.0564, kl=0.0003, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0609 (Recon: 0.0609, KL: 0.0005, Current Beta: 0.0062) | Avg Valid Loss: 0.0575 | Avg Valid recon Loss: 0.0575\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0467, recon=0.0467, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0590 (Recon: 0.0590, KL: 0.0010, Current Beta: 0.0100) | Avg Valid Loss: 0.0565 | Avg Valid recon Loss: 0.0565\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0751, recon=0.0751, kl=0.0004, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0585 (Recon: 0.0585, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0554 | Avg Valid recon Loss: 0.0554\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0677, recon=0.0677, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0575 (Recon: 0.0575, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0535 | Avg Valid recon Loss: 0.0535\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0412, recon=0.0412, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0560 (Recon: 0.0560, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0532 | Avg Valid recon Loss: 0.0532\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0437, recon=0.0437, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0548 (Recon: 0.0548, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0519 | Avg Valid recon Loss: 0.0519\n",
      "\n",
      "[VRAE Run 295/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5049, recon=0.5049, kl=0.2278, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.7281 (Recon: 0.7281, KL: 0.1567, Current Beta: 0.0000) | Avg Valid Loss: 0.4982 | Avg Valid recon Loss: 0.4982\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3473, recon=0.3473, kl=6.5658, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3982 (Recon: 0.3982, KL: 3.0515, Current Beta: 0.0000) | Avg Valid Loss: 0.3339 | Avg Valid recon Loss: 0.3339\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2915, recon=0.2915, kl=18.2616, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2882 (Recon: 0.2882, KL: 13.6210, Current Beta: 0.0000) | Avg Valid Loss: 0.2573 | Avg Valid recon Loss: 0.2573\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.2194, recon=0.2194, kl=20.8850, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2544 (Recon: 0.2544, KL: 20.2905, Current Beta: 0.0000) | Avg Valid Loss: 0.2145 | Avg Valid recon Loss: 0.2145\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2225, recon=0.2225, kl=14.9157, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2108 (Recon: 0.2108, KL: 17.7504, Current Beta: 0.0000) | Avg Valid Loss: 0.1848 | Avg Valid recon Loss: 0.1848\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1520, recon=0.1520, kl=6.8063, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2018 (Recon: 0.2017, KL: 9.7447, Current Beta: 0.0000) | Avg Valid Loss: 0.1641 | Avg Valid recon Loss: 0.1641\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1558, recon=0.1557, kl=2.1244, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1857 (Recon: 0.1857, KL: 3.5773, Current Beta: 0.0000) | Avg Valid Loss: 0.1489 | Avg Valid recon Loss: 0.1489\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1443, recon=0.1443, kl=0.4390, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1732 (Recon: 0.1732, KL: 0.9544, Current Beta: 0.0000) | Avg Valid Loss: 0.1385 | Avg Valid recon Loss: 0.1385\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1269, recon=0.1269, kl=0.0828, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1642 (Recon: 0.1642, KL: 0.2156, Current Beta: 0.0000) | Avg Valid Loss: 0.1307 | Avg Valid recon Loss: 0.1307\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.3898, recon=0.3898, kl=0.0045, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1551 (Recon: 0.1551, KL: 0.0214, Current Beta: 0.0001) | Avg Valid Loss: 0.1235 | Avg Valid recon Loss: 0.1235\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1221, recon=0.1221, kl=0.0035, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.1465 (Recon: 0.1465, KL: 0.0025, Current Beta: 0.0003) | Avg Valid Loss: 0.1172 | Avg Valid recon Loss: 0.1172\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1196, recon=0.1196, kl=0.0004, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.1395 (Recon: 0.1395, KL: 0.0007, Current Beta: 0.0008) | Avg Valid Loss: 0.1122 | Avg Valid recon Loss: 0.1122\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1017, recon=0.1017, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.1319 (Recon: 0.1319, KL: 0.0002, Current Beta: 0.0018) | Avg Valid Loss: 0.1074 | Avg Valid recon Loss: 0.1074\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1249, recon=0.1249, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1270 (Recon: 0.1270, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.1030 | Avg Valid recon Loss: 0.1030\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0960, recon=0.0960, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.1214 (Recon: 0.1214, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0996 | Avg Valid recon Loss: 0.0996\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0932, recon=0.0932, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1150 (Recon: 0.1150, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0961 | Avg Valid recon Loss: 0.0961\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0883, recon=0.0883, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1109 (Recon: 0.1109, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0925 | Avg Valid recon Loss: 0.0925\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0814, recon=0.0814, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1067 (Recon: 0.1067, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0898 | Avg Valid recon Loss: 0.0898\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0711, recon=0.0711, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1029 (Recon: 0.1029, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0869 | Avg Valid recon Loss: 0.0869\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0790, recon=0.0790, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0996 (Recon: 0.0996, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0849 | Avg Valid recon Loss: 0.0849\n",
      "\n",
      "[VRAE Run 296/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2442, recon=0.2442, kl=22.1496, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3532 (Recon: 0.3532, KL: 11.9691, Current Beta: 0.0000) | Avg Valid Loss: 0.1563 | Avg Valid recon Loss: 0.1563\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0964, recon=0.0964, kl=27.6070, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1599 (Recon: 0.1599, KL: 27.2836, Current Beta: 0.0000) | Avg Valid Loss: 0.1046 | Avg Valid recon Loss: 0.1046\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0986, recon=0.0986, kl=33.5183, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1114 (Recon: 0.1114, KL: 30.7315, Current Beta: 0.0000) | Avg Valid Loss: 0.0827 | Avg Valid recon Loss: 0.0827\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0622, recon=0.0622, kl=20.4739, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0894 (Recon: 0.0894, KL: 26.7926, Current Beta: 0.0000) | Avg Valid Loss: 0.0736 | Avg Valid recon Loss: 0.0736\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0758, recon=0.0758, kl=16.9038, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0796 (Recon: 0.0795, KL: 19.2141, Current Beta: 0.0000) | Avg Valid Loss: 0.0691 | Avg Valid recon Loss: 0.0691\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0597, recon=0.0596, kl=8.6187, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0721 (Recon: 0.0721, KL: 10.5128, Current Beta: 0.0000) | Avg Valid Loss: 0.0617 | Avg Valid recon Loss: 0.0617\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0498, recon=0.0498, kl=3.2768, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0660 (Recon: 0.0659, KL: 5.3983, Current Beta: 0.0000) | Avg Valid Loss: 0.0575 | Avg Valid recon Loss: 0.0575\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0472, recon=0.0472, kl=1.4888, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0627 (Recon: 0.0626, KL: 1.7903, Current Beta: 0.0000) | Avg Valid Loss: 0.0550 | Avg Valid recon Loss: 0.0549\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0554, recon=0.0554, kl=0.2609, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0610 (Recon: 0.0610, KL: 0.3800, Current Beta: 0.0000) | Avg Valid Loss: 0.0622 | Avg Valid recon Loss: 0.0622\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0634, recon=0.0634, kl=0.0270, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0602 (Recon: 0.0602, KL: 0.0473, Current Beta: 0.0001) | Avg Valid Loss: 0.0535 | Avg Valid recon Loss: 0.0535\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0581, recon=0.0581, kl=0.0047, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0554 (Recon: 0.0554, KL: 0.0078, Current Beta: 0.0003) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0496\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0605, recon=0.0605, kl=0.0011, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0529, KL: 0.0016, Current Beta: 0.0008) | Avg Valid Loss: 0.0483 | Avg Valid recon Loss: 0.0483\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0376, recon=0.0376, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0513 (Recon: 0.0513, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0470 | Avg Valid recon Loss: 0.0470\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0423, recon=0.0423, kl=0.0003, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0489 (Recon: 0.0489, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0455\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0357, recon=0.0357, kl=0.0004, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0480 (Recon: 0.0480, KL: 0.0004, Current Beta: 0.0062) | Avg Valid Loss: 0.0443 | Avg Valid recon Loss: 0.0443\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0668, recon=0.0668, kl=0.0010, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0436, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0456 | Avg Valid recon Loss: 0.0456\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0672, recon=0.0672, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0477 (Recon: 0.0477, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0382, recon=0.0382, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0460 (Recon: 0.0460, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0419\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0408, recon=0.0408, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0457, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0415\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0378, recon=0.0378, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0442 (Recon: 0.0442, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0404 | Avg Valid recon Loss: 0.0404\n",
      "\n",
      "[VRAE Run 297/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5098, recon=0.5098, kl=0.5300, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.7974 (Recon: 0.7974, KL: 0.3299, Current Beta: 0.0000) | Avg Valid Loss: 0.5535 | Avg Valid recon Loss: 0.5535\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3269, recon=0.3269, kl=21.3180, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4240 (Recon: 0.4240, KL: 9.1697, Current Beta: 0.0000) | Avg Valid Loss: 0.3733 | Avg Valid recon Loss: 0.3733\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2933, recon=0.2933, kl=41.5093, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3270 (Recon: 0.3269, KL: 35.6719, Current Beta: 0.0000) | Avg Valid Loss: 0.2838 | Avg Valid recon Loss: 0.2838\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.3536, recon=0.3536, kl=41.9595, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2700 (Recon: 0.2700, KL: 43.3027, Current Beta: 0.0000) | Avg Valid Loss: 0.2324 | Avg Valid recon Loss: 0.2323\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1776, recon=0.1775, kl=27.9811, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2368 (Recon: 0.2367, KL: 34.2457, Current Beta: 0.0000) | Avg Valid Loss: 0.1976 | Avg Valid recon Loss: 0.1976\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.2218, recon=0.2218, kl=11.7317, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1999 (Recon: 0.1999, KL: 17.7534, Current Beta: 0.0000) | Avg Valid Loss: 0.1745 | Avg Valid recon Loss: 0.1745\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1256, recon=0.1256, kl=3.3451, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1933 (Recon: 0.1933, KL: 6.0372, Current Beta: 0.0000) | Avg Valid Loss: 0.1585 | Avg Valid recon Loss: 0.1585\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.2559, recon=0.2559, kl=0.5744, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1793 (Recon: 0.1792, KL: 1.4139, Current Beta: 0.0000) | Avg Valid Loss: 0.1467 | Avg Valid recon Loss: 0.1467\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1531, recon=0.1531, kl=0.0820, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1698 (Recon: 0.1698, KL: 0.2315, Current Beta: 0.0000) | Avg Valid Loss: 0.1366 | Avg Valid recon Loss: 0.1366\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1673, recon=0.1673, kl=0.0088, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1601 (Recon: 0.1601, KL: 0.0266, Current Beta: 0.0001) | Avg Valid Loss: 0.1279 | Avg Valid recon Loss: 0.1279\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1554, recon=0.1554, kl=0.0023, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.1506 (Recon: 0.1506, KL: 0.0043, Current Beta: 0.0003) | Avg Valid Loss: 0.1215 | Avg Valid recon Loss: 0.1215\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1237, recon=0.1237, kl=0.0012, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.1419 (Recon: 0.1419, KL: 0.0012, Current Beta: 0.0008) | Avg Valid Loss: 0.1155 | Avg Valid recon Loss: 0.1155\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1118, recon=0.1118, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.1348 (Recon: 0.1348, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.1101 | Avg Valid recon Loss: 0.1101\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1093, recon=0.1093, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1293 (Recon: 0.1293, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.1056 | Avg Valid recon Loss: 0.1056\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1103, recon=0.1103, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.1235 (Recon: 0.1235, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.1019 | Avg Valid recon Loss: 0.1018\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1082, recon=0.1082, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1180 (Recon: 0.1180, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0982 | Avg Valid recon Loss: 0.0982\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.2992, recon=0.2992, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1135 (Recon: 0.1135, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0943 | Avg Valid recon Loss: 0.0943\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0829, recon=0.0829, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1075 (Recon: 0.1075, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0915 | Avg Valid recon Loss: 0.0915\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0838, recon=0.0838, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1045 (Recon: 0.1045, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0885 | Avg Valid recon Loss: 0.0885\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0778, recon=0.0778, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1001 (Recon: 0.1001, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0859 | Avg Valid recon Loss: 0.0859\n",
      "\n",
      "[VRAE Run 298/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1949, recon=0.1949, kl=56.4026, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3321 (Recon: 0.3321, KL: 33.0665, Current Beta: 0.0000) | Avg Valid Loss: 0.1504 | Avg Valid recon Loss: 0.1504\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1054, recon=0.1054, kl=57.3575, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1534 (Recon: 0.1534, KL: 58.3591, Current Beta: 0.0000) | Avg Valid Loss: 0.1054 | Avg Valid recon Loss: 0.1054\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0769, recon=0.0769, kl=51.1412, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1097 (Recon: 0.1097, KL: 54.6461, Current Beta: 0.0000) | Avg Valid Loss: 0.0829 | Avg Valid recon Loss: 0.0829\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0591, recon=0.0591, kl=37.9272, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0897 (Recon: 0.0897, KL: 43.5049, Current Beta: 0.0000) | Avg Valid Loss: 0.0734 | Avg Valid recon Loss: 0.0734\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0515, recon=0.0515, kl=23.5969, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0779 (Recon: 0.0779, KL: 29.2769, Current Beta: 0.0000) | Avg Valid Loss: 0.0677 | Avg Valid recon Loss: 0.0677\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0518, recon=0.0518, kl=10.1399, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0692 (Recon: 0.0692, KL: 14.1526, Current Beta: 0.0000) | Avg Valid Loss: 0.0622 | Avg Valid recon Loss: 0.0622\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0506, recon=0.0506, kl=4.7423, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0644 (Recon: 0.0644, KL: 6.0879, Current Beta: 0.0000) | Avg Valid Loss: 0.0579 | Avg Valid recon Loss: 0.0578\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1688, recon=0.1687, kl=1.6809, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0611 (Recon: 0.0610, KL: 1.9959, Current Beta: 0.0000) | Avg Valid Loss: 0.0569 | Avg Valid recon Loss: 0.0569\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0397, recon=0.0397, kl=0.3055, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0589 (Recon: 0.0588, KL: 0.4194, Current Beta: 0.0000) | Avg Valid Loss: 0.0538 | Avg Valid recon Loss: 0.0538\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0465, recon=0.0465, kl=0.0417, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0550 (Recon: 0.0550, KL: 0.0703, Current Beta: 0.0001) | Avg Valid Loss: 0.0521 | Avg Valid recon Loss: 0.0521\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0692, recon=0.0692, kl=0.0068, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0551 (Recon: 0.0551, KL: 0.0115, Current Beta: 0.0003) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0496\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0500, recon=0.0500, kl=0.0009, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0514 (Recon: 0.0514, KL: 0.0016, Current Beta: 0.0008) | Avg Valid Loss: 0.0475 | Avg Valid recon Loss: 0.0475\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0446, recon=0.0446, kl=0.0007, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0517 (Recon: 0.0517, KL: 0.0009, Current Beta: 0.0018) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0365, recon=0.0364, kl=0.0011, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0515 (Recon: 0.0514, KL: 0.0028, Current Beta: 0.0038) | Avg Valid Loss: 0.0461 | Avg Valid recon Loss: 0.0461\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1383, recon=0.1383, kl=0.0003, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0476 (Recon: 0.0476, KL: 0.0016, Current Beta: 0.0062) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0448\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0496, recon=0.0496, kl=0.0012, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0468 (Recon: 0.0467, KL: 0.0007, Current Beta: 0.0100) | Avg Valid Loss: 0.0437 | Avg Valid recon Loss: 0.0437\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0499, recon=0.0499, kl=0.0008, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0458 (Recon: 0.0458, KL: 0.0008, Current Beta: 0.0100) | Avg Valid Loss: 0.0433 | Avg Valid recon Loss: 0.0433\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0642, recon=0.0642, kl=0.0007, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0451 (Recon: 0.0451, KL: 0.0007, Current Beta: 0.0100) | Avg Valid Loss: 0.0432 | Avg Valid recon Loss: 0.0432\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1100, recon=0.1100, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0452 (Recon: 0.0452, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0423 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0415, recon=0.0415, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0447 (Recon: 0.0447, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0415 | Avg Valid recon Loss: 0.0415\n",
      "\n",
      "[VRAE Run 299/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5300, recon=0.5300, kl=0.9521, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.7553 (Recon: 0.7553, KL: 0.6496, Current Beta: 0.0000) | Avg Valid Loss: 0.5152 | Avg Valid recon Loss: 0.5152\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3238, recon=0.3238, kl=37.2724, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4123 (Recon: 0.4123, KL: 15.3822, Current Beta: 0.0000) | Avg Valid Loss: 0.3521 | Avg Valid recon Loss: 0.3521\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2763, recon=0.2763, kl=73.1511, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3106 (Recon: 0.3106, KL: 63.6886, Current Beta: 0.0000) | Avg Valid Loss: 0.2681 | Avg Valid recon Loss: 0.2681\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.2326, recon=0.2326, kl=67.5782, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2596 (Recon: 0.2596, KL: 71.8406, Current Beta: 0.0000) | Avg Valid Loss: 0.2219 | Avg Valid recon Loss: 0.2219\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1789, recon=0.1789, kl=39.0452, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2265 (Recon: 0.2264, KL: 51.0118, Current Beta: 0.0000) | Avg Valid Loss: 0.1917 | Avg Valid recon Loss: 0.1917\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1497, recon=0.1497, kl=14.2297, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2047 (Recon: 0.2047, KL: 22.5637, Current Beta: 0.0000) | Avg Valid Loss: 0.1702 | Avg Valid recon Loss: 0.1702\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1854, recon=0.1854, kl=3.7811, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1872 (Recon: 0.1872, KL: 7.2914, Current Beta: 0.0000) | Avg Valid Loss: 0.1543 | Avg Valid recon Loss: 0.1543\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.3915, recon=0.3914, kl=0.6810, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1744 (Recon: 0.1744, KL: 1.4808, Current Beta: 0.0000) | Avg Valid Loss: 0.1430 | Avg Valid recon Loss: 0.1430\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1542, recon=0.1542, kl=0.1152, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1632 (Recon: 0.1632, KL: 0.2264, Current Beta: 0.0000) | Avg Valid Loss: 0.1337 | Avg Valid recon Loss: 0.1337\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1186, recon=0.1186, kl=0.0185, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1536 (Recon: 0.1536, KL: 0.0364, Current Beta: 0.0001) | Avg Valid Loss: 0.1254 | Avg Valid recon Loss: 0.1254\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1607, recon=0.1607, kl=0.0033, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.1451 (Recon: 0.1451, KL: 0.0064, Current Beta: 0.0003) | Avg Valid Loss: 0.1187 | Avg Valid recon Loss: 0.1187\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1395, recon=0.1395, kl=0.0010, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.1369 (Recon: 0.1369, KL: 0.0015, Current Beta: 0.0008) | Avg Valid Loss: 0.1132 | Avg Valid recon Loss: 0.1132\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1105, recon=0.1105, kl=0.0007, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.1292 (Recon: 0.1292, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.1084 | Avg Valid recon Loss: 0.1084\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0952, recon=0.0952, kl=0.0002, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1228 (Recon: 0.1228, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.1036 | Avg Valid recon Loss: 0.1035\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1671, recon=0.1671, kl=0.0003, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.1179 (Recon: 0.1179, KL: 0.0004, Current Beta: 0.0062) | Avg Valid Loss: 0.0999 | Avg Valid recon Loss: 0.0999\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0716, recon=0.0716, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1127 (Recon: 0.1127, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0956 | Avg Valid recon Loss: 0.0956\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0910, recon=0.0910, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1072 (Recon: 0.1072, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0925 | Avg Valid recon Loss: 0.0924\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0891, recon=0.0891, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1046 (Recon: 0.1046, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0896 | Avg Valid recon Loss: 0.0896\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0696, recon=0.0696, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1007 (Recon: 0.1007, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0871 | Avg Valid recon Loss: 0.0871\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1339, recon=0.1339, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0982 (Recon: 0.0982, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0853 | Avg Valid recon Loss: 0.0853\n",
      "\n",
      "[VRAE Run 300/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1969, recon=0.1969, kl=73.6330, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3400 (Recon: 0.3400, KL: 40.6897, Current Beta: 0.0000) | Avg Valid Loss: 0.1541 | Avg Valid recon Loss: 0.1541\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1141, recon=0.1141, kl=107.7033, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1630 (Recon: 0.1630, KL: 100.0690, Current Beta: 0.0000) | Avg Valid Loss: 0.1073 | Avg Valid recon Loss: 0.1073\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.3445, recon=0.3445, kl=89.1948, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1135 (Recon: 0.1135, KL: 101.2535, Current Beta: 0.0000) | Avg Valid Loss: 0.0842 | Avg Valid recon Loss: 0.0841\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0601, recon=0.0600, kl=72.1497, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0911 (Recon: 0.0911, KL: 74.2558, Current Beta: 0.0000) | Avg Valid Loss: 0.0728 | Avg Valid recon Loss: 0.0728\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0659, recon=0.0659, kl=40.0318, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0793 (Recon: 0.0793, KL: 47.8142, Current Beta: 0.0000) | Avg Valid Loss: 0.0685 | Avg Valid recon Loss: 0.0685\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0690, recon=0.0689, kl=21.9094, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0729 (Recon: 0.0729, KL: 25.4207, Current Beta: 0.0000) | Avg Valid Loss: 0.0619 | Avg Valid recon Loss: 0.0619\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0449, recon=0.0449, kl=6.7574, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0670 (Recon: 0.0669, KL: 9.4539, Current Beta: 0.0000) | Avg Valid Loss: 0.0590 | Avg Valid recon Loss: 0.0589\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0527, recon=0.0527, kl=1.5739, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0638 (Recon: 0.0637, KL: 2.3149, Current Beta: 0.0000) | Avg Valid Loss: 0.0561 | Avg Valid recon Loss: 0.0560\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0586, recon=0.0586, kl=0.5607, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0604 (Recon: 0.0603, KL: 0.5114, Current Beta: 0.0000) | Avg Valid Loss: 0.0532 | Avg Valid recon Loss: 0.0532\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0522, recon=0.0522, kl=0.0542, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0588 (Recon: 0.0588, KL: 0.1185, Current Beta: 0.0001) | Avg Valid Loss: 0.0518 | Avg Valid recon Loss: 0.0518\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0433, recon=0.0433, kl=0.0056, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0548 (Recon: 0.0548, KL: 0.0121, Current Beta: 0.0003) | Avg Valid Loss: 0.0496 | Avg Valid recon Loss: 0.0496\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0508, recon=0.0508, kl=0.0010, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0537 (Recon: 0.0537, KL: 0.0031, Current Beta: 0.0008) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0478\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0530, recon=0.0530, kl=0.0011, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0529 (Recon: 0.0529, KL: 0.0015, Current Beta: 0.0018) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0465\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0433, recon=0.0433, kl=0.0004, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0503 (Recon: 0.0503, KL: 0.0009, Current Beta: 0.0038) | Avg Valid Loss: 0.0453 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0344, recon=0.0344, kl=0.0003, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0452 (Recon: 0.0452, KL: 0.0008, Current Beta: 0.0062) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0380, recon=0.0380, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0491 (Recon: 0.0491, KL: 0.0007, Current Beta: 0.0100) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0449\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0512, recon=0.0512, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0474 (Recon: 0.0474, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0437 | Avg Valid recon Loss: 0.0437\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0345, recon=0.0345, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0474 (Recon: 0.0474, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0422 | Avg Valid recon Loss: 0.0422\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0325, recon=0.0325, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0462, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0414 | Avg Valid recon Loss: 0.0414\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0414, recon=0.0414, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0462 (Recon: 0.0462, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0413\n",
      "\n",
      "[VRAE Run 301/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3799, recon=0.3799, kl=1.3126, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5874 (Recon: 0.5874, KL: 0.5154, Current Beta: 0.0000) | Avg Valid Loss: 0.3571 | Avg Valid recon Loss: 0.3571\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2300, recon=0.2300, kl=13.8207, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2740 (Recon: 0.2740, KL: 8.8443, Current Beta: 0.0000) | Avg Valid Loss: 0.2017 | Avg Valid recon Loss: 0.2017\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1745, recon=0.1745, kl=25.0825, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2046 (Recon: 0.2046, KL: 21.8552, Current Beta: 0.0000) | Avg Valid Loss: 0.1566 | Avg Valid recon Loss: 0.1566\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1297, recon=0.1297, kl=18.8916, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1742 (Recon: 0.1742, KL: 21.4494, Current Beta: 0.0000) | Avg Valid Loss: 0.1335 | Avg Valid recon Loss: 0.1335\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1311, recon=0.1311, kl=8.4920, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1545 (Recon: 0.1545, KL: 12.3236, Current Beta: 0.0000) | Avg Valid Loss: 0.1177 | Avg Valid recon Loss: 0.1177\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1049, recon=0.1049, kl=2.7792, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1431 (Recon: 0.1431, KL: 4.4144, Current Beta: 0.0000) | Avg Valid Loss: 0.1080 | Avg Valid recon Loss: 0.1080\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1256, recon=0.1256, kl=0.8364, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1322 (Recon: 0.1322, KL: 1.3356, Current Beta: 0.0000) | Avg Valid Loss: 0.0996 | Avg Valid recon Loss: 0.0996\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0880, recon=0.0880, kl=0.1815, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1236 (Recon: 0.1236, KL: 0.4293, Current Beta: 0.0000) | Avg Valid Loss: 0.0938 | Avg Valid recon Loss: 0.0938\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1551, recon=0.1550, kl=0.0233, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1146 (Recon: 0.1146, KL: 0.0808, Current Beta: 0.0000) | Avg Valid Loss: 0.0876 | Avg Valid recon Loss: 0.0876\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0956, recon=0.0956, kl=0.0047, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1076 (Recon: 0.1076, KL: 0.0081, Current Beta: 0.0001) | Avg Valid Loss: 0.0836 | Avg Valid recon Loss: 0.0836\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0763, recon=0.0763, kl=0.0011, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.1012 (Recon: 0.1012, KL: 0.0020, Current Beta: 0.0003) | Avg Valid Loss: 0.0801 | Avg Valid recon Loss: 0.0801\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0735, recon=0.0735, kl=0.0004, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0959 (Recon: 0.0959, KL: 0.0005, Current Beta: 0.0008) | Avg Valid Loss: 0.0767 | Avg Valid recon Loss: 0.0767\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0730, recon=0.0730, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0914 (Recon: 0.0914, KL: 0.0002, Current Beta: 0.0018) | Avg Valid Loss: 0.0735 | Avg Valid recon Loss: 0.0735\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0816, recon=0.0816, kl=0.0002, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0859 (Recon: 0.0859, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0712 | Avg Valid recon Loss: 0.0712\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0638, recon=0.0638, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0837 (Recon: 0.0837, KL: 0.0003, Current Beta: 0.0062) | Avg Valid Loss: 0.0695 | Avg Valid recon Loss: 0.0695\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0809, recon=0.0809, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0799 (Recon: 0.0799, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0681 | Avg Valid recon Loss: 0.0681\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0663, recon=0.0663, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0775 (Recon: 0.0775, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0665 | Avg Valid recon Loss: 0.0665\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0593, recon=0.0593, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0744 (Recon: 0.0744, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0651 | Avg Valid recon Loss: 0.0651\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0531, recon=0.0531, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0732 (Recon: 0.0732, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0635 | Avg Valid recon Loss: 0.0635\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0781, recon=0.0781, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0700 (Recon: 0.0700, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0619 | Avg Valid recon Loss: 0.0619\n",
      "\n",
      "[VRAE Run 302/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1615, recon=0.1615, kl=27.4793, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2652 (Recon: 0.2652, KL: 12.1684, Current Beta: 0.0000) | Avg Valid Loss: 0.1113 | Avg Valid recon Loss: 0.1113\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0846, recon=0.0846, kl=27.6541, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1250 (Recon: 0.1250, KL: 29.1431, Current Beta: 0.0000) | Avg Valid Loss: 0.0802 | Avg Valid recon Loss: 0.0802\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2446, recon=0.2446, kl=28.9806, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0888 (Recon: 0.0888, KL: 30.1853, Current Beta: 0.0000) | Avg Valid Loss: 0.0657 | Avg Valid recon Loss: 0.0657\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0708, recon=0.0708, kl=21.5214, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0735 (Recon: 0.0735, KL: 23.4597, Current Beta: 0.0000) | Avg Valid Loss: 0.0589 | Avg Valid recon Loss: 0.0589\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0582, recon=0.0582, kl=11.7722, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0643 (Recon: 0.0643, KL: 15.6466, Current Beta: 0.0000) | Avg Valid Loss: 0.0534 | Avg Valid recon Loss: 0.0534\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0392, recon=0.0392, kl=7.9739, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0587 (Recon: 0.0587, KL: 8.8612, Current Beta: 0.0000) | Avg Valid Loss: 0.0509 | Avg Valid recon Loss: 0.0509\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0489, recon=0.0489, kl=4.1809, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0547, KL: 4.6367, Current Beta: 0.0000) | Avg Valid Loss: 0.0495 | Avg Valid recon Loss: 0.0494\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0614, recon=0.0614, kl=0.9502, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0518 (Recon: 0.0518, KL: 1.2548, Current Beta: 0.0000) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0518, recon=0.0518, kl=0.1584, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0479, KL: 0.2941, Current Beta: 0.0000) | Avg Valid Loss: 0.0421 | Avg Valid recon Loss: 0.0421\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0413, recon=0.0413, kl=0.0224, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0478 (Recon: 0.0478, KL: 0.0407, Current Beta: 0.0001) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0407, recon=0.0407, kl=0.0047, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0436 (Recon: 0.0436, KL: 0.0062, Current Beta: 0.0003) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0392\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0310, recon=0.0310, kl=0.0009, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0423, KL: 0.0016, Current Beta: 0.0008) | Avg Valid Loss: 0.0392 | Avg Valid recon Loss: 0.0392\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0330, recon=0.0330, kl=0.0005, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0434 (Recon: 0.0434, KL: 0.0006, Current Beta: 0.0018) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0522, recon=0.0522, kl=0.0004, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0408 (Recon: 0.0408, KL: 0.0004, Current Beta: 0.0038) | Avg Valid Loss: 0.0359 | Avg Valid recon Loss: 0.0359\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0441, recon=0.0441, kl=0.0002, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0397 (Recon: 0.0397, KL: 0.0004, Current Beta: 0.0062) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0400, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0348 | Avg Valid recon Loss: 0.0348\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0438, recon=0.0438, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0385 (Recon: 0.0385, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0360\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0243, recon=0.0243, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0382 (Recon: 0.0382, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0342 | Avg Valid recon Loss: 0.0342\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0316, recon=0.0316, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0370, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0340 | Avg Valid recon Loss: 0.0340\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0382, recon=0.0382, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0369 (Recon: 0.0369, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0328 | Avg Valid recon Loss: 0.0328\n",
      "\n",
      "[VRAE Run 303/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3383, recon=0.3383, kl=1.7172, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5708 (Recon: 0.5708, KL: 0.6619, Current Beta: 0.0000) | Avg Valid Loss: 0.3439 | Avg Valid recon Loss: 0.3439\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2000, recon=0.2000, kl=45.2498, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2723 (Recon: 0.2723, KL: 29.9493, Current Beta: 0.0000) | Avg Valid Loss: 0.2013 | Avg Valid recon Loss: 0.2013\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1800, recon=0.1800, kl=55.1388, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2043 (Recon: 0.2043, KL: 53.3404, Current Beta: 0.0000) | Avg Valid Loss: 0.1555 | Avg Valid recon Loss: 0.1555\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1304, recon=0.1304, kl=37.8995, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1739 (Recon: 0.1738, KL: 45.5264, Current Beta: 0.0000) | Avg Valid Loss: 0.1312 | Avg Valid recon Loss: 0.1312\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1351, recon=0.1351, kl=15.8085, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1574 (Recon: 0.1574, KL: 24.4333, Current Beta: 0.0000) | Avg Valid Loss: 0.1183 | Avg Valid recon Loss: 0.1183\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1270, recon=0.1270, kl=4.5448, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1455 (Recon: 0.1454, KL: 8.3272, Current Beta: 0.0000) | Avg Valid Loss: 0.1085 | Avg Valid recon Loss: 0.1085\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1137, recon=0.1137, kl=1.1283, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1344 (Recon: 0.1344, KL: 1.8784, Current Beta: 0.0000) | Avg Valid Loss: 0.1006 | Avg Valid recon Loss: 0.1006\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1112, recon=0.1112, kl=0.4438, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1161 (Recon: 0.1161, KL: 0.4406, Current Beta: 0.0000) | Avg Valid Loss: 0.0956 | Avg Valid recon Loss: 0.0956\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0920, recon=0.0920, kl=0.0861, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1178 (Recon: 0.1178, KL: 0.0968, Current Beta: 0.0000) | Avg Valid Loss: 0.0899 | Avg Valid recon Loss: 0.0899\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0994, recon=0.0994, kl=0.0069, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1107 (Recon: 0.1107, KL: 0.0168, Current Beta: 0.0001) | Avg Valid Loss: 0.0852 | Avg Valid recon Loss: 0.0852\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.2664, recon=0.2664, kl=0.0019, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.1040 (Recon: 0.1040, KL: 0.0037, Current Beta: 0.0003) | Avg Valid Loss: 0.0810 | Avg Valid recon Loss: 0.0810\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0899, recon=0.0899, kl=0.0007, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0983 (Recon: 0.0983, KL: 0.0009, Current Beta: 0.0008) | Avg Valid Loss: 0.0776 | Avg Valid recon Loss: 0.0776\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1270, recon=0.1270, kl=0.0004, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0930 (Recon: 0.0930, KL: 0.0009, Current Beta: 0.0018) | Avg Valid Loss: 0.0749 | Avg Valid recon Loss: 0.0749\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0666, recon=0.0666, kl=0.0003, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0883 (Recon: 0.0883, KL: 0.0009, Current Beta: 0.0038) | Avg Valid Loss: 0.0718 | Avg Valid recon Loss: 0.0718\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0659, recon=0.0659, kl=0.0002, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0849 (Recon: 0.0849, KL: 0.0003, Current Beta: 0.0062) | Avg Valid Loss: 0.0691 | Avg Valid recon Loss: 0.0691\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0609, recon=0.0609, kl=0.0004, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0745 (Recon: 0.0744, KL: 0.0008, Current Beta: 0.0100) | Avg Valid Loss: 0.0683 | Avg Valid recon Loss: 0.0683\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0636, recon=0.0636, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0781 (Recon: 0.0781, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0661 | Avg Valid recon Loss: 0.0661\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0512, recon=0.0512, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0754 (Recon: 0.0754, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0645 | Avg Valid recon Loss: 0.0645\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0887, recon=0.0887, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0733 (Recon: 0.0733, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0632 | Avg Valid recon Loss: 0.0632\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0558, recon=0.0557, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0709 (Recon: 0.0709, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0621 | Avg Valid recon Loss: 0.0621\n",
      "\n",
      "[VRAE Run 304/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1746, recon=0.1746, kl=55.6908, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2865 (Recon: 0.2865, KL: 28.6193, Current Beta: 0.0000) | Avg Valid Loss: 0.1158 | Avg Valid recon Loss: 0.1158\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1174, recon=0.1174, kl=54.6236, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1278 (Recon: 0.1278, KL: 56.7626, Current Beta: 0.0000) | Avg Valid Loss: 0.0841 | Avg Valid recon Loss: 0.0841\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0680, recon=0.0680, kl=49.9876, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0927 (Recon: 0.0926, KL: 55.0623, Current Beta: 0.0000) | Avg Valid Loss: 0.0704 | Avg Valid recon Loss: 0.0704\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0513, recon=0.0513, kl=35.6358, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0747 (Recon: 0.0747, KL: 42.0645, Current Beta: 0.0000) | Avg Valid Loss: 0.0617 | Avg Valid recon Loss: 0.0617\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0497, recon=0.0497, kl=21.1347, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0667 (Recon: 0.0667, KL: 28.6814, Current Beta: 0.0000) | Avg Valid Loss: 0.0578 | Avg Valid recon Loss: 0.0577\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0786, recon=0.0786, kl=20.4761, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0603 (Recon: 0.0602, KL: 19.8449, Current Beta: 0.0000) | Avg Valid Loss: 0.0513 | Avg Valid recon Loss: 0.0513\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0448, recon=0.0448, kl=8.3721, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0562 (Recon: 0.0561, KL: 12.6305, Current Beta: 0.0000) | Avg Valid Loss: 0.0488 | Avg Valid recon Loss: 0.0488\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0408, recon=0.0408, kl=2.0630, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0517 (Recon: 0.0516, KL: 4.1415, Current Beta: 0.0000) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0449\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0428, recon=0.0428, kl=1.1960, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0495 (Recon: 0.0494, KL: 1.1293, Current Beta: 0.0000) | Avg Valid Loss: 0.0453 | Avg Valid recon Loss: 0.0452\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0387, recon=0.0387, kl=0.0624, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0481, KL: 0.2278, Current Beta: 0.0001) | Avg Valid Loss: 0.0431 | Avg Valid recon Loss: 0.0431\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0418, recon=0.0418, kl=0.0136, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0468 (Recon: 0.0468, KL: 0.0237, Current Beta: 0.0003) | Avg Valid Loss: 0.0441 | Avg Valid recon Loss: 0.0441\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0594, recon=0.0594, kl=0.0030, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0457 (Recon: 0.0457, KL: 0.0069, Current Beta: 0.0008) | Avg Valid Loss: 0.0405 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0345, recon=0.0345, kl=0.0051, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0432 (Recon: 0.0432, KL: 0.0056, Current Beta: 0.0018) | Avg Valid Loss: 0.0380 | Avg Valid recon Loss: 0.0380\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0373, recon=0.0373, kl=0.0058, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0398 (Recon: 0.0398, KL: 0.0041, Current Beta: 0.0038) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0312, recon=0.0312, kl=0.0020, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0414 (Recon: 0.0414, KL: 0.0032, Current Beta: 0.0062) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0323, recon=0.0322, kl=0.0034, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0398 (Recon: 0.0398, KL: 0.0036, Current Beta: 0.0100) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0383, recon=0.0382, kl=0.0062, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0385 (Recon: 0.0385, KL: 0.0019, Current Beta: 0.0100) | Avg Valid Loss: 0.0348 | Avg Valid recon Loss: 0.0348\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0300, recon=0.0300, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0379 (Recon: 0.0379, KL: 0.0008, Current Beta: 0.0100) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0379, recon=0.0379, kl=0.0008, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0377 (Recon: 0.0377, KL: 0.0008, Current Beta: 0.0100) | Avg Valid Loss: 0.0340 | Avg Valid recon Loss: 0.0340\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0347, recon=0.0347, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0373 (Recon: 0.0373, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0330\n",
      "\n",
      "[VRAE Run 305/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3529, recon=0.3529, kl=8.0968, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5520 (Recon: 0.5520, KL: 2.7489, Current Beta: 0.0000) | Avg Valid Loss: 0.3323 | Avg Valid recon Loss: 0.3323\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2409, recon=0.2409, kl=103.8877, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2613 (Recon: 0.2613, KL: 78.9326, Current Beta: 0.0000) | Avg Valid Loss: 0.1931 | Avg Valid recon Loss: 0.1931\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1832, recon=0.1832, kl=97.5848, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1981 (Recon: 0.1981, KL: 104.4424, Current Beta: 0.0000) | Avg Valid Loss: 0.1505 | Avg Valid recon Loss: 0.1505\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1298, recon=0.1298, kl=58.4354, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1686 (Recon: 0.1686, KL: 75.1571, Current Beta: 0.0000) | Avg Valid Loss: 0.1281 | Avg Valid recon Loss: 0.1280\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1108, recon=0.1108, kl=23.9937, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1532 (Recon: 0.1532, KL: 36.2835, Current Beta: 0.0000) | Avg Valid Loss: 0.1157 | Avg Valid recon Loss: 0.1157\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1209, recon=0.1209, kl=6.6028, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1413 (Recon: 0.1412, KL: 12.5124, Current Beta: 0.0000) | Avg Valid Loss: 0.1059 | Avg Valid recon Loss: 0.1059\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1173, recon=0.1173, kl=1.7446, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1310 (Recon: 0.1310, KL: 3.0368, Current Beta: 0.0000) | Avg Valid Loss: 0.0992 | Avg Valid recon Loss: 0.0992\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0932, recon=0.0932, kl=0.5672, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1233 (Recon: 0.1233, KL: 0.7328, Current Beta: 0.0000) | Avg Valid Loss: 0.0928 | Avg Valid recon Loss: 0.0928\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0893, recon=0.0893, kl=0.1005, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1147 (Recon: 0.1146, KL: 0.1400, Current Beta: 0.0000) | Avg Valid Loss: 0.0876 | Avg Valid recon Loss: 0.0876\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0794, recon=0.0794, kl=0.0288, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1075 (Recon: 0.1075, KL: 0.0321, Current Beta: 0.0001) | Avg Valid Loss: 0.0833 | Avg Valid recon Loss: 0.0833\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0910, recon=0.0910, kl=0.0028, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.1011 (Recon: 0.1010, KL: 0.0071, Current Beta: 0.0003) | Avg Valid Loss: 0.0801 | Avg Valid recon Loss: 0.0801\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0729, recon=0.0729, kl=0.0010, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0962 (Recon: 0.0962, KL: 0.0015, Current Beta: 0.0008) | Avg Valid Loss: 0.0768 | Avg Valid recon Loss: 0.0768\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0768, recon=0.0768, kl=0.0004, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0912 (Recon: 0.0912, KL: 0.0006, Current Beta: 0.0018) | Avg Valid Loss: 0.0738 | Avg Valid recon Loss: 0.0738\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0767, recon=0.0767, kl=0.0004, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0846 (Recon: 0.0846, KL: 0.0006, Current Beta: 0.0038) | Avg Valid Loss: 0.0717 | Avg Valid recon Loss: 0.0717\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0624, recon=0.0624, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0833 (Recon: 0.0833, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0698 | Avg Valid recon Loss: 0.0698\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0548, recon=0.0548, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0794 (Recon: 0.0794, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0680 | Avg Valid recon Loss: 0.0680\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0570, recon=0.0570, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0774 (Recon: 0.0774, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0658 | Avg Valid recon Loss: 0.0658\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0549, recon=0.0549, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0745 (Recon: 0.0745, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0643 | Avg Valid recon Loss: 0.0643\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0603, recon=0.0603, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0729 (Recon: 0.0729, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0634 | Avg Valid recon Loss: 0.0634\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0576, recon=0.0576, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0707 (Recon: 0.0707, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0621 | Avg Valid recon Loss: 0.0621\n",
      "\n",
      "[VRAE Run 306/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 1, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1572, recon=0.1572, kl=69.7101, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2575 (Recon: 0.2575, KL: 34.0405, Current Beta: 0.0000) | Avg Valid Loss: 0.1076 | Avg Valid recon Loss: 0.1076\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0756, recon=0.0756, kl=121.5101, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1174 (Recon: 0.1174, KL: 107.4605, Current Beta: 0.0000) | Avg Valid Loss: 0.0772 | Avg Valid recon Loss: 0.0772\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0601, recon=0.0601, kl=85.9239, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0869 (Recon: 0.0869, KL: 99.0582, Current Beta: 0.0000) | Avg Valid Loss: 0.0647 | Avg Valid recon Loss: 0.0646\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0777, recon=0.0777, kl=67.1388, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0712 (Recon: 0.0712, KL: 71.9344, Current Beta: 0.0000) | Avg Valid Loss: 0.0595 | Avg Valid recon Loss: 0.0595\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0660, recon=0.0660, kl=40.5574, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0636 (Recon: 0.0636, KL: 48.2401, Current Beta: 0.0000) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0565\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0392, recon=0.0391, kl=20.7428, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0586 (Recon: 0.0586, KL: 25.7496, Current Beta: 0.0000) | Avg Valid Loss: 0.0500 | Avg Valid recon Loss: 0.0499\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0469, recon=0.0469, kl=8.9195, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0539 (Recon: 0.0539, KL: 10.5689, Current Beta: 0.0000) | Avg Valid Loss: 0.0465 | Avg Valid recon Loss: 0.0464\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0535, recon=0.0534, kl=2.5787, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0509 (Recon: 0.0508, KL: 3.5197, Current Beta: 0.0000) | Avg Valid Loss: 0.0501 | Avg Valid recon Loss: 0.0501\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0343, recon=0.0343, kl=0.6082, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0540, KL: 0.7403, Current Beta: 0.0000) | Avg Valid Loss: 0.0449 | Avg Valid recon Loss: 0.0449\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0448, recon=0.0448, kl=0.0834, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0468 (Recon: 0.0468, KL: 0.1350, Current Beta: 0.0001) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=0.0233, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0435 (Recon: 0.0435, KL: 0.0270, Current Beta: 0.0003) | Avg Valid Loss: 0.0396 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0263, recon=0.0263, kl=0.0029, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0423, KL: 0.0063, Current Beta: 0.0008) | Avg Valid Loss: 0.0385 | Avg Valid recon Loss: 0.0385\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0319, recon=0.0319, kl=0.0011, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0380 (Recon: 0.0380, KL: 0.0026, Current Beta: 0.0018) | Avg Valid Loss: 0.0377 | Avg Valid recon Loss: 0.0377\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0348, recon=0.0348, kl=0.0063, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0405, KL: 0.0014, Current Beta: 0.0038) | Avg Valid Loss: 0.0363 | Avg Valid recon Loss: 0.0363\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0361, recon=0.0361, kl=0.0022, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0394, KL: 0.0026, Current Beta: 0.0062) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0358\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0344, recon=0.0344, kl=0.0010, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0395 (Recon: 0.0395, KL: 0.0010, Current Beta: 0.0100) | Avg Valid Loss: 0.0357 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0242, recon=0.0241, kl=0.0081, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0356 (Recon: 0.0356, KL: 0.0009, Current Beta: 0.0100) | Avg Valid Loss: 0.0350 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0339, recon=0.0339, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0383 (Recon: 0.0383, KL: 0.0012, Current Beta: 0.0100) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0351\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0315, recon=0.0315, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0375 (Recon: 0.0375, KL: 0.0005, Current Beta: 0.0100) | Avg Valid Loss: 0.0337 | Avg Valid recon Loss: 0.0336\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0291, recon=0.0291, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0368 (Recon: 0.0368, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0330 | Avg Valid recon Loss: 0.0330\n",
      "\n",
      "[VRAE Run 307/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.7186, recon=0.7186, kl=0.7168, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.8449 (Recon: 0.8449, KL: 0.3919, Current Beta: 0.0000) | Avg Valid Loss: 0.7127 | Avg Valid recon Loss: 0.7127\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.4564, recon=0.4564, kl=5.5043, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5863 (Recon: 0.5863, KL: 3.2725, Current Beta: 0.0000) | Avg Valid Loss: 0.5472 | Avg Valid recon Loss: 0.5472\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.3769, recon=0.3769, kl=10.0882, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4682 (Recon: 0.4682, KL: 8.4567, Current Beta: 0.0000) | Avg Valid Loss: 0.4447 | Avg Valid recon Loss: 0.4447\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.4461, recon=0.4460, kl=14.4588, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3965 (Recon: 0.3965, KL: 12.8044, Current Beta: 0.0000) | Avg Valid Loss: 0.3734 | Avg Valid recon Loss: 0.3734\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.3047, recon=0.3046, kl=17.1244, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3414 (Recon: 0.3414, KL: 16.1954, Current Beta: 0.0000) | Avg Valid Loss: 0.3198 | Avg Valid recon Loss: 0.3198\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.3042, recon=0.3042, kl=16.0173, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3024 (Recon: 0.3024, KL: 16.8646, Current Beta: 0.0000) | Avg Valid Loss: 0.2811 | Avg Valid recon Loss: 0.2810\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2623, recon=0.2622, kl=10.0084, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2750 (Recon: 0.2749, KL: 12.6334, Current Beta: 0.0000) | Avg Valid Loss: 0.2506 | Avg Valid recon Loss: 0.2505\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.3002, recon=0.3001, kl=3.5074, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2502 (Recon: 0.2501, KL: 5.7195, Current Beta: 0.0000) | Avg Valid Loss: 0.2256 | Avg Valid recon Loss: 0.2256\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.2726, recon=0.2726, kl=0.7515, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2272 (Recon: 0.2271, KL: 1.5575, Current Beta: 0.0000) | Avg Valid Loss: 0.2056 | Avg Valid recon Loss: 0.2056\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.2129, recon=0.2129, kl=0.0786, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.2107 (Recon: 0.2107, KL: 0.2526, Current Beta: 0.0001) | Avg Valid Loss: 0.1901 | Avg Valid recon Loss: 0.1901\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1705, recon=0.1705, kl=0.0107, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.1950 (Recon: 0.1950, KL: 0.0289, Current Beta: 0.0003) | Avg Valid Loss: 0.1768 | Avg Valid recon Loss: 0.1768\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.3795, recon=0.3795, kl=0.0015, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.1836 (Recon: 0.1836, KL: 0.0030, Current Beta: 0.0008) | Avg Valid Loss: 0.1660 | Avg Valid recon Loss: 0.1660\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1375, recon=0.1375, kl=0.0004, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.1727 (Recon: 0.1727, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.1563 | Avg Valid recon Loss: 0.1563\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1581, recon=0.1581, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1526 (Recon: 0.1526, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.1484 | Avg Valid recon Loss: 0.1484\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.2003, recon=0.2003, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.1559 (Recon: 0.1559, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.1416 | Avg Valid recon Loss: 0.1416\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1118, recon=0.1118, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1461 (Recon: 0.1461, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1347 | Avg Valid recon Loss: 0.1347\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0987, recon=0.0987, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1399 (Recon: 0.1399, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1297 | Avg Valid recon Loss: 0.1297\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1174, recon=0.1174, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1351 (Recon: 0.1351, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1243 | Avg Valid recon Loss: 0.1243\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1169, recon=0.1169, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1297 (Recon: 0.1297, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1196 | Avg Valid recon Loss: 0.1196\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0813, recon=0.0813, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1214 (Recon: 0.1214, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1160 | Avg Valid recon Loss: 0.1160\n",
      "\n",
      "[VRAE Run 308/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6474, recon=0.6474, kl=22.3943, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4717 (Recon: 0.4717, KL: 11.4550, Current Beta: 0.0000) | Avg Valid Loss: 0.2309 | Avg Valid recon Loss: 0.2309\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1269, recon=0.1269, kl=33.4877, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1943 (Recon: 0.1943, KL: 30.3387, Current Beta: 0.0000) | Avg Valid Loss: 0.1372 | Avg Valid recon Loss: 0.1372\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1003, recon=0.1003, kl=35.9452, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1352 (Recon: 0.1352, KL: 35.2214, Current Beta: 0.0000) | Avg Valid Loss: 0.1108 | Avg Valid recon Loss: 0.1108\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0944, recon=0.0944, kl=30.6844, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1145 (Recon: 0.1145, KL: 33.2681, Current Beta: 0.0000) | Avg Valid Loss: 0.0992 | Avg Valid recon Loss: 0.0992\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0964, recon=0.0964, kl=20.1015, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0984 (Recon: 0.0984, KL: 24.3074, Current Beta: 0.0000) | Avg Valid Loss: 0.0871 | Avg Valid recon Loss: 0.0871\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1183, recon=0.1183, kl=10.4910, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0848 (Recon: 0.0848, KL: 13.5906, Current Beta: 0.0000) | Avg Valid Loss: 0.0790 | Avg Valid recon Loss: 0.0790\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0659, recon=0.0658, kl=4.9253, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0803 (Recon: 0.0802, KL: 6.0480, Current Beta: 0.0000) | Avg Valid Loss: 0.0752 | Avg Valid recon Loss: 0.0751\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0809, recon=0.0808, kl=0.8547, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0750 (Recon: 0.0750, KL: 1.5757, Current Beta: 0.0000) | Avg Valid Loss: 0.0691 | Avg Valid recon Loss: 0.0691\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0595, recon=0.0595, kl=0.0670, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0708 (Recon: 0.0708, KL: 0.2016, Current Beta: 0.0000) | Avg Valid Loss: 0.0646 | Avg Valid recon Loss: 0.0646\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0777, recon=0.0777, kl=0.0117, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0688 (Recon: 0.0688, KL: 0.0199, Current Beta: 0.0001) | Avg Valid Loss: 0.0646 | Avg Valid recon Loss: 0.0646\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0640, recon=0.0640, kl=0.0019, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0653 (Recon: 0.0653, KL: 0.0029, Current Beta: 0.0003) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1948, recon=0.1948, kl=0.0003, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0619 (Recon: 0.0619, KL: 0.0004, Current Beta: 0.0008) | Avg Valid Loss: 0.0582 | Avg Valid recon Loss: 0.0582\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0485, recon=0.0485, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0604 (Recon: 0.0604, KL: 0.0002, Current Beta: 0.0018) | Avg Valid Loss: 0.0711 | Avg Valid recon Loss: 0.0711\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0495, recon=0.0495, kl=0.0000, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0600 (Recon: 0.0600, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0552 | Avg Valid recon Loss: 0.0552\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0784, recon=0.0784, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0567 (Recon: 0.0567, KL: 0.0000, Current Beta: 0.0062) | Avg Valid Loss: 0.0533 | Avg Valid recon Loss: 0.0533\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0457, recon=0.0457, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0540, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.0514 | Avg Valid recon Loss: 0.0514\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0476, recon=0.0476, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0527 (Recon: 0.0527, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0506 | Avg Valid recon Loss: 0.0506\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0369, recon=0.0369, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0530 (Recon: 0.0530, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0500 | Avg Valid recon Loss: 0.0500\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0552, recon=0.0552, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0526 (Recon: 0.0526, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0493\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0345, recon=0.0345, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0509 (Recon: 0.0509, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0481 | Avg Valid recon Loss: 0.0481\n",
      "\n",
      "[VRAE Run 309/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6736, recon=0.6736, kl=0.5806, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.8460 (Recon: 0.8460, KL: 0.4075, Current Beta: 0.0000) | Avg Valid Loss: 0.7295 | Avg Valid recon Loss: 0.7295\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.6604, recon=0.6604, kl=8.6499, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5967 (Recon: 0.5967, KL: 4.0139, Current Beta: 0.0000) | Avg Valid Loss: 0.5507 | Avg Valid recon Loss: 0.5507\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.3894, recon=0.3894, kl=23.1290, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4691 (Recon: 0.4691, KL: 17.3025, Current Beta: 0.0000) | Avg Valid Loss: 0.4412 | Avg Valid recon Loss: 0.4412\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.4975, recon=0.4975, kl=32.1664, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3862 (Recon: 0.3862, KL: 29.1732, Current Beta: 0.0000) | Avg Valid Loss: 0.3624 | Avg Valid recon Loss: 0.3624\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2918, recon=0.2918, kl=33.2521, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3286 (Recon: 0.3286, KL: 33.3358, Current Beta: 0.0000) | Avg Valid Loss: 0.3063 | Avg Valid recon Loss: 0.3063\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.3356, recon=0.3356, kl=26.5570, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2889 (Recon: 0.2889, KL: 29.8996, Current Beta: 0.0000) | Avg Valid Loss: 0.2668 | Avg Valid recon Loss: 0.2667\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.3387, recon=0.3387, kl=12.7697, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2587 (Recon: 0.2586, KL: 18.5226, Current Beta: 0.0000) | Avg Valid Loss: 0.2370 | Avg Valid recon Loss: 0.2369\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1861, recon=0.1861, kl=4.0276, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2339 (Recon: 0.2338, KL: 6.6924, Current Beta: 0.0000) | Avg Valid Loss: 0.2151 | Avg Valid recon Loss: 0.2150\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.2368, recon=0.2367, kl=1.3507, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2154 (Recon: 0.2153, KL: 2.0602, Current Beta: 0.0000) | Avg Valid Loss: 0.1971 | Avg Valid recon Loss: 0.1970\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1588, recon=0.1588, kl=0.3046, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1985 (Recon: 0.1984, KL: 0.5596, Current Beta: 0.0001) | Avg Valid Loss: 0.1826 | Avg Valid recon Loss: 0.1826\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1677, recon=0.1677, kl=0.0401, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.1849 (Recon: 0.1849, KL: 0.0854, Current Beta: 0.0003) | Avg Valid Loss: 0.1705 | Avg Valid recon Loss: 0.1705\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1340, recon=0.1340, kl=0.0035, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.1710 (Recon: 0.1710, KL: 0.0077, Current Beta: 0.0008) | Avg Valid Loss: 0.1609 | Avg Valid recon Loss: 0.1609\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1419, recon=0.1419, kl=0.0008, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.1626 (Recon: 0.1626, KL: 0.0009, Current Beta: 0.0018) | Avg Valid Loss: 0.1525 | Avg Valid recon Loss: 0.1525\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1898, recon=0.1898, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1542 (Recon: 0.1542, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.1456 | Avg Valid recon Loss: 0.1456\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1352, recon=0.1352, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.1460 (Recon: 0.1460, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.1382 | Avg Valid recon Loss: 0.1382\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.3628, recon=0.3628, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1402 (Recon: 0.1402, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.1330 | Avg Valid recon Loss: 0.1330\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.1864, recon=0.1864, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1342 (Recon: 0.1342, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1279 | Avg Valid recon Loss: 0.1279\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1207, recon=0.1207, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1289 (Recon: 0.1289, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1236 | Avg Valid recon Loss: 0.1236\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0938, recon=0.0938, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1241 (Recon: 0.1241, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1190 | Avg Valid recon Loss: 0.1190\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1018, recon=0.1018, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1205 (Recon: 0.1205, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1157 | Avg Valid recon Loss: 0.1157\n",
      "\n",
      "[VRAE Run 310/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2572, recon=0.2572, kl=39.3998, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4833 (Recon: 0.4833, KL: 20.1652, Current Beta: 0.0000) | Avg Valid Loss: 0.2232 | Avg Valid recon Loss: 0.2232\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1331, recon=0.1331, kl=56.1797, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1913 (Recon: 0.1913, KL: 51.9771, Current Beta: 0.0000) | Avg Valid Loss: 0.1362 | Avg Valid recon Loss: 0.1362\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1112, recon=0.1112, kl=64.6620, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1336 (Recon: 0.1336, KL: 62.2652, Current Beta: 0.0000) | Avg Valid Loss: 0.1091 | Avg Valid recon Loss: 0.1090\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0955, recon=0.0955, kl=60.2551, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1042 (Recon: 0.1042, KL: 63.6842, Current Beta: 0.0000) | Avg Valid Loss: 0.0958 | Avg Valid recon Loss: 0.0958\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0644, recon=0.0643, kl=38.4309, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0943 (Recon: 0.0942, KL: 47.2349, Current Beta: 0.0000) | Avg Valid Loss: 0.0851 | Avg Valid recon Loss: 0.0851\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0553, recon=0.0552, kl=19.9717, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0829 (Recon: 0.0828, KL: 25.4757, Current Beta: 0.0000) | Avg Valid Loss: 0.0755 | Avg Valid recon Loss: 0.0755\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0472, recon=0.0471, kl=8.1047, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0809 (Recon: 0.0808, KL: 10.5384, Current Beta: 0.0000) | Avg Valid Loss: 0.0724 | Avg Valid recon Loss: 0.0723\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0479, recon=0.0479, kl=0.7893, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0736 (Recon: 0.0736, KL: 2.0823, Current Beta: 0.0000) | Avg Valid Loss: 0.0672 | Avg Valid recon Loss: 0.0672\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0549, recon=0.0549, kl=0.0468, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0704 (Recon: 0.0704, KL: 0.2586, Current Beta: 0.0000) | Avg Valid Loss: 0.0654 | Avg Valid recon Loss: 0.0654\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0508, recon=0.0508, kl=0.0143, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0665 (Recon: 0.0665, KL: 0.0221, Current Beta: 0.0001) | Avg Valid Loss: 0.0620 | Avg Valid recon Loss: 0.0620\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0495, recon=0.0495, kl=0.0032, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0640 (Recon: 0.0640, KL: 0.0043, Current Beta: 0.0003) | Avg Valid Loss: 0.0583 | Avg Valid recon Loss: 0.0583\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0427, recon=0.0427, kl=0.0007, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0616 (Recon: 0.0616, KL: 0.0010, Current Beta: 0.0008) | Avg Valid Loss: 0.0566 | Avg Valid recon Loss: 0.0566\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0447, recon=0.0447, kl=0.0003, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0590 (Recon: 0.0590, KL: 0.0003, Current Beta: 0.0018) | Avg Valid Loss: 0.0574 | Avg Valid recon Loss: 0.0574\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0418, recon=0.0418, kl=0.0002, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0578 (Recon: 0.0577, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.0543 | Avg Valid recon Loss: 0.0543\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0410, recon=0.0410, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0540, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0520 | Avg Valid recon Loss: 0.0520\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0446, recon=0.0446, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0536 (Recon: 0.0536, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0525 | Avg Valid recon Loss: 0.0525\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0400, recon=0.0400, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0561 (Recon: 0.0561, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0520 | Avg Valid recon Loss: 0.0520\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0549, recon=0.0549, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0520 (Recon: 0.0520, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0481 | Avg Valid recon Loss: 0.0481\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0501, recon=0.0501, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0512 (Recon: 0.0512, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0478 | Avg Valid recon Loss: 0.0478\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0431, recon=0.0431, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0500 (Recon: 0.0500, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0460\n",
      "\n",
      "[VRAE Run 311/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.6790, recon=0.6790, kl=1.2561, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.8526 (Recon: 0.8526, KL: 0.9514, Current Beta: 0.0000) | Avg Valid Loss: 0.7271 | Avg Valid recon Loss: 0.7271\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.4756, recon=0.4756, kl=15.1549, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6031 (Recon: 0.6031, KL: 7.0499, Current Beta: 0.0000) | Avg Valid Loss: 0.5537 | Avg Valid recon Loss: 0.5537\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.4288, recon=0.4288, kl=47.4656, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4751 (Recon: 0.4751, KL: 35.2202, Current Beta: 0.0000) | Avg Valid Loss: 0.4498 | Avg Valid recon Loss: 0.4498\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.3047, recon=0.3047, kl=65.0492, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3976 (Recon: 0.3976, KL: 59.6094, Current Beta: 0.0000) | Avg Valid Loss: 0.3703 | Avg Valid recon Loss: 0.3703\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.2935, recon=0.2934, kl=62.5088, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3386 (Recon: 0.3385, KL: 65.0872, Current Beta: 0.0000) | Avg Valid Loss: 0.3101 | Avg Valid recon Loss: 0.3101\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.3224, recon=0.3223, kl=40.3737, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2902 (Recon: 0.2901, KL: 50.2274, Current Beta: 0.0000) | Avg Valid Loss: 0.2647 | Avg Valid recon Loss: 0.2646\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1908, recon=0.1908, kl=15.5459, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2591 (Recon: 0.2590, KL: 24.5618, Current Beta: 0.0000) | Avg Valid Loss: 0.2354 | Avg Valid recon Loss: 0.2353\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1855, recon=0.1855, kl=3.4073, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2346 (Recon: 0.2345, KL: 7.1406, Current Beta: 0.0000) | Avg Valid Loss: 0.2127 | Avg Valid recon Loss: 0.2126\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1953, recon=0.1953, kl=0.6831, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2178 (Recon: 0.2178, KL: 1.4116, Current Beta: 0.0000) | Avg Valid Loss: 0.1953 | Avg Valid recon Loss: 0.1952\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1462, recon=0.1462, kl=0.1205, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1998 (Recon: 0.1998, KL: 0.2427, Current Beta: 0.0001) | Avg Valid Loss: 0.1816 | Avg Valid recon Loss: 0.1816\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1468, recon=0.1468, kl=0.0172, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.1864 (Recon: 0.1864, KL: 0.0334, Current Beta: 0.0003) | Avg Valid Loss: 0.1700 | Avg Valid recon Loss: 0.1699\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1602, recon=0.1602, kl=0.0035, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.1749 (Recon: 0.1749, KL: 0.0045, Current Beta: 0.0008) | Avg Valid Loss: 0.1608 | Avg Valid recon Loss: 0.1608\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1341, recon=0.1341, kl=0.0003, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.1647 (Recon: 0.1647, KL: 0.0008, Current Beta: 0.0018) | Avg Valid Loss: 0.1519 | Avg Valid recon Loss: 0.1519\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.1262, recon=0.1262, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1569 (Recon: 0.1569, KL: 0.0002, Current Beta: 0.0038) | Avg Valid Loss: 0.1447 | Avg Valid recon Loss: 0.1447\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1202, recon=0.1202, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.1504 (Recon: 0.1504, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.1380 | Avg Valid recon Loss: 0.1380\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1086, recon=0.1086, kl=0.0002, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1435 (Recon: 0.1435, KL: 0.0003, Current Beta: 0.0100) | Avg Valid Loss: 0.1328 | Avg Valid recon Loss: 0.1328\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.3499, recon=0.3499, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1374 (Recon: 0.1374, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.1287 | Avg Valid recon Loss: 0.1287\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0960, recon=0.0960, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1324 (Recon: 0.1324, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1238 | Avg Valid recon Loss: 0.1238\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1105, recon=0.1105, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1259 (Recon: 0.1259, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1202 | Avg Valid recon Loss: 0.1202\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.1133, recon=0.1133, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.1231 (Recon: 0.1231, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.1157 | Avg Valid recon Loss: 0.1157\n",
      "\n",
      "[VRAE Run 312/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 32, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2647, recon=0.2647, kl=63.1831, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4529 (Recon: 0.4529, KL: 32.1933, Current Beta: 0.0000) | Avg Valid Loss: 0.2126 | Avg Valid recon Loss: 0.2126\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1397, recon=0.1397, kl=107.9495, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1842 (Recon: 0.1842, KL: 95.5788, Current Beta: 0.0000) | Avg Valid Loss: 0.1327 | Avg Valid recon Loss: 0.1327\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1087, recon=0.1087, kl=106.7834, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1291 (Recon: 0.1291, KL: 109.0028, Current Beta: 0.0000) | Avg Valid Loss: 0.1042 | Avg Valid recon Loss: 0.1042\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1235, recon=0.1235, kl=85.1635, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1013 (Recon: 0.1013, KL: 94.0458, Current Beta: 0.0000) | Avg Valid Loss: 0.0853 | Avg Valid recon Loss: 0.0853\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0771, recon=0.0771, kl=53.2306, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0874 (Recon: 0.0873, KL: 59.4076, Current Beta: 0.0000) | Avg Valid Loss: 0.0799 | Avg Valid recon Loss: 0.0799\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0754, recon=0.0753, kl=25.3162, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0803 (Recon: 0.0802, KL: 32.1582, Current Beta: 0.0000) | Avg Valid Loss: 0.0747 | Avg Valid recon Loss: 0.0747\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0624, recon=0.0624, kl=7.1636, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0743 (Recon: 0.0742, KL: 12.1613, Current Beta: 0.0000) | Avg Valid Loss: 0.0684 | Avg Valid recon Loss: 0.0684\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0487, recon=0.0487, kl=2.3100, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0687 (Recon: 0.0686, KL: 2.6863, Current Beta: 0.0000) | Avg Valid Loss: 0.0637 | Avg Valid recon Loss: 0.0637\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0664, recon=0.0664, kl=0.2802, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0646 (Recon: 0.0645, KL: 0.4546, Current Beta: 0.0000) | Avg Valid Loss: 0.0606 | Avg Valid recon Loss: 0.0606\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1003, recon=0.1003, kl=0.0121, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0604 (Recon: 0.0604, KL: 0.0605, Current Beta: 0.0001) | Avg Valid Loss: 0.0583 | Avg Valid recon Loss: 0.0583\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0495, recon=0.0495, kl=0.0043, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0581, KL: 0.0068, Current Beta: 0.0003) | Avg Valid Loss: 0.0557 | Avg Valid recon Loss: 0.0557\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0438, recon=0.0438, kl=0.0006, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0568 (Recon: 0.0568, KL: 0.0012, Current Beta: 0.0008) | Avg Valid Loss: 0.0548 | Avg Valid recon Loss: 0.0548\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0552, recon=0.0552, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0576 (Recon: 0.0576, KL: 0.0003, Current Beta: 0.0018) | Avg Valid Loss: 0.0537 | Avg Valid recon Loss: 0.0537\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0381, recon=0.0381, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0532 (Recon: 0.0532, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0506 | Avg Valid recon Loss: 0.0506\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0502, recon=0.0502, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0524 (Recon: 0.0524, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0494 | Avg Valid recon Loss: 0.0494\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0420, recon=0.0420, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0506 (Recon: 0.0506, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0472 | Avg Valid recon Loss: 0.0472\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0473, recon=0.0473, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0496 (Recon: 0.0496, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0466 | Avg Valid recon Loss: 0.0466\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0370, recon=0.0370, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0477 (Recon: 0.0477, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0454 | Avg Valid recon Loss: 0.0454\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0490 (Recon: 0.0490, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0450 | Avg Valid recon Loss: 0.0450\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0466 (Recon: 0.0466, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0436 | Avg Valid recon Loss: 0.0436\n",
      "\n",
      "[VRAE Run 313/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.5197, recon=0.5197, kl=0.7716, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6511 (Recon: 0.6511, KL: 0.3643, Current Beta: 0.0000) | Avg Valid Loss: 0.4897 | Avg Valid recon Loss: 0.4897\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2911, recon=0.2911, kl=11.7608, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3788 (Recon: 0.3788, KL: 6.9554, Current Beta: 0.0000) | Avg Valid Loss: 0.3127 | Avg Valid recon Loss: 0.3127\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.3273, recon=0.3273, kl=20.1333, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2755 (Recon: 0.2755, KL: 17.3362, Current Beta: 0.0000) | Avg Valid Loss: 0.2297 | Avg Valid recon Loss: 0.2297\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1586, recon=0.1586, kl=24.4374, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2210 (Recon: 0.2210, KL: 23.0012, Current Beta: 0.0000) | Avg Valid Loss: 0.1832 | Avg Valid recon Loss: 0.1832\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1568, recon=0.1568, kl=23.1248, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1890 (Recon: 0.1890, KL: 24.1689, Current Beta: 0.0000) | Avg Valid Loss: 0.1573 | Avg Valid recon Loss: 0.1573\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.4201, recon=0.4200, kl=14.9281, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1691 (Recon: 0.1691, KL: 18.5314, Current Beta: 0.0000) | Avg Valid Loss: 0.1399 | Avg Valid recon Loss: 0.1399\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1292, recon=0.1292, kl=5.4232, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1528 (Recon: 0.1527, KL: 8.7908, Current Beta: 0.0000) | Avg Valid Loss: 0.1283 | Avg Valid recon Loss: 0.1283\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1068, recon=0.1068, kl=1.5029, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1419 (Recon: 0.1419, KL: 2.6913, Current Beta: 0.0000) | Avg Valid Loss: 0.1177 | Avg Valid recon Loss: 0.1177\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0926, recon=0.0926, kl=0.2335, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1308 (Recon: 0.1307, KL: 0.5666, Current Beta: 0.0000) | Avg Valid Loss: 0.1105 | Avg Valid recon Loss: 0.1105\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1099, recon=0.1099, kl=0.0458, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1235 (Recon: 0.1235, KL: 0.0709, Current Beta: 0.0001) | Avg Valid Loss: 0.1049 | Avg Valid recon Loss: 0.1049\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1908, recon=0.1908, kl=0.0043, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.1139 (Recon: 0.1139, KL: 0.0098, Current Beta: 0.0003) | Avg Valid Loss: 0.1014 | Avg Valid recon Loss: 0.1014\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1342, recon=0.1342, kl=0.0007, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.1087 (Recon: 0.1087, KL: 0.0014, Current Beta: 0.0008) | Avg Valid Loss: 0.0953 | Avg Valid recon Loss: 0.0953\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0830, recon=0.0830, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.1044 (Recon: 0.1044, KL: 0.0003, Current Beta: 0.0018) | Avg Valid Loss: 0.0910 | Avg Valid recon Loss: 0.0910\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0923, recon=0.0923, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0987 (Recon: 0.0987, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0880 | Avg Valid recon Loss: 0.0880\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.2781, recon=0.2781, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0945 (Recon: 0.0945, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0850 | Avg Valid recon Loss: 0.0850\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0678, recon=0.0678, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0917 (Recon: 0.0917, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0851 | Avg Valid recon Loss: 0.0851\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0649, recon=0.0649, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0886 (Recon: 0.0886, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0800 | Avg Valid recon Loss: 0.0800\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0592, recon=0.0592, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0849 (Recon: 0.0849, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0777 | Avg Valid recon Loss: 0.0777\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0664, recon=0.0664, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0822 (Recon: 0.0822, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0751 | Avg Valid recon Loss: 0.0751\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0577, recon=0.0577, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0801 (Recon: 0.0801, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0735 | Avg Valid recon Loss: 0.0735\n",
      "\n",
      "[VRAE Run 314/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1881, recon=0.1881, kl=26.2111, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3369 (Recon: 0.3369, KL: 14.3367, Current Beta: 0.0000) | Avg Valid Loss: 0.1422 | Avg Valid recon Loss: 0.1422\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0947, recon=0.0947, kl=33.3324, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1332 (Recon: 0.1332, KL: 31.7403, Current Beta: 0.0000) | Avg Valid Loss: 0.0958 | Avg Valid recon Loss: 0.0958\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0641, recon=0.0641, kl=35.5163, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0932 (Recon: 0.0932, KL: 35.1702, Current Beta: 0.0000) | Avg Valid Loss: 0.0793 | Avg Valid recon Loss: 0.0793\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0661, recon=0.0661, kl=27.5423, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0783 (Recon: 0.0783, KL: 32.0396, Current Beta: 0.0000) | Avg Valid Loss: 0.0688 | Avg Valid recon Loss: 0.0688\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0487, recon=0.0487, kl=17.7933, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0610 (Recon: 0.0610, KL: 21.1070, Current Beta: 0.0000) | Avg Valid Loss: 0.0593 | Avg Valid recon Loss: 0.0593\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0524, recon=0.0524, kl=10.1203, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0639 (Recon: 0.0639, KL: 11.1902, Current Beta: 0.0000) | Avg Valid Loss: 0.0560 | Avg Valid recon Loss: 0.0560\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0387, recon=0.0387, kl=3.4622, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0582 (Recon: 0.0582, KL: 4.9246, Current Beta: 0.0000) | Avg Valid Loss: 0.0515 | Avg Valid recon Loss: 0.0515\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0641, recon=0.0641, kl=0.9454, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0557 (Recon: 0.0557, KL: 1.2840, Current Beta: 0.0000) | Avg Valid Loss: 0.0487 | Avg Valid recon Loss: 0.0487\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0309, recon=0.0309, kl=0.0618, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0528 (Recon: 0.0528, KL: 0.2397, Current Beta: 0.0000) | Avg Valid Loss: 0.0462 | Avg Valid recon Loss: 0.0462\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0444, recon=0.0444, kl=0.0067, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0504 (Recon: 0.0504, KL: 0.0256, Current Beta: 0.0001) | Avg Valid Loss: 0.0457 | Avg Valid recon Loss: 0.0457\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0379, recon=0.0379, kl=0.0017, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0479, KL: 0.0023, Current Beta: 0.0003) | Avg Valid Loss: 0.0429 | Avg Valid recon Loss: 0.0429\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0495, recon=0.0495, kl=0.0002, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0460 (Recon: 0.0460, KL: 0.0005, Current Beta: 0.0008) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0407\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0517, recon=0.0517, kl=0.0000, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0448 (Recon: 0.0448, KL: 0.0001, Current Beta: 0.0018) | Avg Valid Loss: 0.0403 | Avg Valid recon Loss: 0.0403\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0352, recon=0.0352, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0433 (Recon: 0.0433, KL: 0.0000, Current Beta: 0.0038) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0379\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0371, recon=0.0371, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0423 (Recon: 0.0423, KL: 0.0000, Current Beta: 0.0062) | Avg Valid Loss: 0.0388 | Avg Valid recon Loss: 0.0388\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0308, recon=0.0308, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0415, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0384 | Avg Valid recon Loss: 0.0384\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0487, recon=0.0487, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0400 (Recon: 0.0400, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0356 | Avg Valid recon Loss: 0.0356\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0291, recon=0.0291, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0393 (Recon: 0.0393, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0353 | Avg Valid recon Loss: 0.0353\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0872, recon=0.0872, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0384 (Recon: 0.0384, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0341 | Avg Valid recon Loss: 0.0341\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0542, recon=0.0542, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0408 (Recon: 0.0408, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0358 | Avg Valid recon Loss: 0.0358\n",
      "\n",
      "[VRAE Run 315/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4450, recon=0.4450, kl=1.4531, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6980 (Recon: 0.6980, KL: 0.6620, Current Beta: 0.0000) | Avg Valid Loss: 0.5118 | Avg Valid recon Loss: 0.5118\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3028, recon=0.3028, kl=20.0189, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3965 (Recon: 0.3965, KL: 11.8500, Current Beta: 0.0000) | Avg Valid Loss: 0.3402 | Avg Valid recon Loss: 0.3402\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2362, recon=0.2362, kl=37.4868, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2943 (Recon: 0.2943, KL: 31.1905, Current Beta: 0.0000) | Avg Valid Loss: 0.2492 | Avg Valid recon Loss: 0.2492\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1935, recon=0.1935, kl=45.1904, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2346 (Recon: 0.2346, KL: 42.8571, Current Beta: 0.0000) | Avg Valid Loss: 0.1983 | Avg Valid recon Loss: 0.1983\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1535, recon=0.1535, kl=40.5808, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2016 (Recon: 0.2016, KL: 43.3939, Current Beta: 0.0000) | Avg Valid Loss: 0.1661 | Avg Valid recon Loss: 0.1660\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1935, recon=0.1934, kl=22.8897, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1770 (Recon: 0.1769, KL: 30.3344, Current Beta: 0.0000) | Avg Valid Loss: 0.1476 | Avg Valid recon Loss: 0.1475\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1458, recon=0.1457, kl=7.4857, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1585 (Recon: 0.1584, KL: 12.5030, Current Beta: 0.0000) | Avg Valid Loss: 0.1333 | Avg Valid recon Loss: 0.1332\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1099, recon=0.1099, kl=2.1933, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1455 (Recon: 0.1454, KL: 3.7329, Current Beta: 0.0000) | Avg Valid Loss: 0.1252 | Avg Valid recon Loss: 0.1251\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.3358, recon=0.3357, kl=0.5605, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1345 (Recon: 0.1344, KL: 0.8779, Current Beta: 0.0000) | Avg Valid Loss: 0.1160 | Avg Valid recon Loss: 0.1160\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1656, recon=0.1656, kl=0.0872, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1260 (Recon: 0.1260, KL: 0.1441, Current Beta: 0.0001) | Avg Valid Loss: 0.1102 | Avg Valid recon Loss: 0.1102\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0975, recon=0.0974, kl=0.0124, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.1199 (Recon: 0.1199, KL: 0.0183, Current Beta: 0.0003) | Avg Valid Loss: 0.1038 | Avg Valid recon Loss: 0.1038\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0959, recon=0.0959, kl=0.0012, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.1140 (Recon: 0.1140, KL: 0.0026, Current Beta: 0.0008) | Avg Valid Loss: 0.0994 | Avg Valid recon Loss: 0.0994\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0813, recon=0.0813, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.1077 (Recon: 0.1077, KL: 0.0004, Current Beta: 0.0018) | Avg Valid Loss: 0.0959 | Avg Valid recon Loss: 0.0959\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.2816, recon=0.2816, kl=0.0002, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1038 (Recon: 0.1038, KL: 0.0004, Current Beta: 0.0038) | Avg Valid Loss: 0.0922 | Avg Valid recon Loss: 0.0922\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0790, recon=0.0790, kl=0.0002, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.1009 (Recon: 0.1009, KL: 0.0002, Current Beta: 0.0062) | Avg Valid Loss: 0.0900 | Avg Valid recon Loss: 0.0900\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.1378, recon=0.1378, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0933 (Recon: 0.0933, KL: 0.0006, Current Beta: 0.0100) | Avg Valid Loss: 0.0865 | Avg Valid recon Loss: 0.0865\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0747, recon=0.0747, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0926 (Recon: 0.0926, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0833 | Avg Valid recon Loss: 0.0833\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0711, recon=0.0711, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0895 (Recon: 0.0895, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0823 | Avg Valid recon Loss: 0.0823\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.1130, recon=0.1130, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0873 (Recon: 0.0873, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0803 | Avg Valid recon Loss: 0.0803\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0702, recon=0.0702, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0846 (Recon: 0.0846, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0783 | Avg Valid recon Loss: 0.0783\n",
      "\n",
      "[VRAE Run 316/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1466, recon=0.1466, kl=52.9323, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3346 (Recon: 0.3346, KL: 29.8758, Current Beta: 0.0000) | Avg Valid Loss: 0.1434 | Avg Valid recon Loss: 0.1434\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0962, recon=0.0962, kl=61.5820, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1234 (Recon: 0.1234, KL: 58.7365, Current Beta: 0.0000) | Avg Valid Loss: 0.0965 | Avg Valid recon Loss: 0.0965\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.3028, recon=0.3028, kl=59.2871, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1002 (Recon: 0.1002, KL: 60.2999, Current Beta: 0.0000) | Avg Valid Loss: 0.0777 | Avg Valid recon Loss: 0.0777\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0637, recon=0.0636, kl=48.1448, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0818 (Recon: 0.0817, KL: 54.2706, Current Beta: 0.0000) | Avg Valid Loss: 0.0672 | Avg Valid recon Loss: 0.0672\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0496, recon=0.0496, kl=27.7001, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0692 (Recon: 0.0691, KL: 34.3816, Current Beta: 0.0000) | Avg Valid Loss: 0.0602 | Avg Valid recon Loss: 0.0602\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0551, recon=0.0551, kl=18.1084, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0637 (Recon: 0.0636, KL: 19.8929, Current Beta: 0.0000) | Avg Valid Loss: 0.0549 | Avg Valid recon Loss: 0.0549\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0451, recon=0.0451, kl=7.7941, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0581 (Recon: 0.0581, KL: 9.3588, Current Beta: 0.0000) | Avg Valid Loss: 0.0510 | Avg Valid recon Loss: 0.0510\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0470, recon=0.0470, kl=2.0577, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0540 (Recon: 0.0539, KL: 2.4329, Current Beta: 0.0000) | Avg Valid Loss: 0.0479 | Avg Valid recon Loss: 0.0479\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0586, recon=0.0586, kl=0.1468, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0504 (Recon: 0.0504, KL: 0.3861, Current Beta: 0.0000) | Avg Valid Loss: 0.0444 | Avg Valid recon Loss: 0.0444\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0404, recon=0.0404, kl=0.0099, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0477 (Recon: 0.0477, KL: 0.0679, Current Beta: 0.0001) | Avg Valid Loss: 0.0429 | Avg Valid recon Loss: 0.0429\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0372, recon=0.0372, kl=0.0026, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0447 (Recon: 0.0447, KL: 0.0037, Current Beta: 0.0003) | Avg Valid Loss: 0.0408 | Avg Valid recon Loss: 0.0408\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0367, recon=0.0367, kl=0.0004, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 0.0008, Current Beta: 0.0008) | Avg Valid Loss: 0.0397 | Avg Valid recon Loss: 0.0397\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0496, recon=0.0496, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0415 (Recon: 0.0415, KL: 0.0002, Current Beta: 0.0018) | Avg Valid Loss: 0.0383 | Avg Valid recon Loss: 0.0383\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0326, recon=0.0326, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0405, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0373 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0388, recon=0.0388, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0392, KL: 0.0000, Current Beta: 0.0062) | Avg Valid Loss: 0.0389 | Avg Valid recon Loss: 0.0389\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0369, recon=0.0369, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0391 (Recon: 0.0391, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0354 | Avg Valid recon Loss: 0.0354\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0321, recon=0.0321, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0376 (Recon: 0.0376, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0366 | Avg Valid recon Loss: 0.0366\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0486, recon=0.0486, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0384 (Recon: 0.0384, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0346 | Avg Valid recon Loss: 0.0346\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0357, recon=0.0357, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0362 (Recon: 0.0362, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0335 | Avg Valid recon Loss: 0.0335\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0361, recon=0.0361, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0352 (Recon: 0.0352, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0321 | Avg Valid recon Loss: 0.0321\n",
      "\n",
      "[VRAE Run 317/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.4855, recon=0.4855, kl=3.8144, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.6863 (Recon: 0.6863, KL: 1.4824, Current Beta: 0.0000) | Avg Valid Loss: 0.5149 | Avg Valid recon Loss: 0.5149\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.3407, recon=0.3407, kl=55.4309, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3912 (Recon: 0.3912, KL: 34.2686, Current Beta: 0.0000) | Avg Valid Loss: 0.3459 | Avg Valid recon Loss: 0.3459\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.2542, recon=0.2542, kl=84.4044, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3025 (Recon: 0.3025, KL: 75.5477, Current Beta: 0.0000) | Avg Valid Loss: 0.2552 | Avg Valid recon Loss: 0.2552\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1819, recon=0.1818, kl=86.7606, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2397 (Recon: 0.2396, KL: 87.7155, Current Beta: 0.0000) | Avg Valid Loss: 0.1981 | Avg Valid recon Loss: 0.1981\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1692, recon=0.1692, kl=64.8297, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2036 (Recon: 0.2036, KL: 75.2027, Current Beta: 0.0000) | Avg Valid Loss: 0.1676 | Avg Valid recon Loss: 0.1676\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1365, recon=0.1365, kl=25.6324, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1764 (Recon: 0.1763, KL: 40.0124, Current Beta: 0.0000) | Avg Valid Loss: 0.1493 | Avg Valid recon Loss: 0.1492\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1669, recon=0.1669, kl=8.3768, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1609 (Recon: 0.1608, KL: 13.6153, Current Beta: 0.0000) | Avg Valid Loss: 0.1357 | Avg Valid recon Loss: 0.1357\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1103, recon=0.1103, kl=3.0785, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1465 (Recon: 0.1465, KL: 4.1913, Current Beta: 0.0000) | Avg Valid Loss: 0.1257 | Avg Valid recon Loss: 0.1257\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1245, recon=0.1244, kl=1.0690, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1365 (Recon: 0.1364, KL: 1.2791, Current Beta: 0.0000) | Avg Valid Loss: 0.1181 | Avg Valid recon Loss: 0.1181\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1356, recon=0.1356, kl=0.2660, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.1280 (Recon: 0.1279, KL: 0.3110, Current Beta: 0.0001) | Avg Valid Loss: 0.1118 | Avg Valid recon Loss: 0.1118\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0993, recon=0.0993, kl=0.0293, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.1207 (Recon: 0.1207, KL: 0.0467, Current Beta: 0.0003) | Avg Valid Loss: 0.1060 | Avg Valid recon Loss: 0.1060\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.1090, recon=0.1090, kl=0.0027, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.1143 (Recon: 0.1143, KL: 0.0062, Current Beta: 0.0008) | Avg Valid Loss: 0.1010 | Avg Valid recon Loss: 0.1010\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.1419, recon=0.1419, kl=0.0004, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.1095 (Recon: 0.1095, KL: 0.0006, Current Beta: 0.0018) | Avg Valid Loss: 0.0973 | Avg Valid recon Loss: 0.0973\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0979, recon=0.0979, kl=0.0003, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.1048 (Recon: 0.1048, KL: 0.0004, Current Beta: 0.0038) | Avg Valid Loss: 0.0940 | Avg Valid recon Loss: 0.0940\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0957, recon=0.0957, kl=0.0003, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0992 (Recon: 0.0992, KL: 0.0007, Current Beta: 0.0062) | Avg Valid Loss: 0.0903 | Avg Valid recon Loss: 0.0903\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0951, recon=0.0951, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0977 (Recon: 0.0977, KL: 0.0004, Current Beta: 0.0100) | Avg Valid Loss: 0.0887 | Avg Valid recon Loss: 0.0887\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0803, recon=0.0803, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0935 (Recon: 0.0935, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0864 | Avg Valid recon Loss: 0.0864\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.1274, recon=0.1274, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0907 (Recon: 0.0907, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0837 | Avg Valid recon Loss: 0.0837\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.2402, recon=0.2402, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0894 (Recon: 0.0894, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0828 | Avg Valid recon Loss: 0.0828\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0651, recon=0.0651, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0831 (Recon: 0.0831, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0804 | Avg Valid recon Loss: 0.0804\n",
      "\n",
      "[VRAE Run 318/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 64, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1476, recon=0.1476, kl=92.1450, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.3465 (Recon: 0.3465, KL: 44.1981, Current Beta: 0.0000) | Avg Valid Loss: 0.1424 | Avg Valid recon Loss: 0.1424\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1164, recon=0.1164, kl=112.0380, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1365 (Recon: 0.1365, KL: 109.7869, Current Beta: 0.0000) | Avg Valid Loss: 0.0972 | Avg Valid recon Loss: 0.0972\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0885, recon=0.0885, kl=106.4259, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0966 (Recon: 0.0965, KL: 109.6534, Current Beta: 0.0000) | Avg Valid Loss: 0.0784 | Avg Valid recon Loss: 0.0784\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0599, recon=0.0598, kl=81.9328, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0788 (Recon: 0.0787, KL: 94.4415, Current Beta: 0.0000) | Avg Valid Loss: 0.0671 | Avg Valid recon Loss: 0.0671\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0835, recon=0.0834, kl=52.0142, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0686 (Recon: 0.0685, KL: 62.5620, Current Beta: 0.0000) | Avg Valid Loss: 0.0596 | Avg Valid recon Loss: 0.0596\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0401, recon=0.0401, kl=30.8042, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0571 (Recon: 0.0570, KL: 33.8429, Current Beta: 0.0000) | Avg Valid Loss: 0.0564 | Avg Valid recon Loss: 0.0564\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0634, recon=0.0634, kl=10.9764, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0585 (Recon: 0.0584, KL: 14.3744, Current Beta: 0.0000) | Avg Valid Loss: 0.0525 | Avg Valid recon Loss: 0.0525\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0432, recon=0.0432, kl=2.7487, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0547 (Recon: 0.0547, KL: 3.4437, Current Beta: 0.0000) | Avg Valid Loss: 0.0498 | Avg Valid recon Loss: 0.0497\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0435, recon=0.0434, kl=0.2832, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0520 (Recon: 0.0520, KL: 0.6569, Current Beta: 0.0000) | Avg Valid Loss: 0.0474 | Avg Valid recon Loss: 0.0474\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.1241, recon=0.1241, kl=0.0358, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0481 (Recon: 0.0481, KL: 0.1285, Current Beta: 0.0001) | Avg Valid Loss: 0.0460 | Avg Valid recon Loss: 0.0460\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0691, recon=0.0691, kl=0.0073, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0472 (Recon: 0.0472, KL: 0.0106, Current Beta: 0.0003) | Avg Valid Loss: 0.0457 | Avg Valid recon Loss: 0.0457\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0380, recon=0.0380, kl=0.0010, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0453 (Recon: 0.0453, KL: 0.0023, Current Beta: 0.0008) | Avg Valid Loss: 0.0420 | Avg Valid recon Loss: 0.0420\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0424, recon=0.0424, kl=0.0006, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0435 (Recon: 0.0435, KL: 0.0009, Current Beta: 0.0018) | Avg Valid Loss: 0.0395 | Avg Valid recon Loss: 0.0395\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0499, recon=0.0499, kl=0.0002, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0437 (Recon: 0.0437, KL: 0.0005, Current Beta: 0.0038) | Avg Valid Loss: 0.0405 | Avg Valid recon Loss: 0.0405\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0448, recon=0.0448, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0417, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0434, recon=0.0434, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0401 (Recon: 0.0401, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0360 | Avg Valid recon Loss: 0.0360\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0284, recon=0.0284, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0390, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0365 | Avg Valid recon Loss: 0.0365\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0378, recon=0.0378, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0393 (Recon: 0.0393, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0370 | Avg Valid recon Loss: 0.0370\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0290, recon=0.0290, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0386 (Recon: 0.0386, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0303, recon=0.0303, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0370 (Recon: 0.0370, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0347\n",
      "\n",
      "[VRAE Run 319/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3428, recon=0.3428, kl=9.2005, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.5255 (Recon: 0.5255, KL: 2.9507, Current Beta: 0.0000) | Avg Valid Loss: 0.3020 | Avg Valid recon Loss: 0.3020\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.1700, recon=0.1700, kl=21.7253, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2420 (Recon: 0.2420, KL: 18.0343, Current Beta: 0.0000) | Avg Valid Loss: 0.1743 | Avg Valid recon Loss: 0.1743\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1884, recon=0.1884, kl=27.0751, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1686 (Recon: 0.1686, KL: 25.4316, Current Beta: 0.0000) | Avg Valid Loss: 0.1340 | Avg Valid recon Loss: 0.1340\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1146, recon=0.1146, kl=29.1843, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1515 (Recon: 0.1515, KL: 28.9441, Current Beta: 0.0000) | Avg Valid Loss: 0.1160 | Avg Valid recon Loss: 0.1160\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0947, recon=0.0947, kl=21.4191, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1333 (Recon: 0.1332, KL: 25.7020, Current Beta: 0.0000) | Avg Valid Loss: 0.1024 | Avg Valid recon Loss: 0.1023\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1019, recon=0.1019, kl=7.6090, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1182 (Recon: 0.1181, KL: 11.0364, Current Beta: 0.0000) | Avg Valid Loss: 0.0942 | Avg Valid recon Loss: 0.0942\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.2743, recon=0.2743, kl=2.8480, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1062 (Recon: 0.1062, KL: 3.7800, Current Beta: 0.0000) | Avg Valid Loss: 0.0882 | Avg Valid recon Loss: 0.0882\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.1045, recon=0.1045, kl=0.5231, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0998 (Recon: 0.0998, KL: 0.9810, Current Beta: 0.0000) | Avg Valid Loss: 0.0814 | Avg Valid recon Loss: 0.0814\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.1092, recon=0.1092, kl=0.1234, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0937 (Recon: 0.0937, KL: 0.2555, Current Beta: 0.0000) | Avg Valid Loss: 0.0778 | Avg Valid recon Loss: 0.0778\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0716, recon=0.0716, kl=0.0106, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0879 (Recon: 0.0879, KL: 0.0422, Current Beta: 0.0001) | Avg Valid Loss: 0.0749 | Avg Valid recon Loss: 0.0749\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.1140, recon=0.1140, kl=0.0043, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0828 (Recon: 0.0828, KL: 0.0052, Current Beta: 0.0003) | Avg Valid Loss: 0.0725 | Avg Valid recon Loss: 0.0725\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0566, recon=0.0566, kl=0.0006, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0797 (Recon: 0.0797, KL: 0.0010, Current Beta: 0.0008) | Avg Valid Loss: 0.0670 | Avg Valid recon Loss: 0.0670\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0784, recon=0.0784, kl=0.0001, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0759 (Recon: 0.0759, KL: 0.0002, Current Beta: 0.0018) | Avg Valid Loss: 0.0650 | Avg Valid recon Loss: 0.0650\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0806, recon=0.0806, kl=0.0000, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0733 (Recon: 0.0733, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0629 | Avg Valid recon Loss: 0.0629\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0618, recon=0.0618, kl=0.0000, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0708 (Recon: 0.0708, KL: 0.0000, Current Beta: 0.0062) | Avg Valid Loss: 0.0611 | Avg Valid recon Loss: 0.0611\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0656, recon=0.0656, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0683 (Recon: 0.0683, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0594 | Avg Valid recon Loss: 0.0594\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0478, recon=0.0478, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0686 (Recon: 0.0686, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0583 | Avg Valid recon Loss: 0.0583\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0708, recon=0.0708, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0638 (Recon: 0.0638, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0567 | Avg Valid recon Loss: 0.0567\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0597, recon=0.0597, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0614 (Recon: 0.0614, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0555 | Avg Valid recon Loss: 0.0555\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0576, recon=0.0576, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0615 (Recon: 0.0615, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0540 | Avg Valid recon Loss: 0.0540\n",
      "\n",
      "[VRAE Run 320/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1304, recon=0.1304, kl=16.7539, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2697 (Recon: 0.2697, KL: 8.5791, Current Beta: 0.0000) | Avg Valid Loss: 0.1165 | Avg Valid recon Loss: 0.1165\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0669, recon=0.0669, kl=32.1977, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1116 (Recon: 0.1116, KL: 27.0515, Current Beta: 0.0000) | Avg Valid Loss: 0.0787 | Avg Valid recon Loss: 0.0787\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0766, recon=0.0766, kl=50.6098, beta=0.0000\n",
      "  â†’ Avg Train Loss: 1.1515 (Recon: 1.1515, KL: 59.5964, Current Beta: 0.0000) | Avg Valid Loss: 0.0738 | Avg Valid recon Loss: 0.0738\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0553, recon=0.0553, kl=92.0192, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0696 (Recon: 0.0695, KL: 91.2604, Current Beta: 0.0000) | Avg Valid Loss: 0.0568 | Avg Valid recon Loss: 0.0567\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0638, recon=0.0638, kl=78.3504, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0594 (Recon: 0.0594, KL: 83.3091, Current Beta: 0.0000) | Avg Valid Loss: 0.0527 | Avg Valid recon Loss: 0.0527\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0439, recon=0.0438, kl=67.6675, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0545 (Recon: 0.0544, KL: 71.5982, Current Beta: 0.0000) | Avg Valid Loss: 0.0486 | Avg Valid recon Loss: 0.0484\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0440, recon=0.0436, kl=57.5983, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0493 (Recon: 0.0490, KL: 61.5061, Current Beta: 0.0000) | Avg Valid Loss: 0.0493 | Avg Valid recon Loss: 0.0490\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0629, recon=0.0622, kl=48.4301, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0479 (Recon: 0.0471, KL: 52.1456, Current Beta: 0.0000) | Avg Valid Loss: 0.0430 | Avg Valid recon Loss: 0.0423\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0500, recon=0.0485, kl=35.9823, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0455 (Recon: 0.0438, KL: 41.1480, Current Beta: 0.0000) | Avg Valid Loss: 0.0413 | Avg Valid recon Loss: 0.0399\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0375, recon=0.0366, kl=8.4058, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0401, KL: 20.4466, Current Beta: 0.0001) | Avg Valid Loss: 0.0379 | Avg Valid recon Loss: 0.0373\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0324, recon=0.0322, kl=0.4126, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0390 (Recon: 0.0386, KL: 1.4183, Current Beta: 0.0003) | Avg Valid Loss: 0.0361 | Avg Valid recon Loss: 0.0360\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0254, recon=0.0254, kl=0.0276, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0379 (Recon: 0.0378, KL: 0.1084, Current Beta: 0.0008) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0310, recon=0.0310, kl=0.0064, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0363 (Recon: 0.0362, KL: 0.0157, Current Beta: 0.0018) | Avg Valid Loss: 0.0340 | Avg Valid recon Loss: 0.0340\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0299, recon=0.0299, kl=0.0030, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0361 (Recon: 0.0361, KL: 0.0065, Current Beta: 0.0038) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0333\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0316, recon=0.0316, kl=0.0022, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0337 (Recon: 0.0337, KL: 0.0037, Current Beta: 0.0062) | Avg Valid Loss: 0.0311 | Avg Valid recon Loss: 0.0311\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0289, recon=0.0288, kl=0.0050, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0341 (Recon: 0.0340, KL: 0.0101, Current Beta: 0.0100) | Avg Valid Loss: 0.0317 | Avg Valid recon Loss: 0.0316\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0322, recon=0.0322, kl=0.0012, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0350 (Recon: 0.0350, KL: 0.0022, Current Beta: 0.0100) | Avg Valid Loss: 0.0347 | Avg Valid recon Loss: 0.0347\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0589, recon=0.0589, kl=0.0006, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0348 (Recon: 0.0348, KL: 0.0011, Current Beta: 0.0100) | Avg Valid Loss: 0.0318 | Avg Valid recon Loss: 0.0318\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0296, recon=0.0296, kl=0.0003, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0339 (Recon: 0.0339, KL: 0.0008, Current Beta: 0.0100) | Avg Valid Loss: 0.0321 | Avg Valid recon Loss: 0.0320\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0268, recon=0.0268, kl=0.0021, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0349 (Recon: 0.0348, KL: 0.0007, Current Beta: 0.0100) | Avg Valid Loss: 0.0339 | Avg Valid recon Loss: 0.0339\n",
      "\n",
      "[VRAE Run 321/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.3609, recon=0.3609, kl=11.3820, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4989 (Recon: 0.4989, KL: 3.4383, Current Beta: 0.0000) | Avg Valid Loss: 0.2874 | Avg Valid recon Loss: 0.2874\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2918, recon=0.2918, kl=49.3353, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2368 (Recon: 0.2368, KL: 36.0515, Current Beta: 0.0000) | Avg Valid Loss: 0.1691 | Avg Valid recon Loss: 0.1691\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1528, recon=0.1528, kl=66.0719, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1722 (Recon: 0.1722, KL: 61.2066, Current Beta: 0.0000) | Avg Valid Loss: 0.1346 | Avg Valid recon Loss: 0.1346\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1122, recon=0.1122, kl=62.7179, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1522 (Recon: 0.1522, KL: 66.2407, Current Beta: 0.0000) | Avg Valid Loss: 0.1146 | Avg Valid recon Loss: 0.1146\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1357, recon=0.1357, kl=31.4224, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1354 (Recon: 0.1354, KL: 44.4624, Current Beta: 0.0000) | Avg Valid Loss: 0.1042 | Avg Valid recon Loss: 0.1042\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1323, recon=0.1323, kl=11.2479, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1218 (Recon: 0.1217, KL: 16.5448, Current Beta: 0.0000) | Avg Valid Loss: 0.0948 | Avg Valid recon Loss: 0.0948\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.1838, recon=0.1838, kl=3.4620, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1111 (Recon: 0.1110, KL: 5.7618, Current Beta: 0.0000) | Avg Valid Loss: 0.0888 | Avg Valid recon Loss: 0.0888\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0854, recon=0.0854, kl=1.3593, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1018 (Recon: 0.1017, KL: 1.8202, Current Beta: 0.0000) | Avg Valid Loss: 0.0831 | Avg Valid recon Loss: 0.0831\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0700, recon=0.0700, kl=0.4874, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0945 (Recon: 0.0945, KL: 0.4854, Current Beta: 0.0000) | Avg Valid Loss: 0.0783 | Avg Valid recon Loss: 0.0783\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0750, recon=0.0750, kl=0.0685, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0898 (Recon: 0.0898, KL: 0.0887, Current Beta: 0.0001) | Avg Valid Loss: 0.0748 | Avg Valid recon Loss: 0.0748\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0661, recon=0.0661, kl=0.0092, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0838 (Recon: 0.0838, KL: 0.0129, Current Beta: 0.0003) | Avg Valid Loss: 0.0711 | Avg Valid recon Loss: 0.0711\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0651, recon=0.0651, kl=0.0020, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0789 (Recon: 0.0789, KL: 0.0023, Current Beta: 0.0008) | Avg Valid Loss: 0.0679 | Avg Valid recon Loss: 0.0679\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0514, recon=0.0514, kl=0.0002, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0767 (Recon: 0.0767, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0665 | Avg Valid recon Loss: 0.0665\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0898, recon=0.0898, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0727 (Recon: 0.0727, KL: 0.0001, Current Beta: 0.0038) | Avg Valid Loss: 0.0628 | Avg Valid recon Loss: 0.0628\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0551, recon=0.0551, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0639 (Recon: 0.0639, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0624 | Avg Valid recon Loss: 0.0624\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0510, recon=0.0510, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0681 (Recon: 0.0681, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0601 | Avg Valid recon Loss: 0.0601\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0596, recon=0.0596, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0662 (Recon: 0.0662, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0619 | Avg Valid recon Loss: 0.0619\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0685, recon=0.0685, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0658 (Recon: 0.0658, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0569 | Avg Valid recon Loss: 0.0569\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0390, recon=0.0390, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0628 (Recon: 0.0628, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0565 | Avg Valid recon Loss: 0.0565\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0580, recon=0.0580, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0613 (Recon: 0.0613, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0568 | Avg Valid recon Loss: 0.0568\n",
      "\n",
      "[VRAE Run 322/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1041, recon=0.1041, kl=47.2118, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2754 (Recon: 0.2754, KL: 28.3952, Current Beta: 0.0000) | Avg Valid Loss: 0.1124 | Avg Valid recon Loss: 0.1124\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0696, recon=0.0696, kl=59.0516, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1063 (Recon: 0.1063, KL: 52.4622, Current Beta: 0.0000) | Avg Valid Loss: 0.0773 | Avg Valid recon Loss: 0.0773\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0510, recon=0.0510, kl=51.3762, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0802 (Recon: 0.0802, KL: 53.6453, Current Beta: 0.0000) | Avg Valid Loss: 0.0633 | Avg Valid recon Loss: 0.0633\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0413, recon=0.0413, kl=56.1082, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0657 (Recon: 0.0657, KL: 52.7537, Current Beta: 0.0000) | Avg Valid Loss: 0.0554 | Avg Valid recon Loss: 0.0554\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0488, recon=0.0488, kl=22.5265, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0568 (Recon: 0.0568, KL: 34.5970, Current Beta: 0.0000) | Avg Valid Loss: 0.0491 | Avg Valid recon Loss: 0.0490\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0420, recon=0.0420, kl=15.2205, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0538 (Recon: 0.0538, KL: 18.9570, Current Beta: 0.0000) | Avg Valid Loss: 0.0455 | Avg Valid recon Loss: 0.0454\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0470, recon=0.0469, kl=6.6133, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0463, KL: 7.8165, Current Beta: 0.0000) | Avg Valid Loss: 0.0407 | Avg Valid recon Loss: 0.0406\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0708, recon=0.0708, kl=1.9916, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0444 (Recon: 0.0444, KL: 2.4584, Current Beta: 0.0000) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0402\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0400, recon=0.0400, kl=0.2553, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0405 (Recon: 0.0405, KL: 0.2801, Current Beta: 0.0000) | Avg Valid Loss: 0.0368 | Avg Valid recon Loss: 0.0368\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0921, recon=0.0921, kl=0.0203, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0403 (Recon: 0.0403, KL: 0.0564, Current Beta: 0.0001) | Avg Valid Loss: 0.0364 | Avg Valid recon Loss: 0.0364\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0299, recon=0.0299, kl=0.0082, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0384 (Recon: 0.0384, KL: 0.0078, Current Beta: 0.0003) | Avg Valid Loss: 0.0344 | Avg Valid recon Loss: 0.0344\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0466, recon=0.0466, kl=0.0012, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0368 (Recon: 0.0368, KL: 0.0031, Current Beta: 0.0008) | Avg Valid Loss: 0.0332 | Avg Valid recon Loss: 0.0332\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0333, recon=0.0333, kl=0.0006, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0363 (Recon: 0.0363, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0333 | Avg Valid recon Loss: 0.0333\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0732, recon=0.0732, kl=0.0004, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0341 (Recon: 0.0341, KL: 0.0004, Current Beta: 0.0038) | Avg Valid Loss: 0.0304 | Avg Valid recon Loss: 0.0303\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0325, recon=0.0325, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0343 (Recon: 0.0343, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0314 | Avg Valid recon Loss: 0.0314\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0233, recon=0.0233, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0319 (Recon: 0.0319, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0298 | Avg Valid recon Loss: 0.0298\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0504, recon=0.0504, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0359 (Recon: 0.0359, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0335 | Avg Valid recon Loss: 0.0335\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0374, recon=0.0374, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0343 (Recon: 0.0343, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0334 | Avg Valid recon Loss: 0.0334\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0503, recon=0.0503, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0371 (Recon: 0.0371, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0352 | Avg Valid recon Loss: 0.0352\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0283, recon=0.0283, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0334 (Recon: 0.0334, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0294 | Avg Valid recon Loss: 0.0293\n",
      "\n",
      "[VRAE Run 323/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.001}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.2576, recon=0.2576, kl=29.9312, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.4995 (Recon: 0.4995, KL: 8.7385, Current Beta: 0.0000) | Avg Valid Loss: 0.2920 | Avg Valid recon Loss: 0.2920\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.2063, recon=0.2063, kl=93.0818, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2396 (Recon: 0.2396, KL: 73.4741, Current Beta: 0.0000) | Avg Valid Loss: 0.1729 | Avg Valid recon Loss: 0.1729\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.1340, recon=0.1340, kl=114.2051, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1781 (Recon: 0.1780, KL: 108.5784, Current Beta: 0.0000) | Avg Valid Loss: 0.1316 | Avg Valid recon Loss: 0.1316\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.1168, recon=0.1168, kl=99.6831, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1501 (Recon: 0.1501, KL: 107.4810, Current Beta: 0.0000) | Avg Valid Loss: 0.1146 | Avg Valid recon Loss: 0.1146\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.1171, recon=0.1171, kl=49.9897, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1309 (Recon: 0.1308, KL: 70.5913, Current Beta: 0.0000) | Avg Valid Loss: 0.1004 | Avg Valid recon Loss: 0.1004\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.1028, recon=0.1028, kl=16.1243, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1166 (Recon: 0.1166, KL: 26.5561, Current Beta: 0.0000) | Avg Valid Loss: 0.0956 | Avg Valid recon Loss: 0.0955\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0740, recon=0.0740, kl=4.5784, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1051 (Recon: 0.1050, KL: 8.6253, Current Beta: 0.0000) | Avg Valid Loss: 0.0853 | Avg Valid recon Loss: 0.0852\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0818, recon=0.0818, kl=1.6089, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0971 (Recon: 0.0971, KL: 2.1085, Current Beta: 0.0000) | Avg Valid Loss: 0.0791 | Avg Valid recon Loss: 0.0791\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0983, recon=0.0983, kl=0.3895, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0894 (Recon: 0.0894, KL: 0.5169, Current Beta: 0.0000) | Avg Valid Loss: 0.0752 | Avg Valid recon Loss: 0.0752\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0796, recon=0.0796, kl=0.0655, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0850 (Recon: 0.0850, KL: 0.0883, Current Beta: 0.0001) | Avg Valid Loss: 0.0715 | Avg Valid recon Loss: 0.0715\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0672, recon=0.0672, kl=0.0115, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0780 (Recon: 0.0780, KL: 0.0133, Current Beta: 0.0003) | Avg Valid Loss: 0.0690 | Avg Valid recon Loss: 0.0690\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0624, recon=0.0624, kl=0.0010, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0771 (Recon: 0.0771, KL: 0.0020, Current Beta: 0.0008) | Avg Valid Loss: 0.0662 | Avg Valid recon Loss: 0.0662\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0566, recon=0.0566, kl=0.0004, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0738 (Recon: 0.0738, KL: 0.0005, Current Beta: 0.0018) | Avg Valid Loss: 0.0637 | Avg Valid recon Loss: 0.0637\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0506, recon=0.0506, kl=0.0003, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0716 (Recon: 0.0716, KL: 0.0005, Current Beta: 0.0038) | Avg Valid Loss: 0.0616 | Avg Valid recon Loss: 0.0616\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.1172, recon=0.1172, kl=0.0002, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0689 (Recon: 0.0689, KL: 0.0004, Current Beta: 0.0062) | Avg Valid Loss: 0.0598 | Avg Valid recon Loss: 0.0598\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0620, recon=0.0620, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0673 (Recon: 0.0673, KL: 0.0002, Current Beta: 0.0100) | Avg Valid Loss: 0.0579 | Avg Valid recon Loss: 0.0579\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0616, recon=0.0616, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0591 (Recon: 0.0591, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0568 | Avg Valid recon Loss: 0.0568\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0532, recon=0.0532, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0625 (Recon: 0.0625, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0551 | Avg Valid recon Loss: 0.0551\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0436, recon=0.0436, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0618 (Recon: 0.0618, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0601 | Avg Valid recon Loss: 0.0601\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0528, recon=0.0528, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0594 (Recon: 0.0594, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0541 | Avg Valid recon Loss: 0.0541\n",
      "\n",
      "[VRAE Run 324/324] Training with params: {'batch_size': 256, 'beta': 0.01, 'hidden_layer_depth': 2, 'hidden_size': 128, 'latent_length': 64, 'learning_rate': 0.01}\n",
      "Epoch 1/20\n",
      "Batch 20, loss=0.1378, recon=0.1378, kl=81.4505, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.2681 (Recon: 0.2681, KL: 40.3839, Current Beta: 0.0000) | Avg Valid Loss: 0.1167 | Avg Valid recon Loss: 0.1166\n",
      "Epoch 2/20\n",
      "Batch 20, loss=0.0781, recon=0.0781, kl=119.7847, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1054 (Recon: 0.1054, KL: 113.0864, Current Beta: 0.0000) | Avg Valid Loss: 0.0755 | Avg Valid recon Loss: 0.0755\n",
      "Epoch 3/20\n",
      "Batch 20, loss=0.0678, recon=0.0678, kl=96.7894, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0827 (Recon: 0.0827, KL: 122.2057, Current Beta: 0.0000) | Avg Valid Loss: 0.0647 | Avg Valid recon Loss: 0.0647\n",
      "Epoch 4/20\n",
      "Batch 20, loss=0.0463, recon=0.0463, kl=101.8780, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0662 (Recon: 0.0662, KL: 95.7594, Current Beta: 0.0000) | Avg Valid Loss: 0.0557 | Avg Valid recon Loss: 0.0557\n",
      "Epoch 5/20\n",
      "Batch 20, loss=0.0618, recon=0.0618, kl=54.8046, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0588 (Recon: 0.0588, KL: 66.3760, Current Beta: 0.0000) | Avg Valid Loss: 0.0483 | Avg Valid recon Loss: 0.0482\n",
      "Epoch 6/20\n",
      "Batch 20, loss=0.0502, recon=0.0501, kl=31.3143, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0525 (Recon: 0.0524, KL: 39.3170, Current Beta: 0.0000) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0457\n",
      "Epoch 7/20\n",
      "Batch 20, loss=0.0408, recon=0.0407, kl=14.3592, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0482 (Recon: 0.0481, KL: 17.9794, Current Beta: 0.0000) | Avg Valid Loss: 0.0417 | Avg Valid recon Loss: 0.0417\n",
      "Epoch 8/20\n",
      "Batch 20, loss=0.0411, recon=0.0410, kl=4.7041, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0445 (Recon: 0.0444, KL: 5.2727, Current Beta: 0.0000) | Avg Valid Loss: 0.0398 | Avg Valid recon Loss: 0.0398\n",
      "Epoch 9/20\n",
      "Batch 20, loss=0.0511, recon=0.0511, kl=0.7644, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0424 (Recon: 0.0424, KL: 1.2540, Current Beta: 0.0000) | Avg Valid Loss: 0.0401 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 10/20\n",
      "Batch 20, loss=0.0476, recon=0.0476, kl=0.0736, beta=0.0001\n",
      "  â†’ Avg Train Loss: 0.0417 (Recon: 0.0417, KL: 0.1630, Current Beta: 0.0001) | Avg Valid Loss: 0.0371 | Avg Valid recon Loss: 0.0371\n",
      "Epoch 11/20\n",
      "Batch 20, loss=0.0341, recon=0.0341, kl=0.0106, beta=0.0003\n",
      "  â†’ Avg Train Loss: 0.0384 (Recon: 0.0384, KL: 0.0256, Current Beta: 0.0003) | Avg Valid Loss: 0.0365 | Avg Valid recon Loss: 0.0365\n",
      "Epoch 12/20\n",
      "Batch 20, loss=0.0345, recon=0.0345, kl=0.0037, beta=0.0008\n",
      "  â†’ Avg Train Loss: 0.0406 (Recon: 0.0406, KL: 0.0040, Current Beta: 0.0008) | Avg Valid Loss: 0.0390 | Avg Valid recon Loss: 0.0390\n",
      "Epoch 13/20\n",
      "Batch 20, loss=0.0440, recon=0.0440, kl=0.0009, beta=0.0018\n",
      "  â†’ Avg Train Loss: 0.0365 (Recon: 0.0365, KL: 0.0013, Current Beta: 0.0018) | Avg Valid Loss: 0.0333 | Avg Valid recon Loss: 0.0333\n",
      "Epoch 14/20\n",
      "Batch 20, loss=0.0292, recon=0.0292, kl=0.0001, beta=0.0038\n",
      "  â†’ Avg Train Loss: 0.0349 (Recon: 0.0349, KL: 0.0003, Current Beta: 0.0038) | Avg Valid Loss: 0.0322 | Avg Valid recon Loss: 0.0322\n",
      "Epoch 15/20\n",
      "Batch 20, loss=0.0325, recon=0.0325, kl=0.0001, beta=0.0062\n",
      "  â†’ Avg Train Loss: 0.0339 (Recon: 0.0339, KL: 0.0001, Current Beta: 0.0062) | Avg Valid Loss: 0.0312 | Avg Valid recon Loss: 0.0312\n",
      "Epoch 16/20\n",
      "Batch 20, loss=0.0268, recon=0.0268, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0337 (Recon: 0.0337, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0316 | Avg Valid recon Loss: 0.0316\n",
      "Epoch 17/20\n",
      "Batch 20, loss=0.0327, recon=0.0327, kl=0.0001, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0337 (Recon: 0.0337, KL: 0.0001, Current Beta: 0.0100) | Avg Valid Loss: 0.0326 | Avg Valid recon Loss: 0.0326\n",
      "Epoch 18/20\n",
      "Batch 20, loss=0.0331, recon=0.0331, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0342 (Recon: 0.0342, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0307 | Avg Valid recon Loss: 0.0307\n",
      "Epoch 19/20\n",
      "Batch 20, loss=0.0615, recon=0.0615, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0318 (Recon: 0.0318, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0289 | Avg Valid recon Loss: 0.0289\n",
      "Epoch 20/20\n",
      "Batch 20, loss=0.0344, recon=0.0344, kl=0.0000, beta=0.0100\n",
      "  â†’ Avg Train Loss: 0.0323 (Recon: 0.0323, KL: 0.0000, Current Beta: 0.0100) | Avg Valid Loss: 0.0311 | Avg Valid recon Loss: 0.0311\n",
      "\n",
      "==================================================\n",
      "======= TUNING COMPLETE: REPORTING RESULTS =======\n",
      "==================================================\n",
      "\n",
      "--- Hyperparameter Tuning Results Summary ---\n",
      "     batch_size    beta  hidden_layer_depth  hidden_size  latent_length  \\\n",
      "70           32  0.0010                   2          128             64   \n",
      "195          64  0.0100                   1          128             32   \n",
      "68           32  0.0010                   2          128             32   \n",
      "66           32  0.0010                   2          128             16   \n",
      "104          32  0.0100                   2          128             32   \n",
      "..          ...     ...                 ...          ...            ...   \n",
      "143          64  0.0001                   2          128             64   \n",
      "161          64  0.0010                   1          128             64   \n",
      "179          64  0.0010                   2          128             64   \n",
      "197          64  0.0100                   1          128             64   \n",
      "211          64  0.0100                   2          128             16   \n",
      "\n",
      "     learning_rate  final_train_loss  final_valid_loss  final_recon_loss  \\\n",
      "70           0.001          0.029578          0.025697          0.029577   \n",
      "195          0.010          0.029576          0.025802          0.029570   \n",
      "68           0.001          0.029973          0.025978          0.029973   \n",
      "66           0.001          0.030276          0.026258          0.030275   \n",
      "104          0.001          0.029985          0.026354          0.029985   \n",
      "..             ...               ...               ...               ...   \n",
      "143          0.010               NaN               NaN               NaN   \n",
      "161          0.010               NaN               NaN               NaN   \n",
      "179          0.010               NaN               NaN               NaN   \n",
      "197          0.010               NaN               NaN               NaN   \n",
      "211          0.010               NaN               NaN               NaN   \n",
      "\n",
      "     final_kl_loss  runtime_seconds  \n",
      "70        0.000696       191.722842  \n",
      "195       0.000521        62.380979  \n",
      "68        0.000298       192.748750  \n",
      "66        0.001131       192.709885  \n",
      "104       0.000023       193.382125  \n",
      "..             ...              ...  \n",
      "143            NaN       114.419286  \n",
      "161            NaN        62.355384  \n",
      "179            NaN       115.292812  \n",
      "197            NaN        61.957747  \n",
      "211            NaN       114.960088  \n",
      "\n",
      "[324 rows x 11 columns]\n",
      "\n",
      "Full results table saved to: ./ecg_model_logs\\vrae_tuning_results.csv\n",
      "\n",
      "--- Best Performing Model ---\n",
      "Validation Loss: 0.0257\n",
      "Parameters:\n",
      "{\n",
      "    \"batch_size\": 32,\n",
      "    \"beta\": 0.001,\n",
      "    \"hidden_layer_depth\": 2,\n",
      "    \"hidden_size\": 128,\n",
      "    \"latent_length\": 64,\n",
      "    \"learning_rate\": 0.001\n",
      "}\n",
      "\n",
      "Best parameters saved to: ./ecg_model_logs\\best_vrae_params.json\n",
      "Best model state dictionary saved to: ./ecg_model_logs\\best_vrae_model.pth\n",
      "Loss curve plot for best model saved to: ./ecg_model_logs\\best_vrae_loss_curves.png\n",
      "Results heatmap saved to: ./ecg_model_logs\\vrae_loss_heatmap.png\n",
      "\n",
      "==================================================\n",
      "================ SCRIPT FINISHED =================\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import ParameterGrid, train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Setup\n",
    "output_dir = './ecg_model_logs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "log_path = os.path.join(output_dir, 'training_log.txt')\n",
    "\n",
    "# Clear previous log file\n",
    "with open(log_path, 'w') as f:\n",
    "    f.write(\"--- Starting Hyperparameter Tuning Log ---\\n\")\n",
    "\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Log file: {log_path}\")\n",
    "\n",
    "# Load and Split Data\n",
    "x_train, x_val = train_test_split(x_ecg, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(x_train).float())\n",
    "valid_dataset = TensorDataset(torch.from_numpy(x_val).float())\n",
    "complete_dataset = TensorDataset(torch.from_numpy(x_ecg).float())\n",
    "\n",
    "print(f\"Data split: {len(train_dataset)} training samples, {len(valid_dataset)} validation samples.\")\n",
    "\n",
    "\n",
    "# Search space for VRAE\n",
    "param_grid_vrae = {\n",
    "    'hidden_size': [32, 64, 128],\n",
    "    'latent_length': [16, 32, 64],\n",
    "    'batch_size': [32, 64, 256],\n",
    "    'learning_rate': [1e-3, 1e-2],\n",
    "    'beta': [0.0001, 0.001, 0.01],\n",
    "    'hidden_layer_depth': [1,2],\n",
    "}\n",
    "\n",
    "# Fixed Parameters\n",
    "sequence_length = x_train.shape[1]\n",
    "number_of_features = x_train.shape[2]\n",
    "\n",
    "n_epochs = 20\n",
    "optimizer = 'Adam'\n",
    "cuda = torch.cuda.is_available()\n",
    "print_every = 20\n",
    "clip = True\n",
    "dropout = 0\n",
    "max_grad_norm = 5\n",
    "loss = 'MSELoss'\n",
    "block = 'LSTM'\n",
    "\n",
    "print(f\"\\nCUDA available: {cuda}\")\n",
    "\n",
    "# VRAE Hyperparameter Tuning\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" VRAE HYPERPARAMETER TUNING \".center(50, \"=\"))\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_vrae_valid_loss = float('inf')\n",
    "best_vrae_params = None\n",
    "best_vrae_losses = {}\n",
    "best_vrae_model_path = os.path.join(output_dir, 'best_vrae_model.pth')\n",
    "\n",
    "# List to store results from each run for final reporting\n",
    "results_list = []\n",
    "\n",
    "for i, params in enumerate(ParameterGrid(param_grid_vrae)):\n",
    "    print(f\"\\n[VRAE Run {i+1}/{len(ParameterGrid(param_grid_vrae))}] Training with params: {params}\")\n",
    "    with open(log_path, 'a') as f:\n",
    "        f.write(f\"\\n=== [VRAE] Training with params: {params} ===\\n\")\n",
    "\n",
    "    # VRAE definition\n",
    "    vrae = VRAE(\n",
    "        sequence_length=sequence_length,\n",
    "        number_of_features=number_of_features,\n",
    "        hidden_size=params['hidden_size'],\n",
    "        hidden_layer_depth=params['hidden_layer_depth'],\n",
    "        latent_length=params['latent_length'],\n",
    "        batch_size=params['batch_size'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        n_epochs=n_epochs,\n",
    "        dropout_rate=dropout,\n",
    "        optimizer=optimizer,\n",
    "        cuda=cuda,\n",
    "        print_every=print_every,\n",
    "        clip=clip,\n",
    "        max_grad_norm=max_grad_norm,\n",
    "        loss=loss,\n",
    "        block=block,\n",
    "        dload=output_dir,\n",
    "        beta=params['beta'],\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    vrae.fit(train_dataset, valid_dataset=valid_dataset)\n",
    "    runtime = time.time() - start_time\n",
    "\n",
    "    # Get final losses, handle cases where training might fail\n",
    "    final_valid_loss = vrae.valid_losses[-1] if vrae.valid_losses else float('inf')\n",
    "    final_train_loss = vrae.train_losses[-1] if vrae.train_losses else float('inf')\n",
    "    final_recon_loss = vrae.train_recon_losses[-1] if vrae.train_recon_losses else float('inf')\n",
    "    final_kl_loss = vrae.train_kl_losses[-1] if vrae.train_kl_losses else float('inf')\n",
    "\n",
    "    with open(log_path, 'a') as f:\n",
    "        f.write(f\"[VRAE] Final Train Loss: {final_train_loss:.4f} (Recon: {final_recon_loss:.4f}, KL: {final_kl_loss:.4f})\\n\")\n",
    "        f.write(f\"[VRAE] Final Validation Loss: {final_valid_loss:.4f}\\n\")\n",
    "        f.write(f\"[VRAE] Training time: {runtime:.2f} seconds\\n\")\n",
    "\n",
    "    # Store results for this run\n",
    "    run_results = params.copy()\n",
    "    run_results['final_train_loss'] = final_train_loss\n",
    "    run_results['final_valid_loss'] = final_valid_loss\n",
    "    run_results['final_recon_loss'] = final_recon_loss\n",
    "    run_results['final_kl_loss'] = final_kl_loss\n",
    "    run_results['runtime_seconds'] = runtime\n",
    "    results_list.append(run_results)\n",
    "\n",
    "    if final_valid_loss < best_vrae_valid_loss:\n",
    "        best_vrae_valid_loss = final_valid_loss\n",
    "        best_vrae_params = params\n",
    "        best_vrae_losses = {\n",
    "            'train': vrae.train_losses,\n",
    "            'recon': vrae.train_recon_losses,\n",
    "            'kl': vrae.train_kl_losses,\n",
    "            'valid': vrae.valid_losses\n",
    "        }\n",
    "        # Save the model state dictionary\n",
    "        torch.save(vrae.state_dict(), best_vrae_model_path)\n",
    "        print(f\" New best VRAE model found with validation loss: {best_vrae_valid_loss:.4f}\")\n",
    "        print(f\"   Model saved to {best_vrae_model_path}\")\n",
    "\n",
    "\n",
    "# Reporting and Visualization\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" TUNING COMPLETE: REPORTING RESULTS \".center(50, \"=\"))\n",
    "print(\"=\"*50)\n",
    "\n",
    "if not results_list:\n",
    "    print(\"No training runs were completed. Exiting.\")\n",
    "else:\n",
    "    # --- Create and save results table ---\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    results_df = results_df.sort_values(by='final_valid_loss', ascending=True)\n",
    "    results_csv_path = os.path.join(output_dir, 'vrae_tuning_results.csv')\n",
    "    results_df.to_csv(results_csv_path, index=False)\n",
    "\n",
    "    print(\"\\n--- Hyperparameter Tuning Results Summary ---\")\n",
    "    print(results_df)\n",
    "    print(f\"\\nFull results table saved to: {results_csv_path}\")\n",
    "\n",
    "    # --- Save the best parameters to a JSON file ---\n",
    "    best_params_path = os.path.join(output_dir, 'best_vrae_params.json')\n",
    "    with open(best_params_path, 'w') as f:\n",
    "        json.dump(best_vrae_params, f, indent=4)\n",
    "\n",
    "    print(\"\\n--- Best Performing Model ---\")\n",
    "    print(f\"Validation Loss: {best_vrae_valid_loss:.4f}\")\n",
    "    print(\"Parameters:\")\n",
    "    print(json.dumps(best_vrae_params, indent=4))\n",
    "    print(f\"\\nBest parameters saved to: {best_params_path}\")\n",
    "    print(f\"Best model state dictionary saved to: {best_vrae_model_path}\")\n",
    "\n",
    "    # --- Plot and save loss curves for the best model ---\n",
    "    if best_vrae_losses:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(best_vrae_losses['train'], label='Training Loss')\n",
    "        plt.plot(best_vrae_losses['valid'], label='Validation Loss', linestyle='--')\n",
    "        plt.title(f'Best VRAE Model: Training and Validation Loss\\nParams: {str(best_vrae_params)}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plot_path = os.path.join(output_dir, 'best_vrae_loss_curves.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Loss curve plot for best model saved to: {plot_path}\")\n",
    "\n",
    "    # --- Create and save a heatmap of results ---\n",
    "    # This is most effective for visualizing two changing parameters against the loss.\n",
    "    # Here, we'll visualize hidden_size vs. learning_rate.\n",
    "    # We will average the results for other changing params (like beta, latent_length)\n",
    "    try:\n",
    "        heatmap_data = results_df.pivot_table(\n",
    "            index='hidden_size',\n",
    "            columns='learning_rate',\n",
    "            values='final_valid_loss',\n",
    "            aggfunc='mean' # Use mean if multiple runs have the same hs/lr\n",
    "        )\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(heatmap_data, annot=True, fmt=\".4f\", cmap=\"viridis_r\", cbar_kws={'label': 'Mean Final Validation Loss'})\n",
    "        plt.title('Validation Loss Heatmap: Hidden Size vs. Learning Rate')\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel('Hidden Size')\n",
    "        heatmap_path = os.path.join(output_dir, 'vrae_loss_heatmap.png')\n",
    "        plt.savefig(heatmap_path)\n",
    "        plt.close()\n",
    "        print(f\"Results heatmap saved to: {heatmap_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nCould not generate heatmap. Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" SCRIPT FINISHED \".center(50, \"=\"))\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a26f84c202f2b4",
   "metadata": {},
   "source": [
    "Cluster analysis\n",
    "- Different clustering algorithms\n",
    "- Silhoutte scores for different cluster sizes\n",
    "- t-SNE visualization of the best clustering result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec2938eae05c62",
   "metadata": {},
   "source": [
    "________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6eb32dd-d40c-42dc-a111-f561c6b55c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: torch.Size([5792, 2500, 12])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtrain set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_dataset.tensors[\u001b[32m0\u001b[39m].shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtest set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mval_dataset\u001b[49m.tensors[\u001b[32m0\u001b[39m].shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m latent_vectors_val = best_model.transform(val_dataset)\n\u001b[32m      5\u001b[39m latent_vectors_train = best_model.transform(train_dataset)\n",
      "\u001b[31mNameError\u001b[39m: name 'val_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"train set: {train_dataset.tensors[0].shape}\")\n",
    "print(f\"test set: {val_dataset.tensors[0].shape}\")\n",
    "\n",
    "latent_vectors_val = best_model.transform(val_dataset)\n",
    "latent_vectors_train = best_model.transform(train_dataset)\n",
    "\n",
    "print(f\"laten vector shape train: {latent_vectors_train.shape}\")\n",
    "print(f\"laten vector shape validation: {latent_vectors_val.shape}\")\n",
    "\n",
    "print(f\"x_ecg: {x_ecg.shape}\")\n",
    "\n",
    "\n",
    "# Concatenate the list of tensors into a single tensor\n",
    "latent_vectors_complete = best_model.transform(complete_dataset)\n",
    "\n",
    "print(f\"laten vector shape complete: {latent_vectors_complete.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb80b6-35f1-49ff-93d7-9e6210d3c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The mean ECG value is: {np.mean(x_ecg)}\")\n",
    "print(f\"The median ECG value is: {np.median(x_ecg)}\")\n",
    "print(f\"The min ECG value is: {np.min(x_ecg)}\")\n",
    "print(f\"The max ECG value is: {np.max(x_ecg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef52f31-d3d4-4297-9ba4-5d6b01e504c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T09:57:27.285841Z",
     "start_time": "2025-08-11T09:57:22.632696Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'importlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check the train and valdiation reconstruction losses of the best model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvrae\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mimportlib\u001b[49m\u001b[38;5;241m.\u001b[39mreload(scripts\u001b[38;5;241m.\u001b[39mvrae)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvrae\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VRAE\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load and Split Data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'importlib' is not defined"
     ]
    }
   ],
   "source": [
    "# Check the train and valdiation reconstruction losses of the best model\n",
    "import scripts.vrae\n",
    "importlib.reload(scripts.vrae)\n",
    "from scripts.vrae import VRAE\n",
    "\n",
    "# Load and Split Data\n",
    "x_train, x_val = train_test_split(x_ecg, test_size=0.2, random_state=932, shuffle=True)\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(x_train).float())\n",
    "valid_dataset = TensorDataset(torch.from_numpy(x_val).float())\n",
    "\n",
    "# Reconstruct model with saved parameters\n",
    "sequence_length = x_train.shape[1]\n",
    "number_of_features = x_train.shape[2]\n",
    "\n",
    "# Now reconstruct the model\n",
    "best_model = VRAE(\n",
    "    sequence_length=sequence_length,\n",
    "    number_of_features=number_of_features,\n",
    "    hidden_size=128,\n",
    "    hidden_layer_depth=1,\n",
    "    latent_length=16,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.01,\n",
    "    n_epochs=n_epochs,\n",
    "    dropout_rate=dropout,\n",
    "    optimizer=optimizer,\n",
    "    cuda=cuda,\n",
    "    print_every=50,\n",
    "    clip=clip,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    loss=loss,\n",
    "    block=block,\n",
    "    dload=output_dir,\n",
    "    beta=0.0001\n",
    ")\n",
    "\n",
    "best_model.fit(train_dataset, valid_dataset=valid_dataset)\n",
    "\n",
    "print(best_model.train_recon_losses)\n",
    "print(best_model.valid_recon_loss)\n",
    "\n",
    "train_recon_loss = best_model.train_recon_losses[-1] if best_model.train_recon_losses else float('inf')\n",
    "val_recon_loss = best_model.valid_recon_loss[-1] if best_model.valid_recon_loss else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d20f8fa-ea4a-407e-92ed-3731ec009c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: ./ecg_model_logs\n",
      "Log file: ./ecg_model_logs\\training_log.txt\n",
      "Data split: 5068 training samples, 2173 validation samples.\n",
      "\n",
      "CUDA available: True\n",
      "\n",
      "==================================================\n",
      "=========== VRAE SINGLE MODEL TRAINING ===========\n",
      "==================================================\n",
      "\n",
      "Training with the following parameters:\n",
      "{\n",
      "    \"batch_size\": 32,\n",
      "    \"beta\": 0.001,\n",
      "    \"hidden_layer_depth\": 2,\n",
      "    \"hidden_size\": 128,\n",
      "    \"latent_length\": 64,\n",
      "    \"learning_rate\": 0.001\n",
      "}\n",
      "Epoch 1/20\n",
      "Batch 50, loss=0.0725, recon=0.0725, kl=40.2765, beta=0.0000\n",
      "Batch 100, loss=0.0696, recon=0.0696, kl=57.0153, beta=0.0000\n",
      "Batch 150, loss=0.0433, recon=0.0433, kl=45.9849, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.1272 (Recon: 0.1272, KL: 43.1089, Current Beta: 0.0000) | Avg Valid Loss: 0.0500 | Avg Valid recon Loss: 0.0500\n",
      "Epoch 2/20\n",
      "Batch 50, loss=0.0397, recon=0.0397, kl=64.5358, beta=0.0000\n",
      "Batch 100, loss=0.0387, recon=0.0387, kl=55.9631, beta=0.0000\n",
      "Batch 150, loss=0.0325, recon=0.0325, kl=55.8146, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0633 (Recon: 0.0633, KL: 57.7277, Current Beta: 0.0000) | Avg Valid Loss: 0.0458 | Avg Valid recon Loss: 0.0458\n",
      "Epoch 3/20\n",
      "Batch 50, loss=0.2641, recon=0.2641, kl=66.0387, beta=0.0000\n",
      "Batch 100, loss=0.0735, recon=0.0735, kl=49.8309, beta=0.0000\n",
      "Batch 150, loss=0.0345, recon=0.0345, kl=79.9262, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0543 (Recon: 0.0543, KL: 61.6069, Current Beta: 0.0000) | Avg Valid Loss: 0.0402 | Avg Valid recon Loss: 0.0401\n",
      "Epoch 4/20\n",
      "Batch 50, loss=0.1278, recon=0.1278, kl=85.0192, beta=0.0000\n",
      "Batch 100, loss=0.0628, recon=0.0628, kl=81.9394, beta=0.0000\n",
      "Batch 150, loss=0.0352, recon=0.0352, kl=80.9244, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0484 (Recon: 0.0484, KL: 82.8725, Current Beta: 0.0000) | Avg Valid Loss: 0.0404 | Avg Valid recon Loss: 0.0404\n",
      "Epoch 5/20\n",
      "Batch 50, loss=0.0576, recon=0.0576, kl=83.0726, beta=0.0000\n",
      "Batch 100, loss=0.0287, recon=0.0287, kl=75.4121, beta=0.0000\n",
      "Batch 150, loss=0.0389, recon=0.0389, kl=77.2738, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0483 (Recon: 0.0483, KL: 78.7561, Current Beta: 0.0000) | Avg Valid Loss: 0.0376 | Avg Valid recon Loss: 0.0376\n",
      "Epoch 6/20\n",
      "Batch 50, loss=0.0343, recon=0.0343, kl=86.4203, beta=0.0000\n",
      "Batch 100, loss=0.0321, recon=0.0321, kl=92.2313, beta=0.0000\n",
      "Batch 150, loss=0.0324, recon=0.0324, kl=95.2457, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0463 (Recon: 0.0463, KL: 88.2264, Current Beta: 0.0000) | Avg Valid Loss: 0.0345 | Avg Valid recon Loss: 0.0345\n",
      "Epoch 7/20\n",
      "Batch 50, loss=0.0505, recon=0.0505, kl=95.7043, beta=0.0000\n",
      "Batch 100, loss=0.0255, recon=0.0255, kl=102.9027, beta=0.0000\n",
      "Batch 150, loss=0.0207, recon=0.0207, kl=105.5708, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0427 (Recon: 0.0427, KL: 99.8732, Current Beta: 0.0000) | Avg Valid Loss: 0.0344 | Avg Valid recon Loss: 0.0343\n",
      "Epoch 8/20\n",
      "Batch 50, loss=0.0275, recon=0.0274, kl=112.6125, beta=0.0000\n",
      "Batch 100, loss=0.0273, recon=0.0273, kl=111.1958, beta=0.0000\n",
      "Batch 150, loss=0.0234, recon=0.0234, kl=110.5597, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0392 (Recon: 0.0392, KL: 111.9170, Current Beta: 0.0000) | Avg Valid Loss: 0.0350 | Avg Valid recon Loss: 0.0350\n",
      "Epoch 9/20\n",
      "Batch 50, loss=0.0375, recon=0.0375, kl=103.4752, beta=0.0000\n",
      "Batch 100, loss=0.0552, recon=0.0552, kl=98.9638, beta=0.0000\n",
      "Batch 150, loss=0.0270, recon=0.0270, kl=96.3279, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0359 (Recon: 0.0359, KL: 102.0194, Current Beta: 0.0000) | Avg Valid Loss: 0.0284 | Avg Valid recon Loss: 0.0284\n",
      "Epoch 10/20\n",
      "Batch 50, loss=0.0288, recon=0.0287, kl=87.3561, beta=0.0000\n",
      "Batch 100, loss=0.0449, recon=0.0449, kl=84.6958, beta=0.0000\n",
      "Batch 150, loss=0.0340, recon=0.0339, kl=83.0562, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0340 (Recon: 0.0340, KL: 86.5845, Current Beta: 0.0000) | Avg Valid Loss: 0.0325 | Avg Valid recon Loss: 0.0324\n",
      "Epoch 11/20\n",
      "Batch 50, loss=0.0307, recon=0.0305, kl=73.1785, beta=0.0000\n",
      "Batch 100, loss=0.0225, recon=0.0223, kl=72.6937, beta=0.0000\n",
      "Batch 150, loss=0.0315, recon=0.0313, kl=69.2090, beta=0.0000\n",
      "  â†’ Avg Train Loss: 0.0344 (Recon: 0.0342, KL: 73.2546, Current Beta: 0.0000) | Avg Valid Loss: 0.0290 | Avg Valid recon Loss: 0.0288\n",
      "Epoch 12/20\n",
      "Batch 50, loss=0.0363, recon=0.0359, kl=55.5337, beta=0.0000\n",
      "Batch 100, loss=297.2654, recon=297.2636, kl=227.4309, beta=0.0000\n",
      "Batch 150, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 13/20\n",
      "Batch 50, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 150, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 14/20\n",
      "Batch 50, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "Batch 150, loss=nan, recon=nan, kl=nan, beta=0.0000\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0000) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 15/20\n",
      "Batch 50, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 150, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 16/20\n",
      "Batch 50, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 150, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 17/20\n",
      "Batch 50, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 150, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 18/20\n",
      "Batch 50, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 150, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 19/20\n",
      "Batch 50, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 150, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "Epoch 20/20\n",
      "Batch 50, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 100, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "Batch 150, loss=nan, recon=nan, kl=nan, beta=0.0001\n",
      "  â†’ Avg Train Loss: nan (Recon: nan, KL: nan, Current Beta: 0.0001) | Avg Valid Loss: nan | Avg Valid recon Loss: nan\n",
      "\n",
      "==================================================\n",
      "====== TRAINING COMPLETE: REPORTING RESULTS ======\n",
      "==================================================\n",
      "\n",
      "Training completed in 235.77 seconds.\n",
      "Final Training Loss: nan\n",
      "  -> Final Recon Loss: nan\n",
      "  -> Final KL Loss: nan\n",
      "Final Validation Loss: nan\n",
      "\n",
      "Model saved to: ./ecg_model_logs\\vrae_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import ParameterGrid, train_test_split\n",
    "import json\n",
    "import time \n",
    "# Rerun best model for detailed loss\n",
    "output_dir = './ecg_model_logs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "log_path = os.path.join(output_dir, 'training_log.txt')\n",
    "\n",
    "# Clear previous log file\n",
    "with open(log_path, 'w') as f:\n",
    "    f.write(\"--- Starting Single Model Training Log ---\\n\\n\")\n",
    "\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Log file: {log_path}\")\n",
    "\n",
    "# Load and Split Data\n",
    "x_train, x_val = train_test_split(x_ecg, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(x_train).float())\n",
    "valid_dataset = TensorDataset(torch.from_numpy(x_val).float())\n",
    "\n",
    "print(f\"Data split: {len(train_dataset)} training samples, {len(valid_dataset)} validation samples.\")\n",
    "\n",
    "# --- 3. Define Model Parameters ---\n",
    "# Parameters for the single run\n",
    "# Parameters chosen from full dataset\n",
    "best_params_path = os.path.join(output_dir, 'best_vrae_params.json')\n",
    "\n",
    "# Load best parameters\n",
    "with open(best_params_path, 'r') as f:\n",
    "    best_vrae_params = json.load(f)\n",
    "\n",
    "# Fixed parameters\n",
    "sequence_length = x_train.shape[1]\n",
    "number_of_features = x_train.shape[2]\n",
    "n_epochs = 20\n",
    "optimizer = 'Adam'\n",
    "cuda = torch.cuda.is_available()\n",
    "print_every = 100  # Note: The provided fit method prints per epoch, so this might not be used there.\n",
    "clip = True\n",
    "dropout = 0\n",
    "max_grad_norm = 5\n",
    "loss = 'MSELoss'\n",
    "block = 'LSTM'\n",
    "\n",
    "print(f\"\\nCUDA available: {cuda}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" VRAE SINGLE MODEL TRAINING \".center(50, \"=\"))\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Log the parameters being used\n",
    "print(\"\\nTraining with the following parameters:\")\n",
    "print(json.dumps(best_vrae_params, indent=4))\n",
    "with open(log_path, 'a') as f:\n",
    "    f.write(\"--- Model Parameters ---\\n\")\n",
    "    f.write(json.dumps(best_vrae_params, indent=4))\n",
    "    f.write(\"\\n\\n--- Training Log ---\\n\")\n",
    "\n",
    "# --- 4. Instantiate and Train the VRAE Model ---\n",
    "best_model = VRAE(\n",
    "    sequence_length=sequence_length,\n",
    "    number_of_features=number_of_features,\n",
    "    hidden_size=128,\n",
    "    hidden_layer_depth=1,\n",
    "    latent_length=32,\n",
    "    batch_size=32,\n",
    "    learning_rate=0.01,\n",
    "    n_epochs=n_epochs,\n",
    "    dropout_rate=dropout,\n",
    "    optimizer=optimizer,\n",
    "    cuda=cuda,\n",
    "    print_every=50,\n",
    "    clip=clip,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    loss=loss,\n",
    "    block=block,\n",
    "    dload=output_dir,\n",
    "    beta=0.0001\n",
    ")\n",
    "\n",
    "# Your provided fit method already tracks detailed losses, which is perfect.\n",
    "# Redirecting print output to log file during fit\n",
    "def log_and_print(message, f):\n",
    "    print(message)\n",
    "    f.write(message + '\\n')\n",
    "\n",
    "# We can't directly redirect prints from inside the class easily without modifying it.\n",
    "# The VRAE's internal prints will go to the console. We will log our summary here.\n",
    "start_time = time.time()\n",
    "best_model.fit(train_dataset, valid_dataset=valid_dataset)\n",
    "runtime = time.time() - start_time\n",
    "\n",
    "# --- 5. Reporting and Visualization ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" TRAINING COMPLETE: REPORTING RESULTS \".center(50, \"=\"))\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get final losses\n",
    "final_train_loss = best_model.train_losses[-1]\n",
    "final_recon_loss = best_model.train_recon_losses[-1]\n",
    "final_kl_loss = best_model.train_kl_losses[-1]\n",
    "final_valid_loss = best_model.valid_losses[-1] if best_model.valid_losses else 'N/A'\n",
    "model_path = os.path.join(output_dir, 'vrae_model.pth')\n",
    "\n",
    "# Save the model state dictionary\n",
    "torch.save(best_model.state_dict(), model_path)\n",
    "\n",
    "# Log final results\n",
    "with open(log_path, 'a') as f:\n",
    "    f.write(\"\\n\\n--- Final Results ---\\n\")\n",
    "    log_and_print(f\"\\nTraining completed in {runtime:.2f} seconds.\", f)\n",
    "    log_and_print(f\"Final Training Loss: {final_train_loss:.4f}\", f)\n",
    "    log_and_print(f\"  -> Final Recon Loss: {final_recon_loss:.4f}\", f)\n",
    "    log_and_print(f\"  -> Final KL Loss: {final_kl_loss:.4f}\", f)\n",
    "    if final_valid_loss != 'N/A':\n",
    "        log_and_print(f\"Final Validation Loss: {final_valid_loss:.4f}\", f)\n",
    "    log_and_print(f\"\\nModel saved to: {model_path}\", f)\n",
    "\n",
    "\n",
    "# --- Plot and save detailed loss curves ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "fig.suptitle(f'Best VRAE Model Training and Loss Components', fontsize=16)\n",
    "\n",
    "# Subplot 1: Total Train and Validation Loss\n",
    "ax1.plot(best_model.train_losses, label='Total Training Loss', color='navy')\n",
    "if best_model.valid_losses:\n",
    "    ax1.plot(best_model.valid_losses, label='Validation Loss', linestyle='--', color='darkorange')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Overall Model Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Subplot 2: Detailed Training Loss Components\n",
    "ax2.plot(best_model.train_recon_losses, label='Training Reconstruction Loss', color='green')\n",
    "ax2.plot(best_model.train_kl_losses, label='Training KL Divergence Loss', color='firebrick')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Training Loss Components')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to make room for suptitle\n",
    "plot_path = os.path.join(output_dir, 'vrae_detailed_loss_curves.png')\n",
    "plt.savefig(plot_path)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26cd8bda-54a1-42a4-bb89-7cd704f8955b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latent_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save the latent_veactors locally\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m np.savetxt(\u001b[33m\"\u001b[39m\u001b[33m./data/latent_vectors_19.csv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mlatent_vectors\u001b[49m, delimiter=\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'latent_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the latent_veactors locally\n",
    "np.savetxt(\"./data/latent_vectors_19.csv\", latent_vectors, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5471de9bff3556b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:08:17.062478Z",
     "start_time": "2025-08-03T14:08:16.039059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 7232 latent vectors for the validation set.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m k_range:\n\u001b[32m     27\u001b[39m     kmeans = KMeans(n_clusters=k, random_state=\u001b[32m42\u001b[39m, n_init=\u001b[32m10\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[43mkmeans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_vectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     inertia.append(kmeans.inertia_)\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mK-Means (k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): Inertia = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkmeans.inertia_\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\miniforge3\\envs\\bao_vae_clustering\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\miniforge3\\envs\\bao_vae_clustering\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1454\u001b[39m, in \u001b[36mKMeans.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1427\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1428\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[32m   1429\u001b[39m \n\u001b[32m   1430\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1452\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m   1453\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1454\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1455\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1457\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1461\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1464\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_params_vs_input(X)\n\u001b[32m   1466\u001b[39m     random_state = check_random_state(\u001b[38;5;28mself\u001b[39m.random_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\miniforge3\\envs\\bao_vae_clustering\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\miniforge3\\envs\\bao_vae_clustering\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1107\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1116\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\miniforge3\\envs\\bao_vae_clustering\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\miniforge3\\envs\\bao_vae_clustering\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Clinical relevance analysis (new cluster analysis code block)\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate latent representations for all patients\n",
    "complete_tensor = torch.from_numpy(x_ecg).float()\n",
    "latent_vectors = best_model.transform(TensorDataset(complete_tensor))\n",
    "print(f\"Generated {latent_vectors.shape[0]} latent vectors for the validation set.\")\n",
    "\n",
    "# Save the latent_veactors locally\n",
    "np.savetxt(\"./data/latent_vectors_292.csv\", latent_vectors, delimiter=\",\")\n",
    "\n",
    "\n",
    "# Elbow Method for K-Means\n",
    "inertia = []\n",
    "k_range = range(2, 7)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(latent_vectors)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    print(f\"K-Means (k={k}): Inertia = {kmeans.inertia_:.4f}\")\n",
    "\n",
    "# Plotting the elbow method\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertia, marker='o', linestyle='--')\n",
    "plt.title('Elbow Method for K-Means')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia (Within-cluster sum of squares)')\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "elbow_plot_path = os.path.join(output_dir, 'kmeans_elbow_plot.png')\n",
    "plt.savefig(elbow_plot_path)\n",
    "plt.close()\n",
    "print(f\"\\nElbow method plot saved to: {elbow_plot_path}\")\n",
    "\n",
    "# --- Run Clustering Algorithms and get Silhouette Scores ---\n",
    "cluster_ranges = range(2, 7)\n",
    "clustering_results = []\n",
    "# K-Means\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(latent_vectors)\n",
    "    score = silhouette_score(latent_vectors, labels)\n",
    "    clustering_results.append({'Method': 'K-Means', 'Num Clusters': k, 'Silhouette Score': score, 'labels': labels})\n",
    "    print(f\"K-Means (k={k}): Silhouette Score = {score:.4f}\")\n",
    "\n",
    "# K-Means\n",
    "for k in cluster_ranges:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(latent_vectors)\n",
    "    score = silhouette_score(latent_vectors, labels)\n",
    "    clustering_results.append({'Method': 'K-Means', 'Num Clusters': k, 'Silhouette Score': score, 'labels': labels})\n",
    "    print(f\"K-Means (k={k}): Silhouette Score = {score:.4f}\")\n",
    "\n",
    "# Agglomerative\n",
    "for k in cluster_ranges:\n",
    "    agg = AgglomerativeClustering(n_clusters=k)\n",
    "    labels = agg.fit_predict(latent_vectors)\n",
    "    score = silhouette_score(latent_vectors, labels)\n",
    "    clustering_results.append({'Method': 'Agglomerative', 'Num Clusters': k, 'Silhouette Score': score, 'labels': labels})\n",
    "    print(f\"Agglomerative (k={k}): Silhouette Score = {score:.4f}\")\n",
    "\n",
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=0.7, min_samples=5)\n",
    "labels = dbscan.fit_predict(latent_vectors)\n",
    "num_clusters_found = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "if num_clusters_found > 1:\n",
    "    score = silhouette_score(latent_vectors, labels)\n",
    "    print(f\"DBSCAN: Found {num_clusters_found} clusters. Silhouette Score = {score:.4f}\")\n",
    "else:\n",
    "    score = -1.0 # Or np.nan\n",
    "    print(f\"DBSCAN: Found {num_clusters_found} clusters. Silhouette score cannot be calculated.\")\n",
    "clustering_results.append({'Method': 'DBSCAN', 'Num Clusters': num_clusters_found, 'Silhouette Score': score, 'labels': labels})\n",
    "\n",
    "# Report & save clustering results\n",
    "clustering_df = pd.DataFrame(clustering_results)\n",
    "clustering_df = clustering_df.sort_values(by='Silhouette Score', ascending=False)\n",
    "print(\"\\nClustering Analysis Summary:\")\n",
    "print(clustering_df.drop(columns='labels').to_string(index=False))\n",
    "\n",
    "clustering_csv_path = os.path.join(output_dir, 'vrae_clustering_results.csv')\n",
    "clustering_df.drop(columns='labels').to_csv(clustering_csv_path, index=False)\n",
    "print(f\"\\nClustering results saved to: {clustering_csv_path}\")\n",
    "\n",
    "# --- Bar chart for Silhouette Scores ---\n",
    "plt.figure(figsize=(12, 7))\n",
    "# Create a unique identifier for each bar\n",
    "clustering_df['Method-K'] = clustering_df.apply(lambda row: f\"{row['Method']} (k={row['Num Clusters']})\", axis=1)\n",
    "# Filter out results where score couldn't be calculated if desired\n",
    "plot_df = clustering_df[clustering_df['Silhouette Score'] > -1.0]\n",
    "sns.barplot(x='Silhouette Score', y='Method-K', data=plot_df, orient='h', hue='Method-K', palette='viridis', legend=False)\n",
    "plt.title('Comparison of Silhouette Scores for Clustering Methods')\n",
    "plt.xlabel('Silhouette Score')\n",
    "plt.ylabel('Clustering Method and Number of Clusters (k)')\n",
    "plt.tight_layout()\n",
    "sil_plot_path = os.path.join(output_dir, 'clustering_silhouette_scores.png')\n",
    "plt.savefig(sil_plot_path)\n",
    "plt.close()\n",
    "print(f\"Silhouette score comparison chart saved to: {sil_plot_path}\")\n",
    "\n",
    "# t-SNE visualization for the clustering results\n",
    "print(\"\\n--- Generating t-SNE Visualizations for All Clustering Results ---\")\n",
    "\n",
    "# Ensure perplexity is less than number of samples\n",
    "perplexity_value = min(30, len(latent_vectors) - 1)\n",
    "\n",
    "# Run t-SNE once to save compute time\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity_value)\n",
    "tsne_results = tsne.fit_transform(latent_vectors)\n",
    "\n",
    "for idx, result in clustering_df.iterrows():\n",
    "    method = result['Method']\n",
    "    k = result['Num Clusters']\n",
    "    score = result['Silhouette Score']\n",
    "    labels = result['labels']\n",
    "\n",
    "    # Skip visualizing if only one cluster\n",
    "    if len(np.unique(labels)) <= 1:\n",
    "        print(f\"Skipping t-SNE for {method} (k={k}): Only one cluster.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Generating t-SNE for {method} (k={k})...\")\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(\n",
    "        x=tsne_results[:, 0], y=tsne_results[:, 1],\n",
    "        hue=labels,\n",
    "        palette=sns.color_palette(\"hsv\", len(np.unique(labels))),\n",
    "        legend='full'\n",
    "    )\n",
    "    plt.title(f't-SNE of Latent Space\\n{method} (k={k}) | Silhouette: {score:.4f}')\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Safe filename\n",
    "    filename = f\"tsne_{method.replace(' ', '_').lower()}_k{k}.png\"\n",
    "    tsne_plot_path = os.path.join(output_dir, filename)\n",
    "    plt.savefig(tsne_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"t-SNE plot saved to: {tsne_plot_path}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Part 5: Generate Detailed Clinical Heatmaps for K-Means\n",
    "# =============================================================================\n",
    "print(\"\\n--- Part 5: Generating Clinical Characterization Heatmaps ---\")\n",
    "heatmap_output_dir = os.path.join(output_dir, 'cluster_heatmaps_detailed')\n",
    "if not os.path.exists(heatmap_output_dir):\n",
    "    os.makedirs(heatmap_output_dir)\n",
    "\n",
    "# --- Pre-process the VALIDATION clinical data for analysis ---\n",
    "df_analysis = df_merged.copy() # Use the validation metadata\n",
    "df_analysis['gender_male'] = (df_analysis['gender'] == 'M').astype(int)\n",
    "df_analysis['is_cabg'] = (df_analysis['nice_ap4_model'] == 'CABG').astype(int)\n",
    "df_analysis['cardiogroep'] = df_analysis['cardiogroep'].fillna('Unknown')\n",
    "df_analysis['adm_type'] = df_analysis['adm_type'].fillna('Unknown')\n",
    "\n",
    "# --- Define Variable Groupings for the Heatmap ---\n",
    "mean_vars = {'Age (years)': 'nice_age', 'Height (cm)': 'length', 'Weight (kg)': 'weight', 'APACHE IV Probability': 'nice_ap4_prob', 'Hospital Length of Stay (days)': 'los_hosp'}\n",
    "proportion_vars = {'Gender (% Male)': 'gender_male', 'Admission Model (% CABG)': 'is_cabg', 'ICU Mortality': 'nice_died', 'Required Vasoactive Meds': 'cardio_vasc_insuf'}\n",
    "float_format_rows = list(mean_vars.keys()) + list(proportion_vars.keys())\n",
    "\n",
    "# --- Generate a Heatmap for each K-Means Result ---\n",
    "\n",
    "print(\"\\n--- Part 5: Generating Clinical Characterization Heatmaps ---\")\n",
    "heatmap_output_dir = os.path.join(output_dir, 'cluster_heatmaps_detailed')\n",
    "if not os.path.exists(heatmap_output_dir):\n",
    "    os.makedirs(heatmap_output_dir)\n",
    "\n",
    "# --- Pre-process the VALIDATION clinical data for analysis ---\n",
    "df_analysis = df_merged.copy()  # Use the validation metadata\n",
    "df_analysis['gender_male'] = (df_analysis['gender'] == 'M').astype(int)\n",
    "df_analysis['is_cabg'] = (df_analysis['nice_ap4_model'] == 'CABG').astype(int)\n",
    "df_analysis['cardiogroep'] = df_analysis['cardiogroep'].fillna('Unknown')\n",
    "df_analysis['adm_type'] = df_analysis['adm_type'].fillna('Unknown')\n",
    "\n",
    "# --- Define Variable Groupings for the Heatmap ---\n",
    "mean_vars = {\n",
    "    'Age (years)': 'nice_age',\n",
    "    'Height (cm)': 'length',\n",
    "    'Weight (kg)': 'weight',\n",
    "    'APACHE IV Probability': 'nice_ap4_prob',\n",
    "    'Hospital Length of Stay (days)': 'los_hosp'\n",
    "}\n",
    "proportion_vars = {\n",
    "    'Gender (% Male)': 'gender_male',\n",
    "    'Admission Model (% CABG)': 'is_cabg',\n",
    "    'ICU Mortality': 'nice_died',\n",
    "    'Required Vasoactive Meds': 'cardio_vasc_insuf'\n",
    "}\n",
    "float_format_rows = list(mean_vars.keys()) + list(proportion_vars.keys())\n",
    "\n",
    "# --- Generate a Heatmap for each K-Means Result ---\n",
    "kmeans_results = clustering_df[clustering_df['Method'] == 'K-Means'].sort_values('Num Clusters')\n",
    "\n",
    "for index, result in kmeans_results.iterrows():\n",
    "    k = result['Num Clusters']\n",
    "    labels = result['labels']\n",
    "    print(f\"Generating heatmap for k={k}...\")\n",
    "\n",
    "    df_clustered = df_analysis.iloc[:len(labels)].copy()\n",
    "    df_clustered['cluster'] = labels + 1\n",
    "\n",
    "    # --- Calculate Statistics per cluster ---\n",
    "    all_stats_list = []\n",
    "    for d_name, c_name in {**mean_vars, **proportion_vars}.items():\n",
    "        all_stats_list.append(df_clustered.groupby('cluster')[c_name].mean().rename(d_name))\n",
    "    summary_df = pd.concat(all_stats_list, axis=1).T\n",
    "\n",
    "    # Admission type counts\n",
    "    adm_type_counts = pd.crosstab(df_clustered['adm_type'], df_clustered['cluster'])\n",
    "    adm_type_counts.index = [f\"Adm: {idx}\" for idx in adm_type_counts.index]\n",
    "\n",
    "    # Diagnosis counts\n",
    "    diag_counts = pd.crosstab(df_clustered['cardiogroep'], df_clustered['cluster'])\n",
    "    diag_counts.index = [f\"Diag: {idx}\" for idx in diag_counts.index]\n",
    "\n",
    "    # Combine all into summary table\n",
    "    summary_df = pd.concat([summary_df, adm_type_counts, diag_counts])\n",
    "\n",
    "    # --- Drop rows that are entirely zero (across clusters only, not 'Total') ---\n",
    "    cluster_cols = summary_df.columns  # All clusters\n",
    "    rows_with_data = summary_df[cluster_cols].sum(axis=1) > 0\n",
    "    summary_df = summary_df[rows_with_data]\n",
    "\n",
    "    # --- Add Total column for each row (diagnosis, admission, or variable) ---\n",
    "    summary_df['Total'] = 0.0\n",
    "    all_var_map = {**mean_vars, **proportion_vars}\n",
    "    for idx, row in summary_df.iterrows():\n",
    "        if idx in all_var_map:\n",
    "            summary_df.loc[idx, 'Total'] = df_clustered[all_var_map[idx]].mean()\n",
    "        else:\n",
    "            summary_df.loc[idx, 'Total'] = row.drop('Total').sum()\n",
    "\n",
    "    # --- Add final 'Total Patients' row across clusters ---\n",
    "    total_row = df_clustered['cluster'].value_counts().sort_index()\n",
    "    total_row.name = 'Total Patients'\n",
    "    summary_df = pd.concat([summary_df, pd.DataFrame(total_row).T])\n",
    "    summary_df.loc['Total Patients', 'Total'] = summary_df.loc['Total Patients'].drop('Total').sum()\n",
    "\n",
    "    # --- Prepare data for heatmap ---\n",
    "    heatmap_data = summary_df.drop(columns='Total').iloc[:-1]  # exclude final row\n",
    "    heatmap_data = heatmap_data.div(heatmap_data.sum(axis=1), axis=0).fillna(0)\n",
    "\n",
    "    # --- Prepare annotation strings ---\n",
    "    annot_data_str = summary_df.copy()\n",
    "    for r_idx in annot_data_str.index:\n",
    "        for c_idx in annot_data_str.columns:\n",
    "            val = summary_df.loc[r_idx, c_idx]\n",
    "            if r_idx in float_format_rows:\n",
    "                annot_data_str.loc[r_idx, c_idx] = f\"{val:.2f}\"\n",
    "            else:\n",
    "                annot_data_str.loc[r_idx, c_idx] = f\"{int(val)}\"\n",
    "\n",
    "    # --- Plot the heatmap ---\n",
    "    plt.figure(figsize=(14, max(10, 0.5 * len(summary_df))))\n",
    "    ax = sns.heatmap(\n",
    "        heatmap_data,\n",
    "        annot=annot_data_str.iloc[:-1, :-1],\n",
    "        fmt='s',\n",
    "        cmap='Blues',\n",
    "        linewidths=.5,\n",
    "        cbar_kws={'label': 'Fraction of Category Total per Cluster'}\n",
    "    )\n",
    "\n",
    "    # Add Total column on the right\n",
    "    for i, idx in enumerate(summary_df.index[:-1]):\n",
    "        ax.text(len(summary_df.columns) - 0.5, i + 0.5,\n",
    "                annot_data_str.loc[idx, 'Total'],\n",
    "                ha='center', va='center', color='black', fontweight='bold')\n",
    "\n",
    "    # Add Total row at the bottom\n",
    "    for j, col in enumerate(summary_df.columns):\n",
    "        ax.text(j + 0.5, len(summary_df.index) - 0.5,\n",
    "                annot_data_str.loc['Total Patients', col],\n",
    "                ha='center', va='center', color='black', fontweight='bold')\n",
    "\n",
    "    ax.set_title(f'Clinical Profiles for K-Means Clusters (k={k})', fontsize=16, pad=20)\n",
    "    ax.set_xlabel('Cluster', fontsize=12)\n",
    "    ax.set_ylabel('')\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "\n",
    "    fig_path = os.path.join(heatmap_output_dir, f'kmeans_k{k}_heatmap_detailed.png')\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  > Heatmap saved to: {fig_path}\")\n",
    "\n",
    "print(\"\\n\\nWorkflow complete. All heatmaps generated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f2e43b20142166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:44:38.797175Z",
     "start_time": "2025-08-07T14:43:48.580087Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 50\u001b[0m\n\u001b[0;32m     30\u001b[0m labels \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mfit_predict(latent_tsne)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# # Option B: DBSCAN\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# cluster_algo = \"dbscan\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# dbscan = DBSCAN(eps=5, min_samples=5)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Example: df_merged = pd.read_csv(\"your_clinical_data.csv\")\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# For demo purposes, assume df_merged already exists\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m df_analysis \u001b[38;5;241m=\u001b[39m \u001b[43mdf_merged\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     51\u001b[0m df_analysis \u001b[38;5;241m=\u001b[39m df_analysis\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;28mlen\u001b[39m(labels)]  \u001b[38;5;66;03m# Ensure matching lengths\u001b[39;00m\n\u001b[0;32m     52\u001b[0m df_analysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m labels \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# 1-indexed for readability\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_merged' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fb72012fd83ad17",
   "metadata": {},
   "source": [
    "Run full model\n",
    "- Run VRAE with saved parameters (50 epochs)\n",
    "- Cluster for 4 clusters using k-means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
